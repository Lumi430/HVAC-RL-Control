Using TensorFlow backend.
[2019-03-24 05:42:53,677] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-24 05:42:53,678] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-24 05:42:53.768845: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-24 05:43:26,690] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-24 05:43:26,690] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-24 05:43:26,703] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-24 05:43:26,707] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-24 05:43:26,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-24 05:43:26,714] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-24 05:43:26,720] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-24 05:43:26,720] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:26,720] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-24 05:43:26,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:26,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-24 05:43:27,721] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:27,724] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-24 05:43:27,822] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:27,823] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-24 05:43:28,287] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 05:43:28,287] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:43:28,287] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:43:28,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,288] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:43:28,288] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:43:28,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,289] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,289] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,289] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:43:28,290] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-24 05:43:28,307] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-24 05:43:28,307] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-24 05:43:28,307] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-24 05:43:28,320] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-24 05:43:28,725] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:28,726] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-24 05:43:28,836] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:28,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-24 05:43:29,727] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:29,730] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-24 05:43:30,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:30,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-24 05:43:30,730] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:30,731] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-24 05:43:30,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:30,903] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-24 05:43:31,733] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:31,735] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-24 05:43:31,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:31,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-24 05:43:32,736] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:32,739] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-24 05:43:32,866] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:32,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-24 05:43:33,740] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:33,744] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-24 05:43:33,863] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:33,890] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-24 05:43:34,743] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:34,747] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-24 05:43:34,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:34,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-24 05:43:35,747] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:35,749] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-24 05:43:35,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:35,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-24 05:43:36,749] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:36,753] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-24 05:43:36,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:36,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-24 05:43:37,755] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:37,760] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-24 05:43:37,861] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:37,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-24 05:43:38,759] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:38,761] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-24 05:43:38,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:38,902] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-24 05:43:39,762] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:39,766] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-24 05:43:39,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:39,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-24 05:43:40,767] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:40,774] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-24 05:43:40,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:40,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-24 05:43:41,775] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 05:43:41,778] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-24 05:43:41,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:41,918] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-24 05:43:42,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 05:43:42,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.16666666666667, 93.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2, 6.911199999999999, 6.9112, 121.9260426156618, 277343.6284752955, 277343.6284752959, 124614.5920652939]
[2019-03-24 05:43:42,957] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:43:43,034] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.18386216 0.18034972 0.22861554 0.2107792  0.1963934 ], sampled 0.6336049373835638
[2019-03-24 05:44:12,734] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 05:44:12,737] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.90339617666667, 47.93447812333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6362765305273528, 6.911200000000001, 6.9112, 121.9260426156618, 474738.6254689652, 474738.6254689647, 136109.3540438039]
[2019-03-24 05:44:12,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:44:12,740] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.18096817 0.17687051 0.23060958 0.21092613 0.20062557], sampled 0.27128573025845626
[2019-03-24 05:44:44,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 05:44:44,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.62102789166667, 93.60186230333335, 1.0, 2.0, 0.6607397991805127, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753034.4752660503, 753034.4752660503, 168841.5799941889]
[2019-03-24 05:44:44,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:44:44,371] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.18284108 0.17953436 0.23366345 0.2065726  0.19738854], sampled 0.6048557624914896
[2019-03-24 05:45:08,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 05:45:08,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 70.0, 1.0, 2.0, 0.3043047459633435, 0.0, 1.0, 0.0, 1.0, 2.0, 0.48446306608733, 6.9112, 6.9112, 121.9260426156618, 693595.5275830106, 693595.5275830106, 196406.1788240393]
[2019-03-24 05:45:08,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:45:08,990] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.18751249 0.18196163 0.22662584 0.207706   0.19619407], sampled 0.43608278061745875
[2019-03-24 05:45:09,296] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 05:45:09,297] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.3, 64.5, 1.0, 2.0, 0.6159612399750618, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701977.7075183219, 701977.7075183224, 160844.7436934758]
[2019-03-24 05:45:09,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:45:09,302] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.18350622 0.17812574 0.23432547 0.20709719 0.19694544], sampled 0.017677358229513884
[2019-03-24 05:45:09,303] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 701977.7075183219 W.
[2019-03-24 05:45:19,193] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3833.1298 2512982098.5619 320.0000
[2019-03-24 05:45:19,418] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 3938.1421 2448565447.5886 215.0000
[2019-03-24 05:45:19,419] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3947.6592 2727018873.6985 383.0000
[2019-03-24 05:45:19,632] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 3896.5118 2483343234.8587 253.0000
[2019-03-24 05:45:19,723] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3806.6492 2547904283.9463 293.0000
[2019-03-24 05:45:20,738] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3947.6591907206266, 2727018873.6985207, 383.0, 3896.511783124645, 2483343234.858708, 253.0, 3938.142137055984, 2448565447.588602, 215.0, 3806.64918664678, 2547904283.9463296, 293.0, 3833.129794561616, 2512982098.5618787, 320.0]
[2019-03-24 05:45:24,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.19000058 0.17995788 0.22212724 0.20895055 0.1989637 ], sum to 1.0000
[2019-03-24 05:45:24,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0818
[2019-03-24 05:45:24,791] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4863381604120028, 6.9112, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483305, 111857.1499152333], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835757939017477, 6.911200000000001, 6.9112, 121.9260426156618, 345282.8161442537, 345282.8161442532, 111393.6030497234], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3544697423771846, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12331529148009061, 0.12331529148009042, 0.21421846740331424], 
reward next is 0.7858, 
noisyNet noise sample is [array([0.7868976], dtype=float32), 0.18604526]. 
=============================================
[2019-03-24 05:45:25,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.17531617 0.18086974 0.23890668 0.20890562 0.19600186], sum to 1.0000
[2019-03-24 05:45:25,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5700
[2019-03-24 05:45:25,404] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.1, 76.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 352402.1130053058, 352402.1130053053, 166772.1881737476], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 14400.0000, 
sim time next is 15000.0000, 
raw observation next is [18.08333333333334, 75.83333333333334, 1.0, 2.0, 0.1632018030703928, 0.0, 1.0, 0.0, 1.0, 2.0, 0.2939938768200199, 6.911199999999999, 6.9112, 121.9260426156618, 420723.4174224698, 420723.4174224702, 155390.1034745324], 
processed observation next is [1.0, 0.17391304347826086, 0.22530864197530887, 0.7583333333333334, 1.0, 1.0, 0.0038116703218961973, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.11749234602502483, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1502583633651678, 0.15025836336516793, 0.29882712206640843], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04326516], dtype=float32), -0.3046056]. 
=============================================
[2019-03-24 05:45:25,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[-0.03076624]
 [-0.01486105]
 [-0.03547088]
 [-0.05410136]
 [-0.0544185 ]], R is [[-0.03442614]
 [-0.03408188]
 [ 0.75875092]
 [ 1.53937125]
 [ 1.52397752]].
[2019-03-24 05:45:29,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.18238598 0.17604947 0.23093788 0.20481431 0.20581234], sum to 1.0000
[2019-03-24 05:45:29,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2226
[2019-03-24 05:45:29,777] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 76.83333333333334, 1.0, 2.0, 0.1979356909852966, 1.0, 1.0, 0.1979356909852966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489778.3946960522, 489778.3946960527, 159464.631379217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100200.0000, 
sim time next is 100800.0000, 
raw observation next is [21.7, 77.0, 1.0, 2.0, 0.389625214246334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484782.9932560057, 484782.9932560062, 127209.8777966439], 
processed observation next is [1.0, 0.17391304347826086, 0.3592592592592592, 0.77, 1.0, 1.0, 0.27336335029325476, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17313678330571633, 0.1731367833057165, 0.24463438037816135], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0319028], dtype=float32), 1.4811491]. 
=============================================
[2019-03-24 05:45:35,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.15448083 0.16620094 0.28167346 0.19704537 0.20059934], sum to 1.0000
[2019-03-24 05:45:35,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-24 05:45:35,357] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 52.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.612865005458666, 6.9112, 6.9112, 121.9260426156618, 455511.3062769845, 455511.3062769845, 132053.0227348573], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 205200.0000, 
sim time next is 205800.0000, 
raw observation next is [25.58333333333333, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6099520187547869, 6.911200000000001, 6.9112, 121.9260426156618, 452471.2262896822, 452471.2262896817, 131139.7503181751], 
processed observation next is [0.0, 0.391304347826087, 0.5030864197530862, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5124400234434836, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16159686653202937, 0.16159686653202918, 0.2521918275349521], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.6949429], dtype=float32), -0.19588985]. 
=============================================
[2019-03-24 05:45:39,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7845: loss 4.5029
[2019-03-24 05:45:39,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7845: learning rate 0.0000
[2019-03-24 05:45:39,775] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7859: loss -1.2092
[2019-03-24 05:45:39,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7859: learning rate 0.0000
[2019-03-24 05:45:39,925] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7938: loss 5.5394
[2019-03-24 05:45:39,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7939: learning rate 0.0000
[2019-03-24 05:45:39,933] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7942: loss -0.0963
[2019-03-24 05:45:39,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7942: learning rate 0.0000
[2019-03-24 05:45:39,975] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7962: loss 4.4160
[2019-03-24 05:45:39,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7962: learning rate 0.0000
[2019-03-24 05:45:39,983] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7964: loss 2.5199
[2019-03-24 05:45:39,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7966: learning rate 0.0000
[2019-03-24 05:45:40,020] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7989: loss -0.7904
[2019-03-24 05:45:40,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7990: learning rate 0.0000
[2019-03-24 05:45:40,033] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7996: loss -0.2148
[2019-03-24 05:45:40,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7998: learning rate 0.0000
[2019-03-24 05:45:40,042] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8000: loss 0.3442
[2019-03-24 05:45:40,043] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8000: learning rate 0.0000
[2019-03-24 05:45:40,047] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8001: loss 5.4377
[2019-03-24 05:45:40,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8001: learning rate 0.0000
[2019-03-24 05:45:40,065] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8014: loss 0.8138
[2019-03-24 05:45:40,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8014: learning rate 0.0000
[2019-03-24 05:45:40,081] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8018: loss 4.8137
[2019-03-24 05:45:40,082] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8018: learning rate 0.0000
[2019-03-24 05:45:40,117] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8034: loss 1.4660
[2019-03-24 05:45:40,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8034: learning rate 0.0000
[2019-03-24 05:45:40,147] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8048: loss 5.4620
[2019-03-24 05:45:40,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8048: learning rate 0.0000
[2019-03-24 05:45:40,205] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8086: loss 3.4510
[2019-03-24 05:45:40,207] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8086: learning rate 0.0000
[2019-03-24 05:45:40,250] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8105: loss 7.3134
[2019-03-24 05:45:40,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8106: learning rate 0.0000
[2019-03-24 05:45:44,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.05107445 0.1075857  0.77433306 0.03067045 0.03633639], sum to 1.0000
[2019-03-24 05:45:44,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0650
[2019-03-24 05:45:44,542] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 31.0, 1.0, 2.0, 0.4134274946475043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7097081622654724, 6.911200000000001, 6.9112, 121.9260426156549, 1047261.564302087, 1047261.564302086, 222187.4228776993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 382800.0000, 
sim time next is 383400.0000, 
raw observation next is [27.95, 30.5, 1.0, 2.0, 0.8270187989662371, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1055000.02637714, 1055000.02637714, 205471.7622767377], 
processed observation next is [1.0, 0.43478260869565216, 0.5907407407407407, 0.305, 1.0, 1.0, 0.7940699987693298, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37678572370612146, 0.37678572370612146, 0.39513800437834173], 
reward next is 0.6049, 
noisyNet noise sample is [array([1.1587294], dtype=float32), -0.3692725]. 
=============================================
[2019-03-24 05:45:44,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.02214621 0.01609892 0.94490993 0.00498015 0.01186483], sum to 1.0000
[2019-03-24 05:45:44,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3231
[2019-03-24 05:45:45,095] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.23333333333333, 25.33333333333334, 1.0, 2.0, 0.4213277590294748, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7170517664058319, 6.9112, 6.9112, 121.9260426156618, 1062498.224518893, 1062498.224518893, 225199.9015175331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 393600.0000, 
sim time next is 394200.0000, 
raw observation next is [30.35, 25.0, 1.0, 2.0, 0.4538360799351875, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7702548645016288, 6.911199999999999, 6.9112, 121.9260426156618, 1142765.256633013, 1142765.256633014, 235731.0963609077], 
processed observation next is [1.0, 0.5652173913043478, 0.6796296296296297, 0.25, 1.0, 1.0, 0.34980485706569936, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.712818580627036, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40813044879750465, 0.408130448797505, 0.453329031463284], 
reward next is 0.5467, 
noisyNet noise sample is [array([-1.2665073], dtype=float32), -0.29840815]. 
=============================================
[2019-03-24 05:45:45,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.00325582 0.01712336 0.9618495  0.00580769 0.01196368], sum to 1.0000
[2019-03-24 05:45:45,535] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0206
[2019-03-24 05:45:45,538] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.7, 24.83333333333334, 1.0, 2.0, 0.500955389362224, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8448202571274307, 6.911200000000001, 6.9112, 121.9260426156618, 1256669.698952982, 1256669.698952981, 251946.8239385696], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 399000.0000, 
sim time next is 399600.0000, 
raw observation next is [30.7, 25.0, 1.0, 2.0, 0.4941123120008425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.832766801155182, 6.9112, 6.9112, 121.9260426156618, 1239004.714707402, 1239004.714707402, 249647.3790955647], 
processed observation next is [1.0, 0.6521739130434783, 0.6925925925925925, 0.25, 1.0, 1.0, 0.39775275238195534, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7909585014439774, 0.0, 0.0, 0.8094621288201359, 0.4425016838240722, 0.4425016838240722, 0.48009111364531676], 
reward next is 0.5199, 
noisyNet noise sample is [array([0.30576134], dtype=float32), -0.14423592]. 
=============================================
[2019-03-24 05:45:55,129] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15807: loss 0.6191
[2019-03-24 05:45:55,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15807: learning rate 0.0000
[2019-03-24 05:45:55,167] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15825: loss 0.9046
[2019-03-24 05:45:55,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15825: learning rate 0.0000
[2019-03-24 05:45:55,199] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15841: loss 0.7681
[2019-03-24 05:45:55,201] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15841: learning rate 0.0000
[2019-03-24 05:45:55,305] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15894: loss 0.8676
[2019-03-24 05:45:55,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15895: learning rate 0.0000
[2019-03-24 05:45:55,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15898: loss 0.8994
[2019-03-24 05:45:55,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15898: learning rate 0.0000
[2019-03-24 05:45:55,426] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15958: loss 1.0200
[2019-03-24 05:45:55,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15958: learning rate 0.0000
[2019-03-24 05:45:55,432] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15961: loss 0.8477
[2019-03-24 05:45:55,436] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15963: learning rate 0.0000
[2019-03-24 05:45:55,444] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15966: loss 0.8171
[2019-03-24 05:45:55,448] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15967: learning rate 0.0000
[2019-03-24 05:45:55,488] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15982: loss 0.7902
[2019-03-24 05:45:55,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15983: learning rate 0.0000
[2019-03-24 05:45:55,607] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16049: loss 0.7942
[2019-03-24 05:45:55,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16049: learning rate 0.0000
[2019-03-24 05:45:55,617] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16050: loss 0.9277
[2019-03-24 05:45:55,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16051: learning rate 0.0000
[2019-03-24 05:45:55,673] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16075: loss 0.7973
[2019-03-24 05:45:55,678] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16075: learning rate 0.0000
[2019-03-24 05:45:55,692] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16084: loss 0.8248
[2019-03-24 05:45:55,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16085: learning rate 0.0000
[2019-03-24 05:45:55,721] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16102: loss 0.7180
[2019-03-24 05:45:55,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16103: learning rate 0.0000
[2019-03-24 05:45:55,785] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16130: loss 0.6377
[2019-03-24 05:45:55,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16133: learning rate 0.0000
[2019-03-24 05:45:55,898] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16186: loss 0.5319
[2019-03-24 05:45:55,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16187: learning rate 0.0000
[2019-03-24 05:46:07,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1131701e-04 9.4160969e-05 9.9869257e-01 1.5267613e-05 2.8666673e-04], sum to 1.0000
[2019-03-24 05:46:07,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0447
[2019-03-24 05:46:07,302] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.66666666666666, 36.66666666666667, 1.0, 2.0, 0.2235169772148256, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3622581953817712, 6.911199999999999, 6.9112, 121.9260426156618, 539633.3522797812, 539633.3522797817, 174402.9197470827], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [31.83333333333333, 36.33333333333333, 1.0, 2.0, 0.2245054215201489, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3636457793221454, 6.911199999999999, 6.9112, 121.9260426156618, 541527.6370404379, 541527.6370404384, 174677.7465113599], 
processed observation next is [0.0, 0.5217391304347826, 0.7345679012345677, 0.3633333333333333, 1.0, 1.0, 0.07679216847636774, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.20455722415268177, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1934027275144421, 0.19340272751444226, 0.33591874329107674], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.8251392], dtype=float32), 0.3606603]. 
=============================================
[2019-03-24 05:46:11,102] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23761: loss 0.9251
[2019-03-24 05:46:11,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23761: learning rate 0.0000
[2019-03-24 05:46:11,166] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23790: loss 0.9312
[2019-03-24 05:46:11,169] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23790: learning rate 0.0000
[2019-03-24 05:46:11,327] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23874: loss 0.9439
[2019-03-24 05:46:11,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23874: learning rate 0.0000
[2019-03-24 05:46:11,387] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23902: loss 0.9259
[2019-03-24 05:46:11,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23902: learning rate 0.0000
[2019-03-24 05:46:11,445] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23937: loss 0.9243
[2019-03-24 05:46:11,448] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23938: loss 0.9119
[2019-03-24 05:46:11,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23938: learning rate 0.0000
[2019-03-24 05:46:11,451] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23938: learning rate 0.0000
[2019-03-24 05:46:11,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23940: loss 0.8968
[2019-03-24 05:46:11,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23941: learning rate 0.0000
[2019-03-24 05:46:11,508] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23963: loss 0.8166
[2019-03-24 05:46:11,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23964: learning rate 0.0000
[2019-03-24 05:46:11,607] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24014: loss 0.7151
[2019-03-24 05:46:11,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24017: learning rate 0.0000
[2019-03-24 05:46:11,619] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24019: loss 0.7604
[2019-03-24 05:46:11,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24019: learning rate 0.0000
[2019-03-24 05:46:11,645] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24030: loss 0.6299
[2019-03-24 05:46:11,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24030: learning rate 0.0000
[2019-03-24 05:46:11,726] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24070: loss 0.6520
[2019-03-24 05:46:11,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24070: learning rate 0.0000
[2019-03-24 05:46:11,818] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24115: loss 0.4721
[2019-03-24 05:46:11,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24115: learning rate 0.0000
[2019-03-24 05:46:11,858] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24132: loss 0.4340
[2019-03-24 05:46:11,858] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24132: loss 0.5709
[2019-03-24 05:46:11,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24133: learning rate 0.0000
[2019-03-24 05:46:11,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24133: learning rate 0.0000
[2019-03-24 05:46:11,956] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24189: loss 0.4838
[2019-03-24 05:46:11,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24189: learning rate 0.0000
[2019-03-24 05:46:13,586] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 05:46:13,594] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:46:13,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:46:13,596] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:46:13,597] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:46:13,597] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:46:13,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:46:13,599] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:46:13,599] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:46:13,599] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:46:13,600] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:46:13,610] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-24 05:46:13,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-24 05:46:13,656] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-24 05:46:13,679] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-24 05:46:13,679] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-24 05:46:21,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:46:21,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 77.0, 1.0, 2.0, 0.1746344571106185, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3143806361744218, 6.911199999999999, 6.9112, 121.9260426156618, 450120.6483111135, 450120.648311114, 157818.0053158975]
[2019-03-24 05:46:21,375] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:46:21,378] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9150970e-07 1.2915838e-07 9.9999917e-01 2.6931142e-09 4.4955732e-07], sampled 0.10476929843195704
[2019-03-24 05:46:23,197] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:46:23,199] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.35, 49.5, 1.0, 2.0, 0.4402460052238437, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7257443563090344, 6.9112, 6.9112, 121.9260426156618, 1085027.67835552, 1085027.67835552, 233495.2065731562]
[2019-03-24 05:46:23,201] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:46:23,205] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3781569e-07 9.3327273e-08 9.9999940e-01 1.7843027e-09 3.3168965e-07], sampled 0.050016970663884774
[2019-03-24 05:46:23,837] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:46:23,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.5, 30.33333333333334, 1.0, 2.0, 0.1660125384556534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2871687217343863, 6.911199999999999, 6.9112, 121.9260426156618, 421861.0496330519, 421861.0496330523, 157838.9742511839]
[2019-03-24 05:46:23,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:46:23,844] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3443591e-08 2.1826592e-08 9.9999988e-01 2.8866298e-10 8.6312511e-08], sampled 0.2160336036991084
[2019-03-24 05:46:40,729] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:46:40,732] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.78008876, 92.48846504, 1.0, 2.0, 0.2386854860577222, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3827961686187576, 6.911199999999999, 6.9112, 121.9260426156618, 564495.8569580242, 564495.8569580247, 178820.6269494202]
[2019-03-24 05:46:40,732] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:46:40,735] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7304500e-07 1.1661338e-07 9.9999940e-01 2.3780984e-09 4.0899812e-07], sampled 0.5058103238579885
[2019-03-24 05:47:11,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:47:11,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.2, 76.0, 1.0, 2.0, 0.7347675384514264, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1552485.167169891, 1552485.167169891, 323649.6547221013]
[2019-03-24 05:47:11,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:47:11,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0972562e-09 5.0257545e-09 1.0000000e+00 4.6648886e-11 2.2297790e-08], sampled 0.08771081052405505
[2019-03-24 05:47:27,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00587781], dtype=float32), 0.0059773624]
[2019-03-24 05:47:27,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.30239617166666, 70.644883605, 1.0, 2.0, 0.2442241136714927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3932107083247008, 6.9112, 6.9112, 121.9260426156618, 582835.6269437856, 582835.6269437856, 179863.2606398314]
[2019-03-24 05:47:27,774] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:47:27,778] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5460236e-08 2.2941620e-08 9.9999988e-01 3.0763905e-10 9.0162935e-08], sampled 0.445678869778385
[2019-03-24 05:47:57,564] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6811.1569 2600714453.0131 61.0000
[2019-03-24 05:47:57,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7375 2661655597.9132 110.0000
[2019-03-24 05:47:57,813] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.4663 2623867798.8011 97.0000
[2019-03-24 05:47:57,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7156.5770 2831346488.3291 210.0000
[2019-03-24 05:47:58,075] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.2460 2565944753.5707 47.0000
[2019-03-24 05:47:59,090] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 25000, evaluation results [25000.0, 7156.57696733635, 2831346488.3290596, 210.0, 6811.156859919094, 2600714453.0131416, 61.0, 7491.246017841513, 2565944753.570658, 47.0, 6580.737454292601, 2661655597.9131775, 110.0, 7161.466343444668, 2623867798.801107, 97.0]
[2019-03-24 05:48:05,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4719346e-03 2.3007381e-03 9.8998696e-01 4.0361178e-04 5.8368132e-03], sum to 1.0000
[2019-03-24 05:48:05,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0296
[2019-03-24 05:48:05,334] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.75, 69.0, 1.0, 2.0, 0.1656791211586564, 0.0, 2.0, 0.0, 1.0, 2.0, 0.286297063348849, 6.911199999999999, 6.9112, 121.9260426156618, 420819.3717497808, 420819.3717497812, 157819.2634514942], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [20.7, 69.33333333333333, 1.0, 2.0, 0.1620850090567886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2801507443447126, 6.911199999999999, 6.9112, 121.9260426156618, 411730.6132241186, 411730.613224119, 157054.3960257685], 
processed observation next is [1.0, 0.13043478260869565, 0.3222222222222222, 0.6933333333333332, 1.0, 1.0, 0.0024821536390340483, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.10018843043089073, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14704664758004235, 0.1470466475800425, 0.30202768466493946], 
reward next is 0.6980, 
noisyNet noise sample is [array([-1.1269737], dtype=float32), -0.1830384]. 
=============================================
[2019-03-24 05:48:05,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[28.858633]
 [28.799366]
 [28.766605]
 [28.952883]
 [29.098331]], R is [[29.45973206]
 [29.86163521]
 [30.25899696]
 [30.64657021]
 [30.34010506]].
[2019-03-24 05:48:12,426] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31709: loss 0.3367
[2019-03-24 05:48:12,430] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31709: learning rate 0.0000
[2019-03-24 05:48:12,453] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31723: loss 0.3460
[2019-03-24 05:48:12,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31723: learning rate 0.0000
[2019-03-24 05:48:12,485] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31739: loss 0.3083
[2019-03-24 05:48:12,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31741: learning rate 0.0000
[2019-03-24 05:48:12,853] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31938: loss 0.2253
[2019-03-24 05:48:12,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31938: learning rate 0.0000
[2019-03-24 05:48:12,872] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31947: loss 0.1800
[2019-03-24 05:48:12,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31949: learning rate 0.0000
[2019-03-24 05:48:12,898] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31958: loss 0.1619
[2019-03-24 05:48:12,901] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31958: learning rate 0.0000
[2019-03-24 05:48:12,949] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31982: loss 0.1851
[2019-03-24 05:48:12,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31982: learning rate 0.0000
[2019-03-24 05:48:13,003] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32011: loss 0.1563
[2019-03-24 05:48:13,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32011: learning rate 0.0000
[2019-03-24 05:48:13,061] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32045: loss 0.1473
[2019-03-24 05:48:13,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32045: learning rate 0.0000
[2019-03-24 05:48:13,092] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32060: loss 0.0700
[2019-03-24 05:48:13,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32060: learning rate 0.0000
[2019-03-24 05:48:13,127] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32078: loss 0.1039
[2019-03-24 05:48:13,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32078: learning rate 0.0000
[2019-03-24 05:48:13,135] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32082: loss 0.1501
[2019-03-24 05:48:13,137] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32082: loss 0.1030
[2019-03-24 05:48:13,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32082: learning rate 0.0000
[2019-03-24 05:48:13,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32082: learning rate 0.0000
[2019-03-24 05:48:13,198] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32116: loss 0.0440
[2019-03-24 05:48:13,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32116: learning rate 0.0000
[2019-03-24 05:48:13,213] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32119: loss 0.0983
[2019-03-24 05:48:13,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32120: learning rate 0.0000
[2019-03-24 05:48:13,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0570099e-05 7.0175383e-04 9.9910849e-01 2.4863784e-06 1.2661655e-04], sum to 1.0000
[2019-03-24 05:48:13,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8562
[2019-03-24 05:48:13,495] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.1, 93.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2723671158765912, 6.911199999999999, 6.9112, 121.9260426156618, 402066.5628595112, 402066.5628595116, 156715.5716084334], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1216800.0000, 
sim time next is 1217400.0000, 
raw observation next is [18.08333333333334, 93.0, 1.0, 2.0, 0.1871168736594103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.320590751976916, 6.911199999999999, 6.9112, 121.9260426156618, 473355.4792855986, 473355.479285599, 162853.1692108123], 
processed observation next is [1.0, 0.08695652173913043, 0.22530864197530887, 0.93, 1.0, 1.0, 0.03228199245167892, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.15073843997114497, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16905552831628523, 0.16905552831628537, 0.31317917155925445], 
reward next is 0.6868, 
noisyNet noise sample is [array([-0.9259778], dtype=float32), -0.86982405]. 
=============================================
[2019-03-24 05:48:13,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32211: loss 0.0625
[2019-03-24 05:48:13,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32211: learning rate 0.0000
[2019-03-24 05:48:17,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4062439e-05 2.4280079e-04 9.9967921e-01 2.7260346e-06 3.1175776e-05], sum to 1.0000
[2019-03-24 05:48:17,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-24 05:48:17,894] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.1744353402217354, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2939806947230585, 6.9112, 6.9112, 121.9260426156618, 437165.7858235738, 437165.7858235738, 160970.3713400724], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1301400.0000, 
sim time next is 1302000.0000, 
raw observation next is [19.63333333333333, 86.0, 1.0, 2.0, 0.1729037338942574, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2917905576059382, 6.911199999999999, 6.9112, 121.9260426156618, 433693.5042375661, 433693.5042375665, 160568.8323374759], 
processed observation next is [1.0, 0.043478260869565216, 0.2827160493827159, 0.86, 1.0, 1.0, 0.015361587969354037, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11473819700742273, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15489053722770219, 0.15489053722770232, 0.3087862160336075], 
reward next is 0.6912, 
noisyNet noise sample is [array([0.89116913], dtype=float32), -0.47925505]. 
=============================================
[2019-03-24 05:48:17,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[51.117626]
 [51.72199 ]
 [52.0301  ]
 [52.076866]
 [51.745693]], R is [[51.18138504]
 [51.36001205]
 [51.53595352]
 [51.70911407]
 [51.87959671]].
[2019-03-24 05:48:18,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7717644e-05 3.6495505e-06 9.9980348e-01 2.0418522e-08 1.7506728e-04], sum to 1.0000
[2019-03-24 05:48:18,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0072
[2019-03-24 05:48:18,422] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 91.0, 1.0, 2.0, 0.1696996270377601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2896389475737139, 6.911199999999999, 6.9112, 121.9260426156618, 428433.6759762816, 428433.6759762821, 159290.7998481577], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1312200.0000, 
sim time next is 1312800.0000, 
raw observation next is [18.43333333333333, 91.33333333333333, 1.0, 2.0, 0.1688948397011804, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2884388654673948, 6.911199999999999, 6.9112, 121.9260426156618, 426536.9013107778, 426536.9013107782, 159088.8877734622], 
processed observation next is [1.0, 0.17391304347826086, 0.2382716049382715, 0.9133333333333333, 1.0, 1.0, 0.010589094882357628, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11054858183424346, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15233460761099207, 0.1523346076109922, 0.3059401687951196], 
reward next is 0.6941, 
noisyNet noise sample is [array([0.599537], dtype=float32), 0.73660773]. 
=============================================
[2019-03-24 05:48:27,825] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39668: loss 0.0916
[2019-03-24 05:48:27,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39669: learning rate 0.0000
[2019-03-24 05:48:27,958] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39739: loss 0.0499
[2019-03-24 05:48:27,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39739: learning rate 0.0000
[2019-03-24 05:48:27,998] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39757: loss 0.0112
[2019-03-24 05:48:28,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39757: learning rate 0.0000
[2019-03-24 05:48:28,103] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39810: loss 0.0188
[2019-03-24 05:48:28,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39810: learning rate 0.0000
[2019-03-24 05:48:28,334] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39934: loss 0.0017
[2019-03-24 05:48:28,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39934: learning rate 0.0000
[2019-03-24 05:48:28,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39956: loss 0.0260
[2019-03-24 05:48:28,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39956: learning rate 0.0000
[2019-03-24 05:48:28,407] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39965: loss 0.0087
[2019-03-24 05:48:28,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39965: learning rate 0.0000
[2019-03-24 05:48:28,481] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40010: loss 0.0033
[2019-03-24 05:48:28,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40010: learning rate 0.0000
[2019-03-24 05:48:28,490] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40012: loss 0.0087
[2019-03-24 05:48:28,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40013: learning rate 0.0000
[2019-03-24 05:48:28,537] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40033: loss 0.0063
[2019-03-24 05:48:28,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40034: learning rate 0.0000
[2019-03-24 05:48:28,618] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40071: loss 0.0264
[2019-03-24 05:48:28,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40072: learning rate 0.0000
[2019-03-24 05:48:28,790] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40165: loss 0.0727
[2019-03-24 05:48:28,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40165: learning rate 0.0000
[2019-03-24 05:48:28,816] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40183: loss 0.0155
[2019-03-24 05:48:28,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40185: learning rate 0.0000
[2019-03-24 05:48:28,829] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40189: loss 0.0112
[2019-03-24 05:48:28,830] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40189: learning rate 0.0000
[2019-03-24 05:48:28,831] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40189: loss 0.0048
[2019-03-24 05:48:28,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40190: learning rate 0.0000
[2019-03-24 05:48:28,887] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40216: loss 0.0018
[2019-03-24 05:48:28,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40216: learning rate 0.0000
[2019-03-24 05:48:28,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6677759e-09 1.7424583e-07 9.9999976e-01 5.7864469e-10 8.8701952e-08], sum to 1.0000
[2019-03-24 05:48:28,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3931
[2019-03-24 05:48:28,961] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [35.13333333333333, 23.33333333333333, 1.0, 2.0, 0.2121972385422543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3472559385308393, 6.911199999999999, 6.9112, 121.9260426156618, 518829.0113772419, 518829.0113772424, 171111.7604500811], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1516200.0000, 
sim time next is 1516800.0000, 
raw observation next is [35.26666666666667, 22.66666666666666, 1.0, 2.0, 0.2085221553817576, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3416787448360883, 6.911199999999999, 6.9112, 121.9260426156618, 510569.131185089, 510569.1311850894, 170184.8475723014], 
processed observation next is [0.0, 0.5652173913043478, 0.8617283950617286, 0.2266666666666666, 1.0, 1.0, 0.057764470692568584, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.17709843104511033, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18234611828038894, 0.18234611828038907, 0.32727855302365655], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.18565276], dtype=float32), -0.60630643]. 
=============================================
[2019-03-24 05:48:36,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5442589e-05 1.4777097e-04 9.9979895e-01 3.9305455e-06 3.3802557e-05], sum to 1.0000
[2019-03-24 05:48:36,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6971
[2019-03-24 05:48:36,746] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.05, 69.5, 1.0, 2.0, 0.1835287405177061, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3140643703994907, 6.9112, 6.9112, 121.9260426156618, 463991.5962578287, 463991.5962578287, 162135.803993013], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1650600.0000, 
sim time next is 1651200.0000, 
raw observation next is [20.83333333333333, 70.66666666666667, 1.0, 2.0, 0.178641568855947, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3062801400792042, 6.911200000000001, 6.9112, 121.9260426156618, 452064.5918548274, 452064.591854827, 160977.1850157692], 
processed observation next is [1.0, 0.08695652173913043, 0.32716049382716034, 0.7066666666666667, 1.0, 1.0, 0.02219234387612739, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1328501750990052, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16145163994815265, 0.1614516399481525, 0.30957150964571], 
reward next is 0.6904, 
noisyNet noise sample is [array([-0.45884806], dtype=float32), -0.15938625]. 
=============================================
[2019-03-24 05:48:38,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4855979e-08 1.4282980e-07 9.9999976e-01 4.0018544e-09 6.2550953e-08], sum to 1.0000
[2019-03-24 05:48:38,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4970
[2019-03-24 05:48:38,883] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.2, 76.33333333333334, 1.0, 2.0, 0.2176955987860826, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3545501401927537, 6.911199999999999, 6.9112, 121.9260426156618, 529192.791492575, 529192.7914925754, 172702.8241423384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1711200.0000, 
sim time next is 1711800.0000, 
raw observation next is [23.15, 77.0, 1.0, 2.0, 0.2187418113748523, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3560542045863105, 6.911199999999999, 6.9112, 121.9260426156618, 531346.4804360439, 531346.4804360444, 172984.7759080889], 
processed observation next is [1.0, 0.8260869565217391, 0.4129629629629629, 0.77, 1.0, 1.0, 0.06993072782720511, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1950677557328881, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18976660015572996, 0.18976660015573013, 0.33266303059247865], 
reward next is 0.6673, 
noisyNet noise sample is [array([0.49789536], dtype=float32), 1.1802449]. 
=============================================
[2019-03-24 05:48:40,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2476801e-06 1.4763540e-05 9.9992585e-01 1.3666875e-07 5.1965235e-05], sum to 1.0000
[2019-03-24 05:48:40,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5541
[2019-03-24 05:48:40,609] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.1811498517822169, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3027034204599133, 6.911199999999999, 6.9112, 121.9260426156618, 451356.6497012957, 451356.6497012962, 162897.5692129425], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1746000.0000, 
sim time next is 1746600.0000, 
raw observation next is [19.96666666666667, 88.16666666666667, 1.0, 2.0, 0.1960652871403518, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3272709404980897, 6.911199999999999, 6.9112, 121.9260426156618, 488138.3618033796, 488138.3618033801, 166248.0580942589], 
processed observation next is [1.0, 0.21739130434782608, 0.2950617283950618, 0.8816666666666667, 1.0, 1.0, 0.04293486564327594, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.15908867562261209, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1743351292154927, 0.17433512921549288, 0.31970780402742094], 
reward next is 0.6803, 
noisyNet noise sample is [array([0.03772666], dtype=float32), -0.052006036]. 
=============================================
[2019-03-24 05:48:43,370] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47582: loss 10.3834
[2019-03-24 05:48:43,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47583: learning rate 0.0000
[2019-03-24 05:48:43,595] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47691: loss 10.4220
[2019-03-24 05:48:43,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47692: learning rate 0.0000
[2019-03-24 05:48:43,671] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47728: loss 10.0894
[2019-03-24 05:48:43,675] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47729: learning rate 0.0000
[2019-03-24 05:48:43,926] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47851: loss 7.3805
[2019-03-24 05:48:43,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47851: learning rate 0.0000
[2019-03-24 05:48:44,159] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47965: loss 5.9773
[2019-03-24 05:48:44,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47966: learning rate 0.0000
[2019-03-24 05:48:44,174] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47967: loss 5.7401
[2019-03-24 05:48:44,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47967: learning rate 0.0000
[2019-03-24 05:48:44,227] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48002: loss 5.4236
[2019-03-24 05:48:44,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48002: learning rate 0.0000
[2019-03-24 05:48:44,264] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48020: loss 5.0875
[2019-03-24 05:48:44,267] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48020: learning rate 0.0000
[2019-03-24 05:48:44,293] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48033: loss 4.3940
[2019-03-24 05:48:44,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48033: learning rate 0.0000
[2019-03-24 05:48:44,321] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48042: loss 4.5053
[2019-03-24 05:48:44,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48044: learning rate 0.0000
[2019-03-24 05:48:44,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0629732e-05 6.0206057e-06 9.9996579e-01 9.0251785e-07 6.6829525e-06], sum to 1.0000
[2019-03-24 05:48:44,393] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-24 05:48:44,398] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.35, 85.5, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2613751904984444, 6.9112, 6.9112, 121.9260426156618, 382627.7960521247, 382627.7960521247, 153397.1840361874], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [18.36666666666667, 85.66666666666666, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2609502503892058, 6.911200000000001, 6.9112, 121.9260426156618, 382194.828453599, 382194.8284535985, 153402.826759583], 
processed observation next is [1.0, 0.8695652173913043, 0.2358024691358026, 0.8566666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.0761878129865072, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1364981530191425, 0.1364981530191423, 0.2950054360761212], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.76175004], dtype=float32), -0.49748507]. 
=============================================
[2019-03-24 05:48:44,452] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48109: loss 3.9478
[2019-03-24 05:48:44,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48110: learning rate 0.0000
[2019-03-24 05:48:44,468] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48117: loss 3.5200
[2019-03-24 05:48:44,470] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48117: learning rate 0.0000
[2019-03-24 05:48:44,554] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48159: loss 3.1478
[2019-03-24 05:48:44,557] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48159: learning rate 0.0000
[2019-03-24 05:48:44,593] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48177: loss 3.1662
[2019-03-24 05:48:44,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48180: learning rate 0.0000
[2019-03-24 05:48:44,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48195: loss 3.3514
[2019-03-24 05:48:44,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48195: learning rate 0.0000
[2019-03-24 05:48:44,631] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48195: loss 2.9040
[2019-03-24 05:48:44,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48195: learning rate 0.0000
[2019-03-24 05:48:45,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6058961e-05 5.5918248e-05 9.9986124e-01 4.3297351e-07 6.2870181e-06], sum to 1.0000
[2019-03-24 05:48:45,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7634
[2019-03-24 05:48:45,301] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.5, 90.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2730902894323272, 6.911199999999999, 6.9112, 121.9260426156618, 403315.7040290431, 403315.7040290436, 156928.9639393331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1814400.0000, 
sim time next is 1815000.0000, 
raw observation next is [18.48333333333333, 90.16666666666667, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2728551234378404, 6.911199999999999, 6.9112, 121.9260426156618, 402980.9734693601, 402980.9734693606, 156894.48151223], 
processed observation next is [1.0, 0.0, 0.24012345679012337, 0.9016666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.0910689042973005, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14392177623905716, 0.14392177623905736, 0.3017201567542885], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22405596], dtype=float32), -0.13101104]. 
=============================================
[2019-03-24 05:48:45,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[39.042507]
 [39.43726 ]
 [39.43516 ]
 [39.441303]
 [39.41242 ]], R is [[38.76391983]
 [38.37628174]
 [37.99251938]
 [37.6125946 ]
 [37.23646927]].
[2019-03-24 05:48:48,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2499056e-07 3.9407234e-07 9.9999952e-01 8.9197749e-10 5.3533277e-08], sum to 1.0000
[2019-03-24 05:48:48,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8965
[2019-03-24 05:48:48,203] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.71666666666667, 85.66666666666667, 1.0, 2.0, 0.3597475203787777, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5851695676691034, 6.911199999999999, 6.9112, 121.9260426156618, 873252.564172976, 873252.5641729764, 209952.2486596659], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1867800.0000, 
sim time next is 1868400.0000, 
raw observation next is [21.7, 86.0, 1.0, 2.0, 0.3909588102332414, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355687227051954, 6.911199999999999, 6.9112, 121.9260426156618, 948310.8833224991, 948310.8833224996, 219247.6136748217], 
processed observation next is [1.0, 0.6521739130434783, 0.3592592592592592, 0.86, 1.0, 1.0, 0.27495096456338264, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5444609033814942, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.338682458329464, 0.33868245832946414, 0.42163002629773405], 
reward next is 0.5784, 
noisyNet noise sample is [array([1.0833287], dtype=float32), 0.25364196]. 
=============================================
[2019-03-24 05:48:48,373] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 05:48:48,374] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:48:48,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:48,375] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:48:48,378] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:48,378] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:48:48,379] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:48:48,380] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:48:48,381] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:48,381] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:48,381] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:48,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-24 05:48:48,397] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-24 05:48:48,444] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-24 05:48:48,445] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-24 05:48:48,470] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-24 05:49:23,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:49:23,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.03333333333333, 26.0, 1.0, 2.0, 0.1953625942392332, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3234397422548039, 6.911199999999999, 6.9112, 121.9260426156618, 483186.3398092178, 483186.3398092182, 166572.2928106241]
[2019-03-24 05:49:23,151] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:23,154] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7925657e-07 4.7722767e-07 9.9999905e-01 2.5597684e-09 2.2810106e-07], sampled 0.5378779181526587
[2019-03-24 05:49:27,541] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:49:27,542] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.43333333333334, 71.66666666666666, 1.0, 2.0, 0.3022983991113024, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4812779294479548, 6.911199999999999, 6.9112, 121.9260426156618, 689317.0912123594, 689317.0912123598, 195859.7758072692]
[2019-03-24 05:49:27,543] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:27,545] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2808935e-07 1.0540156e-06 9.9999797e-01 7.6842310e-09 5.2582271e-07], sampled 0.24914265053056472
[2019-03-24 05:49:34,129] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:49:34,132] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.7690482, 83.28645041, 1.0, 2.0, 0.2908512470468023, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4630802230331889, 6.9112, 6.9112, 121.9260426156618, 663980.6033606363, 663980.6033606363, 192790.4417546138]
[2019-03-24 05:49:34,134] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:49:34,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.8694736e-07 2.0644477e-06 9.9999607e-01 1.9731811e-08 1.0920182e-06], sampled 0.9113144244185981
[2019-03-24 05:49:40,509] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:49:40,510] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.02088948, 78.92715960000001, 1.0, 2.0, 0.3252252815641408, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5177692400980772, 6.911199999999999, 6.9112, 121.9260426156618, 741302.3288969714, 741302.3288969719, 202147.582219001]
[2019-03-24 05:49:40,512] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:49:40,515] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.9438688e-07 1.2033697e-06 9.9999774e-01 9.2241530e-09 6.0624410e-07], sampled 0.12489207290820681
[2019-03-24 05:49:57,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:49:57,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.68980298, 77.32923228666667, 1.0, 2.0, 0.2985523355919884, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4753050414332059, 6.911199999999999, 6.9112, 121.9260426156618, 680478.3580785216, 680478.358078522, 194858.2593821523]
[2019-03-24 05:49:57,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:49:57,324] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.6304356e-07 1.1102468e-06 9.9999785e-01 8.5887768e-09 5.7147992e-07], sampled 0.08645196782741782
[2019-03-24 05:50:11,457] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:50:11,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 71.0, 1.0, 2.0, 0.2650386240181762, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4241059903918997, 6.911199999999999, 6.9112, 121.9260426156618, 622749.4202857926, 622749.420285793, 185554.0620357046]
[2019-03-24 05:50:11,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:50:11,461] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.5346779e-07 1.5675727e-06 9.9999702e-01 1.3342187e-08 8.0684572e-07], sampled 0.9183858623645567
[2019-03-24 05:50:28,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00590053], dtype=float32), 0.005157879]
[2019-03-24 05:50:28,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.74990225666667, 87.970369345, 1.0, 2.0, 0.2686899406985146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4292694378486315, 6.911199999999999, 6.9112, 121.9260426156618, 627763.7574730957, 627763.7574730961, 186627.8828469237]
[2019-03-24 05:50:28,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:50:28,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.1500278e-07 1.7042016e-06 9.9999678e-01 1.4898313e-08 8.7969494e-07], sampled 0.4088939667318031
[2019-03-24 05:50:32,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661715815.0537 110.0000
[2019-03-24 05:50:32,542] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7490.4975 2565977415.7002 47.0000
[2019-03-24 05:50:32,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6811.1513 2600736365.7806 61.0000
[2019-03-24 05:50:32,720] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.4193 2623909188.2852 97.0000
[2019-03-24 05:50:32,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7156.5487 2831357797.1978 210.0000
[2019-03-24 05:50:33,844] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 50000, evaluation results [50000.0, 7156.548703533039, 2831357797.1978273, 210.0, 6811.151293584971, 2600736365.780614, 61.0, 7490.497536420795, 2565977415.700171, 47.0, 6579.928819146758, 2661715815.053693, 110.0, 7161.419268685619, 2623909188.2852426, 97.0]
[2019-03-24 05:50:37,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3739612e-09 3.4549199e-08 1.0000000e+00 3.8266404e-12 6.5677436e-10], sum to 1.0000
[2019-03-24 05:50:37,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6253
[2019-03-24 05:50:38,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.43333333333333, 70.33333333333333, 1.0, 2.0, 0.3678271098787296, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5904322062397982, 6.911199999999999, 6.9112, 121.9260426156618, 872060.8749664477, 872060.8749664482, 213442.9420144342], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1947000.0000, 
sim time next is 1947600.0000, 
raw observation next is [25.7, 69.0, 1.0, 2.0, 0.4290227667562809, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6881764608450693, 6.911199999999999, 6.9112, 121.9260426156618, 1015422.591663984, 1015422.591663985, 232286.8077720101], 
processed observation next is [1.0, 0.5652173913043478, 0.5074074074074074, 0.69, 1.0, 1.0, 0.320265198519382, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6102205760563366, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36265092559428, 0.36265092559428036, 0.44670539956155786], 
reward next is 0.5533, 
noisyNet noise sample is [array([0.7108079], dtype=float32), 0.64854884]. 
=============================================
[2019-03-24 05:50:41,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0209233e-08 1.5917293e-07 9.9999988e-01 9.3903191e-11 2.6625868e-10], sum to 1.0000
[2019-03-24 05:50:41,889] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-24 05:50:41,896] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.85, 68.0, 1.0, 2.0, 0.218657034921527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3547609202686759, 6.9112, 6.9112, 121.9260426156618, 528742.4676384599, 528742.4676384599, 173187.0810793163], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2025000.0000, 
sim time next is 2025600.0000, 
raw observation next is [25.06666666666667, 67.33333333333334, 1.0, 2.0, 0.2209170691859246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.358027257775456, 6.9112, 6.9112, 121.9260426156618, 533315.0611886536, 533315.0611886536, 173794.4167626656], 
processed observation next is [0.0, 0.43478260869565216, 0.4839506172839507, 0.6733333333333335, 1.0, 1.0, 0.07252032045943405, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.19753407221932, 0.0, 0.0, 0.8094621288201359, 0.1904696647102334, 0.1904696647102334, 0.3342200322358954], 
reward next is 0.6658, 
noisyNet noise sample is [array([0.41898468], dtype=float32), -0.88693285]. 
=============================================
[2019-03-24 05:50:44,403] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55502: loss 0.3345
[2019-03-24 05:50:44,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55504: learning rate 0.0000
[2019-03-24 05:50:44,680] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55636: loss 0.3203
[2019-03-24 05:50:44,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55637: learning rate 0.0000
[2019-03-24 05:50:44,787] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55691: loss 0.1932
[2019-03-24 05:50:44,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55693: learning rate 0.0000
[2019-03-24 05:50:44,899] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55752: loss 0.2338
[2019-03-24 05:50:44,902] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55754: learning rate 0.0000
[2019-03-24 05:50:45,300] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55962: loss 0.0103
[2019-03-24 05:50:45,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55962: learning rate 0.0000
[2019-03-24 05:50:45,379] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56000: loss 0.0385
[2019-03-24 05:50:45,382] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56000: learning rate 0.0000
[2019-03-24 05:50:45,415] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56024: loss 0.0129
[2019-03-24 05:50:45,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56025: learning rate 0.0000
[2019-03-24 05:50:45,517] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56074: loss 0.0013
[2019-03-24 05:50:45,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56074: learning rate 0.0000
[2019-03-24 05:50:45,568] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56101: loss 0.0006
[2019-03-24 05:50:45,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56101: learning rate 0.0000
[2019-03-24 05:50:45,586] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56111: loss 0.0109
[2019-03-24 05:50:45,588] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56111: learning rate 0.0000
[2019-03-24 05:50:45,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56112: loss 0.0005
[2019-03-24 05:50:45,594] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56113: learning rate 0.0000
[2019-03-24 05:50:45,602] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56117: loss 0.0012
[2019-03-24 05:50:45,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56119: learning rate 0.0000
[2019-03-24 05:50:45,643] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56139: loss 0.0005
[2019-03-24 05:50:45,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56139: learning rate 0.0000
[2019-03-24 05:50:45,668] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56149: loss 0.0006
[2019-03-24 05:50:45,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56149: learning rate 0.0000
[2019-03-24 05:50:45,776] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56210: loss 0.0007
[2019-03-24 05:50:45,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56211: learning rate 0.0000
[2019-03-24 05:50:45,854] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56246: loss 0.0116
[2019-03-24 05:50:45,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56246: learning rate 0.0000
[2019-03-24 05:50:51,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5828395e-05 1.6268632e-05 9.9996197e-01 1.1403168e-07 5.8436021e-06], sum to 1.0000
[2019-03-24 05:50:51,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1361
[2019-03-24 05:50:51,547] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.48333333333333, 91.83333333333334, 1.0, 2.0, 0.6594290391377082, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1466496.061657463, 1466496.061657464, 310010.8116791521], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2218200.0000, 
sim time next is 2218800.0000, 
raw observation next is [24.26666666666667, 92.66666666666667, 1.0, 2.0, 0.5828767394825025, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9279587522262788, 6.9112, 6.9112, 121.9260426156618, 1329089.57757417, 1329089.57757417, 287256.0452504259], 
processed observation next is [1.0, 0.6956521739130435, 0.4543209876543211, 0.9266666666666667, 1.0, 1.0, 0.503424689860122, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9099484402828484, 0.0, 0.0, 0.8094621288201359, 0.4746748491336321, 0.4746748491336321, 0.5524154716354344], 
reward next is 0.4476, 
noisyNet noise sample is [array([-0.01731704], dtype=float32), 0.8652179]. 
=============================================
[2019-03-24 05:50:53,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0474567e-09 3.7664001e-09 1.0000000e+00 2.5694929e-11 1.9350369e-10], sum to 1.0000
[2019-03-24 05:50:53,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7890
[2019-03-24 05:50:53,818] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.23333333333333, 94.5, 1.0, 2.0, 0.3845922722276688, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6215770283053315, 6.911199999999999, 6.9112, 121.9260426156618, 924575.9316139044, 924575.9316139049, 217820.5444880937], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2278200.0000, 
sim time next is 2278800.0000, 
raw observation next is [21.4, 94.0, 1.0, 2.0, 0.3960284446562462, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393323322223139, 6.911199999999999, 6.9112, 121.9260426156618, 950194.4104806761, 950194.4104806766, 221383.9922331509], 
processed observation next is [1.0, 0.391304347826087, 0.3481481481481481, 0.94, 1.0, 1.0, 0.28098624363838837, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5491654152778923, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33935514660024146, 0.33935514660024163, 0.42573844660221327], 
reward next is 0.5743, 
noisyNet noise sample is [array([0.57625145], dtype=float32), 0.5775359]. 
=============================================
[2019-03-24 05:50:54,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2939032e-06 1.1299006e-05 9.9998367e-01 2.1324851e-09 3.6729198e-06], sum to 1.0000
[2019-03-24 05:50:54,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8799
[2019-03-24 05:50:54,239] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.2119441320606387, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3462570850805116, 6.911199999999999, 6.9112, 121.9260426156618, 517196.4885496756, 517196.488549676, 171163.2766848538], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2271600.0000, 
sim time next is 2272200.0000, 
raw observation next is [20.4, 96.16666666666666, 1.0, 2.0, 0.2358302469496082, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3850684831618982, 6.911199999999999, 6.9112, 121.9260426156618, 575128.0967309882, 575128.0967309887, 176822.3018945345], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.9616666666666666, 1.0, 1.0, 0.09027410351143832, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2313356039523727, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20540289168963866, 0.20540289168963882, 0.3400428882587202], 
reward next is 0.6600, 
noisyNet noise sample is [array([1.8899314], dtype=float32), -2.6782825]. 
=============================================
[2019-03-24 05:50:59,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0563102e-07 1.6177910e-06 9.9999702e-01 7.7668885e-09 7.7851837e-07], sum to 1.0000
[2019-03-24 05:50:59,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9573
[2019-03-24 05:50:59,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 37.16666666666667, 1.0, 2.0, 0.3951740929340421, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6445696654069768, 6.9112, 6.9112, 121.9260426156618, 962729.9072049495, 962729.9072049495, 220253.2739921264], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2379000.0000, 
sim time next is 2379600.0000, 
raw observation next is [30.5, 37.0, 1.0, 2.0, 0.4028791810720653, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6567600132264204, 6.911199999999999, 6.9112, 121.9260426156618, 980807.3074625806, 980807.3074625811, 222654.393489564], 
processed observation next is [1.0, 0.5652173913043478, 0.6851851851851852, 0.37, 1.0, 1.0, 0.2891418822286491, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5709500165330255, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3502883240937788, 0.35028832409377897, 0.42818152594146924], 
reward next is 0.5718, 
noisyNet noise sample is [array([-0.7919359], dtype=float32), -0.36255598]. 
=============================================
[2019-03-24 05:50:59,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3989561e-06 2.1100634e-06 9.9999404e-01 1.4553071e-08 3.7339933e-07], sum to 1.0000
[2019-03-24 05:50:59,648] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-24 05:50:59,653] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.71666666666667, 37.83333333333334, 1.0, 2.0, 0.5707766424441109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9238260236328794, 6.911199999999999, 6.9112, 121.9260426156618, 1375870.249789618, 1375870.249789618, 280577.4587529614], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2393400.0000, 
sim time next is 2394000.0000, 
raw observation next is [30.7, 38.0, 1.0, 2.0, 0.575198374345468, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9307261348669562, 6.9112, 6.9112, 121.9260426156618, 1385920.746770924, 1385920.746770924, 282268.3098786611], 
processed observation next is [1.0, 0.7391304347826086, 0.6925925925925925, 0.38, 1.0, 1.0, 0.49428377898270004, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9134076685836953, 0.0, 0.0, 0.8094621288201359, 0.49497169527532997, 0.49497169527532997, 0.5428236728435791], 
reward next is 0.4572, 
noisyNet noise sample is [array([0.40760675], dtype=float32), 0.2635621]. 
=============================================
[2019-03-24 05:50:59,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.898647]
 [60.11755 ]
 [59.994328]
 [59.974354]
 [59.96361 ]], R is [[59.64027023]
 [59.50429535]
 [59.37126541]
 [59.23511124]
 [59.08450699]].
[2019-03-24 05:50:59,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8212276e-06 6.0095763e-06 9.9996126e-01 2.2982253e-08 2.2926839e-05], sum to 1.0000
[2019-03-24 05:50:59,682] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0656
[2019-03-24 05:50:59,857] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 38.33333333333334, 1.0, 2.0, 0.4688636759426808, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7661696159236476, 6.9112, 6.9112, 121.9260426156618, 1144927.647313753, 1144927.647313753, 243583.5262547537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2374800.0000, 
sim time next is 2375400.0000, 
raw observation next is [29.8, 38.16666666666666, 1.0, 2.0, 0.4733634011967581, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7730572446432766, 6.911199999999999, 6.9112, 121.9260426156618, 1155096.645181082, 1155096.645181083, 245139.6232459543], 
processed observation next is [1.0, 0.4782608695652174, 0.6592592592592593, 0.3816666666666666, 1.0, 1.0, 0.3730516680913787, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7163215558040958, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4125345161361007, 0.41253451613610104, 0.471422352396066], 
reward next is 0.5286, 
noisyNet noise sample is [array([0.23812006], dtype=float32), 0.33637193]. 
=============================================
[2019-03-24 05:51:00,114] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63684: loss 0.0938
[2019-03-24 05:51:00,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63685: learning rate 0.0000
[2019-03-24 05:51:00,143] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63703: loss 0.1127
[2019-03-24 05:51:00,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63706: learning rate 0.0000
[2019-03-24 05:51:00,160] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63713: loss 0.1243
[2019-03-24 05:51:00,164] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63714: learning rate 0.0000
[2019-03-24 05:51:00,231] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63748: loss 0.0812
[2019-03-24 05:51:00,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63748: learning rate 0.0000
[2019-03-24 05:51:00,453] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63860: loss 0.0502
[2019-03-24 05:51:00,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63861: learning rate 0.0000
[2019-03-24 05:51:00,494] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63882: loss 0.0439
[2019-03-24 05:51:00,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63882: learning rate 0.0000
[2019-03-24 05:51:00,571] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63924: loss 0.0596
[2019-03-24 05:51:00,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63925: learning rate 0.0000
[2019-03-24 05:51:00,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63984: loss 0.0560
[2019-03-24 05:51:00,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63984: learning rate 0.0000
[2019-03-24 05:51:00,771] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64031: loss 0.0414
[2019-03-24 05:51:00,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64031: learning rate 0.0000
[2019-03-24 05:51:00,913] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64106: loss 0.0355
[2019-03-24 05:51:00,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64106: learning rate 0.0000
[2019-03-24 05:51:00,939] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64121: loss 0.0341
[2019-03-24 05:51:00,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64121: learning rate 0.0000
[2019-03-24 05:51:00,958] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64128: loss 0.0356
[2019-03-24 05:51:00,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64129: learning rate 0.0000
[2019-03-24 05:51:01,118] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64215: loss 0.0358
[2019-03-24 05:51:01,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64215: learning rate 0.0000
[2019-03-24 05:51:01,122] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64215: loss 0.0300
[2019-03-24 05:51:01,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64216: learning rate 0.0000
[2019-03-24 05:51:01,147] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64228: loss 0.0294
[2019-03-24 05:51:01,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64228: learning rate 0.0000
[2019-03-24 05:51:01,245] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64283: loss 0.0286
[2019-03-24 05:51:01,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64283: learning rate 0.0000
[2019-03-24 05:51:03,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8590664e-06 7.3867595e-06 9.9998593e-01 2.2702686e-07 3.5945095e-06], sum to 1.0000
[2019-03-24 05:51:03,970] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6020
[2019-03-24 05:51:03,976] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.76666666666667, 23.0, 1.0, 2.0, 0.7221727430003896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9572512594079678, 6.911199999999997, 6.9112, 121.9260426156618, 1591927.375546781, 1591927.375546782, 310525.0784657538], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2468400.0000, 
sim time next is 2469000.0000, 
raw observation next is [34.88333333333333, 23.0, 1.0, 2.0, 0.7335381760776968, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9575760628645833, 6.9112, 6.9112, 121.9260426156618, 1604595.173258624, 1604595.173258624, 312941.9271685902], 
processed observation next is [1.0, 0.5652173913043478, 0.8475308641975309, 0.23, 1.0, 1.0, 0.682783542949639, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9469700785807291, 0.0, 0.0, 0.8094621288201359, 0.5730697047352229, 0.5730697047352229, 0.601811398401135], 
reward next is 0.3982, 
noisyNet noise sample is [array([0.36065376], dtype=float32), 1.0438733]. 
=============================================
[2019-03-24 05:51:04,000] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.546257]
 [46.3436  ]
 [46.215675]
 [46.19933 ]
 [46.22293 ]], R is [[46.55893707]
 [46.4961853 ]
 [46.43634796]
 [46.41296387]
 [46.4848175 ]].
[2019-03-24 05:51:05,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1719061e-05 1.2334264e-04 9.9979228e-01 2.0111843e-06 5.0683044e-05], sum to 1.0000
[2019-03-24 05:51:05,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-24 05:51:05,221] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 47.0, 1.0, 2.0, 0.1904795302176483, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3163766162613529, 6.911199999999999, 6.9112, 121.9260426156618, 472393.7393056062, 472393.7393056067, 165297.4528093151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2503200.0000, 
sim time next is 2503800.0000, 
raw observation next is [26.8, 47.5, 1.0, 2.0, 0.1905780827747748, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3164955120711695, 6.911199999999999, 6.9112, 121.9260426156618, 472583.4009422936, 472583.400942294, 165327.5096558811], 
processed observation next is [1.0, 1.0, 0.5481481481481482, 0.475, 1.0, 1.0, 0.03640247949377953, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14561939008896185, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16877978605081914, 0.16877978605081928, 0.3179375185690021], 
reward next is 0.6821, 
noisyNet noise sample is [array([0.7408115], dtype=float32), 1.1092768]. 
=============================================
[2019-03-24 05:51:06,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0159397e-07 5.1296520e-06 9.9999392e-01 3.2928696e-10 3.9033881e-07], sum to 1.0000
[2019-03-24 05:51:06,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4678
[2019-03-24 05:51:06,874] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333334, 58.66666666666667, 1.0, 2.0, 0.2079464865724075, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3463079080635058, 6.911199999999999, 6.9112, 121.9260426156618, 516823.0813496343, 516823.0813496348, 169056.8956693387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2521200.0000, 
sim time next is 2521800.0000, 
raw observation next is [24.25, 59.0, 1.0, 2.0, 0.2044436934664954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3407125764427226, 6.911199999999999, 6.9112, 121.9260426156618, 508389.6151657411, 508389.6151657415, 168221.0560813294], 
processed observation next is [1.0, 0.17391304347826086, 0.4537037037037037, 0.59, 1.0, 1.0, 0.052909158888685005, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.17589072055340327, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1815677197020504, 0.18156771970205052, 0.3235020309256335], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.88251203], dtype=float32), 0.23642075]. 
=============================================
[2019-03-24 05:51:15,539] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71631: loss 0.1076
[2019-03-24 05:51:15,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71632: learning rate 0.0000
[2019-03-24 05:51:15,654] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71686: loss 0.0480
[2019-03-24 05:51:15,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71686: learning rate 0.0000
[2019-03-24 05:51:15,708] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71712: loss 0.0065
[2019-03-24 05:51:15,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71712: learning rate 0.0000
[2019-03-24 05:51:15,788] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71755: loss 0.0249
[2019-03-24 05:51:15,791] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71755: learning rate 0.0000
[2019-03-24 05:51:15,927] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71821: loss 0.0158
[2019-03-24 05:51:15,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71822: learning rate 0.0000
[2019-03-24 05:51:16,116] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71918: loss 0.0529
[2019-03-24 05:51:16,117] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71918: learning rate 0.0000
[2019-03-24 05:51:16,155] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71935: loss 0.0062
[2019-03-24 05:51:16,157] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71936: learning rate 0.0000
[2019-03-24 05:51:16,288] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72002: loss 0.0409
[2019-03-24 05:51:16,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72002: learning rate 0.0000
[2019-03-24 05:51:16,425] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72069: loss 0.0947
[2019-03-24 05:51:16,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72071: learning rate 0.0000
[2019-03-24 05:51:16,469] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72091: loss 0.0458
[2019-03-24 05:51:16,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72091: learning rate 0.0000
[2019-03-24 05:51:16,543] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72127: loss 0.0058
[2019-03-24 05:51:16,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72129: learning rate 0.0000
[2019-03-24 05:51:16,603] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72158: loss 0.0098
[2019-03-24 05:51:16,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72159: learning rate 0.0000
[2019-03-24 05:51:16,689] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72199: loss 0.0051
[2019-03-24 05:51:16,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72199: learning rate 0.0000
[2019-03-24 05:51:16,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72227: loss 0.0005
[2019-03-24 05:51:16,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72227: learning rate 0.0000
[2019-03-24 05:51:16,818] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72261: loss 0.0038
[2019-03-24 05:51:16,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72261: learning rate 0.0000
[2019-03-24 05:51:16,825] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72262: loss 0.0088
[2019-03-24 05:51:16,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72264: learning rate 0.0000
[2019-03-24 05:51:17,622] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2373193e-08 3.0772216e-07 9.9999964e-01 5.0828491e-10 6.2542087e-09], sum to 1.0000
[2019-03-24 05:51:17,632] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8242
[2019-03-24 05:51:17,636] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 49.0, 1.0, 2.0, 0.3168375253522716, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5044156590386327, 6.911199999999999, 6.9112, 121.9260426156618, 722174.6886609298, 722174.6886609303, 199823.171155946], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2733000.0000, 
sim time next is 2733600.0000, 
raw observation next is [32.0, 49.0, 1.0, 2.0, 0.3039867491710529, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4839579410840492, 6.9112, 6.9112, 121.9260426156618, 692908.9285079209, 692908.9285079209, 196319.0575014229], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.49, 1.0, 1.0, 0.17141279663220582, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3549474263550615, 0.0, 0.0, 0.8094621288201359, 0.24746747446711462, 0.24746747446711462, 0.3775366490411979], 
reward next is 0.6225, 
noisyNet noise sample is [array([-0.46444768], dtype=float32), 0.5028896]. 
=============================================
[2019-03-24 05:51:18,185] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0498200e-07 2.7889831e-07 9.9999821e-01 3.4650799e-10 1.3983164e-06], sum to 1.0000
[2019-03-24 05:51:18,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9788
[2019-03-24 05:51:18,202] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.35, 53.5, 1.0, 2.0, 0.3145290685001624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5007405205488838, 6.911200000000001, 6.9112, 121.9260426156618, 716910.5120988208, 716910.5120988203, 199189.8556576612], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2730600.0000, 
sim time next is 2731200.0000, 
raw observation next is [31.56666666666667, 52.0, 1.0, 2.0, 0.3125631409977197, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4976106999392062, 6.911199999999999, 6.9112, 121.9260426156618, 712427.4637474616, 712427.463747462, 198651.1213953412], 
processed observation next is [0.0, 0.6086956521739131, 0.7246913580246915, 0.52, 1.0, 1.0, 0.18162278690204728, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3720133749240077, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2544383799098077, 0.2544383799098079, 0.3820213872987331], 
reward next is 0.6180, 
noisyNet noise sample is [array([0.82473403], dtype=float32), 0.37226903]. 
=============================================
[2019-03-24 05:51:20,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7819192e-07 2.7130650e-06 9.9999702e-01 5.3454552e-09 8.5391134e-09], sum to 1.0000
[2019-03-24 05:51:20,984] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-24 05:51:21,150] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 79.5, 1.0, 2.0, 1.013746326991428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1870936.822609441, 1870936.822609442, 382654.6442059719], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2795400.0000, 
sim time next is 2796000.0000, 
raw observation next is [27.63333333333333, 79.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.01118790722712, 6.9112, 121.9254833685839, 1929332.892075671, 1878130.381613016, 383774.6280586988], 
processed observation next is [1.0, 0.34782608695652173, 0.5790123456790122, 0.7933333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.00999879072271197, 0.0, 0.8094584160011147, 0.6890474614555968, 0.6707608505760772, 0.738028130882113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6671648], dtype=float32), 0.67221665]. 
=============================================
[2019-03-24 05:51:21,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.09613 ]
 [63.539967]
 [63.142406]
 [63.02582 ]
 [63.016407]], R is [[63.83055115]
 [63.45637131]
 [63.16042328]
 [63.05083847]
 [62.99085236]].
[2019-03-24 05:51:22,419] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 05:51:22,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:51:22,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:22,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:51:22,422] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:51:22,422] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:22,423] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:22,423] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:51:22,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:51:22,425] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:22,426] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:22,435] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-24 05:51:22,457] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-24 05:51:22,481] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-24 05:51:22,508] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-24 05:51:22,508] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-24 05:51:40,574] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:51:40,575] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.5, 26.16666666666667, 1.0, 2.0, 0.3154830815558511, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289275335320863, 6.9112, 6.9112, 121.9260426156618, 788099.4391541276, 788099.4391541276, 195402.2925907531]
[2019-03-24 05:51:40,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:51:40,579] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4020417e-07 7.7635923e-07 9.9999881e-01 5.0264006e-09 4.2594056e-08], sampled 0.5491964327861486
[2019-03-24 05:51:43,046] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:51:43,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.56666666666667, 29.33333333333334, 1.0, 2.0, 0.182944019718219, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3080467526250559, 6.911199999999999, 6.9112, 121.9260426156618, 458234.6516159337, 458234.6516159342, 162866.201248677]
[2019-03-24 05:51:43,048] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:51:43,050] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7191494e-07 1.0833149e-06 9.9999833e-01 7.7090441e-09 6.1823535e-08], sampled 0.23970920570437027
[2019-03-24 05:52:06,832] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:06,834] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.712781045, 78.82634838, 1.0, 2.0, 0.2169586604602905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3539889850553605, 6.911199999999999, 6.9112, 121.9260426156618, 528606.3601902741, 528606.3601902745, 172410.5721818604]
[2019-03-24 05:52:06,835] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:52:06,837] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0448109e-07 7.0587276e-07 9.9999893e-01 4.3353352e-09 3.6979689e-08], sampled 0.8221806863064995
[2019-03-24 05:52:12,680] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:12,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 94.33333333333334, 1.0, 2.0, 0.2988109294259936, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4773216252491381, 6.911199999999999, 6.9112, 121.9260426156618, 697755.8155138171, 697755.8155138176, 194515.0559184501]
[2019-03-24 05:52:12,683] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:52:12,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0404036e-07 4.7191540e-07 9.9999928e-01 2.6122184e-09 2.3480904e-08], sampled 0.980267638229286
[2019-03-24 05:52:33,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:33,469] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.2538324859676001, 0.0, 2.0, 0.0, 1.0, 2.0, 0.407225037319163, 6.9112, 6.9112, 121.9260426156618, 600857.625690029, 600857.625690029, 182517.7837634613]
[2019-03-24 05:52:33,470] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:52:33,472] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5881525e-07 6.0156952e-07 9.9999917e-01 3.4974412e-09 3.0096526e-08], sampled 0.26388670936744774
[2019-03-24 05:52:39,731] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:39,732] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.16666666666667, 99.0, 1.0, 2.0, 0.2686119576223491, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4297165596546446, 6.911199999999999, 6.9112, 121.9260426156618, 630629.5627432216, 630629.562743222, 186485.4657782095]
[2019-03-24 05:52:39,732] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:52:39,736] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.5382047e-07 5.8209781e-07 9.9999917e-01 3.3983751e-09 2.9063090e-08], sampled 0.8133270300780826
[2019-03-24 05:52:48,660] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:48,661] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.23333333333333, 88.33333333333334, 1.0, 2.0, 0.2507092432172384, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4018762965615202, 6.9112, 6.9112, 121.9260426156618, 592136.5385233238, 592136.5385233238, 181811.7568409256]
[2019-03-24 05:52:48,661] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:52:48,665] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2122597e-07 5.1561381e-07 9.9999928e-01 2.9170319e-09 2.5934193e-08], sampled 0.4903712444870628
[2019-03-24 05:52:50,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:50,772] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.34948304, 63.95515789, 1.0, 2.0, 0.3190093848680157, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5084047475389363, 6.911200000000001, 6.9112, 121.9260426156618, 735845.4740769305, 735845.4740769301, 200256.800692485]
[2019-03-24 05:52:50,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:52:50,777] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7747705e-07 8.4711826e-07 9.9999881e-01 5.7321348e-09 4.7080103e-08], sampled 0.37416339543728605
[2019-03-24 05:52:56,705] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00560613], dtype=float32), 0.0049615484]
[2019-03-24 05:52:56,707] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.18333333333333, 69.33333333333334, 1.0, 2.0, 0.6498348236884218, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1455546.204717964, 1455546.204717964, 308349.2726120053]
[2019-03-24 05:52:56,708] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:52:56,712] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3867822e-07 3.2665761e-07 9.9999952e-01 1.5768719e-09 1.4963170e-08], sampled 0.17832738088762046
[2019-03-24 05:53:06,300] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600807839.8901 61.0000
[2019-03-24 05:53:06,623] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661677694.6124 110.0000
[2019-03-24 05:53:06,868] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.2281 2831332529.6120 210.0000
[2019-03-24 05:53:06,898] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.4193 2623909188.2852 97.0000
[2019-03-24 05:53:07,014] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.9769 2565881560.1474 47.0000
[2019-03-24 05:53:08,029] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 75000, evaluation results [75000.0, 7157.228091348372, 2831332529.6120005, 210.0, 6809.511993196244, 2600807839.890115, 61.0, 7491.976866775571, 2565881560.1473603, 47.0, 6579.928819146758, 2661677694.612359, 110.0, 7161.419268685619, 2623909188.2852426, 97.0]
[2019-03-24 05:53:08,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8048498e-07 4.0245127e-06 9.9999464e-01 3.4087225e-08 4.8446532e-07], sum to 1.0000
[2019-03-24 05:53:08,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3957
[2019-03-24 05:53:08,806] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.15, 58.33333333333334, 1.0, 2.0, 0.3330265303605512, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5301890822508986, 6.911199999999999, 6.9112, 121.9260426156618, 759092.9119825382, 759092.9119825386, 204334.0582594296], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.3345151030176292, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325589384003935, 6.911199999999999, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935537, 204753.8197928081], 
processed observation next is [1.0, 0.8260869565217391, 0.7037037037037037, 0.59, 1.0, 1.0, 0.20775607502098717, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4156986730004918, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27231700621198335, 0.27231700621198346, 0.39375734575540017], 
reward next is 0.6062, 
noisyNet noise sample is [array([-0.9948658], dtype=float32), -0.9365785]. 
=============================================
[2019-03-24 05:53:11,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0066156e-11 4.5149340e-12 1.0000000e+00 2.3773770e-14 1.8929204e-11], sum to 1.0000
[2019-03-24 05:53:11,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3261
[2019-03-24 05:53:11,594] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.3, 84.0, 1.0, 2.0, 0.5667087160420496, 0.0, 2.0, 0.0, 1.0, 2.0, 0.903896913354734, 6.911199999999999, 6.9112, 121.9260426156618, 1314466.00021361, 1314466.00021361, 280763.6105194314], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [24.41666666666666, 84.83333333333333, 1.0, 2.0, 0.5896852004345052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9400072936387561, 6.9112, 6.9112, 121.9260426156618, 1363065.379117066, 1363065.379117066, 289584.1187089287], 
processed observation next is [1.0, 0.4782608695652174, 0.4598765432098763, 0.8483333333333333, 1.0, 1.0, 0.5115300005172682, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.925009117048445, 0.0, 0.0, 0.8094621288201359, 0.4868090639703807, 0.4868090639703807, 0.556892535978709], 
reward next is 0.4431, 
noisyNet noise sample is [array([0.93274415], dtype=float32), -0.8152139]. 
=============================================
[2019-03-24 05:53:11,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5397232e-10 1.6543918e-07 9.9999988e-01 8.2230035e-11 1.8543764e-10], sum to 1.0000
[2019-03-24 05:53:11,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7172
[2019-03-24 05:53:11,778] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.91666666666667, 81.5, 1.0, 2.0, 0.8977677028591335, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156439, 1738536.291114296, 1738536.291114297, 356484.320092489], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2902200.0000, 
sim time next is 2902800.0000, 
raw observation next is [26.73333333333333, 83.0, 1.0, 2.0, 1.007643256173885, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1863969.102771713, 1863969.102771714, 381219.0041694266], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.83, 1.0, 1.0, 1.0090991144927204, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6657032509898975, 0.6657032509898979, 0.7331134695565896], 
reward next is 0.2669, 
noisyNet noise sample is [array([-0.24581411], dtype=float32), 0.32447675]. 
=============================================
[2019-03-24 05:53:16,564] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79492: loss 0.1785
[2019-03-24 05:53:16,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79492: learning rate 0.0000
[2019-03-24 05:53:16,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79606: loss 0.1057
[2019-03-24 05:53:16,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79609: learning rate 0.0000
[2019-03-24 05:53:17,134] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79654: loss 0.6914
[2019-03-24 05:53:17,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79654: learning rate 0.0000
[2019-03-24 05:53:17,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9192053e-08 2.4714650e-09 1.0000000e+00 3.6367787e-10 2.1439260e-10], sum to 1.0000
[2019-03-24 05:53:17,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-24 05:53:17,451] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 82.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.92533192700601, 6.9112, 121.9258972003621, 1885320.949613588, 1878084.148520202, 384084.595697478], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2979000.0000, 
sim time next is 2979600.0000, 
raw observation next is [28.13333333333333, 82.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 8.243299679470775, 6.9112, 121.9210953654887, 2560920.513358832, 1878794.09471904, 379343.0440159679], 
processed observation next is [1.0, 0.4782608695652174, 0.5975308641975308, 0.8266666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.1332099679470775, 0.0, 0.8094292842237641, 0.9146144690567257, 0.6709978909710858, 0.7295058538768614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.64737046], dtype=float32), -0.08499162]. 
=============================================
[2019-03-24 05:53:17,477] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79763: loss 0.3834
[2019-03-24 05:53:17,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79763: learning rate 0.0000
[2019-03-24 05:53:17,669] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79801: loss 0.1345
[2019-03-24 05:53:17,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79801: learning rate 0.0000
[2019-03-24 05:53:17,879] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79837: loss 0.2003
[2019-03-24 05:53:17,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79837: learning rate 0.0000
[2019-03-24 05:53:18,132] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79902: loss 0.2230
[2019-03-24 05:53:18,135] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79903: learning rate 0.0000
[2019-03-24 05:53:18,581] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80074: loss 0.0875
[2019-03-24 05:53:18,585] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80078: learning rate 0.0000
[2019-03-24 05:53:18,728] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80087: loss 0.5918
[2019-03-24 05:53:18,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80089: learning rate 0.0000
[2019-03-24 05:53:18,897] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80105: loss 0.1825
[2019-03-24 05:53:18,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80105: learning rate 0.0000
[2019-03-24 05:53:19,062] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80121: loss 0.5756
[2019-03-24 05:53:19,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80121: learning rate 0.0000
[2019-03-24 05:53:19,227] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80137: loss 0.1706
[2019-03-24 05:53:19,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80137: learning rate 0.0000
[2019-03-24 05:53:19,409] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80168: loss 0.1569
[2019-03-24 05:53:19,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80168: learning rate 0.0000
[2019-03-24 05:53:19,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80271: loss 0.3478
[2019-03-24 05:53:19,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80271: learning rate 0.0000
[2019-03-24 05:53:19,939] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80306: loss 0.4239
[2019-03-24 05:53:19,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80310: learning rate 0.0000
[2019-03-24 05:53:20,135] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80345: loss 0.1877
[2019-03-24 05:53:20,139] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80345: learning rate 0.0000
[2019-03-24 05:53:27,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7651606e-07 7.4057289e-07 9.9999905e-01 5.9829336e-11 5.1985638e-09], sum to 1.0000
[2019-03-24 05:53:27,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4327
[2019-03-24 05:53:27,846] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.23333333333333, 32.0, 1.0, 2.0, 0.233307632007212, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3750527424294787, 6.911199999999999, 6.9112, 121.9260426156618, 554930.3043398954, 554930.3043398958, 177333.999466881], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3174000.0000, 
sim time next is 3174600.0000, 
raw observation next is [34.11666666666667, 32.0, 1.0, 2.0, 0.232733040665538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3743988288547948, 6.911199999999999, 6.9112, 121.9260426156618, 554438.0441760548, 554438.0441760552, 177140.3650587295], 
processed observation next is [1.0, 0.7391304347826086, 0.8191358024691359, 0.32, 1.0, 1.0, 0.08658695317325951, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.21799853606849348, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19801358720573384, 0.198013587205734, 0.34065454818986446], 
reward next is 0.6593, 
noisyNet noise sample is [array([0.84632266], dtype=float32), 0.83991945]. 
=============================================
[2019-03-24 05:53:29,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1826843e-08 1.5038770e-08 1.0000000e+00 6.5078073e-12 6.5646093e-11], sum to 1.0000
[2019-03-24 05:53:29,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8289
[2019-03-24 05:53:29,039] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 60.33333333333334, 1.0, 2.0, 0.2756660635378733, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4402054839509474, 6.911199999999999, 6.9112, 121.9260426156618, 642802.8364693229, 642802.8364693234, 188464.9432410452], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3189000.0000, 
sim time next is 3189600.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.2753466878031779, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4397212494401461, 6.911199999999999, 6.9112, 121.9260426156618, 642219.1395899624, 642219.1395899629, 188376.7729672722], 
processed observation next is [1.0, 0.9565217391304348, 0.5925925925925926, 0.62, 1.0, 1.0, 0.1373174854799737, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2996515618001826, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22936397842498657, 0.22936397842498674, 0.3622630249370619], 
reward next is 0.6377, 
noisyNet noise sample is [array([-0.2585131], dtype=float32), -1.1744564]. 
=============================================
[2019-03-24 05:53:30,752] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7790248e-12 2.8652764e-13 1.0000000e+00 6.3165245e-17 1.2001625e-15], sum to 1.0000
[2019-03-24 05:53:30,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7754
[2019-03-24 05:53:30,764] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.36666666666667, 84.33333333333333, 1.0, 2.0, 0.2817755209505938, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4498858966085693, 6.911199999999999, 6.9112, 121.9260426156618, 656571.9675763813, 656571.9675763818, 190066.3398734307], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3206400.0000, 
sim time next is 3207000.0000, 
raw observation next is [24.18333333333333, 83.66666666666667, 1.0, 2.0, 0.2743412443892973, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4386162773833877, 6.9112, 6.9112, 121.9260426156618, 642734.8156731772, 642734.8156731772, 188009.1238293129], 
processed observation next is [0.0, 0.08695652173913043, 0.45123456790123445, 0.8366666666666667, 1.0, 1.0, 0.13612052903487773, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2982703467292346, 0.0, 0.0, 0.8094621288201359, 0.22954814845470617, 0.22954814845470617, 0.3615560073640633], 
reward next is 0.6384, 
noisyNet noise sample is [array([0.7155338], dtype=float32), 1.4426007]. 
=============================================
[2019-03-24 05:53:30,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.56293]
 [66.58486]
 [66.55011]
 [66.28804]
 [66.32654]], R is [[66.27912903]
 [66.2508316 ]
 [66.21858215]
 [66.18305969]
 [66.14610291]].
[2019-03-24 05:53:31,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2483700e-14 1.2680573e-11 1.0000000e+00 4.3968623e-17 1.9017683e-15], sum to 1.0000
[2019-03-24 05:53:31,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6382
[2019-03-24 05:53:31,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.53333333333333, 65.33333333333333, 1.0, 2.0, 0.2350720844290662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3801591580385306, 6.9112, 6.9112, 121.9260426156618, 565582.0547052455, 565582.0547052455, 177310.9038518941], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3224400.0000, 
sim time next is 3225000.0000, 
raw observation next is [25.91666666666667, 62.16666666666667, 1.0, 2.0, 0.2313349681730199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3747092647338575, 6.911199999999999, 6.9112, 121.9260426156618, 558009.9874009512, 558009.9874009517, 176300.6497323102], 
processed observation next is [0.0, 0.30434782608695654, 0.5154320987654323, 0.6216666666666667, 1.0, 1.0, 0.08492258115835703, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.21838658091732188, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19928928121462544, 0.1992892812146256, 0.3390397110236735], 
reward next is 0.6610, 
noisyNet noise sample is [array([-0.88386196], dtype=float32), 0.9578237]. 
=============================================
[2019-03-24 05:53:31,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.377064]
 [63.414875]
 [63.38464 ]
 [63.36852 ]
 [63.31341 ]], R is [[63.33280563]
 [63.3584938 ]
 [63.38248825]
 [63.40511703]
 [63.42663956]].
[2019-03-24 05:53:32,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9090971e-13 2.9228871e-13 1.0000000e+00 3.0963873e-18 6.4473508e-17], sum to 1.0000
[2019-03-24 05:53:32,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7698
[2019-03-24 05:53:32,449] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666666, 71.0, 1.0, 2.0, 0.2838788065803081, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4528732223798136, 6.9112, 6.9112, 121.9260426156618, 658864.1649463684, 658864.1649463684, 190699.8151958458], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3267600.0000, 
sim time next is 3268200.0000, 
raw observation next is [26.23333333333333, 73.5, 1.0, 2.0, 0.2842674196666588, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4535275287532133, 6.911199999999999, 6.9112, 121.9260426156618, 660028.4645672605, 660028.4645672609, 190793.4728088856], 
processed observation next is [0.0, 0.8260869565217391, 0.5271604938271603, 0.735, 1.0, 1.0, 0.14793740436507, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3169094109415166, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23572445163116446, 0.23572445163116462, 0.3669105246324723], 
reward next is 0.6331, 
noisyNet noise sample is [array([1.3477633], dtype=float32), -1.116977]. 
=============================================
[2019-03-24 05:53:33,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.019219e-13 9.172667e-12 1.000000e+00 3.820439e-17 3.628730e-16], sum to 1.0000
[2019-03-24 05:53:33,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4168
[2019-03-24 05:53:33,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.277598949349704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4435493086671354, 6.911200000000001, 6.9112, 121.9260426156618, 648856.3776503887, 648856.3776503883, 188908.6287819818], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3285000.0000, 
sim time next is 3285600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.277318498379177, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4431019541800156, 6.911199999999999, 6.9112, 121.9260426156618, 648204.8920767662, 648204.8920767666, 188835.8779298466], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.94, 1.0, 1.0, 0.13966487902282976, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30387744272501943, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23150174717027366, 0.23150174717027378, 0.36314591909585886], 
reward next is 0.6369, 
noisyNet noise sample is [array([-0.8713112], dtype=float32), 0.11858606]. 
=============================================
[2019-03-24 05:53:34,059] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87487: loss 0.0057
[2019-03-24 05:53:34,061] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87487: learning rate 0.0000
[2019-03-24 05:53:34,398] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87664: loss 0.0074
[2019-03-24 05:53:34,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87665: learning rate 0.0000
[2019-03-24 05:53:34,445] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87682: loss 0.0038
[2019-03-24 05:53:34,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87682: learning rate 0.0000
[2019-03-24 05:53:34,713] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87830: loss 0.0034
[2019-03-24 05:53:34,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87831: learning rate 0.0000
[2019-03-24 05:53:34,743] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87837: loss 0.0058
[2019-03-24 05:53:34,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87837: learning rate 0.0000
[2019-03-24 05:53:34,814] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87881: loss 0.0096
[2019-03-24 05:53:34,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87882: learning rate 0.0000
[2019-03-24 05:53:34,877] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87914: loss 0.0101
[2019-03-24 05:53:34,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87914: learning rate 0.0000
[2019-03-24 05:53:34,917] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87929: loss 0.0066
[2019-03-24 05:53:34,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87930: learning rate 0.0000
[2019-03-24 05:53:35,046] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87997: loss 0.0187
[2019-03-24 05:53:35,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87998: learning rate 0.0000
[2019-03-24 05:53:35,163] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88060: loss 0.0025
[2019-03-24 05:53:35,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88061: learning rate 0.0000
[2019-03-24 05:53:35,298] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88129: loss 0.0160
[2019-03-24 05:53:35,302] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88129: learning rate 0.0000
[2019-03-24 05:53:35,468] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88218: loss 0.0215
[2019-03-24 05:53:35,472] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88218: learning rate 0.0000
[2019-03-24 05:53:35,495] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88229: loss 0.0024
[2019-03-24 05:53:35,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88229: learning rate 0.0000
[2019-03-24 05:53:35,618] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88293: loss 0.0050
[2019-03-24 05:53:35,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88294: learning rate 0.0000
[2019-03-24 05:53:35,689] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88327: loss 0.0063
[2019-03-24 05:53:35,690] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88327: learning rate 0.0000
[2019-03-24 05:53:35,849] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88413: loss 0.0020
[2019-03-24 05:53:35,853] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88413: learning rate 0.0000
[2019-03-24 05:53:44,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.5951407e-12 1.4444702e-11 1.0000000e+00 2.1235687e-14 1.4681124e-12], sum to 1.0000
[2019-03-24 05:53:44,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-24 05:53:44,318] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.25, 87.5, 1.0, 2.0, 0.753027673793535, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1573328.192363802, 1573328.192363802, 327091.1305289448], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3486600.0000, 
sim time next is 3487200.0000, 
raw observation next is [26.5, 88.0, 1.0, 2.0, 0.7967500373060534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1623231.092092403, 1623231.092092403, 335588.9647556776], 
processed observation next is [1.0, 0.34782608695652173, 0.5370370370370371, 0.88, 1.0, 1.0, 0.7580357586976827, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.579725390033001, 0.579725390033001, 0.6453633937609184], 
reward next is 0.3546, 
noisyNet noise sample is [array([-1.5425085], dtype=float32), 0.09285253]. 
=============================================
[2019-03-24 05:53:44,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4240137e-11 8.2027656e-11 1.0000000e+00 5.7860355e-15 4.5365875e-14], sum to 1.0000
[2019-03-24 05:53:44,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1072
[2019-03-24 05:53:44,877] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.4214934586429214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6710313132431414, 6.9112, 6.9112, 121.9260426156618, 960868.7717383375, 960868.7717383375, 230826.0483937461], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3474600.0000, 
sim time next is 3475200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3494989714459582, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5564137449288197, 6.911199999999999, 6.9112, 121.9260426156618, 796659.3223928347, 796659.3223928352, 209028.250309132], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.94, 1.0, 1.0, 0.22559401362614073, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44551718116102457, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28452118656886954, 0.2845211865688697, 0.4019774044406385], 
reward next is 0.5980, 
noisyNet noise sample is [array([-1.6960977], dtype=float32), -1.1583023]. 
=============================================
[2019-03-24 05:53:47,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8574838e-11 5.6008354e-11 1.0000000e+00 2.7586579e-14 1.4767835e-14], sum to 1.0000
[2019-03-24 05:53:47,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6051
[2019-03-24 05:53:47,340] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.3239487066617671, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5157368912783563, 6.911199999999999, 6.9112, 121.9260426156618, 738391.1661097357, 738391.1661097362, 201792.2614621826], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3250827099963042, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175422615188495, 6.911199999999999, 6.9112, 121.9260426156618, 740977.2012901632, 740977.2012901637, 202107.8459867062], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 1.0, 0.19652703570988592, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3969278268985619, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26463471474648687, 0.26463471474648703, 0.3886689345898196], 
reward next is 0.6113, 
noisyNet noise sample is [array([1.0405352], dtype=float32), -1.5864127]. 
=============================================
[2019-03-24 05:53:47,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4016210e-12 1.5450568e-11 1.0000000e+00 3.5114301e-15 1.4225790e-13], sum to 1.0000
[2019-03-24 05:53:47,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4327
[2019-03-24 05:53:47,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.3106863888043722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4946228493258451, 6.911199999999999, 6.9112, 121.9260426156618, 708147.7928401276, 708147.7928401281, 198139.7284822987], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3520800.0000, 
sim time next is 3521400.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.3183060224009879, 0.0, 2.0, 0.0, 1.0, 2.0, 0.506753554165799, 6.911199999999999, 6.9112, 121.9260426156618, 725523.4500499418, 725523.4500499422, 200229.6120420552], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.7900000000000001, 1.0, 1.0, 0.1884595504773665, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38344194270724874, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2591155178749792, 0.2591155178749794, 0.38505694623472153], 
reward next is 0.6149, 
noisyNet noise sample is [array([-0.58326256], dtype=float32), 0.71816254]. 
=============================================
[2019-03-24 05:53:49,771] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95544: loss 0.1840
[2019-03-24 05:53:49,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95545: learning rate 0.0000
[2019-03-24 05:53:49,957] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95638: loss 0.1149
[2019-03-24 05:53:49,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95639: learning rate 0.0000
[2019-03-24 05:53:50,086] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95704: loss 0.0592
[2019-03-24 05:53:50,088] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95704: loss 0.0793
[2019-03-24 05:53:50,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95704: learning rate 0.0000
[2019-03-24 05:53:50,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95704: learning rate 0.0000
[2019-03-24 05:53:50,332] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95824: loss 0.0353
[2019-03-24 05:53:50,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95824: learning rate 0.0000
[2019-03-24 05:53:50,350] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95831: loss 0.0330
[2019-03-24 05:53:50,353] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95833: learning rate 0.0000
[2019-03-24 05:53:50,410] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95863: loss 0.0204
[2019-03-24 05:53:50,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95863: learning rate 0.0000
[2019-03-24 05:53:50,697] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96000: loss 0.0050
[2019-03-24 05:53:50,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96000: learning rate 0.0000
[2019-03-24 05:53:50,707] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96004: loss 0.0059
[2019-03-24 05:53:50,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96014: learning rate 0.0000
[2019-03-24 05:53:50,733] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96021: loss 0.0040
[2019-03-24 05:53:50,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96023: learning rate 0.0000
[2019-03-24 05:53:50,815] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96057: loss 0.0224
[2019-03-24 05:53:50,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96057: learning rate 0.0000
[2019-03-24 05:53:51,099] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96204: loss 0.0275
[2019-03-24 05:53:51,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96204: learning rate 0.0000
[2019-03-24 05:53:51,215] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96256: loss 0.0609
[2019-03-24 05:53:51,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96258: learning rate 0.0000
[2019-03-24 05:53:51,408] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96351: loss 0.0342
[2019-03-24 05:53:51,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96353: learning rate 0.0000
[2019-03-24 05:53:51,441] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96368: loss 0.0495
[2019-03-24 05:53:51,444] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96368: learning rate 0.0000
[2019-03-24 05:53:51,467] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96379: loss 0.0703
[2019-03-24 05:53:51,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96380: learning rate 0.0000
[2019-03-24 05:53:58,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7794427e-11 2.1170630e-09 1.0000000e+00 6.2709451e-13 1.8227236e-12], sum to 1.0000
[2019-03-24 05:53:58,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1427
[2019-03-24 05:53:58,034] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3333610375363617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.530721628568927, 6.9112, 6.9112, 121.9260426156618, 759855.7577629411, 759855.7577629411, 204427.611975845], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3728400.0000, 
sim time next is 3729000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3356688411489772, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5343957270801273, 6.911199999999999, 6.9112, 121.9260426156618, 765118.7395316652, 765118.7395316657, 205079.1137591513], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20912957279640146, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4179946588501591, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27325669268988045, 0.2732566926898806, 0.394382911075291], 
reward next is 0.6056, 
noisyNet noise sample is [array([1.3400468], dtype=float32), -1.0312808]. 
=============================================
[2019-03-24 05:53:58,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.784912]
 [57.71512 ]
 [57.87047 ]
 [57.72336 ]
 [58.25986 ]], R is [[57.69117355]
 [57.72113037]
 [57.75208664]
 [57.78026199]
 [57.79189682]].
[2019-03-24 05:53:58,729] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 05:53:58,730] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:53:58,732] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:58,732] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:53:58,733] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:53:58,734] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:58,734] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:58,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:53:58,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:53:58,739] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:58,740] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:58,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-24 05:53:58,751] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-24 05:53:58,772] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-24 05:53:58,773] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-24 05:53:58,859] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-24 05:54:36,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:54:36,532] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.15148913, 54.93795031833333, 1.0, 2.0, 0.2132112611279048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3467959815103797, 6.911199999999999, 6.9112, 121.9260426156618, 517397.6402051318, 517397.6402051322, 171748.8759063389]
[2019-03-24 05:54:36,533] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:54:36,535] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.9729627e-11 4.0466863e-10 1.0000000e+00 6.0464966e-14 4.4502618e-13], sampled 0.9519754434357637
[2019-03-24 05:54:43,219] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:54:43,220] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.88076636666667, 83.74938203333333, 1.0, 2.0, 0.2785496875421473, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4442160378516322, 6.911199999999999, 6.9112, 121.9260426156618, 645236.6037287373, 645236.6037287378, 189349.1131312235]
[2019-03-24 05:54:43,222] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:54:43,226] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.02536035e-10 4.57856586e-10 1.00000000e+00 7.26576731e-14
 5.30963077e-13], sampled 0.7948434092528506
[2019-03-24 05:55:10,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:10,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.87397105, 64.82798336, 1.0, 2.0, 0.8007742904069539, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1627824.234798742, 1627824.234798743, 336386.4588294461]
[2019-03-24 05:55:10,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:55:10,519] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2707970e-09 4.7255297e-09 1.0000000e+00 2.0450404e-12 1.2067136e-11], sampled 0.4640559671510607
[2019-03-24 05:55:16,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:16,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.5, 84.0, 1.0, 2.0, 0.2761845454308107, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4409677919443773, 6.9112, 6.9112, 121.9260426156618, 643593.8841982486, 643593.8841982486, 188613.5436975995]
[2019-03-24 05:55:16,846] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:55:16,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.1159572e-11 3.6743808e-10 1.0000000e+00 5.2195590e-14 3.9077503e-13], sampled 0.8295037886106907
[2019-03-24 05:55:33,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:33,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 60.5, 1.0, 2.0, 0.5668302345637676, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9024121937974721, 6.911199999999999, 6.9112, 121.9260426156618, 1292469.080586886, 1292469.080586887, 281180.4475188004]
[2019-03-24 05:55:33,059] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:55:33,064] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0288684e-10 1.9937494e-09 1.0000000e+00 6.0093521e-13 3.7606875e-12], sampled 0.954850701144932
[2019-03-24 05:55:34,880] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:34,880] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 61.0, 1.0, 2.0, 0.5107109342654343, 0.0, 2.0, 0.0, 1.0, 2.0, 0.814836343226641, 6.911199999999999, 6.9112, 121.9260426156618, 1186468.504512214, 1186468.504512215, 260340.6269928307]
[2019-03-24 05:55:34,881] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:55:34,884] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3441781e-10 5.7627453e-10 1.0000000e+00 1.0330165e-13 7.2974645e-13], sampled 0.9709841670828929
[2019-03-24 05:55:39,220] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:39,222] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.55216496333334, 65.45498625333335, 1.0, 2.0, 0.2291283381070959, 0.0, 2.0, 0.0, 1.0, 2.0, 0.370976545406106, 6.911199999999999, 6.9112, 121.9260426156618, 552314.0971325078, 552314.0971325082, 175804.7753744991]
[2019-03-24 05:55:39,222] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:55:39,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.4115005e-11 2.9255631e-10 1.0000000e+00 3.8625458e-14 2.9311273e-13], sampled 0.9585372357681785
[2019-03-24 05:55:39,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00579111], dtype=float32), 0.0048165396]
[2019-03-24 05:55:39,999] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 83.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2555595812478105, 6.911199999999999, 6.9112, 121.9260426156618, 376045.9750099197, 376045.9750099201, 153251.4017459546]
[2019-03-24 05:55:40,000] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:55:40,002] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0748062e-10 4.8729748e-10 1.0000000e+00 7.6594099e-14 5.6042383e-13], sampled 0.8914644054465503
[2019-03-24 05:55:43,056] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661671772.7634 110.0000
[2019-03-24 05:55:43,147] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600782091.6628 61.0000
[2019-03-24 05:55:43,192] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7160.7623 2623886949.3959 97.0000
[2019-03-24 05:55:43,242] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7492.5206 2565975221.9196 47.0000
[2019-03-24 05:55:43,365] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.2535 2831322700.3798 210.0000
[2019-03-24 05:55:44,380] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 100000, evaluation results [100000.0, 7157.253499039712, 2831322700.379781, 210.0, 6809.511993196244, 2600782091.662834, 61.0, 7492.520639979948, 2565975221.919632, 47.0, 6579.928819146758, 2661671772.7634306, 110.0, 7160.762343300278, 2623886949.395926, 97.0]
[2019-03-24 05:55:51,172] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103547: loss 0.2015
[2019-03-24 05:55:51,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103548: learning rate 0.0000
[2019-03-24 05:55:51,502] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103717: loss 0.1133
[2019-03-24 05:55:51,506] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103718: learning rate 0.0000
[2019-03-24 05:55:51,531] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103733: loss 0.1850
[2019-03-24 05:55:51,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103733: learning rate 0.0000
[2019-03-24 05:55:51,560] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103749: loss 0.1778
[2019-03-24 05:55:51,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103750: learning rate 0.0000
[2019-03-24 05:55:51,604] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103771: loss 0.1213
[2019-03-24 05:55:51,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103771: learning rate 0.0000
[2019-03-24 05:55:51,693] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103817: loss 0.0522
[2019-03-24 05:55:51,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103817: learning rate 0.0000
[2019-03-24 05:55:51,739] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103841: loss 0.1632
[2019-03-24 05:55:51,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103841: learning rate 0.0000
[2019-03-24 05:55:51,932] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103942: loss 0.1357
[2019-03-24 05:55:51,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103944: learning rate 0.0000
[2019-03-24 05:55:51,956] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103960: loss 0.1831
[2019-03-24 05:55:51,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103960: learning rate 0.0000
[2019-03-24 05:55:51,983] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103971: loss 0.1891
[2019-03-24 05:55:51,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103971: learning rate 0.0000
[2019-03-24 05:55:52,151] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104057: loss 0.1197
[2019-03-24 05:55:52,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104057: learning rate 0.0000
[2019-03-24 05:55:52,490] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104236: loss 0.2220
[2019-03-24 05:55:52,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104237: learning rate 0.0000
[2019-03-24 05:55:52,524] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104254: loss 0.0806
[2019-03-24 05:55:52,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104255: learning rate 0.0000
[2019-03-24 05:55:52,655] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104321: loss 0.2148
[2019-03-24 05:55:52,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104322: learning rate 0.0000
[2019-03-24 05:55:52,809] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104406: loss 0.1859
[2019-03-24 05:55:52,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104407: learning rate 0.0000
[2019-03-24 05:55:52,837] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104419: loss 0.1260
[2019-03-24 05:55:52,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104419: learning rate 0.0000
[2019-03-24 05:56:01,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8953057e-10 6.0539556e-09 1.0000000e+00 7.9334792e-13 2.0439874e-12], sum to 1.0000
[2019-03-24 05:56:02,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7565
[2019-03-24 05:56:02,004] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 70.0, 1.0, 2.0, 0.8779183303245323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1715878.328030074, 1715878.328030075, 352237.095138044], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4104600.0000, 
sim time next is 4105200.0000, 
raw observation next is [28.33333333333334, 70.0, 1.0, 2.0, 0.7188255575584772, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1534288.662441583, 1534288.662441583, 320673.3651112838], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.7, 1.0, 1.0, 0.6652685209029491, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5479602365862796, 0.5479602365862796, 0.6166795482909303], 
reward next is 0.3833, 
noisyNet noise sample is [array([-0.07590944], dtype=float32), -0.6049747]. 
=============================================
[2019-03-24 05:56:04,447] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7149879e-10 3.4588695e-08 1.0000000e+00 3.4621523e-14 3.9563049e-12], sum to 1.0000
[2019-03-24 05:56:04,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0893
[2019-03-24 05:56:04,465] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.2271295428570012, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3688742112674594, 6.9112, 6.9112, 121.9260426156618, 550027.6961038894, 550027.6961038894, 175113.3169575913], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4134600.0000, 
sim time next is 4135200.0000, 
raw observation next is [21.56666666666667, 90.66666666666666, 1.0, 2.0, 0.2288068205468099, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3713686786635816, 6.9112, 6.9112, 121.9260426156618, 553599.9061732817, 553599.9061732817, 175554.6446274801], 
processed observation next is [1.0, 0.8695652173913043, 0.35432098765432113, 0.9066666666666666, 1.0, 1.0, 0.08191288160334512, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.21421084832947695, 0.0, 0.0, 0.8094621288201359, 0.19771425220474348, 0.19771425220474348, 0.3376050858220771], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.5381152], dtype=float32), 0.2409321]. 
=============================================
[2019-03-24 05:56:06,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111620: loss 0.0525
[2019-03-24 05:56:06,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111620: learning rate 0.0000
[2019-03-24 05:56:06,546] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111646: loss 0.0448
[2019-03-24 05:56:06,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111646: learning rate 0.0000
[2019-03-24 05:56:06,694] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111724: loss 0.0579
[2019-03-24 05:56:06,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111726: learning rate 0.0000
[2019-03-24 05:56:06,714] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111733: loss 0.0561
[2019-03-24 05:56:06,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111733: learning rate 0.0000
[2019-03-24 05:56:06,729] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111740: loss 0.0355
[2019-03-24 05:56:06,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111740: learning rate 0.0000
[2019-03-24 05:56:06,920] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111840: loss 0.0176
[2019-03-24 05:56:06,923] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111841: learning rate 0.0000
[2019-03-24 05:56:06,933] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111849: loss 0.0124
[2019-03-24 05:56:06,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111849: learning rate 0.0000
[2019-03-24 05:56:06,942] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111852: loss 0.0083
[2019-03-24 05:56:06,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111853: learning rate 0.0000
[2019-03-24 05:56:07,177] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111976: loss 0.0119
[2019-03-24 05:56:07,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111977: learning rate 0.0000
[2019-03-24 05:56:07,219] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111999: loss 0.0091
[2019-03-24 05:56:07,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111999: learning rate 0.0000
[2019-03-24 05:56:07,508] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112147: loss 0.0352
[2019-03-24 05:56:07,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112147: learning rate 0.0000
[2019-03-24 05:56:07,725] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112264: loss 0.0021
[2019-03-24 05:56:07,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112264: learning rate 0.0000
[2019-03-24 05:56:07,811] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112307: loss 0.0055
[2019-03-24 05:56:07,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112309: learning rate 0.0000
[2019-03-24 05:56:07,820] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112312: loss 0.0026
[2019-03-24 05:56:07,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112313: learning rate 0.0000
[2019-03-24 05:56:07,877] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112342: loss 0.0031
[2019-03-24 05:56:07,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112343: learning rate 0.0000
[2019-03-24 05:56:08,184] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112506: loss 0.0136
[2019-03-24 05:56:08,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112508: learning rate 0.0000
[2019-03-24 05:56:13,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5898247e-10 6.1942085e-10 1.0000000e+00 6.8927232e-14 2.9373378e-14], sum to 1.0000
[2019-03-24 05:56:13,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0291
[2019-03-24 05:56:13,917] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 89.0, 1.0, 2.0, 0.3219957938006485, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147996262421214, 6.9112, 6.9112, 121.9260426156618, 754401.1072823419, 754401.1072823419, 200736.6442541974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [23.66666666666667, 89.0, 1.0, 2.0, 0.3230958249183882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5161205665447313, 6.911199999999999, 6.9112, 121.9260426156618, 754528.3044038875, 754528.304403888, 201126.0586691232], 
processed observation next is [1.0, 0.2608695652173913, 0.43209876543209896, 0.89, 1.0, 1.0, 0.1941616963314145, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.395150708180914, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2694743944299598, 0.26947439442995996, 0.38678088205600614], 
reward next is 0.6132, 
noisyNet noise sample is [array([0.24672744], dtype=float32), 0.15464407]. 
=============================================
[2019-03-24 05:56:13,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[53.20005 ]
 [53.020283]
 [52.824562]
 [52.544796]
 [52.475708]], R is [[53.23726654]
 [53.31886292]
 [53.4026413 ]
 [53.47784042]
 [53.58454895]].
[2019-03-24 05:56:15,013] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7284275e-08 1.7234136e-07 9.9999988e-01 1.2164778e-10 2.7486646e-09], sum to 1.0000
[2019-03-24 05:56:15,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2693
[2019-03-24 05:56:15,024] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.33333333333334, 60.0, 1.0, 2.0, 0.9933381832286006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1847637.579924064, 1847637.579924064, 377881.8629778679], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4365600.0000, 
sim time next is 4366200.0000, 
raw observation next is [31.66666666666667, 59.5, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.336430729767303, 6.9112, 121.9244372912352, 2096058.809030602, 1878305.535758159, 382610.0000543051], 
processed observation next is [1.0, 0.5217391304347826, 0.7283950617283952, 0.595, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.04252307297673026, 0.0, 0.809451471135363, 0.7485924317966436, 0.6708234056279139, 0.7357884616428945], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.98807704], dtype=float32), 0.012292067]. 
=============================================
[2019-03-24 05:56:17,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6809394e-11 4.3207118e-09 1.0000000e+00 4.2252936e-13 6.3508525e-11], sum to 1.0000
[2019-03-24 05:56:17,038] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3526
[2019-03-24 05:56:17,040] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 79.0, 1.0, 2.0, 0.330869846161674, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5267555707679853, 6.911199999999999, 6.9112, 121.9260426156618, 754174.5979286213, 754174.5979286218, 203725.9067906221], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4398000.0000, 
sim time next is 4398600.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.3236951861515245, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5153332783694635, 6.911199999999999, 6.9112, 121.9260426156618, 737813.0270643377, 737813.0270643382, 201720.5262720674], 
processed observation next is [1.0, 0.9130434782608695, 0.5370370370370371, 0.79, 1.0, 1.0, 0.19487522160895773, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39416659796182935, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2635046525229778, 0.26350465252297794, 0.387924088984745], 
reward next is 0.6121, 
noisyNet noise sample is [array([0.8940325], dtype=float32), 0.40151897]. 
=============================================
[2019-03-24 05:56:18,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2148797e-11 9.4565137e-12 1.0000000e+00 2.3724101e-16 6.9239516e-14], sum to 1.0000
[2019-03-24 05:56:18,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3814
[2019-03-24 05:56:18,160] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 92.66666666666667, 1.0, 2.0, 0.2488832671747669, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4004410018410109, 6.911199999999999, 6.9112, 121.9260426156618, 593121.0603713352, 593121.0603713357, 181060.2070164508], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4411200.0000, 
sim time next is 4411800.0000, 
raw observation next is [22.25, 92.0, 1.0, 2.0, 0.2486691657104514, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4000965409067711, 6.911199999999999, 6.9112, 121.9260426156618, 592610.6878534715, 592610.687853472, 181007.4018929616], 
processed observation next is [0.0, 0.043478260869565216, 0.37962962962962965, 0.92, 1.0, 1.0, 0.10555853060768022, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.25012067613346384, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21164667423338268, 0.21164667423338285, 0.34809115748646463], 
reward next is 0.6519, 
noisyNet noise sample is [array([-1.2583908], dtype=float32), 0.36878908]. 
=============================================
[2019-03-24 05:56:21,157] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6365636e-10 8.1799900e-10 1.0000000e+00 7.9658326e-14 3.9132621e-13], sum to 1.0000
[2019-03-24 05:56:21,166] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9761
[2019-03-24 05:56:21,171] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.08333333333333, 72.66666666666667, 1.0, 2.0, 0.354417533619521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5642442560955184, 6.911199999999999, 6.9112, 121.9260426156618, 807876.7615317225, 807876.761531723, 210453.6695052309], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4470600.0000, 
sim time next is 4471200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.3582039033765037, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5702722800620889, 6.911199999999999, 6.9112, 121.9260426156618, 816512.1962128424, 816512.1962128428, 211556.1240975448], 
processed observation next is [0.0, 0.782608695652174, 0.6296296296296297, 0.74, 1.0, 1.0, 0.23595702782917108, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46284035007761104, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2916114986474437, 0.29161149864744385, 0.4068387001875861], 
reward next is 0.5932, 
noisyNet noise sample is [array([-1.3794951], dtype=float32), 0.98476654]. 
=============================================
[2019-03-24 05:56:21,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119609: loss 0.4033
[2019-03-24 05:56:21,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119609: learning rate 0.0000
[2019-03-24 05:56:22,055] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119641: loss 0.3969
[2019-03-24 05:56:22,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119641: learning rate 0.0000
[2019-03-24 05:56:22,079] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119650: loss 0.5137
[2019-03-24 05:56:22,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119650: learning rate 0.0000
[2019-03-24 05:56:22,100] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119660: loss 0.3729
[2019-03-24 05:56:22,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119660: learning rate 0.0000
[2019-03-24 05:56:22,162] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119692: loss 0.5178
[2019-03-24 05:56:22,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119693: learning rate 0.0000
[2019-03-24 05:56:22,294] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119756: loss 0.4440
[2019-03-24 05:56:22,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119757: learning rate 0.0000
[2019-03-24 05:56:22,480] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119849: loss 0.9780
[2019-03-24 05:56:22,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119850: learning rate 0.0000
[2019-03-24 05:56:22,673] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119945: loss 0.5106
[2019-03-24 05:56:22,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119945: learning rate 0.0000
[2019-03-24 05:56:22,720] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119969: loss 0.8225
[2019-03-24 05:56:22,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119969: learning rate 0.0000
[2019-03-24 05:56:22,905] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120062: loss 0.4957
[2019-03-24 05:56:22,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120062: learning rate 0.0000
[2019-03-24 05:56:23,090] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120153: loss 0.7413
[2019-03-24 05:56:23,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120153: learning rate 0.0000
[2019-03-24 05:56:23,095] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120154: loss 1.0083
[2019-03-24 05:56:23,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120154: learning rate 0.0000
[2019-03-24 05:56:23,366] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120293: loss 0.8569
[2019-03-24 05:56:23,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120294: learning rate 0.0000
[2019-03-24 05:56:23,524] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120366: loss 0.6013
[2019-03-24 05:56:23,530] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120369: learning rate 0.0000
[2019-03-24 05:56:23,652] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120430: loss 0.6302
[2019-03-24 05:56:23,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120431: learning rate 0.0000
[2019-03-24 05:56:23,969] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120588: loss 0.3498
[2019-03-24 05:56:23,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120588: learning rate 0.0000
[2019-03-24 05:56:24,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0011428e-14 2.9446348e-11 1.0000000e+00 1.3534310e-15 9.7287182e-14], sum to 1.0000
[2019-03-24 05:56:24,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2194
[2019-03-24 05:56:24,507] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.15, 95.5, 1.0, 2.0, 0.2877983716105538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4590755899570713, 6.911199999999999, 6.9112, 121.9260426156618, 667570.8440646087, 667570.8440646091, 191740.0319013757], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4509000.0000, 
sim time next is 4509600.0000, 
raw observation next is [23.2, 94.0, 1.0, 2.0, 0.2841409643822238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4534965099615545, 6.911199999999999, 6.9112, 121.9260426156618, 660971.600547736, 660971.6005477365, 190721.1518253025], 
processed observation next is [0.0, 0.17391304347826086, 0.4148148148148148, 0.94, 1.0, 1.0, 0.14778686235979024, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3168706374519431, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23606128590990574, 0.2360612859099059, 0.36677144581788945], 
reward next is 0.6332, 
noisyNet noise sample is [array([0.5451798], dtype=float32), 2.019215]. 
=============================================
[2019-03-24 05:56:26,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1937798e-14 2.8522689e-15 1.0000000e+00 4.9050120e-19 2.9254579e-17], sum to 1.0000
[2019-03-24 05:56:26,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5851
[2019-03-24 05:56:26,415] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2444915850926329, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3941937619193779, 6.911199999999999, 6.9112, 121.9260426156618, 585090.7789500315, 585090.778950032, 179821.5116135829], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2428033147186268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3916837198670403, 6.9112, 6.9112, 121.9260426156618, 581640.2062659097, 581640.2062659097, 179368.3363354052], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0985753746650319, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.23960464983380036, 0.0, 0.0, 0.8094621288201359, 0.20772864509496775, 0.20772864509496775, 0.3449391083373177], 
reward next is 0.6551, 
noisyNet noise sample is [array([-0.89610255], dtype=float32), 0.42658255]. 
=============================================
[2019-03-24 05:56:31,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5099814e-10 2.9916480e-09 1.0000000e+00 1.9240849e-13 9.8679389e-12], sum to 1.0000
[2019-03-24 05:56:31,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9478
[2019-03-24 05:56:31,530] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.1, 93.16666666666667, 1.0, 2.0, 0.3319406407513321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5284603106280661, 6.911199999999999, 6.9112, 121.9260426156618, 756616.5389298984, 756616.5389298989, 204027.6728066334], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4665000.0000, 
sim time next is 4665600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.332198642741717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5288710581992969, 6.911199999999999, 6.9112, 121.9260426156618, 757204.9121717567, 757204.9121717572, 204100.2805614574], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20499838421632977, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4110888227491211, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2704303257756274, 0.2704303257756276, 0.3925005395412642], 
reward next is 0.6075, 
noisyNet noise sample is [array([0.18313077], dtype=float32), -0.25195864]. 
=============================================
[2019-03-24 05:56:32,894] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:56:32,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:56:32,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:32,898] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:56:32,900] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:56:32,903] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:32,905] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:32,902] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:56:32,905] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:56:32,911] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:32,912] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:32,922] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-24 05:56:32,922] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-24 05:56:32,981] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-24 05:56:32,982] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-24 05:56:32,982] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-24 05:57:15,534] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:57:15,535] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.11476802, 94.649711335, 1.0, 2.0, 0.2956162782847577, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4706748595863839, 6.9112, 6.9112, 121.9260426156618, 675070.9179440615, 675070.9179440615, 194052.9784392189]
[2019-03-24 05:57:15,536] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:57:15,540] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6680893e-11 8.4348188e-11 1.0000000e+00 3.0121597e-15 1.3762228e-13], sampled 0.0637572253966765
[2019-03-24 05:57:17,350] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:57:17,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.28333333333333, 85.50000000000001, 1.0, 2.0, 0.2223268631260363, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3605946988733776, 6.9112, 6.9112, 121.9260426156618, 537354.6577134571, 537354.6577134571, 174071.0504459626]
[2019-03-24 05:57:17,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:57:17,358] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.9992987e-12 3.7836262e-11 1.0000000e+00 9.1995084e-16 4.9007412e-14], sampled 0.833335321220295
[2019-03-24 05:57:19,734] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:57:19,737] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.175322945, 68.58453260499999, 1.0, 2.0, 0.2574621151511549, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4125546036771936, 6.9112, 6.9112, 121.9260426156618, 607490.5427027168, 607490.5427027168, 183523.8258016788]
[2019-03-24 05:57:19,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:57:19,743] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.4406883e-12 4.6203742e-11 1.0000000e+00 1.2004739e-15 6.2323322e-14], sampled 0.542672605755815
[2019-03-24 05:57:32,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:57:32,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.33333333333334, 60.0, 1.0, 2.0, 0.993338183232473, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1847637.579928485, 1847637.579928485, 377881.8628674139]
[2019-03-24 05:57:33,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:57:33,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0390496e-09 3.7536414e-09 1.0000000e+00 8.0464335e-13 2.0056894e-11], sampled 0.05000922216522119
[2019-03-24 05:57:34,737] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:57:34,738] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.33333333333334, 94.0, 1.0, 2.0, 0.3211434153705349, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5112707761807556, 6.911200000000001, 6.9112, 121.9260426156618, 731993.8838087041, 731993.8838087036, 201012.3775934329]
[2019-03-24 05:57:34,739] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:57:34,742] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0986897e-11 5.7624017e-11 1.0000000e+00 1.6847576e-15 8.2528453e-14], sampled 0.27292011406651684
[2019-03-24 05:58:04,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:58:04,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.83333333333333, 55.5, 1.0, 2.0, 0.3387303159607074, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5398100407115393, 6.911199999999999, 6.9112, 121.9260426156618, 781099.7019492743, 781099.7019492747, 205780.1169020791]
[2019-03-24 05:58:04,029] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:58:04,033] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4821313e-11 1.7200598e-10 1.0000000e+00 8.2459183e-15 3.3865751e-13], sampled 0.4825283349348324
[2019-03-24 05:58:06,670] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00612615], dtype=float32), 0.0047059464]
[2019-03-24 05:58:06,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.66666666666666, 50.0, 1.0, 2.0, 0.27579387492427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4401488262017813, 6.9112, 6.9112, 121.9260426156618, 641367.9207773753, 641367.9207773753, 188557.0853262777]
[2019-03-24 05:58:06,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:58:06,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3587569e-11 7.2159216e-11 1.0000000e+00 2.2962203e-15 1.1056911e-13], sampled 0.42360872219450485
[2019-03-24 05:58:17,220] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661677694.6124 110.0000
[2019-03-24 05:58:17,542] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.8595 2831362235.9031 210.0000
[2019-03-24 05:58:17,737] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6811.9826 2600678705.4340 61.0000
[2019-03-24 05:58:17,753] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.9187 2623802615.4855 97.0000
[2019-03-24 05:58:17,952] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.1715 2566003647.8353 47.0000
[2019-03-24 05:58:18,968] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 125000, evaluation results [125000.0, 7157.859463619724, 2831362235.9030914, 210.0, 6811.982610042657, 2600678705.433957, 61.0, 7491.171516197488, 2566003647.835342, 47.0, 6579.928819146758, 2661677694.612359, 110.0, 7162.918675037749, 2623802615.4854736, 97.0]
[2019-03-24 05:58:19,257] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2908510e-09 2.6640363e-09 1.0000000e+00 2.1312726e-12 1.4158626e-10], sum to 1.0000
[2019-03-24 05:58:19,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-24 05:58:19,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 84.0, 1.0, 2.0, 0.8086289899179073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1636789.384014105, 1636789.384014105, 337952.1665045164], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4704000.0000, 
sim time next is 4704600.0000, 
raw observation next is [26.75, 81.5, 1.0, 2.0, 0.8489858181454526, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1682853.034122941, 1682853.034122942, 346172.0756261489], 
processed observation next is [1.0, 0.43478260869565216, 0.5462962962962963, 0.815, 1.0, 1.0, 0.8202212120779198, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6010189407581933, 0.6010189407581936, 0.6657155300502864], 
reward next is 0.3343, 
noisyNet noise sample is [array([-0.6449816], dtype=float32), -0.741978]. 
=============================================
[2019-03-24 05:58:23,768] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127525: loss 0.3048
[2019-03-24 05:58:23,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127526: learning rate 0.0000
[2019-03-24 05:58:23,953] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127622: loss 0.3609
[2019-03-24 05:58:23,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127623: learning rate 0.0000
[2019-03-24 05:58:24,045] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127672: loss 0.3408
[2019-03-24 05:58:24,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127674: learning rate 0.0000
[2019-03-24 05:58:24,084] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127691: loss 0.3576
[2019-03-24 05:58:24,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127691: learning rate 0.0000
[2019-03-24 05:58:24,151] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127731: loss 0.3447
[2019-03-24 05:58:24,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127731: learning rate 0.0000
[2019-03-24 05:58:24,222] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127763: loss 0.3453
[2019-03-24 05:58:24,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127763: learning rate 0.0000
[2019-03-24 05:58:24,246] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127776: loss 0.3570
[2019-03-24 05:58:24,247] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127776: learning rate 0.0000
[2019-03-24 05:58:24,472] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127898: loss 0.4092
[2019-03-24 05:58:24,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127898: learning rate 0.0000
[2019-03-24 05:58:24,592] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127965: loss 0.3934
[2019-03-24 05:58:24,597] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127965: learning rate 0.0000
[2019-03-24 05:58:24,625] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127977: loss 0.4452
[2019-03-24 05:58:24,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127978: learning rate 0.0000
[2019-03-24 05:58:24,902] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128116: loss 0.4667
[2019-03-24 05:58:24,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128117: learning rate 0.0000
[2019-03-24 05:58:25,039] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128185: loss 0.5356
[2019-03-24 05:58:25,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128186: learning rate 0.0000
[2019-03-24 05:58:25,356] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128349: loss 0.4911
[2019-03-24 05:58:25,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128350: learning rate 0.0000
[2019-03-24 05:58:25,375] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128360: loss 0.5123
[2019-03-24 05:58:25,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128360: learning rate 0.0000
[2019-03-24 05:58:25,548] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128449: loss 0.4537
[2019-03-24 05:58:25,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128449: learning rate 0.0000
[2019-03-24 05:58:25,769] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128560: loss 0.3501
[2019-03-24 05:58:25,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128560: learning rate 0.0000
[2019-03-24 05:58:39,117] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135580: loss 1.0691
[2019-03-24 05:58:39,119] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135580: learning rate 0.0000
[2019-03-24 05:58:39,147] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135595: loss 1.2531
[2019-03-24 05:58:39,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135595: learning rate 0.0000
[2019-03-24 05:58:39,339] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135692: loss 1.3816
[2019-03-24 05:58:39,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135693: learning rate 0.0000
[2019-03-24 05:58:39,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135727: loss 1.2542
[2019-03-24 05:58:39,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135727: learning rate 0.0000
[2019-03-24 05:58:39,417] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135737: loss 1.5549
[2019-03-24 05:58:39,418] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135737: learning rate 0.0000
[2019-03-24 05:58:39,438] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135747: loss 1.9062
[2019-03-24 05:58:39,440] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135747: learning rate 0.0000
[2019-03-24 05:58:39,602] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5479024e-12 8.9613447e-12 1.0000000e+00 7.5368504e-18 1.4855080e-13], sum to 1.0000
[2019-03-24 05:58:39,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4705
[2019-03-24 05:58:39,616] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.9, 83.0, 1.0, 2.0, 0.4124493216291957, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6566327525703108, 6.9112, 6.9112, 121.9260426156618, 940238.4159471216, 940238.4159471216, 227980.4219670802], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5081400.0000, 
sim time next is 5082000.0000, 
raw observation next is [28.86666666666667, 82.66666666666667, 1.0, 2.0, 0.4098631427879538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.652515471629089, 6.911199999999999, 6.9112, 121.9260426156618, 934339.2498860427, 934339.2498860431, 227170.4960809102], 
processed observation next is [0.0, 0.8260869565217391, 0.6246913580246916, 0.8266666666666667, 1.0, 1.0, 0.29745612236661173, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5656443395363612, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3336925892450152, 0.3336925892450154, 0.43686633861713503], 
reward next is 0.5631, 
noisyNet noise sample is [array([0.8352258], dtype=float32), 0.48540497]. 
=============================================
[2019-03-24 05:58:39,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.672054]
 [62.63754 ]
 [62.618023]
 [62.519703]
 [62.42748 ]], R is [[62.64080429]
 [62.57597351]
 [62.51266098]
 [62.45502472]
 [62.38903427]].
[2019-03-24 05:58:39,650] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135849: loss 1.5407
[2019-03-24 05:58:39,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135849: learning rate 0.0000
[2019-03-24 05:58:39,718] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135893: loss 1.2899
[2019-03-24 05:58:39,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135894: learning rate 0.0000
[2019-03-24 05:58:39,786] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135922: loss 1.2042
[2019-03-24 05:58:39,787] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135922: learning rate 0.0000
[2019-03-24 05:58:39,948] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136008: loss 0.8990
[2019-03-24 05:58:39,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136008: learning rate 0.0000
[2019-03-24 05:58:40,249] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136166: loss 1.0245
[2019-03-24 05:58:40,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136167: learning rate 0.0000
[2019-03-24 05:58:40,319] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136205: loss 1.5768
[2019-03-24 05:58:40,324] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136205: learning rate 0.0000
[2019-03-24 05:58:40,375] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136233: loss 1.4253
[2019-03-24 05:58:40,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136233: learning rate 0.0000
[2019-03-24 05:58:40,532] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136317: loss 1.3809
[2019-03-24 05:58:40,535] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136317: learning rate 0.0000
[2019-03-24 05:58:40,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0887998e-10 2.6450318e-11 1.0000000e+00 5.0008109e-15 3.6708795e-13], sum to 1.0000
[2019-03-24 05:58:40,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2565
[2019-03-24 05:58:40,638] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.28333333333333, 98.83333333333334, 1.0, 2.0, 0.3509479994226563, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5587206446592696, 6.911199999999999, 6.9112, 121.9260426156618, 799964.0075151563, 799964.0075151568, 209449.1056711054], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [25.56666666666667, 97.66666666666667, 1.0, 2.0, 0.3586478785030692, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5709791029228416, 6.911199999999999, 6.9112, 121.9260426156618, 817524.7603789673, 817524.7603789677, 211685.9091864844], 
processed observation next is [0.0, 0.30434782608695654, 0.5024691358024692, 0.9766666666666667, 1.0, 1.0, 0.23648556964651093, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46372387865355197, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.291973128706774, 0.29197312870677417, 0.4070882868970854], 
reward next is 0.5929, 
noisyNet noise sample is [array([-1.0386658], dtype=float32), 0.063360326]. 
=============================================
[2019-03-24 05:58:40,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.901108]
 [61.845062]
 [61.78282 ]
 [61.786903]
 [61.760666]], R is [[61.8901062 ]
 [61.86841965]
 [61.84431839]
 [61.82048416]
 [61.79693604]].
[2019-03-24 05:58:40,894] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136504: loss 1.3034
[2019-03-24 05:58:40,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136505: learning rate 0.0000
[2019-03-24 05:58:41,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136590: loss 1.2048
[2019-03-24 05:58:41,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136592: learning rate 0.0000
[2019-03-24 05:58:43,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1247240e-12 2.2769731e-12 1.0000000e+00 1.5874957e-16 3.3602573e-14], sum to 1.0000
[2019-03-24 05:58:43,379] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0856
[2019-03-24 05:58:43,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.9, 69.0, 1.0, 2.0, 0.396621193369555, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6314338568948134, 6.911199999999999, 6.9112, 121.9260426156618, 904134.6030605014, 904134.6030605017, 223065.9801016634], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5158800.0000, 
sim time next is 5159400.0000, 
raw observation next is [30.7, 69.83333333333333, 1.0, 2.0, 0.3920178693437719, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6241052151259696, 6.911199999999999, 6.9112, 121.9260426156618, 893634.7831630382, 893634.7831630387, 221655.7912558208], 
processed observation next is [0.0, 0.7391304347826086, 0.6925925925925925, 0.6983333333333333, 1.0, 1.0, 0.2762117492187761, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.530131518907462, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3191552797010851, 0.31915527970108526, 0.4262611370304246], 
reward next is 0.5737, 
noisyNet noise sample is [array([1.1459006], dtype=float32), 0.265373]. 
=============================================
[2019-03-24 05:58:44,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5436959e-11 1.3784343e-10 1.0000000e+00 3.0473986e-15 1.0992524e-13], sum to 1.0000
[2019-03-24 05:58:44,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-24 05:58:44,670] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.4963046083253751, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7901330999666568, 6.911199999999999, 6.9112, 121.9260426156618, 1131539.925529328, 1131539.925529328, 255680.5784827885], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5195400.0000, 
sim time next is 5196000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4528107169281732, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7208894083651592, 6.911199999999999, 6.9112, 121.9260426156618, 1032310.081691384, 1032310.081691385, 240955.2942846895], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.3485841868192538, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6511117604564489, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36868217203263715, 0.3686821720326375, 0.4633755659320952], 
reward next is 0.5366, 
noisyNet noise sample is [array([-0.7024672], dtype=float32), 1.0507387]. 
=============================================
[2019-03-24 05:58:44,682] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[54.911842]
 [55.25434 ]
 [55.961147]
 [55.600998]
 [56.78138 ]], R is [[54.72911072]
 [54.69012833]
 [54.67695236]
 [54.65229416]
 [54.61192703]].
[2019-03-24 05:58:48,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1181359e-10 7.4041457e-09 1.0000000e+00 4.2561244e-14 3.2533561e-12], sum to 1.0000
[2019-03-24 05:58:48,700] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3868
[2019-03-24 05:58:48,706] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 90.0, 1.0, 2.0, 0.3525452125814478, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5612634600256666, 6.9112, 6.9112, 121.9260426156618, 803606.6635363535, 803606.6635363535, 209909.95422568], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5263200.0000, 
sim time next is 5263800.0000, 
raw observation next is [26.05, 90.0, 1.0, 2.0, 0.3511209154609651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589959326237395, 6.911199999999999, 6.9112, 121.9260426156618, 800358.3645926407, 800358.3645926411, 209497.8172400304], 
processed observation next is [1.0, 0.9565217391304348, 0.5203703703703704, 0.9, 1.0, 1.0, 0.22752489935829176, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4487449157796743, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2858422730688002, 0.2858422730688004, 0.40288041776928923], 
reward next is 0.5971, 
noisyNet noise sample is [array([-0.2799875], dtype=float32), -0.075397044]. 
=============================================
[2019-03-24 05:58:49,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1720442e-09 1.1545810e-08 1.0000000e+00 5.3587104e-13 1.2532003e-11], sum to 1.0000
[2019-03-24 05:58:49,517] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2412
[2019-03-24 05:58:49,520] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.71666666666667, 89.16666666666667, 1.0, 2.0, 0.336185829691536, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5352187896770224, 6.9112, 6.9112, 121.9260426156618, 766297.7448390721, 766297.7448390721, 205225.5445530677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5269800.0000, 
sim time next is 5270400.0000, 
raw observation next is [25.7, 89.0, 1.0, 2.0, 0.3347562754240094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5329428927257878, 6.911199999999999, 6.9112, 121.9260426156618, 763037.6149873456, 763037.6149873461, 204821.3226953159], 
processed observation next is [1.0, 0.0, 0.5074074074074074, 0.89, 1.0, 1.0, 0.2080431850285826, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41617861590723465, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27251343392405203, 0.2725134339240522, 0.39388715902945365], 
reward next is 0.6061, 
noisyNet noise sample is [array([0.7078914], dtype=float32), -1.2553649]. 
=============================================
[2019-03-24 05:58:50,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1895437e-07 1.6476963e-07 9.9999964e-01 3.1652483e-10 2.2370370e-08], sum to 1.0000
[2019-03-24 05:58:50,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7808
[2019-03-24 05:58:50,565] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.3, 87.0, 1.0, 2.0, 0.4375297645296226, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7004840616648562, 6.911199999999999, 6.9112, 121.9260426156618, 1030005.444207732, 1030005.444207732, 235215.4074893717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5304600.0000, 
sim time next is 5305200.0000, 
raw observation next is [23.46666666666667, 86.33333333333334, 1.0, 2.0, 0.4938434487812154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7900675319385694, 6.911199999999999, 6.9112, 121.9260426156618, 1159975.297945646, 1159975.297945646, 254110.7315354687], 
processed observation next is [1.0, 0.391304347826087, 0.42469135802469143, 0.8633333333333334, 1.0, 1.0, 0.39743267712049457, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7375844149232116, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41427689212344504, 0.41427689212344504, 0.4886744837220552], 
reward next is 0.5113, 
noisyNet noise sample is [array([0.53298956], dtype=float32), 0.49806783]. 
=============================================
[2019-03-24 05:58:54,398] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143563: loss -4.5090
[2019-03-24 05:58:54,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143564: learning rate 0.0000
[2019-03-24 05:58:54,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143583: loss -1.5503
[2019-03-24 05:58:54,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143586: learning rate 0.0000
[2019-03-24 05:58:54,479] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143604: loss -4.3326
[2019-03-24 05:58:54,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143605: learning rate 0.0000
[2019-03-24 05:58:54,707] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143719: loss 1.8364
[2019-03-24 05:58:54,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143719: learning rate 0.0000
[2019-03-24 05:58:54,724] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143723: loss -9.1425
[2019-03-24 05:58:54,727] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143725: learning rate 0.0000
[2019-03-24 05:58:54,829] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143780: loss -10.9339
[2019-03-24 05:58:54,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143780: learning rate 0.0000
[2019-03-24 05:58:54,857] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143791: loss -1.9120
[2019-03-24 05:58:54,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143791: learning rate 0.0000
[2019-03-24 05:58:55,141] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143932: loss -4.0148
[2019-03-24 05:58:55,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143932: learning rate 0.0000
[2019-03-24 05:58:55,317] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144018: loss -3.3724
[2019-03-24 05:58:55,320] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144018: learning rate 0.0000
[2019-03-24 05:58:55,491] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144103: loss -7.9154
[2019-03-24 05:58:55,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144103: learning rate 0.0000
[2019-03-24 05:58:55,540] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144127: loss -2.2740
[2019-03-24 05:58:55,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144127: learning rate 0.0000
[2019-03-24 05:58:55,717] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144216: loss -1.3886
[2019-03-24 05:58:55,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144217: learning rate 0.0000
[2019-03-24 05:58:55,744] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144226: loss -8.8538
[2019-03-24 05:58:55,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144227: learning rate 0.0000
[2019-03-24 05:58:55,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.58439387e-10 3.38032224e-09 1.00000000e+00 3.98907470e-13
 1.42687945e-11], sum to 1.0000
[2019-03-24 05:58:55,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9544
[2019-03-24 05:58:55,814] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.26666666666667, 77.5, 1.0, 2.0, 0.3767212428160145, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5997524875174334, 6.9112, 6.9112, 121.9260426156618, 858745.41481327, 858745.41481327, 217031.0602058497], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5424600.0000, 
sim time next is 5425200.0000, 
raw observation next is [29.2, 78.0, 1.0, 2.0, 0.3803040096668656, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6054563690265585, 6.9112, 6.9112, 121.9260426156618, 866917.039670989, 866917.039670989, 218105.8146527194], 
processed observation next is [1.0, 0.8260869565217391, 0.637037037037037, 0.78, 1.0, 1.0, 0.26226667817484, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5068204612831981, 0.0, 0.0, 0.8094621288201359, 0.30961322845392464, 0.30961322845392464, 0.4194342589475373], 
reward next is 0.5806, 
noisyNet noise sample is [array([-0.7782405], dtype=float32), -0.12112682]. 
=============================================
[2019-03-24 05:58:55,984] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144344: loss -1.7773
[2019-03-24 05:58:55,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144344: learning rate 0.0000
[2019-03-24 05:58:56,104] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144401: loss 1.3467
[2019-03-24 05:58:56,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144402: learning rate 0.0000
[2019-03-24 05:58:56,461] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144582: loss -2.0155
[2019-03-24 05:58:56,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144582: learning rate 0.0000
[2019-03-24 05:58:56,541] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6033315e-08 9.9197209e-08 9.9999988e-01 2.3093399e-11 1.5246297e-10], sum to 1.0000
[2019-03-24 05:58:56,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6151
[2019-03-24 05:58:56,560] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.6, 75.0, 1.0, 2.0, 0.3614208147684624, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5753937077655771, 6.9112, 6.9112, 121.9260426156618, 823848.9645240116, 823848.9645240116, 212499.2123586477], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5421600.0000, 
sim time next is 5422200.0000, 
raw observation next is [29.53333333333333, 75.5, 1.0, 2.0, 0.3698856858685513, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588870058238524, 6.911199999999999, 6.9112, 121.9260426156618, 843155.0223874085, 843155.022387409, 214994.7273267504], 
processed observation next is [1.0, 0.782608695652174, 0.6493827160493827, 0.755, 1.0, 1.0, 0.24986391174827538, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48608757279815495, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3011267937097888, 0.30112679370978895, 0.41345139870528924], 
reward next is 0.5865, 
noisyNet noise sample is [array([-0.09955972], dtype=float32), -0.5498264]. 
=============================================
[2019-03-24 05:58:58,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2800613e-09 1.0613036e-07 9.9999988e-01 2.2706117e-11 7.8429768e-10], sum to 1.0000
[2019-03-24 05:58:58,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6260
[2019-03-24 05:58:58,404] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.56666666666667, 92.33333333333334, 1.0, 2.0, 0.3701640692918462, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5893132537147245, 6.911199999999999, 6.9112, 121.9260426156618, 843789.9471642909, 843789.9471642914, 215076.0738576259], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5448000.0000, 
sim time next is 5448600.0000, 
raw observation next is [26.5, 92.5, 1.0, 2.0, 0.3687997659703715, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5871412383946797, 6.9112, 6.9112, 121.9260426156618, 840678.3086473903, 840678.3086473903, 214671.6411579181], 
processed observation next is [1.0, 0.043478260869565216, 0.5370370370370371, 0.925, 1.0, 1.0, 0.24857114996472798, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48392654799334955, 0.0, 0.0, 0.8094621288201359, 0.30024225308835367, 0.30024225308835367, 0.4128300791498425], 
reward next is 0.5872, 
noisyNet noise sample is [array([0.64794856], dtype=float32), -0.11104103]. 
=============================================
[2019-03-24 05:58:59,119] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5659624e-07 1.2628702e-07 9.9999976e-01 1.8357459e-10 5.6700720e-09], sum to 1.0000
[2019-03-24 05:58:59,125] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-24 05:58:59,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2539196.496226802 W.
[2019-03-24 05:58:59,137] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.91666666666667, 76.16666666666666, 1.0, 2.0, 0.8569959549872699, 1.0, 2.0, 0.7418626394700697, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2539196.496226802, 2539196.496226802, 474091.8583621589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5485800.0000, 
sim time next is 5486400.0000, 
raw observation next is [31.1, 75.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.207824681656131, 6.9112, 121.924550439713, 2479276.397905808, 2327379.907872772, 443050.2424166395], 
processed observation next is [1.0, 0.5217391304347826, 0.7074074074074075, 0.75, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.02966246816561311, 0.0, 0.8094522223235895, 0.8854558563949314, 0.8312071099545614, 0.852019696955076], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.096836], dtype=float32), -0.16781417]. 
=============================================
[2019-03-24 05:59:00,217] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2374336e-07 5.0860944e-08 9.9999988e-01 3.2282074e-10 1.1027321e-09], sum to 1.0000
[2019-03-24 05:59:00,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5585
[2019-03-24 05:59:00,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2221607.693027799 W.
[2019-03-24 05:59:00,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 86.0, 1.0, 2.0, 0.6716503182404929, 1.0, 2.0, 0.6491898210966811, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2221607.693027799, 2221607.693027799, 421708.9101293333], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5478000.0000, 
sim time next is 5478600.0000, 
raw observation next is [28.96666666666667, 85.5, 1.0, 2.0, 0.6658056353388678, 1.0, 2.0, 0.6462674796458687, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2211594.695749858, 2211594.695749858, 420177.8591212179], 
processed observation next is [1.0, 0.391304347826087, 0.6283950617283951, 0.855, 1.0, 1.0, 0.6021495658796046, 1.0, 1.0, 0.5788898567212722, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7898552484820921, 0.7898552484820921, 0.8080343444638806], 
reward next is 0.1920, 
noisyNet noise sample is [array([-1.2445065], dtype=float32), -0.46791333]. 
=============================================
[2019-03-24 05:59:02,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1334779e-08 1.5128134e-06 9.9999845e-01 5.9400630e-11 1.7310054e-08], sum to 1.0000
[2019-03-24 05:59:02,159] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-24 05:59:02,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2017117.459717996 W.
[2019-03-24 05:59:02,176] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 77.0, 1.0, 2.0, 0.5895018633042084, 1.0, 2.0, 0.5895018633042084, 1.0, 2.0, 0.9385061651156541, 6.911199999999999, 6.9112, 121.94756008, 2017117.459717996, 2017117.459717997, 389685.3423693965], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5502000.0000, 
sim time next is 5502600.0000, 
raw observation next is [28.05, 78.0, 1.0, 2.0, 0.5633004792888839, 1.0, 2.0, 0.5633004792888839, 1.0, 2.0, 0.8967927084437536, 6.911199999999999, 6.9112, 121.94756008, 1927366.615035204, 1927366.615035204, 375742.6959906948], 
processed observation next is [1.0, 0.6956521739130435, 0.5944444444444444, 0.78, 1.0, 1.0, 0.4801196182010523, 1.0, 1.0, 0.4801196182010523, 1.0, 1.0, 0.8709908855546918, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6883452196554299, 0.6883452196554299, 0.7225821076744131], 
reward next is 0.2774, 
noisyNet noise sample is [array([-0.03249402], dtype=float32), 0.02677043]. 
=============================================
[2019-03-24 05:59:02,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5270943e-08 2.9577077e-07 9.9999976e-01 1.6231013e-11 8.8327958e-09], sum to 1.0000
[2019-03-24 05:59:02,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4199
[2019-03-24 05:59:02,239] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.85, 90.5, 1.0, 2.0, 0.3433248460785621, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5465843362666998, 6.911199999999999, 6.9112, 121.9260426156618, 782578.635768153, 782578.6357681534, 207256.7867665519], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5527800.0000, 
sim time next is 5528400.0000, 
raw observation next is [25.83333333333334, 90.66666666666667, 1.0, 2.0, 0.3435968736913721, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5470174130856141, 6.911199999999999, 6.9112, 121.9260426156618, 783199.015451003, 783199.0154510034, 207334.5766560704], 
processed observation next is [1.0, 1.0, 0.5123456790123458, 0.9066666666666667, 1.0, 1.0, 0.218567706775443, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43377176635701764, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2797139340896439, 0.27971393408964407, 0.3987203397232123], 
reward next is 0.6013, 
noisyNet noise sample is [array([0.98790455], dtype=float32), 0.09548102]. 
=============================================
[2019-03-24 05:59:06,882] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0107577e-08 1.6689263e-07 9.9999988e-01 3.9584824e-10 4.2646757e-09], sum to 1.0000
[2019-03-24 05:59:06,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1552
[2019-03-24 05:59:06,895] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.28333333333333, 96.33333333333333, 1.0, 2.0, 0.3227668079140173, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5138552699801836, 6.911199999999999, 6.9112, 121.9260426156618, 735695.9172341208, 735695.9172341212, 201463.1402651975], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5609400.0000, 
sim time next is 5610000.0000, 
raw observation next is [24.16666666666667, 96.66666666666666, 1.0, 2.0, 0.3203699722524447, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5100394295474722, 6.9112, 6.9112, 121.9260426156618, 730230.1070320953, 730230.1070320953, 200798.7532254894], 
processed observation next is [1.0, 0.9565217391304348, 0.45061728395061745, 0.9666666666666666, 1.0, 1.0, 0.19091663363386271, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38754928693434015, 0.0, 0.0, 0.8094621288201359, 0.2607964667971769, 0.2607964667971769, 0.38615144851055655], 
reward next is 0.6138, 
noisyNet noise sample is [array([-1.2007867], dtype=float32), -0.0781646]. 
=============================================
[2019-03-24 05:59:06,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[46.430424]
 [46.342785]
 [46.238766]
 [46.21046 ]
 [46.15834 ]], R is [[46.66659927]
 [46.81250381]
 [46.95568085]
 [47.09628296]
 [47.23460388]].
[2019-03-24 05:59:07,354] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 05:59:07,355] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:59:07,356] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:59:07,357] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:59:07,358] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:59:07,360] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:59:07,361] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:59:07,361] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:59:07,362] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:59:07,364] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:59:07,364] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:59:07,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-24 05:59:07,378] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-24 05:59:07,402] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-24 05:59:07,460] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-24 05:59:07,485] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-24 05:59:11,846] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 05:59:11,847] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.58333333333333, 52.83333333333334, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2212241828812512, 6.911199999999999, 6.9112, 121.9260426156618, 315903.9547290356, 315903.9547290361, 125317.3483571121]
[2019-03-24 05:59:11,849] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:59:11,851] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1175239e-09 3.4973127e-08 1.0000000e+00 7.2022362e-12 9.1394781e-10], sampled 0.2932058028564791
[2019-03-24 06:00:04,331] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:04,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 94.0, 1.0, 2.0, 0.5450820753505857, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8677884160419892, 6.911200000000001, 6.9112, 121.9260426156618, 1242839.359632788, 1242839.359632788, 273105.5921639157]
[2019-03-24 06:00:04,336] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:00:04,340] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0777495e-07 7.3257900e-07 9.9999905e-01 7.6948398e-10 3.8963101e-08], sampled 0.27330167497863556
[2019-03-24 06:00:29,895] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:29,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.76666666666667, 88.83333333333334, 1.0, 2.0, 0.2909150201545938, 0.0, 2.0, 0.0, 1.0, 2.0, 0.467405388046471, 6.911199999999999, 6.9112, 121.9260426156618, 691157.7559666148, 691157.7559666153, 191898.5668776332]
[2019-03-24 06:00:29,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:00:29,900] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5013146e-08 6.8596272e-08 9.9999988e-01 1.9893255e-11 2.0369149e-09], sampled 0.6835728906278937
[2019-03-24 06:00:31,884] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:31,885] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333333, 61.0, 1.0, 2.0, 0.8778399284812882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.925941910975, 1715788.835204302, 1715788.835204302, 352224.315886955]
[2019-03-24 06:00:31,886] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:00:31,888] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0439171e-06 3.2824403e-06 9.9999535e-01 7.1803088e-09 2.3245606e-07], sampled 0.7946956094241641
[2019-03-24 06:00:32,144] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:32,145] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.54784703666667, 52.14889498333334, 1.0, 2.0, 0.2870770620803645, 0.0, 2.0, 0.0, 1.0, 2.0, 0.466796017337794, 6.911199999999999, 6.9112, 121.9260426156618, 696433.8685908366, 696433.8685908371, 189958.222348588]
[2019-03-24 06:00:32,146] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:00:32,150] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2294132e-08 5.7573569e-08 1.0000000e+00 1.5451392e-11 1.6561709e-09], sampled 0.7243453769594869
[2019-03-24 06:00:35,039] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:35,040] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.95701982333333, 80.41265714666666, 1.0, 2.0, 0.3303206250715435, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5258811929056153, 6.9112, 6.9112, 121.9260426156618, 752922.1053593726, 752922.1053593726, 203572.6909955134]
[2019-03-24 06:00:35,041] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:00:35,043] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7578771e-09 4.1624560e-08 1.0000000e+00 9.4125870e-12 1.1111098e-09], sampled 0.01660045936705823
[2019-03-24 06:00:41,446] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00634628], dtype=float32), 0.0046486715]
[2019-03-24 06:00:41,447] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.68704777333333, 44.01637272000001, 1.0, 2.0, 0.2767102845731366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.441913209701537, 6.911199999999999, 6.9112, 121.9260426156618, 645489.980263158, 645489.9802631584, 188725.4756213656]
[2019-03-24 06:00:41,448] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:00:41,449] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7442651e-09 3.3008099e-08 1.0000000e+00 6.6789812e-12 8.4881624e-10], sampled 0.35752951311819137
[2019-03-24 06:00:51,904] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6810.3365 2600717670.7672 61.0000
[2019-03-24 06:00:52,053] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7158.0741 2831250566.6803 210.0000
[2019-03-24 06:00:52,225] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7492.4646 2566004360.6099 47.0000
[2019-03-24 06:00:52,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.7684 2623880762.9586 97.0000
[2019-03-24 06:00:52,581] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7566 2661641541.6047 110.0000
[2019-03-24 06:00:53,598] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 150000, evaluation results [150000.0, 7158.074124500664, 2831250566.680278, 210.0, 6810.336502542156, 2600717670.767205, 61.0, 7492.464605249343, 2566004360.6098795, 47.0, 6580.756643715333, 2661641541.6046743, 110.0, 7162.768394127867, 2623880762.9585886, 97.0]
[2019-03-24 06:00:56,607] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151579: loss 0.4747
[2019-03-24 06:00:56,610] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151579: learning rate 0.0000
[2019-03-24 06:00:56,670] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151615: loss 0.4947
[2019-03-24 06:00:56,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151615: learning rate 0.0000
[2019-03-24 06:00:56,737] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151646: loss 0.4978
[2019-03-24 06:00:56,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151647: learning rate 0.0000
[2019-03-24 06:00:56,796] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151680: loss 0.5372
[2019-03-24 06:00:56,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151680: learning rate 0.0000
[2019-03-24 06:00:56,844] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151708: loss 0.6777
[2019-03-24 06:00:56,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151708: learning rate 0.0000
[2019-03-24 06:00:57,004] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151791: loss 0.6195
[2019-03-24 06:00:57,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151792: learning rate 0.0000
[2019-03-24 06:00:57,018] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151799: loss 0.5259
[2019-03-24 06:00:57,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151800: learning rate 0.0000
[2019-03-24 06:00:57,366] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151981: loss 0.7310
[2019-03-24 06:00:57,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151982: learning rate 0.0000
[2019-03-24 06:00:57,377] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151986: loss 0.6383
[2019-03-24 06:00:57,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151986: learning rate 0.0000
[2019-03-24 06:00:57,598] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152098: loss 0.5122
[2019-03-24 06:00:57,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152098: learning rate 0.0000
[2019-03-24 06:00:57,779] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152199: loss 0.3309
[2019-03-24 06:00:57,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152199: learning rate 0.0000
[2019-03-24 06:00:57,786] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152201: loss 0.4042
[2019-03-24 06:00:57,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152202: learning rate 0.0000
[2019-03-24 06:00:57,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152235: loss 0.5262
[2019-03-24 06:00:57,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152235: learning rate 0.0000
[2019-03-24 06:00:57,974] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152297: loss 0.3882
[2019-03-24 06:00:57,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152297: learning rate 0.0000
[2019-03-24 06:00:58,130] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152377: loss 0.1983
[2019-03-24 06:00:58,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152377: learning rate 0.0000
[2019-03-24 06:00:58,636] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152636: loss 0.3253
[2019-03-24 06:00:58,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152636: learning rate 0.0000
[2019-03-24 06:01:11,590] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159447: loss 4.6468
[2019-03-24 06:01:11,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159447: learning rate 0.0000
[2019-03-24 06:01:11,728] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159517: loss 4.2479
[2019-03-24 06:01:11,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159517: learning rate 0.0000
[2019-03-24 06:01:11,958] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159636: loss 3.6950
[2019-03-24 06:01:11,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159637: learning rate 0.0000
[2019-03-24 06:01:12,002] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159659: loss 3.6050
[2019-03-24 06:01:12,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159660: learning rate 0.0000
[2019-03-24 06:01:12,121] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159718: loss 3.8804
[2019-03-24 06:01:12,123] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159718: learning rate 0.0000
[2019-03-24 06:01:12,180] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159754: loss 3.9307
[2019-03-24 06:01:12,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159754: learning rate 0.0000
[2019-03-24 06:01:12,319] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159823: loss 3.1118
[2019-03-24 06:01:12,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159824: learning rate 0.0000
[2019-03-24 06:01:12,656] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160000: loss 3.6437
[2019-03-24 06:01:12,657] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160000: learning rate 0.0000
[2019-03-24 06:01:12,719] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160026: loss 3.1127
[2019-03-24 06:01:12,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160027: learning rate 0.0000
[2019-03-24 06:01:12,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160088: loss 3.3424
[2019-03-24 06:01:12,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160088: learning rate 0.0000
[2019-03-24 06:01:13,043] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2194860e-06 7.0339962e-07 9.9999678e-01 1.1333758e-08 1.3337631e-06], sum to 1.0000
[2019-03-24 06:01:13,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1928
[2019-03-24 06:01:13,054] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 58.5, 1.0, 2.0, 0.8377642268549603, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9930191816759371, 6.911199999999999, 6.9112, 121.9260426156618, 1674921.456228021, 1674921.456228022, 343116.8307286978], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6013800.0000, 
sim time next is 6014400.0000, 
raw observation next is [29.0, 58.33333333333333, 1.0, 2.0, 0.7611918105831622, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9920167058691933, 6.911199999999999, 6.9112, 121.9260426156618, 1588042.32350168, 1588042.323501681, 327707.3108474912], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.5833333333333333, 1.0, 1.0, 0.7157045364085264, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9900208823364917, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5671579726791715, 0.5671579726791718, 0.6302063670144061], 
reward next is 0.3698, 
noisyNet noise sample is [array([3.0707474], dtype=float32), -0.4341048]. 
=============================================
[2019-03-24 06:01:13,104] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160227: loss 3.2272
[2019-03-24 06:01:13,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160228: learning rate 0.0000
[2019-03-24 06:01:13,130] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160246: loss 2.8080
[2019-03-24 06:01:13,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160246: learning rate 0.0000
[2019-03-24 06:01:13,159] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160256: loss 3.1563
[2019-03-24 06:01:13,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160258: learning rate 0.0000
[2019-03-24 06:01:13,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160361: loss 3.3937
[2019-03-24 06:01:13,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160362: learning rate 0.0000
[2019-03-24 06:01:13,367] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160363: loss 3.3306
[2019-03-24 06:01:13,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160363: learning rate 0.0000
[2019-03-24 06:01:13,855] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160622: loss 3.1884
[2019-03-24 06:01:13,856] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160622: learning rate 0.0000
[2019-03-24 06:01:23,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1520190e-08 2.7164731e-07 9.9999976e-01 1.9268960e-11 2.2034413e-10], sum to 1.0000
[2019-03-24 06:01:23,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6696
[2019-03-24 06:01:23,550] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.26666666666667, 76.66666666666667, 1.0, 2.0, 0.2474266504596132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3982907526857721, 6.911199999999999, 6.9112, 121.9260426156618, 590249.093202896, 590249.0932028964, 180663.6473957574], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6225600.0000, 
sim time next is 6226200.0000, 
raw observation next is [24.2, 77.0, 1.0, 2.0, 0.2465146298916079, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3968793462837923, 6.9112, 6.9112, 121.9260426156618, 588245.7135229128, 588245.7135229128, 180428.3949643195], 
processed observation next is [0.0, 0.043478260869565216, 0.45185185185185184, 0.77, 1.0, 1.0, 0.10299360701381895, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24609918285474033, 0.0, 0.0, 0.8094621288201359, 0.21008775482961173, 0.21008775482961173, 0.3469776826236914], 
reward next is 0.6530, 
noisyNet noise sample is [array([0.53072464], dtype=float32), -2.308673]. 
=============================================
[2019-03-24 06:01:26,317] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9384186e-09 3.2235026e-09 1.0000000e+00 8.5987603e-13 5.6950861e-10], sum to 1.0000
[2019-03-24 06:01:26,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-24 06:01:26,333] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.6, 63.33333333333334, 1.0, 2.0, 0.3249457618378271, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5173242355904639, 6.9112, 6.9112, 121.9260426156618, 740664.8977279244, 740664.8977279244, 202069.4748904861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6273600.0000, 
sim time next is 6274200.0000, 
raw observation next is [29.65, 63.16666666666666, 1.0, 2.0, 0.3253176892298653, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5179163561114183, 6.911199999999999, 6.9112, 121.9260426156618, 741513.0602101295, 741513.06021013, 202173.1151153756], 
processed observation next is [0.0, 0.6086956521739131, 0.6537037037037037, 0.6316666666666666, 1.0, 1.0, 0.1968067728926968, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39739544513927283, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2648260929321891, 0.2648260929321893, 0.3887944521449531], 
reward next is 0.6112, 
noisyNet noise sample is [array([-0.30937886], dtype=float32), 0.60327494]. 
=============================================
[2019-03-24 06:01:26,722] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167347: loss 0.0339
[2019-03-24 06:01:26,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167348: learning rate 0.0000
[2019-03-24 06:01:27,083] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167531: loss 0.0262
[2019-03-24 06:01:27,084] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167532: learning rate 0.0000
[2019-03-24 06:01:27,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5199668e-10 2.7938861e-11 1.0000000e+00 1.4206348e-13 7.6834728e-12], sum to 1.0000
[2019-03-24 06:01:27,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4891
[2019-03-24 06:01:27,168] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 62.0, 1.0, 2.0, 0.3282032846409597, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5225103179831622, 6.9112, 6.9112, 121.9260426156618, 748093.5532803336, 748093.5532803336, 202979.0415348883], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [30.05, 61.66666666666667, 1.0, 2.0, 0.326032087861063, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5190537019986241, 6.9112, 6.9112, 121.9260426156618, 743142.2144709254, 743142.2144709254, 202372.5150692438], 
processed observation next is [0.0, 0.6956521739130435, 0.6685185185185185, 0.6166666666666667, 1.0, 1.0, 0.19765724745364646, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3988171274982801, 0.0, 0.0, 0.8094621288201359, 0.2654079337396162, 0.2654079337396162, 0.3891779135946996], 
reward next is 0.6108, 
noisyNet noise sample is [array([-0.17026186], dtype=float32), -0.3514644]. 
=============================================
[2019-03-24 06:01:27,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.52703]
 [64.47611]
 [64.51693]
 [64.51285]
 [64.49103]], R is [[64.51972961]
 [64.48419189]
 [64.44950104]
 [64.41557312]
 [64.38230133]].
[2019-03-24 06:01:27,383] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167677: loss 0.0070
[2019-03-24 06:01:27,387] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167677: learning rate 0.0000
[2019-03-24 06:01:27,396] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167682: loss 0.0028
[2019-03-24 06:01:27,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167683: learning rate 0.0000
[2019-03-24 06:01:27,499] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167731: loss 0.0008
[2019-03-24 06:01:27,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167733: learning rate 0.0000
[2019-03-24 06:01:27,617] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167792: loss 0.0030
[2019-03-24 06:01:27,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167792: learning rate 0.0000
[2019-03-24 06:01:27,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167801: loss 0.0055
[2019-03-24 06:01:27,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167801: learning rate 0.0000
[2019-03-24 06:01:27,947] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167957: loss 0.0006
[2019-03-24 06:01:27,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167957: learning rate 0.0000
[2019-03-24 06:01:28,075] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168023: loss 0.0007
[2019-03-24 06:01:28,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168023: learning rate 0.0000
[2019-03-24 06:01:28,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168133: loss 0.0188
[2019-03-24 06:01:28,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168134: learning rate 0.0000
[2019-03-24 06:01:28,453] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168207: loss 0.0058
[2019-03-24 06:01:28,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168210: learning rate 0.0000
[2019-03-24 06:01:28,512] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168236: loss 0.0023
[2019-03-24 06:01:28,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168239: learning rate 0.0000
[2019-03-24 06:01:28,712] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168336: loss 0.0070
[2019-03-24 06:01:28,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168337: learning rate 0.0000
[2019-03-24 06:01:28,720] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168339: loss 0.0012
[2019-03-24 06:01:28,726] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168340: learning rate 0.0000
[2019-03-24 06:01:29,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168500: loss 0.0045
[2019-03-24 06:01:29,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168500: learning rate 0.0000
[2019-03-24 06:01:29,143] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168549: loss 0.0144
[2019-03-24 06:01:29,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168550: learning rate 0.0000
[2019-03-24 06:01:34,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.08483125e-08 2.62579896e-08 1.00000000e+00 2.29439384e-12
 1.25686100e-10], sum to 1.0000
[2019-03-24 06:01:34,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-24 06:01:34,663] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2249805.486273007 W.
[2019-03-24 06:01:34,666] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.25, 54.0, 1.0, 2.0, 0.6881092894513651, 1.0, 2.0, 0.6574193067021171, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2249805.486273007, 2249805.486273007, 426060.1213183627], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [32.2, 54.0, 1.0, 2.0, 0.9401230813620174, 1.0, 2.0, 0.9401230813620174, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2144719.712320993, 2144719.712320994, 405057.3974349311], 
processed observation next is [1.0, 0.6086956521739131, 0.7481481481481482, 0.54, 1.0, 1.0, 0.9287179540024016, 1.0, 1.0, 0.9287179540024016, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7659713258289261, 0.7659713258289265, 0.7789565335287136], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13727649], dtype=float32), 0.9521871]. 
=============================================
[2019-03-24 06:01:37,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.06343236e-07 2.58771161e-06 9.99997139e-01 2.60994160e-09
 7.47801536e-08], sum to 1.0000
[2019-03-24 06:01:37,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4936
[2019-03-24 06:01:37,937] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.4519187154000786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.719469312881971, 6.9112, 6.9112, 121.9260426156618, 1030275.144814337, 1030275.144814337, 240665.6523078063], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6508800.0000, 
sim time next is 6509400.0000, 
raw observation next is [26.43333333333333, 88.33333333333334, 1.0, 2.0, 0.5363989761996477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.853964639404899, 6.911199999999999, 6.9112, 121.9260426156618, 1223025.257169456, 1223025.257169456, 269933.5484673487], 
processed observation next is [1.0, 0.34782608695652173, 0.5345679012345678, 0.8833333333333334, 1.0, 1.0, 0.44809401928529485, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8174557992561238, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43679473470337715, 0.43679473470337715, 0.5191029778218244], 
reward next is 0.4809, 
noisyNet noise sample is [array([-0.0011193], dtype=float32), -0.36320218]. 
=============================================
[2019-03-24 06:01:40,200] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7134514e-06 8.0617992e-06 9.9998736e-01 1.1550775e-08 8.5357340e-07], sum to 1.0000
[2019-03-24 06:01:40,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1444
[2019-03-24 06:01:40,212] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.86666666666667, 87.5, 1.0, 2.0, 0.3576712469837454, 0.0, 2.0, 0.0, 1.0, 2.0, 0.56942427373741, 6.911199999999999, 6.9112, 121.9260426156618, 815297.3804265403, 815297.3804265407, 211400.6962951944], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6551400.0000, 
sim time next is 6552000.0000, 
raw observation next is [26.8, 88.0, 1.0, 2.0, 0.3593292339492426, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5720638429833473, 6.911199999999999, 6.9112, 121.9260426156618, 819078.7151458251, 819078.7151458255, 211884.7285644137], 
processed observation next is [1.0, 0.8695652173913043, 0.5481481481481482, 0.88, 1.0, 1.0, 0.23729670708243167, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4650798037291841, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2925281125520804, 0.29252811255208055, 0.4074706318546417], 
reward next is 0.5925, 
noisyNet noise sample is [array([0.12994397], dtype=float32), 0.24076505]. 
=============================================
[2019-03-24 06:01:40,226] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[51.002346]
 [52.4105  ]
 [51.638157]
 [51.330257]
 [51.23209 ]], R is [[50.95687103]
 [51.04076385]
 [51.1244812 ]
 [51.20738602]
 [51.28952789]].
[2019-03-24 06:01:42,138] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 06:01:42,142] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:01:42,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:42,145] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:01:42,146] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:42,149] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:01:42,151] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:01:42,152] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:42,152] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:01:42,152] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:42,155] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:42,164] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-24 06:01:42,165] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-24 06:01:42,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-24 06:01:42,166] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-24 06:01:42,213] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-24 06:01:54,650] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:01:54,653] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.8, 19.0, 1.0, 2.0, 0.163964717348544, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2962216659063828, 6.9112, 6.9112, 121.9260426156618, 423028.4808387364, 423028.4808387364, 146692.4287701538]
[2019-03-24 06:01:54,654] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:01:54,657] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2835768e-08 7.0871685e-08 9.9999988e-01 2.3953136e-11 6.0096381e-09], sampled 0.5987290758832697
[2019-03-24 06:02:13,202] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:13,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.87842008, 109.9432997, 1.0, 2.0, 0.3975542838791784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6352015117968242, 6.911199999999999, 6.9112, 121.9260426156618, 929332.775232291, 929332.7752322914, 222847.5981367268]
[2019-03-24 06:02:13,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:02:13,214] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.9741874e-08 3.9531753e-07 9.9999952e-01 3.4446171e-10 4.3539764e-08], sampled 0.847660695156838
[2019-03-24 06:02:22,016] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:22,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 87.0, 1.0, 2.0, 0.4416477978160431, 0.0, 2.0, 0.0, 1.0, 2.0, 0.708421710404127, 6.911199999999999, 6.9112, 121.9260426156618, 1045301.166530158, 1045301.166530159, 236348.4316514492]
[2019-03-24 06:02:22,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:02:22,022] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5795096e-07 6.6829165e-07 9.9999905e-01 7.3187395e-10 8.0296736e-08], sampled 0.12603660609668954
[2019-03-24 06:02:26,820] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:26,822] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333334, 75.66666666666666, 1.0, 2.0, 0.3013583825264763, 0.0, 2.0, 0.0, 1.0, 2.0, 0.480059256826532, 6.911200000000001, 6.9112, 121.9260426156618, 692522.6660965651, 692522.6660965646, 195508.8936504829]
[2019-03-24 06:02:26,823] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:02:26,825] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.5959241e-09 5.3094624e-08 1.0000000e+00 1.6038920e-11 4.2633830e-09], sampled 0.37966080573399164
[2019-03-24 06:02:28,303] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:28,305] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.33699389, 63.52867314, 1.0, 2.0, 0.3629936207454328, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5778976661036286, 6.911199999999999, 6.9112, 121.9260426156618, 827436.0683877681, 827436.0683877686, 212959.6296186984]
[2019-03-24 06:02:28,306] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:02:28,311] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.98258601e-08 1.00651576e-07 9.99999881e-01 4.35215336e-11
 9.03134989e-09], sampled 0.4321105962244334
[2019-03-24 06:02:30,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:30,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.90000000000001, 55.0, 1.0, 2.0, 0.9347979478098125, 1.0, 1.0, 0.9347979478098125, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9255224764902, 2132556.892726143, 2132556.892726144, 402603.9190281041]
[2019-03-24 06:02:30,600] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:02:30,602] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.5688858e-08 2.5666395e-07 9.9999976e-01 1.8134523e-10 2.9649726e-08], sampled 0.4705364168260845
[2019-03-24 06:02:30,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2132556.892726143 W.
[2019-03-24 06:02:38,586] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:38,586] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.90983650333333, 75.64464140666666, 1.0, 2.0, 0.2807766252001347, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4484968372878048, 6.9112, 6.9112, 121.9260426156618, 655525.7263128256, 655525.7263128256, 189761.7399408122]
[2019-03-24 06:02:38,588] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:02:38,593] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1224251e-08 5.8945407e-08 1.0000000e+00 1.9913151e-11 4.9880420e-09], sampled 0.7380909741909271
[2019-03-24 06:02:53,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:53,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.96317487333333, 108.4302256, 1.0, 2.0, 0.3320165513447925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290255782178876, 6.911199999999999, 6.9112, 121.9260426156618, 764642.8382897101, 764642.8382897106, 203905.6767069992]
[2019-03-24 06:02:53,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:02:53,916] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6164769e-08 8.3085915e-08 9.9999988e-01 3.3324402e-11 7.4560136e-09], sampled 0.782681948703112
[2019-03-24 06:02:57,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:02:57,645] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.15317750666667, 79.30040475166666, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.514935643986217, 6.9112, 121.9239631053306, 2187563.016919139, 1878401.678911595, 381974.7462760602]
[2019-03-24 06:02:57,646] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:02:57,650] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.18035686e-07 5.05462026e-07 9.99999285e-01 5.04487951e-10
 6.18778699e-08], sampled 0.5567614532750826
[2019-03-24 06:02:57,652] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2187563.016919139 W.
[2019-03-24 06:03:08,892] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:03:08,894] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.1, 66.0, 1.0, 2.0, 0.3012183035624207, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4797562299309799, 6.911199999999999, 6.9112, 121.9260426156618, 691027.4235407024, 691027.4235407029, 195495.5257511216]
[2019-03-24 06:03:08,894] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:03:08,898] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0569881e-08 5.7574336e-08 1.0000000e+00 1.8352762e-11 4.7053472e-09], sampled 0.5188657616139236
[2019-03-24 06:03:10,055] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:03:10,057] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.06750882, 92.60360394, 1.0, 2.0, 0.9066180690466233, 1.0, 2.0, 0.9066180690466233, 0.0, 1.0, 0.0, 6.9112, 6.9112, 123.6862724906213, 2068161.519474956, 2068161.519474956, 390047.6978219085]
[2019-03-24 06:03:10,057] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:03:10,061] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7676386e-07 1.5316336e-06 9.9999785e-01 2.4282383e-09 2.1223509e-07], sampled 0.9881234388064746
[2019-03-24 06:03:10,062] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2068161.519474956 W.
[2019-03-24 06:03:15,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:03:15,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.827313255, 60.227181335, 1.0, 2.0, 0.2870974437330228, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4576398967666547, 6.911199999999999, 6.9112, 121.9260426156618, 663157.8716879498, 663157.8716879502, 191633.5988218085]
[2019-03-24 06:03:15,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:03:15,877] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0783927e-08 5.8924275e-08 1.0000000e+00 1.8869292e-11 4.8602606e-09], sampled 0.7249273702404441
[2019-03-24 06:03:20,949] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:03:20,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.242487625, 79.664048065, 1.0, 2.0, 0.182500025331012, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3068937773624644, 6.911199999999999, 6.9112, 121.9260426156618, 456727.7976443874, 456727.7976443879, 162840.9067063133]
[2019-03-24 06:03:20,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:03:20,954] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1993977e-08 6.3777613e-08 9.9999988e-01 2.1475304e-11 5.3244071e-09], sampled 0.7456376491002927
[2019-03-24 06:03:25,819] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00672077], dtype=float32), 0.0048807287]
[2019-03-24 06:03:25,820] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.72962713666667, 71.7415091, 1.0, 2.0, 0.1653704540033636, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2826725705286114, 6.911199999999999, 6.9112, 121.9260426156618, 417829.1663469014, 417829.1663469019, 158297.2528577187]
[2019-03-24 06:03:25,820] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:03:25,823] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1174314e-08 1.0837459e-07 9.9999988e-01 4.6398465e-11 9.7477617e-09], sampled 0.06220222467034919
[2019-03-24 06:03:27,125] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600807839.8901 61.0000
[2019-03-24 06:03:27,372] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661719036.3567 110.0000
[2019-03-24 06:03:27,443] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.0788 2623884868.9789 97.0000
[2019-03-24 06:03:27,487] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.1924 2565942907.5071 47.0000
[2019-03-24 06:03:27,605] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.1837 2831389104.9882 210.0000
[2019-03-24 06:03:28,619] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 175000, evaluation results [175000.0, 7157.1836559949525, 2831389104.9881516, 210.0, 6809.511993196244, 2600807839.890115, 61.0, 7491.192354905317, 2565942907.5071335, 47.0, 6579.928819146758, 2661719036.3567276, 110.0, 7162.078812812093, 2623884868.9788747, 97.0]
[2019-03-24 06:03:29,162] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175273: loss 3.4311
[2019-03-24 06:03:29,164] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175276: learning rate 0.0000
[2019-03-24 06:03:29,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175598: loss 3.4707
[2019-03-24 06:03:29,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175598: learning rate 0.0000
[2019-03-24 06:03:29,807] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175616: loss 4.1523
[2019-03-24 06:03:29,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175616: learning rate 0.0000
[2019-03-24 06:03:29,976] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175707: loss 4.2300
[2019-03-24 06:03:29,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175708: learning rate 0.0000
[2019-03-24 06:03:30,127] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175789: loss 4.1935
[2019-03-24 06:03:30,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175789: learning rate 0.0000
[2019-03-24 06:03:30,145] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175800: loss 4.1815
[2019-03-24 06:03:30,147] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175800: learning rate 0.0000
[2019-03-24 06:03:30,200] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175830: loss 3.2986
[2019-03-24 06:03:30,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175831: learning rate 0.0000
[2019-03-24 06:03:30,491] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175978: loss 4.4144
[2019-03-24 06:03:30,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175978: learning rate 0.0000
[2019-03-24 06:03:30,539] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176002: loss 3.5848
[2019-03-24 06:03:30,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176003: learning rate 0.0000
[2019-03-24 06:03:30,714] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176094: loss 3.4748
[2019-03-24 06:03:30,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176096: learning rate 0.0000
[2019-03-24 06:03:30,854] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176167: loss 4.0811
[2019-03-24 06:03:30,860] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176169: learning rate 0.0000
[2019-03-24 06:03:31,068] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176276: loss 3.8675
[2019-03-24 06:03:31,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176276: loss 3.7650
[2019-03-24 06:03:31,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176277: learning rate 0.0000
[2019-03-24 06:03:31,074] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176277: learning rate 0.0000
[2019-03-24 06:03:31,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176306: loss 3.8327
[2019-03-24 06:03:31,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176307: learning rate 0.0000
[2019-03-24 06:03:31,460] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176481: loss 2.9525
[2019-03-24 06:03:31,461] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176481: learning rate 0.0000
[2019-03-24 06:03:31,633] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176571: loss 2.3929
[2019-03-24 06:03:31,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176571: learning rate 0.0000
[2019-03-24 06:03:34,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6501082e-06 2.1907768e-05 9.9997604e-01 4.2827207e-08 3.6367177e-07], sum to 1.0000
[2019-03-24 06:03:34,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4738
[2019-03-24 06:03:34,131] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.91666666666666, 47.33333333333334, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2635127683745847, 6.911199999999999, 6.9112, 121.9260426156618, 378840.6320807002, 378840.6320807007, 151273.8863801135], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [22.93333333333333, 47.66666666666667, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2459985894830582, 6.911199999999999, 6.9112, 121.9260426156618, 354100.5140641936, 354100.5140641941, 148584.8491079308], 
processed observation next is [1.0, 0.2608695652173913, 0.40493827160493817, 0.47666666666666674, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.05749823685382273, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12646446930864055, 0.12646446930864075, 0.28574009443832843], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0540938], dtype=float32), 0.6786858]. 
=============================================
[2019-03-24 06:03:38,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9151537e-08 4.0781956e-08 1.0000000e+00 3.6598551e-09 2.7789973e-09], sum to 1.0000
[2019-03-24 06:03:38,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5184
[2019-03-24 06:03:38,136] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.75, 80.5, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2519841830464786, 6.9112, 6.9112, 121.9260426156618, 367655.3017869956, 367655.3017869956, 151328.3966127326], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6759000.0000, 
sim time next is 6759600.0000, 
raw observation next is [19.0, 79.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2519155622416804, 6.911199999999999, 6.9112, 121.9260426156618, 367883.4379565184, 367883.4379565189, 151446.0245318291], 
processed observation next is [1.0, 0.21739130434782608, 0.25925925925925924, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.06489445280210046, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.131386942127328, 0.13138694212732818, 0.29124235486890215], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.336112], dtype=float32), -0.9482786]. 
=============================================
[2019-03-24 06:03:39,500] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4892649e-06 7.6745346e-06 9.9998593e-01 7.5692501e-09 1.8491659e-06], sum to 1.0000
[2019-03-24 06:03:39,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7502
[2019-03-24 06:03:39,513] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.33333333333334, 83.66666666666667, 1.0, 2.0, 0.1755408592972121, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3063203278172884, 6.911199999999999, 6.9112, 121.9260426156618, 447732.0881857203, 447732.0881857208, 159437.1744717914], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6754800.0000, 
sim time next is 6755400.0000, 
raw observation next is [18.25, 84.0, 1.0, 2.0, 0.171306512089811, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2993952302871526, 6.911199999999999, 6.9112, 121.9260426156618, 437197.6729404959, 437197.6729404964, 158460.7836469268], 
processed observation next is [1.0, 0.17391304347826086, 0.23148148148148148, 0.84, 1.0, 1.0, 0.013460133440251203, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.12424403785894073, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1561420260501771, 0.1561420260501773, 0.30473227624409], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.46432713], dtype=float32), -0.47661915]. 
=============================================
[2019-03-24 06:03:39,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9238013e-09 6.1817737e-08 9.9999976e-01 7.7771595e-11 7.5214487e-08], sum to 1.0000
[2019-03-24 06:03:39,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2877
[2019-03-24 06:03:39,992] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333334, 68.5, 1.0, 2.0, 0.1640439404392484, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2836106289805842, 6.911199999999999, 6.9112, 121.9260426156618, 416756.9140327604, 416756.9140327608, 157451.7373979165], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6763800.0000, 
sim time next is 6764400.0000, 
raw observation next is [21.1, 67.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2687963726728689, 6.911199999999999, 6.9112, 121.9260426156618, 395161.8199810675, 395161.819981068, 155347.9507921251], 
processed observation next is [1.0, 0.30434782608695654, 0.3370370370370371, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.08599546584108608, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1411292214218098, 0.14112922142181, 0.2987460592156252], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8888153], dtype=float32), 0.59434116]. 
=============================================
[2019-03-24 06:03:44,432] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183246: loss 0.0072
[2019-03-24 06:03:44,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183248: learning rate 0.0000
[2019-03-24 06:03:44,936] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183513: loss 0.0005
[2019-03-24 06:03:44,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183513: learning rate 0.0000
[2019-03-24 06:03:45,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183753: loss 0.0092
[2019-03-24 06:03:45,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183753: learning rate 0.0000
[2019-03-24 06:03:45,467] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183790: loss 0.0640
[2019-03-24 06:03:45,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183793: learning rate 0.0000
[2019-03-24 06:03:45,479] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183797: loss 0.0161
[2019-03-24 06:03:45,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183797: learning rate 0.0000
[2019-03-24 06:03:45,564] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183840: loss 0.0468
[2019-03-24 06:03:45,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183840: learning rate 0.0000
[2019-03-24 06:03:45,587] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183853: loss 0.0337
[2019-03-24 06:03:45,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183853: learning rate 0.0000
[2019-03-24 06:03:45,680] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183901: loss 0.0408
[2019-03-24 06:03:45,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183901: learning rate 0.0000
[2019-03-24 06:03:45,777] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183955: loss 0.0197
[2019-03-24 06:03:45,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183955: learning rate 0.0000
[2019-03-24 06:03:45,846] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183988: loss 0.0018
[2019-03-24 06:03:45,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183992: learning rate 0.0000
[2019-03-24 06:03:46,084] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184118: loss 0.0103
[2019-03-24 06:03:46,086] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184119: learning rate 0.0000
[2019-03-24 06:03:46,100] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184123: loss 0.0011
[2019-03-24 06:03:46,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184123: learning rate 0.0000
[2019-03-24 06:03:46,675] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184421: loss 0.0348
[2019-03-24 06:03:46,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184421: learning rate 0.0000
[2019-03-24 06:03:46,728] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184450: loss 0.0400
[2019-03-24 06:03:46,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184450: learning rate 0.0000
[2019-03-24 06:03:46,762] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184460: loss 0.0267
[2019-03-24 06:03:46,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184461: learning rate 0.0000
[2019-03-24 06:03:46,951] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184558: loss 0.0123
[2019-03-24 06:03:46,953] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184559: learning rate 0.0000
[2019-03-24 06:03:47,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4741234e-11 6.4148402e-11 1.0000000e+00 1.0529174e-12 1.4272021e-09], sum to 1.0000
[2019-03-24 06:03:47,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5809
[2019-03-24 06:03:48,005] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 61.5, 1.0, 2.0, 0.2520670279061268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4045430772258995, 6.911200000000001, 6.9112, 121.9260426156618, 597239.643988091, 597239.6439880906, 182048.5740247457], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6949800.0000, 
sim time next is 6950400.0000, 
raw observation next is [27.46666666666667, 60.33333333333333, 1.0, 2.0, 0.2528775923094454, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4057101342080571, 6.9112, 6.9112, 121.9260426156618, 598660.9105309437, 598660.9105309437, 182276.8422304312], 
processed observation next is [0.0, 0.43478260869565216, 0.5728395061728396, 0.6033333333333333, 1.0, 1.0, 0.11056856227314929, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.25713766776007135, 0.0, 0.0, 0.8094621288201359, 0.2138074680467656, 0.2138074680467656, 0.3505323889046754], 
reward next is 0.6495, 
noisyNet noise sample is [array([-0.72714764], dtype=float32), 0.23762766]. 
=============================================
[2019-03-24 06:03:49,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4685016e-09 2.4878116e-08 1.0000000e+00 1.9232860e-12 7.7210749e-10], sum to 1.0000
[2019-03-24 06:03:49,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9985
[2019-03-24 06:03:49,386] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 50.0, 1.0, 2.0, 0.2866993723034877, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4570115338237601, 6.911199999999999, 6.9112, 121.9260426156618, 662298.4782320516, 662298.4782320521, 191527.3403024013], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6968400.0000, 
sim time next is 6969000.0000, 
raw observation next is [31.0, 49.5, 1.0, 2.0, 0.284048522239265, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4529343815684833, 6.9112, 6.9112, 121.9260426156618, 657542.2444355385, 657542.2444355385, 190794.5390788048], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.495, 1.0, 1.0, 0.14767681218960121, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3161679769606041, 0.0, 0.0, 0.8094621288201359, 0.2348365158698352, 0.2348365158698352, 0.36691257515154774], 
reward next is 0.6331, 
noisyNet noise sample is [array([0.92533547], dtype=float32), 0.043809347]. 
=============================================
[2019-03-24 06:03:49,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.781933]
 [63.74487 ]
 [63.68861 ]
 [63.640106]
 [63.615353]], R is [[63.80472565]
 [63.79835892]
 [63.79069138]
 [63.78158569]
 [63.77054977]].
[2019-03-24 06:03:59,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191237: loss 0.0040
[2019-03-24 06:03:59,644] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191239: learning rate 0.0000
[2019-03-24 06:04:00,048] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191455: loss 0.0054
[2019-03-24 06:04:00,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191456: learning rate 0.0000
[2019-03-24 06:04:00,515] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191704: loss 0.0269
[2019-03-24 06:04:00,516] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191704: learning rate 0.0000
[2019-03-24 06:04:00,518] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191704: loss 0.0428
[2019-03-24 06:04:00,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191704: learning rate 0.0000
[2019-03-24 06:04:00,531] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191711: loss 0.0413
[2019-03-24 06:04:00,532] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191711: learning rate 0.0000
[2019-03-24 06:04:00,767] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191841: loss 0.0374
[2019-03-24 06:04:00,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191842: learning rate 0.0000
[2019-03-24 06:04:00,832] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191870: loss 0.0191
[2019-03-24 06:04:00,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191870: learning rate 0.0000
[2019-03-24 06:04:00,969] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191941: loss 0.0122
[2019-03-24 06:04:00,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191942: learning rate 0.0000
[2019-03-24 06:04:01,004] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191957: loss 0.0093
[2019-03-24 06:04:01,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191957: learning rate 0.0000
[2019-03-24 06:04:01,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6646869e-09 5.0547007e-09 1.0000000e+00 4.5177572e-13 2.1827321e-10], sum to 1.0000
[2019-03-24 06:04:01,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4711
[2019-03-24 06:04:01,064] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.36666666666667, 87.0, 1.0, 2.0, 0.1854515255273199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3082075731605455, 6.911199999999999, 6.9112, 121.9260426156618, 460141.889395608, 460141.8893956085, 164153.1524810712], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7195200.0000, 
sim time next is 7195800.0000, 
raw observation next is [20.43333333333334, 86.5, 1.0, 2.0, 0.1873496542112199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3113156188990643, 6.9112, 6.9112, 121.9260426156618, 464796.6551620231, 464796.6551620231, 164581.4372452712], 
processed observation next is [1.0, 0.2608695652173913, 0.31234567901234594, 0.865, 1.0, 1.0, 0.032559112156214175, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13914452362383034, 0.0, 0.0, 0.8094621288201359, 0.16599880541500825, 0.16599880541500825, 0.31650276393321386], 
reward next is 0.6835, 
noisyNet noise sample is [array([-0.810783], dtype=float32), 1.4982666]. 
=============================================
[2019-03-24 06:04:01,277] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192105: loss 0.0053
[2019-03-24 06:04:01,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192105: learning rate 0.0000
[2019-03-24 06:04:01,411] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192173: loss 0.0103
[2019-03-24 06:04:01,413] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192173: learning rate 0.0000
[2019-03-24 06:04:01,483] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192203: loss 0.0149
[2019-03-24 06:04:01,484] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192204: learning rate 0.0000
[2019-03-24 06:04:01,714] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192341: loss 0.0909
[2019-03-24 06:04:01,716] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192341: learning rate 0.0000
[2019-03-24 06:04:01,805] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192383: loss 0.0304
[2019-03-24 06:04:01,806] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192383: learning rate 0.0000
[2019-03-24 06:04:01,929] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192455: loss 0.0058
[2019-03-24 06:04:01,931] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192455: learning rate 0.0000
[2019-03-24 06:04:02,435] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192767: loss 0.0011
[2019-03-24 06:04:02,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192767: learning rate 0.0000
[2019-03-24 06:04:10,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.01028491e-09 1.09571074e-09 1.00000000e+00 1.04569695e-11
 5.61286906e-10], sum to 1.0000
[2019-03-24 06:04:10,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8100
[2019-03-24 06:04:10,696] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333334, 96.0, 1.0, 2.0, 0.1925212457089778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3196534885898185, 6.911199999999999, 6.9112, 121.9260426156618, 477318.6169445709, 477318.6169445714, 165770.0964758712], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7365000.0000, 
sim time next is 7365600.0000, 
raw observation next is [19.3, 96.0, 1.0, 2.0, 0.191469352419662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3180856840796537, 6.911199999999999, 6.9112, 121.9260426156618, 474928.605570259, 474928.6055702594, 165504.1958496801], 
processed observation next is [1.0, 0.2608695652173913, 0.27037037037037037, 0.96, 1.0, 1.0, 0.037463514785311916, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14760710509956712, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16961735913223536, 0.1696173591322355, 0.3182772997109233], 
reward next is 0.6817, 
noisyNet noise sample is [array([-1.524305], dtype=float32), 1.0963448]. 
=============================================
[2019-03-24 06:04:12,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1998698e-08 4.0038390e-07 9.9999964e-01 3.4572187e-12 1.8034534e-09], sum to 1.0000
[2019-03-24 06:04:12,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8342
[2019-03-24 06:04:12,613] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.9, 92.5, 1.0, 2.0, 0.1912273174808517, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3167014006769981, 6.911200000000001, 6.9112, 121.9260426156618, 473095.6242887283, 473095.6242887279, 165633.367724516], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7435800.0000, 
sim time next is 7436400.0000, 
raw observation next is [19.86666666666667, 92.66666666666667, 1.0, 2.0, 0.1909308745742399, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3162818057171355, 6.911199999999999, 6.9112, 121.9260426156618, 472454.0938934181, 472454.0938934186, 165554.3876283773], 
processed observation next is [0.0, 0.043478260869565216, 0.2913580246913582, 0.9266666666666667, 1.0, 1.0, 0.03682246973123798, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14535225714641933, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16873360496193504, 0.1687336049619352, 0.318373822362264], 
reward next is 0.6816, 
noisyNet noise sample is [array([-1.6430024], dtype=float32), 0.10614817]. 
=============================================
[2019-03-24 06:04:13,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6215667e-10 4.6552785e-08 1.0000000e+00 7.6709933e-13 3.6714837e-12], sum to 1.0000
[2019-03-24 06:04:13,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6159
[2019-03-24 06:04:13,557] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.35, 95.0, 1.0, 2.0, 0.1871462301492598, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3113206517042149, 6.911199999999999, 6.9112, 121.9260426156618, 464703.319628733, 464703.3196287335, 164472.6379599523], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7443000.0000, 
sim time next is 7443600.0000, 
raw observation next is [19.3, 95.33333333333334, 1.0, 2.0, 0.1860286600438784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3095346645188087, 6.911199999999999, 6.9112, 121.9260426156618, 462014.0378903489, 462014.0378903494, 164211.9472926277], 
processed observation next is [0.0, 0.13043478260869565, 0.27037037037037037, 0.9533333333333335, 1.0, 1.0, 0.030986500052236205, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13691833064851083, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16500501353226746, 0.16500501353226765, 0.31579220633197636], 
reward next is 0.6842, 
noisyNet noise sample is [array([-1.6513523], dtype=float32), -1.0333765]. 
=============================================
[2019-03-24 06:04:15,617] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199258: loss 0.0091
[2019-03-24 06:04:15,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199258: learning rate 0.0000
[2019-03-24 06:04:16,114] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199510: loss 0.0007
[2019-03-24 06:04:16,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199513: learning rate 0.0000
[2019-03-24 06:04:16,272] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199588: loss 0.0038
[2019-03-24 06:04:16,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199589: learning rate 0.0000
[2019-03-24 06:04:16,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1473957e-08 3.8806993e-09 1.0000000e+00 3.8035785e-13 7.5055323e-11], sum to 1.0000
[2019-03-24 06:04:16,505] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0439
[2019-03-24 06:04:16,510] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.7, 90.33333333333334, 1.0, 2.0, 0.2496427063080977, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4008757105929696, 6.911199999999999, 6.9112, 121.9260426156618, 592302.3363995753, 592302.3363995758, 181402.987604244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7503600.0000, 
sim time next is 7504200.0000, 
raw observation next is [22.65, 90.5, 1.0, 2.0, 0.2484747863102708, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3990917971892344, 6.9112, 6.9112, 121.9260426156618, 589852.8944307165, 589852.8944307165, 181096.2176326459], 
processed observation next is [0.0, 0.8695652173913043, 0.3944444444444444, 0.905, 1.0, 1.0, 0.1053271265598462, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24886474648654294, 0.0, 0.0, 0.8094621288201359, 0.21066174801097018, 0.21066174801097018, 0.3482619569858575], 
reward next is 0.6517, 
noisyNet noise sample is [array([1.4142783], dtype=float32), 1.4899653]. 
=============================================
[2019-03-24 06:04:16,514] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199711: loss 0.0354
[2019-03-24 06:04:16,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199712: learning rate 0.0000
[2019-03-24 06:04:16,643] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199773: loss 0.0103
[2019-03-24 06:04:16,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199773: learning rate 0.0000
[2019-03-24 06:04:16,709] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199802: loss 0.0147
[2019-03-24 06:04:16,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199802: learning rate 0.0000
[2019-03-24 06:04:16,844] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199871: loss 0.0099
[2019-03-24 06:04:16,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199871: learning rate 0.0000
[2019-03-24 06:04:16,866] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199880: loss 0.0008
[2019-03-24 06:04:16,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199882: learning rate 0.0000
[2019-03-24 06:04:16,976] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199938: loss 0.0013
[2019-03-24 06:04:16,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199938: learning rate 0.0000
[2019-03-24 06:04:17,104] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 06:04:17,105] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:04:17,107] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:04:17,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:17,110] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:04:17,110] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:04:17,111] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:17,112] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:17,113] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:17,107] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:04:17,116] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:17,125] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-24 06:04:17,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-24 06:04:17,126] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-24 06:04:17,126] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-24 06:04:17,226] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-24 06:04:26,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:04:26,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.17100053, 53.78031212666667, 1.0, 2.0, 0.2760808056980004, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4534863130657062, 6.911199999999999, 6.9112, 121.9260426156618, 677824.8949848982, 677824.8949848986, 186398.9694847503]
[2019-03-24 06:04:26,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:04:26,891] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.1935569e-09 3.9115037e-08 1.0000000e+00 1.3699362e-11 3.8379979e-09], sampled 0.4362917696259154
[2019-03-24 06:04:33,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:04:33,350] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.83333333333334, 75.83333333333333, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2436201343021086, 6.911199999999999, 6.9112, 121.9260426156618, 352577.6368430557, 352577.6368430562, 148861.033532648]
[2019-03-24 06:04:33,350] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:04:33,354] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.5154281e-09 3.0970057e-08 1.0000000e+00 9.5149340e-12 2.9748168e-09], sampled 0.5463243955075595
[2019-03-24 06:04:46,027] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:04:46,028] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.29613003, 63.64164252, 1.0, 2.0, 0.1664893517270736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2868807126650657, 6.9112, 6.9112, 121.9260426156618, 422326.3940851068, 422326.3940851068, 158129.6030432715]
[2019-03-24 06:04:46,029] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:04:46,033] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2672655e-09 8.1101472e-09 1.0000000e+00 1.3121226e-12 6.3329536e-10], sampled 0.3074603615808491
[2019-03-24 06:04:58,155] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:04:58,155] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.5, 90.66666666666666, 1.0, 2.0, 0.3156836585316872, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5026356665412866, 6.9112, 6.9112, 121.9260426156618, 721165.104706034, 721165.104706034, 199480.8169294189]
[2019-03-24 06:04:58,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:04:58,159] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3413140e-09 2.4129857e-08 1.0000000e+00 6.9834299e-12 2.2340734e-09], sampled 0.8175482282845826
[2019-03-24 06:05:19,920] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:05:19,922] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.19583110166667, 80.10506096333333, 1.0, 2.0, 0.2303654918260908, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3727444756040624, 6.911199999999999, 6.9112, 121.9260426156618, 554735.2731401353, 554735.2731401358, 176144.5986085452]
[2019-03-24 06:05:19,925] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:05:19,927] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5669457e-09 9.7148352e-09 1.0000000e+00 1.7440087e-12 7.8221524e-10], sampled 0.9229057517047627
[2019-03-24 06:05:22,989] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:05:22,990] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.28333333333333, 92.50000000000001, 1.0, 2.0, 0.2306619205485093, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3794258715182729, 6.911199999999999, 6.9112, 121.9260426156618, 567099.8742095678, 567099.8742095683, 175100.3062986575]
[2019-03-24 06:05:22,991] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:05:22,995] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.6304631e-09 2.6101148e-08 1.0000000e+00 7.5600819e-12 2.4275117e-09], sampled 0.46436594023432554
[2019-03-24 06:05:27,667] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00683043], dtype=float32), 0.0050143744]
[2019-03-24 06:05:27,668] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3819573343115409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6080885157059063, 6.911199999999999, 6.9112, 121.9260426156618, 870687.9950775777, 870687.9950775781, 218604.4257285618]
[2019-03-24 06:05:27,669] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:05:27,672] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4335284e-09 2.0082457e-08 1.0000000e+00 5.1089332e-12 1.7715633e-09], sampled 0.31597863532746695
[2019-03-24 06:06:02,255] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7155.8476 2831359193.2116 210.0000
[2019-03-24 06:06:02,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7160.7985 2623802691.8439 97.0000
[2019-03-24 06:06:02,447] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.9202 2565925778.3573 47.0000
[2019-03-24 06:06:02,527] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6810.3396 2600751810.6095 61.0000
[2019-03-24 06:06:02,531] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7547 2661626271.5934 110.0000
[2019-03-24 06:06:03,544] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 200000, evaluation results [200000.0, 7155.8476132799715, 2831359193.2116127, 210.0, 6810.339601629198, 2600751810.609544, 61.0, 7491.9202498530285, 2565925778.3573475, 47.0, 6580.754708850709, 2661626271.5933523, 110.0, 7160.798490334361, 2623802691.8438516, 97.0]
[2019-03-24 06:06:03,728] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200096: loss 0.0029
[2019-03-24 06:06:03,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200096: learning rate 0.0000
[2019-03-24 06:06:03,792] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200126: loss 0.0209
[2019-03-24 06:06:03,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200126: learning rate 0.0000
[2019-03-24 06:06:04,088] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200286: loss 0.0081
[2019-03-24 06:06:04,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200286: learning rate 0.0000
[2019-03-24 06:06:04,233] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200357: loss 0.0230
[2019-03-24 06:06:04,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200357: learning rate 0.0000
[2019-03-24 06:06:04,307] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200400: loss 0.0139
[2019-03-24 06:06:04,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200400: learning rate 0.0000
[2019-03-24 06:06:04,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200421: loss 0.0087
[2019-03-24 06:06:04,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200421: learning rate 0.0000
[2019-03-24 06:06:05,068] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200793: loss 0.0258
[2019-03-24 06:06:05,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200795: learning rate 0.0000
[2019-03-24 06:06:08,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8682396e-09 3.5233981e-08 1.0000000e+00 1.3076879e-12 2.9919719e-10], sum to 1.0000
[2019-03-24 06:06:08,286] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1538
[2019-03-24 06:06:08,290] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.7, 85.33333333333333, 1.0, 2.0, 0.2598731949750184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4163040364865317, 6.911199999999999, 6.9112, 121.9260426156618, 612699.841394145, 612699.8413941455, 184152.3421228656], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7594800.0000, 
sim time next is 7595400.0000, 
raw observation next is [23.65, 85.66666666666667, 1.0, 2.0, 0.2597263649763433, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4160804688265266, 6.911199999999999, 6.9112, 121.9260426156618, 612403.2816684177, 612403.2816684182, 184113.0265727915], 
processed observation next is [0.0, 0.9130434782608695, 0.4314814814814814, 0.8566666666666667, 1.0, 1.0, 0.11872186306707538, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.27010058603315823, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21871545773872061, 0.21871545773872078, 0.35406351263998365], 
reward next is 0.6459, 
noisyNet noise sample is [array([-0.43434954], dtype=float32), 0.002343068]. 
=============================================
[2019-03-24 06:06:14,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7513258e-06 1.2302347e-05 9.9997985e-01 4.8481660e-08 2.9274888e-06], sum to 1.0000
[2019-03-24 06:06:14,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0935
[2019-03-24 06:06:14,310] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.43333333333333, 77.0, 1.0, 2.0, 0.354845745790822, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5805578022613751, 6.911199999999999, 6.9112, 121.9260426156618, 867569.8130191339, 867569.8130191343, 208085.0998025317], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7723200.0000, 
sim time next is 7723800.0000, 
raw observation next is [22.8, 75.5, 1.0, 2.0, 0.3662152972916484, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5980401712282077, 6.9112, 6.9112, 121.9260426156618, 893425.4339335411, 893425.4339335411, 211525.6729564746], 
processed observation next is [1.0, 0.391304347826087, 0.4, 0.755, 1.0, 1.0, 0.2454944015376767, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4975502140352596, 0.0, 0.0, 0.8094621288201359, 0.3190805121191218, 0.3190805121191218, 0.4067801403009127], 
reward next is 0.5932, 
noisyNet noise sample is [array([-0.32202628], dtype=float32), -1.2143185]. 
=============================================
[2019-03-24 06:06:17,562] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207372: loss 0.2106
[2019-03-24 06:06:17,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207373: learning rate 0.0000
[2019-03-24 06:06:17,754] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207472: loss 0.1577
[2019-03-24 06:06:17,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207474: learning rate 0.0000
[2019-03-24 06:06:17,991] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207599: loss 0.1245
[2019-03-24 06:06:17,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207599: learning rate 0.0000
[2019-03-24 06:06:18,101] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207657: loss 0.1314
[2019-03-24 06:06:18,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207661: learning rate 0.0000
[2019-03-24 06:06:18,201] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207708: loss 0.1163
[2019-03-24 06:06:18,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207709: learning rate 0.0000
[2019-03-24 06:06:18,315] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207766: loss 0.0910
[2019-03-24 06:06:18,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207766: learning rate 0.0000
[2019-03-24 06:06:18,623] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207928: loss 0.1300
[2019-03-24 06:06:18,624] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207929: learning rate 0.0000
[2019-03-24 06:06:18,709] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207983: loss 0.1620
[2019-03-24 06:06:18,710] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207983: loss 0.1467
[2019-03-24 06:06:18,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207983: learning rate 0.0000
[2019-03-24 06:06:18,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207983: learning rate 0.0000
[2019-03-24 06:06:18,907] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208078: loss 0.1023
[2019-03-24 06:06:18,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208079: learning rate 0.0000
[2019-03-24 06:06:18,927] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208089: loss 0.1231
[2019-03-24 06:06:18,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208089: learning rate 0.0000
[2019-03-24 06:06:19,134] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208199: loss 0.1266
[2019-03-24 06:06:19,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208200: learning rate 0.0000
[2019-03-24 06:06:19,424] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208354: loss 0.1223
[2019-03-24 06:06:19,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208354: learning rate 0.0000
[2019-03-24 06:06:19,448] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208363: loss 0.2021
[2019-03-24 06:06:19,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208363: learning rate 0.0000
[2019-03-24 06:06:19,523] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208407: loss 0.2708
[2019-03-24 06:06:19,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208407: learning rate 0.0000
[2019-03-24 06:06:20,363] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208846: loss 0.2661
[2019-03-24 06:06:20,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208846: learning rate 0.0000
[2019-03-24 06:06:22,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7247304e-08 1.7282871e-07 9.9999988e-01 1.4021449e-11 3.7296122e-09], sum to 1.0000
[2019-03-24 06:06:22,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5091
[2019-03-24 06:06:22,634] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.53333333333333, 65.0, 1.0, 2.0, 0.4658253872596297, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7579132420004532, 6.911199999999999, 6.9112, 121.9260426156618, 1131329.973843503, 1131329.973843504, 242949.2293971051], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7896000.0000, 
sim time next is 7896600.0000, 
raw observation next is [24.8, 64.0, 1.0, 2.0, 0.4770380318444773, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7751978948737023, 6.9112, 6.9112, 121.9260426156618, 1156628.725236638, 1156628.725236638, 246813.6880759777], 
processed observation next is [1.0, 0.391304347826087, 0.4740740740740741, 0.64, 1.0, 1.0, 0.37742622838628254, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7189973685921277, 0.0, 0.0, 0.8094621288201359, 0.4130816875845136, 0.4130816875845136, 0.47464170783841864], 
reward next is 0.5254, 
noisyNet noise sample is [array([1.0699735], dtype=float32), 0.031189289]. 
=============================================
[2019-03-24 06:06:24,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1458920e-06 6.1423464e-07 9.9999714e-01 9.0593727e-10 1.5192748e-07], sum to 1.0000
[2019-03-24 06:06:24,447] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-24 06:06:24,450] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 52.0, 1.0, 2.0, 0.5744236627306175, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9232655386251566, 6.9112, 6.9112, 121.9260426156618, 1366520.69721481, 1366520.69721481, 282696.5064779027], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7905600.0000, 
sim time next is 7906200.0000, 
raw observation next is [28.36666666666667, 51.5, 1.0, 2.0, 0.5873874101478244, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9438413042169649, 6.911199999999999, 6.9112, 121.9260426156618, 1396508.014477781, 1396508.014477782, 287652.7532017858], 
processed observation next is [1.0, 0.5217391304347826, 0.606172839506173, 0.515, 1.0, 1.0, 0.5087945358902671, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9298016302712061, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4987528623134932, 0.49875286231349353, 0.5531783715418958], 
reward next is 0.4468, 
noisyNet noise sample is [array([-1.4197783], dtype=float32), -1.0440814]. 
=============================================
[2019-03-24 06:06:26,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-24 06:06:26,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,251] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-24 06:06:26,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,410] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-24 06:06:26,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-24 06:06:26,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,619] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,620] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-24 06:06:26,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-24 06:06:26,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-24 06:06:26,990] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:26,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:26,992] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-24 06:06:27,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-24 06:06:27,058] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-24 06:06:27,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-24 06:06:27,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,250] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-24 06:06:27,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-24 06:06:27,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-24 06:06:27,403] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,403] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:06:27,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:27,430] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-24 06:06:27,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-24 06:06:40,682] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2375790e-11 8.4676217e-11 1.0000000e+00 2.6982908e-15 1.4599801e-13], sum to 1.0000
[2019-03-24 06:06:40,689] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7274
[2019-03-24 06:06:40,693] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 26.0, 1.0, 2.0, 0.1768607349432163, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3065599922964047, 6.911199999999999, 6.9112, 121.9260426156618, 449839.979502729, 449839.9795027294, 160046.0689441109], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 244800.0000, 
sim time next is 245400.0000, 
raw observation next is [29.36666666666667, 26.83333333333334, 1.0, 2.0, 0.1784069445839721, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3094531257161006, 6.911199999999999, 6.9112, 121.9260426156618, 453908.9614898559, 453908.9614898563, 160344.929377556], 
processed observation next is [0.0, 0.8695652173913043, 0.64320987654321, 0.26833333333333337, 1.0, 1.0, 0.021913029266633455, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13681640714512575, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16211034338923425, 0.16211034338923438, 0.3083556334183769], 
reward next is 0.6916, 
noisyNet noise sample is [array([0.38202837], dtype=float32), 1.673018]. 
=============================================
[2019-03-24 06:06:53,848] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 06:06:53,849] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:06:53,851] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:06:53,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:53,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:06:53,853] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:53,855] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:53,856] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:06:53,856] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:06:53,858] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:53,859] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:53,874] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-24 06:06:53,874] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-24 06:06:53,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-24 06:06:53,875] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-24 06:06:53,875] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-24 06:06:55,296] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00658526], dtype=float32), 0.00480852]
[2019-03-24 06:06:55,298] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.73333333333333, 46.66666666666666, 1.0, 2.0, 0.3037746897629506, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5297437903132916, 6.9112, 6.9112, 121.9260426156618, 774765.7108139032, 774765.7108139032, 189939.880821113]
[2019-03-24 06:06:55,298] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:06:55,302] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.8831002e-06 1.1289103e-05 9.9998224e-01 2.5976918e-08 1.5755184e-06], sampled 0.6167957462135352
[2019-03-24 06:07:15,260] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00658526], dtype=float32), 0.00480852]
[2019-03-24 06:07:15,261] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.83333333333334, 55.66666666666667, 1.0, 2.0, 0.2024520759876052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3331215850531905, 6.911199999999999, 6.9112, 121.9260426156618, 497869.3411743111, 497869.3411743115, 168539.6006557204]
[2019-03-24 06:07:15,263] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:07:15,266] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4839644e-06 6.1177275e-06 9.9999070e-01 9.9507407e-09 7.6336681e-07], sampled 0.2726833965877137
[2019-03-24 06:07:38,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00658526], dtype=float32), 0.00480852]
[2019-03-24 06:07:38,093] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.88486648333333, 75.54285885333334, 1.0, 2.0, 0.2318021911962636, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3751812004231221, 6.911199999999999, 6.9112, 121.9260426156618, 558465.814919992, 558465.8149199925, 176466.6938323918]
[2019-03-24 06:07:38,094] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:07:38,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3426198e-06 3.4556306e-06 9.9999487e-01 4.0515640e-09 3.8402487e-07], sampled 0.41698686327765566
[2019-03-24 06:08:34,001] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00658526], dtype=float32), 0.00480852]
[2019-03-24 06:08:34,002] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.64822834, 100.2812345666667, 1.0, 2.0, 0.2201310376856916, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3564664981633002, 6.9112, 6.9112, 121.9260426156618, 530753.4520607754, 530753.4520607754, 173666.2613035152]
[2019-03-24 06:08:34,003] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:08:34,004] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7905130e-06 4.3727296e-06 9.9999332e-01 6.0949641e-09 5.1641479e-07], sampled 0.9732369663482892
[2019-03-24 06:08:34,911] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00658526], dtype=float32), 0.00480852]
[2019-03-24 06:08:34,912] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.91583170333334, 84.04577882666666, 1.0, 2.0, 0.2556136594397899, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4094623764212666, 6.911199999999999, 6.9112, 121.9260426156618, 602575.6855808164, 602575.6855808168, 183088.522215547]
[2019-03-24 06:08:34,913] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:08:34,916] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.6532327e-07 2.2839188e-06 9.9999666e-01 2.1239721e-09 2.3453909e-07], sampled 0.4812238666606512
[2019-03-24 06:08:38,288] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7504 2661644033.7644 110.0000
[2019-03-24 06:08:38,648] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.9754 2565853652.7012 47.0000
[2019-03-24 06:08:38,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.2396 2831323017.1963 210.0000
[2019-03-24 06:08:39,030] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.7221 2623904956.9185 97.0000
[2019-03-24 06:08:39,039] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6810.3335 2600720014.0157 61.0000
[2019-03-24 06:08:40,052] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 7157.239583854098, 2831323017.196332, 210.0, 6810.333543520029, 2600720014.015744, 61.0, 7491.975361939925, 2565853652.70124, 47.0, 6580.750378123269, 2661644033.764386, 110.0, 7162.722057844956, 2623904956.9184656, 97.0]
[2019-03-24 06:08:40,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3747710e-07 3.6206072e-07 9.9999845e-01 2.0350430e-10 3.0551584e-07], sum to 1.0000
[2019-03-24 06:08:40,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-24 06:08:40,693] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.26666666666667, 44.66666666666667, 1.0, 2.0, 0.1720013735986604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2905219709600841, 6.911199999999999, 6.9112, 121.9260426156618, 431664.0841858284, 431664.0841858289, 160328.4339957927], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 508800.0000, 
sim time next is 509400.0000, 
raw observation next is [26.0, 45.5, 1.0, 2.0, 0.1703296871156831, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2881034735198899, 6.911199999999999, 6.9112, 121.9260426156618, 427834.8119614259, 427834.8119614264, 159895.9907014186], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.455, 1.0, 1.0, 0.012297246566289412, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11012934189986237, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15279814712908066, 0.15279814712908085, 0.30749228981042037], 
reward next is 0.6925, 
noisyNet noise sample is [array([-0.00437168], dtype=float32), -0.8079567]. 
=============================================
[2019-03-24 06:08:45,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7739991e-07 2.8034822e-06 9.9999583e-01 6.9547496e-10 1.2065667e-06], sum to 1.0000
[2019-03-24 06:08:45,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7098
[2019-03-24 06:08:45,166] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.7, 32.0, 1.0, 2.0, 0.7406475410335802, 0.0, 2.0, 0.0, 1.0, 2.0, 0.958029043476851, 6.9112, 6.9112, 121.9260426156618, 1611751.349955381, 1611751.349955381, 314621.3383011417], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 576000.0000, 
sim time next is 576600.0000, 
raw observation next is [31.8, 31.66666666666667, 1.0, 2.0, 0.6381728202087376, 0.0, 2.0, 0.0, 1.0, 2.0, 0.957803470780019, 6.911199999999999, 6.9112, 121.9260426156618, 1488134.488487712, 1488134.488487713, 295614.3619180482], 
processed observation next is [1.0, 0.6956521739130435, 0.7333333333333334, 0.3166666666666667, 1.0, 1.0, 0.5692533573913542, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9472543384750237, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5314766030313257, 0.531476603031326, 0.5684891575347081], 
reward next is 0.4315, 
noisyNet noise sample is [array([0.5651135], dtype=float32), 0.43043402]. 
=============================================
[2019-03-24 06:08:48,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5991796e-08 2.3017697e-07 9.9999976e-01 5.2649274e-12 4.5457906e-08], sum to 1.0000
[2019-03-24 06:08:48,774] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3112
[2019-03-24 06:08:48,778] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [35.7, 19.33333333333334, 1.0, 2.0, 0.7646224791265318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9563462146353575, 6.911199999999999, 6.9112, 121.9260426156618, 1647718.093620694, 1647718.093620695, 317886.6844309499], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 657600.0000, 
sim time next is 658200.0000, 
raw observation next is [35.7, 19.16666666666667, 1.0, 2.0, 0.7734007955183333, 0.0, 2.0, 0.0, 1.0, 2.0, 0.956273114248501, 6.911199999999999, 6.9112, 121.9260426156618, 1658878.013119833, 1658878.013119834, 319539.3410592859], 
processed observation next is [1.0, 0.6086956521739131, 0.8777777777777779, 0.1916666666666667, 1.0, 1.0, 0.7302390422837302, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9453413928106263, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5924564332570832, 0.5924564332570835, 0.6144987328063191], 
reward next is 0.3855, 
noisyNet noise sample is [array([-0.84061635], dtype=float32), -1.0729271]. 
=============================================
[2019-03-24 06:08:51,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6923707e-08 1.3890448e-07 9.9999988e-01 8.9366110e-12 8.1112556e-10], sum to 1.0000
[2019-03-24 06:08:51,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2771
[2019-03-24 06:08:51,098] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.03333333333333, 46.33333333333334, 1.0, 2.0, 0.1836175313855825, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3207671879107682, 6.911199999999999, 6.9112, 121.9260426156618, 468543.7023870462, 468543.7023870467, 161123.6860146132], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 704400.0000, 
sim time next is 705000.0000, 
raw observation next is [23.86666666666667, 47.16666666666666, 1.0, 2.0, 0.1797040352388992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.314044346985263, 6.911200000000001, 6.9112, 121.9260426156618, 458619.9961860174, 458619.9961860169, 160261.2579429565], 
processed observation next is [1.0, 0.13043478260869565, 0.4395061728395063, 0.47166666666666657, 1.0, 1.0, 0.023457184808213318, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14255543373157875, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1637928557807205, 0.1637928557807203, 0.3081947268133779], 
reward next is 0.6918, 
noisyNet noise sample is [array([-1.6470959], dtype=float32), 0.06847641]. 
=============================================
[2019-03-24 06:08:51,111] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.62026 ]
 [53.509083]
 [53.627502]
 [53.54309 ]
 [53.523037]], R is [[53.86624908]
 [54.01773453]
 [54.16518784]
 [54.30885315]
 [54.44245911]].
[2019-03-24 06:08:52,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9398483e-10 3.5962553e-09 1.0000000e+00 3.1580383e-13 5.0091428e-12], sum to 1.0000
[2019-03-24 06:08:52,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4749
[2019-03-24 06:08:52,963] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.2, 25.0, 1.0, 2.0, 0.1792339517379773, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3051348132708078, 6.9112, 6.9112, 121.9260426156618, 451890.508917706, 451890.508917706, 161470.123461996], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 756000.0000, 
sim time next is 756600.0000, 
raw observation next is [31.06666666666667, 25.33333333333334, 1.0, 2.0, 0.1801573722818416, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3068091633261798, 6.911199999999999, 6.9112, 121.9260426156618, 454302.4301014813, 454302.4301014818, 161653.0234443884], 
processed observation next is [1.0, 0.782608695652174, 0.7061728395061729, 0.2533333333333334, 1.0, 1.0, 0.023996871764097125, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13351145415772472, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1622508678933862, 0.16225086789338636, 0.31087119893151616], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.1173875], dtype=float32), -0.09697625]. 
=============================================
[2019-03-24 06:08:54,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0530837e-07 1.8709328e-06 9.9999630e-01 2.7163314e-09 1.0435439e-06], sum to 1.0000
[2019-03-24 06:08:54,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5000
[2019-03-24 06:08:54,146] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.53333333333333, 32.5, 1.0, 2.0, 0.1679608007452045, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2874743360021444, 6.9112, 6.9112, 121.9260426156618, 424660.6036284645, 424660.6036284645, 158778.7960421469], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 767400.0000, 
sim time next is 768000.0000, 
raw observation next is [28.36666666666667, 33.0, 1.0, 2.0, 0.1675364583607951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2868752158096606, 6.911199999999999, 6.9112, 121.9260426156618, 423683.0843232842, 423683.0843232846, 158666.4467523977], 
processed observation next is [1.0, 0.9130434782608695, 0.606172839506173, 0.33, 1.0, 1.0, 0.008971974239041768, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.10859401976207571, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15131538725831578, 0.15131538725831595, 0.3051277822161494], 
reward next is 0.6949, 
noisyNet noise sample is [array([-0.46232033], dtype=float32), -2.8297546]. 
=============================================
[2019-03-24 06:08:54,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.21506 ]
 [56.356388]
 [56.3041  ]
 [56.41488 ]
 [56.60632 ]], R is [[56.352314  ]
 [56.48344803]
 [56.61306381]
 [56.74108505]
 [56.86751938]].
[2019-03-24 06:08:57,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.69798722e-09 1.04153423e-06 9.99998927e-01 2.18599080e-11
 1.00621875e-08], sum to 1.0000
[2019-03-24 06:08:57,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9763
[2019-03-24 06:08:57,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 47.66666666666667, 1.0, 2.0, 0.1989115340914036, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3286973303917445, 6.9112, 6.9112, 121.9260426156618, 491146.1886505545, 491146.1886505545, 167479.4580233938], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 854400.0000, 
sim time next is 855000.0000, 
raw observation next is [26.95, 48.5, 1.0, 2.0, 0.1993743342146711, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3293224002493372, 6.911199999999999, 6.9112, 121.9260426156618, 492099.3568467228, 492099.3568467232, 167609.1444703948], 
processed observation next is [0.0, 0.9130434782608695, 0.5537037037037037, 0.485, 1.0, 1.0, 0.04687420739841797, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.16165300031167146, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.175749770302401, 0.17574977030240113, 0.3223252778276823], 
reward next is 0.6777, 
noisyNet noise sample is [array([-0.74834335], dtype=float32), -0.3698598]. 
=============================================
[2019-03-24 06:08:57,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.59911 ]
 [72.664215]
 [72.73933 ]
 [72.790596]
 [72.89434 ]], R is [[72.52516937]
 [72.47784424]
 [72.43160248]
 [72.3862915 ]
 [72.34155273]].
[2019-03-24 06:09:00,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6647606e-07 6.1845685e-07 9.9999928e-01 8.9265255e-11 5.2513460e-08], sum to 1.0000
[2019-03-24 06:09:00,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9757
[2019-03-24 06:09:00,213] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.4, 66.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2720490481305002, 6.911199999999999, 6.9112, 121.9260426156618, 400527.2925259741, 400527.2925259746, 156161.5969599855], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 885600.0000, 
sim time next is 886200.0000, 
raw observation next is [21.46666666666667, 66.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2730382225082135, 6.9112, 6.9112, 121.9260426156618, 402316.343206948, 402316.343206948, 156482.4191947738], 
processed observation next is [0.0, 0.2608695652173913, 0.35061728395061736, 0.66, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.09129777813526689, 0.0, 0.0, 0.8094621288201359, 0.14368440828819573, 0.14368440828819573, 0.30092772922071886], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8963329], dtype=float32), 1.2776974]. 
=============================================
[2019-03-24 06:09:03,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3753314e-07 1.3267685e-07 9.9999964e-01 3.1675673e-10 3.4223159e-08], sum to 1.0000
[2019-03-24 06:09:03,212] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-24 06:09:03,217] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.4, 45.0, 1.0, 2.0, 0.2101128227414338, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3440549415576382, 6.911199999999999, 6.9112, 121.9260426156618, 514084.2288425532, 514084.2288425536, 170592.6313047144], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 919800.0000, 
sim time next is 920400.0000, 
raw observation next is [28.4, 44.66666666666667, 1.0, 2.0, 0.2087272187385455, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3420947327219264, 6.911199999999999, 6.9112, 121.9260426156618, 511202.2478621704, 511202.2478621708, 170216.8654216539], 
processed observation next is [0.0, 0.6521739130434783, 0.6074074074074074, 0.4466666666666667, 1.0, 1.0, 0.05800859373636368, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.177618415902408, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18257223137934656, 0.18257223137934672, 0.3273401258108729], 
reward next is 0.6727, 
noisyNet noise sample is [array([1.9622852], dtype=float32), 0.035004273]. 
=============================================
[2019-03-24 06:09:15,261] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4156377e-06 5.2024978e-07 9.9999440e-01 8.8302379e-09 7.1914110e-07], sum to 1.0000
[2019-03-24 06:09:15,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9986
[2019-03-24 06:09:15,272] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.6, 78.5, 1.0, 2.0, 0.1781770400660634, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3006462168367347, 6.9112, 6.9112, 121.9260426156618, 446883.8829764696, 446883.8829764696, 161714.3320125374], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1189800.0000, 
sim time next is 1190400.0000, 
raw observation next is [20.53333333333333, 79.0, 1.0, 2.0, 0.1776951422282318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2998360313560058, 6.911199999999999, 6.9112, 121.9260426156618, 445677.6292618216, 445677.629261822, 161609.3601938649], 
processed observation next is [1.0, 0.782608695652174, 0.3160493827160493, 0.79, 1.0, 1.0, 0.021065645509799752, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.12479503919500722, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.159170581879222, 0.15917058187922214, 0.3107872311420479], 
reward next is 0.6892, 
noisyNet noise sample is [array([-1.1727453], dtype=float32), 0.12545583]. 
=============================================
[2019-03-24 06:09:15,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0853508e-06 5.9443159e-06 9.9998307e-01 3.5937053e-09 4.9083724e-06], sum to 1.0000
[2019-03-24 06:09:15,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7719
[2019-03-24 06:09:15,489] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.93333333333333, 83.66666666666667, 1.0, 2.0, 0.1734361983515775, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2927325334740633, 6.911199999999999, 6.9112, 121.9260426156618, 435069.7337082, 435069.7337082005, 160675.2621442514], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [19.86666666666667, 84.33333333333334, 1.0, 2.0, 0.1735313597836777, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2928051348773633, 6.911199999999999, 6.9112, 121.9260426156618, 435226.7341702249, 435226.7341702253, 160711.8532720295], 
processed observation next is [1.0, 0.8695652173913043, 0.2913580246913582, 0.8433333333333334, 1.0, 1.0, 0.016108761647235355, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11600641859670413, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1554381193465089, 0.15543811934650903, 0.3090612562923644], 
reward next is 0.6909, 
noisyNet noise sample is [array([2.0929406], dtype=float32), -0.27867246]. 
=============================================
[2019-03-24 06:09:19,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7881654e-11 2.8715122e-10 1.0000000e+00 2.7566447e-13 1.7053229e-11], sum to 1.0000
[2019-03-24 06:09:19,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6623
[2019-03-24 06:09:19,286] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.4, 54.0, 1.0, 2.0, 0.4473169055488818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7288626540309239, 6.9112, 6.9112, 121.9260426156618, 1088425.35152318, 1088425.35152318, 236737.5836252861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1269000.0000, 
sim time next is 1269600.0000, 
raw observation next is [26.43333333333333, 53.66666666666666, 1.0, 2.0, 0.4274817962630937, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6969833531197049, 6.9112, 6.9112, 121.9260426156618, 1040963.013841048, 1040963.013841048, 230317.5768567622], 
processed observation next is [1.0, 0.6956521739130435, 0.5345679012345678, 0.5366666666666666, 1.0, 1.0, 0.31843070983701627, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6212291913996312, 0.0, 0.0, 0.8094621288201359, 0.37177250494323144, 0.37177250494323144, 0.442918417032235], 
reward next is 0.5571, 
noisyNet noise sample is [array([-1.0350801], dtype=float32), 1.6185102]. 
=============================================
[2019-03-24 06:09:20,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3984022e-08 3.1411960e-07 9.9999964e-01 7.1362247e-13 1.0306237e-08], sum to 1.0000
[2019-03-24 06:09:20,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2488
[2019-03-24 06:09:20,494] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.53333333333333, 65.33333333333333, 1.0, 2.0, 0.207406990539841, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3393852828896605, 6.911199999999999, 6.9112, 121.9260426156618, 507059.323951068, 507059.3239510685, 170017.9223416151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1280400.0000, 
sim time next is 1281000.0000, 
raw observation next is [24.41666666666666, 66.16666666666667, 1.0, 2.0, 0.2087302856768048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3414531170929873, 6.911199999999999, 6.9112, 121.9260426156618, 510129.2185495688, 510129.2185495693, 170339.3027434797], 
processed observation next is [1.0, 0.8260869565217391, 0.4598765432098763, 0.6616666666666667, 1.0, 1.0, 0.058012244853339036, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1768163963662341, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.182189006624846, 0.1821890066248462, 0.3275755821989994], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.3324746], dtype=float32), -1.1093762]. 
=============================================
[2019-03-24 06:09:20,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.0349  ]
 [72.478966]
 [73.2154  ]
 [73.85866 ]
 [74.51823 ]], R is [[71.59648132]
 [71.55355835]
 [71.51113892]
 [71.46906281]
 [71.4272995 ]].
[2019-03-24 06:09:26,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0574836e-07 3.4600607e-08 9.9999917e-01 5.6038901e-10 5.2452720e-07], sum to 1.0000
[2019-03-24 06:09:26,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3877
[2019-03-24 06:09:26,434] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 34.0, 1.0, 2.0, 0.1773360875571294, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2973005753134328, 6.911199999999999, 6.9112, 121.9260426156618, 442883.4246774926, 442883.4246774931, 161884.9533191128], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1360800.0000, 
sim time next is 1361400.0000, 
raw observation next is [29.25, 35.0, 1.0, 2.0, 0.1763036268920071, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2954410331072967, 6.911199999999999, 6.9112, 121.9260426156618, 440170.6259941357, 440170.6259941361, 161685.3451068202], 
processed observation next is [1.0, 0.782608695652174, 0.6388888888888888, 0.35, 1.0, 1.0, 0.01940907963334178, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11930129138412085, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1572037949979056, 0.15720379499790574, 0.3109333559746542], 
reward next is 0.6891, 
noisyNet noise sample is [array([1.2531129], dtype=float32), -0.62130445]. 
=============================================
[2019-03-24 06:09:27,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1387248e-05 3.6843614e-06 9.9996209e-01 2.1698545e-08 2.8182299e-06], sum to 1.0000
[2019-03-24 06:09:27,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-24 06:09:27,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.25, 55.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2418832331767691, 6.911199999999999, 6.9112, 121.9260426156618, 351274.2787665935, 351274.278766594, 149019.9049831817], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [22.6, 54.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2459587036524087, 6.911199999999999, 6.9112, 121.9260426156618, 358146.8650023618, 358146.8650023623, 150048.3871567976], 
processed observation next is [0.0, 0.2608695652173913, 0.39259259259259266, 0.54, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.057448379565510875, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12790959464370066, 0.12790959464370083, 0.28855459068614925], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8216363], dtype=float32), -1.6642082]. 
=============================================
[2019-03-24 06:09:27,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.1053 ]
 [48.17094]
 [48.24702]
 [48.27435]
 [48.31818]], R is [[47.61452484]
 [47.13837814]
 [46.666996  ]
 [46.20032501]
 [45.73832321]].
[2019-03-24 06:09:28,461] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:09:28,463] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:09:28,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:28,464] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:09:28,465] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:09:28,466] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:09:28,467] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:28,467] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:28,472] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:28,469] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:09:28,476] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:28,487] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-24 06:09:28,515] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-24 06:09:28,535] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-24 06:09:28,560] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-24 06:09:28,560] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-24 06:09:35,325] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:09:35,326] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.3229629, 50.22554354, 1.0, 2.0, 0.2574368988304849, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4116014362270107, 6.911199999999999, 6.9112, 121.9260426156618, 603177.3231128802, 603177.3231128807, 183711.1004007859]
[2019-03-24 06:09:35,327] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:09:35,330] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.7625728e-08 1.9073714e-07 9.9999964e-01 4.3639724e-11 2.0621252e-08], sampled 0.6437894812849211
[2019-03-24 06:09:40,023] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:09:40,025] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 32.66666666666666, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2399950673128363, 6.911199999999999, 6.9112, 121.9260426156618, 342714.4119979753, 342714.4119979757, 124444.910145598]
[2019-03-24 06:09:40,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:09:40,030] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.0481228e-07 8.9389408e-07 9.9999857e-01 4.8717036e-10 1.2257688e-07], sampled 0.9413561039568078
[2019-03-24 06:09:55,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:09:55,952] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.8, 94.66666666666667, 1.0, 2.0, 0.2135190399697647, 0.0, 2.0, 0.0, 1.0, 2.0, 0.352700078879372, 6.911199999999999, 6.9112, 121.9260426156618, 527042.3404397196, 527042.3404397201, 170825.6599349032]
[2019-03-24 06:09:55,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:09:55,961] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.52457915e-07 3.36392304e-07 9.99999523e-01 1.14512025e-10
 4.15077572e-08], sampled 0.9589340755783026
[2019-03-24 06:10:03,140] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:10:03,141] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.16666666666666, 50.33333333333334, 1.0, 2.0, 0.1902287426312736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.316049062181786, 6.9112, 6.9112, 121.9260426156618, 471880.0692645998, 471880.0692645998, 165225.5984169093]
[2019-03-24 06:10:03,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:10:03,146] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7340820e-07 6.1141475e-07 9.9999905e-01 2.7344482e-10 7.9244629e-08], sampled 0.8894381799434894
[2019-03-24 06:10:20,146] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:10:20,148] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.13333333333334, 68.33333333333334, 1.0, 2.0, 0.4082192772686216, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6538303137908346, 6.911199999999999, 6.9112, 122.2973727499453, 962167.3319571167, 962167.3319571172, 225951.2262360377]
[2019-03-24 06:10:20,149] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:10:20,151] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3084266e-07 3.0558087e-07 9.9999952e-01 9.3829222e-11 3.6169542e-08], sampled 0.060257918463161086
[2019-03-24 06:10:32,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:10:32,529] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.15855512, 96.10689663, 1.0, 2.0, 0.3682656920150127, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5862909752641741, 6.9112, 6.9112, 121.9260426156618, 839460.2214594414, 839460.2214594414, 214517.0570040068]
[2019-03-24 06:10:32,530] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:10:32,533] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0595154e-07 2.4327858e-07 9.9999964e-01 6.7587304e-11 2.7739455e-08], sampled 0.24030166894185379
[2019-03-24 06:10:56,663] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:10:56,664] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666666, 84.33333333333334, 1.0, 2.0, 0.2675500958629948, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4268612157186947, 6.9112, 6.9112, 121.9260426156618, 621234.7273526844, 621234.7273526844, 186472.5746870367]
[2019-03-24 06:10:56,665] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:10:56,667] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2841871e-08 1.6680731e-07 9.9999976e-01 3.8663614e-11 1.8509787e-08], sampled 0.02878858434551068
[2019-03-24 06:11:00,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:11:00,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 49.0, 1.0, 2.0, 0.7264506073020018, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9902082486365171, 6.9112, 6.9112, 121.9260426156618, 1549829.297097225, 1549829.297097225, 320808.5482674419]
[2019-03-24 06:11:00,530] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:11:00,533] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5862188e-08 4.0782503e-08 1.0000000e+00 4.1913109e-12 3.5842511e-09], sampled 0.8848614738950885
[2019-03-24 06:11:11,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00690879], dtype=float32), 0.004748329]
[2019-03-24 06:11:11,655] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.7920795, 94.52842382, 1.0, 2.0, 0.2088424017034306, 0.0, 2.0, 0.0, 1.0, 2.0, 0.340224032090253, 6.9112, 6.9112, 121.9260426156618, 507843.322465218, 507843.322465218, 170636.3225831183]
[2019-03-24 06:11:11,655] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:11:11,657] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2417222e-07 2.8464288e-07 9.9999964e-01 8.4793367e-11 3.3415080e-08], sampled 0.46679278676879987
[2019-03-24 06:11:14,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.2396 2831323017.1963 210.0000
[2019-03-24 06:11:14,143] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.9002 2565936088.0889 47.0000
[2019-03-24 06:11:14,339] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7518 2661662861.6380 110.0000
[2019-03-24 06:11:14,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600807368.6641 61.0000
[2019-03-24 06:11:14,644] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.5601 2623860781.5612 97.0000
[2019-03-24 06:11:15,658] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 250000, evaluation results [250000.0, 7157.239583854098, 2831323017.196332, 210.0, 6809.511993196244, 2600807368.6640587, 61.0, 7491.900150621743, 2565936088.088949, 47.0, 6580.751804327726, 2661662861.6380196, 110.0, 7161.560133993777, 2623860781.5611587, 97.0]
[2019-03-24 06:11:16,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2481237e-09 2.2802404e-09 1.0000000e+00 4.2527569e-14 1.1429327e-09], sum to 1.0000
[2019-03-24 06:11:16,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8962
[2019-03-24 06:11:16,537] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.83333333333334, 22.5, 1.0, 2.0, 0.1974001942991696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3287281414718822, 6.9112, 6.9112, 121.9260426156618, 490584.3566642849, 490584.3566642849, 166681.7979376726], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1443000.0000, 
sim time next is 1443600.0000, 
raw observation next is [33.6, 23.0, 1.0, 2.0, 0.1963798520973876, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3271649953824944, 6.911199999999999, 6.9112, 121.9260426156618, 488205.4799265197, 488205.4799265201, 166429.8416243132], 
processed observation next is [0.0, 0.7391304347826086, 0.8, 0.23, 1.0, 1.0, 0.043309347734985223, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.15895624422811797, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17435909997375704, 0.17435909997375718, 0.32005738773906384], 
reward next is 0.6799, 
noisyNet noise sample is [array([-0.39769706], dtype=float32), -0.48670685]. 
=============================================
[2019-03-24 06:11:17,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1371724e-10 5.5225020e-09 1.0000000e+00 1.0448232e-12 3.6202635e-11], sum to 1.0000
[2019-03-24 06:11:17,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5764
[2019-03-24 06:11:17,047] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.43333333333333, 41.0, 1.0, 2.0, 0.1755294343282799, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2951861545382772, 6.911199999999999, 6.9112, 121.9260426156618, 439292.0249526602, 439292.0249526607, 161323.5949873653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1466400.0000, 
sim time next is 1467000.0000, 
raw observation next is [27.15, 42.0, 1.0, 2.0, 0.175477967313483, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2953060127005119, 6.911199999999999, 6.9112, 121.9260426156618, 439364.8634585245, 439364.863458525, 161274.4060083602], 
processed observation next is [0.0, 1.0, 0.561111111111111, 0.42, 1.0, 1.0, 0.018426151563670237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11913251587563983, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15691602266375876, 0.15691602266375893, 0.3101430884776158], 
reward next is 0.6899, 
noisyNet noise sample is [array([-0.00150447], dtype=float32), 0.12713622]. 
=============================================
[2019-03-24 06:11:17,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.371117]
 [63.418594]
 [63.483414]
 [63.51937 ]
 [63.60251 ]], R is [[63.40256882]
 [63.45830536]
 [63.51357269]
 [63.56856537]
 [63.62335205]].
[2019-03-24 06:11:21,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8817807e-09 6.4108319e-10 1.0000000e+00 1.8767776e-12 1.3303088e-09], sum to 1.0000
[2019-03-24 06:11:21,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9593
[2019-03-24 06:11:21,975] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.3, 66.0, 1.0, 2.0, 0.1973585031365062, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3278546008420535, 6.911199999999999, 6.9112, 121.9260426156618, 489523.1114988198, 489523.1114988203, 166816.3257177087], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [23.2, 66.5, 1.0, 2.0, 0.1965200288721692, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3265747087072634, 6.911199999999999, 6.9112, 121.9260426156618, 487579.9581589517, 487579.9581589521, 166608.6462207899], 
processed observation next is [0.0, 1.0, 0.4148148148148148, 0.665, 1.0, 1.0, 0.04347622484782049, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.15821838588407924, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17413569934248277, 0.1741356993424829, 0.32040124273228826], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.5869075], dtype=float32), 1.4175845]. 
=============================================
[2019-03-24 06:11:26,194] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0262810e-07 2.2541016e-07 9.9999952e-01 1.5966461e-10 1.6600427e-07], sum to 1.0000
[2019-03-24 06:11:26,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3669
[2019-03-24 06:11:26,209] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 52.5, 1.0, 2.0, 0.1712510714265247, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2906599121118347, 6.911199999999999, 6.9112, 121.9260426156618, 431021.7576606121, 431021.7576606126, 159911.2999552871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1632600.0000, 
sim time next is 1633200.0000, 
raw observation next is [24.26666666666667, 53.0, 1.0, 2.0, 0.1701497893080163, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2889899143084811, 6.911200000000001, 6.9112, 121.9260426156618, 428417.8693042473, 428417.8693042469, 159640.1562912713], 
processed observation next is [1.0, 0.9130434782608695, 0.4543209876543211, 0.53, 1.0, 1.0, 0.012083082509543213, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11123739288560135, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15300638189437404, 0.1530063818943739, 0.3070003005601371], 
reward next is 0.6930, 
noisyNet noise sample is [array([0.30623165], dtype=float32), 0.17164525]. 
=============================================
[2019-03-24 06:11:26,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8254019e-08 2.4021330e-07 9.9999976e-01 2.0569968e-10 8.0509155e-09], sum to 1.0000
[2019-03-24 06:11:26,690] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3999
[2019-03-24 06:11:26,693] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 62.0, 1.0, 2.0, 0.1605747205333182, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2747956831539229, 6.9112, 6.9112, 121.9260426156618, 405953.2854859546, 405953.2854859546, 157231.9590907313], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1644000.0000, 
sim time next is 1644600.0000, 
raw observation next is [22.26666666666667, 62.5, 1.0, 2.0, 0.1606681358855865, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2748788993589955, 6.911199999999999, 6.9112, 121.9260426156618, 406131.459811271, 406131.4598112715, 157265.5295903841], 
processed observation next is [1.0, 0.0, 0.38024691358024704, 0.625, 1.0, 1.0, 0.0007953998637934609, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.09359862419874437, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14504694993259679, 0.14504694993259698, 0.30243371075073866], 
reward next is 0.6976, 
noisyNet noise sample is [array([-1.3104625], dtype=float32), -0.7465625]. 
=============================================
[2019-03-24 06:11:28,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1846497e-07 1.1322880e-08 9.9999988e-01 4.4462101e-11 3.4314460e-09], sum to 1.0000
[2019-03-24 06:11:28,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9806
[2019-03-24 06:11:28,404] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.35, 88.16666666666667, 1.0, 2.0, 0.1634691626698114, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2821727978410318, 6.911199999999999, 6.9112, 121.9260426156618, 415000.7290615852, 415000.7290615857, 157408.2973052396], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1666200.0000, 
sim time next is 1666800.0000, 
raw observation next is [18.4, 88.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.270733324482954, 6.911199999999999, 6.9112, 121.9260426156618, 398291.2026140668, 398291.2026140673, 155802.3921806759], 
processed observation next is [1.0, 0.30434782608695654, 0.237037037037037, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.0884166556036925, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14224685807645243, 0.1422468580764526, 0.29961998496283826], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6488505], dtype=float32), -0.24714291]. 
=============================================
[2019-03-24 06:11:42,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5153733e-06 1.3741639e-07 9.9999511e-01 4.3074896e-10 1.8720755e-07], sum to 1.0000
[2019-03-24 06:11:42,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0880
[2019-03-24 06:11:42,849] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.86666666666667, 66.0, 1.0, 2.0, 0.2831276507911435, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4512358495316218, 6.911199999999999, 6.9112, 121.9260426156618, 653210.5768685122, 653210.5768685127, 190612.7426100512], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1966200.0000, 
sim time next is 1966800.0000, 
raw observation next is [27.73333333333333, 67.0, 1.0, 2.0, 0.2870224436019045, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4573821221605894, 6.911199999999999, 6.9112, 121.9260426156618, 661537.5250217651, 661537.5250217656, 191650.4888751833], 
processed observation next is [1.0, 0.782608695652174, 0.5827160493827159, 0.67, 1.0, 1.0, 0.151217194764172, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32172765270073667, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23626340179348757, 0.23626340179348773, 0.3685586324522756], 
reward next is 0.6314, 
noisyNet noise sample is [array([1.4041167], dtype=float32), 0.7843492]. 
=============================================
[2019-03-24 06:11:43,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0075834e-07 9.8310302e-06 9.9998999e-01 1.4455295e-09 6.7307461e-08], sum to 1.0000
[2019-03-24 06:11:43,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-24 06:11:43,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333334, 84.33333333333334, 1.0, 2.0, 0.2531080902796654, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4067035753320804, 6.911199999999999, 6.9112, 121.9260426156618, 601442.6010756982, 601442.6010756986, 182209.7610137181], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1977600.0000, 
sim time next is 1978200.0000, 
raw observation next is [22.95, 85.0, 1.0, 2.0, 0.2460648331866176, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3963526844014344, 6.911200000000001, 6.9112, 121.9260426156618, 587764.799474252, 587764.7994742516, 180279.5115960459], 
processed observation next is [1.0, 0.9130434782608695, 0.4055555555555555, 0.85, 1.0, 1.0, 0.10245813474597333, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24544085550179298, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20991599981223288, 0.20991599981223272, 0.3466913684539344], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.14846843], dtype=float32), 0.7982615]. 
=============================================
[2019-03-24 06:11:46,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.5931978e-09 8.3435435e-07 9.9999917e-01 2.5785524e-12 7.8073494e-09], sum to 1.0000
[2019-03-24 06:11:46,378] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-24 06:11:46,388] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.63333333333334, 68.66666666666667, 1.0, 2.0, 0.2164416219195435, 0.0, 2.0, 0.0, 1.0, 2.0, 0.351576275600089, 6.911200000000001, 6.9112, 121.9260426156618, 524263.1166849277, 524263.1166849273, 172589.9699184271], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2024400.0000, 
sim time next is 2025000.0000, 
raw observation next is [24.85, 68.0, 1.0, 2.0, 0.218657034921527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3547609202686759, 6.9112, 6.9112, 121.9260426156618, 528742.4676384599, 528742.4676384599, 173187.0810793163], 
processed observation next is [0.0, 0.43478260869565216, 0.475925925925926, 0.68, 1.0, 1.0, 0.06982980347800832, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.19345115033584484, 0.0, 0.0, 0.8094621288201359, 0.18883659558516425, 0.18883659558516425, 0.33305207899868516], 
reward next is 0.6669, 
noisyNet noise sample is [array([-1.5481457], dtype=float32), -0.27092397]. 
=============================================
[2019-03-24 06:11:46,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.007065]
 [67.004715]
 [67.01315 ]
 [67.0029  ]
 [67.03591 ]], R is [[67.02266693]
 [67.02053833]
 [67.01951599]
 [67.01950836]
 [67.02043152]].
[2019-03-24 06:11:46,458] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1135946e-07 2.3089499e-06 9.9999726e-01 1.1757577e-10 6.9846770e-08], sum to 1.0000
[2019-03-24 06:11:46,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5889
[2019-03-24 06:11:46,466] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 65.0, 1.0, 2.0, 0.2607319555147809, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4169471237116292, 6.9112, 6.9112, 121.9260426156618, 611302.7931325737, 611302.7931325737, 184522.48527113], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2034000.0000, 
sim time next is 2034600.0000, 
raw observation next is [27.35, 64.66666666666667, 1.0, 2.0, 0.2626522206420528, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4198218367891517, 6.911199999999999, 6.9112, 121.9260426156618, 614769.9499536854, 614769.9499536859, 185049.7612277352], 
processed observation next is [0.0, 0.5652173913043478, 0.5685185185185185, 0.6466666666666667, 1.0, 1.0, 0.12220502457387238, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2747772959864396, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2195606964120305, 0.21956069641203066, 0.3558649254379523], 
reward next is 0.6441, 
noisyNet noise sample is [array([-0.58820194], dtype=float32), 0.9030859]. 
=============================================
[2019-03-24 06:11:49,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.22682714e-11 7.17340467e-12 1.00000000e+00 2.76495673e-15
 1.02603925e-10], sum to 1.0000
[2019-03-24 06:11:49,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-24 06:11:49,458] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.53333333333333, 73.66666666666667, 1.0, 2.0, 0.2826865633521532, 0.0, 2.0, 0.0, 1.0, 2.0, 0.450580134432635, 6.9112, 6.9112, 121.9260426156618, 652679.2293577581, 652679.2293577581, 190484.9551473657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2112000.0000, 
sim time next is 2112600.0000, 
raw observation next is [26.76666666666667, 72.83333333333333, 1.0, 2.0, 0.2854834629402814, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4549155449087431, 6.911199999999999, 6.9112, 121.9260426156618, 657829.3039090307, 657829.3039090312, 191250.0614410054], 
processed observation next is [0.0, 0.43478260869565216, 0.5469135802469137, 0.7283333333333333, 1.0, 1.0, 0.1493850749289064, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31864443113592883, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23493903711036812, 0.2349390371103683, 0.36778857969424117], 
reward next is 0.6322, 
noisyNet noise sample is [array([-0.488573], dtype=float32), 1.0700785]. 
=============================================
[2019-03-24 06:11:51,640] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7695428e-08 2.8174739e-08 1.0000000e+00 5.3825840e-11 5.0099818e-09], sum to 1.0000
[2019-03-24 06:11:51,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1160
[2019-03-24 06:11:51,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.25, 49.5, 1.0, 2.0, 0.2841757507314682, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4528964994845996, 6.911199999999999, 6.9112, 121.9260426156618, 655526.4354074282, 655526.4354074287, 190889.5608874546], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [31.33333333333334, 49.0, 1.0, 2.0, 0.2832110650127285, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4513991962538886, 6.911199999999999, 6.9112, 121.9260426156618, 653718.6226257801, 653718.6226257805, 190626.4396565207], 
processed observation next is [0.0, 0.6521739130434783, 0.7160493827160496, 0.49, 1.0, 1.0, 0.14667983930086728, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31424899531736067, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2334709366520643, 0.23347093665206448, 0.36658930703177056], 
reward next is 0.6334, 
noisyNet noise sample is [array([-1.8273152], dtype=float32), -0.73632056]. 
=============================================
[2019-03-24 06:11:51,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[55.411526]
 [55.450592]
 [55.500233]
 [55.565407]
 [55.59916 ]], R is [[55.4164505 ]
 [55.49518967]
 [55.57271194]
 [55.64897156]
 [55.72385788]].
[2019-03-24 06:11:51,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3061987e-07 3.7314436e-07 9.9999952e-01 3.7694310e-09 1.8308553e-08], sum to 1.0000
[2019-03-24 06:11:51,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8308
[2019-03-24 06:11:51,710] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.53333333333333, 80.0, 1.0, 2.0, 0.2880869411373666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4591696971293928, 6.9112, 6.9112, 121.9260426156618, 664968.2585509312, 664968.2585509312, 191906.3801217674], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2157600.0000, 
sim time next is 2158200.0000, 
raw observation next is [25.45, 80.5, 1.0, 2.0, 0.2876070842374012, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4584175561894611, 6.911199999999999, 6.9112, 121.9260426156618, 663989.3012820509, 663989.3012820514, 191776.7095184272], 
processed observation next is [0.0, 1.0, 0.4981481481481481, 0.805, 1.0, 1.0, 0.15191319552071575, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32302194523682637, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23713903617216103, 0.2371390361721612, 0.36880136445851386], 
reward next is 0.6312, 
noisyNet noise sample is [array([-0.98984957], dtype=float32), 0.48363978]. 
=============================================
[2019-03-24 06:11:52,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.4752363e-07 5.0336830e-06 9.9999368e-01 7.8696868e-11 3.7279287e-07], sum to 1.0000
[2019-03-24 06:11:52,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-24 06:11:52,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.61666666666667, 79.50000000000001, 1.0, 2.0, 0.2884737715004826, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4597725751965148, 6.911199999999999, 6.9112, 121.9260426156618, 665720.6355223367, 665720.6355223372, 192011.8897732603], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2157000.0000, 
sim time next is 2157600.0000, 
raw observation next is [25.53333333333333, 80.0, 1.0, 2.0, 0.2880869411373666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4591696971293928, 6.9112, 6.9112, 121.9260426156618, 664968.2585509312, 664968.2585509312, 191906.3801217674], 
processed observation next is [0.0, 1.0, 0.5012345679012346, 0.8, 1.0, 1.0, 0.15248445373496025, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32396212141174097, 0.0, 0.0, 0.8094621288201359, 0.23748866376818972, 0.23748866376818972, 0.36905073100339886], 
reward next is 0.6309, 
noisyNet noise sample is [array([0.47815728], dtype=float32), 0.54133373]. 
=============================================
[2019-03-24 06:12:01,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6493477e-09 2.4721271e-07 9.9999976e-01 1.6318090e-10 2.8026589e-08], sum to 1.0000
[2019-03-24 06:12:01,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2683
[2019-03-24 06:12:01,340] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.71666666666667, 69.5, 1.0, 2.0, 0.2494030975004532, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4005554070550124, 6.911199999999999, 6.9112, 121.9260426156618, 591961.3499537823, 591961.3499537827, 181330.8608108834], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2310600.0000, 
sim time next is 2311200.0000, 
raw observation next is [25.6, 70.0, 1.0, 2.0, 0.2510245644184377, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4032437353905943, 6.911199999999999, 6.9112, 121.9260426156618, 596105.1368709797, 596105.1368709801, 181715.2191596316], 
processed observation next is [1.0, 0.782608695652174, 0.5037037037037038, 0.7, 1.0, 1.0, 0.10836257668861629, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2540546692382429, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2128946917396356, 0.21289469173963577, 0.3494523445377531], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.9337641], dtype=float32), 0.8337496]. 
=============================================
[2019-03-24 06:12:03,288] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9907291e-06 1.4703792e-07 9.9999535e-01 1.3105496e-10 5.8172708e-07], sum to 1.0000
[2019-03-24 06:12:03,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6024
[2019-03-24 06:12:03,301] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 41.5, 1.0, 2.0, 0.3896527339392219, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6472913356975561, 6.9112, 6.9112, 121.9260426156618, 966779.5718291216, 966779.5718291216, 217189.4524245115], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2363400.0000, 
sim time next is 2364000.0000, 
raw observation next is [27.8, 41.33333333333334, 1.0, 2.0, 0.3636810776435743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6034101143525111, 6.9112, 6.9112, 121.9260426156618, 901393.1039348674, 901393.1039348674, 209608.5727935475], 
processed observation next is [1.0, 0.34782608695652173, 0.5851851851851853, 0.41333333333333344, 1.0, 1.0, 0.24247747338520753, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5042626429406388, 0.0, 0.0, 0.8094621288201359, 0.32192610854816694, 0.32192610854816694, 0.40309340921836057], 
reward next is 0.5969, 
noisyNet noise sample is [array([-0.65797293], dtype=float32), -1.518436]. 
=============================================
[2019-03-24 06:12:03,322] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.088524]
 [62.204296]
 [62.738403]
 [62.7224  ]
 [62.719185]], R is [[61.96070862]
 [61.9234314 ]
 [61.9186821 ]
 [61.980793  ]
 [62.03690338]].
[2019-03-24 06:12:03,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0314793e-09 7.4258871e-08 9.9999988e-01 2.3398039e-11 1.7975172e-08], sum to 1.0000
[2019-03-24 06:12:03,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-24 06:12:03,671] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 39.33333333333334, 1.0, 2.0, 0.4689542353530016, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7687781996105643, 6.9112, 6.9112, 121.9260426156618, 1149310.075168503, 1149310.075168503, 243341.551544018], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2371200.0000, 
sim time next is 2371800.0000, 
raw observation next is [29.2, 39.16666666666666, 1.0, 2.0, 0.4701345952641549, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7703033282544092, 6.911199999999999, 6.9112, 121.9260426156618, 1151535.368243787, 1151535.368243787, 243779.8862398479], 
processed observation next is [1.0, 0.43478260869565216, 0.637037037037037, 0.39166666666666655, 1.0, 1.0, 0.3692078515049463, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7128791603180115, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4112626315156382, 0.4112626315156382, 0.46880747353816904], 
reward next is 0.5312, 
noisyNet noise sample is [array([-0.1806476], dtype=float32), 0.921115]. 
=============================================
[2019-03-24 06:12:03,841] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 06:12:03,843] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:12:03,843] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:12:03,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:12:03,843] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:12:03,844] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:12:03,845] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:12:03,846] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:12:03,845] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:12:03,849] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:12:03,850] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:12:03,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-24 06:12:03,863] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-24 06:12:03,915] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-24 06:12:03,915] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-24 06:12:03,916] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-24 06:12:16,318] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:12:16,320] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.56666666666666, 45.16666666666667, 1.0, 2.0, 0.1964587447298523, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3250427006150483, 6.911199999999999, 6.9112, 121.9260426156618, 485620.5909410791, 485620.5909410795, 166856.0362540202]
[2019-03-24 06:12:16,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:12:16,323] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5905150e-07 2.8446107e-07 9.9999964e-01 9.2545430e-11 4.4818655e-08], sampled 0.8400734854714481
[2019-03-24 06:12:44,301] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:12:44,302] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.41666666666666, 69.83333333333333, 1.0, 2.0, 0.3484800663507395, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5547916148338091, 6.911199999999999, 6.9112, 121.9260426156618, 794335.593520399, 794335.5935203994, 208734.0718167681]
[2019-03-24 06:12:44,304] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:12:44,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1102609e-07 1.9381493e-07 9.9999964e-01 5.3998469e-11 2.9462843e-08], sampled 0.7336365698487993
[2019-03-24 06:12:54,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:12:54,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 79.0, 1.0, 2.0, 0.4709644815577524, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7497907928822878, 6.911199999999999, 6.9112, 121.9260426156618, 1073725.719861967, 1073725.719861968, 247016.9228018505]
[2019-03-24 06:12:54,270] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:12:54,272] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3130769e-07 2.2751243e-07 9.9999964e-01 7.1098204e-11 3.4958173e-08], sampled 0.8295498756242928
[2019-03-24 06:12:57,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:12:57,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.3288623713128148, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5235596054297098, 6.911199999999999, 6.9112, 121.9260426156618, 749596.5838607415, 749596.5838607418, 203163.7784302259]
[2019-03-24 06:12:57,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:12:57,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6904033e-07 2.8993520e-07 9.9999964e-01 9.9713765e-11 4.6269321e-08], sampled 0.3906443604144625
[2019-03-24 06:13:13,821] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:13:13,822] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.46666666666667, 86.0, 1.0, 2.0, 0.1907138418979806, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3170820396391636, 6.911199999999999, 6.9112, 121.9260426156618, 473357.910362334, 473357.9103623345, 165290.861395985]
[2019-03-24 06:13:13,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:13:13,826] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3980589e-07 2.4485553e-07 9.9999964e-01 7.5127626e-11 3.8531521e-08], sampled 0.6023527095807764
[2019-03-24 06:13:28,555] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:13:28,559] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.06666666666667, 55.0, 1.0, 2.0, 0.3619393643038852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5821135662456025, 6.911199999999999, 6.9112, 121.9260426156618, 861970.0867458957, 861970.0867458961, 211539.0116763067]
[2019-03-24 06:13:28,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:13:28,562] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4408212e-07 2.4894686e-07 9.9999964e-01 8.0290843e-11 3.8926203e-08], sampled 0.6176930274254985
[2019-03-24 06:13:36,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:13:36,574] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.95367062, 82.59051074999999, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2547649107348219, 6.9112, 6.9112, 121.9260426156618, 373692.4068190277, 373692.4068190277, 152595.6277932202]
[2019-03-24 06:13:36,574] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:13:36,578] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0090145e-07 1.7876640e-07 9.9999976e-01 4.5617739e-11 2.7715394e-08], sampled 0.591934783603758
[2019-03-24 06:13:48,125] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00703144], dtype=float32), 0.004909824]
[2019-03-24 06:13:48,126] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.33333333333333, 81.66666666666667, 1.0, 2.0, 0.3466481424224238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5708973831074768, 6.9112, 6.9112, 121.9260426156618, 853424.1768704399, 853424.1768704399, 205253.3640799759]
[2019-03-24 06:13:48,128] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:13:48,132] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.7901277e-08 1.5250855e-07 9.9999976e-01 3.7353034e-11 2.3487321e-08], sampled 0.8718092829112551
[2019-03-24 06:13:49,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7487 2661640729.3871 110.0000
[2019-03-24 06:13:49,851] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7490.4975 2565924950.4796 47.0000
[2019-03-24 06:13:49,926] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6810.3343 2600751341.6916 61.0000
[2019-03-24 06:13:50,062] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7164.4722 2623746151.4225 97.0000
[2019-03-24 06:13:50,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7158.0105 2831283678.6220 210.0000
[2019-03-24 06:13:51,166] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 275000, evaluation results [275000.0, 7158.010523565507, 2831283678.621974, 210.0, 6810.334324083558, 2600751341.691554, 61.0, 7490.497536420795, 2565924950.479642, 47.0, 6580.748729497854, 2661640729.3870745, 110.0, 7164.472177343485, 2623746151.422472, 97.0]
[2019-03-24 06:13:57,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9816730e-08 1.8340880e-07 9.9999976e-01 1.5627018e-12 1.4109248e-08], sum to 1.0000
[2019-03-24 06:13:57,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0689
[2019-03-24 06:13:57,912] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.43333333333334, 39.66666666666666, 1.0, 2.0, 0.1859294593260825, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3096691278712665, 6.911199999999999, 6.9112, 121.9260426156618, 462118.4389293514, 462118.4389293519, 164134.470379524], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2497200.0000, 
sim time next is 2497800.0000, 
raw observation next is [28.26666666666667, 40.33333333333334, 1.0, 2.0, 0.1860150267072862, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3098041525214388, 6.911199999999999, 6.9112, 121.9260426156618, 462322.4798551124, 462322.4798551129, 164154.7464070008], 
processed observation next is [1.0, 0.9130434782608695, 0.6024691358024692, 0.40333333333333343, 1.0, 1.0, 0.030970269889626426, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13725519065179845, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16511517137682585, 0.16511517137682605, 0.3156822046288477], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.3208331], dtype=float32), 1.5097039]. 
=============================================
[2019-03-24 06:14:00,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5345910e-07 2.0300977e-06 9.9999142e-01 1.2224107e-09 6.0000507e-06], sum to 1.0000
[2019-03-24 06:14:00,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6666
[2019-03-24 06:14:00,906] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.5, 30.0, 1.0, 2.0, 0.6969765607577699, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9581936063784067, 6.9112, 6.9112, 121.9260426156618, 1558333.299173223, 1558333.299173223, 306468.2182838047], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2548200.0000, 
sim time next is 2548800.0000, 
raw observation next is [32.6, 30.0, 1.0, 2.0, 0.624589263921651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9583722956780631, 6.9112, 6.9112, 121.9260426156618, 1470178.021323208, 1470178.021323208, 293635.93613077], 
processed observation next is [1.0, 0.5217391304347826, 0.7629629629629631, 0.3, 1.0, 1.0, 0.5530824570495846, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9479653695975789, 0.0, 0.0, 0.8094621288201359, 0.5250635790440028, 0.5250635790440028, 0.5646844925591731], 
reward next is 0.4353, 
noisyNet noise sample is [array([0.653577], dtype=float32), -1.1081682]. 
=============================================
[2019-03-24 06:14:01,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0259829e-07 5.1092311e-06 9.9999237e-01 7.5455722e-09 2.1053281e-06], sum to 1.0000
[2019-03-24 06:14:01,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0772
[2019-03-24 06:14:01,163] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.76666666666667, 30.16666666666666, 1.0, 2.0, 0.8994293931108578, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9656468583828018, 6.911199999999999, 6.9112, 121.9260426156618, 1784682.008686913, 1784682.008686913, 350558.3118282714], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2556600.0000, 
sim time next is 2557200.0000, 
raw observation next is [33.73333333333333, 30.33333333333334, 1.0, 2.0, 0.8696086888118701, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9657132083399886, 6.9112, 6.9112, 121.9260426156618, 1749046.283728372, 1749046.283728372, 344106.8991654426], 
processed observation next is [1.0, 0.6086956521739131, 0.804938271604938, 0.3033333333333334, 1.0, 1.0, 0.8447722485855597, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9571415104249859, 0.0, 0.0, 0.8094621288201359, 0.6246593870458471, 0.6246593870458471, 0.6617440368566204], 
reward next is 0.3383, 
noisyNet noise sample is [array([-1.6787021], dtype=float32), -0.45042133]. 
=============================================
[2019-03-24 06:14:05,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3525564e-07 4.7205198e-08 9.9999928e-01 1.0630477e-10 4.8712456e-09], sum to 1.0000
[2019-03-24 06:14:05,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2753
[2019-03-24 06:14:05,163] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.73333333333334, 84.33333333333334, 1.0, 2.0, 0.2870422453978838, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4577438068713591, 6.911199999999999, 6.9112, 121.9260426156618, 664784.0346797326, 664784.0346797331, 191571.2370066661], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2665200.0000, 
sim time next is 2665800.0000, 
raw observation next is [24.55, 85.5, 1.0, 2.0, 0.2877059708768899, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4588319698780817, 6.911199999999999, 6.9112, 121.9260426156618, 666573.234517862, 666573.2345178624, 191738.659459798], 
processed observation next is [0.0, 0.8695652173913043, 0.46481481481481485, 0.855, 1.0, 1.0, 0.15203091771058325, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32353996234760213, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.238061869470665, 0.23806186947066516, 0.36872819126884226], 
reward next is 0.6313, 
noisyNet noise sample is [array([-0.02110745], dtype=float32), -0.7543164]. 
=============================================
[2019-03-24 06:14:05,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3324976e-09 1.7481019e-08 1.0000000e+00 2.0632577e-13 3.6189418e-09], sum to 1.0000
[2019-03-24 06:14:05,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-24 06:14:05,642] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 87.66666666666667, 1.0, 2.0, 0.2741083650887592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4378674142105303, 6.911200000000001, 6.9112, 121.9260426156618, 640082.8378376578, 640082.8378376573, 188030.12819727], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2629200.0000, 
sim time next is 2629800.0000, 
raw observation next is [23.75, 87.0, 1.0, 2.0, 0.2704880838778864, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4324666057769616, 6.9112, 6.9112, 121.9260426156618, 633760.4096457134, 633760.4096457134, 187017.6420215803], 
processed observation next is [0.0, 0.43478260869565216, 0.4351851851851852, 0.87, 1.0, 1.0, 0.13153343318796, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.290583257221202, 0.0, 0.0, 0.8094621288201359, 0.22634300344489763, 0.22634300344489763, 0.3596493115799621], 
reward next is 0.6404, 
noisyNet noise sample is [array([-0.37532398], dtype=float32), -0.16604622]. 
=============================================
[2019-03-24 06:14:12,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6705492e-06 7.4783151e-07 9.9999094e-01 9.8123565e-11 6.9824989e-07], sum to 1.0000
[2019-03-24 06:14:12,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3439
[2019-03-24 06:14:12,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.63333333333333, 86.0, 1.0, 2.0, 0.4089757543696327, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6511027203668988, 6.911199999999999, 6.9112, 121.9260426156618, 932315.0957575429, 932315.0957575433, 226885.3212892899], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2791200.0000, 
sim time next is 2791800.0000, 
raw observation next is [25.95, 84.5, 1.0, 2.0, 0.4345566739040032, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918283773780031, 6.9112, 6.9112, 121.9260426156618, 990667.9273574271, 990667.9273574271, 235003.4424082596], 
processed observation next is [1.0, 0.30434782608695654, 0.5166666666666666, 0.845, 1.0, 1.0, 0.32685318321905144, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6147854717225038, 0.0, 0.0, 0.8094621288201359, 0.35380997405622394, 0.35380997405622394, 0.4519296969389608], 
reward next is 0.5481, 
noisyNet noise sample is [array([0.43795496], dtype=float32), -0.872025]. 
=============================================
[2019-03-24 06:14:13,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4174483e-07 1.3666808e-07 9.9999917e-01 1.1183617e-08 3.9245410e-08], sum to 1.0000
[2019-03-24 06:14:13,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9041
[2019-03-24 06:14:13,073] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.3460181720678437, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5508721989571399, 6.911199999999999, 6.9112, 121.9260426156618, 788720.9928784597, 788720.9928784602, 208025.2880203486], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2790000.0000, 
sim time next is 2790600.0000, 
raw observation next is [25.31666666666667, 87.5, 1.0, 2.0, 0.3646451314177276, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5805269248798693, 6.911199999999999, 6.9112, 121.9260426156618, 831202.6923833875, 831202.6923833879, 213439.6559612453], 
processed observation next is [1.0, 0.30434782608695654, 0.49320987654321, 0.875, 1.0, 1.0, 0.2436251564496757, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47565865609983665, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2968581044226384, 0.29685810442263855, 0.41046087684854865], 
reward next is 0.5895, 
noisyNet noise sample is [array([0.9249656], dtype=float32), -0.51069105]. 
=============================================
[2019-03-24 06:14:13,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6689792e-05 2.9023347e-06 9.9998009e-01 9.2155450e-10 3.1065650e-07], sum to 1.0000
[2019-03-24 06:14:13,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6078
[2019-03-24 06:14:13,325] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 91.5, 1.0, 2.0, 0.2998743406361051, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4786899285269207, 6.9112, 6.9112, 121.9260426156618, 698151.6222518362, 698151.6222518362, 194869.4870745188], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2784600.0000, 
sim time next is 2785200.0000, 
raw observation next is [23.66666666666667, 90.66666666666666, 1.0, 2.0, 0.2974400222392327, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4746905061438255, 6.911199999999999, 6.9112, 121.9260426156618, 691700.2843428763, 691700.2843428768, 194243.3012987351], 
processed observation next is [1.0, 0.21739130434782608, 0.43209876543209896, 0.9066666666666666, 1.0, 1.0, 0.16361907409432466, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34336313267978186, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24703581583674153, 0.2470358158367417, 0.37354481018987523], 
reward next is 0.6265, 
noisyNet noise sample is [array([-1.2141228], dtype=float32), 0.18028612]. 
=============================================
[2019-03-24 06:14:15,263] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6405417e-08 2.9748466e-07 9.9999940e-01 4.7806554e-09 2.1274832e-07], sum to 1.0000
[2019-03-24 06:14:15,276] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8324
[2019-03-24 06:14:15,284] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.2724713171942328, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4356929416048398, 6.9112, 6.9112, 121.9260426156618, 638698.3872514422, 638698.3872514422, 187514.4581373856], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2853000.0000, 
sim time next is 2853600.0000, 
raw observation next is [22.66666666666666, 96.0, 1.0, 2.0, 0.2732228131756042, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4367848568043565, 6.911199999999999, 6.9112, 121.9260426156618, 639883.7637113736, 639883.763711374, 187730.6875090062], 
processed observation next is [1.0, 0.0, 0.3950617283950615, 0.96, 1.0, 1.0, 0.13478906330429072, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.29598107100544563, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22852991561120484, 0.228529915611205, 0.361020552901935], 
reward next is 0.6390, 
noisyNet noise sample is [array([-1.1079227], dtype=float32), 0.47475925]. 
=============================================
[2019-03-24 06:14:16,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1414686e-07 5.1023296e-08 9.9999964e-01 9.7234373e-12 1.1377629e-08], sum to 1.0000
[2019-03-24 06:14:16,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7788
[2019-03-24 06:14:16,396] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.2769641363859059, 0.0, 2.0, 0.0, 1.0, 2.0, 0.44255595739796, 6.911199999999999, 6.9112, 121.9260426156618, 647491.8079330726, 647491.807933073, 188739.8814190305], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2854800.0000, 
sim time next is 2855400.0000, 
raw observation next is [22.91666666666667, 93.50000000000001, 1.0, 2.0, 0.2742352732089408, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4384394759342528, 6.911199999999999, 6.9112, 121.9260426156618, 642447.5054091265, 642447.5054091269, 187983.4596099157], 
processed observation next is [1.0, 0.043478260869565216, 0.4043209876543212, 0.9350000000000002, 1.0, 1.0, 0.13599437286778668, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.298049344917816, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2294455376461166, 0.22944553764611675, 0.3615066530959917], 
reward next is 0.6385, 
noisyNet noise sample is [array([-0.7788027], dtype=float32), -1.5453203]. 
=============================================
[2019-03-24 06:14:16,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.9263224e-10 4.0850834e-09 1.0000000e+00 2.7304857e-13 1.1304110e-08], sum to 1.0000
[2019-03-24 06:14:16,640] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2660
[2019-03-24 06:14:16,645] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.4, 94.0, 1.0, 2.0, 0.289272178110847, 0.0, 2.0, 0.0, 1.0, 2.0, 0.463728586970868, 6.911199999999999, 6.9112, 121.9260426156618, 683408.4484021887, 683408.4484021892, 191656.6083673539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2869200.0000, 
sim time next is 2869800.0000, 
raw observation next is [22.33333333333334, 94.00000000000001, 1.0, 2.0, 0.2871326638682727, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4605155228109871, 6.9112, 6.9112, 121.9260426156618, 679207.9421276815, 679207.9421276815, 191053.6835831213], 
processed observation next is [1.0, 0.21739130434782608, 0.38271604938271625, 0.9400000000000002, 1.0, 1.0, 0.1513484093669913, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32564440351373386, 0.0, 0.0, 0.8094621288201359, 0.2425742650456005, 0.2425742650456005, 0.367410929967541], 
reward next is 0.6326, 
noisyNet noise sample is [array([0.9384881], dtype=float32), -1.530925]. 
=============================================
[2019-03-24 06:14:19,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0768679e-07 5.8865631e-08 9.9999988e-01 1.7157507e-10 3.5247267e-09], sum to 1.0000
[2019-03-24 06:14:19,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2408
[2019-03-24 06:14:19,559] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3425109631862427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5452886081958119, 6.9112, 6.9112, 121.9260426156618, 780722.5168627085, 780722.5168627085, 207024.1181883372], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2929800.0000, 
sim time next is 2930400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3424704587966064, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5452241238883752, 6.911199999999999, 6.9112, 121.9260426156618, 780630.1437848256, 780630.143784826, 207012.5539758367], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.89, 1.0, 1.0, 0.2172267366626267, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4315301548604689, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.278796479923152, 0.27879647992315215, 0.3981010653381475], 
reward next is 0.6019, 
noisyNet noise sample is [array([0.3179249], dtype=float32), 0.5495712]. 
=============================================
[2019-03-24 06:14:24,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1750427e-09 6.0024191e-10 1.0000000e+00 4.0024326e-14 6.0277050e-10], sum to 1.0000
[2019-03-24 06:14:24,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6394
[2019-03-24 06:14:24,664] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 95.0, 1.0, 2.0, 0.4076335696492001, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6489659185800652, 6.911199999999999, 6.9112, 121.9260426156618, 929253.5505848766, 929253.550584877, 226468.1826038717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3035400.0000, 
sim time next is 3036000.0000, 
raw observation next is [25.0, 96.0, 1.0, 2.0, 0.367795724412698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5855427715355127, 6.911199999999999, 6.9112, 121.9260426156618, 838388.3461991163, 838388.3461991167, 214371.3630288927], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.96, 1.0, 1.0, 0.247375862396069, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48192846441939086, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29942440935682724, 0.2994244093568274, 0.41225262120940903], 
reward next is 0.5877, 
noisyNet noise sample is [array([-0.05845564], dtype=float32), -0.42971304]. 
=============================================
[2019-03-24 06:14:24,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.14151 ]
 [64.599884]
 [64.86134 ]
 [64.706154]
 [64.913635]], R is [[64.12421417]
 [64.04745483]
 [63.98707581]
 [63.92370987]
 [63.85668564]].
[2019-03-24 06:14:32,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7862513e-07 8.2698868e-08 9.9999976e-01 8.5809165e-13 7.3335149e-10], sum to 1.0000
[2019-03-24 06:14:32,889] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8111
[2019-03-24 06:14:32,893] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.0, 32.0, 1.0, 2.0, 0.2334469235632098, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3758181667991389, 6.911199999999999, 6.9112, 121.9260426156618, 556982.5311336388, 556982.5311336393, 177256.9268407444], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3175200.0000, 
sim time next is 3175800.0000, 
raw observation next is [33.83333333333334, 33.0, 1.0, 2.0, 0.2386907109263997, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3839938450625623, 6.9112, 6.9112, 121.9260426156618, 568670.7461727466, 568670.7461727466, 178576.5183970683], 
processed observation next is [1.0, 0.782608695652174, 0.8086419753086423, 0.33, 1.0, 1.0, 0.09367941776952346, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.22999230632820283, 0.0, 0.0, 0.8094621288201359, 0.20309669506169523, 0.20309669506169523, 0.34341638153282367], 
reward next is 0.6566, 
noisyNet noise sample is [array([-1.3647108], dtype=float32), -0.88640326]. 
=============================================
[2019-03-24 06:14:32,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0407633e-09 2.1101170e-09 1.0000000e+00 5.4327051e-13 1.6841739e-10], sum to 1.0000
[2019-03-24 06:14:32,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2441
[2019-03-24 06:14:32,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666666, 76.16666666666667, 1.0, 2.0, 0.3130350027325569, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4983619191885308, 6.911199999999999, 6.9112, 121.9260426156618, 713503.4822012775, 713503.482201278, 198780.6762511596], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3192600.0000, 
sim time next is 3193200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3216778626318957, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5121216336265743, 6.911199999999999, 6.9112, 121.9260426156618, 733212.6515237777, 733212.6515237781, 201161.8051272096], 
processed observation next is [1.0, 1.0, 0.5555555555555556, 0.79, 1.0, 1.0, 0.192473645990352, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3901520420332178, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26186166125849203, 0.2618616612584922, 0.38684962524463384], 
reward next is 0.6132, 
noisyNet noise sample is [array([-0.5359029], dtype=float32), 1.4460001]. 
=============================================
[2019-03-24 06:14:33,001] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7382593e-11 1.6188791e-10 1.0000000e+00 6.9005923e-13 5.5526087e-11], sum to 1.0000
[2019-03-24 06:14:33,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7394
[2019-03-24 06:14:33,012] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.55, 85.0, 1.0, 2.0, 0.2897242295985258, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4620615782937903, 6.911199999999999, 6.9112, 121.9260426156618, 671342.2983639446, 671342.2983639451, 192267.9222642426], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3205800.0000, 
sim time next is 3206400.0000, 
raw observation next is [24.36666666666667, 84.33333333333333, 1.0, 2.0, 0.2817755209505938, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4498858966085693, 6.911199999999999, 6.9112, 121.9260426156618, 656571.9675763813, 656571.9675763818, 190066.3398734307], 
processed observation next is [0.0, 0.08695652173913043, 0.4580246913580248, 0.8433333333333333, 1.0, 1.0, 0.14497085827451647, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31235737076071163, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2344899884201362, 0.23448998842013635, 0.3655121920642898], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.3519445], dtype=float32), 1.042661]. 
=============================================
[2019-03-24 06:14:33,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8474393e-09 1.0424688e-07 9.9999988e-01 8.2877376e-14 4.0247325e-10], sum to 1.0000
[2019-03-24 06:14:33,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4606
[2019-03-24 06:14:33,065] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.33333333333334, 36.0, 1.0, 2.0, 0.2440265744654949, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3915151107768152, 6.911199999999999, 6.9112, 121.9260426156618, 577719.2620113569, 577719.2620113574, 180091.609986259], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3177600.0000, 
sim time next is 3178200.0000, 
raw observation next is [33.16666666666666, 37.0, 1.0, 2.0, 0.2468048588419459, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3956671524176223, 6.911199999999999, 6.9112, 121.9260426156618, 583110.6988813381, 583110.6988813386, 180837.1175874101], 
processed observation next is [1.0, 0.782608695652174, 0.7839506172839502, 0.37, 1.0, 1.0, 0.1033391176689832, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24458394052202784, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20825382102904932, 0.2082538210290495, 0.34776368766809634], 
reward next is 0.6522, 
noisyNet noise sample is [array([-0.93236375], dtype=float32), 0.06369323]. 
=============================================
[2019-03-24 06:14:39,232] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 06:14:39,235] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:14:39,235] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:14:39,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:39,239] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:14:39,239] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:39,238] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:14:39,241] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:14:39,244] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:39,246] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:39,245] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:39,261] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-24 06:14:39,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-24 06:14:39,262] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-24 06:14:39,335] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-24 06:14:39,335] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-24 06:14:40,613] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:14:40,615] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.76666666666667, 78.16666666666667, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.9260426156618, 265888.3951282164, 265888.3951282168, 120739.9722427131]
[2019-03-24 06:14:40,617] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:14:40,619] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.7886710e-07 5.5322806e-07 9.9999905e-01 3.4499281e-10 3.1586882e-08], sampled 0.8048101270176217
[2019-03-24 06:14:41,337] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:14:41,338] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.817570465, 44.321527395, 1.0, 2.0, 0.1751392223908915, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2936154914180991, 6.9112, 6.9112, 121.9260426156618, 437393.2027563363, 437393.2027563363, 161409.8595963324]
[2019-03-24 06:14:41,338] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:14:41,340] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5452635e-10 1.5536726e-09 1.0000000e+00 4.4574885e-14 2.2995255e-11], sampled 0.6496173461243849
[2019-03-24 06:14:58,214] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:14:58,216] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.85, 17.5, 1.0, 2.0, 0.3940132297745723, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6416232934178373, 6.911199999999999, 6.9112, 121.9260426156618, 957899.9687223135, 957899.968722314, 220033.8729654821]
[2019-03-24 06:14:58,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:14:58,222] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3034043e-09 2.1365343e-09 1.0000000e+00 7.3128156e-14 3.4271783e-11], sampled 0.9620534353855122
[2019-03-24 06:15:07,550] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:15:07,551] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.83333333333334, 57.66666666666666, 1.0, 2.0, 0.1833923090597802, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3044520662844996, 6.911199999999999, 6.9112, 121.9260426156618, 454624.0882119189, 454624.0882119194, 163762.8504908861]
[2019-03-24 06:15:07,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:15:07,554] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.07561762e-10 6.61204980e-10 1.00000000e+00 1.23793925e-14
 8.57500008e-12], sampled 0.5417763326764568
[2019-03-24 06:15:08,345] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:15:08,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.86328057666667, 80.51550946666667, 1.0, 2.0, 0.2602868359277094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4175260480308918, 6.911199999999999, 6.9112, 121.9260426156618, 615937.2626428857, 615937.2626428861, 184142.8833888657]
[2019-03-24 06:15:08,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:15:08,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6066877e-10 5.8767641e-10 1.0000000e+00 1.0269770e-14 7.1355916e-12], sampled 0.1131178610665472
[2019-03-24 06:15:20,027] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:15:20,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.00000000000001, 1.0, 2.0, 0.3914614391139913, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6232193600784914, 6.911199999999999, 6.9112, 121.9260426156618, 892365.6193357643, 892365.6193357648, 221480.1514766958]
[2019-03-24 06:15:20,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:15:20,031] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3004542e-09 2.0256408e-09 1.0000000e+00 7.2032319e-14 3.3004398e-11], sampled 0.33445170967825466
[2019-03-24 06:15:26,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:15:26,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.26138707, 90.76713966, 1.0, 2.0, 0.3075704502440532, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4897897665669747, 6.9112, 6.9112, 121.9260426156618, 704164.0846253128, 704164.0846253128, 197238.2942233925]
[2019-03-24 06:15:26,028] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:15:26,030] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.4626955e-10 7.1681189e-10 1.0000000e+00 1.4129461e-14 9.3472504e-12], sampled 0.5993255429742655
[2019-03-24 06:15:51,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:15:51,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.13333333333333, 63.33333333333333, 1.0, 2.0, 0.3094992326877331, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4927328581251801, 6.911199999999999, 6.9112, 121.9260426156618, 705440.6616805027, 705440.6616805032, 197814.896520491]
[2019-03-24 06:15:51,385] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:15:51,387] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.8609725e-10 1.4244662e-09 1.0000000e+00 3.9927493e-14 2.0680744e-11], sampled 0.46720516553488345
[2019-03-24 06:16:06,363] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:16:06,364] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.042491615, 76.62683298833333, 1.0, 2.0, 0.3501085489033033, 0.0, 2.0, 0.0, 1.0, 2.0, 0.557384212093465, 6.911199999999999, 6.9112, 121.9260426156618, 798049.5364334093, 798049.5364334098, 209208.3809632987]
[2019-03-24 06:16:06,365] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:16:06,369] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1779026e-10 9.8766295e-10 1.0000000e+00 2.3450593e-14 1.3644886e-11], sampled 0.6516875041924526
[2019-03-24 06:16:10,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00709874], dtype=float32), 0.0048480807]
[2019-03-24 06:16:10,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.2459730857883118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3955155676311585, 6.9112, 6.9112, 121.9260426156618, 585404.0854632002, 585404.0854632002, 180391.9927144519]
[2019-03-24 06:16:10,642] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:16:10,645] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.2179301e-10 9.7820285e-10 1.0000000e+00 2.2948293e-14 1.3422815e-11], sampled 0.3919091589777518
[2019-03-24 06:16:25,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.1763 2831356056.4901 210.0000
[2019-03-24 06:16:25,467] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.4940 2623870296.7475 97.0000
[2019-03-24 06:16:25,498] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600776538.2001 61.0000
[2019-03-24 06:16:25,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7492.5206 2565975221.9196 47.0000
[2019-03-24 06:16:25,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.7458 2661643387.4987 110.0000
[2019-03-24 06:16:26,637] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 300000, evaluation results [300000.0, 7157.176337152175, 2831356056.4901485, 210.0, 6809.511993196244, 2600776538.2001104, 61.0, 7492.520639979948, 2565975221.919632, 47.0, 6580.7458447130875, 2661643387.4986925, 110.0, 7161.493984015352, 2623870296.747451, 97.0]
[2019-03-24 06:16:28,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3001376e-11 1.2036042e-10 1.0000000e+00 4.2526434e-14 1.9437547e-11], sum to 1.0000
[2019-03-24 06:16:28,273] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5652
[2019-03-24 06:16:28,279] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.05, 76.0, 1.0, 2.0, 0.3416951631891526, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5439898280316935, 6.9112, 6.9112, 121.9260426156618, 778862.0303715111, 778862.0303715111, 206791.5579236836], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3335400.0000, 
sim time next is 3336000.0000, 
raw observation next is [28.36666666666667, 75.33333333333333, 1.0, 2.0, 0.3467236854779041, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5519953992829236, 6.911199999999999, 6.9112, 121.9260426156618, 790329.9838583546, 790329.9838583551, 208231.3070468186], 
processed observation next is [0.0, 0.6086956521739131, 0.606172839506173, 0.7533333333333333, 1.0, 1.0, 0.22229010175940966, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4399942491036545, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28226070852084095, 0.2822607085208411, 0.4004448212438819], 
reward next is 0.5996, 
noisyNet noise sample is [array([3.189408], dtype=float32), -1.4876813]. 
=============================================
[2019-03-24 06:16:28,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.08156 ]
 [62.125397]
 [62.175564]
 [62.18614 ]
 [62.166805]], R is [[61.97779465]
 [61.96034241]
 [61.94604111]
 [61.93443298]
 [61.92475128]].
[2019-03-24 06:16:35,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5552279e-07 2.3291364e-06 9.9999678e-01 2.0015223e-10 5.1659345e-07], sum to 1.0000
[2019-03-24 06:16:35,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3717
[2019-03-24 06:16:35,905] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 1.017472216576762, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1875190.602163787, 1875190.602163787, 383536.7520579225], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.93939467919477, 6.9112, 121.9257104054318, 1892529.879445864, 1878091.723025867, 384033.8130512019], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.89, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.002819467919476981, 0.0, 0.8094599232896831, 0.6759035283735229, 0.6707470439378096, 0.7385265635600037], 
reward next is 0.1205, 
noisyNet noise sample is [array([-1.2308654], dtype=float32), 1.0586455]. 
=============================================
[2019-03-24 06:16:36,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1255091e-05 1.4003901e-05 9.9997473e-01 9.2701864e-09 3.1809385e-08], sum to 1.0000
[2019-03-24 06:16:36,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0235
[2019-03-24 06:16:36,099] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333334, 88.66666666666666, 1.0, 2.0, 0.3763221636113651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5991171404265291, 6.911199999999997, 6.9112, 121.9260426156618, 857835.1947618364, 857835.1947618377, 216905.2310525814], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3483600.0000, 
sim time next is 3484200.0000, 
raw observation next is [25.41666666666666, 87.33333333333333, 1.0, 2.0, 0.3656986355821445, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5822041378198565, 6.9112, 6.9112, 121.9260426156618, 833605.4440593066, 833605.4440593066, 213750.267531807], 
processed observation next is [1.0, 0.30434782608695654, 0.49691358024691334, 0.8733333333333333, 1.0, 1.0, 0.24487932807398155, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47775517227482056, 0.0, 0.0, 0.8094621288201359, 0.2977162300211809, 0.2977162300211809, 0.41105820679193655], 
reward next is 0.5889, 
noisyNet noise sample is [array([-0.91686714], dtype=float32), -0.367552]. 
=============================================
[2019-03-24 06:16:40,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.607337e-09 3.121842e-09 1.000000e+00 8.081062e-15 2.534891e-12], sum to 1.0000
[2019-03-24 06:16:40,101] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5760
[2019-03-24 06:16:40,106] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.53333333333333, 92.33333333333333, 1.0, 2.0, 0.275356306959322, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4419306281697443, 6.9112, 6.9112, 121.9260426156618, 652482.8226426454, 652482.8226426454, 187935.1218103065], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3552000.0000, 
sim time next is 3552600.0000, 
raw observation next is [22.26666666666667, 96.16666666666667, 1.0, 2.0, 0.2775556281455688, 0.0, 2.0, 0.0, 1.0, 2.0, 0.44480842440877, 6.911199999999999, 6.9112, 121.9260426156618, 655155.4545426702, 655155.4545426706, 188627.2464575701], 
processed observation next is [1.0, 0.08695652173913043, 0.38024691358024704, 0.9616666666666667, 1.0, 1.0, 0.13994717636377235, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30601053051096244, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2339840909080965, 0.23398409090809666, 0.3627447047260963], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.28727755], dtype=float32), 0.82897717]. 
=============================================
[2019-03-24 06:16:41,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6939373e-08 1.7544055e-07 9.9999976e-01 2.0746610e-10 7.3113718e-08], sum to 1.0000
[2019-03-24 06:16:41,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6079
[2019-03-24 06:16:41,712] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.2, 75.66666666666667, 1.0, 2.0, 0.5377971794212238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8592882951665288, 6.911199999999999, 6.9112, 121.9260426156618, 1257497.322546846, 1257497.322546847, 269843.0940091418], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3594000.0000, 
sim time next is 3594600.0000, 
raw observation next is [25.15, 77.5, 1.0, 2.0, 0.560733605894545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8949667747504972, 6.911199999999999, 6.9112, 121.9260426156618, 1305078.424531753, 1305078.424531753, 278430.1339907936], 
processed observation next is [1.0, 0.6086956521739131, 0.487037037037037, 0.775, 1.0, 1.0, 0.477063816541125, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8687084684381216, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46609943733276893, 0.46609943733276893, 0.5354425653669108], 
reward next is 0.4646, 
noisyNet noise sample is [array([0.63359386], dtype=float32), 1.1980463]. 
=============================================
[2019-03-24 06:16:43,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.5828682e-08 4.3728847e-09 9.9999988e-01 5.8120338e-13 8.6439189e-12], sum to 1.0000
[2019-03-24 06:16:43,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2155
[2019-03-24 06:16:43,654] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2817426503870812, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4491945799494716, 6.9112, 6.9112, 121.9260426156618, 651639.6451902161, 651639.6451902161, 190207.8526188865], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.2819611815182757, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4495424895344518, 6.9112, 6.9112, 121.9260426156618, 652140.6883017546, 652140.6883017546, 190264.9905738857], 
processed observation next is [1.0, 0.782608695652174, 0.48148148148148145, 0.83, 1.0, 1.0, 0.14519188275985204, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31192811191806474, 0.0, 0.0, 0.8094621288201359, 0.23290738867919808, 0.23290738867919808, 0.3658942126420879], 
reward next is 0.6341, 
noisyNet noise sample is [array([-1.1055213], dtype=float32), 1.050495]. 
=============================================
[2019-03-24 06:16:43,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.05374 ]
 [60.428688]
 [59.96636 ]
 [59.317158]
 [58.694942]], R is [[61.51958466]
 [61.53860474]
 [61.55728149]
 [61.57640076]
 [61.59700394]].
[2019-03-24 06:16:45,244] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1106441e-10 7.1484718e-10 1.0000000e+00 1.1440160e-14 1.1583379e-11], sum to 1.0000
[2019-03-24 06:16:45,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-24 06:16:45,256] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 99.33333333333334, 1.0, 2.0, 0.3011994618268468, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4821067092853237, 6.911199999999999, 6.9112, 121.9260426156618, 708399.9173478773, 708399.9173478778, 194962.9190464158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3652800.0000, 
sim time next is 3653400.0000, 
raw observation next is [22.0, 99.16666666666666, 1.0, 2.0, 0.303114110866662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4852050246487458, 6.911199999999999, 6.9112, 121.9260426156618, 713060.6185037738, 713060.6185037743, 195470.6214260419], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9916666666666666, 1.0, 1.0, 0.17037394150793098, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3565062808109322, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25466450660849066, 0.2546645066084908, 0.37590504120392676], 
reward next is 0.6241, 
noisyNet noise sample is [array([0.21190125], dtype=float32), -1.4198792]. 
=============================================
[2019-03-24 06:16:48,222] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7176289e-10 2.6155504e-09 1.0000000e+00 2.9447722e-13 9.2839653e-11], sum to 1.0000
[2019-03-24 06:16:48,229] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8611
[2019-03-24 06:16:48,234] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.06666666666667, 94.0, 1.0, 2.0, 0.3333229452815321, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5306609844586601, 6.911199999999999, 6.9112, 121.9260426156618, 759768.8880908467, 759768.8880908471, 204417.0532518622], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3710400.0000, 
sim time next is 3711000.0000, 
raw observation next is [25.08333333333334, 94.0, 1.0, 2.0, 0.3347748465457037, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5329724585563442, 6.911199999999999, 6.9112, 121.9260426156618, 763079.9667486678, 763079.9667486682, 204826.704247771], 
processed observation next is [1.0, 0.9565217391304348, 0.4845679012345681, 0.94, 1.0, 1.0, 0.20806529350679015, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41621557319543023, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27252855955309563, 0.2725285595530958, 0.3938975081687904], 
reward next is 0.6061, 
noisyNet noise sample is [array([0.28215316], dtype=float32), 0.2302798]. 
=============================================
[2019-03-24 06:16:48,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.300976]
 [61.300457]
 [61.24643 ]
 [61.23191 ]
 [61.181885]], R is [[61.27819061]
 [61.27230072]
 [61.26810837]
 [61.26080322]
 [61.25428772]].
[2019-03-24 06:16:48,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6967860e-08 6.3650232e-09 1.0000000e+00 5.3530411e-13 5.4579132e-09], sum to 1.0000
[2019-03-24 06:16:48,624] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9120
[2019-03-24 06:16:48,626] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.91666666666667, 84.83333333333333, 1.0, 2.0, 0.3944153391718242, 0.0, 2.0, 0.0, 1.0, 2.0, 0.62792206517237, 6.911199999999999, 6.9112, 121.9260426156618, 899103.2052491654, 899103.2052491659, 222385.343825693], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3690600.0000, 
sim time next is 3691200.0000, 
raw observation next is [26.93333333333333, 85.66666666666667, 1.0, 2.0, 0.3308345194403716, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5266993294771608, 6.911199999999999, 6.9112, 121.9260426156618, 754094.0356731904, 754094.0356731908, 203719.1015734745], 
processed observation next is [1.0, 0.7391304347826086, 0.5530864197530863, 0.8566666666666667, 1.0, 1.0, 0.20337442790520432, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.408374161846451, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26931929845471086, 0.26931929845471103, 0.3917675030259125], 
reward next is 0.6082, 
noisyNet noise sample is [array([-0.11490703], dtype=float32), -0.5856958]. 
=============================================
[2019-03-24 06:16:48,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3460810e-07 1.3668406e-07 9.9999976e-01 1.5162130e-11 4.1109938e-09], sum to 1.0000
[2019-03-24 06:16:48,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8484
[2019-03-24 06:16:48,928] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 98.0, 1.0, 2.0, 0.3280819017470606, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5223170724629099, 6.9112, 6.9112, 121.9260426156618, 747816.7429647115, 747816.7429647115, 202945.0951816084], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3733200.0000, 
sim time next is 3733800.0000, 
raw observation next is [24.33333333333333, 98.33333333333334, 1.0, 2.0, 0.4053361785818995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6453083971801191, 6.911199999999999, 6.9112, 121.9260426156618, 924013.1925869095, 924013.19258691, 225752.5799662697], 
processed observation next is [1.0, 0.21739130434782608, 0.45679012345678993, 0.9833333333333334, 1.0, 1.0, 0.2920668792641661, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5566354964751489, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33000471163818196, 0.3300047116381821, 0.434139576858211], 
reward next is 0.5659, 
noisyNet noise sample is [array([-1.6418549], dtype=float32), 0.8802004]. 
=============================================
[2019-03-24 06:16:54,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5413730e-09 1.3317895e-08 1.0000000e+00 1.3872449e-12 1.0772003e-08], sum to 1.0000
[2019-03-24 06:16:54,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0085
[2019-03-24 06:16:54,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 59.0, 1.0, 2.0, 0.3086484622644129, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4913784039035961, 6.911199999999999, 6.9112, 121.9260426156618, 703500.6134347584, 703500.6134347587, 197583.3672626213], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3834000.0000, 
sim time next is 3834600.0000, 
raw observation next is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.3133434476982595, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4988529736192807, 6.911199999999999, 6.9112, 121.9260426156618, 714206.8510819931, 714206.8510819935, 198865.1871761332], 
processed observation next is [0.0, 0.391304347826087, 0.6728395061728393, 0.5966666666666667, 1.0, 1.0, 0.18255172345030893, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37356621702410087, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2550738753864261, 0.2550738753864263, 0.3824330522617946], 
reward next is 0.6176, 
noisyNet noise sample is [array([-1.4539465], dtype=float32), 2.0465767]. 
=============================================
[2019-03-24 06:16:56,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4581892e-08 7.9660829e-08 9.9999976e-01 1.0887861e-12 8.1412042e-09], sum to 1.0000
[2019-03-24 06:16:56,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9833
[2019-03-24 06:16:56,394] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.3761610379218959, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5988606230813969, 6.9112, 6.9112, 121.9260426156618, 857467.6995142838, 857467.6995142838, 216861.9496545842], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3898800.0000, 
sim time next is 3899400.0000, 
raw observation next is [26.83333333333333, 89.83333333333334, 1.0, 2.0, 0.3660285889124369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5827294342675118, 6.911199999999999, 6.9112, 121.9260426156618, 834357.9779134631, 834357.9779134636, 213852.6195457595], 
processed observation next is [0.0, 0.13043478260869565, 0.5493827160493825, 0.8983333333333334, 1.0, 1.0, 0.24527212965766299, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47841179283438967, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2979849921119511, 0.2979849921119513, 0.41125503758799903], 
reward next is 0.5887, 
noisyNet noise sample is [array([-0.760283], dtype=float32), -0.6081561]. 
=============================================
[2019-03-24 06:17:02,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9100234e-08 5.3070703e-09 1.0000000e+00 3.2032307e-11 2.9020613e-09], sum to 1.0000
[2019-03-24 06:17:02,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-24 06:17:02,394] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.25, 83.16666666666667, 1.0, 2.0, 0.3333128567252552, 0.0, 2.0, 0.0, 1.0, 2.0, 0.530644923148506, 6.911199999999999, 6.9112, 121.9260426156618, 759745.8810644371, 759745.8810644376, 204413.3756168031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3971400.0000, 
sim time next is 3972000.0000, 
raw observation next is [26.2, 83.33333333333334, 1.0, 2.0, 0.335344756675619, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338797740438467, 6.9112, 6.9112, 121.9260426156618, 764379.6577056436, 764379.6577056436, 204986.760954909], 
processed observation next is [0.0, 1.0, 0.5259259259259259, 0.8333333333333335, 1.0, 1.0, 0.20874375794716551, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4173497175548083, 0.0, 0.0, 0.8094621288201359, 0.2729927348948727, 0.2729927348948727, 0.39420530952867117], 
reward next is 0.6058, 
noisyNet noise sample is [array([-0.02674267], dtype=float32), 0.4209892]. 
=============================================
[2019-03-24 06:17:02,409] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[56.960354]
 [56.857407]
 [56.745575]
 [56.695515]
 [56.63425 ]], R is [[57.06357574]
 [57.09983826]
 [57.13034439]
 [57.15720367]
 [57.18060303]].
[2019-03-24 06:17:04,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0052295e-05 9.8958208e-06 9.9996698e-01 1.7206904e-08 3.0786198e-06], sum to 1.0000
[2019-03-24 06:17:04,420] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9393
[2019-03-24 06:17:04,427] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.36666666666667, 79.83333333333334, 1.0, 2.0, 0.9686255445547347, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1819424.863996268, 1819424.863996268, 372194.0844888535], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4024200.0000, 
sim time next is 4024800.0000, 
raw observation next is [26.4, 79.0, 1.0, 2.0, 0.9842819404385281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1837298.588405243, 1837298.588405244, 375782.6962651269], 
processed observation next is [1.0, 0.6086956521739131, 0.5333333333333333, 0.79, 1.0, 1.0, 0.9812880243315811, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6561780672875868, 0.6561780672875872, 0.7226590312790903], 
reward next is 0.2773, 
noisyNet noise sample is [array([-0.16026902], dtype=float32), 1.6820062]. 
=============================================
[2019-03-24 06:17:13,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0853669e-06 4.4663398e-06 9.9996448e-01 6.1183045e-09 2.5926727e-05], sum to 1.0000
[2019-03-24 06:17:13,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-24 06:17:13,962] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.6, 70.66666666666667, 1.0, 2.0, 0.3898934866980462, 0.0, 2.0, 0.0, 1.0, 2.0, 0.635277070580618, 6.9112, 6.9112, 121.9260426156618, 948577.5364146802, 948577.5364146802, 218739.837636129], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4242000.0000, 
sim time next is 4242600.0000, 
raw observation next is [23.2, 72.5, 1.0, 2.0, 0.3433176840639171, 0.0, 2.0, 0.0, 1.0, 2.0, 0.560576934366301, 6.911200000000001, 6.9112, 121.9260426156618, 837406.283050732, 837406.2830507315, 204946.9723512079], 
processed observation next is [1.0, 0.08695652173913043, 0.4148148148148148, 0.725, 1.0, 1.0, 0.2182353381713299, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45072116795787615, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29907367251811856, 0.2990736725181184, 0.3941287929830921], 
reward next is 0.6059, 
noisyNet noise sample is [array([0.2892133], dtype=float32), -0.19274145]. 
=============================================
[2019-03-24 06:17:15,154] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 06:17:15,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:17:15,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:15,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:17:15,156] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:17:15,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:17:15,157] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:17:15,157] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:15,158] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:15,157] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:15,160] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:15,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-24 06:17:15,200] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-24 06:17:15,227] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-24 06:17:15,228] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-24 06:17:15,248] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-24 06:17:20,839] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:17:20,840] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.75889403166667, 44.77626309, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2667840743119747, 6.9112, 6.9112, 121.9260426156618, 391763.0040046379, 391763.0040046379, 154813.9252346279]
[2019-03-24 06:17:20,843] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:17:20,845] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6729933e-07 3.1563050e-07 9.9999917e-01 2.1183031e-11 3.0389253e-07], sampled 0.11838045291551669
[2019-03-24 06:17:26,686] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:17:26,687] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.6408634, 17.23695645666667, 1.0, 2.0, 0.3900645966625024, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6790227743574703, 6.911199999999999, 6.9112, 121.9260426156618, 994271.91528955, 994271.9152895504, 214247.2214506794]
[2019-03-24 06:17:26,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:17:26,690] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3294559e-06 2.2948516e-06 9.9999416e-01 5.9600819e-10 2.2081833e-06], sampled 0.5351736789113575
[2019-03-24 06:17:29,127] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:17:29,128] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.83488629, 51.43823882333334, 1.0, 2.0, 0.1658394576028505, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2807774740554459, 6.911199999999999, 6.9112, 121.9260426156618, 416792.6247569559, 416792.6247569564, 158891.1248721239]
[2019-03-24 06:17:29,130] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:17:29,133] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6012594e-07 3.0043577e-07 9.9999928e-01 1.9628656e-11 2.8975933e-07], sampled 0.8111766433161981
[2019-03-24 06:17:32,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:17:32,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.95, 24.5, 1.0, 2.0, 0.1762806709523529, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3017834528118479, 6.911200000000001, 6.9112, 121.9260426156618, 445754.2337080447, 445754.2337080443, 160543.884406746]
[2019-03-24 06:17:32,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:17:32,024] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3654251e-07 2.6307214e-07 9.9999940e-01 1.5533531e-11 2.4939447e-07], sampled 0.9274737603255913
[2019-03-24 06:17:46,139] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:17:46,141] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.43333333333333, 83.66666666666667, 1.0, 2.0, 0.8602693220227012, 1.0, 2.0, 0.8602693220227012, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156044, 1962347.728154, 1962347.728154, 369287.681682843]
[2019-03-24 06:17:46,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:17:46,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7106936e-06 5.9938839e-06 9.9998450e-01 3.1289829e-09 5.8401570e-06], sampled 0.5227122676835989
[2019-03-24 06:18:04,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:18:04,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 94.5, 1.0, 2.0, 0.7375792333946586, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1555694.538439687, 1555694.538439687, 324168.736132708]
[2019-03-24 06:18:04,012] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:18:04,016] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8951692e-06 4.7764142e-06 9.9998772e-01 2.0334006e-09 4.6308992e-06], sampled 0.07889830471474713
[2019-03-24 06:18:24,789] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00744678], dtype=float32), 0.004932124]
[2019-03-24 06:18:24,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.26666666666667, 64.0, 1.0, 2.0, 0.2592171208566835, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4148392724538323, 6.911199999999999, 6.9112, 121.9260426156618, 609296.2203930177, 609296.2203930181, 184073.8327510813]
[2019-03-24 06:18:24,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:18:24,795] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3513758e-07 4.2337078e-07 9.9999893e-01 3.6246957e-11 4.1309039e-07], sampled 0.6205130882695745
[2019-03-24 06:19:01,532] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6810.3314 2600769258.1026 61.0000
[2019-03-24 06:19:01,773] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.8595 2831362235.9031 210.0000
[2019-03-24 06:19:01,868] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661716428.4293 110.0000
[2019-03-24 06:19:01,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.8385 2565929408.3055 47.0000
[2019-03-24 06:19:01,976] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7161.4578 2623889326.2358 97.0000
[2019-03-24 06:19:02,991] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 325000, evaluation results [325000.0, 7157.859463619724, 2831362235.9030914, 210.0, 6810.331391877612, 2600769258.1025743, 61.0, 7491.83852290894, 2565929408.3054905, 47.0, 6579.928819146758, 2661716428.4292536, 110.0, 7161.457827495762, 2623889326.2357626, 97.0]
[2019-03-24 06:19:08,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2058169e-05 6.2758103e-04 9.9920243e-01 3.7558272e-07 1.5762473e-04], sum to 1.0000
[2019-03-24 06:19:08,204] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-24 06:19:08,208] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 89.83333333333333, 1.0, 2.0, 0.2606402430199101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4214180411421168, 6.911199999999999, 6.9112, 121.9260426156618, 626900.6258914957, 626900.6258914962, 183611.2445221305], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4338600.0000, 
sim time next is 4339200.0000, 
raw observation next is [22.2, 89.66666666666667, 1.0, 2.0, 0.2527877215011443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4080769634214177, 6.911199999999999, 6.9112, 121.9260426156618, 606344.2670350132, 606344.2670350136, 181771.2685928846], 
processed observation next is [1.0, 0.21739130434782608, 0.37777777777777777, 0.8966666666666667, 1.0, 1.0, 0.11046157321564799, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2600962042767721, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21655152394107613, 0.2165515239410763, 0.34956013190939345], 
reward next is 0.6504, 
noisyNet noise sample is [array([-0.6309735], dtype=float32), 0.40470535]. 
=============================================
[2019-03-24 06:19:17,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6757617e-03 1.5206453e-03 8.2372552e-01 9.0148575e-07 1.7207725e-01], sum to 1.0000
[2019-03-24 06:19:17,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0273
[2019-03-24 06:19:17,173] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.2963327602348053, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4721317979302087, 6.911199999999999, 6.9112, 121.9260426156618, 681987.4256476453, 681987.4256476457, 194140.4816715851], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4549800.0000, 
sim time next is 4550400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2962901632620016, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4720641612741234, 6.9112, 6.9112, 121.9260426156618, 681892.1997830853, 681892.1997830853, 194129.0526442703], 
processed observation next is [0.0, 0.6956521739130435, 0.4074074074074074, 1.0, 1.0, 1.0, 0.1622501943595257, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3400802015926542, 0.0, 0.0, 0.8094621288201359, 0.24353292849395902, 0.24353292849395902, 0.3733251012389813], 
reward next is 0.6267, 
noisyNet noise sample is [array([-0.0548659], dtype=float32), -0.35907927]. 
=============================================
[2019-03-24 06:19:18,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6934879e-02 2.6344044e-02 7.9279399e-01 7.8237445e-06 1.6391924e-01], sum to 1.0000
[2019-03-24 06:19:18,385] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2587
[2019-03-24 06:19:18,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.2993700254288083, 0.0, 2.0, 0.0, 1.0, 2.0, 0.476749141907154, 6.911199999999999, 6.9112, 121.9260426156618, 685717.9525835869, 685717.9525835874, 195020.1667387571], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4539600.0000, 
sim time next is 4540200.0000, 
raw observation next is [24.43333333333333, 91.33333333333334, 1.0, 2.0, 0.3036765333846547, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835278860208507, 6.911199999999999, 6.9112, 121.9260426156618, 693964.5598471183, 693964.5598471187, 196207.2944772982], 
processed observation next is [0.0, 0.5652173913043478, 0.4604938271604937, 0.9133333333333334, 1.0, 1.0, 0.17104349212458897, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3544098575260633, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24784448565968512, 0.24784448565968525, 0.37732172014865034], 
reward next is 0.6227, 
noisyNet noise sample is [array([0.5643232], dtype=float32), 0.8723868]. 
=============================================
[2019-03-24 06:19:19,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0762274e-03 1.6862117e-03 9.9057722e-01 3.2217005e-07 4.6600020e-03], sum to 1.0000
[2019-03-24 06:19:19,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6813
[2019-03-24 06:19:19,539] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.93333333333333, 91.33333333333334, 1.0, 2.0, 0.2886164860222499, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4600759514355465, 6.911199999999999, 6.9112, 121.9260426156618, 666811.4479311414, 666811.4479311417, 192029.9360992657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4524000.0000, 
sim time next is 4524600.0000, 
raw observation next is [24.06666666666667, 91.16666666666667, 1.0, 2.0, 0.2918268700921166, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4650390469423913, 6.911199999999999, 6.9112, 121.9260426156618, 672625.5278761594, 672625.5278761599, 192918.6415013293], 
processed observation next is [0.0, 0.34782608695652173, 0.4469135802469137, 0.9116666666666667, 1.0, 1.0, 0.15693675010966263, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.33129880867798905, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24022340281291407, 0.24022340281291424, 0.37099738750255634], 
reward next is 0.6290, 
noisyNet noise sample is [array([-0.27166405], dtype=float32), -2.3360083]. 
=============================================
[2019-03-24 06:19:27,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5301342e-04 1.2750839e-03 3.5957456e-02 2.1134365e-04 9.6240312e-01], sum to 1.0000
[2019-03-24 06:19:27,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7318
[2019-03-24 06:19:27,033] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.3906050520758481, 1.0, 2.0, 0.3906050520758481, 1.0, 2.0, 0.6218559640231887, 6.911199999999999, 6.9112, 121.94756008, 1336006.390482422, 1336006.390482423, 292991.0870043231], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4700400.0000, 
sim time next is 4701000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.3948735758733637, 1.0, 2.0, 0.3948735758733637, 1.0, 2.0, 0.6286515929249484, 6.9112, 6.9112, 121.94756008, 1350619.110340594, 1350619.110340594, 294843.7582503562], 
processed observation next is [1.0, 0.391304347826087, 0.43827160493827144, 0.95, 1.0, 1.0, 0.2796113998492425, 1.0, 1.0, 0.2796113998492425, 1.0, 1.0, 0.5358144911561855, 0.0, 0.0, 0.8096049824067558, 0.4823639679787836, 0.4823639679787836, 0.5670072274045311], 
reward next is 0.4330, 
noisyNet noise sample is [array([1.4546021], dtype=float32), -0.03741265]. 
=============================================
[2019-03-24 06:19:27,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[49.228123]
 [49.27632 ]
 [49.040905]
 [49.591503]
 [49.416336]], R is [[48.69406509]
 [48.64368057]
 [48.59721756]
 [48.56822586]
 [48.55356216]].
[2019-03-24 06:19:31,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2885388e-04 9.7430329e-04 6.4552003e-03 1.4792102e-04 9.9219370e-01], sum to 1.0000
[2019-03-24 06:19:31,284] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6575
[2019-03-24 06:19:31,288] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.93333333333333, 94.0, 1.0, 2.0, 0.3860805296293371, 1.0, 2.0, 0.3860805296293371, 1.0, 2.0, 0.6146527769349345, 6.911199999999998, 6.9112, 121.94756008, 1320517.597819505, 1320517.597819506, 291038.3343365302], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [23.95, 94.0, 1.0, 2.0, 0.3628938712540348, 1.0, 2.0, 0.3628938712540348, 1.0, 2.0, 0.5777388616647088, 6.911199999999998, 6.9112, 121.94756008, 1241147.649866389, 1241147.64986639, 281209.3746364118], 
processed observation next is [1.0, 0.391304347826087, 0.4425925925925926, 0.94, 1.0, 1.0, 0.24154032292147004, 1.0, 1.0, 0.24154032292147004, 1.0, 1.0, 0.4721735770808859, -1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.4432670178094247, 0.443267017809425, 0.5407872589161765], 
reward next is 0.4592, 
noisyNet noise sample is [array([1.185266], dtype=float32), -1.3757992]. 
=============================================
[2019-03-24 06:19:34,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6682026e-03 3.2711297e-03 8.5366871e-03 1.3723537e-05 9.8151028e-01], sum to 1.0000
[2019-03-24 06:19:34,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2776
[2019-03-24 06:19:34,175] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.26666666666667, 93.66666666666667, 1.0, 2.0, 0.2938207298498244, 1.0, 2.0, 0.2938207298498244, 1.0, 2.0, 0.4677721709940398, 6.911199999999999, 6.9112, 121.94756008, 1004752.995612909, 1004752.995612909, 253699.787224069], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4864800.0000, 
sim time next is 4865400.0000, 
raw observation next is [25.4, 93.5, 1.0, 2.0, 0.3055429083093955, 1.0, 2.0, 0.3055429083093955, 1.0, 2.0, 0.486434260866377, 6.911200000000001, 6.9112, 121.94756008, 1044865.627179666, 1044865.627179665, 258181.2621656849], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.935, 1.0, 1.0, 0.17326536703499465, 1.0, 1.0, 0.17326536703499465, 1.0, 1.0, 0.35804282608297117, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.37316629542130925, 0.3731662954213089, 0.49650242724170174], 
reward next is 0.5035, 
noisyNet noise sample is [array([1.0917447], dtype=float32), 0.26696792]. 
=============================================
[2019-03-24 06:19:35,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9192549e-05 7.3397554e-05 9.6071791e-03 2.5187940e-06 9.9026769e-01], sum to 1.0000
[2019-03-24 06:19:35,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1946
[2019-03-24 06:19:35,910] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.2795124607164807, 1.0, 2.0, 0.2795124607164807, 1.0, 2.0, 0.4449929405459633, 6.9112, 6.9112, 121.94756008, 955793.753143349, 955793.753143349, 248333.4288363701], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4905000.0000, 
sim time next is 4905600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.29217855276877, 1.0, 2.0, 0.29217855276877, 1.0, 2.0, 0.4651577715990274, 6.9112, 6.9112, 121.94756008, 999133.7261954264, 999133.7261954264, 253078.0858444762], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.1573554199628214, 1.0, 1.0, 0.1573554199628214, 1.0, 1.0, 0.33144721449878417, 0.0, 0.0, 0.8096049824067558, 0.3568334736412237, 0.3568334736412237, 0.4866886266239927], 
reward next is 0.5133, 
noisyNet noise sample is [array([-0.09808949], dtype=float32), 1.7506455]. 
=============================================
[2019-03-24 06:19:36,581] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3338116e-05 2.4715095e-05 1.9139562e-04 1.9608603e-06 9.9975854e-01], sum to 1.0000
[2019-03-24 06:19:36,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6916
[2019-03-24 06:19:36,594] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 75.0, 1.0, 2.0, 0.2058792463787421, 1.0, 2.0, 0.2058792463787421, 1.0, 2.0, 0.3277664652539102, 6.9112, 6.9112, 121.94756008, 703889.1430949762, 703889.1430949762, 222524.6829124527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4932000.0000, 
sim time next is 4932600.0000, 
raw observation next is [26.65, 76.16666666666667, 1.0, 2.0, 0.3812213989286979, 1.0, 2.0, 0.3812213989286979, 1.0, 2.0, 0.6069168826086782, 6.9112, 6.9112, 122.8821113016549, 1303875.251331973, 1303875.251331973, 289156.0712709043], 
processed observation next is [1.0, 0.08695652173913043, 0.5425925925925925, 0.7616666666666667, 1.0, 1.0, 0.26335880824844987, 1.0, 1.0, 0.26335880824844987, 1.0, 1.0, 0.5086461032608477, 0.0, 0.0, 0.8158094306537709, 0.46566973261856176, 0.46566973261856176, 0.556069367828662], 
reward next is 0.4439, 
noisyNet noise sample is [array([-0.06930571], dtype=float32), -1.4675634]. 
=============================================
[2019-03-24 06:19:39,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6512141e-04 4.6340385e-04 8.0201903e-04 4.6720965e-05 9.9832267e-01], sum to 1.0000
[2019-03-24 06:19:39,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4271
[2019-03-24 06:19:39,062] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.3921082271234609, 1.0, 2.0, 0.3921082271234609, 1.0, 2.0, 0.624249067653982, 6.911199999999999, 6.9112, 121.94756008, 1341152.277255132, 1341152.277255133, 293642.3591179592], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4958400.0000, 
sim time next is 4959000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.406684600477836, 1.0, 2.0, 0.406684600477836, 1.0, 2.0, 0.6474551287534854, 6.911199999999999, 6.9112, 121.94756008, 1391054.024878673, 1391054.024878674, 300022.7403813118], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.29367214342599524, 1.0, 1.0, 0.29367214342599524, 1.0, 1.0, 0.5593189109418567, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4968050088852404, 0.4968050088852407, 0.5769668084255997], 
reward next is 0.4230, 
noisyNet noise sample is [array([0.7700661], dtype=float32), -1.6877365]. 
=============================================
[2019-03-24 06:19:39,073] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[45.95108 ]
 [46.141   ]
 [46.61193 ]
 [46.898087]
 [47.453987]], R is [[45.68645477]
 [45.6648941 ]
 [45.62771606]
 [45.62602615]
 [45.62284088]].
[2019-03-24 06:19:43,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9026335e-04 4.3699933e-05 8.9574769e-06 3.2634656e-08 9.9975699e-01], sum to 1.0000
[2019-03-24 06:19:43,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6879
[2019-03-24 06:19:43,302] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.66666666666667, 97.33333333333334, 1.0, 2.0, 0.1860022436496072, 1.0, 2.0, 0.1860022436496072, 1.0, 2.0, 0.2964704048502453, 6.911199999999999, 6.9112, 121.94756008, 644133.3295277085, 644133.3295277089, 216069.8183577603], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5019000.0000, 
sim time next is 5019600.0000, 
raw observation next is [22.73333333333333, 96.66666666666667, 1.0, 2.0, 0.1850932764444004, 1.0, 2.0, 0.1850932764444004, 1.0, 2.0, 0.2950406360442379, 6.911200000000001, 6.9112, 121.94756008, 641269.3152100896, 641269.3152100891, 215778.1458443645], 
processed observation next is [0.0, 0.08695652173913043, 0.39753086419753075, 0.9666666666666667, 1.0, 1.0, 0.02987294814809572, 1.0, 1.0, 0.02987294814809572, 1.0, 1.0, 0.11880079505529738, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22902475543217485, 0.22902475543217468, 0.4149579727776241], 
reward next is 0.5850, 
noisyNet noise sample is [array([-2.5258944], dtype=float32), -0.8411075]. 
=============================================
[2019-03-24 06:19:51,199] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 06:19:51,204] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:19:51,205] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:19:51,205] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:19:51,207] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:51,207] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:19:51,206] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:51,206] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:51,208] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:19:51,209] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:51,214] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:51,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-24 06:19:51,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-24 06:19:51,225] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-24 06:19:51,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-24 06:19:51,327] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-24 06:20:11,820] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:20:11,822] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.83333333333334, 20.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2239194258734909, 6.911200000000001, 6.9112, 121.94756008, 501964.0585606111, 501964.0585606106, 194722.3082477197]
[2019-03-24 06:20:11,824] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:20:11,826] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5286625e-05 1.0134357e-05 5.1651386e-05 9.4788625e-08 9.9992287e-01], sampled 0.6111991612822609
[2019-03-24 06:20:13,087] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:20:13,088] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.74028081166666, 41.758975485, 1.0, 2.0, 0.1718732420812064, 1.0, 2.0, 0.1718732420812064, 1.0, 2.0, 0.2738622199975043, 6.9112, 6.9112, 121.94756008, 593753.7327869923, 593753.7327869923, 211626.3459084043]
[2019-03-24 06:20:13,089] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:20:13,090] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.37474935e-05 9.14583052e-06 4.70585692e-05 8.11023213e-08
 9.99929905e-01], sampled 0.7996134219297316
[2019-03-24 06:20:33,193] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:20:33,194] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.760091485, 102.02990125, 1.0, 2.0, 0.215038354166018, 1.0, 2.0, 0.215038354166018, 1.0, 2.0, 0.3423480631425692, 6.9112, 6.9112, 121.94756008, 735218.6131843305, 735218.6131843305, 225569.933467888]
[2019-03-24 06:20:33,195] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:20:33,197] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7401622e-05 1.7413213e-05 8.5313361e-05 2.2077641e-07 9.9986959e-01], sampled 0.9427929126087368
[2019-03-24 06:20:36,165] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:20:36,167] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.1, 46.0, 1.0, 2.0, 0.1663088964791595, 1.0, 2.0, 0.1663088964791595, 1.0, 2.0, 0.2664712018234821, 6.9112, 6.9112, 121.94756008, 588481.4694478223, 588481.4694478223, 209663.4341489207]
[2019-03-24 06:20:36,167] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:20:36,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9791627e-05 1.2778874e-05 6.4458414e-05 1.3762127e-07 9.9990284e-01], sampled 0.30345997381271106
[2019-03-24 06:20:37,584] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:20:37,585] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.0, 27.0, 1.0, 2.0, 0.1725755856379214, 1.0, 2.0, 0.1725755856379214, 1.0, 2.0, 0.2754106346362808, 6.9112, 6.9112, 121.94756008, 601888.7516937836, 601888.7516937836, 211791.3059259063]
[2019-03-24 06:20:37,588] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:20:37,592] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3090107e-05 8.4600351e-06 4.4686371e-05 7.5085261e-08 9.9993372e-01], sampled 0.04011150637302785
[2019-03-24 06:21:15,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:21:15,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.293237612457299, 1.0, 2.0, 0.293237612457299, 1.0, 2.0, 0.4668438291143318, 6.911200000000001, 6.9112, 121.94756008, 1002757.655697832, 1002757.655697832, 253478.8564127278]
[2019-03-24 06:21:15,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:21:15,085] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7078586e-05 1.7673065e-05 8.5498730e-05 2.1971903e-07 9.9986947e-01], sampled 0.4773445959853607
[2019-03-24 06:21:31,826] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:21:31,828] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.08333333333333, 48.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 351264.7883457432, 351264.7883457432, 167195.2216676363]
[2019-03-24 06:21:31,829] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:21:31,830] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9961459e-05 1.3103998e-05 6.4363419e-05 1.3770222e-07 9.9990237e-01], sampled 0.8096491010918059
[2019-03-24 06:21:32,714] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00729905], dtype=float32), 0.004798162]
[2019-03-24 06:21:32,715] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.1577863, 81.46184300166667, 1.0, 2.0, 0.2253631993436868, 1.0, 2.0, 0.2253631993436868, 1.0, 2.0, 0.3587855529221501, 6.911200000000001, 6.9112, 121.94756008, 770537.1175444686, 770537.1175444681, 229059.0481426645]
[2019-03-24 06:21:32,716] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:21:32,718] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9683679e-05 1.2639879e-05 6.3453954e-05 1.3446179e-07 9.9990404e-01], sampled 0.1882056621043905
[2019-03-24 06:21:37,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4490.5950 2940542692.1644 28.0000
[2019-03-24 06:21:37,762] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.9533 2875714617.1956 8.0000
[2019-03-24 06:21:37,846] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4277.9389 2919919956.2289 33.0000
[2019-03-24 06:21:37,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4513.3279 3107335853.9804 0.0000
[2019-03-24 06:21:37,968] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.4163 2894543437.6775 12.0000
[2019-03-24 06:21:38,983] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 350000, evaluation results [350000.0, 4513.327888029111, 3107335853.980426, 0.0, 4609.416276210397, 2894543437.6774726, 12.0, 4392.953291429409, 2875714617.195589, 8.0, 4490.595039099135, 2940542692.164368, 28.0, 4277.938864510663, 2919919956.2289147, 33.0]
[2019-03-24 06:21:42,936] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5470974e-04 1.8761095e-05 1.6032692e-04 5.7973793e-06 9.9956042e-01], sum to 1.0000
[2019-03-24 06:21:42,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8389
[2019-03-24 06:21:42,949] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.43333333333333, 85.33333333333334, 1.0, 2.0, 0.207865757640201, 1.0, 2.0, 0.207865757640201, 1.0, 2.0, 0.3309290558783079, 6.9112, 6.9112, 121.94756008, 710684.0570554617, 710684.0570554617, 223181.1777607993], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5277000.0000, 
sim time next is 5277600.0000, 
raw observation next is [25.4, 85.0, 1.0, 2.0, 0.2064612072474896, 1.0, 2.0, 0.2064612072474896, 1.0, 2.0, 0.3286929659100987, 6.9112, 6.9112, 121.94756008, 705879.7492993816, 705879.7492993816, 222716.7784205547], 
processed observation next is [1.0, 0.08695652173913043, 0.49629629629629624, 0.85, 1.0, 1.0, 0.05531096100891618, 1.0, 1.0, 0.05531096100891618, 1.0, 1.0, 0.1608662073876234, 0.0, 0.0, 0.8096049824067558, 0.2520999104640649, 0.2520999104640649, 0.4283014969626052], 
reward next is 0.5717, 
noisyNet noise sample is [array([-0.4422982], dtype=float32), 0.03170594]. 
=============================================
[2019-03-24 06:21:43,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7916158e-04 1.0577846e-04 2.9967094e-04 1.6235953e-07 9.9931526e-01], sum to 1.0000
[2019-03-24 06:21:43,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9793
[2019-03-24 06:21:43,492] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 87.0, 1.0, 2.0, 0.1897204428737582, 1.0, 2.0, 0.1897204428737582, 1.0, 2.0, 0.3024439453852049, 6.9112, 6.9112, 121.94756008, 657707.841152487, 657707.841152487, 217255.5837675038], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5288400.0000, 
sim time next is 5289000.0000, 
raw observation next is [23.8, 87.33333333333333, 1.0, 2.0, 0.2143903712611179, 1.0, 2.0, 0.2143903712611179, 1.0, 2.0, 0.3417754731241785, 6.9112, 6.9112, 121.94756008, 743327.5119009524, 743327.5119009524, 225349.631784334], 
processed observation next is [1.0, 0.21739130434782608, 0.43703703703703706, 0.8733333333333333, 1.0, 1.0, 0.0647504419775213, 1.0, 1.0, 0.0647504419775213, 1.0, 1.0, 0.1772193414052231, 0.0, 0.0, 0.8096049824067558, 0.2654741113931973, 0.2654741113931973, 0.4333646765083346], 
reward next is 0.5666, 
noisyNet noise sample is [array([0.3734934], dtype=float32), 0.64012927]. 
=============================================
[2019-03-24 06:21:43,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[44.8611  ]
 [44.6479  ]
 [44.64832 ]
 [44.311073]
 [44.079853]], R is [[44.8526535 ]
 [44.98632812]
 [45.11781311]
 [45.24604034]
 [45.36975098]].
[2019-03-24 06:21:44,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6250501e-07 1.8245397e-05 5.8565979e-06 1.0906450e-08 9.9997568e-01], sum to 1.0000
[2019-03-24 06:21:44,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9871
[2019-03-24 06:21:44,569] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.83333333333334, 90.33333333333334, 1.0, 2.0, 0.1830743953106861, 1.0, 2.0, 0.1830743953106861, 1.0, 2.0, 0.2926044878115261, 6.9112, 6.9112, 121.94756008, 642604.811583984, 642604.811583984, 215029.5288914606], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5294400.0000, 
sim time next is 5295000.0000, 
raw observation next is [22.71666666666667, 90.66666666666667, 1.0, 2.0, 0.1802295955781759, 1.0, 2.0, 0.1802295955781759, 1.0, 2.0, 0.2881918818915071, 6.911200000000001, 6.9112, 121.94756008, 633689.4516885822, 633689.4516885817, 214106.7230941149], 
processed observation next is [1.0, 0.2608695652173913, 0.39691358024691364, 0.9066666666666667, 1.0, 1.0, 0.024082851878780818, 1.0, 1.0, 0.024082851878780818, 1.0, 1.0, 0.11023985236438383, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2263176613173508, 0.22631766131735062, 0.41174369825791324], 
reward next is 0.5883, 
noisyNet noise sample is [array([1.9863666], dtype=float32), -1.5378864]. 
=============================================
[2019-03-24 06:21:44,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[54.232155]
 [54.212784]
 [54.201183]
 [54.177998]
 [54.089924]], R is [[54.32011414]
 [54.36339569]
 [54.40329742]
 [54.44369507]
 [54.48000336]].
[2019-03-24 06:21:45,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7947131e-05 1.2932725e-05 8.0073770e-04 5.0460002e-08 9.9915838e-01], sum to 1.0000
[2019-03-24 06:21:45,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7756
[2019-03-24 06:21:45,466] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 79.66666666666667, 1.0, 2.0, 0.4039033396390336, 1.0, 2.0, 0.4039033396390336, 1.0, 2.0, 0.6430272709187701, 6.9112, 6.9112, 121.94756008, 1381532.216461792, 1381532.216461792, 298796.2350595768], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5311200.0000, 
sim time next is 5311800.0000, 
raw observation next is [25.3, 78.5, 1.0, 2.0, 0.4150611109849554, 1.0, 2.0, 0.4150611109849554, 1.0, 2.0, 0.6607908062847212, 6.9112, 6.9112, 121.94756008, 1419732.2113675, 1419732.2113675, 303742.5746254607], 
processed observation next is [1.0, 0.4782608695652174, 0.49259259259259264, 0.785, 1.0, 1.0, 0.30364417974399455, 1.0, 1.0, 0.30364417974399455, 1.0, 1.0, 0.5759885078559015, 0.0, 0.0, 0.8096049824067558, 0.5070472183455357, 0.5070472183455357, 0.5841203358181937], 
reward next is 0.4159, 
noisyNet noise sample is [array([-0.9631545], dtype=float32), -1.1826979]. 
=============================================
[2019-03-24 06:21:48,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8154460e-05 5.4237707e-06 8.0173391e-05 2.6271687e-07 9.9988592e-01], sum to 1.0000
[2019-03-24 06:21:48,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1146
[2019-03-24 06:21:48,458] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.06666666666667, 90.16666666666667, 1.0, 2.0, 0.2547685534651964, 1.0, 2.0, 0.2547685534651964, 1.0, 2.0, 0.4055998343491191, 6.911199999999999, 6.9112, 121.94756008, 871133.8021791588, 871133.8021791592, 239322.6813978856], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5386200.0000, 
sim time next is 5386800.0000, 
raw observation next is [25.23333333333333, 89.33333333333334, 1.0, 2.0, 0.3746843353881212, 1.0, 2.0, 0.3746843353881212, 1.0, 2.0, 0.5965096645547836, 6.9112, 6.9112, 121.94756008, 1281506.406382319, 1281506.406382319, 286170.1360457752], 
processed observation next is [1.0, 0.34782608695652173, 0.49012345679012337, 0.8933333333333334, 1.0, 1.0, 0.2555765897477633, 1.0, 1.0, 0.2555765897477633, 1.0, 1.0, 0.49563708069347945, 0.0, 0.0, 0.8096049824067558, 0.4576808594222568, 0.4576808594222568, 0.5503271847034138], 
reward next is 0.4497, 
noisyNet noise sample is [array([-0.4837064], dtype=float32), 0.17288318]. 
=============================================
[2019-03-24 06:21:49,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5322623e-05 7.0362853e-06 6.0777329e-05 1.5278842e-07 9.9986672e-01], sum to 1.0000
[2019-03-24 06:21:49,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-24 06:21:49,683] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.2057084772307327, 1.0, 2.0, 0.2057084772307327, 1.0, 2.0, 0.3274945952087164, 6.911199999999999, 6.9112, 121.94756008, 703305.0255485396, 703305.02554854, 222468.3508599203], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5378400.0000, 
sim time next is 5379000.0000, 
raw observation next is [24.43333333333333, 91.00000000000001, 1.0, 2.0, 0.2868405069125433, 1.0, 2.0, 0.2868405069125433, 1.0, 2.0, 0.4566594287478979, 6.9112, 6.9112, 121.94756008, 980868.0648504586, 980868.0648504586, 251067.5742445572], 
processed observation next is [1.0, 0.2608695652173913, 0.4604938271604937, 0.9100000000000001, 1.0, 1.0, 0.15100060346731348, 1.0, 1.0, 0.15100060346731348, 1.0, 1.0, 0.32082428593487233, 0.0, 0.0, 0.8096049824067558, 0.35031002316087806, 0.35031002316087806, 0.48282225816261004], 
reward next is 0.5172, 
noisyNet noise sample is [array([-2.097823], dtype=float32), -1.0562317]. 
=============================================
[2019-03-24 06:21:49,697] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[48.090557]
 [48.105022]
 [47.997288]
 [48.08727 ]
 [47.73038 ]], R is [[47.57889938]
 [47.67528915]
 [47.76245499]
 [47.85314941]
 [47.94994354]].
[2019-03-24 06:21:53,036] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6253015e-04 3.9783210e-04 4.7791073e-05 3.5710275e-06 9.9858826e-01], sum to 1.0000
[2019-03-24 06:21:53,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-24 06:21:53,046] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.09999999999999, 70.0, 1.0, 2.0, 0.5180506675322457, 1.0, 2.0, 0.5180506675322457, 1.0, 2.0, 0.8247535344436997, 6.9112, 6.9112, 121.94756008, 1772388.063526737, 1772388.063526737, 352536.8634954771], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [32.3, 69.0, 1.0, 2.0, 0.6385740666492673, 1.0, 2.0, 0.6326516953010682, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2164943.581090957, 2164943.581090958, 413141.7442113165], 
processed observation next is [1.0, 0.5652173913043478, 0.7518518518518518, 0.69, 1.0, 1.0, 0.5697310317253182, 1.0, 1.0, 0.5626805896441288, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7731941361039132, 0.7731941361039135, 0.7945033542525317], 
reward next is 0.2055, 
noisyNet noise sample is [array([-1.0862405], dtype=float32), 1.1582566]. 
=============================================
[2019-03-24 06:21:53,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[38.26703 ]
 [37.119785]
 [35.82757 ]
 [35.78553 ]
 [35.36732 ]], R is [[37.95962143]
 [37.90206909]
 [37.80503464]
 [37.54584885]
 [37.32163239]].
[2019-03-24 06:21:54,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6134939e-03 1.1538686e-03 1.3809934e-03 7.8580932e-05 9.9377304e-01], sum to 1.0000
[2019-03-24 06:21:54,348] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3431
[2019-03-24 06:21:54,357] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.85, 82.5, 1.0, 2.0, 0.8522116282653167, 1.0, 2.0, 0.7394704761090929, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2530997.156105634, 2530997.156105634, 472646.3175139622], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5482200.0000, 
sim time next is 5482800.0000, 
raw observation next is [30.0, 82.0, 1.0, 2.0, 0.881653979135555, 1.0, 2.0, 0.7541916515442121, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2581456.411356, 2581456.411356, 481620.5325458971], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666666, 0.82, 1.0, 1.0, 0.8591118799232798, 1.0, 1.0, 0.7073710137431096, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9219487183414287, 0.9219487183414287, 0.926193331819033], 
reward next is 0.0738, 
noisyNet noise sample is [array([1.2360034], dtype=float32), -1.0268869]. 
=============================================
[2019-03-24 06:22:02,667] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9220507e-05 2.7603204e-07 2.5018911e-05 3.0493123e-07 9.9993515e-01], sum to 1.0000
[2019-03-24 06:22:02,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9377
[2019-03-24 06:22:02,679] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 91.16666666666667, 1.0, 2.0, 0.2151441420015429, 1.0, 2.0, 0.2151441420015429, 1.0, 2.0, 0.3425164808219942, 6.911199999999999, 6.9112, 121.94756008, 735580.4765235457, 735580.4765235462, 225605.3803835529], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5595000.0000, 
sim time next is 5595600.0000, 
raw observation next is [25.36666666666667, 91.33333333333334, 1.0, 2.0, 0.2166002602935157, 1.0, 2.0, 0.2166002602935157, 1.0, 2.0, 0.344834668565277, 6.911200000000001, 6.9112, 121.94756008, 740561.367386624, 740561.3673866235, 226093.9262243712], 
processed observation next is [1.0, 0.782608695652174, 0.49506172839506185, 0.9133333333333334, 1.0, 1.0, 0.06738126225418535, 1.0, 1.0, 0.06738126225418535, 1.0, 1.0, 0.18104333570659623, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26448620263808, 0.2644862026380798, 0.4347960119699446], 
reward next is 0.5652, 
noisyNet noise sample is [array([0.26403463], dtype=float32), -0.6088291]. 
=============================================
[2019-03-24 06:22:02,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0814235e-04 5.7463470e-04 4.0085240e-05 1.0545191e-08 9.9927717e-01], sum to 1.0000
[2019-03-24 06:22:02,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0798
[2019-03-24 06:22:02,801] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.1982818432057327, 1.0, 2.0, 0.1982818432057327, 1.0, 2.0, 0.315671151972332, 6.911200000000001, 6.9112, 121.94756008, 677902.5814819692, 677902.5814819688, 220034.3011965678], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5627400.0000, 
sim time next is 5628000.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.1982317020939327, 1.0, 2.0, 0.1982317020939327, 1.0, 2.0, 0.3155913256893644, 6.9112, 6.9112, 121.94756008, 677731.0790837279, 677731.0790837279, 220017.9725932201], 
processed observation next is [0.0, 0.13043478260869565, 0.42592592592592593, 0.97, 1.0, 1.0, 0.0455139310642056, 1.0, 1.0, 0.0455139310642056, 1.0, 1.0, 0.14448915711170546, 0.0, 0.0, 0.8096049824067558, 0.24204681395847424, 0.24204681395847424, 0.4231114857561925], 
reward next is 0.5769, 
noisyNet noise sample is [array([0.3551046], dtype=float32), -1.3798496]. 
=============================================
[2019-03-24 06:22:02,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.94819 ]
 [57.185833]
 [57.552338]
 [57.50493 ]
 [57.443096]], R is [[57.56692123]
 [57.56811142]
 [57.56927109]
 [57.57041931]
 [57.57152176]].
[2019-03-24 06:22:03,454] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8411500e-05 5.8973924e-04 8.9726082e-06 1.9393720e-07 9.9933261e-01], sum to 1.0000
[2019-03-24 06:22:03,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6237
[2019-03-24 06:22:03,467] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.2, 96.0, 1.0, 2.0, 0.2089130187968315, 1.0, 2.0, 0.2089130187968315, 1.0, 2.0, 0.3325963297465784, 6.9112, 6.9112, 121.94756008, 714266.2655979053, 714266.2655979053, 223528.1618471813], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5641200.0000, 
sim time next is 5641800.0000, 
raw observation next is [24.26666666666667, 95.83333333333333, 1.0, 2.0, 0.2097773595516542, 1.0, 2.0, 0.2097773595516542, 1.0, 2.0, 0.3339723883778694, 6.911200000000001, 6.9112, 121.94756008, 717222.798473194, 717222.7984731935, 223815.0021386588], 
processed observation next is [0.0, 0.30434782608695654, 0.4543209876543211, 0.9583333333333333, 1.0, 1.0, 0.05925876137101689, 1.0, 1.0, 0.05925876137101689, 1.0, 1.0, 0.16746548547233675, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.25615099945471215, 0.256150999454712, 0.4304134656512669], 
reward next is 0.5696, 
noisyNet noise sample is [array([-0.46622917], dtype=float32), -0.7624481]. 
=============================================
[2019-03-24 06:22:05,714] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.64984428e-05 1.02000115e-04 2.71088473e-04 3.98296010e-08
 9.99600351e-01], sum to 1.0000
[2019-03-24 06:22:05,724] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4796
[2019-03-24 06:22:05,730] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.23333333333333, 76.0, 1.0, 2.0, 0.249483493272046, 1.0, 2.0, 0.249483493272046, 1.0, 2.0, 0.3971858463992297, 6.911200000000001, 6.9112, 121.94756008, 853052.4641168907, 853052.4641168902, 237442.3719909699], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.06666666666666, 77.0, 1.0, 2.0, 0.2498660317222393, 1.0, 2.0, 0.2498660317222393, 1.0, 2.0, 0.397794860070345, 6.9112, 6.9112, 121.94756008, 854361.1968684477, 854361.1968684477, 237577.9471108664], 
processed observation next is [0.0, 0.782608695652174, 0.6320987654320985, 0.77, 1.0, 1.0, 0.10698337109790394, 1.0, 1.0, 0.10698337109790394, 1.0, 1.0, 0.2472435750879312, 0.0, 0.0, 0.8096049824067558, 0.30512899888158845, 0.30512899888158845, 0.4568806675208969], 
reward next is 0.5431, 
noisyNet noise sample is [array([-0.4706594], dtype=float32), -0.42586753]. 
=============================================
[2019-03-24 06:22:09,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8640320e-04 5.6748489e-05 5.3493970e-04 1.5118539e-07 9.9912173e-01], sum to 1.0000
[2019-03-24 06:22:09,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4410
[2019-03-24 06:22:09,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.73333333333333, 91.0, 1.0, 2.0, 0.1655056539665007, 1.0, 2.0, 0.1655056539665007, 1.0, 2.0, 0.2665327527792553, 6.9112, 6.9112, 121.94756008, 592747.413160618, 592747.413160618, 209154.2881516318], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5809200.0000, 
sim time next is 5809800.0000, 
raw observation next is [21.86666666666667, 90.0, 1.0, 2.0, 0.1646257178357868, 1.0, 2.0, 0.1646257178357868, 1.0, 2.0, 0.2651091387208688, 6.911199999999999, 6.9112, 121.94756008, 589565.3004659489, 589565.3004659493, 208885.0435951354], 
processed observation next is [1.0, 0.21739130434782608, 0.36543209876543226, 0.9, 1.0, 1.0, 0.005506806947365241, 1.0, 1.0, 0.005506806947365241, 1.0, 1.0, 0.08138642340108596, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.21055903588069602, 0.2105590358806962, 0.4017020069137219], 
reward next is 0.5983, 
noisyNet noise sample is [array([-1.8419651], dtype=float32), 0.14891897]. 
=============================================
[2019-03-24 06:22:16,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.02939899 0.01767941 0.02112221 0.00415047 0.92764896], sum to 1.0000
[2019-03-24 06:22:16,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6811
[2019-03-24 06:22:16,711] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 62.0, 1.0, 2.0, 0.338630613302783, 1.0, 2.0, 0.338630613302783, 1.0, 2.0, 0.5450798566844175, 6.911200000000001, 6.9112, 121.94756008, 1212107.982631112, 1212107.982631112, 270885.6202990919], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5911200.0000, 
sim time next is 5911800.0000, 
raw observation next is [25.35, 61.16666666666667, 1.0, 2.0, 0.3053318308349412, 1.0, 2.0, 0.3053318308349412, 1.0, 2.0, 0.4913909718972274, 6.911200000000001, 6.9112, 121.94756008, 1092418.576178685, 1092418.576178684, 257719.3709167842], 
processed observation next is [1.0, 0.43478260869565216, 0.4944444444444445, 0.6116666666666667, 1.0, 1.0, 0.17301408432731094, 1.0, 1.0, 0.17301408432731094, 1.0, 1.0, 0.36423871487153425, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39014949149238753, 0.3901494914923871, 0.4956141748399696], 
reward next is 0.5044, 
noisyNet noise sample is [array([2.0781038], dtype=float32), -0.085663065]. 
=============================================
[2019-03-24 06:22:22,206] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5082380e-05 2.3148117e-04 5.5577842e-05 1.3634459e-06 9.9969649e-01], sum to 1.0000
[2019-03-24 06:22:22,213] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-24 06:22:22,221] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.3212747936761701, 1.0, 2.0, 0.3212747936761701, 1.0, 2.0, 0.5114799347220196, 6.9112, 6.9112, 121.94756008, 1098702.548813288, 1098702.548813288, 264315.9589206303], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6008400.0000, 
sim time next is 6009000.0000, 
raw observation next is [29.0, 61.5, 1.0, 2.0, 0.3749910125720049, 1.0, 2.0, 0.3749910125720049, 1.0, 2.0, 0.5969979046193049, 6.9112, 6.9112, 121.94756008, 1282556.190694168, 1282556.190694168, 286300.1981522686], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.615, 1.0, 1.0, 0.2559416816333392, 1.0, 1.0, 0.2559416816333392, 1.0, 1.0, 0.4962473807741311, 0.0, 0.0, 0.8096049824067558, 0.45805578239077427, 0.45805578239077427, 0.5505773041389781], 
reward next is 0.4494, 
noisyNet noise sample is [array([0.00874266], dtype=float32), -0.5992696]. 
=============================================
[2019-03-24 06:22:22,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[43.694614]
 [43.56561 ]
 [42.638733]
 [42.026005]
 [41.232414]], R is [[43.88766479]
 [43.94048691]
 [44.01006699]
 [44.06943893]
 [44.07943344]].
[2019-03-24 06:22:24,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9321049e-05 1.9782224e-06 7.0665243e-05 2.0998397e-07 9.9990785e-01], sum to 1.0000
[2019-03-24 06:22:24,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8109
[2019-03-24 06:22:24,219] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.53333333333333, 51.66666666666667, 1.0, 2.0, 0.5779984047404978, 1.0, 2.0, 0.5779984047404978, 1.0, 2.0, 0.9201922844407365, 6.9112, 6.9112, 121.94756008, 1977712.128315442, 1977712.128315442, 383518.3682215148], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6099600.0000, 
sim time next is 6100200.0000, 
raw observation next is [30.5, 52.0, 1.0, 2.0, 0.5869446935820241, 1.0, 2.0, 0.5869446935820241, 1.0, 2.0, 0.934435067636733, 6.911199999999999, 6.9112, 121.94756008, 2008357.672521347, 2008357.672521347, 388308.284887013], 
processed observation next is [1.0, 0.6086956521739131, 0.6851851851851852, 0.52, 1.0, 1.0, 0.5082674923595525, 1.0, 1.0, 0.5082674923595525, 1.0, 1.0, 0.9180438345459163, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7172705973290525, 0.7172705973290525, 0.7467467017057943], 
reward next is 0.2533, 
noisyNet noise sample is [array([-0.272911], dtype=float32), -1.2680762]. 
=============================================
[2019-03-24 06:22:26,973] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:22:26,975] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:22:26,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:26,978] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:22:26,979] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:26,980] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:22:26,982] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:22:26,982] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:22:26,984] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:26,990] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:26,991] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:27,001] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-24 06:22:27,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-24 06:22:27,055] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-24 06:22:27,056] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-24 06:22:27,056] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-24 06:22:28,504] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:22:28,506] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 24.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 367708.5686399696, 367708.5686399701, 149007.3791911086]
[2019-03-24 06:22:28,509] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:22:28,512] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6394517e-06 1.2685448e-06 7.1389509e-06 2.1469180e-08 9.9998796e-01], sampled 0.11742175586660952
[2019-03-24 06:22:36,157] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:22:36,159] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.83333333333333, 25.16666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 425292.1603553697, 425292.1603553697, 180728.1679256402]
[2019-03-24 06:22:36,161] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:22:36,164] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4056571e-06 8.1547000e-07 4.8405141e-06 1.2017834e-08 9.9999189e-01], sampled 0.13199597765770643
[2019-03-24 06:23:07,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:23:07,281] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.33333333333334, 98.0, 1.0, 2.0, 0.175275643947033, 1.0, 2.0, 0.175275643947033, 1.0, 2.0, 0.2796881533146867, 6.9112, 6.9112, 121.94756008, 610971.0098871051, 610971.0098871051, 212639.3480318803]
[2019-03-24 06:23:07,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:23:07,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.3259072e-06 2.1996011e-06 1.1921247e-05 4.6457899e-08 9.9997950e-01], sampled 0.022723826779317613
[2019-03-24 06:23:14,321] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:23:14,323] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.5, 53.66666666666666, 1.0, 2.0, 0.4469209622114967, 1.0, 2.0, 0.4469209622114967, 1.0, 2.0, 0.7115127270402907, 6.9112, 6.9112, 121.94756008, 1528818.79621195, 1528818.79621195, 318245.6224061322]
[2019-03-24 06:23:14,324] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:23:14,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.4144413e-06 3.0706640e-06 1.5962292e-05 7.1816686e-08 9.9997246e-01], sampled 0.8595917045003009
[2019-03-24 06:23:18,187] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:23:18,189] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666666, 85.0, 1.0, 2.0, 0.4772617707431717, 1.0, 2.0, 0.4772617707431717, 1.0, 2.0, 0.7598162823538661, 6.9112, 6.9112, 121.94756008, 1632710.978703529, 1632710.978703529, 332569.0958298052]
[2019-03-24 06:23:18,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:23:18,192] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2162116e-05 4.6087403e-06 2.2391989e-05 1.1919351e-07 9.9996066e-01], sampled 0.03538135977275447
[2019-03-24 06:23:21,419] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:23:21,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.87565380666667, 71.96902606, 1.0, 2.0, 0.2368757444607266, 1.0, 2.0, 0.2368757444607266, 1.0, 2.0, 0.3771138996858962, 6.9112, 6.9112, 121.94756008, 809920.3410456864, 809920.3410456864, 233019.8215811161]
[2019-03-24 06:23:21,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:23:21,426] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6309031e-06 5.2021562e-07 3.3258684e-06 6.7314541e-09 9.9999452e-01], sampled 0.9377458117604457
[2019-03-24 06:23:28,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00737895], dtype=float32), 0.0045137974]
[2019-03-24 06:23:28,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.49243334, 63.9680048, 1.0, 2.0, 0.1630025506036711, 1.0, 2.0, 0.1630025506036711, 1.0, 2.0, 0.2613030847747678, 6.9112, 6.9112, 121.94756008, 577577.1931495945, 577577.1931495945, 208622.5773122177]
[2019-03-24 06:23:28,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:23:28,366] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9689899e-06 6.3021463e-07 3.9615429e-06 8.7982537e-09 9.9999344e-01], sampled 0.1958015363534552
[2019-03-24 06:24:13,458] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4276.7567 2920075557.8507 33.0000
[2019-03-24 06:24:13,639] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.9118 2894627400.8137 12.0000
[2019-03-24 06:24:13,807] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4393.0589 2875811161.0564 8.0000
[2019-03-24 06:24:13,817] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4491.0342 2940647647.8048 28.0000
[2019-03-24 06:24:13,943] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4512.9526 3107449379.1896 0.0000
[2019-03-24 06:24:14,959] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 375000, evaluation results [375000.0, 4512.9526200127175, 3107449379.189636, 0.0, 4609.911759045645, 2894627400.813697, 12.0, 4393.058948646484, 2875811161.0563874, 8.0, 4491.034231614697, 2940647647.8048067, 28.0, 4276.756711876909, 2920075557.8506994, 33.0]
[2019-03-24 06:24:15,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8238952e-06 4.1758326e-06 1.2210043e-04 2.5171881e-08 9.9986386e-01], sum to 1.0000
[2019-03-24 06:24:15,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6837
[2019-03-24 06:24:15,349] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.03333333333333, 54.33333333333334, 1.0, 2.0, 0.5125547365029359, 1.0, 2.0, 0.5125547365029359, 1.0, 2.0, 0.8160038332550609, 6.911200000000001, 6.9112, 121.94756008, 1753566.580073529, 1753566.580073529, 349793.7987670568], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6106800.0000, 
sim time next is 6107400.0000, 
raw observation next is [30.0, 54.5, 1.0, 2.0, 0.5167668832584392, 1.0, 2.0, 0.5167668832584392, 1.0, 2.0, 0.8227097080698649, 6.9112, 6.9112, 121.94756008, 1767991.55283503, 1767991.55283503, 351894.651397753], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666666, 0.545, 1.0, 1.0, 0.4247224800695705, 1.0, 1.0, 0.4247224800695705, 1.0, 1.0, 0.7783871350873312, 0.0, 0.0, 0.8096049824067558, 0.6314255545839393, 0.6314255545839393, 0.6767204834572172], 
reward next is 0.3233, 
noisyNet noise sample is [array([1.116909], dtype=float32), 0.072618015]. 
=============================================
[2019-03-24 06:24:21,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9023441e-07 1.7760760e-06 1.9424790e-06 3.2727201e-09 9.9999523e-01], sum to 1.0000
[2019-03-24 06:24:21,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6925
[2019-03-24 06:24:21,012] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.66666666666666, 87.66666666666667, 1.0, 2.0, 0.162733431847716, 1.0, 2.0, 0.162733431847716, 1.0, 2.0, 0.2611356481447041, 6.9112, 6.9112, 121.94756008, 578157.3837250319, 578157.3837250319, 208488.8400929077], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6241200.0000, 
sim time next is 6241800.0000, 
raw observation next is [22.78333333333333, 87.33333333333333, 1.0, 2.0, 0.1637377849740982, 1.0, 2.0, 0.1637377849740982, 1.0, 2.0, 0.2626071838369245, 6.911199999999999, 6.9112, 121.94756008, 580927.5873552085, 580927.5873552089, 208823.824574423], 
processed observation next is [0.0, 0.21739130434782608, 0.39938271604938264, 0.8733333333333333, 1.0, 1.0, 0.004449744016783554, 1.0, 1.0, 0.004449744016783554, 1.0, 1.0, 0.0782589797961556, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2074741383411459, 0.20747413834114606, 0.40158427802773655], 
reward next is 0.5984, 
noisyNet noise sample is [array([0.98464304], dtype=float32), -1.1114005]. 
=============================================
[2019-03-24 06:24:35,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9755991e-05 3.3011591e-05 2.7070793e-05 2.3045221e-08 9.9984014e-01], sum to 1.0000
[2019-03-24 06:24:35,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-24 06:24:35,158] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.06666666666667, 86.0, 1.0, 2.0, 0.2375487770944625, 1.0, 2.0, 0.2375487770944625, 1.0, 2.0, 0.3781853895579465, 6.911200000000001, 6.9112, 121.94756008, 812222.7785200696, 812222.7785200691, 233253.663914934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6549600.0000, 
sim time next is 6550200.0000, 
raw observation next is [27.0, 86.5, 1.0, 2.0, 0.2376288998804805, 1.0, 2.0, 0.2376288998804805, 1.0, 2.0, 0.3783129476427041, 6.9112, 6.9112, 121.94756008, 812496.8781786092, 812496.8781786092, 233281.519100759], 
processed observation next is [1.0, 0.8260869565217391, 0.5555555555555556, 0.865, 1.0, 1.0, 0.09241535700057202, 1.0, 1.0, 0.09241535700057202, 1.0, 1.0, 0.22289118455338014, 0.0, 0.0, 0.8096049824067558, 0.29017745649236043, 0.29017745649236043, 0.44861830596299807], 
reward next is 0.5514, 
noisyNet noise sample is [array([1.4120439], dtype=float32), 0.77517164]. 
=============================================
[2019-03-24 06:24:36,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7731062e-06 2.8267013e-05 4.3652084e-04 5.2900413e-07 9.9952793e-01], sum to 1.0000
[2019-03-24 06:24:36,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6640
[2019-03-24 06:24:36,054] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.43333333333333, 79.83333333333334, 1.0, 2.0, 0.4711517394938536, 1.0, 2.0, 0.4711517394938536, 1.0, 2.0, 0.7500889136151261, 6.911200000000001, 6.9112, 121.94756008, 1611789.729847721, 1611789.72984772, 329651.4541609855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [27.46666666666667, 79.66666666666667, 1.0, 2.0, 0.4800216375294963, 1.0, 2.0, 0.4800216375294963, 1.0, 2.0, 0.7642100801602809, 6.911199999999999, 6.9112, 121.94756008, 1642161.14986797, 1642161.149867971, 333891.680059779], 
processed observation next is [1.0, 0.6521739130434783, 0.5728395061728396, 0.7966666666666667, 1.0, 1.0, 0.38097813991606705, 1.0, 1.0, 0.38097813991606705, 1.0, 1.0, 0.7052626002003511, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5864861249528465, 0.5864861249528468, 0.6420993847303443], 
reward next is 0.3579, 
noisyNet noise sample is [array([0.9175732], dtype=float32), 1.5199647]. 
=============================================
[2019-03-24 06:24:36,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8062237e-04 1.0278396e-04 8.7082048e-04 1.6456972e-06 9.9804413e-01], sum to 1.0000
[2019-03-24 06:24:36,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9851
[2019-03-24 06:24:36,474] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 79.0, 1.0, 2.0, 0.5258287028650245, 1.0, 2.0, 0.5258287028650245, 1.0, 2.0, 0.8371364200064096, 6.911199999999999, 6.9112, 121.94756008, 1799025.56807939, 1799025.568079391, 356446.9053049923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6537600.0000, 
sim time next is 6538200.0000, 
raw observation next is [27.65, 78.83333333333334, 1.0, 2.0, 0.5730923083637081, 1.0, 2.0, 0.5730923083637081, 1.0, 2.0, 0.912381619228483, 6.9112, 6.9112, 121.94756008, 1960906.724143951, 1960906.724143951, 380909.9269296594], 
processed observation next is [1.0, 0.6956521739130435, 0.5796296296296296, 0.7883333333333334, 1.0, 1.0, 0.49177655757584293, 1.0, 1.0, 0.49177655757584293, 1.0, 1.0, 0.8904770240356038, 0.0, 0.0, 0.8096049824067558, 0.7003238300514111, 0.7003238300514111, 0.7325190902493449], 
reward next is 0.2675, 
noisyNet noise sample is [array([0.70833856], dtype=float32), -1.3051821]. 
=============================================
[2019-03-24 06:24:49,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3381875e-03 2.5627273e-03 9.2069218e-03 6.3397514e-04 9.8625815e-01], sum to 1.0000
[2019-03-24 06:24:49,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-24 06:24:49,516] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.03333333333333, 54.66666666666667, 1.0, 2.0, 0.40474902205478, 1.0, 2.0, 0.40474902205478, 1.0, 2.0, 0.6454701752083974, 6.911199999999999, 6.9112, 121.94756008, 1407026.094584486, 1407026.094584486, 299249.4786996031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6798000.0000, 
sim time next is 6798600.0000, 
raw observation next is [28.05, 55.0, 1.0, 2.0, 0.4089940980947927, 1.0, 2.0, 0.4089940980947927, 1.0, 2.0, 0.6520962114719215, 6.9112, 6.9112, 121.94756008, 1419908.881492912, 1419908.881492912, 301127.8568748503], 
processed observation next is [1.0, 0.6956521739130435, 0.5944444444444444, 0.55, 1.0, 1.0, 0.2964215453509437, 1.0, 1.0, 0.2964215453509437, 1.0, 1.0, 0.5651202643399019, 0.0, 0.0, 0.8096049824067558, 0.5071103148188971, 0.5071103148188971, 0.5790920324516352], 
reward next is 0.4209, 
noisyNet noise sample is [array([-1.1630628], dtype=float32), 0.59952927]. 
=============================================
[2019-03-24 06:24:56,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.02545722 0.02966119 0.03303468 0.0286495  0.8831974 ], sum to 1.0000
[2019-03-24 06:24:56,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1233
[2019-03-24 06:24:56,280] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.96666666666667, 80.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2450098065345406, 6.911199999999999, 6.9112, 121.94756008, 545849.4559250729, 545849.4559250734, 203477.4223299353], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6939600.0000, 
sim time next is 6940200.0000, 
raw observation next is [23.08333333333333, 80.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2465107977768201, 6.9112, 6.9112, 121.94756008, 548880.5901395315, 548880.5901395315, 204003.8621316444], 
processed observation next is [0.0, 0.30434782608695654, 0.41049382716049365, 0.8033333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.058138497221025126, 0.0, 0.0, 0.8096049824067558, 0.19602878219268982, 0.19602878219268982, 0.3923151194839315], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.247824], dtype=float32), 0.27101356]. 
=============================================
[2019-03-24 06:25:01,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8354886e-04 3.5671473e-03 3.4128004e-04 1.6724870e-04 9.9534082e-01], sum to 1.0000
[2019-03-24 06:25:01,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0793
[2019-03-24 06:25:01,336] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.4, 75.66666666666667, 1.0, 2.0, 0.3159003033379993, 1.0, 2.0, 0.3159003033379993, 1.0, 2.0, 0.504507057126084, 6.911199999999999, 6.9112, 121.94756008, 1105755.641913198, 1105755.641913199, 262195.5479037693], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7058400.0000, 
sim time next is 7059000.0000, 
raw observation next is [24.15, 76.83333333333333, 1.0, 2.0, 0.3159063979299436, 1.0, 2.0, 0.3159063979299436, 1.0, 2.0, 0.5046478925631763, 6.9112, 6.9112, 121.94756008, 1106968.201214772, 1106968.201214772, 262188.7797549097], 
processed observation next is [1.0, 0.6956521739130435, 0.44999999999999996, 0.7683333333333333, 1.0, 1.0, 0.18560285467850432, 1.0, 1.0, 0.18560285467850432, 1.0, 1.0, 0.38080986570397035, 0.0, 0.0, 0.8096049824067558, 0.3953457861481328, 0.3953457861481328, 0.5042091918363648], 
reward next is 0.4958, 
noisyNet noise sample is [array([-0.10870636], dtype=float32), -1.5357648]. 
=============================================
[2019-03-24 06:25:01,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[29.60649 ]
 [29.544598]
 [29.25505 ]
 [28.85944 ]
 [28.472435]], R is [[29.6838932 ]
 [29.88283157]
 [30.08623505]
 [30.2714386 ]
 [30.40067291]].
[2019-03-24 06:25:01,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3010715e-03 1.2172306e-02 3.3863287e-03 2.0083500e-04 9.8293948e-01], sum to 1.0000
[2019-03-24 06:25:01,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3406
[2019-03-24 06:25:01,419] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.76666666666667, 89.66666666666667, 1.0, 2.0, 0.1665937129820808, 1.0, 2.0, 0.1665937129820808, 1.0, 2.0, 0.2711960171321267, 6.911200000000001, 6.9112, 121.94756008, 607114.3725778314, 607114.3725778309, 208910.5349386618], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7015200.0000, 
sim time next is 7015800.0000, 
raw observation next is [20.68333333333333, 90.33333333333334, 1.0, 2.0, 0.1641532005972039, 1.0, 2.0, 0.1641532005972039, 1.0, 2.0, 0.2673473791279743, 6.9112, 6.9112, 121.94756008, 598580.5980428999, 598580.5980428999, 208135.5099526501], 
processed observation next is [1.0, 0.17391304347826086, 0.3216049382716048, 0.9033333333333334, 1.0, 1.0, 0.00494428642524273, 1.0, 1.0, 0.00494428642524273, 1.0, 1.0, 0.08418422390996785, 0.0, 0.0, 0.8096049824067558, 0.21377878501532138, 0.21377878501532138, 0.4002605960627887], 
reward next is 0.5997, 
noisyNet noise sample is [array([-1.7867544], dtype=float32), -1.7723547]. 
=============================================
[2019-03-24 06:25:03,065] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 06:25:03,067] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:25:03,067] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:25:03,068] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:25:03,069] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:25:03,069] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:25:03,070] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:25:03,070] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:25:03,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:25:03,071] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:25:03,077] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:25:03,088] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-24 06:25:03,115] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-24 06:25:03,140] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-24 06:25:03,141] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-24 06:25:03,142] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-24 06:25:05,482] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00712586], dtype=float32), 0.00411827]
[2019-03-24 06:25:05,484] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.7, 57.5, 1.0, 2.0, 0.369882672936103, 1.0, 2.0, 0.369882672936103, 1.0, 2.0, 0.5921856462567405, 6.911199999999999, 6.9112, 121.94756008, 1306397.45121987, 1306397.45121987, 284079.0589362871]
[2019-03-24 06:25:05,485] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:25:05,488] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1974831e-04 3.4261233e-04 4.6521280e-04 1.6630629e-05 9.9905580e-01], sampled 0.9153176194936131
[2019-03-24 06:25:42,341] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00712586], dtype=float32), 0.00411827]
[2019-03-24 06:25:42,343] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.16666666666667, 70.0, 1.0, 2.0, 0.2100813699122127, 1.0, 2.0, 0.2100813699122127, 1.0, 2.0, 0.3344563827728048, 6.9112, 6.9112, 121.94756008, 718262.6880803367, 718262.6880803367, 223915.9904659716]
[2019-03-24 06:25:42,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:25:42,347] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.5893724e-05 1.7534659e-04 2.3673993e-04 6.4047490e-06 9.9952567e-01], sampled 0.1416134405030307
[2019-03-24 06:26:48,729] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00712586], dtype=float32), 0.00411827]
[2019-03-24 06:26:48,730] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.641838255, 59.887370525, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 442205.9356917631, 442205.9356917626, 185392.4195063965]
[2019-03-24 06:26:48,731] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:26:48,732] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.6550819e-05 2.5960259e-04 3.4771179e-04 1.1134504e-05 9.9929500e-01], sampled 0.9243613345064373
[2019-03-24 06:26:50,335] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4608.2056 2894377472.0048 12.0000
[2019-03-24 06:26:50,348] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4512.8694 3106943075.0683 0.0000
[2019-03-24 06:26:50,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4276.5311 2919393150.0664 33.0000
[2019-03-24 06:26:50,600] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4394.1508 2875354185.3773 8.0000
[2019-03-24 06:26:50,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4493.2007 2940248014.2153 28.0000
[2019-03-24 06:26:51,653] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 400000, evaluation results [400000.0, 4512.869392365094, 3106943075.0683484, 0.0, 4608.2055923842645, 2894377472.0047903, 12.0, 4394.150846121872, 2875354185.3773456, 8.0, 4493.200731585518, 2940248014.215324, 28.0, 4276.531117555522, 2919393150.066354, 33.0]
[2019-03-24 06:26:59,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.00613806 0.01474311 0.04156463 0.00937803 0.9281762 ], sum to 1.0000
[2019-03-24 06:26:59,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-24 06:26:59,525] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.61666666666667, 92.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.208524404619938, 6.9112, 6.9112, 121.94756008, 467370.3915234149, 467370.3915234149, 190078.4199826225], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7188600.0000, 
sim time next is 7189200.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2068386935301767, 6.9112, 6.9112, 121.94756008, 463558.2146752925, 463558.2146752925, 189519.232404466], 
processed observation next is [1.0, 0.21739130434782608, 0.28148148148148155, 0.92, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.008548366912720859, 0.0, 0.0, 0.8096049824067558, 0.16555650524117588, 0.16555650524117588, 0.36446006231628075], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15535417], dtype=float32), 0.8831714]. 
=============================================
[2019-03-24 06:27:02,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00791886 0.02742578 0.0217189  0.00730557 0.93563086], sum to 1.0000
[2019-03-24 06:27:02,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5104
[2019-03-24 06:27:02,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.4, 88.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.211240046844912, 6.911199999999999, 6.9112, 121.94756008, 473556.307181845, 473556.3071818455, 191279.6023939792], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7272000.0000, 
sim time next is 7272600.0000, 
raw observation next is [20.38333333333333, 88.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2193877400305997, 6.9112, 6.9112, 121.94756008, 491829.5973779319, 491829.5973779319, 193661.3352215113], 
processed observation next is [1.0, 0.17391304347826086, 0.3104938271604937, 0.8816666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.024234675038249595, 0.0, 0.0, 0.8096049824067558, 0.17565342763497566, 0.17565342763497566, 0.37242564465675254], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2201447], dtype=float32), 1.0938327]. 
=============================================
[2019-03-24 06:27:03,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.02048597 0.05623258 0.05505831 0.01822514 0.849998  ], sum to 1.0000
[2019-03-24 06:27:03,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-24 06:27:03,709] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.4, 88.0, 1.0, 2.0, 0.1913492393823981, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3170242380238074, 6.911199999999999, 6.9112, 121.9260426156618, 473553.1598432814, 473553.1598432819, 165637.6639332931], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7272000.0000, 
sim time next is 7272600.0000, 
raw observation next is [20.38333333333333, 88.16666666666667, 1.0, 2.0, 0.1987109823085073, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3292586177918289, 6.911199999999999, 6.9112, 121.9260426156618, 491826.0919997876, 491826.0919997881, 167271.0408667381], 
processed observation next is [1.0, 0.17391304347826086, 0.3104938271604937, 0.8816666666666667, 1.0, 1.0, 0.04608450274822299, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.16157327223978613, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17565217571420985, 0.17565217571421005, 0.321675078589881], 
reward next is 0.6783, 
noisyNet noise sample is [array([-1.0773587], dtype=float32), -0.69888926]. 
=============================================
[2019-03-24 06:27:04,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.00376929 0.02664602 0.03017768 0.00189464 0.9375124 ], sum to 1.0000
[2019-03-24 06:27:04,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-24 06:27:04,361] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.3497138813600881, 1.0, 2.0, 0.3497138813600881, 1.0, 2.0, 0.5579468890897806, 6.911199999999999, 6.9112, 121.94756008, 1218471.960233406, 1218471.960233406, 275796.5484446607], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7318800.0000, 
sim time next is 7319400.0000, 
raw observation next is [26.73333333333333, 61.66666666666667, 1.0, 2.0, 0.195746680528196, 1.0, 2.0, 0.195746680528196, 1.0, 2.0, 0.3129137043103664, 6.911200000000001, 6.9112, 121.94756008, 687556.750325007, 687556.7503250065, 219091.591805888], 
processed observation next is [1.0, 0.7391304347826086, 0.545679012345679, 0.6166666666666667, 1.0, 1.0, 0.04255557205737618, 1.0, 1.0, 0.04255557205737618, 1.0, 1.0, 0.141142130387958, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24555598225893108, 0.2455559822589309, 0.4213299842420923], 
reward next is 0.5787, 
noisyNet noise sample is [array([1.3492823], dtype=float32), 0.19375558]. 
=============================================
[2019-03-24 06:27:07,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.02107337 0.06940064 0.13695382 0.03079027 0.7417819 ], sum to 1.0000
[2019-03-24 06:27:07,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0223
[2019-03-24 06:27:07,101] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 75.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2436950458360315, 6.911200000000001, 6.9112, 121.94756008, 543411.9234221039, 543411.9234221034, 202944.8846669625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7331400.0000, 
sim time next is 7332000.0000, 
raw observation next is [23.4, 76.33333333333334, 1.0, 2.0, 0.4476835413724406, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543898.3646159809, 543898.3646159809, 135249.9463489855], 
processed observation next is [1.0, 0.8695652173913043, 0.42222222222222217, 0.7633333333333334, 1.0, 1.0, 0.3424804063957626, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19424941593427889, 0.19424941593427889, 0.260096050671126], 
reward next is 0.7399, 
noisyNet noise sample is [array([1.1509266], dtype=float32), 0.011190724]. 
=============================================
[2019-03-24 06:27:07,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[19.10326 ]
 [19.413448]
 [19.343494]
 [19.454885]
 [19.982697]], R is [[19.1501503 ]
 [18.95864868]
 [18.76906204]
 [18.58137131]
 [18.3955574 ]].
[2019-03-24 06:27:10,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.01720746 0.03443345 0.06131231 0.0078516  0.8791952 ], sum to 1.0000
[2019-03-24 06:27:10,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2396
[2019-03-24 06:27:10,874] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.8, 90.0, 1.0, 2.0, 0.2067989703069323, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3388382363651832, 6.9112, 6.9112, 121.9260426156618, 506320.6770659878, 506320.6770659878, 169793.8433424318], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7408800.0000, 
sim time next is 7409400.0000, 
raw observation next is [20.75, 90.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2267214028486707, 6.9112, 6.9112, 121.94756008, 507929.9489641048, 507929.9489641048, 196656.1481824373], 
processed observation next is [1.0, 0.782608695652174, 0.32407407407407407, 0.9, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.03340175356083837, 0.0, 0.0, 0.8096049824067558, 0.181403553201466, 0.181403553201466, 0.37818490035084096], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2664009], dtype=float32), 0.15113106]. 
=============================================
[2019-03-24 06:27:12,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.01438049 0.13121551 0.1365885  0.0390243  0.6787912 ], sum to 1.0000
[2019-03-24 06:27:12,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8306
[2019-03-24 06:27:12,701] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.75, 87.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2307190762290352, 6.9112, 6.9112, 121.94756008, 515273.4627967145, 515273.4627967145, 198841.0352131304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7464600.0000, 
sim time next is 7465200.0000, 
raw observation next is [21.9, 87.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2326141499108851, 6.9112, 6.9112, 121.94756008, 519206.261292344, 519206.261292344, 199512.3779802237], 
processed observation next is [0.0, 0.391304347826087, 0.36666666666666664, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04076768738860637, 0.0, 0.0, 0.8096049824067558, 0.18543080760440858, 0.18543080760440858, 0.3836776499619687], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.6397455], dtype=float32), 0.6435957]. 
=============================================
[2019-03-24 06:27:17,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9342660e-04 7.1962655e-04 6.4761085e-03 2.4382329e-04 9.9216700e-01], sum to 1.0000
[2019-03-24 06:27:17,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5798
[2019-03-24 06:27:17,129] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2389897706293124, 6.9112, 6.9112, 121.94756008, 532862.7059095411, 532862.7059095411, 201577.2737060806], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7531800.0000, 
sim time next is 7532400.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2386815931033377, 6.9112, 6.9112, 121.94756008, 532178.4361820533, 532178.4361820533, 201485.6983681172], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04835199137917211, 0.0, 0.0, 0.8096049824067558, 0.19006372720787618, 0.19006372720787618, 0.3874724968617639], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.99963224], dtype=float32), 0.11092473]. 
=============================================
[2019-03-24 06:27:17,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0893879e-04 3.8961045e-04 1.0433394e-02 1.6718188e-03 9.8719621e-01], sum to 1.0000
[2019-03-24 06:27:17,691] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-24 06:27:17,699] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.55, 93.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2440822510718909, 6.9112, 6.9112, 121.94756008, 543070.4158062718, 543070.4158062718, 203386.9302139056], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7547400.0000, 
sim time next is 7548000.0000, 
raw observation next is [21.73333333333333, 92.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2455806370105822, 6.911200000000001, 6.9112, 121.94756008, 545894.6997491535, 545894.699749153, 203944.9435209401], 
processed observation next is [0.0, 0.34782608695652173, 0.3604938271604937, 0.9233333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.056975796263227727, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.1949623927675548, 0.19496239276755464, 0.39220181446334634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01596314], dtype=float32), 0.47950912]. 
=============================================
[2019-03-24 06:27:17,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[34.4642  ]
 [34.441326]
 [34.75413 ]
 [34.71425 ]
 [34.442482]], R is [[34.31071091]
 [33.96760559]
 [33.62792969]
 [33.29164886]
 [32.9587326 ]].
[2019-03-24 06:27:20,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.20975493e-07 1.07391956e-04 1.37441629e-03 2.75134244e-06
 9.98514712e-01], sum to 1.0000
[2019-03-24 06:27:20,697] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6803
[2019-03-24 06:27:20,704] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.1834609661380303, 1.0, 2.0, 0.1834609661380303, 1.0, 2.0, 0.2923732534689454, 6.911199999999999, 6.9112, 121.94756008, 634598.3433741434, 634598.3433741438, 215265.1174665028], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7574400.0000, 
sim time next is 7575000.0000, 
raw observation next is [27.88333333333334, 62.0, 1.0, 2.0, 0.1815916223196064, 1.0, 2.0, 0.1815916223196064, 1.0, 2.0, 0.28948998112118, 6.911200000000001, 6.9112, 121.94756008, 629582.0632684028, 629582.0632684025, 214662.7515246585], 
processed observation next is [0.0, 0.6956521739130435, 0.5882716049382718, 0.62, 1.0, 1.0, 0.025704312285245716, 1.0, 1.0, 0.025704312285245716, 1.0, 1.0, 0.11186247640147501, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22485073688157245, 0.2248507368815723, 0.41281298370126635], 
reward next is 0.5872, 
noisyNet noise sample is [array([0.38877356], dtype=float32), 0.6137514]. 
=============================================
[2019-03-24 06:27:20,718] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[53.90045 ]
 [53.928486]
 [53.61266 ]
 [53.57179 ]
 [53.612484]], R is [[53.93710709]
 [53.98376465]
 [54.02859497]
 [54.07177353]
 [54.11359787]].
[2019-03-24 06:27:21,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3977263e-05 3.5058347e-05 1.8443934e-04 1.3555749e-05 9.9974293e-01], sum to 1.0000
[2019-03-24 06:27:21,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2789
[2019-03-24 06:27:21,421] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 78.5, 1.0, 2.0, 0.1751764944944379, 1.0, 2.0, 0.1751764944944379, 1.0, 2.0, 0.2796549348046699, 6.9112, 6.9112, 121.94756008, 611924.6486108549, 611924.6486108549, 212589.9786046758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7587000.0000, 
sim time next is 7587600.0000, 
raw observation next is [24.63333333333333, 79.66666666666667, 1.0, 2.0, 0.1752381175032932, 1.0, 2.0, 0.1752381175032932, 1.0, 2.0, 0.2797464708397961, 6.9112, 6.9112, 121.94756008, 612071.839088386, 612071.839088386, 212610.3020246117], 
processed observation next is [0.0, 0.8260869565217391, 0.46790123456790106, 0.7966666666666667, 1.0, 1.0, 0.01814061607534906, 1.0, 1.0, 0.01814061607534906, 1.0, 1.0, 0.0996830885497451, 0.0, 0.0, 0.8096049824067558, 0.2185970853887093, 0.2185970853887093, 0.4088659654319456], 
reward next is 0.5911, 
noisyNet noise sample is [array([-1.0732049], dtype=float32), -0.17477207]. 
=============================================
[2019-03-24 06:27:30,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.01094039 0.01876491 0.09244706 0.02811017 0.84973747], sum to 1.0000
[2019-03-24 06:27:30,638] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8665
[2019-03-24 06:27:30,641] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 48.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2139485900040984, 6.911199999999999, 6.9112, 121.94756008, 477971.6262194397, 477971.6262194401, 189912.1202334068], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7804200.0000, 
sim time next is 7804800.0000, 
raw observation next is [25.4, 48.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2426562102071823, 6.9112, 6.9112, 121.94756008, 542348.1352695349, 542348.1352695349, 198146.4564575093], 
processed observation next is [1.0, 0.34782608695652173, 0.49629629629629624, 0.48, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.053320262758977874, 0.0, 0.0, 0.8096049824067558, 0.19369576259626245, 0.19369576259626245, 0.38105087780290253], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.63574046], dtype=float32), 0.20536777]. 
=============================================
[2019-03-24 06:27:35,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:35,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:36,012] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-24 06:27:36,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:36,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:36,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-24 06:27:36,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:36,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:36,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-24 06:27:36,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:36,946] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:36,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-24 06:27:37,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:37,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:37,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-24 06:27:37,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:37,613] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:37,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-24 06:27:37,714] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:37,715] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:37,718] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-24 06:27:37,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:37,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:37,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-24 06:27:37,914] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:37,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:37,916] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-24 06:27:38,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-24 06:27:38,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,218] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-24 06:27:38,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,266] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-24 06:27:38,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-24 06:27:38,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-24 06:27:38,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,392] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-24 06:27:38,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:27:38,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:38,487] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-24 06:27:39,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.01178327 0.02830548 0.08518761 0.11476502 0.7599586 ], sum to 1.0000
[2019-03-24 06:27:39,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1736
[2019-03-24 06:27:39,916] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.55, 75.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2197054006947597, 6.9112, 6.9112, 121.94756008, 478067.5141114736, 478067.5141114736, 186026.9649863557], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7800.0000, 
sim time next is 8400.0000, 
raw observation next is [18.5, 75.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406710.2660837862, 406710.2660837867, 151325.9823761276], 
processed observation next is [1.0, 0.08695652173913043, 0.24074074074074073, 0.7533333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14525366645849508, 0.14525366645849525, 0.2910115045694761], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03258793], dtype=float32), -1.3417567]. 
=============================================
[2019-03-24 06:27:40,582] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 06:27:40,582] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:27:40,584] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:40,585] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:27:40,586] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:27:40,586] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:40,586] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:40,587] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:27:40,588] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:40,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:27:40,591] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:40,613] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-24 06:27:40,638] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-24 06:27:40,663] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-24 06:27:40,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-24 06:27:40,664] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-24 06:28:11,149] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00744054], dtype=float32), 0.0039786096]
[2019-03-24 06:28:11,150] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666666, 68.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2164727402547315, 6.911199999999999, 6.9112, 121.94756008, 485110.5374760585, 485110.537476059, 193483.9186923675]
[2019-03-24 06:28:11,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:28:11,156] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0025488  0.01492649 0.01837001 0.01060196 0.95355266], sampled 0.8734430652584473
[2019-03-24 06:28:50,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00744054], dtype=float32), 0.0039786096]
[2019-03-24 06:28:50,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.13518245666667, 100.5963441933333, 1.0, 2.0, 0.3678125340209883, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5855695329793615, 6.911199999999999, 6.9112, 121.9260426156618, 838426.6845676017, 838426.6845676021, 214378.3536887465]
[2019-03-24 06:28:50,888] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:28:50,892] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.6267727e-04 4.2142174e-03 5.8278786e-03 2.5247028e-03 9.8697054e-01], sampled 0.798633925263344
[2019-03-24 06:29:09,969] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00744054], dtype=float32), 0.0039786096]
[2019-03-24 06:29:09,970] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.85285423, 80.08677592, 1.0, 2.0, 0.3309840134253689, 1.0, 2.0, 0.3309840134253689, 1.0, 2.0, 0.5269373287699557, 6.9112, 6.9112, 121.94756008, 1131930.873672153, 1131930.873672153, 268170.8456288625]
[2019-03-24 06:29:09,971] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:29:09,973] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.0261477e-04 4.6089017e-03 6.1675687e-03 2.7452908e-03 9.8597568e-01], sampled 0.9353772148817537
[2019-03-24 06:29:18,070] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00744054], dtype=float32), 0.0039786096]
[2019-03-24 06:29:18,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.8, 84.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2151775611836073, 6.911200000000001, 6.9112, 121.94756008, 482381.5300715648, 482381.5300715644, 192350.542055392]
[2019-03-24 06:29:18,072] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:29:18,076] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.00221662 0.01305031 0.01665159 0.00925281 0.9588287 ], sampled 0.4369078151449196
[2019-03-24 06:29:25,467] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00744054], dtype=float32), 0.0039786096]
[2019-03-24 06:29:25,469] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.46465014333334, 89.37853153, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 422194.2403728379, 422194.2403728379, 182175.8697258403]
[2019-03-24 06:29:25,470] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:29:25,473] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.00256988 0.01455461 0.01852323 0.01050053 0.9538517 ], sampled 0.42105856072337633
[2019-03-24 06:29:27,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4422.4810 2860616166.2828 12.0000
[2019-03-24 06:29:27,939] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4630.4974 2879692041.1831 14.0000
[2019-03-24 06:29:27,952] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4536.4134 3094313636.8538 4.0000
[2019-03-24 06:29:27,965] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4304.0314 2905288802.1461 38.0000
[2019-03-24 06:29:28,264] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4524.2867 2927875500.7340 28.0000
[2019-03-24 06:29:29,277] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 425000, evaluation results [425000.0, 4536.413365027109, 3094313636.853753, 4.0, 4630.497410443444, 2879692041.1831, 14.0, 4422.481016181975, 2860616166.282776, 12.0, 4524.286680105298, 2927875500.7340417, 28.0, 4304.031402632873, 2905288802.1460934, 38.0]
[2019-03-24 06:29:40,017] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.03217087 0.20121913 0.09642521 0.15497892 0.51520586], sum to 1.0000
[2019-03-24 06:29:40,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0331
[2019-03-24 06:29:40,032] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 27.66666666666667, 1.0, 2.0, 0.3457491928451276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442102.1825674325, 442102.1825674321, 121416.6853282609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 246000.0000, 
sim time next is 246600.0000, 
raw observation next is [28.7, 28.5, 1.0, 2.0, 0.3423640626086832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438029.5142457873, 438029.5142457873, 120971.9171219807], 
processed observation next is [0.0, 0.8695652173913043, 0.6185185185185185, 0.285, 1.0, 1.0, 0.21710007453414665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1564391122306383, 0.1564391122306383, 0.23263830215765519], 
reward next is 0.7674, 
noisyNet noise sample is [array([1.1486148], dtype=float32), -0.049481608]. 
=============================================
[2019-03-24 06:29:40,038] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.04298923 0.18542258 0.12631288 0.16925985 0.4760154 ], sum to 1.0000
[2019-03-24 06:29:40,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5380
[2019-03-24 06:29:40,055] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.7, 34.0, 1.0, 2.0, 0.1625147919785384, 1.0, 2.0, 0.1625147919785384, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 414545.4861294608, 414545.4861294613, 152399.8090459438], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 250200.0000, 
sim time next is 250800.0000, 
raw observation next is [26.36666666666667, 35.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 1.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 410820.5424380731, 410820.5424380736, 177558.8605036472], 
processed observation next is [0.0, 0.9130434782608695, 0.5320987654320989, 0.35, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.14672162229931182, 0.14672162229931202, 0.3414593471223985], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44376406], dtype=float32), -0.44059512]. 
=============================================
[2019-03-24 06:29:47,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2080969e-04 6.5321374e-01 4.6865297e-03 2.7489230e-02 3.1428969e-01], sum to 1.0000
[2019-03-24 06:29:47,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7622
[2019-03-24 06:29:47,478] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.31666666666667, 29.5, 1.0, 2.0, 0.8449056567302353, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1074500.310624148, 1074500.310624148, 209371.2405787189], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 384600.0000, 
sim time next is 385200.0000, 
raw observation next is [28.5, 29.0, 1.0, 2.0, 0.2793864939287297, 1.0, 1.0, 0.2793864939287297, 1.0, 1.0, 0.4721161214149184, 6.911200000000001, 6.9112, 121.94756008, 1052463.549997566, 1052463.549997565, 245107.4065932019], 
processed observation next is [1.0, 0.4782608695652174, 0.6111111111111112, 0.29, 1.0, 1.0, 0.142126778486583, 1.0, 0.5, 0.142126778486583, 1.0, 0.5, 0.34014515176864796, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.37587983928484503, 0.3758798392848447, 0.47136039729461904], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03382367], dtype=float32), 0.9738058]. 
=============================================
[2019-03-24 06:29:49,085] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0044588  0.521954   0.02788985 0.03943278 0.40626448], sum to 1.0000
[2019-03-24 06:29:49,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2459
[2019-03-24 06:29:49,095] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 31.0, 1.0, 2.0, 0.9161951826721578, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.113491237077124, 6.9112, 121.9252497062393, 1237866.801334686, 1134276.281039834, 224992.6301123511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [31.16666666666667, 30.5, 1.0, 2.0, 0.9981112119699187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.699888065789567, 6.9112, 121.9228393557685, 1646951.420557136, 1243083.249499429, 244831.2417359964], 
processed observation next is [1.0, 0.5652173913043478, 0.7098765432098767, 0.305, 1.0, 1.0, 0.9977514428213318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.07886880657895672, 0.0, 0.8094408625056, 0.5881969359132628, 0.44395830339265324, 0.4708293110307623], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6654187], dtype=float32), -0.5308328]. 
=============================================
[2019-03-24 06:29:54,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.00122034 0.55034107 0.01467678 0.08865547 0.3451064 ], sum to 1.0000
[2019-03-24 06:29:54,572] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7097
[2019-03-24 06:29:54,577] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.93333333333334, 63.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 1.0, 0.2, 6.9112, 6.9112, 121.94756008, 399096.3622083284, 399096.3622083284, 176742.9306137355], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 520800.0000, 
sim time next is 521400.0000, 
raw observation next is [21.76666666666667, 64.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 399267.712312266, 399267.7123122665, 176836.3161718851], 
processed observation next is [1.0, 0.0, 0.3617283950617285, 0.64, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.142595611540095, 0.14259561154009517, 0.3400698387920867], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21874794], dtype=float32), 0.5046686]. 
=============================================
[2019-03-24 06:29:57,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5081861e-04 1.2208058e-01 1.4755797e-03 3.7148660e-01 5.0480640e-01], sum to 1.0000
[2019-03-24 06:29:57,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-24 06:29:57,292] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.2, 33.0, 1.0, 2.0, 0.3874115888254534, 1.0, 2.0, 0.3874115888254534, 1.0, 2.0, 0.6240418436178069, 6.9112, 6.9112, 121.94756008, 1388872.415228831, 1388872.415228831, 291270.6677533201], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 572400.0000, 
sim time next is 573000.0000, 
raw observation next is [31.28333333333333, 32.83333333333334, 1.0, 2.0, 0.6418371346554548, 1.0, 2.0, 0.6418371346554548, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1546145.293120477, 1546145.293120478, 286337.4318685188], 
processed observation next is [1.0, 0.6521739130434783, 0.7141975308641975, 0.3283333333333334, 1.0, 1.0, 0.573615636494589, 1.0, 1.0, 0.573615636494589, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5521947475430276, 0.5521947475430279, 0.5506489074394593], 
reward next is 0.4494, 
noisyNet noise sample is [array([-0.62286115], dtype=float32), -2.2127619]. 
=============================================
[2019-03-24 06:29:57,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.38188 ]
 [50.778675]
 [49.272114]
 [50.005867]
 [50.617554]], R is [[49.49163818]
 [49.43658829]
 [48.9422226 ]
 [48.91973877]
 [48.86870575]].
[2019-03-24 06:30:02,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8183854e-04 1.7849630e-01 5.0604939e-03 1.5263493e-02 8.0049789e-01], sum to 1.0000
[2019-03-24 06:30:02,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0064
[2019-03-24 06:30:02,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666667, 18.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2234821140626047, 6.9112, 6.9112, 121.94756008, 500197.3310524567, 500197.3310524567, 193352.774665687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 668400.0000, 
sim time next is 669000.0000, 
raw observation next is [34.43333333333334, 18.66666666666667, 1.0, 2.0, 0.3956367120296798, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496986.3818820539, 496986.3818820539, 128133.2614799911], 
processed observation next is [1.0, 0.7391304347826086, 0.8308641975308644, 0.1866666666666667, 1.0, 1.0, 0.28051989527342835, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17749513638644782, 0.17749513638644782, 0.2464101182307521], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.6157263], dtype=float32), -0.5461086]. 
=============================================
[2019-03-24 06:30:02,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[40.380745]
 [41.24811 ]
 [42.707497]
 [42.86346 ]
 [43.634804]], R is [[38.4776268 ]
 [38.09284973]
 [37.71192169]
 [37.33480453]
 [37.53952789]].
[2019-03-24 06:30:06,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.00163325 0.3477603  0.0019023  0.41471317 0.23399103], sum to 1.0000
[2019-03-24 06:30:06,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9718
[2019-03-24 06:30:06,552] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.36666666666667, 33.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2, 6.9112, 6.9112, 121.94756008, 423694.9997648729, 423694.9997648729, 181009.6205477052], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 768000.0000, 
sim time next is 768600.0000, 
raw observation next is [28.2, 33.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 422594.8626251193, 422594.8626251198, 181019.3219732255], 
processed observation next is [1.0, 0.9130434782608695, 0.6, 0.335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.15092673665182832, 0.1509267366518285, 0.34811408071774136], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14002867], dtype=float32), -0.3962229]. 
=============================================
[2019-03-24 06:30:07,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.00637726 0.12207023 0.00512883 0.71683216 0.14959157], sum to 1.0000
[2019-03-24 06:30:07,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9430
[2019-03-24 06:30:07,915] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 43.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 383361.9925824342, 383361.9925824347, 148555.0636665442], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 778800.0000, 
sim time next is 779400.0000, 
raw observation next is [25.25, 44.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 1.0, 0.2, 6.9112, 6.9112, 121.94756008, 381643.3893138513, 381643.3893138513, 173534.3868177642], 
processed observation next is [0.0, 0.0, 0.49074074074074076, 0.44, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8096049824067558, 0.1363012104692326, 0.1363012104692326, 0.33371997464954656], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1735827], dtype=float32), -1.8804286]. 
=============================================
[2019-03-24 06:30:10,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9851225e-04 2.3461571e-02 1.1826946e-04 9.5199555e-01 2.4226103e-02], sum to 1.0000
[2019-03-24 06:30:10,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5374
[2019-03-24 06:30:10,423] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 51.5, 1.0, 2.0, 0.1955018390532028, 1.0, 2.0, 0.1955018390532028, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481358.9713241899, 481358.9713241903, 158885.7545278592], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 811800.0000, 
sim time next is 812400.0000, 
raw observation next is [26.7, 50.66666666666667, 1.0, 2.0, 0.1975008391046096, 1.0, 2.0, 0.1975008391046096, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 485483.0727770816, 485483.0727770821, 159279.5271130505], 
processed observation next is [0.0, 0.391304347826087, 0.5444444444444444, 0.5066666666666667, 1.0, 1.0, 0.0446438560769162, 1.0, 1.0, 0.0446438560769162, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17338681170610057, 0.17338681170610074, 0.3063067829097125], 
reward next is 0.6937, 
noisyNet noise sample is [array([0.66963863], dtype=float32), 2.5755]. 
=============================================
[2019-03-24 06:30:14,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2974736e-07 2.6241103e-02 1.5952495e-05 9.7219402e-01 1.5481350e-03], sum to 1.0000
[2019-03-24 06:30:14,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3135
[2019-03-24 06:30:14,072] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 49.0, 1.0, 2.0, 0.188910959739526, 1.0, 2.0, 0.188910959739526, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 468227.3318898448, 468227.3318898453, 157606.6097506984], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 932400.0000, 
sim time next is 933000.0000, 
raw observation next is [26.13333333333333, 49.66666666666667, 1.0, 2.0, 0.188339373414155, 1.0, 2.0, 0.188339373414155, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466969.4616661393, 466969.4616661398, 157492.7896073475], 
processed observation next is [0.0, 0.8260869565217391, 0.5234567901234567, 0.4966666666666667, 1.0, 1.0, 0.033737349302565466, 1.0, 1.0, 0.033737349302565466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1667748077379069, 0.16677480773790707, 0.30287074924489904], 
reward next is 0.6971, 
noisyNet noise sample is [array([1.2112671], dtype=float32), 1.8081365]. 
=============================================
[2019-03-24 06:30:14,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.74306 ]
 [64.93782 ]
 [64.94008 ]
 [64.82583 ]
 [65.025055]], R is [[64.81173706]
 [64.86052704]
 [64.9085083 ]
 [64.95557404]
 [65.00170135]].
[2019-03-24 06:30:16,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0921480e-05 1.1178451e-03 2.5925490e-06 9.5665801e-01 4.2160556e-02], sum to 1.0000
[2019-03-24 06:30:16,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4338
[2019-03-24 06:30:16,464] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.23333333333333, 57.0, 1.0, 2.0, 0.1613416209924927, 1.0, 2.0, 0.1613416209924927, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406749.4542227573, 406749.4542227577, 152106.6798037379], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1016400.0000, 
sim time next is 1017000.0000, 
raw observation next is [22.75, 59.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 402867.1502698167, 402867.1502698172, 151686.5848428083], 
processed observation next is [1.0, 0.782608695652174, 0.39814814814814814, 0.59, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1438811250963631, 0.14388112509636328, 0.29170497085155445], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8257149], dtype=float32), 0.42860672]. 
=============================================
[2019-03-24 06:30:16,480] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[54.958565]
 [56.268612]
 [57.423836]
 [58.504097]
 [59.666153]], R is [[53.34509659]
 [53.51913452]
 [53.69079208]
 [53.85996246]
 [54.02729034]].
[2019-03-24 06:30:17,285] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 06:30:17,286] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:30:17,287] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:30:17,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:17,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:17,289] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:30:17,289] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:30:17,288] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:30:17,291] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:17,292] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:17,292] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:17,310] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-24 06:30:17,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-24 06:30:17,334] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-24 06:30:17,380] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-24 06:30:17,381] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-24 06:30:49,865] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00818373], dtype=float32), 0.0048793824]
[2019-03-24 06:30:49,866] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 41.0, 1.0, 2.0, 0.6451397714245071, 1.0, 2.0, 0.6451397714245071, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1471199.603100068, 1471199.603100068, 283917.687838229]
[2019-03-24 06:30:49,867] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:30:49,871] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9347780e-07 3.9124739e-04 4.0273807e-07 9.9928880e-01 3.1927321e-04], sampled 0.7154724881071282
[2019-03-24 06:31:42,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00818373], dtype=float32), 0.0048793824]
[2019-03-24 06:31:42,422] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.8, 83.0, 1.0, 2.0, 0.5977721838525217, 1.0, 2.0, 0.5977721838525217, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1363084.751215584, 1363084.751215584, 267277.1419991928]
[2019-03-24 06:31:42,423] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:31:42,426] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3352548e-07 3.4172006e-04 3.2463447e-07 9.9935180e-01 3.0589348e-04], sampled 0.6799362717890506
[2019-03-24 06:31:52,635] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00818373], dtype=float32), 0.0048793824]
[2019-03-24 06:31:52,637] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.20170514333334, 84.25244604, 1.0, 2.0, 0.2016114320764696, 1.0, 2.0, 0.2016114320764696, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495662.4053938572, 495662.4053938576, 160145.5599546069]
[2019-03-24 06:31:52,638] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:31:52,640] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4047264e-06 1.3932392e-03 4.4288599e-06 9.9751151e-01 1.0874628e-03], sampled 0.703908697803185
[2019-03-24 06:32:04,098] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7112.1643 2438619138.4491 33.0000
[2019-03-24 06:32:04,850] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6895.8337 2495171602.9828 47.0000
[2019-03-24 06:32:04,907] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7455.2342 2465894040.1623 46.0000
[2019-03-24 06:32:04,913] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7497.1082 2668532046.5390 67.0000
[2019-03-24 06:32:04,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7769.7994 2410704778.7340 22.0000
[2019-03-24 06:32:06,008] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 450000, evaluation results [450000.0, 7497.108213488986, 2668532046.538992, 67.0, 7112.164297544297, 2438619138.449143, 33.0, 7769.799445057817, 2410704778.734009, 22.0, 6895.833731795978, 2495171602.982827, 47.0, 7455.234208586183, 2465894040.1622972, 46.0]
[2019-03-24 06:32:11,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.7502298e-06 1.2604170e-03 3.4165087e-06 9.9780113e-01 9.2530769e-04], sum to 1.0000
[2019-03-24 06:32:11,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8151
[2019-03-24 06:32:11,919] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 45.0, 1.0, 2.0, 0.3520247641613432, 1.0, 2.0, 0.3520247641613432, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 880847.3473521969, 880847.3473521983, 196225.5716616623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1081800.0000, 
sim time next is 1082400.0000, 
raw observation next is [25.73333333333333, 44.33333333333333, 1.0, 2.0, 0.322154567252525, 1.0, 2.0, 0.322154567252525, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 806675.5395366829, 806675.5395366834, 188475.0622586704], 
processed observation next is [1.0, 0.5217391304347826, 0.5086419753086419, 0.4433333333333333, 1.0, 1.0, 0.1930411514911012, 1.0, 1.0, 0.1930411514911012, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28809840697738676, 0.2880984069773869, 0.3624520428051354], 
reward next is 0.6375, 
noisyNet noise sample is [array([-0.84884024], dtype=float32), 0.8718977]. 
=============================================
[2019-03-24 06:32:13,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1200320e-05 6.6294573e-04 6.6628570e-05 9.9894840e-01 2.6086363e-04], sum to 1.0000
[2019-03-24 06:32:13,319] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5595
[2019-03-24 06:32:13,324] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.05, 51.0, 1.0, 2.0, 0.1687114955863715, 1.0, 2.0, 0.1687114955863715, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422306.2484225116, 422306.2484225116, 153539.193937692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1101000.0000, 
sim time next is 1101600.0000, 
raw observation next is [24.8, 52.0, 1.0, 2.0, 0.1693442525538703, 1.0, 2.0, 0.1693442525538703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 424119.3167940279, 424119.3167940284, 153673.2754658154], 
processed observation next is [1.0, 0.782608695652174, 0.4740740740740741, 0.52, 1.0, 1.0, 0.011124110183178939, 1.0, 1.0, 0.011124110183178939, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15147118456929567, 0.15147118456929584, 0.2955255297419527], 
reward next is 0.7045, 
noisyNet noise sample is [array([0.42616645], dtype=float32), -0.24292018]. 
=============================================
[2019-03-24 06:32:14,546] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.1284192e-06 1.8570340e-03 1.2894243e-05 9.9740016e-01 7.2074693e-04], sum to 1.0000
[2019-03-24 06:32:14,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0896
[2019-03-24 06:32:14,558] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.11666666666667, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 353062.1117907489, 353062.1117907489, 143556.7459230055], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1129800.0000, 
sim time next is 1130400.0000, 
raw observation next is [19.1, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 351697.0582984101, 351697.0582984106, 143347.7644895531], 
processed observation next is [1.0, 0.08695652173913043, 0.262962962962963, 0.74, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12560609224943217, 0.12560609224943237, 0.2756687778645252], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55431193], dtype=float32), 0.09679532]. 
=============================================
[2019-03-24 06:32:17,072] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1257793e-05 3.2528084e-02 7.2768441e-04 9.6281850e-01 3.8444868e-03], sum to 1.0000
[2019-03-24 06:32:17,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3161
[2019-03-24 06:32:17,081] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 80.0, 1.0, 2.0, 0.1758454467685886, 1.0, 2.0, 0.1758454467685886, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 440279.0627883208, 440279.0627883213, 155004.0567529932], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1191600.0000, 
sim time next is 1192200.0000, 
raw observation next is [20.33333333333333, 80.5, 1.0, 2.0, 0.1751957893369967, 1.0, 2.0, 0.1751957893369967, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438673.1824347606, 438673.1824347611, 154870.5603089491], 
processed observation next is [1.0, 0.8260869565217391, 0.3086419753086418, 0.805, 1.0, 1.0, 0.018090225401186544, 1.0, 1.0, 0.018090225401186544, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1566689937267002, 0.15666899372670037, 0.2978280005941329], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.01432969], dtype=float32), -1.9315953]. 
=============================================
[2019-03-24 06:32:18,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5788722e-06 6.6354946e-04 8.0256450e-07 9.9906129e-01 2.7281715e-04], sum to 1.0000
[2019-03-24 06:32:18,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6189
[2019-03-24 06:32:18,786] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.05, 93.0, 1.0, 2.0, 0.162024842811124, 1.0, 2.0, 0.162024842811124, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409462.8708974149, 409462.8708974149, 152260.2971971562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1218600.0000, 
sim time next is 1219200.0000, 
raw observation next is [18.03333333333333, 93.0, 1.0, 2.0, 0.1610422547590967, 1.0, 2.0, 0.1610422547590967, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 407124.4579192352, 407124.4579192356, 152064.568991152], 
processed observation next is [1.0, 0.08695652173913043, 0.22345679012345673, 0.93, 1.0, 1.0, 0.0012407794751151126, 1.0, 1.0, 0.0012407794751151126, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14540159211401257, 0.1454015921140127, 0.29243186344452304], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.54598296], dtype=float32), -0.7415868]. 
=============================================
[2019-03-24 06:32:19,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2017990e-09 5.3433882e-07 8.6382894e-11 9.9999261e-01 6.9429452e-06], sum to 1.0000
[2019-03-24 06:32:19,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1539
[2019-03-24 06:32:19,154] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666666, 56.33333333333334, 1.0, 2.0, 0.5037650484345205, 1.0, 2.0, 0.5037650484345205, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1214109.213315651, 1214109.213315652, 239308.2664949336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1263000.0000, 
sim time next is 1263600.0000, 
raw observation next is [26.2, 56.0, 1.0, 2.0, 0.5172824728058335, 1.0, 2.0, 0.5172824728058335, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1246586.983874358, 1246586.983874358, 243614.5441139588], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.56, 1.0, 1.0, 0.42533627714980177, 1.0, 1.0, 0.42533627714980177, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.445209637097985, 0.445209637097985, 0.46848950791145927], 
reward next is 0.5315, 
noisyNet noise sample is [array([1.4554493], dtype=float32), -0.6609492]. 
=============================================
[2019-03-24 06:32:20,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7953182e-09 3.0589861e-05 1.0101338e-07 9.9995828e-01 1.0908296e-05], sum to 1.0000
[2019-03-24 06:32:20,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-24 06:32:20,517] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.3, 81.0, 1.0, 2.0, 0.2873016026919413, 1.0, 2.0, 0.2873016026919413, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716111.2929045912, 716111.2929045912, 179755.6036805967], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1242000.0000, 
sim time next is 1242600.0000, 
raw observation next is [20.5, 79.83333333333333, 1.0, 2.0, 0.3588920220271926, 1.0, 2.0, 0.3588920220271926, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 892798.8648029665, 892798.864802966, 197951.3194723231], 
processed observation next is [1.0, 0.391304347826087, 0.3148148148148148, 0.7983333333333333, 1.0, 1.0, 0.23677621669903884, 1.0, 1.0, 0.23677621669903884, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3188567374296309, 0.3188567374296307, 0.38067561436985214], 
reward next is 0.6193, 
noisyNet noise sample is [array([1.3818256], dtype=float32), -0.09603464]. 
=============================================
[2019-03-24 06:32:32,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8617298e-08 1.0954125e-04 1.0123974e-06 9.9760628e-01 2.2831308e-03], sum to 1.0000
[2019-03-24 06:32:32,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6650
[2019-03-24 06:32:32,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.9, 67.16666666666667, 1.0, 2.0, 0.1707544333428029, 1.0, 2.0, 0.1707544333428029, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429217.0298702568, 429217.0298702568, 153994.0711718191], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1482600.0000, 
sim time next is 1483200.0000, 
raw observation next is [21.8, 68.0, 1.0, 2.0, 0.1710017050134664, 1.0, 2.0, 0.1710017050134664, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 429709.7266107408, 429709.7266107413, 154042.1328524786], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.68, 1.0, 1.0, 0.01309726787317428, 1.0, 1.0, 0.01309726787317428, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.153467759503836, 0.15346775950383618, 0.29623487087015116], 
reward next is 0.7038, 
noisyNet noise sample is [array([-1.0868754], dtype=float32), 0.31828094]. 
=============================================
[2019-03-24 06:32:41,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3615212e-09 2.4054780e-08 1.5293473e-08 9.9999845e-01 1.5640971e-06], sum to 1.0000
[2019-03-24 06:32:41,344] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4618
[2019-03-24 06:32:41,347] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.56666666666667, 69.0, 1.0, 2.0, 0.5007052961665075, 1.0, 2.0, 0.5007052961665075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1213493.103468691, 1213493.103468692, 238566.211058724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1698600.0000, 
sim time next is 1699200.0000, 
raw observation next is [23.6, 69.0, 1.0, 2.0, 0.4304933948423378, 1.0, 2.0, 0.4304933948423378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1044295.612135208, 1044295.612135208, 217291.6929298351], 
processed observation next is [1.0, 0.6956521739130435, 0.4296296296296297, 0.69, 1.0, 1.0, 0.32201594624087837, 1.0, 1.0, 0.32201594624087837, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37296271861971714, 0.37296271861971714, 0.41786864024968284], 
reward next is 0.5821, 
noisyNet noise sample is [array([-0.5126286], dtype=float32), 0.54559094]. 
=============================================
[2019-03-24 06:32:44,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.50965683e-07 8.47873453e-05 1.14756155e-07 9.99898911e-01
 1.55207636e-05], sum to 1.0000
[2019-03-24 06:32:44,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2644
[2019-03-24 06:32:44,102] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.4, 74.0, 1.0, 2.0, 0.2161300223340447, 1.0, 2.0, 0.2161300223340447, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 525172.40709321, 525172.4070932105, 163044.2218427305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1708800.0000, 
sim time next is 1709400.0000, 
raw observation next is [23.35, 74.5, 1.0, 2.0, 0.215773376492308, 1.0, 2.0, 0.215773376492308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 524120.9759386794, 524120.9759386799, 162960.9570331465], 
processed observation next is [1.0, 0.782608695652174, 0.42037037037037045, 0.745, 1.0, 1.0, 0.06639687677655713, 1.0, 1.0, 0.06639687677655713, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18718606283524264, 0.1871860628352428, 0.31338645583297403], 
reward next is 0.6866, 
noisyNet noise sample is [array([0.06832998], dtype=float32), -0.05393599]. 
=============================================
[2019-03-24 06:32:44,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3519361e-09 1.0239709e-06 1.1326467e-08 9.9999607e-01 2.8262118e-06], sum to 1.0000
[2019-03-24 06:32:44,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0080
[2019-03-24 06:32:44,511] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.1727166348349507, 1.0, 2.0, 0.1727166348349507, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434387.737282242, 434387.737282242, 154400.9401856153], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1832400.0000, 
sim time next is 1833000.0000, 
raw observation next is [18.95, 89.16666666666667, 1.0, 2.0, 0.1781118737204456, 1.0, 2.0, 0.1781118737204456, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 447712.1934603621, 447712.1934603626, 155509.7922878002], 
processed observation next is [1.0, 0.21739130434782608, 0.25740740740740736, 0.8916666666666667, 1.0, 1.0, 0.021561754429101895, 1.0, 1.0, 0.021561754429101895, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15989721195012932, 0.15989721195012951, 0.29905729286115423], 
reward next is 0.7009, 
noisyNet noise sample is [array([1.8138282], dtype=float32), -2.4080908]. 
=============================================
[2019-03-24 06:32:44,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.723526]
 [63.729023]
 [63.730007]
 [63.69569 ]
 [63.66131 ]], R is [[63.82823181]
 [63.89302444]
 [63.95601654]
 [64.01819611]
 [64.08096313]].
[2019-03-24 06:32:46,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2408120e-09 2.6786849e-05 1.9322826e-09 9.9989307e-01 8.0063401e-05], sum to 1.0000
[2019-03-24 06:32:46,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6003
[2019-03-24 06:32:46,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.5, 86.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393388.49851155, 393388.4985115504, 150010.5213915214], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1805400.0000, 
sim time next is 1806000.0000, 
raw observation next is [18.53333333333333, 86.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397169.929215304, 397169.9292153044, 150605.6971425651], 
processed observation next is [1.0, 0.9130434782608695, 0.24197530864197525, 0.8666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14184640329117998, 0.14184640329118015, 0.289626340658779], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1910231], dtype=float32), 0.6657935]. 
=============================================
[2019-03-24 06:32:46,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.43813 ]
 [67.285355]
 [66.78147 ]
 [66.3459  ]
 [66.016846]], R is [[66.81292725]
 [66.14479828]
 [65.48335266]
 [64.82852173]
 [64.18023682]].
[2019-03-24 06:32:47,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4826542e-09 7.2754489e-07 7.5417532e-08 9.9998534e-01 1.3806989e-05], sum to 1.0000
[2019-03-24 06:32:47,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-24 06:32:47,705] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666666, 62.16666666666666, 1.0, 2.0, 0.6110639727763083, 1.0, 2.0, 0.6110639727763083, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1447701.934573788, 1447701.934573788, 274345.6225345824], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1779000.0000, 
sim time next is 1779600.0000, 
raw observation next is [26.53333333333333, 61.33333333333334, 1.0, 2.0, 0.6411704271983505, 1.0, 2.0, 0.6411704271983505, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1511080.280276082, 1511080.280276083, 284784.3222959135], 
processed observation next is [1.0, 0.6086956521739131, 0.5382716049382715, 0.6133333333333334, 1.0, 1.0, 0.5728219371408935, 1.0, 1.0, 0.5728219371408935, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5396715286700293, 0.5396715286700297, 0.5476621582613721], 
reward next is 0.4523, 
noisyNet noise sample is [array([-3.1432776], dtype=float32), -0.75115705]. 
=============================================
[2019-03-24 06:32:48,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6658118e-08 1.9497356e-06 3.5975567e-08 9.9999321e-01 4.7343051e-06], sum to 1.0000
[2019-03-24 06:32:48,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4864
[2019-03-24 06:32:48,762] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.6, 77.0, 1.0, 2.0, 0.3189782760482395, 1.0, 2.0, 0.3189782760482395, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 786737.9349976537, 786737.9349976542, 187404.7456383329], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1846800.0000, 
sim time next is 1847400.0000, 
raw observation next is [21.63333333333334, 77.0, 1.0, 2.0, 0.3578267477135162, 1.0, 2.0, 0.3578267477135162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881283.7390133124, 881283.7390133124, 197456.5863723349], 
processed observation next is [1.0, 0.391304347826087, 0.35679012345679034, 0.77, 1.0, 1.0, 0.23550803299228118, 1.0, 1.0, 0.23550803299228118, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31474419250475444, 0.31474419250475444, 0.3797242045621825], 
reward next is 0.6203, 
noisyNet noise sample is [array([-0.25402653], dtype=float32), -0.726112]. 
=============================================
[2019-03-24 06:32:52,363] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9022684e-09 3.0307632e-05 1.5993290e-06 9.9928963e-01 6.7854743e-04], sum to 1.0000
[2019-03-24 06:32:52,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5971
[2019-03-24 06:32:52,377] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 89.0, 1.0, 2.0, 0.2142023052249495, 1.0, 2.0, 0.2142023052249495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520889.5199799223, 520889.5199799227, 162643.6171201518], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1879200.0000, 
sim time next is 1879800.0000, 
raw observation next is [21.28333333333333, 89.16666666666667, 1.0, 2.0, 0.2153644904906034, 1.0, 2.0, 0.2153644904906034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523701.4883292301, 523701.4883292301, 162892.9620614137], 
processed observation next is [1.0, 0.782608695652174, 0.3438271604938271, 0.8916666666666667, 1.0, 1.0, 0.06591010772690882, 1.0, 1.0, 0.06591010772690882, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1870362458318679, 0.1870362458318679, 0.31325569627194944], 
reward next is 0.6867, 
noisyNet noise sample is [array([-0.6703739], dtype=float32), 0.48134604]. 
=============================================
[2019-03-24 06:32:53,980] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 06:32:53,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:32:53,983] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:53,983] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:32:53,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:32:53,984] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:53,986] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:53,987] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:32:53,988] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:32:53,990] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:53,991] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:54,008] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-24 06:32:54,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-24 06:32:54,035] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-24 06:32:54,077] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-24 06:32:54,101] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-24 06:33:05,080] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00848502], dtype=float32), 0.005217783]
[2019-03-24 06:33:05,080] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.16666666666667, 23.0, 1.0, 2.0, 0.503000147776918, 1.0, 2.0, 0.503000147776918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1247459.541097456, 1247459.541097457, 240081.6716430794]
[2019-03-24 06:33:05,081] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:33:05,083] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7590472e-08 1.3025951e-05 8.2698151e-08 9.9997199e-01 1.4956189e-05], sampled 0.353282438699438
[2019-03-24 06:33:06,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00848502], dtype=float32), 0.005217783]
[2019-03-24 06:33:06,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.82400121, 31.60093495333333, 1.0, 2.0, 0.2431063606557676, 1.0, 2.0, 0.2431063606557676, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578406.9870225796, 578406.9870225801, 168521.9514955136]
[2019-03-24 06:33:06,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:33:06,688] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9756573e-08 7.1551626e-06 3.5258278e-08 9.9998367e-01 9.1981765e-06], sampled 0.9808982089217839
[2019-03-24 06:33:26,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00848502], dtype=float32), 0.005217783]
[2019-03-24 06:33:26,250] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.46340204833334, 73.17760104666667, 1.0, 2.0, 0.2636624410628618, 1.0, 2.0, 0.2636624410628618, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 630262.3977277525, 630262.3977277529, 173308.7747282686]
[2019-03-24 06:33:26,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:33:26,256] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1235565e-08 9.8083365e-06 5.4822006e-08 9.9997830e-01 1.1819643e-05], sampled 0.6795698621208023
[2019-03-24 06:33:35,357] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00848502], dtype=float32), 0.005217783]
[2019-03-24 06:33:35,359] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.26666666666667, 81.33333333333334, 1.0, 2.0, 0.8047311872128246, 1.0, 2.0, 0.8047311872128246, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1835530.321801144, 1835530.321801143, 345714.2588989176]
[2019-03-24 06:33:35,361] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:33:35,363] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4138440e-09 1.7057754e-06 4.6667510e-09 9.9999571e-01 2.5661923e-06], sampled 0.4942866864129667
[2019-03-24 06:34:23,127] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00848502], dtype=float32), 0.005217783]
[2019-03-24 06:34:23,130] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.33333333333334, 92.33333333333334, 1.0, 2.0, 0.261850099947628, 1.0, 2.0, 0.261850099947628, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 609070.2790233238, 609070.2790233243, 172166.2758610513]
[2019-03-24 06:34:23,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:34:23,134] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5735186e-08 5.9987215e-06 2.8595586e-08 9.9998546e-01 8.5732172e-06], sampled 0.17336897835959642
[2019-03-24 06:34:41,618] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7520.2649 2668560100.9945 68.0000
[2019-03-24 06:34:41,830] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473084.7055 47.0000
[2019-03-24 06:34:41,998] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2509 2438816149.8681 34.0000
[2019-03-24 06:34:42,004] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7799.0617 2410680163.6948 22.0000
[2019-03-24 06:34:42,085] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.0628 2465991683.2747 46.0000
[2019-03-24 06:34:43,098] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 475000, evaluation results [475000.0, 7520.264856580551, 2668560100.9944863, 68.0, 7122.250931801856, 2438816149.8680835, 34.0, 7799.061735162378, 2410680163.6948166, 22.0, 6905.908355438081, 2495473084.7055235, 47.0, 7477.062817679772, 2465991683.274708, 46.0]
[2019-03-24 06:34:43,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6197672e-08 8.5974098e-06 3.0742985e-08 9.9998820e-01 3.1536722e-06], sum to 1.0000
[2019-03-24 06:34:43,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-24 06:34:43,573] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.58333333333333, 92.0, 1.0, 2.0, 0.1845413307212665, 1.0, 2.0, 0.1845413307212665, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457919.1518491962, 457919.1518491962, 156707.7941384964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1907400.0000, 
sim time next is 1908000.0000, 
raw observation next is [19.5, 92.0, 1.0, 2.0, 0.182828118341462, 1.0, 2.0, 0.182828118341462, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454199.224823771, 454199.224823771, 156364.9000392375], 
processed observation next is [1.0, 0.08695652173913043, 0.2777777777777778, 0.92, 1.0, 1.0, 0.02717633135888334, 1.0, 1.0, 0.02717633135888334, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1622140088656325, 0.1622140088656325, 0.3007017308446875], 
reward next is 0.6993, 
noisyNet noise sample is [array([-0.6297577], dtype=float32), -0.85299706]. 
=============================================
[2019-03-24 06:34:43,594] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.868546]
 [67.42359 ]
 [66.76746 ]
 [66.55904 ]
 [65.93039 ]], R is [[68.18707275]
 [68.20384216]
 [68.21976471]
 [68.2348175 ]
 [68.24899292]].
[2019-03-24 06:34:50,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7527580e-08 2.0635132e-04 1.1757812e-06 9.9976832e-01 2.4156350e-05], sum to 1.0000
[2019-03-24 06:34:51,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0492
[2019-03-24 06:34:51,017] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.26666666666667, 81.33333333333334, 1.0, 2.0, 0.2344421807937091, 1.0, 2.0, 0.2344421807937091, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 561003.944559553, 561003.9445595535, 166728.441153906], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2076000.0000, 
sim time next is 2076600.0000, 
raw observation next is [23.18333333333334, 81.66666666666667, 1.0, 2.0, 0.2335381206819934, 1.0, 2.0, 0.2335381206819934, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 559198.8618241604, 559198.8618241609, 166543.0319174659], 
processed observation next is [0.0, 0.0, 0.4141975308641978, 0.8166666666666668, 1.0, 1.0, 0.08754538176427785, 1.0, 1.0, 0.08754538176427785, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19971387922291445, 0.19971387922291461, 0.32027506137974215], 
reward next is 0.6797, 
noisyNet noise sample is [array([-0.67183346], dtype=float32), 0.28562593]. 
=============================================
[2019-03-24 06:34:53,234] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3887806e-08 3.3462577e-05 3.8796655e-09 9.9992990e-01 3.6557518e-05], sum to 1.0000
[2019-03-24 06:34:53,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5211
[2019-03-24 06:34:53,249] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 67.0, 1.0, 2.0, 0.2941154367674391, 1.0, 2.0, 0.2941154367674391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671721.9932481602, 671721.9932481606, 179123.272924046], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2116200.0000, 
sim time next is 2116800.0000, 
raw observation next is [28.2, 66.0, 1.0, 2.0, 0.2945522941581613, 1.0, 2.0, 0.2945522941581613, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672431.8460157218, 672431.8460157218, 179212.8317180733], 
processed observation next is [0.0, 0.5217391304347826, 0.6, 0.66, 1.0, 1.0, 0.16018130256923965, 1.0, 1.0, 0.16018130256923965, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24015423071990064, 0.24015423071990064, 0.34464006099629485], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.00052605], dtype=float32), -1.155268]. 
=============================================
[2019-03-24 06:34:53,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0995696e-07 1.1283162e-05 7.0398372e-08 9.9989843e-01 8.9350295e-05], sum to 1.0000
[2019-03-24 06:34:53,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1919
[2019-03-24 06:34:53,869] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.36666666666667, 81.0, 1.0, 2.0, 0.2881164963486647, 1.0, 2.0, 0.2881164963486647, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 662907.6950306101, 662907.6950306105, 177943.5217618892], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2158800.0000, 
sim time next is 2159400.0000, 
raw observation next is [25.28333333333333, 81.5, 1.0, 2.0, 0.287807096189877, 1.0, 2.0, 0.287807096189877, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662337.8966197898, 662337.8966197898, 177877.2295442247], 
processed observation next is [0.0, 1.0, 0.49197530864197525, 0.815, 1.0, 1.0, 0.1521513049879488, 1.0, 1.0, 0.1521513049879488, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23654924879278205, 0.23654924879278205, 0.3420715952773552], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.88879955], dtype=float32), 0.53795516]. 
=============================================
[2019-03-24 06:34:56,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7216553e-08 1.5201306e-07 4.3832902e-08 9.9999762e-01 2.0895252e-06], sum to 1.0000
[2019-03-24 06:34:56,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5802
[2019-03-24 06:34:56,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.3, 55.83333333333334, 1.0, 2.0, 0.2963421839271059, 1.0, 2.0, 0.2963421839271059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 675438.6288479753, 675438.6288479757, 179585.2467875286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2123400.0000, 
sim time next is 2124000.0000, 
raw observation next is [30.5, 55.0, 1.0, 2.0, 0.2965227031170326, 1.0, 2.0, 0.2965227031170326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 675850.2590118239, 675850.2590118244, 179628.3550753726], 
processed observation next is [0.0, 0.6086956521739131, 0.6851851851851852, 0.55, 1.0, 1.0, 0.16252702752027692, 1.0, 1.0, 0.16252702752027692, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24137509250422282, 0.24137509250422298, 0.3454391443757165], 
reward next is 0.6546, 
noisyNet noise sample is [array([-0.47378674], dtype=float32), 0.16856202]. 
=============================================
[2019-03-24 06:34:56,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.65593 ]
 [61.74507 ]
 [61.868904]
 [61.985325]
 [62.104176]], R is [[61.58695984]
 [61.62573624]
 [61.66427231]
 [61.70269775]
 [61.74097061]].
[2019-03-24 06:35:04,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9268698e-06 3.5632507e-05 1.1217436e-06 9.9990666e-01 5.2639538e-05], sum to 1.0000
[2019-03-24 06:35:04,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1729
[2019-03-24 06:35:04,869] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.3, 76.0, 1.0, 2.0, 0.244574504261326, 1.0, 2.0, 0.244574504261326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 582585.3454150024, 582585.3454150029, 168878.6779269531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2318400.0000, 
sim time next is 2319000.0000, 
raw observation next is [24.16666666666667, 76.66666666666667, 1.0, 2.0, 0.2426579609299767, 1.0, 2.0, 0.2426579609299767, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578402.3970495819, 578402.3970495823, 168465.2075508467], 
processed observation next is [1.0, 0.8695652173913043, 0.45061728395061745, 0.7666666666666667, 1.0, 1.0, 0.09840233444044846, 1.0, 1.0, 0.09840233444044846, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20657228466056496, 0.20657228466056513, 0.3239715529823975], 
reward next is 0.6760, 
noisyNet noise sample is [array([0.61679083], dtype=float32), 0.6264813]. 
=============================================
[2019-03-24 06:35:04,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[57.51125 ]
 [57.03254 ]
 [56.40534 ]
 [55.938118]
 [55.480835]], R is [[58.18574524]
 [58.2791214 ]
 [58.37072372]
 [58.46104813]
 [58.55086517]].
[2019-03-24 06:35:05,103] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6218998e-08 1.1656726e-05 1.2331239e-07 9.9998629e-01 1.9472916e-06], sum to 1.0000
[2019-03-24 06:35:05,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1583
[2019-03-24 06:35:05,116] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 73.5, 1.0, 2.0, 0.6298081142706975, 1.0, 2.0, 0.6298081142706975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1455211.072606292, 1455211.072606292, 279380.3097194274], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2301000.0000, 
sim time next is 2301600.0000, 
raw observation next is [25.73333333333333, 73.0, 1.0, 2.0, 0.6006246991723867, 1.0, 2.0, 0.6006246991723867, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1388307.085950593, 1388307.085950593, 269166.4131448966], 
processed observation next is [1.0, 0.6521739130434783, 0.5086419753086419, 0.73, 1.0, 1.0, 0.5245532133004603, 1.0, 1.0, 0.5245532133004603, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49582395926806894, 0.49582395926806894, 0.5176277175863396], 
reward next is 0.4824, 
noisyNet noise sample is [array([-0.8249722], dtype=float32), 0.29470736]. 
=============================================
[2019-03-24 06:35:09,091] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0953713e-06 7.3145382e-04 2.4297174e-06 9.9925226e-01 1.2698821e-05], sum to 1.0000
[2019-03-24 06:35:09,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7798
[2019-03-24 06:35:09,106] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 38.0, 1.0, 2.0, 0.5016354541933707, 1.0, 2.0, 0.5016354541933707, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1216272.068203857, 1216272.068203857, 238877.0540306407], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2376000.0000, 
sim time next is 2376600.0000, 
raw observation next is [30.0, 37.83333333333334, 1.0, 2.0, 0.5645782868826731, 1.0, 2.0, 0.5645782868826731, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1365732.267867035, 1365732.267867035, 259376.7818771984], 
processed observation next is [1.0, 0.5217391304347826, 0.6666666666666666, 0.3783333333333334, 1.0, 1.0, 0.4816408177174679, 1.0, 1.0, 0.4816408177174679, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4877615242382268, 0.4877615242382268, 0.4988015036099969], 
reward next is 0.5012, 
noisyNet noise sample is [array([0.36565697], dtype=float32), 0.7068983]. 
=============================================
[2019-03-24 06:35:15,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4547405e-07 2.4154089e-05 6.6141155e-07 9.9993408e-01 4.0879906e-05], sum to 1.0000
[2019-03-24 06:35:15,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0138
[2019-03-24 06:35:15,232] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.45, 86.83333333333334, 1.0, 2.0, 0.2385199155737947, 1.0, 2.0, 0.2385199155737947, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571340.7734158846, 571340.773415885, 167654.9867008235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2596200.0000, 
sim time next is 2596800.0000, 
raw observation next is [22.3, 87.66666666666667, 1.0, 2.0, 0.2375895716365208, 1.0, 2.0, 0.2375895716365208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569528.2011578564, 569528.2011578564, 167464.4267631104], 
processed observation next is [0.0, 0.043478260869565216, 0.38148148148148153, 0.8766666666666667, 1.0, 1.0, 0.09236853766252477, 1.0, 1.0, 0.09236853766252477, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20340292898494872, 0.20340292898494872, 0.32204697454444303], 
reward next is 0.6780, 
noisyNet noise sample is [array([-1.0315056], dtype=float32), -0.9663911]. 
=============================================
[2019-03-24 06:35:15,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4226120e-12 2.6685829e-08 1.2766982e-08 9.9999952e-01 4.6748318e-07], sum to 1.0000
[2019-03-24 06:35:15,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-24 06:35:15,272] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 46.0, 1.0, 2.0, 0.1888579444428245, 1.0, 2.0, 0.1888579444428245, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467558.533367378, 467558.5333673784, 157580.9825185927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2502000.0000, 
sim time next is 2502600.0000, 
raw observation next is [27.0, 46.5, 1.0, 2.0, 0.1900181903521907, 1.0, 2.0, 0.1900181903521907, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470344.0077944551, 470344.0077944551, 157818.580623086], 
processed observation next is [1.0, 1.0, 0.5555555555555556, 0.465, 1.0, 1.0, 0.03573594089546511, 1.0, 1.0, 0.03573594089546511, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16798000278373396, 0.16798000278373396, 0.30349727042901153], 
reward next is 0.6965, 
noisyNet noise sample is [array([0.81675994], dtype=float32), 1.0606769]. 
=============================================
[2019-03-24 06:35:26,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0354450e-07 3.7613535e-07 3.6303372e-06 9.9998760e-01 8.3934110e-06], sum to 1.0000
[2019-03-24 06:35:26,160] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5132
[2019-03-24 06:35:26,167] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333333, 59.33333333333334, 1.0, 2.0, 0.3159276082096178, 1.0, 2.0, 0.3159276082096178, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720099.7205039146, 720099.7205039151, 184327.0365649902], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2746200.0000, 
sim time next is 2746800.0000, 
raw observation next is [30.0, 62.0, 1.0, 2.0, 0.3214507999529557, 1.0, 2.0, 0.3214507999529557, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732694.8515294126, 732694.8515294126, 185688.2695754703], 
processed observation next is [0.0, 0.8260869565217391, 0.6666666666666666, 0.62, 1.0, 1.0, 0.19220333327732825, 1.0, 1.0, 0.19220333327732825, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26167673268907593, 0.26167673268907593, 0.35709282610667364], 
reward next is 0.6429, 
noisyNet noise sample is [array([0.19934672], dtype=float32), 0.7841389]. 
=============================================
[2019-03-24 06:35:26,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6347821e-08 1.1492708e-06 1.9297518e-08 9.9995720e-01 4.1599509e-05], sum to 1.0000
[2019-03-24 06:35:26,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6746
[2019-03-24 06:35:26,882] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3826817149186156, 1.0, 2.0, 0.3826817149186156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 872340.1912388051, 872340.1912388055, 201484.9198710899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3744203310446477, 1.0, 2.0, 0.3744203310446477, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853497.5089342609, 853497.5089342614, 199277.6919983268], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.2552622988626759, 1.0, 1.0, 0.2552622988626759, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3048205389050932, 0.30482053890509336, 0.3832263307660131], 
reward next is 0.6168, 
noisyNet noise sample is [array([-0.67574006], dtype=float32), -0.123007685]. 
=============================================
[2019-03-24 06:35:30,995] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:35:30,996] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:35:30,997] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:35:30,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:30,997] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:30,999] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:35:30,999] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:31,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:35:31,001] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:31,005] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-24 06:35:31,027] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:35:31,029] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:31,033] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-24 06:35:31,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-24 06:35:31,054] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-24 06:35:31,111] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-24 06:35:44,486] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00844085], dtype=float32), 0.0052353186]
[2019-03-24 06:35:44,487] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.84776121333334, 80.81522204333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 330326.7197745536, 330326.719774554, 139979.7990754016]
[2019-03-24 06:35:44,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:35:44,490] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2371812e-08 3.8759395e-06 4.8413590e-08 9.9999380e-01 2.2050344e-06], sampled 0.5747284157697433
[2019-03-24 06:36:22,078] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00844085], dtype=float32), 0.0052353186]
[2019-03-24 06:36:22,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 44.0, 1.0, 2.0, 0.3886310858629872, 1.0, 2.0, 0.3886310858629872, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885909.888377119, 885909.888377119, 203089.0331019354]
[2019-03-24 06:36:22,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:22,084] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9159562e-08 3.6490567e-06 4.3303334e-08 9.9999428e-01 1.8684398e-06], sampled 0.354254798910447
[2019-03-24 06:37:15,214] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00844085], dtype=float32), 0.0052353186]
[2019-03-24 06:37:15,215] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.63180653, 92.005235365, 1.0, 2.0, 0.2230576506175629, 1.0, 2.0, 0.2230576506175629, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535214.9081744669, 535214.9081744674, 164293.8873455585]
[2019-03-24 06:37:15,215] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:37:15,217] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0494402e-08 1.7283988e-06 1.5979481e-08 9.9999738e-01 9.8802354e-07], sampled 0.9683181305287045
[2019-03-24 06:37:22,261] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854538.5563 34.0000
[2019-03-24 06:37:22,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6907.5494 2495385784.9754 47.0000
[2019-03-24 06:37:22,676] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00844085], dtype=float32), 0.0052353186]
[2019-03-24 06:37:22,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.92144857, 66.01062989833333, 1.0, 2.0, 0.225331865010301, 1.0, 2.0, 0.225331865010301, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 542758.6733075003, 542758.6733075008, 164868.7394624498]
[2019-03-24 06:37:22,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:37:22,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4130454e-08 2.2137831e-06 2.1299204e-08 9.9999666e-01 1.0960034e-06], sampled 0.3430835144449208
[2019-03-24 06:37:22,717] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6328 2465982800.3557 46.0000
[2019-03-24 06:37:22,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7799.0582 2410683430.4018 22.0000
[2019-03-24 06:37:22,766] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0718 2668501826.2914 68.0000
[2019-03-24 06:37:23,779] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 500000, evaluation results [500000.0, 7523.07182876169, 2668501826.291425, 68.0, 7121.435945869477, 2438854538.5562716, 34.0, 7799.058209372665, 2410683430.4017854, 22.0, 6907.54940058186, 2495385784.97543, 47.0, 7477.632811050205, 2465982800.355744, 46.0]
[2019-03-24 06:37:26,928] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8782129e-07 2.0195832e-05 2.3805258e-06 9.9989080e-01 8.5648426e-05], sum to 1.0000
[2019-03-24 06:37:26,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3847
[2019-03-24 06:37:26,945] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.13333333333334, 93.33333333333334, 1.0, 2.0, 0.2901029731030326, 1.0, 2.0, 0.2901029731030326, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688030.6495149565, 688030.6495149565, 179330.6673182531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.26666666666667, 92.66666666666667, 1.0, 2.0, 0.285435183999411, 1.0, 2.0, 0.285435183999411, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676104.622080692, 676104.6220806924, 178180.0187684657], 
processed observation next is [1.0, 0.30434782608695654, 0.38024691358024704, 0.9266666666666667, 1.0, 1.0, 0.1493275999992988, 1.0, 1.0, 0.1493275999992988, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24146593645738998, 0.24146593645739015, 0.3426538822470494], 
reward next is 0.6573, 
noisyNet noise sample is [array([-0.74412], dtype=float32), -0.8778326]. 
=============================================
[2019-03-24 06:37:31,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2644701e-07 1.0481684e-05 3.7668983e-06 9.9995434e-01 3.0615251e-05], sum to 1.0000
[2019-03-24 06:37:31,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0069
[2019-03-24 06:37:31,218] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.3914614391139908, 1.0, 2.0, 0.3914614391139908, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 892365.6193357634, 892365.6193357639, 203857.3576867197], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2959800.0000, 
sim time next is 2960400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3578338806341264, 1.0, 2.0, 0.3578338806341264, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 815668.2946214838, 815668.2946214842, 194918.448396757], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2355165245644362, 1.0, 1.0, 0.2355165245644362, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2913101052219585, 0.29131010522195866, 0.3748431699937635], 
reward next is 0.6252, 
noisyNet noise sample is [array([-0.12937482], dtype=float32), -1.1431435]. 
=============================================
[2019-03-24 06:37:31,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6335798e-07 7.2729053e-06 3.6422728e-07 9.9998987e-01 2.3328305e-06], sum to 1.0000
[2019-03-24 06:37:31,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4168
[2019-03-24 06:37:31,480] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333334, 98.16666666666667, 1.0, 2.0, 0.4182625528527835, 1.0, 2.0, 0.4182625528527835, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 953498.7692084492, 953498.7692084496, 211262.9176388569], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3039000.0000, 
sim time next is 3039600.0000, 
raw observation next is [25.26666666666667, 96.33333333333334, 1.0, 2.0, 0.3940944949224653, 1.0, 2.0, 0.3940944949224653, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 898371.3849022567, 898371.3849022571, 204574.3770598155], 
processed observation next is [1.0, 0.17391304347826086, 0.49135802469135814, 0.9633333333333334, 1.0, 1.0, 0.2786839225267444, 1.0, 1.0, 0.2786839225267444, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32084692317937735, 0.3208469231793775, 0.3934122635765683], 
reward next is 0.6066, 
noisyNet noise sample is [array([0.60410047], dtype=float32), 0.5521774]. 
=============================================
[2019-03-24 06:37:32,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9122352e-09 4.5669967e-07 1.3789227e-10 9.9999952e-01 5.9830110e-09], sum to 1.0000
[2019-03-24 06:37:32,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4222
[2019-03-24 06:37:32,241] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.25, 92.33333333333334, 1.0, 2.0, 0.3351922583353478, 1.0, 2.0, 0.3351922583353478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 764031.8821065259, 764031.8821065264, 189120.5720612799], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3012600.0000, 
sim time next is 3013200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3350211796937588, 1.0, 2.0, 0.3350211796937588, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 763641.7339361904, 763641.7339361907, 189077.4155790203], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20835854725447472, 1.0, 1.0, 0.20835854725447472, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27272919069149654, 0.2727291906914967, 0.36361041457503906], 
reward next is 0.6364, 
noisyNet noise sample is [array([-1.0051342], dtype=float32), -1.4191592]. 
=============================================
[2019-03-24 06:37:33,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8880429e-10 6.5169235e-07 5.5594240e-09 9.9999917e-01 2.1877435e-07], sum to 1.0000
[2019-03-24 06:37:33,374] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1258
[2019-03-24 06:37:33,380] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 90.83333333333334, 1.0, 2.0, 0.3492769951276752, 1.0, 2.0, 0.3492769951276752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796153.0795702597, 796153.0795702597, 192706.0635962891], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3042600.0000, 
sim time next is 3043200.0000, 
raw observation next is [24.2, 92.66666666666667, 1.0, 2.0, 0.3117235884736262, 1.0, 2.0, 0.3117235884736262, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 710512.978676787, 710512.9786767875, 183297.6048031337], 
processed observation next is [1.0, 0.21739130434782608, 0.45185185185185184, 0.9266666666666667, 1.0, 1.0, 0.18062331961145975, 1.0, 1.0, 0.18062331961145975, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25375463524170966, 0.2537546352417098, 0.3524953938521802], 
reward next is 0.6475, 
noisyNet noise sample is [array([1.5492096], dtype=float32), 0.06337714]. 
=============================================
[2019-03-24 06:37:39,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3518173e-07 3.2451132e-06 2.8357553e-08 9.9999022e-01 6.3338102e-06], sum to 1.0000
[2019-03-24 06:37:39,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3724
[2019-03-24 06:37:39,056] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.2556876893990848, 1.0, 2.0, 0.2556876893990848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 602698.475924039, 602698.4759240395, 171125.9340971062], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3114000.0000, 
sim time next is 3114600.0000, 
raw observation next is [28.06666666666667, 55.83333333333334, 1.0, 2.0, 0.2506960926085855, 1.0, 2.0, 0.2506960926085855, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593677.2994905453, 593677.2994905453, 170113.4062744232], 
processed observation next is [1.0, 0.043478260869565216, 0.5950617283950619, 0.5583333333333335, 1.0, 1.0, 0.10797153881974464, 1.0, 1.0, 0.10797153881974464, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21202760696090903, 0.21202760696090903, 0.3271411659123523], 
reward next is 0.6729, 
noisyNet noise sample is [array([0.20920648], dtype=float32), 1.226217]. 
=============================================
[2019-03-24 06:37:46,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3639708e-10 2.1181707e-08 3.4397949e-09 1.0000000e+00 1.9076460e-08], sum to 1.0000
[2019-03-24 06:37:46,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0673
[2019-03-24 06:37:46,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2501802804580343, 1.0, 2.0, 0.2501802804580343, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594621.7357073472, 594621.7357073472, 170087.264637225], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3294000.0000, 
sim time next is 3294600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.2508654583124967, 1.0, 2.0, 0.2508654583124967, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 596085.9312154732, 596085.9312154737, 170235.4307368351], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.9400000000000002, 1.0, 1.0, 0.10817316465773415, 1.0, 1.0, 0.10817316465773415, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21288783257695473, 0.2128878325769549, 0.32737582834006745], 
reward next is 0.6726, 
noisyNet noise sample is [array([1.7473892], dtype=float32), -0.33177584]. 
=============================================
[2019-03-24 06:37:50,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0655944e-09 1.7471260e-07 3.4145624e-09 9.9999988e-01 2.5992593e-08], sum to 1.0000
[2019-03-24 06:37:50,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2189
[2019-03-24 06:37:50,503] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 93.66666666666667, 1.0, 2.0, 0.3291465741246498, 1.0, 2.0, 0.3291465741246498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750244.7021354008, 750244.7021354008, 187602.2448020706], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3370800.0000, 
sim time next is 3371400.0000, 
raw observation next is [24.65, 93.5, 1.0, 2.0, 0.3264885609160157, 1.0, 2.0, 0.3264885609160157, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744183.1827555321, 744183.1827555321, 186938.7077786363], 
processed observation next is [1.0, 0.0, 0.46851851851851845, 0.935, 1.0, 1.0, 0.19820066775716155, 1.0, 1.0, 0.19820066775716155, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26577970812697577, 0.26577970812697577, 0.35949751495891596], 
reward next is 0.6405, 
noisyNet noise sample is [array([0.8079123], dtype=float32), -1.9867123]. 
=============================================
[2019-03-24 06:37:55,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9310412e-06 5.6733192e-05 2.2270664e-05 9.9989510e-01 1.8022440e-05], sum to 1.0000
[2019-03-24 06:37:55,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4531
[2019-03-24 06:37:55,204] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.08333333333334, 79.00000000000001, 1.0, 2.0, 0.7490992134052223, 1.0, 2.0, 0.7490992134052223, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1708516.689653601, 1708516.689653602, 323170.759255529], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3503400.0000, 
sim time next is 3504000.0000, 
raw observation next is [28.16666666666667, 79.0, 1.0, 2.0, 0.8744252886949087, 1.0, 2.0, 0.8744252886949087, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1994674.757888093, 1994674.757888093, 375468.3670869508], 
processed observation next is [1.0, 0.5652173913043478, 0.5987654320987656, 0.79, 1.0, 1.0, 0.8505062960653674, 1.0, 1.0, 0.8505062960653674, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7123838421028903, 0.7123838421028903, 0.72205455209029], 
reward next is 0.2779, 
noisyNet noise sample is [array([2.0778198], dtype=float32), 0.5638596]. 
=============================================
[2019-03-24 06:37:55,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[40.60776 ]
 [40.505577]
 [40.284187]
 [39.85574 ]
 [39.48144 ]], R is [[40.03789139]
 [40.01602936]
 [40.03933716]
 [40.10266113]
 [40.16989136]].
[2019-03-24 06:37:57,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9928704e-08 1.5981547e-06 5.9801255e-07 9.9999678e-01 1.0281959e-06], sum to 1.0000
[2019-03-24 06:37:57,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6076
[2019-03-24 06:37:57,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2508621073679737, 1.0, 2.0, 0.2508621073679737, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592973.9238051678, 592973.9238051678, 170104.3921247984], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3542400.0000, 
sim time next is 3543000.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.252721542928433, 1.0, 2.0, 0.252721542928433, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 597036.6460741224, 597036.6460741229, 170510.6589195863], 
processed observation next is [1.0, 0.0, 0.4012345679012348, 0.8983333333333334, 1.0, 1.0, 0.1103827892005155, 1.0, 1.0, 0.1103827892005155, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21322737359790087, 0.21322737359790103, 0.32790511330689676], 
reward next is 0.6721, 
noisyNet noise sample is [array([0.7028824], dtype=float32), 0.12343821]. 
=============================================
[2019-03-24 06:37:57,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.59108 ]
 [56.480186]
 [56.46412 ]
 [56.41873 ]
 [56.37297 ]], R is [[55.88360596]
 [55.99764633]
 [56.11316681]
 [56.22999191]
 [56.34789276]].
[2019-03-24 06:38:03,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4723145e-11 8.9524411e-07 2.8570321e-10 9.9999905e-01 3.5359101e-08], sum to 1.0000
[2019-03-24 06:38:03,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1275
[2019-03-24 06:38:03,728] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666666, 92.66666666666667, 1.0, 2.0, 0.2828266431536002, 1.0, 2.0, 0.2828266431536002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 652416.70431743, 652416.7043174305, 176778.0818587932], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3619200.0000, 
sim time next is 3619800.0000, 
raw observation next is [23.5, 94.5, 1.0, 2.0, 0.2863310628053812, 1.0, 2.0, 0.2863310628053812, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 659498.7813577587, 659498.7813577591, 177555.5308125737], 
processed observation next is [1.0, 0.9130434782608695, 0.42592592592592593, 0.945, 1.0, 1.0, 0.15039412238735855, 1.0, 1.0, 0.15039412238735855, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2355352790563424, 0.23553527905634256, 0.34145294387033404], 
reward next is 0.6585, 
noisyNet noise sample is [array([0.06636925], dtype=float32), -0.73413587]. 
=============================================
[2019-03-24 06:38:06,319] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2071482e-05 2.7465782e-04 1.8388051e-05 9.9933076e-01 3.3409201e-04], sum to 1.0000
[2019-03-24 06:38:06,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0000
[2019-03-24 06:38:06,337] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1729065.837631797 W.
[2019-03-24 06:38:06,340] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.91666666666667, 84.83333333333333, 1.0, 2.0, 0.758100277066693, 1.0, 2.0, 0.758100277066693, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1729065.837631797, 1729065.837631797, 326745.1854905955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3689400.0000, 
sim time next is 3690000.0000, 
raw observation next is [26.9, 84.0, 1.0, 2.0, 0.713239980613612, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1527913.27237858, 1527913.272378581, 319646.9955388777], 
processed observation next is [1.0, 0.7391304347826086, 0.5518518518518518, 0.84, 1.0, 1.0, 0.6586190245400143, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5456833115637786, 0.5456833115637789, 0.6147057606516878], 
reward next is 0.3853, 
noisyNet noise sample is [array([-1.0692456], dtype=float32), -0.96481556]. 
=============================================
[2019-03-24 06:38:06,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[42.465553]
 [42.41429 ]
 [42.49245 ]
 [42.578033]
 [42.617897]], R is [[42.5081749 ]
 [42.4547348 ]
 [42.39624405]
 [42.33398819]
 [42.28355408]].
[2019-03-24 06:38:11,743] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 06:38:11,743] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:38:11,744] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:11,745] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:38:11,746] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:38:11,747] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:38:11,748] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:38:11,751] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:11,752] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:11,748] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:11,754] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:11,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-24 06:38:11,799] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-24 06:38:11,847] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-24 06:38:11,848] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-24 06:38:11,902] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-24 06:38:12,931] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:38:12,932] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.2, 46.0, 1.0, 2.0, 0.3000426653845873, 1.0, 2.0, 0.3000426653845873, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760687.010360172, 760687.010360172, 183066.7245804156]
[2019-03-24 06:38:12,932] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:38:12,933] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2668755e-08 3.1069728e-06 5.1748199e-08 9.9999642e-01 3.9051926e-07], sampled 0.7519170411512974
[2019-03-24 06:38:15,014] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:38:15,015] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.003231415, 0.9654355525, 1.0, 2.0, 0.1871867515931558, 1.0, 2.0, 0.1871867515931558, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 482960.1268509717, 482960.1268509722, 138275.4795015408]
[2019-03-24 06:38:15,016] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:38:15,019] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0446902e-08 1.4058152e-06 1.7054433e-08 9.9999845e-01 1.3720262e-07], sampled 0.5467265951163142
[2019-03-24 06:38:19,891] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:38:19,892] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.755714, 59.5060254, 1.0, 2.0, 0.2205576466453349, 1.0, 2.0, 0.2205576466453349, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530062.8461133788, 530062.8461133792, 163785.5698122618]
[2019-03-24 06:38:19,894] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:38:19,898] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.0716183e-09 9.3512409e-07 9.9729007e-09 9.9999893e-01 9.0211877e-08], sampled 0.5930023089136158
[2019-03-24 06:38:33,875] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:38:33,876] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.91402416666667, 52.64201011333334, 1.0, 2.0, 0.2635477100259604, 1.0, 2.0, 0.2635477100259604, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614322.9039714782, 614322.9039714787, 172615.268565326]
[2019-03-24 06:38:33,877] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:38:33,880] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.13729520e-09 1.05168294e-06 1.15527570e-08 9.99998808e-01
 1.01917394e-07], sampled 0.6547606140027842
[2019-03-24 06:38:52,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:38:52,423] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.48992019833333, 90.21371565166667, 1.0, 2.0, 0.3792336366354597, 1.0, 2.0, 0.3792336366354597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 864475.7087295507, 864475.7087295512, 200562.5273611461]
[2019-03-24 06:38:52,424] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:38:52,427] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3596742e-08 1.6509223e-06 2.1669052e-08 9.9999821e-01 1.7210536e-07], sampled 0.12221397881432339
[2019-03-24 06:39:03,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:03,580] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.16666666666667, 94.00000000000001, 1.0, 2.0, 0.7258248004320756, 1.0, 2.0, 0.7258248004320756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1655384.121012981, 1655384.121012981, 314058.0370955283]
[2019-03-24 06:39:03,581] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:03,584] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3275452e-07 8.7476683e-06 1.9946326e-07 9.9998987e-01 1.1296958e-06], sampled 0.658765573773993
[2019-03-24 06:39:08,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:08,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.90628950166666, 66.929235425, 1.0, 2.0, 0.4493813391728404, 1.0, 2.0, 0.4493813391728404, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1024486.618748126, 1024486.618748126, 220173.9399811385]
[2019-03-24 06:39:08,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:39:08,179] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6297402e-08 2.6783487e-06 4.1133525e-08 9.9999690e-01 3.0634601e-07], sampled 0.25642893021366886
[2019-03-24 06:39:11,474] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:11,476] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 92.66666666666667, 1.0, 2.0, 0.3035079628165998, 1.0, 2.0, 0.3035079628165998, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712736.7414226364, 712736.7414226364, 182283.760775981]
[2019-03-24 06:39:11,476] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:11,478] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.9097736e-08 4.7515678e-06 9.0880356e-08 9.9999452e-01 5.9827073e-07], sampled 0.3396708721338445
[2019-03-24 06:39:14,365] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:14,366] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.94675595, 92.17262902499999, 1.0, 2.0, 0.2736458222683138, 1.0, 2.0, 0.2736458222683138, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639709.209787299, 639709.209787299, 175031.3206743334]
[2019-03-24 06:39:14,369] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:39:14,371] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4319582e-08 1.6798784e-06 2.2986869e-08 9.9999809e-01 1.9127677e-07], sampled 0.023560706540147414
[2019-03-24 06:39:24,658] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:24,660] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 88.0, 1.0, 2.0, 0.5877965149481493, 1.0, 2.0, 0.5877965149481493, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1340317.583359126, 1340317.583359126, 263869.702329318]
[2019-03-24 06:39:24,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:24,664] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.232429e-07 2.635056e-05 8.831211e-07 9.999682e-01 3.882751e-06], sampled 0.4013965831530356
[2019-03-24 06:39:35,836] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853237], dtype=float32), 0.005022749]
[2019-03-24 06:39:35,837] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.56666666666666, 69.33333333333333, 1.0, 2.0, 0.2740792444092333, 1.0, 2.0, 0.2740792444092333, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638313.9322040146, 638313.9322040151, 175022.7337519444]
[2019-03-24 06:39:35,839] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:35,841] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.4195889e-09 9.7056864e-07 1.0469067e-08 9.9999893e-01 9.2516210e-08], sampled 0.1495883909852661
[2019-03-24 06:39:59,069] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 06:39:59,241] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473646.4269 47.0000
[2019-03-24 06:39:59,270] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0359 2668562720.4983 68.0000
[2019-03-24 06:39:59,367] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7123.0862 2438788121.7056 34.0000
[2019-03-24 06:39:59,429] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3709 2465927417.8106 46.0000
[2019-03-24 06:40:00,443] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 525000, evaluation results [525000.0, 7523.035865829873, 2668562720.4982953, 68.0, 7123.08617139173, 2438788121.7055836, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495473646.426865, 47.0, 7478.370866121276, 2465927417.8105526, 46.0]
[2019-03-24 06:40:00,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9798941e-09 4.0734158e-05 4.6382449e-09 9.9995875e-01 4.4698442e-07], sum to 1.0000
[2019-03-24 06:40:00,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-24 06:40:00,933] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 60.33333333333334, 1.0, 2.0, 0.3180862720860232, 1.0, 2.0, 0.3180862720860232, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 725022.3303932914, 725022.3303932919, 184857.8791273852], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3835200.0000, 
sim time next is 3835800.0000, 
raw observation next is [30.5, 61.0, 1.0, 2.0, 0.3232628655747117, 1.0, 2.0, 0.3232628655747117, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736827.145683931, 736827.1456839314, 186137.3330077328], 
processed observation next is [0.0, 0.391304347826087, 0.6851851851851852, 0.61, 1.0, 1.0, 0.19436055425560914, 1.0, 1.0, 0.19436055425560914, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26315255202997534, 0.2631525520299755, 0.35795640963025543], 
reward next is 0.6420, 
noisyNet noise sample is [array([1.9885831], dtype=float32), -0.18338525]. 
=============================================
[2019-03-24 06:40:01,816] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6564663e-08 8.9160096e-08 5.5074372e-09 9.9999964e-01 1.9393400e-07], sum to 1.0000
[2019-03-24 06:40:01,823] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7754
[2019-03-24 06:40:01,830] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.11666666666667, 73.66666666666667, 1.0, 2.0, 0.2822032872972042, 1.0, 2.0, 0.2822032872972042, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 653988.9152404042, 653988.9152404047, 176774.9764294717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3811800.0000, 
sim time next is 3812400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.2808158110903777, 1.0, 2.0, 0.2808158110903777, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 651593.6832654703, 651593.6832654708, 176487.4369806657], 
processed observation next is [0.0, 0.13043478260869565, 0.5185185185185185, 0.74, 1.0, 1.0, 0.14382834653616391, 1.0, 1.0, 0.14382834653616391, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23271202973766797, 0.23271202973766814, 0.33939891727051097], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.19462378], dtype=float32), -1.7989955]. 
=============================================
[2019-03-24 06:40:02,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4355454e-09 2.6442778e-05 1.7522110e-08 9.9997127e-01 2.2060806e-06], sum to 1.0000
[2019-03-24 06:40:02,978] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-24 06:40:02,984] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.2874543810868774, 1.0, 2.0, 0.2874543810868774, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 661755.0820637108, 661755.0820637112, 177804.9469189871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3825600.0000, 
sim time next is 3826200.0000, 
raw observation next is [27.66666666666667, 67.33333333333333, 1.0, 2.0, 0.2912903905229123, 1.0, 2.0, 0.2912903905229123, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669195.9684502201, 669195.9684502205, 178646.9498308211], 
processed observation next is [0.0, 0.2608695652173913, 0.580246913580247, 0.6733333333333333, 1.0, 1.0, 0.15629808395584796, 1.0, 1.0, 0.15629808395584796, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23899856016079288, 0.23899856016079304, 0.34355182659773287], 
reward next is 0.6564, 
noisyNet noise sample is [array([0.9553213], dtype=float32), 0.6175732]. 
=============================================
[2019-03-24 06:40:04,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5935272e-09 3.2775537e-07 1.7077309e-07 9.9999952e-01 2.5492748e-09], sum to 1.0000
[2019-03-24 06:40:04,581] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-24 06:40:04,584] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.4113983559059707, 1.0, 2.0, 0.4113983559059707, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 937841.1202178769, 937841.1202178773, 209344.5271776941], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3870000.0000, 
sim time next is 3870600.0000, 
raw observation next is [31.65, 67.33333333333334, 1.0, 2.0, 0.3988642014344495, 1.0, 2.0, 0.3988642014344495, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 909250.780093349, 909250.7800933486, 205880.0483850614], 
processed observation next is [0.0, 0.8260869565217391, 0.7277777777777777, 0.6733333333333335, 1.0, 1.0, 0.28436214456482084, 1.0, 1.0, 0.28436214456482084, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3247324214619104, 0.3247324214619102, 0.39592316997127197], 
reward next is 0.6041, 
noisyNet noise sample is [array([-1.4584544], dtype=float32), -0.7509644]. 
=============================================
[2019-03-24 06:40:06,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0401910e-08 4.6861817e-07 5.5023666e-08 9.9999928e-01 6.4961583e-08], sum to 1.0000
[2019-03-24 06:40:06,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8309
[2019-03-24 06:40:06,907] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.65, 90.5, 1.0, 2.0, 0.3641520900737498, 1.0, 2.0, 0.3641520900737498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830078.204004865, 830078.204004865, 196569.1641256263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.3732502302803786, 1.0, 2.0, 0.3732502302803786, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850828.7638557577, 850828.7638557577, 198968.9474926231], 
processed observation next is [0.0, 0.30434782608695654, 0.5506172839506175, 0.8933333333333334, 1.0, 1.0, 0.2538693217623555, 1.0, 1.0, 0.2538693217623555, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3038674156627706, 0.3038674156627706, 0.3826325913319675], 
reward next is 0.6174, 
noisyNet noise sample is [array([-0.01239459], dtype=float32), -0.4533539]. 
=============================================
[2019-03-24 06:40:19,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.94950620e-07 1.35059845e-05 1.23104041e-06 9.99901652e-01
 8.31151265e-05], sum to 1.0000
[2019-03-24 06:40:19,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9172
[2019-03-24 06:40:19,251] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.2245231851789679, 1.0, 2.0, 0.2245231851789679, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 542653.5568961143, 542653.5568961147, 164761.1222670652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2234989128774162, 1.0, 2.0, 0.2234989128774162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540600.4585407497, 540600.4585407497, 164553.3585424161], 
processed observation next is [1.0, 0.043478260869565216, 0.3333333333333333, 0.94, 1.0, 1.0, 0.07559394390168594, 1.0, 1.0, 0.07559394390168594, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19307159233598206, 0.19307159233598206, 0.3164487664277233], 
reward next is 0.6836, 
noisyNet noise sample is [array([1.9480331], dtype=float32), -0.5938019]. 
=============================================
[2019-03-24 06:40:19,939] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3175263e-07 1.5165893e-05 2.4606368e-07 9.9998164e-01 2.8395550e-06], sum to 1.0000
[2019-03-24 06:40:19,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7807
[2019-03-24 06:40:19,951] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.91666666666666, 99.16666666666666, 1.0, 2.0, 0.2118527270907408, 1.0, 2.0, 0.2118527270907408, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 516648.7524605885, 516648.7524605889, 162190.3724569089], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4165800.0000, 
sim time next is 4166400.0000, 
raw observation next is [19.93333333333333, 99.33333333333334, 1.0, 2.0, 0.2075866173459062, 1.0, 2.0, 0.2075866173459062, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506136.2306983392, 506136.2306983396, 161276.5970025589], 
processed observation next is [1.0, 0.21739130434782608, 0.293827160493827, 0.9933333333333334, 1.0, 1.0, 0.05665073493560261, 1.0, 1.0, 0.05665073493560261, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18076293953512113, 0.1807629395351213, 0.3101473019279979], 
reward next is 0.6899, 
noisyNet noise sample is [array([0.33277836], dtype=float32), 0.6761554]. 
=============================================
[2019-03-24 06:40:21,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1017357e-06 4.4505228e-04 1.9470439e-04 9.9930334e-01 5.3833821e-05], sum to 1.0000
[2019-03-24 06:40:22,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1707
[2019-03-24 06:40:22,005] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.86666666666667, 30.0, 1.0, 2.0, 0.6840747303288156, 1.0, 2.0, 0.6840747303288156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1615784.409495482, 1615784.409495482, 300808.7414594888], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4196400.0000, 
sim time next is 4197000.0000, 
raw observation next is [34.08333333333333, 28.5, 1.0, 2.0, 0.6695152279285133, 1.0, 2.0, 0.6695152279285133, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1588090.756501662, 1588090.756501663, 295625.1567259348], 
processed observation next is [1.0, 0.5652173913043478, 0.8179012345679011, 0.285, 1.0, 1.0, 0.6065657475339443, 1.0, 1.0, 0.6065657475339443, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.567175270179165, 0.5671752701791654, 0.5685099167806439], 
reward next is 0.4315, 
noisyNet noise sample is [array([-1.0919428], dtype=float32), -1.1428764]. 
=============================================
[2019-03-24 06:40:22,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.630386]
 [40.524353]
 [40.880867]
 [41.27697 ]
 [40.949265]], R is [[40.81133652]
 [40.82474518]
 [40.81885529]
 [40.83596039]
 [40.93173218]].
[2019-03-24 06:40:25,238] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0720385e-08 2.0663232e-05 3.4390505e-06 9.9997568e-01 2.2599413e-07], sum to 1.0000
[2019-03-24 06:40:25,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-24 06:40:25,249] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333333, 68.66666666666666, 1.0, 2.0, 0.2371484651854297, 1.0, 2.0, 0.2371484651854297, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 566976.6918548514, 566976.6918548519, 167307.7115223125], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4232400.0000, 
sim time next is 4233000.0000, 
raw observation next is [25.16666666666667, 71.33333333333334, 1.0, 2.0, 0.242368650657069, 1.0, 2.0, 0.242368650657069, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576829.590448756, 576829.590448756, 168364.5523006804], 
processed observation next is [1.0, 1.0, 0.4876543209876545, 0.7133333333333334, 1.0, 1.0, 0.09805791744889167, 1.0, 1.0, 0.09805791744889167, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20601056801741285, 0.20601056801741285, 0.32377798519361617], 
reward next is 0.6762, 
noisyNet noise sample is [array([-1.0716544], dtype=float32), 0.008369057]. 
=============================================
[2019-03-24 06:40:25,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.72519 ]
 [55.598553]
 [55.528816]
 [55.49485 ]
 [55.370663]], R is [[55.98572159]
 [56.10411835]
 [56.22306824]
 [56.34233475]
 [56.46178436]].
[2019-03-24 06:40:26,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2813498e-06 1.0865323e-03 3.2175543e-05 9.9858689e-01 2.8911111e-04], sum to 1.0000
[2019-03-24 06:40:26,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9665
[2019-03-24 06:40:26,109] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 87.0, 1.0, 2.0, 0.4228057243988815, 1.0, 2.0, 0.4228057243988815, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 963995.9076926167, 963995.9076926162, 212547.7983900346], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4347600.0000, 
sim time next is 4348200.0000, 
raw observation next is [25.0, 86.5, 1.0, 2.0, 0.4499477302744034, 1.0, 2.0, 0.4499477302744034, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1025778.725137577, 1025778.725137577, 220336.8898253379], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.865, 1.0, 1.0, 0.34517586937428973, 1.0, 1.0, 0.34517586937428973, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3663495446919918, 0.3663495446919918, 0.4237247881256498], 
reward next is 0.5763, 
noisyNet noise sample is [array([-1.507136], dtype=float32), 0.7584383]. 
=============================================
[2019-03-24 06:40:31,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5325234e-08 5.7935773e-05 1.4812353e-07 9.9994135e-01 5.2708020e-07], sum to 1.0000
[2019-03-24 06:40:31,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0128
[2019-03-24 06:40:31,706] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.3, 91.0, 1.0, 2.0, 0.2776111652401019, 1.0, 2.0, 0.2776111652401019, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647231.3156147987, 647231.3156147987, 175878.7793612766], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4510800.0000, 
sim time next is 4511400.0000, 
raw observation next is [23.25, 92.5, 1.0, 2.0, 0.2783188782866938, 1.0, 2.0, 0.2783188782866938, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 647856.7210228491, 647856.7210228496, 175997.6684832477], 
processed observation next is [0.0, 0.21739130434782608, 0.4166666666666667, 0.925, 1.0, 1.0, 0.14085580748415932, 1.0, 1.0, 0.14085580748415932, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23137740036530324, 0.2313774003653034, 0.33845705477547633], 
reward next is 0.6615, 
noisyNet noise sample is [array([0.4433851], dtype=float32), -1.0770773]. 
=============================================
[2019-03-24 06:40:31,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0181539e-08 1.5150673e-04 3.1814084e-06 9.9984491e-01 2.9990048e-07], sum to 1.0000
[2019-03-24 06:40:31,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6944
[2019-03-24 06:40:31,969] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 67.16666666666667, 1.0, 2.0, 0.3555676416557703, 1.0, 2.0, 0.3555676416557703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 810499.7604745188, 810499.7604745192, 194331.2768001027], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4389000.0000, 
sim time next is 4389600.0000, 
raw observation next is [29.93333333333333, 68.33333333333334, 1.0, 2.0, 0.3521059141629029, 1.0, 2.0, 0.3521059141629029, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802604.7836199175, 802604.7836199179, 193435.7628684585], 
processed observation next is [1.0, 0.8260869565217391, 0.6641975308641974, 0.6833333333333335, 1.0, 1.0, 0.22869751686059867, 1.0, 1.0, 0.22869751686059867, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28664456557854195, 0.2866445655785421, 0.3719918516701125], 
reward next is 0.6280, 
noisyNet noise sample is [array([-1.1167616], dtype=float32), -0.7752451]. 
=============================================
[2019-03-24 06:40:34,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0555950e-08 1.1379735e-05 2.6217132e-08 9.9998581e-01 2.8861352e-06], sum to 1.0000
[2019-03-24 06:40:34,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0825
[2019-03-24 06:40:34,170] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.289415168376541, 1.0, 2.0, 0.289415168376541, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664869.4785638442, 664869.4785638442, 178201.1124622581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4431600.0000, 
sim time next is 4432200.0000, 
raw observation next is [23.15, 97.66666666666667, 1.0, 2.0, 0.2900129585553853, 1.0, 2.0, 0.2900129585553853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666768.3005945421, 666768.3005945425, 178368.4485109902], 
processed observation next is [0.0, 0.30434782608695654, 0.4129629629629629, 0.9766666666666667, 1.0, 1.0, 0.15477733161355392, 1.0, 1.0, 0.15477733161355392, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23813153592662217, 0.23813153592662234, 0.34301624713651957], 
reward next is 0.6570, 
noisyNet noise sample is [array([-0.17840402], dtype=float32), -0.09680975]. 
=============================================
[2019-03-24 06:40:37,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3163598e-07 2.8571043e-05 1.0763689e-05 9.9993587e-01 2.4228328e-05], sum to 1.0000
[2019-03-24 06:40:37,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-24 06:40:37,303] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.7250293257435543, 1.0, 2.0, 0.7250293257435543, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1653568.207815636, 1653568.207815636, 313748.8394118575], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4622400.0000, 
sim time next is 4623000.0000, 
raw observation next is [28.11666666666667, 73.16666666666667, 1.0, 2.0, 0.7527901898156543, 1.0, 2.0, 0.7527901898156543, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1716943.016658205, 1716943.016658206, 324632.4019376704], 
processed observation next is [1.0, 0.5217391304347826, 0.5969135802469138, 0.7316666666666667, 1.0, 1.0, 0.7057026069233979, 1.0, 1.0, 0.7057026069233979, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6131939345207875, 0.6131939345207879, 0.6242930806493662], 
reward next is 0.3757, 
noisyNet noise sample is [array([-0.03166011], dtype=float32), 0.4886815]. 
=============================================
[2019-03-24 06:40:37,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[46.204212]
 [46.385845]
 [46.04794 ]
 [45.578148]
 [45.116863]], R is [[45.79187393]
 [45.73059082]
 [45.72941208]
 [45.74282455]
 [45.77184677]].
[2019-03-24 06:40:37,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3611489e-07 7.3237766e-06 1.2979945e-08 9.9999261e-01 2.8621983e-08], sum to 1.0000
[2019-03-24 06:40:37,775] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5304
[2019-03-24 06:40:37,778] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.86666666666667, 83.66666666666667, 1.0, 2.0, 0.3678031132702795, 1.0, 2.0, 0.3678031132702795, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 838405.1982717998, 838405.1982717995, 197528.9421933658], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4475400.0000, 
sim time next is 4476000.0000, 
raw observation next is [27.73333333333333, 83.33333333333334, 1.0, 2.0, 0.3642663786295128, 1.0, 2.0, 0.3642663786295128, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 830338.8638499288, 830338.8638499293, 196599.1849498586], 
processed observation next is [0.0, 0.8260869565217391, 0.5827160493827159, 0.8333333333333335, 1.0, 1.0, 0.2431742602732295, 1.0, 1.0, 0.2431742602732295, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29654959423211746, 0.29654959423211763, 0.37807535567280504], 
reward next is 0.6219, 
noisyNet noise sample is [array([-0.11741855], dtype=float32), -2.147312]. 
=============================================
[2019-03-24 06:40:37,801] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.24116 ]
 [69.144295]
 [69.12548 ]
 [69.10739 ]
 [69.0818  ]], R is [[69.2099762 ]
 [69.13801575]
 [69.06079865]
 [68.98635101]
 [68.91464996]].
[2019-03-24 06:40:42,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4598785e-07 2.5871670e-06 1.0249104e-07 9.9999642e-01 1.0286903e-07], sum to 1.0000
[2019-03-24 06:40:42,611] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6901
[2019-03-24 06:40:42,616] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.96666666666667, 94.66666666666667, 1.0, 2.0, 0.2756742140360862, 1.0, 2.0, 0.2756742140360862, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641655.2879670919, 641655.2879670924, 175377.3087178453], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4573200.0000, 
sim time next is 4573800.0000, 
raw observation next is [22.95, 95.0, 1.0, 2.0, 0.2755783855490848, 1.0, 2.0, 0.2755783855490848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641131.6100609051, 641131.6100609056, 175341.0623565192], 
processed observation next is [0.0, 0.9565217391304348, 0.4055555555555555, 0.95, 1.0, 1.0, 0.13759331612986286, 1.0, 1.0, 0.13759331612986286, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22897557502175184, 0.228975575021752, 0.3371943506856138], 
reward next is 0.6628, 
noisyNet noise sample is [array([0.39098257], dtype=float32), -0.6052565]. 
=============================================
[2019-03-24 06:40:45,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2283752e-05 2.2498683e-04 1.0225337e-05 9.9962687e-01 1.2564869e-04], sum to 1.0000
[2019-03-24 06:40:45,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2945
[2019-03-24 06:40:45,123] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.9190827990685297, 1.0, 2.0, 0.9190827990685297, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2096663.782773647, 2096663.782773648, 395419.3716149392], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4723200.0000, 
sim time next is 4723800.0000, 
raw observation next is [28.13333333333334, 83.16666666666667, 1.0, 2.0, 0.8579409241936969, 1.0, 2.0, 0.8579409241936969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1957030.634576544, 1957030.634576545, 368279.2826523963], 
processed observation next is [1.0, 0.6956521739130435, 0.5975308641975311, 0.8316666666666667, 1.0, 1.0, 0.830882052611544, 1.0, 1.0, 0.830882052611544, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6989395123487657, 0.6989395123487661, 0.7082293897161467], 
reward next is 0.2918, 
noisyNet noise sample is [array([0.11520948], dtype=float32), 1.0708352]. 
=============================================
[2019-03-24 06:40:46,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1603930e-06 6.6257121e-06 2.6407656e-07 9.9998593e-01 3.0189467e-06], sum to 1.0000
[2019-03-24 06:40:46,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-24 06:40:46,720] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.11666666666667, 94.16666666666667, 1.0, 2.0, 0.3218072282059379, 1.0, 2.0, 0.3218072282059379, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745579.2824057261, 745579.2824057261, 186354.9998832502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4686600.0000, 
sim time next is 4687200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3102707922174567, 1.0, 2.0, 0.3102707922174567, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721221.0181866242, 721221.0181866246, 183614.3550898554], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.94, 1.0, 1.0, 0.178893800258877, 1.0, 1.0, 0.178893800258877, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25757893506665147, 0.25757893506665164, 0.35310452901895273], 
reward next is 0.6469, 
noisyNet noise sample is [array([0.46128744], dtype=float32), 0.9747113]. 
=============================================
[2019-03-24 06:40:48,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0342859e-05 1.7916244e-04 1.6944489e-04 9.9917692e-01 3.8412231e-04], sum to 1.0000
[2019-03-24 06:40:48,108] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6558
[2019-03-24 06:40:48,117] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 73.0, 1.0, 2.0, 0.8857401957536086, 1.0, 2.0, 0.8857401957536086, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2020514.692233734, 2020514.692233734, 380458.0133455956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4716000.0000, 
sim time next is 4716600.0000, 
raw observation next is [28.91666666666667, 75.66666666666667, 1.0, 2.0, 0.8652083056674167, 1.0, 2.0, 0.8652083056674167, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1973626.420263577, 1973626.420263577, 371436.9804131464], 
processed observation next is [1.0, 0.6086956521739131, 0.6265432098765434, 0.7566666666666667, 1.0, 1.0, 0.8395336972231151, 1.0, 1.0, 0.8395336972231151, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7048665786655632, 0.7048665786655632, 0.7143018854098969], 
reward next is 0.2857, 
noisyNet noise sample is [array([-1.0673137], dtype=float32), 1.0901644]. 
=============================================
[2019-03-24 06:40:48,305] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 06:40:48,306] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:40:48,306] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:48,307] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:40:48,308] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:48,309] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:40:48,309] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:48,310] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:40:48,311] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:48,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:40:48,312] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:48,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-24 06:40:48,365] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-24 06:40:48,398] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-24 06:40:48,399] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-24 06:40:48,430] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-24 06:40:55,531] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:40:55,533] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.03333333333333, 88.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 326926.1381901086, 326926.1381901091, 139530.206280766]
[2019-03-24 06:40:55,534] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:40:55,537] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2654534e-07 9.1907823e-06 2.8969640e-07 9.9998915e-01 1.3508873e-06], sampled 0.08439659068085592
[2019-03-24 06:41:01,880] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:01,882] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 25.66666666666667, 1.0, 2.0, 0.1639365500234049, 1.0, 2.0, 0.1639365500234049, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418993.5991473464, 418993.5991473469, 152691.373123908]
[2019-03-24 06:41:01,883] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:41:01,886] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.1491598e-08 5.6048843e-06 1.4362851e-07 9.9999344e-01 6.9022138e-07], sampled 0.55814916280969
[2019-03-24 06:41:02,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:02,423] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 46.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 268410.8348133441, 268410.8348133445, 103655.7094609561]
[2019-03-24 06:41:02,423] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:41:02,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7550473e-07 1.6760145e-05 6.1023678e-07 9.9997985e-01 2.4880819e-06], sampled 0.3627443126764103
[2019-03-24 06:41:27,970] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:27,971] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.05858124, 59.04052168, 1.0, 2.0, 0.3029948016535809, 1.0, 2.0, 0.3029948016535809, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690608.4536479969, 690608.4536479973, 181181.1172026728]
[2019-03-24 06:41:27,973] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:41:27,977] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7943304e-08 6.0876055e-06 1.5766588e-07 9.9999297e-01 6.7317586e-07], sampled 0.6438324796610704
[2019-03-24 06:41:29,043] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:29,044] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.68263121, 94.82719718333334, 1.0, 2.0, 0.5895651477276134, 1.0, 2.0, 0.5895651477276134, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1344354.03118007, 1344354.03118007, 264474.1371969276]
[2019-03-24 06:41:29,047] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:41:29,050] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.9369397e-07 2.1720502e-05 8.2011326e-07 9.9997437e-01 2.7964713e-06], sampled 0.34803627396178116
[2019-03-24 06:41:40,509] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:40,510] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 76.33333333333334, 1.0, 2.0, 0.4375497020898057, 1.0, 2.0, 0.4375497020898057, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 997495.6372620988, 997495.6372620988, 216748.3085423381]
[2019-03-24 06:41:40,510] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:41:40,515] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4238012e-07 1.0432461e-05 3.1459825e-07 9.9998784e-01 1.1953923e-06], sampled 0.8160939443258539
[2019-03-24 06:41:44,704] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:41:44,707] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.13333333333333, 88.0, 1.0, 2.0, 0.3315401495147978, 1.0, 2.0, 0.3315401495147978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755703.2200209826, 755703.220020983, 188203.2092263901]
[2019-03-24 06:41:44,708] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:41:44,711] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4348217e-07 3.0941552e-05 1.3341285e-06 9.9996269e-01 4.3455861e-06], sampled 0.01372698366193914
[2019-03-24 06:42:00,387] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:42:00,388] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.00936312666667, 81.992425755, 1.0, 2.0, 0.3290299473393614, 1.0, 2.0, 0.3290299473393614, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 761923.349071052, 761923.3490710525, 188144.7144326518]
[2019-03-24 06:42:00,388] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:42:00,391] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4250402e-07 1.0155876e-05 3.2160824e-07 9.9998796e-01 1.3797672e-06], sampled 0.12159457688882491
[2019-03-24 06:42:20,878] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00871573], dtype=float32), 0.0048374296]
[2019-03-24 06:42:20,880] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.2811530085513183, 1.0, 2.0, 0.2811530085513183, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 651542.066738279, 651542.0667382794, 176527.519749084]
[2019-03-24 06:42:20,882] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:42:20,885] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.3417118e-08 5.1225302e-06 1.2650447e-07 9.9999404e-01 5.8958801e-07], sampled 0.7432523138575152
[2019-03-24 06:42:36,103] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6603 2465954857.3676 46.0000
[2019-03-24 06:42:36,122] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.9276 2438900406.8959 34.0000
[2019-03-24 06:42:36,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6907.0324 2495407705.4923 47.0000
[2019-03-24 06:42:36,205] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3745 2668509944.6151 68.0000
[2019-03-24 06:42:36,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.8013 2410636185.2039 22.0000
[2019-03-24 06:42:37,309] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 550000, evaluation results [550000.0, 7522.374490849826, 2668509944.6150527, 68.0, 7120.927562416481, 2438900406.895905, 34.0, 7797.801344385335, 2410636185.203944, 22.0, 6907.03243025009, 2495407705.492321, 47.0, 7477.660323724453, 2465954857.36756, 46.0]
[2019-03-24 06:42:41,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5533755e-07 1.2958561e-04 1.5038178e-05 9.9984848e-01 5.9993476e-06], sum to 1.0000
[2019-03-24 06:42:41,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1994
[2019-03-24 06:42:41,373] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 86.33333333333334, 1.0, 2.0, 0.8444729607096317, 1.0, 2.0, 0.8444729607096317, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1926276.020790904, 1926276.020790904, 362474.5223656769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4801200.0000, 
sim time next is 4801800.0000, 
raw observation next is [27.25, 85.66666666666667, 1.0, 2.0, 0.8636796036290069, 1.0, 2.0, 0.8636796036290069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1970135.452073438, 1970135.452073439, 370771.055989335], 
processed observation next is [1.0, 0.5652173913043478, 0.5648148148148148, 0.8566666666666667, 1.0, 1.0, 0.8377138138440557, 1.0, 1.0, 0.8377138138440557, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7036198043119422, 0.7036198043119425, 0.713021261517952], 
reward next is 0.2870, 
noisyNet noise sample is [array([1.7317303], dtype=float32), -0.7994188]. 
=============================================
[2019-03-24 06:42:41,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1727517e-06 5.5814903e-06 2.1821938e-06 9.9996877e-01 2.1243244e-05], sum to 1.0000
[2019-03-24 06:42:41,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2798
[2019-03-24 06:42:41,388] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3660808598888733, 1.0, 2.0, 0.3660808598888733, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 834477.1938695301, 834477.1938695306, 197074.3959088311], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4863000.0000, 
sim time next is 4863600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.407966493860941, 1.0, 2.0, 0.407966493860941, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 930012.9549849208, 930012.9549849213, 208388.1223402811], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.29519820697731075, 1.0, 1.0, 0.29519820697731075, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.332147483923186, 0.33214748392318616, 0.40074638911592514], 
reward next is 0.5993, 
noisyNet noise sample is [array([-0.36279437], dtype=float32), 0.15530229]. 
=============================================
[2019-03-24 06:42:42,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3059682e-07 1.2136183e-05 2.1481494e-06 9.9998426e-01 1.3016518e-06], sum to 1.0000
[2019-03-24 06:42:43,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-24 06:42:43,010] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 92.0, 1.0, 2.0, 0.3549884402873794, 1.0, 2.0, 0.3549884402873794, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809178.8012085364, 809178.8012085368, 194180.82153696], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [25.91666666666667, 93.33333333333334, 1.0, 2.0, 0.3551081968284088, 1.0, 2.0, 0.3551081968284088, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809451.9245349567, 809451.9245349567, 194211.8389061017], 
processed observation next is [1.0, 1.0, 0.5154320987654323, 0.9333333333333335, 1.0, 1.0, 0.23227166289096282, 1.0, 1.0, 0.23227166289096282, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28908997304819883, 0.28908997304819883, 0.37348430558865714], 
reward next is 0.6265, 
noisyNet noise sample is [array([1.1152043], dtype=float32), 0.72473186]. 
=============================================
[2019-03-24 06:42:44,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4375568e-05 7.2524569e-04 6.3461348e-06 9.9917835e-01 7.5683332e-05], sum to 1.0000
[2019-03-24 06:42:44,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0244
[2019-03-24 06:42:44,599] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.66666666666667, 1.0, 2.0, 0.3495625560594092, 1.0, 2.0, 0.3495625560594092, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796804.3345639971, 796804.3345639971, 192779.8636583545], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4854000.0000, 
sim time next is 4854600.0000, 
raw observation next is [25.0, 95.0, 1.0, 2.0, 0.3503788030457934, 1.0, 2.0, 0.3503788030457934, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 798665.884020859, 798665.8840208594, 192989.8895940035], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.95, 1.0, 1.0, 0.2266414321973731, 1.0, 1.0, 0.2266414321973731, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28523781572173534, 0.2852378157217355, 0.37113440306539136], 
reward next is 0.6289, 
noisyNet noise sample is [array([1.6657839], dtype=float32), 0.69705105]. 
=============================================
[2019-03-24 06:42:47,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8404620e-06 5.0011982e-07 6.8531541e-08 9.9999619e-01 1.4465555e-06], sum to 1.0000
[2019-03-24 06:42:47,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-24 06:42:47,798] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.73333333333333, 88.66666666666667, 1.0, 2.0, 0.4377113239098153, 1.0, 2.0, 0.4377113239098153, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 997864.3314455437, 997864.3314455441, 216794.5160129205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4911600.0000, 
sim time next is 4912200.0000, 
raw observation next is [28.55, 90.0, 1.0, 2.0, 0.4382234229707674, 1.0, 2.0, 0.4382234229707674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999032.5408769954, 999032.5408769954, 216941.8912176396], 
processed observation next is [1.0, 0.8695652173913043, 0.612962962962963, 0.9, 1.0, 1.0, 0.331218360679485, 1.0, 1.0, 0.331218360679485, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35679733602749836, 0.35679733602749836, 0.4171959446493069], 
reward next is 0.5828, 
noisyNet noise sample is [array([0.5081762], dtype=float32), -1.578519]. 
=============================================
[2019-03-24 06:42:55,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5719990e-10 2.4078352e-07 8.1005268e-08 9.9999893e-01 7.4596983e-07], sum to 1.0000
[2019-03-24 06:42:55,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2031
[2019-03-24 06:42:55,827] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.25, 86.5, 1.0, 2.0, 0.3054832939636362, 1.0, 2.0, 0.3054832939636362, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 696282.987665305, 696282.9876653055, 181781.7492648135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5039400.0000, 
sim time next is 5040000.0000, 
raw observation next is [25.5, 85.0, 1.0, 2.0, 0.3065185368515945, 1.0, 2.0, 0.3065185368515945, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698643.6747963013, 698643.6747963013, 182032.3444399821], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.85, 1.0, 1.0, 0.1744268295852316, 1.0, 1.0, 0.1744268295852316, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24951559814153618, 0.24951559814153618, 0.3500622008461194], 
reward next is 0.6499, 
noisyNet noise sample is [array([-0.16578816], dtype=float32), 1.6224517]. 
=============================================
[2019-03-24 06:42:55,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.16811]
 [65.21262]
 [65.2496 ]
 [65.2461 ]
 [65.25975]], R is [[65.15890503]
 [65.15773773]
 [65.1572876 ]
 [65.15740967]
 [65.15812683]].
[2019-03-24 06:42:55,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5019041e-08 1.6374368e-05 1.2327730e-07 9.9998200e-01 1.5507530e-06], sum to 1.0000
[2019-03-24 06:42:55,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9821
[2019-03-24 06:42:55,922] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 97.33333333333333, 1.0, 2.0, 0.3789501473453089, 1.0, 2.0, 0.3789501473453089, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 863829.1212679162, 863829.1212679157, 200487.2856628718], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5096400.0000, 
sim time next is 5097000.0000, 
raw observation next is [26.05, 98.66666666666667, 1.0, 2.0, 0.3840274320079088, 1.0, 2.0, 0.3840274320079088, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 875409.5658687972, 875409.5658687977, 201849.094096262], 
processed observation next is [0.0, 1.0, 0.5203703703703704, 0.9866666666666667, 1.0, 1.0, 0.266699323818939, 1.0, 1.0, 0.266699323818939, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3126462735245705, 0.3126462735245706, 0.38817133480050386], 
reward next is 0.6118, 
noisyNet noise sample is [array([-0.23918284], dtype=float32), -0.9265618]. 
=============================================
[2019-03-24 06:42:55,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.665016]
 [69.57286 ]
 [69.480385]
 [69.35917 ]
 [69.22988 ]], R is [[69.65322876]
 [69.5711441 ]
 [69.49192047]
 [69.41508484]
 [69.34008026]].
[2019-03-24 06:43:00,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1898002e-08 5.8706384e-08 4.0145400e-07 9.9999940e-01 6.4249242e-08], sum to 1.0000
[2019-03-24 06:43:01,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6638
[2019-03-24 06:43:01,007] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 86.16666666666667, 1.0, 2.0, 0.3420171055607409, 1.0, 2.0, 0.3420171055607409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 779596.2409566608, 779596.2409566613, 190849.74920918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5173800.0000, 
sim time next is 5174400.0000, 
raw observation next is [26.2, 86.33333333333334, 1.0, 2.0, 0.34383718005523, 1.0, 2.0, 0.34383718005523, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 783747.0528281057, 783747.0528281062, 191313.43725951], 
processed observation next is [0.0, 0.9130434782608695, 0.5259259259259259, 0.8633333333333334, 1.0, 1.0, 0.21885378578003573, 1.0, 1.0, 0.21885378578003573, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27990966172432347, 0.27990966172432363, 0.3679104562682885], 
reward next is 0.6321, 
noisyNet noise sample is [array([0.05476246], dtype=float32), 1.3263528]. 
=============================================
[2019-03-24 06:43:04,719] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.45966615e-05 4.73013060e-05 8.62554714e-07 9.99918222e-01
 1.89571947e-05], sum to 1.0000
[2019-03-24 06:43:04,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8404
[2019-03-24 06:43:04,728] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 94.0, 1.0, 2.0, 0.414519225510525, 1.0, 2.0, 0.414519225510525, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944959.9731520371, 944959.9731520376, 210212.5680197875], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5211600.0000, 
sim time next is 5212200.0000, 
raw observation next is [24.41666666666667, 92.5, 1.0, 2.0, 0.3939161776937234, 1.0, 2.0, 0.3939161776937234, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 897964.6577144553, 897964.6577144548, 204524.6189799], 
processed observation next is [1.0, 0.30434782608695654, 0.4598765432098767, 0.925, 1.0, 1.0, 0.2784716401115755, 1.0, 1.0, 0.2784716401115755, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3207016634694483, 0.3207016634694482, 0.39331657496134614], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.68963766], dtype=float32), 0.3359386]. 
=============================================
[2019-03-24 06:43:10,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9810849e-05 6.1767950e-04 3.0396593e-06 9.9928099e-01 3.8425464e-05], sum to 1.0000
[2019-03-24 06:43:10,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2604
[2019-03-24 06:43:10,390] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 65.0, 1.0, 2.0, 0.6781909405343517, 1.0, 2.0, 0.6781909405343517, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1546646.775206517, 1546646.775206517, 295990.124946499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5319600.0000, 
sim time next is 5320200.0000, 
raw observation next is [28.0, 64.0, 1.0, 2.0, 0.6696796953719586, 1.0, 2.0, 0.6696796953719586, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1527217.118586839, 1527217.118586839, 292844.9551957673], 
processed observation next is [1.0, 0.5652173913043478, 0.5925925925925926, 0.64, 1.0, 1.0, 0.6067615421094745, 1.0, 1.0, 0.6067615421094745, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5454346852095854, 0.5454346852095854, 0.5631633753764755], 
reward next is 0.4368, 
noisyNet noise sample is [array([-0.14530839], dtype=float32), 1.5813589]. 
=============================================
[2019-03-24 06:43:11,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6522050e-06 1.7504910e-05 1.6424922e-07 9.9997568e-01 5.0043950e-06], sum to 1.0000
[2019-03-24 06:43:11,593] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0316
[2019-03-24 06:43:11,598] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.3618764685814599, 1.0, 2.0, 0.3618764685814599, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 824888.1739753722, 824888.1739753727, 195971.6786702698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5382000.0000, 
sim time next is 5382600.0000, 
raw observation next is [24.65, 91.00000000000001, 1.0, 2.0, 0.3649979689813453, 1.0, 2.0, 0.3649979689813453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832007.4164577109, 832007.4164577114, 196789.3510489978], 
processed observation next is [1.0, 0.30434782608695654, 0.46851851851851845, 0.9100000000000001, 1.0, 1.0, 0.2440452011682682, 1.0, 1.0, 0.2440452011682682, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2971455058777539, 0.29714550587775407, 0.37844105970961117], 
reward next is 0.6216, 
noisyNet noise sample is [array([-0.94630706], dtype=float32), 0.3427355]. 
=============================================
[2019-03-24 06:43:12,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.59985520e-05 1.99171394e-04 1.54742720e-05 9.99663711e-01
 1.05673156e-04], sum to 1.0000
[2019-03-24 06:43:12,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4006
[2019-03-24 06:43:12,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 82.5, 1.0, 2.0, 0.3271878227363662, 1.0, 2.0, 0.3271878227363662, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745777.8237121577, 745777.8237121577, 187113.2477135737], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5517000.0000, 
sim time next is 5517600.0000, 
raw observation next is [26.46666666666667, 83.0, 1.0, 2.0, 0.3293657297806714, 1.0, 2.0, 0.3293657297806714, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750744.4821731109, 750744.4821731109, 187657.2190241101], 
processed observation next is [1.0, 0.8695652173913043, 0.5358024691358025, 0.83, 1.0, 1.0, 0.2016258687865136, 1.0, 1.0, 0.2016258687865136, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2681230293475396, 0.2681230293475396, 0.36087926735405784], 
reward next is 0.6391, 
noisyNet noise sample is [array([-0.14158851], dtype=float32), -0.24377507]. 
=============================================
[2019-03-24 06:43:14,047] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4036359e-07 3.9451069e-04 4.0866249e-07 9.9780947e-01 1.7954515e-03], sum to 1.0000
[2019-03-24 06:43:14,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5434
[2019-03-24 06:43:14,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.4, 89.0, 1.0, 2.0, 0.3854615226422124, 1.0, 2.0, 0.3854615226422124, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878680.5205535688, 878680.5205535688, 202235.3652068733], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5439600.0000, 
sim time next is 5440200.0000, 
raw observation next is [27.33333333333333, 89.16666666666667, 1.0, 2.0, 0.383828672655006, 1.0, 2.0, 0.383828672655006, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 874956.2254443313, 874956.2254443318, 201795.6224672914], 
processed observation next is [1.0, 1.0, 0.5679012345679011, 0.8916666666666667, 1.0, 1.0, 0.2664627055416738, 1.0, 1.0, 0.2664627055416738, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3124843662301183, 0.3124843662301185, 0.38806850474479115], 
reward next is 0.6119, 
noisyNet noise sample is [array([-0.59944385], dtype=float32), -0.2425165]. 
=============================================
[2019-03-24 06:43:15,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0932523e-06 2.5659811e-04 1.3226760e-05 9.9967599e-01 5.2061365e-05], sum to 1.0000
[2019-03-24 06:43:15,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9362
[2019-03-24 06:43:15,038] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 81.0, 1.0, 2.0, 0.3863056944165255, 1.0, 2.0, 0.3863056944165255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880605.961606524, 880605.9616065244, 202463.2333453339], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5428800.0000, 
sim time next is 5429400.0000, 
raw observation next is [28.71666666666667, 81.5, 1.0, 2.0, 0.3867584402441162, 1.0, 2.0, 0.3867584402441162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 881638.6152818279, 881638.6152818283, 202585.4441874152], 
processed observation next is [1.0, 0.8695652173913043, 0.6191358024691359, 0.815, 1.0, 1.0, 0.26995052410013837, 1.0, 1.0, 0.26995052410013837, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3148709340292242, 0.3148709340292244, 0.38958739266810616], 
reward next is 0.6104, 
noisyNet noise sample is [array([-1.0555156], dtype=float32), -2.2375484]. 
=============================================
[2019-03-24 06:43:16,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1902684e-05 8.3210667e-05 3.6936734e-05 9.9950087e-01 3.3704212e-04], sum to 1.0000
[2019-03-24 06:43:16,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5387
[2019-03-24 06:43:16,845] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.75, 76.0, 1.0, 2.0, 0.9527710750888814, 1.0, 2.0, 0.9527710750888814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2173608.929528561, 2173608.929528561, 410926.2241153743], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5501400.0000, 
sim time next is 5502000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.8785844346110133, 1.0, 2.0, 0.8785844346110133, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2004172.942320237, 2004172.942320238, 377297.2166658855], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.77, 1.0, 1.0, 0.8554576602512063, 1.0, 1.0, 0.8554576602512063, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.715776050828656, 0.7157760508286565, 0.7255715705113184], 
reward next is 0.2744, 
noisyNet noise sample is [array([-0.8217877], dtype=float32), -0.8469536]. 
=============================================
[2019-03-24 06:43:16,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[43.86221 ]
 [44.247112]
 [43.333256]
 [44.60259 ]
 [40.345642]], R is [[42.58148575]
 [42.36542892]
 [42.19630051]
 [42.06680679]
 [41.90375137]].
[2019-03-24 06:43:17,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4761025e-05 2.1607915e-04 9.5866208e-06 9.9928999e-01 4.0952326e-04], sum to 1.0000
[2019-03-24 06:43:17,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6254
[2019-03-24 06:43:17,775] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.36666666666667, 94.33333333333334, 1.0, 2.0, 0.4522692226711553, 1.0, 2.0, 0.4522692226711553, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1031074.761826388, 1031074.761826388, 221017.6641814422], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5463600.0000, 
sim time next is 5464200.0000, 
raw observation next is [26.43333333333334, 94.16666666666667, 1.0, 2.0, 0.4536006951017007, 1.0, 2.0, 0.4536006951017007, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1034112.275624715, 1034112.275624716, 221407.7631467796], 
processed observation next is [1.0, 0.21739130434782608, 0.5345679012345682, 0.9416666666666668, 1.0, 1.0, 0.3495246370258342, 1.0, 1.0, 0.3495246370258342, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3693258127231125, 0.3693258127231128, 0.42578415989765306], 
reward next is 0.5742, 
noisyNet noise sample is [array([1.0204114], dtype=float32), 0.35709405]. 
=============================================
[2019-03-24 06:43:18,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2104039e-07 2.8732053e-05 1.1531323e-06 9.9992979e-01 3.9718656e-05], sum to 1.0000
[2019-03-24 06:43:18,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9469
[2019-03-24 06:43:18,079] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.46666666666667, 83.0, 1.0, 2.0, 0.3293657297806714, 1.0, 2.0, 0.3293657297806714, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750744.4821731109, 750744.4821731109, 187657.2190241101], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5517600.0000, 
sim time next is 5518200.0000, 
raw observation next is [26.43333333333333, 83.5, 1.0, 2.0, 0.3308246435239282, 1.0, 2.0, 0.3308246435239282, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 754071.5137402088, 754071.5137402093, 188022.5389831465], 
processed observation next is [1.0, 0.8695652173913043, 0.5345679012345678, 0.835, 1.0, 1.0, 0.2033626708618193, 1.0, 1.0, 0.2033626708618193, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2693112549072174, 0.2693112549072176, 0.3615818057368202], 
reward next is 0.6384, 
noisyNet noise sample is [array([0.6761013], dtype=float32), -0.75212836]. 
=============================================
[2019-03-24 06:43:20,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2988575e-06 5.0233281e-04 3.4612440e-05 9.9882764e-01 6.2602537e-04], sum to 1.0000
[2019-03-24 06:43:20,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-24 06:43:20,293] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 79.66666666666667, 1.0, 2.0, 0.6052933329558486, 1.0, 2.0, 0.6052933329558486, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1380250.490143595, 1380250.490143596, 269866.2820810745], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5568000.0000, 
sim time next is 5568600.0000, 
raw observation next is [26.71666666666667, 79.33333333333334, 1.0, 2.0, 0.6073478945005766, 1.0, 2.0, 0.6073478945005766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1384939.743048194, 1384939.743048195, 270577.3879877405], 
processed observation next is [1.0, 0.43478260869565216, 0.5450617283950618, 0.7933333333333334, 1.0, 1.0, 0.5325570172625912, 1.0, 1.0, 0.5325570172625912, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49462133680292647, 0.4946213368029268, 0.5203411307456548], 
reward next is 0.4797, 
noisyNet noise sample is [array([0.9171262], dtype=float32), 0.5853568]. 
=============================================
[2019-03-24 06:43:25,326] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 06:43:25,327] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:43:25,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:25,329] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:43:25,329] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:43:25,333] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:25,331] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:43:25,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:43:25,336] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:25,339] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:25,339] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:25,359] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-24 06:43:25,388] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-24 06:43:25,414] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-24 06:43:25,416] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-24 06:43:25,480] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-24 06:43:47,148] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:43:47,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.6, 70.83333333333333, 1.0, 2.0, 0.2202857119051238, 1.0, 2.0, 0.2202857119051238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536948.8313363063, 536948.8313363068, 163999.5079448917]
[2019-03-24 06:43:47,154] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:43:47,159] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5062521e-07 5.5950054e-06 2.9417896e-07 9.9998975e-01 4.1328781e-06], sampled 0.5008230377116707
[2019-03-24 06:43:54,781] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:43:54,783] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.61666666666667, 59.66666666666666, 1.0, 2.0, 0.2016452867323119, 1.0, 2.0, 0.2016452867323119, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491365.6648452976, 491365.664845298, 160010.1477679104]
[2019-03-24 06:43:54,783] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:43:54,785] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0503406e-07 9.3054359e-06 5.7820409e-07 9.9998236e-01 7.4771706e-06], sampled 0.4616847304496715
[2019-03-24 06:44:11,539] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:11,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.9, 94.0, 1.0, 2.0, 0.3005638385175522, 1.0, 2.0, 0.3005638385175522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700168.6265382771, 700168.6265382776, 181318.6064379787]
[2019-03-24 06:44:11,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:44:11,544] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.14687530e-07 1.79160379e-05 1.33091635e-06 9.99966741e-01
 1.33988515e-05], sampled 0.28069642066214995
[2019-03-24 06:44:19,949] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:19,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.75930168666666, 65.75645467000001, 1.0, 2.0, 0.4644743884529537, 1.0, 2.0, 0.4644743884529537, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1058919.093220285, 1058919.093220285, 224618.6343184443]
[2019-03-24 06:44:19,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:44:19,953] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3525946e-07 1.4566654e-05 9.9931469e-07 9.9997365e-01 1.0271631e-05], sampled 0.8093130742650068
[2019-03-24 06:44:20,344] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:20,346] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.7652756240148304, 1.0, 2.0, 0.7652756240148304, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1745447.269835426, 1745447.269835426, 329614.6636570867]
[2019-03-24 06:44:20,347] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:44:20,353] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.1656493e-06 1.3217963e-04 1.5006517e-05 9.9976176e-01 8.1929880e-05], sampled 0.28397320682452
[2019-03-24 06:44:25,513] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:25,514] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.48643775, 79.37026387, 1.0, 2.0, 0.297779984860703, 1.0, 2.0, 0.297779984860703, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688810.3011368284, 688810.3011368284, 180421.5201510215]
[2019-03-24 06:44:25,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:44:25,521] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1291861e-07 1.1809025e-05 7.8016978e-07 9.9997783e-01 9.1667207e-06], sampled 0.49653357362210393
[2019-03-24 06:44:51,634] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:51,635] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.06124524, 98.76355336, 1.0, 2.0, 0.3120368287019263, 1.0, 2.0, 0.3120368287019263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 711227.2797525951, 711227.2797525955, 183374.5184521885]
[2019-03-24 06:44:51,637] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:44:51,639] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3459636e-07 5.1035745e-06 2.6266977e-07 9.9999082e-01 3.6373353e-06], sampled 0.17245949603395927
[2019-03-24 06:44:58,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:44:58,780] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.7, 85.66666666666667, 1.0, 2.0, 0.3011169388427569, 1.0, 2.0, 0.3011169388427569, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706136.94121575, 706136.9412157504, 181659.4742704587]
[2019-03-24 06:44:58,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:44:58,784] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3007439e-07 1.0210971e-05 6.3243112e-07 9.9998140e-01 7.4460809e-06], sampled 0.14381400603874017
[2019-03-24 06:45:01,233] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00891328], dtype=float32), 0.0047597173]
[2019-03-24 06:45:01,234] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.3, 72.0, 1.0, 2.0, 0.5824951429626398, 1.0, 2.0, 0.5824951429626398, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1361761.507624052, 1361761.507624052, 263651.2355700661]
[2019-03-24 06:45:01,234] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:45:01,237] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9963866e-06 6.8693305e-05 6.9582325e-06 9.9987268e-01 4.7710146e-05], sampled 0.08055032906567328
[2019-03-24 06:45:12,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7333 2495416168.7968 47.0000
[2019-03-24 06:45:12,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0851 2668494907.5392 68.0000
[2019-03-24 06:45:12,953] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.2054 2410715882.6656 22.0000
[2019-03-24 06:45:12,989] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2475 2438815213.3778 34.0000
[2019-03-24 06:45:13,094] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.8219 2465891420.0528 46.0000
[2019-03-24 06:45:14,106] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 575000, evaluation results [575000.0, 7523.085099490553, 2668494907.5392137, 68.0, 7122.247549992863, 2438815213.3778014, 34.0, 7796.205398825364, 2410715882.6655507, 22.0, 6906.733277770052, 2495416168.7968493, 47.0, 7479.8219463540245, 2465891420.0528073, 46.0]
[2019-03-24 06:45:20,489] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8689740e-08 4.4784764e-07 2.9373336e-07 9.9997783e-01 2.1362306e-05], sum to 1.0000
[2019-03-24 06:45:20,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4681
[2019-03-24 06:45:20,502] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.4, 88.5, 1.0, 2.0, 0.2170580275134808, 1.0, 2.0, 0.2170580275134808, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 527405.0994779253, 527405.0994779258, 163243.4852329102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [21.43333333333333, 88.0, 1.0, 2.0, 0.2165482266423634, 1.0, 2.0, 0.2165482266423634, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 526416.3970499747, 526416.3970499751, 163142.2490342285], 
processed observation next is [0.0, 0.30434782608695654, 0.3493827160493826, 0.88, 1.0, 1.0, 0.06731931743138499, 1.0, 1.0, 0.06731931743138499, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18800585608927667, 0.18800585608927683, 0.3137350942965933], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.42289788], dtype=float32), 0.2474851]. 
=============================================
[2019-03-24 06:45:20,514] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.19489 ]
 [74.164894]
 [74.15919 ]
 [74.125656]
 [74.047874]], R is [[74.1366806 ]
 [74.08139038]
 [74.02639771]
 [73.97161102]
 [73.91699982]].
[2019-03-24 06:45:21,014] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8563792e-06 9.8057512e-07 1.6227503e-06 9.9998510e-01 6.3889725e-06], sum to 1.0000
[2019-03-24 06:45:21,023] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7814
[2019-03-24 06:45:21,029] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.51666666666667, 85.00000000000001, 1.0, 2.0, 0.2555657804721929, 1.0, 2.0, 0.2555657804721929, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602931.3516543022, 602931.3516543022, 171120.7297247765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5785800.0000, 
sim time next is 5786400.0000, 
raw observation next is [23.43333333333334, 85.0, 1.0, 2.0, 0.2537043594792154, 1.0, 2.0, 0.2537043594792154, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599460.1674732888, 599460.1674732893, 170737.7296342226], 
processed observation next is [0.0, 1.0, 0.42345679012345705, 0.85, 1.0, 1.0, 0.11155280890382784, 1.0, 1.0, 0.11155280890382784, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.214092916954746, 0.21409291695474617, 0.3283417877581204], 
reward next is 0.6717, 
noisyNet noise sample is [array([-1.5158641], dtype=float32), 0.52990335]. 
=============================================
[2019-03-24 06:45:23,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5005921e-08 8.2398719e-06 5.7079268e-07 9.9999046e-01 7.0325700e-07], sum to 1.0000
[2019-03-24 06:45:23,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0139
[2019-03-24 06:45:23,543] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.21666666666667, 46.83333333333334, 1.0, 2.0, 0.3298843932923254, 1.0, 2.0, 0.3298843932923254, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809135.2734918176, 809135.2734918181, 190061.2060402922], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [27.3, 47.0, 1.0, 2.0, 0.3283762467030173, 1.0, 2.0, 0.3283762467030173, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804258.9868667234, 804258.9868667234, 189641.9023530478], 
processed observation next is [1.0, 0.5652173913043478, 0.5666666666666667, 0.47, 1.0, 1.0, 0.20044791274168725, 1.0, 1.0, 0.20044791274168725, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2872353524524012, 0.2872353524524012, 0.3646959660635535], 
reward next is 0.6353, 
noisyNet noise sample is [array([1.4229949], dtype=float32), -1.1253799]. 
=============================================
[2019-03-24 06:45:24,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7675753e-07 1.5683876e-05 9.0422155e-08 9.9990487e-01 7.9080797e-05], sum to 1.0000
[2019-03-24 06:45:24,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1232
[2019-03-24 06:45:24,146] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 52.33333333333333, 1.0, 2.0, 0.1974498268406427, 1.0, 2.0, 0.1974498268406427, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484144.8105067951, 484144.8105067955, 159230.7645803722], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [26.36666666666666, 53.66666666666666, 1.0, 2.0, 0.1997985088964041, 1.0, 2.0, 0.1997985088964041, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489237.2954695782, 489237.2954695782, 159701.7905745519], 
processed observation next is [1.0, 0.782608695652174, 0.5320987654320986, 0.5366666666666666, 1.0, 1.0, 0.04737917725762393, 1.0, 1.0, 0.04737917725762393, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17472760552484934, 0.17472760552484934, 0.30711882802798446], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.29323193], dtype=float32), -0.35898876]. 
=============================================
[2019-03-24 06:45:26,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1580336e-09 3.1455467e-05 5.5061622e-07 9.9994838e-01 1.9537943e-05], sum to 1.0000
[2019-03-24 06:45:26,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2207
[2019-03-24 06:45:26,603] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.73333333333333, 74.33333333333333, 1.0, 2.0, 0.1976489898575148, 1.0, 2.0, 0.1976489898575148, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491342.7730998464, 491342.7730998468, 159463.889466969], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5902800.0000, 
sim time next is 5903400.0000, 
raw observation next is [21.91666666666667, 73.66666666666667, 1.0, 2.0, 0.2035949032120841, 1.0, 2.0, 0.2035949032120841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505409.3781613049, 505409.3781613049, 160700.5991791402], 
processed observation next is [1.0, 0.30434782608695654, 0.36728395061728414, 0.7366666666666667, 1.0, 1.0, 0.05189869430010011, 1.0, 1.0, 0.05189869430010011, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18050334934332318, 0.18050334934332318, 0.30903961380603884], 
reward next is 0.6910, 
noisyNet noise sample is [array([-1.3246375], dtype=float32), -0.2689074]. 
=============================================
[2019-03-24 06:45:28,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8803178e-08 3.9309912e-06 9.2895419e-08 9.9994469e-01 5.1256124e-05], sum to 1.0000
[2019-03-24 06:45:28,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6760
[2019-03-24 06:45:28,759] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.11666666666667, 76.83333333333333, 1.0, 2.0, 0.2435046734301128, 1.0, 2.0, 0.2435046734301128, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580407.807674649, 580407.807674649, 168654.1003524399], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5953800.0000, 
sim time next is 5954400.0000, 
raw observation next is [23.9, 78.0, 1.0, 2.0, 0.2424839276549925, 1.0, 2.0, 0.2424839276549925, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578429.2122029299, 578429.2122029304, 168444.1570897187], 
processed observation next is [1.0, 0.9565217391304348, 0.4407407407407407, 0.78, 1.0, 1.0, 0.09819515197022916, 1.0, 1.0, 0.09819515197022916, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20658186150104638, 0.20658186150104654, 0.3239310713263821], 
reward next is 0.6761, 
noisyNet noise sample is [array([-1.7991769], dtype=float32), 0.58905756]. 
=============================================
[2019-03-24 06:45:29,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8630886e-07 1.5745592e-06 1.3628669e-07 9.9999511e-01 2.6902990e-06], sum to 1.0000
[2019-03-24 06:45:29,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1571
[2019-03-24 06:45:29,893] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 53.66666666666667, 1.0, 2.0, 0.2273227775152814, 1.0, 2.0, 0.2273227775152814, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541382.421572309, 541382.421572309, 165058.9616589594], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5938800.0000, 
sim time next is 5939400.0000, 
raw observation next is [28.13333333333333, 54.33333333333334, 1.0, 2.0, 0.2317225223508645, 1.0, 2.0, 0.2317225223508645, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551760.5064526057, 551760.5064526057, 166017.8096887413], 
processed observation next is [1.0, 0.7391304347826086, 0.5975308641975308, 0.5433333333333334, 1.0, 1.0, 0.08538395517960058, 1.0, 1.0, 0.08538395517960058, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19705732373307347, 0.19705732373307347, 0.3192650186321948], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.93299603], dtype=float32), 1.0985982]. 
=============================================
[2019-03-24 06:45:30,026] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6799757e-05 8.6360215e-04 5.3301148e-05 9.9884593e-01 2.2023692e-04], sum to 1.0000
[2019-03-24 06:45:30,036] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2122
[2019-03-24 06:45:30,048] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 54.5, 1.0, 2.0, 0.5881438487128824, 1.0, 2.0, 0.5881438487128824, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1401234.736772487, 1401234.736772487, 266668.3911703142], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5916600.0000, 
sim time next is 5917200.0000, 
raw observation next is [27.26666666666667, 53.66666666666667, 1.0, 2.0, 0.5893062969270708, 1.0, 2.0, 0.5893062969270708, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1403906.085800899, 1403906.085800898, 267065.9124243752], 
processed observation next is [1.0, 0.4782608695652174, 0.5654320987654322, 0.5366666666666667, 1.0, 1.0, 0.5110789249131795, 1.0, 1.0, 0.5110789249131795, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5013950306431783, 0.5013950306431779, 0.5135882931237984], 
reward next is 0.4864, 
noisyNet noise sample is [array([-2.2942674], dtype=float32), 0.44381025]. 
=============================================
[2019-03-24 06:45:30,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1046313e-05 3.8727871e-04 2.4169776e-05 9.9942005e-01 7.7463606e-05], sum to 1.0000
[2019-03-24 06:45:30,417] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1745
[2019-03-24 06:45:30,420] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 77.0, 1.0, 2.0, 0.2274801213786239, 1.0, 2.0, 0.2274801213786239, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 557033.2995638859, 557033.2995638864, 165651.9001220658], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5986800.0000, 
sim time next is 5987400.0000, 
raw observation next is [22.51666666666667, 76.33333333333334, 1.0, 2.0, 0.282234250582633, 1.0, 2.0, 0.282234250582633, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689922.7998019736, 689922.7998019741, 178185.2056755584], 
processed observation next is [1.0, 0.30434782608695654, 0.3895061728395063, 0.7633333333333334, 1.0, 1.0, 0.145516964979325, 1.0, 1.0, 0.145516964979325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2464009999292763, 0.24640099992927647, 0.34266385706838154], 
reward next is 0.6573, 
noisyNet noise sample is [array([-1.0726693], dtype=float32), 0.9959774]. 
=============================================
[2019-03-24 06:45:31,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5455261e-07 3.6827805e-06 2.0074928e-07 9.9999452e-01 1.1362227e-06], sum to 1.0000
[2019-03-24 06:45:31,139] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2890
[2019-03-24 06:45:31,143] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.65, 72.5, 1.0, 2.0, 0.4638667235044441, 1.0, 2.0, 0.4638667235044441, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1117615.450980505, 1117615.450980505, 226952.2640617788], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [23.83333333333334, 72.33333333333334, 1.0, 2.0, 0.4772926505178835, 1.0, 2.0, 0.4772926505178835, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1145627.819459781, 1145627.819459781, 230892.473691785], 
processed observation next is [1.0, 0.34782608695652173, 0.43827160493827183, 0.7233333333333334, 1.0, 1.0, 0.3777293458546232, 1.0, 1.0, 0.3777293458546232, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4091527926642075, 0.4091527926642075, 0.4440239878688173], 
reward next is 0.5560, 
noisyNet noise sample is [array([-0.95772386], dtype=float32), -0.97967345]. 
=============================================
[2019-03-24 06:45:31,403] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1764308e-07 1.1143837e-04 2.2113377e-06 9.9981934e-01 6.6355948e-05], sum to 1.0000
[2019-03-24 06:45:31,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4476
[2019-03-24 06:45:31,420] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 62.33333333333333, 1.0, 2.0, 0.2439075867244605, 1.0, 2.0, 0.2439075867244605, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580937.8623298251, 580937.8623298251, 168726.8530688026], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5946600.0000, 
sim time next is 5947200.0000, 
raw observation next is [26.4, 63.0, 1.0, 2.0, 0.2444689003205018, 1.0, 2.0, 0.2444689003205018, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582378.7714281756, 582378.7714281756, 168856.8384996375], 
processed observation next is [1.0, 0.8695652173913043, 0.5333333333333333, 0.63, 1.0, 1.0, 0.10055821466726406, 1.0, 1.0, 0.10055821466726406, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20799241836720558, 0.20799241836720558, 0.3247246894223798], 
reward next is 0.6753, 
noisyNet noise sample is [array([1.2326262], dtype=float32), -0.53564465]. 
=============================================
[2019-03-24 06:45:32,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2615543e-05 4.4194262e-06 6.0745269e-06 9.9996138e-01 5.5303344e-06], sum to 1.0000
[2019-03-24 06:45:32,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1730
[2019-03-24 06:45:32,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 69.5, 1.0, 2.0, 0.2681356703597977, 1.0, 2.0, 0.2681356703597977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626787.68662295, 626787.68662295, 173751.2214179221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [26.23333333333333, 70.0, 1.0, 2.0, 0.267668324258318, 1.0, 2.0, 0.267668324258318, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626073.4126661815, 626073.4126661819, 173660.3816687487], 
processed observation next is [1.0, 0.8695652173913043, 0.5271604938271603, 0.7, 1.0, 1.0, 0.1281765764979976, 1.0, 1.0, 0.1281765764979976, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22359764738077909, 0.22359764738077925, 0.3339622724399014], 
reward next is 0.6660, 
noisyNet noise sample is [array([-0.5687823], dtype=float32), -1.1404064]. 
=============================================
[2019-03-24 06:45:32,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.171127]
 [55.42449 ]
 [55.65791 ]
 [55.883442]
 [56.07785 ]], R is [[55.11828995]
 [55.23297119]
 [55.34638596]
 [55.4585762 ]
 [55.56963348]].
[2019-03-24 06:45:33,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6594405e-07 1.2106855e-05 5.1436814e-06 9.9985552e-01 1.2673238e-04], sum to 1.0000
[2019-03-24 06:45:33,581] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8808
[2019-03-24 06:45:33,589] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.85, 61.0, 1.0, 2.0, 0.2633301480473152, 1.0, 2.0, 0.2633301480473152, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615893.1749064892, 615893.1749064892, 172660.4298485106], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6028200.0000, 
sim time next is 6028800.0000, 
raw observation next is [27.73333333333333, 61.66666666666667, 1.0, 2.0, 0.2636301353016073, 1.0, 2.0, 0.2636301353016073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616494.9881256861, 616494.9881256861, 172724.7369334765], 
processed observation next is [1.0, 0.782608695652174, 0.5827160493827159, 0.6166666666666667, 1.0, 1.0, 0.12336920869238963, 1.0, 1.0, 0.12336920869238963, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22017678147345932, 0.22017678147345932, 0.33216295564130094], 
reward next is 0.6678, 
noisyNet noise sample is [array([-0.76430565], dtype=float32), 1.0479728]. 
=============================================
[2019-03-24 06:45:35,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2817087e-07 1.1448972e-06 2.0496527e-06 9.9997342e-01 2.3253522e-05], sum to 1.0000
[2019-03-24 06:45:35,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9810
[2019-03-24 06:45:35,614] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 62.5, 1.0, 2.0, 0.2816654184762361, 1.0, 2.0, 0.2816654184762361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 650476.0634750358, 650476.0634750363, 176540.8741809904], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [28.13333333333333, 63.33333333333333, 1.0, 2.0, 0.2834998374868933, 1.0, 2.0, 0.2834998374868933, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654196.3681895522, 654196.3681895522, 176947.2892532273], 
processed observation next is [1.0, 0.8260869565217391, 0.5975308641975308, 0.6333333333333333, 1.0, 1.0, 0.14702361605582534, 1.0, 1.0, 0.14702361605582534, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2336415600676972, 0.2336415600676972, 0.34028324856389863], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.563374], dtype=float32), -0.39810634]. 
=============================================
[2019-03-24 06:45:36,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2266187e-06 1.0838808e-04 6.8875022e-05 9.9959451e-01 2.2702600e-04], sum to 1.0000
[2019-03-24 06:45:36,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-24 06:45:36,219] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666667, 53.33333333333334, 1.0, 2.0, 0.7131558128422617, 1.0, 2.0, 0.7131558128422617, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1626463.737867276, 1626463.737867277, 309174.1698011294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6081600.0000, 
sim time next is 6082200.0000, 
raw observation next is [29.95, 54.5, 1.0, 2.0, 0.694092194384482, 1.0, 2.0, 0.694092194384482, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1582947.648210454, 1582947.648210455, 301933.4677075503], 
processed observation next is [1.0, 0.391304347826087, 0.6648148148148147, 0.545, 1.0, 1.0, 0.6358240409339071, 1.0, 1.0, 0.6358240409339071, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.5653384457894479, 0.5653384457894483, 0.5806412840529814], 
reward next is 0.4194, 
noisyNet noise sample is [array([1.9747199], dtype=float32), -1.4256039]. 
=============================================
[2019-03-24 06:45:37,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1196583e-05 1.3938206e-04 5.9599639e-05 9.9891949e-01 8.7033043e-04], sum to 1.0000
[2019-03-24 06:45:37,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9210
[2019-03-24 06:45:37,204] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.36666666666667, 57.66666666666666, 1.0, 2.0, 0.2708324806164394, 1.0, 2.0, 0.2708324806164394, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623662.4829132595, 623662.4829132595, 173930.9782885725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6111600.0000, 
sim time next is 6112200.0000, 
raw observation next is [29.23333333333333, 58.33333333333334, 1.0, 2.0, 0.2735203070325756, 1.0, 2.0, 0.2735203070325756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 629779.0875301999, 629779.0875302004, 174548.775395557], 
processed observation next is [1.0, 0.7391304347826086, 0.6382716049382715, 0.5833333333333335, 1.0, 1.0, 0.13514322265782813, 1.0, 1.0, 0.13514322265782813, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2249211026893571, 0.22492110268935728, 0.3356707219145327], 
reward next is 0.6643, 
noisyNet noise sample is [array([2.3003707], dtype=float32), -0.82722336]. 
=============================================
[2019-03-24 06:45:37,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.05495374e-07 2.63180186e-06 2.53063627e-06 9.99993682e-01
 1.05318509e-06], sum to 1.0000
[2019-03-24 06:45:37,385] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8204
[2019-03-24 06:45:37,389] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 57.0, 1.0, 2.0, 0.2673126506306102, 1.0, 2.0, 0.2673126506306102, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 615460.536569333, 615460.5365693334, 173116.3043207774], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6111000.0000, 
sim time next is 6111600.0000, 
raw observation next is [29.36666666666667, 57.66666666666666, 1.0, 2.0, 0.2708324806164394, 1.0, 2.0, 0.2708324806164394, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623662.4829132595, 623662.4829132595, 173930.9782885725], 
processed observation next is [1.0, 0.7391304347826086, 0.64320987654321, 0.5766666666666665, 1.0, 1.0, 0.131943429305285, 1.0, 1.0, 0.131943429305285, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22273660104044984, 0.22273660104044984, 0.33448265055494714], 
reward next is 0.6655, 
noisyNet noise sample is [array([0.72196406], dtype=float32), 0.98569643]. 
=============================================
[2019-03-24 06:45:39,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0208723e-05 5.8099354e-04 6.9705427e-05 9.9914157e-01 1.8753030e-04], sum to 1.0000
[2019-03-24 06:45:39,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2128
[2019-03-24 06:45:39,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.1, 85.33333333333334, 1.0, 2.0, 0.2847986352469613, 1.0, 2.0, 0.2847986352469613, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663783.0009402285, 663783.0009402285, 177561.2475175937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6162600.0000, 
sim time next is 6163200.0000, 
raw observation next is [24.2, 85.0, 1.0, 2.0, 0.2896061668759385, 1.0, 2.0, 0.2896061668759385, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674183.4465577877, 674183.4465577882, 178666.2099184654], 
processed observation next is [1.0, 0.34782608695652173, 0.45185185185185184, 0.85, 1.0, 1.0, 0.1542930558046887, 1.0, 1.0, 0.1542930558046887, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24077980234206703, 0.2407798023420672, 0.34358886522781806], 
reward next is 0.6564, 
noisyNet noise sample is [array([-1.3500752], dtype=float32), -1.035319]. 
=============================================
[2019-03-24 06:45:50,746] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.79179119e-07 1.15198304e-07 1.18690805e-04 9.99865890e-01
 1.50656560e-05], sum to 1.0000
[2019-03-24 06:45:50,753] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8849
[2019-03-24 06:45:50,758] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.18333333333333, 88.00000000000001, 1.0, 2.0, 0.2885943278501918, 1.0, 2.0, 0.2885943278501918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666527.6851175785, 666527.685117579, 178178.0154349005], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6318600.0000, 
sim time next is 6319200.0000, 
raw observation next is [24.16666666666667, 88.0, 1.0, 2.0, 0.2877976204924003, 1.0, 2.0, 0.2877976204924003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664930.0563520597, 664930.0563520597, 178000.7445355219], 
processed observation next is [0.0, 0.13043478260869565, 0.45061728395061745, 0.88, 1.0, 1.0, 0.15214002439571467, 1.0, 1.0, 0.15214002439571467, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2374750201257356, 0.2374750201257356, 0.3423091241067729], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.13964882], dtype=float32), 0.72854877]. 
=============================================
[2019-03-24 06:45:50,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8660139e-05 2.4314811e-04 6.3030995e-05 9.9962199e-01 4.3284806e-05], sum to 1.0000
[2019-03-24 06:45:50,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4862
[2019-03-24 06:45:50,894] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 54.0, 1.0, 2.0, 0.9598456834360257, 1.0, 2.0, 0.9598456834360257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2189768.413603971, 2189768.413603971, 414232.0483893591], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6447600.0000, 
sim time next is 6448200.0000, 
raw observation next is [32.03333333333334, 54.16666666666666, 1.0, 2.0, 0.9141828223484915, 1.0, 2.0, 0.9141828223484915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2085472.624744575, 2085472.624744575, 393195.4078799831], 
processed observation next is [1.0, 0.6521739130434783, 0.7419753086419755, 0.5416666666666665, 1.0, 1.0, 0.8978366932720137, 1.0, 1.0, 0.8978366932720137, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.744811651694491, 0.744811651694491, 0.7561450151538136], 
reward next is 0.2439, 
noisyNet noise sample is [array([0.25234038], dtype=float32), -0.7940599]. 
=============================================
[2019-03-24 06:45:54,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7035521e-05 3.2724092e-05 2.6904540e-06 9.9991918e-01 1.8317834e-05], sum to 1.0000
[2019-03-24 06:45:54,013] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-24 06:45:54,016] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 88.66666666666666, 1.0, 2.0, 0.4206709489903827, 1.0, 2.0, 0.4206709489903827, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 958992.5424878366, 958992.5424878361, 211940.4441297685], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6507600.0000, 
sim time next is 6508200.0000, 
raw observation next is [26.3, 88.83333333333334, 1.0, 2.0, 0.4137529670171948, 1.0, 2.0, 0.4137529670171948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 943212.0947301729, 943212.0947301734, 209999.4748959977], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.8883333333333334, 1.0, 1.0, 0.3020868654966604, 1.0, 1.0, 0.3020868654966604, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3368614624036332, 0.33686146240363335, 0.4038451440307648], 
reward next is 0.5962, 
noisyNet noise sample is [array([0.647951], dtype=float32), 1.1604985]. 
=============================================
[2019-03-24 06:45:54,379] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9572772e-05 3.9146628e-04 1.5449346e-04 9.9938738e-01 4.7010752e-05], sum to 1.0000
[2019-03-24 06:45:54,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4511
[2019-03-24 06:45:54,395] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.48333333333333, 65.83333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.114241009789984, 6.9112, 121.9253915219233, 2431292.001776143, 2327317.41239881, 443048.3983238532], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6437400.0000, 
sim time next is 6438000.0000, 
raw observation next is [30.66666666666667, 64.66666666666667, 1.0, 2.0, 0.9331435029635083, 1.0, 2.0, 0.9331435029635083, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259203479652, 2128778.096074348, 2128778.096074349, 401843.4122448416], 
processed observation next is [1.0, 0.5217391304347826, 0.6913580246913582, 0.6466666666666667, 1.0, 1.0, 0.9204089320994147, 1.0, 1.0, 0.9204089320994147, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.80946131708978, 0.7602778914551243, 0.7602778914551246, 0.7727757927785415], 
reward next is 0.2272, 
noisyNet noise sample is [array([0.45158508], dtype=float32), -1.2247252]. 
=============================================
[2019-03-24 06:45:54,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[40.08183 ]
 [39.78254 ]
 [39.026417]
 [39.449043]
 [39.599308]], R is [[39.98239136]
 [39.58256912]
 [39.30834961]
 [38.91526794]
 [38.52611542]].
[2019-03-24 06:46:01,981] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 06:46:01,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:46:01,983] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:46:01,983] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:46:01,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:46:01,984] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:46:01,984] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:46:01,985] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:46:01,986] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:46:01,987] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:46:01,987] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:46:02,007] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-24 06:46:02,007] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-24 06:46:02,069] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-24 06:46:02,098] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-24 06:46:02,127] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-24 06:46:07,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00906674], dtype=float32), 0.0048746825]
[2019-03-24 06:46:07,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 24.0, 1.0, 2.0, 0.1705941638965221, 1.0, 2.0, 0.1705941638965221, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 434280.7734519877, 434280.7734519881, 154039.3049545239]
[2019-03-24 06:46:07,408] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:46:07,412] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5816680e-07 4.3505916e-06 5.7660793e-07 9.9998176e-01 1.3196680e-05], sampled 0.5864635905311095
[2019-03-24 06:46:21,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00906674], dtype=float32), 0.0048746825]
[2019-03-24 06:46:21,477] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.48900808333333, 43.550284555, 1.0, 2.0, 0.3031155838633257, 1.0, 2.0, 0.3031155838633257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718055.8461413466, 718055.8461413466, 182447.9391648113]
[2019-03-24 06:46:21,478] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:46:21,480] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.72713690e-07 1.49615935e-05 2.47786534e-06 9.99942183e-01
 3.95199531e-05], sampled 0.600525386595771
[2019-03-24 06:47:10,381] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00906674], dtype=float32), 0.0048746825]
[2019-03-24 06:47:10,382] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.925925765, 88.00644783999999, 1.0, 2.0, 0.388975634367793, 1.0, 2.0, 0.388975634367793, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 886695.7635043979, 886695.7635043984, 203184.2654975717]
[2019-03-24 06:47:10,383] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:47:10,387] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0441015e-07 7.2923326e-06 1.0467189e-06 9.9997199e-01 1.9391735e-05], sampled 0.019574291746192296
[2019-03-24 06:47:16,578] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00906674], dtype=float32), 0.0048746825]
[2019-03-24 06:47:16,579] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.88091245666666, 85.45125222333334, 1.0, 2.0, 0.5406773892200751, 1.0, 2.0, 0.5406773892200751, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1232788.17204008, 1232788.17204008, 248248.2841119835]
[2019-03-24 06:47:16,582] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:47:16,585] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4443760e-06 2.4481405e-05 4.4254634e-06 9.9991119e-01 5.8491958e-05], sampled 0.2699156591386267
[2019-03-24 06:47:38,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00906674], dtype=float32), 0.0048746825]
[2019-03-24 06:47:38,968] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.65395116666667, 82.4596642, 1.0, 2.0, 0.2600672637353562, 1.0, 2.0, 0.2600672637353562, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614101.8468754507, 614101.8468754512, 172171.1740854136]
[2019-03-24 06:47:38,969] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:47:38,972] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2834295e-07 1.2722914e-05 2.0374432e-06 9.9995255e-01 3.2113898e-05], sampled 0.02601400850755542
[2019-03-24 06:47:50,325] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.0959 2466037368.8419 46.0000
[2019-03-24 06:47:50,349] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.9810 2668512577.4021 67.0000
[2019-03-24 06:47:50,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495480362.8452 47.0000
[2019-03-24 06:47:50,490] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 06:47:50,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.4955 2410734733.6910 22.0000
[2019-03-24 06:47:51,614] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 600000, evaluation results [600000.0, 7522.980972480654, 2668512577.4021297, 67.0, 7121.435945869477, 2438873699.591536, 34.0, 7797.49551214777, 2410734733.6910453, 22.0, 6905.908355438081, 2495480362.845248, 47.0, 7477.0958563497, 2466037368.8419013, 46.0]
[2019-03-24 06:47:54,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0940293e-06 4.4127685e-04 2.8035340e-05 9.9944752e-01 7.4041789e-05], sum to 1.0000
[2019-03-24 06:47:54,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5388
[2019-03-24 06:47:54,981] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.65, 38.5, 1.0, 2.0, 0.4775863436201391, 1.0, 2.0, 0.4775863436201391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1184779.651485537, 1184779.651485538, 232113.1148042365], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6607800.0000, 
sim time next is 6608400.0000, 
raw observation next is [27.76666666666667, 39.0, 1.0, 2.0, 0.4750418766085447, 1.0, 2.0, 0.4750418766085447, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1175141.156244112, 1175141.156244113, 231249.5371320433], 
processed observation next is [1.0, 0.4782608695652174, 0.5839506172839507, 0.39, 1.0, 1.0, 0.37504985310541034, 1.0, 1.0, 0.37504985310541034, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4196932700871828, 0.41969327008718327, 0.4447106483308525], 
reward next is 0.5553, 
noisyNet noise sample is [array([0.02254971], dtype=float32), -0.23836158]. 
=============================================
[2019-03-24 06:48:05,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3998202e-08 1.0649065e-05 3.4167309e-07 9.9991465e-01 7.4315205e-05], sum to 1.0000
[2019-03-24 06:48:05,744] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5133
[2019-03-24 06:48:05,747] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 48.16666666666666, 1.0, 2.0, 0.2672128129988656, 1.0, 2.0, 0.2672128129988656, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 622401.9285225354, 622401.9285225358, 173436.1518339233], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [31.0, 48.0, 1.0, 2.0, 0.2701367018065738, 1.0, 2.0, 0.2701367018065738, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627828.1449778436, 627828.1449778436, 174047.0576007167], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.48, 1.0, 1.0, 0.13111512119830213, 1.0, 1.0, 0.13111512119830213, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.224224337492087, 0.224224337492087, 0.3347058800013783], 
reward next is 0.6653, 
noisyNet noise sample is [array([0.27786872], dtype=float32), -0.09716567]. 
=============================================
[2019-03-24 06:48:05,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.97004]
 [69.93796]
 [69.89921]
 [69.79789]
 [69.75996]], R is [[70.02680206]
 [69.99300385]
 [69.96067047]
 [69.9296875 ]
 [69.89997101]].
[2019-03-24 06:48:08,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4874350e-08 3.8219488e-07 2.6588727e-06 9.9999332e-01 3.5792182e-06], sum to 1.0000
[2019-03-24 06:48:08,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0317
[2019-03-24 06:48:08,426] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 78.33333333333334, 1.0, 2.0, 0.2364284270136029, 1.0, 2.0, 0.2364284270136029, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 563570.3522126428, 563570.3522126433, 167080.0437772126], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7060800.0000, 
sim time next is 7061400.0000, 
raw observation next is [23.8, 78.5, 1.0, 2.0, 0.2333788817462619, 1.0, 2.0, 0.2333788817462619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 557155.646062962, 557155.6460629625, 166441.4552347805], 
processed observation next is [1.0, 0.7391304347826086, 0.43703703703703706, 0.785, 1.0, 1.0, 0.08735581160269273, 1.0, 1.0, 0.08735581160269273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1989841593082007, 0.19898415930820088, 0.3200797216053471], 
reward next is 0.6799, 
noisyNet noise sample is [array([-1.08415], dtype=float32), -0.82885635]. 
=============================================
[2019-03-24 06:48:09,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0516546e-08 1.6254000e-07 3.9074457e-08 9.9999964e-01 1.4761319e-07], sum to 1.0000
[2019-03-24 06:48:09,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6941
[2019-03-24 06:48:09,856] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.1, 63.0, 1.0, 2.0, 0.2172545452716742, 1.0, 2.0, 0.2172545452716742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528110.4046949161, 528110.4046949166, 163293.7997213798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6902400.0000, 
sim time next is 6903000.0000, 
raw observation next is [24.95, 63.5, 1.0, 2.0, 0.215929393857342, 1.0, 2.0, 0.215929393857342, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 525378.6513125534, 525378.6513125539, 163025.0225741257], 
processed observation next is [0.0, 0.9130434782608695, 0.47962962962962963, 0.635, 1.0, 1.0, 0.06658261173493095, 1.0, 1.0, 0.06658261173493095, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18763523261162623, 0.1876352326116264, 0.3135096587963956], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.42050228], dtype=float32), -0.696627]. 
=============================================
[2019-03-24 06:48:09,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.585144]
 [69.60267 ]
 [69.574104]
 [69.55923 ]
 [69.5873  ]], R is [[69.59594727]
 [69.58596039]
 [69.57564545]
 [69.56510925]
 [69.55458069]].
[2019-03-24 06:48:18,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9416644e-06 4.9052378e-06 6.0431714e-05 9.9989641e-01 3.3420158e-05], sum to 1.0000
[2019-03-24 06:48:18,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0557
[2019-03-24 06:48:18,824] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.71666666666667, 82.33333333333334, 1.0, 2.0, 0.2318667036440794, 1.0, 2.0, 0.2318667036440794, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574753.5027468394, 574753.5027468394, 166815.4736890712], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7113000.0000, 
sim time next is 7113600.0000, 
raw observation next is [20.7, 82.0, 1.0, 2.0, 0.2075443507783577, 1.0, 2.0, 0.2075443507783577, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515088.4594402253, 515088.4594402253, 161537.4463662849], 
processed observation next is [1.0, 0.34782608695652173, 0.3222222222222222, 0.82, 1.0, 1.0, 0.05660041759328297, 1.0, 1.0, 0.05660041759328297, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18396016408579477, 0.18396016408579477, 0.3106489353197786], 
reward next is 0.6894, 
noisyNet noise sample is [array([-0.39070252], dtype=float32), 0.23170398]. 
=============================================
[2019-03-24 06:48:20,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2808755e-06 1.1963606e-04 6.9054504e-06 9.9889356e-01 9.7658543e-04], sum to 1.0000
[2019-03-24 06:48:20,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4053
[2019-03-24 06:48:20,195] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.96666666666667, 85.66666666666667, 1.0, 2.0, 0.2175362237512524, 1.0, 2.0, 0.2175362237512524, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534211.693767747, 534211.6937677475, 163530.4740516185], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7104000.0000, 
sim time next is 7104600.0000, 
raw observation next is [20.95, 85.5, 1.0, 2.0, 0.2074034140550272, 1.0, 2.0, 0.2074034140550272, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510128.6479314286, 510128.647931429, 161379.6444745359], 
processed observation next is [1.0, 0.21739130434782608, 0.33148148148148143, 0.855, 1.0, 1.0, 0.0564326357797943, 1.0, 1.0, 0.0564326357797943, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18218880283265307, 0.1821888028326532, 0.31034547014333824], 
reward next is 0.6897, 
noisyNet noise sample is [array([-0.2282261], dtype=float32), 1.142977]. 
=============================================
[2019-03-24 06:48:20,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7494286e-07 4.5880639e-05 1.0329949e-06 9.9982673e-01 1.2610518e-04], sum to 1.0000
[2019-03-24 06:48:20,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2586
[2019-03-24 06:48:20,722] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.45, 76.5, 1.0, 2.0, 0.1837525926716292, 1.0, 2.0, 0.1837525926716292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456691.2044678655, 456691.2044678659, 156563.1289343265], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7151400.0000, 
sim time next is 7152000.0000, 
raw observation next is [21.26666666666667, 77.66666666666666, 1.0, 2.0, 0.182849891728568, 1.0, 2.0, 0.182849891728568, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454585.5368975335, 454585.536897534, 156378.4675970066], 
processed observation next is [1.0, 0.782608695652174, 0.34320987654320995, 0.7766666666666666, 1.0, 1.0, 0.02720225205781904, 1.0, 1.0, 0.02720225205781904, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16235197746340482, 0.162351977463405, 0.30072782230193573], 
reward next is 0.6993, 
noisyNet noise sample is [array([-0.4610391], dtype=float32), 0.47466668]. 
=============================================
[2019-03-24 06:48:20,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.41167 ]
 [74.20658 ]
 [74.132645]
 [74.03131 ]
 [73.547745]], R is [[74.42852783]
 [74.38315582]
 [74.3380661 ]
 [74.2935257 ]
 [74.24969482]].
[2019-03-24 06:48:22,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5823239e-06 5.8908545e-04 3.5301684e-06 9.9937540e-01 2.6400319e-05], sum to 1.0000
[2019-03-24 06:48:22,189] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6099
[2019-03-24 06:48:22,193] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.182774862842905, 1.0, 2.0, 0.182774862842905, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454538.4399423928, 454538.4399423932, 156366.5682375079], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7165800.0000, 
sim time next is 7166400.0000, 
raw observation next is [19.8, 89.0, 1.0, 2.0, 0.1823612212189492, 1.0, 2.0, 0.1823612212189492, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453520.5036595218, 453520.5036595218, 156280.6299055244], 
processed observation next is [1.0, 0.9565217391304348, 0.2888888888888889, 0.89, 1.0, 1.0, 0.02662050145113001, 1.0, 1.0, 0.02662050145113001, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16197160844982922, 0.16197160844982922, 0.30053967289523925], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.06924935], dtype=float32), -1.6080873]. 
=============================================
[2019-03-24 06:48:24,474] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5266466e-07 7.1445020e-06 4.0227187e-07 9.9998224e-01 9.2903083e-06], sum to 1.0000
[2019-03-24 06:48:24,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2247
[2019-03-24 06:48:24,491] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.5, 76.33333333333333, 1.0, 2.0, 0.3912090994968183, 1.0, 2.0, 0.3912090994968183, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 951007.4520393739, 951007.4520393753, 206191.5961085076], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7210200.0000, 
sim time next is 7210800.0000, 
raw observation next is [22.4, 76.0, 1.0, 2.0, 0.3901071846078397, 1.0, 2.0, 0.3901071846078397, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 950234.4622952867, 950234.4622952872, 205944.5068006843], 
processed observation next is [1.0, 0.4782608695652174, 0.38518518518518513, 0.76, 1.0, 1.0, 0.2739371245331425, 1.0, 1.0, 0.2739371245331425, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33936945081974523, 0.3393694508197454, 0.3960471284628544], 
reward next is 0.6040, 
noisyNet noise sample is [array([0.36194614], dtype=float32), -1.3768433]. 
=============================================
[2019-03-24 06:48:38,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7354403e-06 7.5108896e-06 1.6907579e-07 9.9954766e-01 4.4090749e-04], sum to 1.0000
[2019-03-24 06:48:38,168] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4566
[2019-03-24 06:48:38,171] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 88.0, 1.0, 2.0, 0.254119611566592, 1.0, 2.0, 0.254119611566592, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599415.0542580193, 599415.0542580198, 170787.8053956336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7500600.0000, 
sim time next is 7501200.0000, 
raw observation next is [23.03333333333333, 88.66666666666667, 1.0, 2.0, 0.2528384190475303, 1.0, 2.0, 0.2528384190475303, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 596732.3222065425, 596732.322206543, 170512.1600662805], 
processed observation next is [0.0, 0.8260869565217391, 0.4086419753086419, 0.8866666666666667, 1.0, 1.0, 0.11052192743753607, 1.0, 1.0, 0.11052192743753607, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2131186865023366, 0.21311868650233676, 0.3279080001274625], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.5998225], dtype=float32), 0.44708788]. 
=============================================
[2019-03-24 06:48:39,497] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:48:39,498] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:48:39,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:39,501] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:48:39,501] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:48:39,502] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:39,503] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:48:39,504] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:39,504] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:48:39,504] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:39,506] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:39,520] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-24 06:48:39,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-24 06:48:39,550] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-24 06:48:39,609] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-24 06:48:39,609] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-24 06:48:51,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:48:51,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.872411445, 64.705645545, 1.0, 2.0, 0.1855289209923459, 1.0, 2.0, 0.1855289209923459, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459011.5791546701, 459011.5791546705, 156875.4018809127]
[2019-03-24 06:48:51,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:48:51,595] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.0536153e-07 7.8991716e-06 1.3479947e-06 9.9997509e-01 1.5116813e-05], sampled 0.675318885205601
[2019-03-24 06:49:43,647] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:49:43,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.6, 82.33333333333333, 1.0, 2.0, 0.2685269057220289, 1.0, 2.0, 0.2685269057220289, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625802.19269321, 625802.1926932104, 173754.9119091449]
[2019-03-24 06:49:43,649] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:49:43,651] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3336801e-07 5.8091391e-06 9.1457849e-07 9.9998260e-01 1.0423346e-05], sampled 0.4325469823018777
[2019-03-24 06:49:50,122] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:49:50,124] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.91666666666666, 74.0, 1.0, 2.0, 0.829959767100832, 1.0, 2.0, 0.829959767100832, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1893135.76921592, 1893135.769215919, 356289.4224539523]
[2019-03-24 06:49:50,126] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:49:50,132] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0709865e-06 2.4543211e-05 5.0380077e-06 9.9992836e-01 3.9962222e-05], sampled 0.258592570238552
[2019-03-24 06:49:50,357] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:49:50,358] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.28103068, 74.50108969, 1.0, 2.0, 0.3165052963247487, 1.0, 2.0, 0.3165052963247487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721417.0754531118, 721417.0754531123, 184468.7020458258]
[2019-03-24 06:49:50,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:49:50,362] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7799337e-07 4.9471760e-06 7.6888233e-07 9.9998498e-01 8.9970308e-06], sampled 0.3017577442859951
[2019-03-24 06:50:00,220] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:50:00,221] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.91666666666667, 86.5, 1.0, 2.0, 0.2215879130781493, 1.0, 2.0, 0.2215879130781493, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536247.5560016213, 536247.5560016218, 164147.6854124962]
[2019-03-24 06:50:00,221] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:50:00,225] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5598005e-07 9.7482462e-06 1.6923780e-06 9.9997079e-01 1.7092609e-05], sampled 0.9336499097557426
[2019-03-24 06:50:01,722] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00894065], dtype=float32), 0.004917445]
[2019-03-24 06:50:01,723] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666666, 89.33333333333334, 1.0, 2.0, 0.2907278348302323, 1.0, 2.0, 0.2907278348302323, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662636.5798110027, 662636.5798110027, 178250.6365832321]
[2019-03-24 06:50:01,726] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:50:01,727] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7061772e-07 7.4201180e-06 1.2550092e-06 9.9997699e-01 1.3912456e-05], sampled 0.5976403115799417
[2019-03-24 06:50:26,228] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7795.5476 2410646937.9079 22.0000
[2019-03-24 06:50:26,326] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.4365 2668485279.8166 68.0000
[2019-03-24 06:50:26,388] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2636 2438850519.1944 34.0000
[2019-03-24 06:50:26,400] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7263 2495466382.2204 47.0000
[2019-03-24 06:50:26,417] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465974643.4194 46.0000
[2019-03-24 06:50:27,432] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 625000, evaluation results [625000.0, 7522.436455377774, 2668485279.816584, 68.0, 7122.263554302433, 2438850519.194408, 34.0, 7795.547616998981, 2410646937.9079185, 22.0, 6906.726251468734, 2495466382.220423, 47.0, 7479.033116937025, 2465974643.419423, 46.0]
[2019-03-24 06:50:29,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1810878e-08 1.7233877e-07 9.3710505e-06 9.9998593e-01 4.5864472e-06], sum to 1.0000
[2019-03-24 06:50:29,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-24 06:50:29,190] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.41666666666666, 62.0, 1.0, 2.0, 0.2596328505161408, 1.0, 2.0, 0.2596328505161408, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609676.6512104865, 609676.6512104865, 171923.8313191254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7577400.0000, 
sim time next is 7578000.0000, 
raw observation next is [27.3, 62.0, 1.0, 2.0, 0.2567814082614762, 1.0, 2.0, 0.2567814082614762, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441992, 171329.0931738438], 
processed observation next is [0.0, 0.7391304347826086, 0.5666666666666667, 0.62, 1.0, 1.0, 0.11521596221604312, 1.0, 1.0, 0.11521596221604312, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21579624565864255, 0.21579624565864255, 0.329479025334315], 
reward next is 0.6705, 
noisyNet noise sample is [array([-0.22583286], dtype=float32), -0.60510015]. 
=============================================
[2019-03-24 06:50:29,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.345184]
 [67.2968  ]
 [67.252045]
 [67.17724 ]
 [67.110275]], R is [[67.41361237]
 [67.40885925]
 [67.40296936]
 [67.39598083]
 [67.38803101]].
[2019-03-24 06:50:31,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4962261e-06 9.7242984e-05 3.5520413e-04 9.9915612e-01 3.8992421e-04], sum to 1.0000
[2019-03-24 06:50:31,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4641
[2019-03-24 06:50:31,057] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.61666666666667, 87.16666666666666, 1.0, 2.0, 0.2411399981412557, 1.0, 2.0, 0.2411399981412557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575262.8592585712, 575262.8592585716, 168145.6247604917], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7602600.0000, 
sim time next is 7603200.0000, 
raw observation next is [22.5, 87.0, 1.0, 2.0, 0.2379280605057488, 1.0, 2.0, 0.2379280605057488, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569001.5717244351, 569001.5717244351, 167487.0866529777], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.87, 1.0, 1.0, 0.0927715006020819, 1.0, 1.0, 0.0927715006020819, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2032148470444411, 0.2032148470444411, 0.3220905512557264], 
reward next is 0.6779, 
noisyNet noise sample is [array([0.06891986], dtype=float32), 0.096842356]. 
=============================================
[2019-03-24 06:50:31,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5071841e-07 1.6782277e-06 2.6605510e-05 9.9996483e-01 6.6545304e-06], sum to 1.0000
[2019-03-24 06:50:31,646] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7079
[2019-03-24 06:50:31,652] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.73333333333333, 81.33333333333334, 1.0, 2.0, 0.1633231357204959, 1.0, 2.0, 0.1633231357204959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411568.2498900262, 411568.2498900267, 152503.0766012587], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7681800.0000, 
sim time next is 7682400.0000, 
raw observation next is [19.7, 82.0, 1.0, 2.0, 0.1643098783951006, 1.0, 2.0, 0.1643098783951006, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413802.902495349, 413802.9024953495, 152698.0278546865], 
processed observation next is [1.0, 0.9565217391304348, 0.28518518518518515, 0.82, 1.0, 1.0, 0.00513080761321501, 1.0, 1.0, 0.00513080761321501, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14778675089119608, 0.14778675089119625, 0.29365005356670476], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.79572254], dtype=float32), 1.5168507]. 
=============================================
[2019-03-24 06:50:39,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1233941e-05 5.9037382e-05 1.2941111e-04 9.9976283e-01 3.7563721e-05], sum to 1.0000
[2019-03-24 06:50:39,201] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-24 06:50:39,205] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.16666666666666, 50.33333333333334, 1.0, 2.0, 0.6621541416137023, 1.0, 2.0, 0.6621541416137023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1547391.04477921, 1547391.044779211, 291888.0338214025], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7747800.0000, 
sim time next is 7748400.0000, 
raw observation next is [29.13333333333333, 50.66666666666667, 1.0, 2.0, 0.663261462811178, 1.0, 2.0, 0.663261462811178, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1549349.866443273, 1549349.866443273, 292268.0615857979], 
processed observation next is [1.0, 0.6956521739130435, 0.6345679012345677, 0.5066666666666667, 1.0, 1.0, 0.5991207890609263, 1.0, 1.0, 0.5991207890609263, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5533392380154546, 0.5533392380154546, 0.5620539645880729], 
reward next is 0.4379, 
noisyNet noise sample is [array([-1.656758], dtype=float32), 1.2267103]. 
=============================================
[2019-03-24 06:50:42,903] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:42,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:42,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-24 06:50:43,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4840272e-07 6.9871692e-07 3.3413394e-06 9.9998820e-01 7.3186402e-06], sum to 1.0000
[2019-03-24 06:50:43,227] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1678
[2019-03-24 06:50:43,231] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.8, 36.5, 1.0, 2.0, 0.5296378486353047, 1.0, 2.0, 0.5296378486353047, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1273534.063735993, 1273534.063735994, 247511.7627663298], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7828200.0000, 
sim time next is 7828800.0000, 
raw observation next is [30.86666666666667, 36.33333333333334, 1.0, 2.0, 0.5770025432269255, 1.0, 2.0, 0.5770025432269255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1385881.997177156, 1385881.997177157, 263262.6074748607], 
processed observation next is [1.0, 0.6086956521739131, 0.6987654320987656, 0.36333333333333345, 1.0, 1.0, 0.49643159907967316, 1.0, 1.0, 0.49643159907967316, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49495785613469856, 0.49495785613469895, 0.5062742451439628], 
reward next is 0.4937, 
noisyNet noise sample is [array([0.13170105], dtype=float32), -0.67476594]. 
=============================================
[2019-03-24 06:50:44,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.66533856e-07 6.91024179e-05 2.73029468e-06 9.99819696e-01
 1.07839165e-04], sum to 1.0000
[2019-03-24 06:50:44,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6850
[2019-03-24 06:50:44,217] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.46666666666667, 71.66666666666667, 1.0, 2.0, 0.2102411559131023, 1.0, 2.0, 0.2102411559131023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513009.4173097268, 513009.4173097272, 161855.582960069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [23.38333333333333, 72.33333333333333, 1.0, 2.0, 0.2109657433313155, 1.0, 2.0, 0.2109657433313155, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514639.5537558011, 514639.5537558015, 162005.7939251364], 
processed observation next is [1.0, 1.0, 0.4216049382716048, 0.7233333333333333, 1.0, 1.0, 0.06067350396585177, 1.0, 1.0, 0.06067350396585177, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18379984062707183, 0.18379984062707197, 0.3115496037021854], 
reward next is 0.6885, 
noisyNet noise sample is [array([-0.68806756], dtype=float32), -2.4528604]. 
=============================================
[2019-03-24 06:50:44,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5872276e-08 1.3262851e-06 3.7879345e-05 9.9993706e-01 2.3662637e-05], sum to 1.0000
[2019-03-24 06:50:44,337] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0102
[2019-03-24 06:50:44,343] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 59.5, 1.0, 2.0, 0.2484618765381973, 1.0, 2.0, 0.2484618765381973, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 589346.4652164239, 589346.4652164242, 169649.969106349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7932600.0000, 
sim time next is 7933200.0000, 
raw observation next is [27.13333333333333, 60.0, 1.0, 2.0, 0.2488504492558021, 1.0, 2.0, 0.2488504492558021, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590934.9848711631, 590934.9848711631, 169765.2843273121], 
processed observation next is [1.0, 0.8260869565217391, 0.5604938271604937, 0.6, 1.0, 1.0, 0.10577434435214536, 1.0, 1.0, 0.10577434435214536, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21104820888255826, 0.21104820888255826, 0.32647170062944636], 
reward next is 0.6735, 
noisyNet noise sample is [array([-0.271434], dtype=float32), -1.605993]. 
=============================================
[2019-03-24 06:50:45,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:45,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:45,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-24 06:50:46,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:46,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:46,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-24 06:50:48,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:48,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:48,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-24 06:50:48,355] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:48,355] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:48,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-24 06:50:48,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:48,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:48,543] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-24 06:50:48,935] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:48,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:48,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-24 06:50:48,977] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:48,978] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:48,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-24 06:50:49,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,081] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,081] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-24 06:50:49,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-24 06:50:49,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-24 06:50:49,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-24 06:50:49,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,582] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-24 06:50:49,804] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:49,804] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:49,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-24 06:50:50,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:50,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:50,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-24 06:50:51,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:50:51,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:50:51,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-24 06:50:53,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5458443e-10 1.7565610e-07 1.2361042e-08 9.9999738e-01 2.4988644e-06], sum to 1.0000
[2019-03-24 06:50:53,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-24 06:50:53,551] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.16666666666667, 7.333333333333333, 1.0, 2.0, 0.2000327826846299, 1.0, 2.0, 0.2000327826846299, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513783.3507668347, 513783.3507668347, 160171.745413032], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 150000.0000, 
sim time next is 150600.0000, 
raw observation next is [35.88333333333333, 7.666666666666667, 1.0, 2.0, 0.1983601009451936, 1.0, 2.0, 0.1983601009451936, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509686.5817274615, 509686.5817274615, 159817.7295422485], 
processed observation next is [1.0, 0.7391304347826086, 0.8845679012345679, 0.07666666666666667, 1.0, 1.0, 0.04566678683951619, 1.0, 1.0, 0.04566678683951619, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18203092204552196, 0.18203092204552196, 0.30734178758124714], 
reward next is 0.6927, 
noisyNet noise sample is [array([-0.08467545], dtype=float32), 1.3863059]. 
=============================================
[2019-03-24 06:50:59,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0382420e-05 6.9330657e-05 9.1177035e-06 9.9985564e-01 5.5406636e-05], sum to 1.0000
[2019-03-24 06:50:59,349] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9662
[2019-03-24 06:50:59,354] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 13.33333333333333, 1.0, 2.0, 0.1649889725971699, 1.0, 2.0, 0.1649889725971699, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425671.7897507418, 425671.7897507418, 134678.5543395637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 175200.0000, 
sim time next is 175800.0000, 
raw observation next is [28.15, 13.66666666666667, 1.0, 2.0, 0.1637871596516539, 1.0, 2.0, 0.1637871596516539, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422570.2562954921, 422570.2562954926, 134066.730346175], 
processed observation next is [0.0, 0.0, 0.5981481481481481, 0.1366666666666667, 1.0, 1.0, 0.004508523394826083, 1.0, 1.0, 0.004508523394826083, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15091794867696148, 0.15091794867696165, 0.25782063528110577], 
reward next is 0.7422, 
noisyNet noise sample is [array([0.204322], dtype=float32), 0.930843]. 
=============================================
[2019-03-24 06:50:59,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3043527e-07 1.2133097e-05 2.8652098e-06 9.9995601e-01 2.8489283e-05], sum to 1.0000
[2019-03-24 06:50:59,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3112
[2019-03-24 06:50:59,910] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.65, 16.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404047.840884294, 404047.840884294, 130514.1221981965], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 179400.0000, 
sim time next is 180000.0000, 
raw observation next is [26.4, 17.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400337.3110635817, 400337.3110635821, 129700.6827114083], 
processed observation next is [0.0, 0.08695652173913043, 0.5333333333333333, 0.17, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14297761109413634, 0.14297761109413645, 0.24942438982963133], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4500538], dtype=float32), 0.5850866]. 
=============================================
[2019-03-24 06:50:59,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[53.55238 ]
 [53.24564 ]
 [53.660046]
 [53.411674]
 [53.016476]], R is [[53.25520325]
 [52.72265244]
 [52.19542694]
 [51.67347336]
 [51.90145874]].
[2019-03-24 06:51:00,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1165239e-04 2.2221210e-04 1.8508645e-05 9.9878234e-01 3.6525365e-04], sum to 1.0000
[2019-03-24 06:51:00,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0107
[2019-03-24 06:51:00,039] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 331972.5556729701, 331972.5556729705, 140486.5204400352], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 195600.0000, 
sim time next is 196200.0000, 
raw observation next is [21.35, 62.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 338521.8370633307, 338521.8370633307, 141575.0194176796], 
processed observation next is [0.0, 0.2608695652173913, 0.3462962962962963, 0.62, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12090065609404668, 0.12090065609404668, 0.2722596527263069], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4644473], dtype=float32), 2.813138]. 
=============================================
[2019-03-24 06:51:01,671] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3084915e-06 1.5359552e-04 4.0390264e-06 9.9976844e-01 6.5501408e-05], sum to 1.0000
[2019-03-24 06:51:01,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8564
[2019-03-24 06:51:01,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.4, 32.0, 1.0, 2.0, 0.1656052054284723, 1.0, 2.0, 0.1656052054284723, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422117.0136226637, 422117.0136226642, 153024.4835688299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 324000.0000, 
sim time next is 324600.0000, 
raw observation next is [27.3, 32.33333333333334, 1.0, 2.0, 0.1652829951018208, 1.0, 2.0, 0.1652829951018208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421341.1647495348, 421341.1647495353, 152959.2946781706], 
processed observation next is [0.0, 0.782608695652174, 0.5666666666666667, 0.3233333333333334, 1.0, 1.0, 0.006289279883119984, 1.0, 1.0, 0.006289279883119984, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15047898741054813, 0.15047898741054833, 0.29415248976571273], 
reward next is 0.7058, 
noisyNet noise sample is [array([0.9898352], dtype=float32), -0.34889063]. 
=============================================
[2019-03-24 06:51:02,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9333608e-09 2.8879109e-07 1.6776330e-06 9.9999762e-01 4.7106613e-07], sum to 1.0000
[2019-03-24 06:51:02,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6677
[2019-03-24 06:51:02,537] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.03333333333333, 36.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406544.4496806829, 406544.4496806834, 151553.2227044549], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 251400.0000, 
sim time next is 252000.0000, 
raw observation next is [25.7, 37.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402092.6995052445, 402092.6995052445, 150855.426423846], 
processed observation next is [0.0, 0.9565217391304348, 0.5074074074074074, 0.37, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1436045355375873, 0.1436045355375873, 0.2901065892766269], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2510568], dtype=float32), 0.15419392]. 
=============================================
[2019-03-24 06:51:02,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.561615]
 [67.64663 ]
 [67.724884]
 [67.78    ]
 [67.84205 ]], R is [[66.83153534]
 [66.16322327]
 [66.20915222]
 [66.25401306]
 [66.29779816]].
[2019-03-24 06:51:05,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6618947e-05 5.0042354e-04 5.0857343e-05 9.9930215e-01 4.9973129e-05], sum to 1.0000
[2019-03-24 06:51:05,284] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8441
[2019-03-24 06:51:05,291] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 43.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337785.8239663325, 337785.8239663325, 125161.252198686], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 282600.0000, 
sim time next is 283200.0000, 
raw observation next is [21.9, 42.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 341007.5687475059, 341007.5687475064, 126053.1129559439], 
processed observation next is [0.0, 0.2608695652173913, 0.36666666666666664, 0.42, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12178841740982353, 0.12178841740982373, 0.24240983260758442], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.8361933], dtype=float32), -2.05554]. 
=============================================
[2019-03-24 06:51:05,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3426990e-05 5.0957297e-04 1.0714183e-04 9.9905473e-01 2.8513203e-04], sum to 1.0000
[2019-03-24 06:51:05,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2506
[2019-03-24 06:51:05,826] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 51.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 330132.5714092806, 330132.5714092811, 124966.27014312], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 270000.0000, 
sim time next is 270600.0000, 
raw observation next is [20.33333333333333, 51.16666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 328381.9062604767, 328381.9062604771, 124399.2459755515], 
processed observation next is [0.0, 0.13043478260869565, 0.3086419753086418, 0.5116666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11727925223588453, 0.11727925223588467, 0.2392293191837529], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43580496], dtype=float32), -0.18199904]. 
=============================================
[2019-03-24 06:51:06,785] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.05159963e-03 1.89073238e-04 1.49308935e-05 9.98554885e-01
 1.89497456e-04], sum to 1.0000
[2019-03-24 06:51:06,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1791
[2019-03-24 06:51:06,799] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 33.33333333333333, 1.0, 2.0, 0.1633449952190278, 1.0, 2.0, 0.1633449952190278, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 416519.2511959677, 416519.2511959682, 152566.9655119463], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 326400.0000, 
sim time next is 327000.0000, 
raw observation next is [26.9, 33.66666666666667, 1.0, 2.0, 0.1627619659667164, 1.0, 2.0, 0.1627619659667164, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415075.1599131557, 415075.1599131557, 152449.2420835832], 
processed observation next is [0.0, 0.782608695652174, 0.5518518518518518, 0.3366666666666667, 1.0, 1.0, 0.0032880547222814364, 1.0, 1.0, 0.0032880547222814364, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14824112854041274, 0.14824112854041274, 0.29317161939150616], 
reward next is 0.7068, 
noisyNet noise sample is [array([-0.37346873], dtype=float32), -1.1333258]. 
=============================================
[2019-03-24 06:51:06,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[42.184917]
 [41.883427]
 [41.945087]
 [42.91549 ]
 [42.049217]], R is [[42.55960846]
 [42.84061432]
 [43.11859894]
 [43.39357758]
 [43.6654892 ]].
[2019-03-24 06:51:16,185] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 06:51:16,187] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:51:16,189] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:51:16,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:16,191] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:51:16,192] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:51:16,192] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:16,197] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:51:16,198] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:16,200] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:16,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:16,213] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-24 06:51:16,213] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-24 06:51:16,214] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-24 06:51:16,310] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-24 06:51:16,337] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-24 06:51:51,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00882256], dtype=float32), 0.0051456536]
[2019-03-24 06:51:51,828] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.89661002666667, 46.51534889833334, 1.0, 2.0, 0.4674855239919501, 1.0, 2.0, 0.4674855239919501, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1081603.696808661, 1081603.696808661, 226256.7200649171]
[2019-03-24 06:51:51,828] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:51:51,831] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.8317376e-06 2.9297687e-05 7.8691237e-06 9.9992239e-01 3.6615162e-05], sampled 0.07802565638417336
[2019-03-24 06:51:53,331] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00882256], dtype=float32), 0.0051456536]
[2019-03-24 06:51:53,332] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.2864188668789183, 1.0, 2.0, 0.2864188668789183, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 662202.7005069316, 662202.7005069321, 177696.2422320624]
[2019-03-24 06:51:53,333] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:51:53,336] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0096423e-06 9.7193870e-06 2.2503227e-06 9.9997473e-01 1.2333932e-05], sampled 0.17264802797683831
[2019-03-24 06:51:59,473] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00882256], dtype=float32), 0.0051456536]
[2019-03-24 06:51:59,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 95.0, 1.0, 2.0, 0.3126713350376271, 1.0, 2.0, 0.3126713350376271, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717560.3596863016, 717560.3596863016, 183770.0693534624]
[2019-03-24 06:51:59,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:51:59,481] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.01641433e-06 9.61610294e-06 2.25757435e-06 9.99974370e-01
 1.27481635e-05], sampled 0.5492876929373909
[2019-03-24 06:53:01,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00882256], dtype=float32), 0.0051456536]
[2019-03-24 06:53:01,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 368809.1769250394, 368809.1769250399, 146342.3989913297]
[2019-03-24 06:53:01,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:53:01,007] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1408452e-06 3.1772117e-05 8.4627891e-06 9.9991870e-01 3.6808247e-05], sampled 0.9343199072332445
[2019-03-24 06:53:03,899] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8901 2410725515.2747 22.0000
[2019-03-24 06:53:04,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0359 2668567512.6863 68.0000
[2019-03-24 06:53:04,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.4156 2465949042.5326 46.0000
[2019-03-24 06:53:04,471] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 06:53:04,529] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2589 2438872630.9547 34.0000
[2019-03-24 06:53:05,545] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 650000, evaluation results [650000.0, 7523.03586582998, 2668567512.6862664, 68.0, 7122.258924911334, 2438872630.954681, 34.0, 7796.890068421621, 2410725515.274654, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.415603352539, 2465949042.532596, 46.0]
[2019-03-24 06:53:07,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1329699e-08 4.4328704e-07 2.7608630e-07 9.9999905e-01 2.0283336e-07], sum to 1.0000
[2019-03-24 06:53:07,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6364
[2019-03-24 06:53:07,520] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.1, 56.66666666666667, 1.0, 2.0, 0.2640572231993409, 1.0, 2.0, 0.2640572231993409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 659281.6241262534, 659281.6241262539, 174251.173571557], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 547800.0000, 
sim time next is 548400.0000, 
raw observation next is [25.4, 52.33333333333334, 1.0, 2.0, 0.3898272881027562, 1.0, 2.0, 0.3898272881027562, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 964964.4879027349, 964964.4879027352, 206283.651034396], 
processed observation next is [1.0, 0.34782608695652173, 0.49629629629629624, 0.5233333333333334, 1.0, 1.0, 0.2736039144080431, 1.0, 1.0, 0.2736039144080431, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34463017425097675, 0.34463017425097686, 0.3966993289123], 
reward next is 0.6033, 
noisyNet noise sample is [array([-0.6385593], dtype=float32), 1.30074]. 
=============================================
[2019-03-24 06:53:07,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1955136e-07 1.8753950e-05 6.5604013e-07 9.9987555e-01 1.0426192e-04], sum to 1.0000
[2019-03-24 06:53:07,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6039
[2019-03-24 06:53:07,895] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.1, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378921.0817063411, 378921.0817063411, 147862.171270716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 538800.0000, 
sim time next is 539400.0000, 
raw observation next is [20.3, 73.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380948.0458494136, 380948.0458494136, 148198.0724118507], 
processed observation next is [1.0, 0.21739130434782608, 0.3074074074074074, 0.73, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13605287351764772, 0.13605287351764772, 0.2849962930997129], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3983703], dtype=float32), -0.65989304]. 
=============================================
[2019-03-24 06:53:16,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9790686e-08 1.8170398e-06 3.5845619e-07 9.9999607e-01 1.6584603e-06], sum to 1.0000
[2019-03-24 06:53:16,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7914
[2019-03-24 06:53:16,868] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.03333333333333, 53.33333333333333, 1.0, 2.0, 0.4515295830025075, 1.0, 2.0, 0.4515295830025075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1112165.242190444, 1112165.242190444, 223979.5038632738], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 722400.0000, 
sim time next is 723000.0000, 
raw observation next is [25.16666666666667, 53.16666666666667, 1.0, 2.0, 0.4328775341215912, 1.0, 2.0, 0.4328775341215912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1066372.334678714, 1066372.334678714, 218455.8318107212], 
processed observation next is [1.0, 0.34782608695652173, 0.4876543209876545, 0.5316666666666667, 1.0, 1.0, 0.3248542072876086, 1.0, 1.0, 0.3248542072876086, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.38084726238525496, 0.38084726238525496, 0.4201073688667715], 
reward next is 0.5799, 
noisyNet noise sample is [array([-0.28866622], dtype=float32), -1.2802024]. 
=============================================
[2019-03-24 06:53:16,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.37428 ]
 [61.028297]
 [61.41905 ]
 [62.01997 ]
 [62.226307]], R is [[61.89104462]
 [61.84140396]
 [61.75402832]
 [61.68828583]
 [61.70131302]].
[2019-03-24 06:53:20,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6628950e-08 2.2406237e-05 5.3318411e-07 9.9997509e-01 1.9491463e-06], sum to 1.0000
[2019-03-24 06:53:20,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9383
[2019-03-24 06:53:20,057] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 65.5, 1.0, 2.0, 0.1766833608515386, 1.0, 2.0, 0.1766833608515386, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441907.3014585593, 441907.3014585593, 155166.3489396679], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 894600.0000, 
sim time next is 895200.0000, 
raw observation next is [22.73333333333333, 65.33333333333333, 1.0, 2.0, 0.1788686108294333, 1.0, 2.0, 0.1788686108294333, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446791.7393445487, 446791.7393445491, 155604.9438243966], 
processed observation next is [0.0, 0.34782608695652173, 0.39753086419753075, 0.6533333333333333, 1.0, 1.0, 0.022462631939801556, 1.0, 1.0, 0.022462631939801556, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15956847833733884, 0.15956847833733895, 0.2992402765853781], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.31334785], dtype=float32), -0.72655135]. 
=============================================
[2019-03-24 06:53:21,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.12543184e-07 1.57800127e-06 7.27519989e-07 9.99996781e-01
 8.08455297e-07], sum to 1.0000
[2019-03-24 06:53:21,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5460
[2019-03-24 06:53:21,297] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.03333333333333, 34.0, 1.0, 2.0, 0.166754226462714, 1.0, 2.0, 0.166754226462714, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421216.9992084483, 421216.9992084483, 153214.8659248664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 769200.0000, 
sim time next is 769800.0000, 
raw observation next is [27.86666666666666, 34.5, 1.0, 2.0, 0.1657431239813753, 1.0, 2.0, 0.1657431239813753, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418785.4100805492, 418785.4100805497, 153011.3430781446], 
processed observation next is [1.0, 0.9130434782608695, 0.587654320987654, 0.345, 1.0, 1.0, 0.006837052358780123, 1.0, 1.0, 0.006837052358780123, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14956621788591043, 0.14956621788591062, 0.29425258284258576], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.2805541], dtype=float32), -0.12823081]. 
=============================================
[2019-03-24 06:53:23,412] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5450632e-07 4.5765418e-07 2.2671887e-07 9.9999785e-01 1.2008317e-06], sum to 1.0000
[2019-03-24 06:53:23,419] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4381
[2019-03-24 06:53:23,423] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.1, 65.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397449.5981047471, 397449.5981047476, 150522.6854045383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 881400.0000, 
sim time next is 882000.0000, 
raw observation next is [21.0, 65.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391163.1675133269, 391163.1675133273, 149521.456785761], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333333, 0.65, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1397011312547596, 0.13970113125475975, 0.28754126304954036], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5933915], dtype=float32), 0.6331033]. 
=============================================
[2019-03-24 06:53:23,446] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.82054]
 [65.91047]
 [65.99607]
 [66.04804]
 [66.12025]], R is [[65.10710907]
 [64.45603943]
 [63.81148148]
 [63.88079071]
 [63.94850159]].
[2019-03-24 06:53:27,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.05401792e-04 1.53282221e-04 1.26449886e-05 9.99715984e-01
 1.26214945e-05], sum to 1.0000
[2019-03-24 06:53:27,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-24 06:53:27,880] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 60.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 342586.881051095, 342586.881051095, 141791.5597638137], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 967200.0000, 
sim time next is 967800.0000, 
raw observation next is [20.45, 60.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 337120.2809306571, 337120.2809306576, 140976.4912042532], 
processed observation next is [1.0, 0.17391304347826086, 0.31296296296296294, 0.6083333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12040010033237754, 0.1204001003323777, 0.27110863693125614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75659716], dtype=float32), 1.2349219]. 
=============================================
[2019-03-24 06:53:28,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4027286e-07 1.9433110e-05 2.6261055e-06 9.9997365e-01 3.9764045e-06], sum to 1.0000
[2019-03-24 06:53:28,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9557
[2019-03-24 06:53:28,362] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.2, 72.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397986.9881579591, 397986.9881579595, 150632.5096910427], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1054800.0000, 
sim time next is 1055400.0000, 
raw observation next is [20.33333333333333, 71.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 384271.6874596584, 384271.6874596589, 148604.0118459212], 
processed observation next is [1.0, 0.21739130434782608, 0.3086419753086418, 0.7133333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13723988837844944, 0.1372398883784496, 0.28577694585754077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.94824296], dtype=float32), -0.3380533]. 
=============================================
[2019-03-24 06:53:28,455] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.8192046e-08 1.3459940e-06 2.2227252e-06 9.9999285e-01 3.5399405e-06], sum to 1.0000
[2019-03-24 06:53:28,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8851
[2019-03-24 06:53:28,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.13333333333333, 58.0, 1.0, 2.0, 0.2649238485794211, 1.0, 2.0, 0.2649238485794211, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 665339.5171114596, 665339.5171114601, 174526.1845973516], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 981600.0000, 
sim time next is 982200.0000, 
raw observation next is [23.26666666666667, 58.0, 1.0, 2.0, 0.2721432757842354, 1.0, 2.0, 0.2721432757842354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682382.1661886979, 682382.1661886979, 176207.9425649587], 
processed observation next is [1.0, 0.34782608695652173, 0.41728395061728407, 0.58, 1.0, 1.0, 0.1335038997431374, 1.0, 1.0, 0.1335038997431374, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24370791649596354, 0.24370791649596354, 0.33886142800953595], 
reward next is 0.6611, 
noisyNet noise sample is [array([-0.71748424], dtype=float32), 1.2693939]. 
=============================================
[2019-03-24 06:53:30,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8611168e-06 1.2430487e-03 1.0293832e-05 9.9868304e-01 5.8784954e-05], sum to 1.0000
[2019-03-24 06:53:30,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4626
[2019-03-24 06:53:30,134] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.53333333333333, 52.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 357700.4883364897, 357700.4883364902, 144312.9724391848], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 951600.0000, 
sim time next is 952200.0000, 
raw observation next is [22.4, 53.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 356135.8522003012, 356135.8522003017, 144050.69446514], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.53, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12719137578582185, 0.12719137578582204, 0.27702056627911537], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6328439], dtype=float32), 0.38702747]. 
=============================================
[2019-03-24 06:53:36,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8613333e-05 2.0764415e-05 3.5566289e-05 9.9983561e-01 8.9364701e-05], sum to 1.0000
[2019-03-24 06:53:36,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1102
[2019-03-24 06:53:36,196] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 74.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 359990.1927918905, 359990.192791891, 144651.6053084526], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1125000.0000, 
sim time next is 1125600.0000, 
raw observation next is [19.2, 74.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 359398.8498015938, 359398.8498015942, 144553.5776004814], 
processed observation next is [1.0, 0.0, 0.26666666666666666, 0.7433333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1283567320719978, 0.12835673207199794, 0.277987649231695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81908953], dtype=float32), 0.83540785]. 
=============================================
[2019-03-24 06:53:38,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1008735e-04 5.6761874e-05 4.3025455e-05 9.9909914e-01 5.9094286e-04], sum to 1.0000
[2019-03-24 06:53:38,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4184
[2019-03-24 06:53:38,618] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.78333333333333, 76.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 358684.1325584982, 358684.1325584986, 144375.1586090275], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.86666666666667, 76.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 349015.4611896204, 349015.4611896209, 142961.9359409213], 
processed observation next is [1.0, 0.21739130434782608, 0.25432098765432115, 0.76, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.124648378996293, 0.12464837899629318, 0.27492679988638713], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.96225595], dtype=float32), -0.92096037]. 
=============================================
[2019-03-24 06:53:44,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0805088e-06 1.6531611e-05 3.8880198e-06 9.9980408e-01 1.7046128e-04], sum to 1.0000
[2019-03-24 06:53:44,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4168
[2019-03-24 06:53:44,022] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 62.0, 1.0, 2.0, 0.2079923547626867, 1.0, 2.0, 0.2079923547626867, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507987.2172869714, 507987.2172869719, 161391.7759339587], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1278000.0000, 
sim time next is 1278600.0000, 
raw observation next is [24.88333333333334, 62.83333333333334, 1.0, 2.0, 0.2084064174482531, 1.0, 2.0, 0.2084064174482531, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508812.4892308354, 508812.4892308358, 161473.738571559], 
processed observation next is [1.0, 0.8260869565217391, 0.47716049382716075, 0.6283333333333334, 1.0, 1.0, 0.05762668743839656, 1.0, 1.0, 0.05762668743839656, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1817187461538698, 0.18171874615386993, 0.3105264203299211], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.25309932], dtype=float32), 0.48431835]. 
=============================================
[2019-03-24 06:53:47,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1301059e-07 9.5981804e-08 2.3416040e-05 9.9996567e-01 1.0524835e-05], sum to 1.0000
[2019-03-24 06:53:47,190] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4305
[2019-03-24 06:53:47,196] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.1, 56.33333333333333, 1.0, 2.0, 0.3944658624519662, 1.0, 2.0, 0.3944658624519662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 967187.4980523477, 967187.4980523481, 207339.3426372161], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [25.35, 54.66666666666667, 1.0, 2.0, 0.3919396664413367, 1.0, 2.0, 0.3919396664413367, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 961780.0680658388, 961780.0680658402, 206657.0173337643], 
processed observation next is [1.0, 0.391304347826087, 0.4944444444444445, 0.5466666666666667, 1.0, 1.0, 0.27611865052540085, 1.0, 1.0, 0.27611865052540085, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3434928814520853, 0.3434928814520858, 0.3974173410264698], 
reward next is 0.6026, 
noisyNet noise sample is [array([-1.1470608], dtype=float32), 1.304071]. 
=============================================
[2019-03-24 06:53:49,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9263325e-08 2.7413482e-06 7.8730791e-06 9.9998903e-01 2.1737623e-07], sum to 1.0000
[2019-03-24 06:53:49,642] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-24 06:53:49,648] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 41.5, 1.0, 2.0, 0.4781390140392947, 1.0, 2.0, 0.4781390140392947, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1174981.980514585, 1174981.980514584, 232007.0472530476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1337400.0000, 
sim time next is 1338000.0000, 
raw observation next is [28.0, 41.0, 1.0, 2.0, 0.4835193407749394, 1.0, 2.0, 0.4835193407749394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1186930.959202104, 1186930.959202105, 233639.8980994501], 
processed observation next is [1.0, 0.4782608695652174, 0.5925925925925926, 0.41, 1.0, 1.0, 0.3851420723511183, 1.0, 1.0, 0.3851420723511183, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42390391400075145, 0.4239039140007518, 0.44930749634509637], 
reward next is 0.5507, 
noisyNet noise sample is [array([-0.6955389], dtype=float32), 0.2878796]. 
=============================================
[2019-03-24 06:53:49,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.71945 ]
 [65.86857 ]
 [66.12981 ]
 [66.527855]
 [66.589066]], R is [[65.63516998]
 [65.53265381]
 [65.43439484]
 [65.34284973]
 [65.2937851 ]].
[2019-03-24 06:53:54,257] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:53:54,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:53:54,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:54,263] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:53:54,263] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:54,264] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:53:54,264] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:53:54,265] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:53:54,265] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:54,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:54,269] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:54,289] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-24 06:53:54,289] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-24 06:53:54,348] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-24 06:53:54,350] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-24 06:53:54,414] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-24 06:54:52,257] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:54:52,257] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.26666666666667, 70.0, 1.0, 2.0, 0.2592485311339247, 1.0, 2.0, 0.2592485311339247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 607300.8770500822, 607300.8770500827, 171770.2792838079]
[2019-03-24 06:54:52,258] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:54:52,261] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3338216e-07 1.4924375e-06 2.3386941e-07 9.9999642e-01 1.6124544e-06], sampled 0.9375145704555136
[2019-03-24 06:55:11,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:55:11,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 60.33333333333334, 1.0, 2.0, 0.2124493282402474, 1.0, 2.0, 0.2124493282402474, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517025.6151074703, 517025.6151074703, 162281.5060271704]
[2019-03-24 06:55:11,224] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:55:11,229] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0838028e-07 5.4774705e-06 1.0265463e-06 9.9998760e-01 5.2478358e-06], sampled 0.3278316180307703
[2019-03-24 06:55:19,104] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:55:19,105] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.33333333333334, 94.0, 1.0, 2.0, 0.2412613615778189, 1.0, 2.0, 0.2412613615778189, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570287.8082722353, 570287.8082722353, 167952.6436786607]
[2019-03-24 06:55:19,106] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:55:19,110] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5842296e-07 1.7154792e-06 2.7405920e-07 9.9999595e-01 1.8814226e-06], sampled 0.8945215915528862
[2019-03-24 06:55:22,770] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:55:22,771] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.75, 51.5, 1.0, 2.0, 0.556393936788536, 1.0, 2.0, 0.556393936788536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1268652.845449688, 1268652.845449689, 253373.0368358407]
[2019-03-24 06:55:22,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:55:22,775] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1416166e-07 1.3182332e-06 2.0453122e-07 9.9999690e-01 1.4020067e-06], sampled 0.13988446949475297
[2019-03-24 06:55:33,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:55:33,128] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 39.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401618.0916323743, 401618.0916323743, 151610.3531897162]
[2019-03-24 06:55:33,130] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:55:33,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4718914e-07 3.3940489e-06 5.9199272e-07 9.9999213e-01 3.5325052e-06], sampled 0.6818289503498371
[2019-03-24 06:55:33,161] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904664], dtype=float32), 0.0053793406]
[2019-03-24 06:55:33,161] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.77582508333333, 95.93670799333333, 1.0, 2.0, 0.2101209624207811, 1.0, 2.0, 0.2101209624207811, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509427.1104227037, 509427.1104227041, 161715.4732693485]
[2019-03-24 06:55:33,162] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:55:33,164] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8710656e-07 2.8495283e-06 4.8401409e-07 9.9999356e-01 2.8820070e-06], sampled 0.6508860616755666
[2019-03-24 06:55:38,388] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8575 2410719508.4490 22.0000
[2019-03-24 06:55:38,596] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 06:55:38,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854707.0827 34.0000
[2019-03-24 06:55:38,724] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7284 2495420228.1706 47.0000
[2019-03-24 06:55:38,735] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.0014 2465964291.6208 46.0000
[2019-03-24 06:55:39,753] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 675000, evaluation results [675000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438854707.082678, 34.0, 7796.8574532743105, 2410719508.4489765, 22.0, 6906.728428702432, 2495420228.170619, 47.0, 7477.001371473447, 2465964291.620775, 46.0]
[2019-03-24 06:55:51,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9955457e-04 3.2925727e-05 7.1398908e-06 9.9898618e-01 3.7430160e-04], sum to 1.0000
[2019-03-24 06:55:51,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6415
[2019-03-24 06:55:51,025] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 69.0, 1.0, 2.0, 0.4304933948423378, 1.0, 2.0, 0.4304933948423378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1044295.612135208, 1044295.612135208, 217291.6929298351], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1699200.0000, 
sim time next is 1699800.0000, 
raw observation next is [23.65, 68.83333333333333, 1.0, 2.0, 0.4096091476548824, 1.0, 2.0, 0.4096091476548824, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994781.2118063004, 994781.2118063004, 211325.3972978488], 
processed observation next is [1.0, 0.6956521739130435, 0.4314814814814814, 0.6883333333333332, 1.0, 1.0, 0.2971537472081933, 1.0, 1.0, 0.2971537472081933, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35527900421653585, 0.35527900421653585, 0.4063949948035554], 
reward next is 0.5936, 
noisyNet noise sample is [array([-0.0874347], dtype=float32), 0.060153034]. 
=============================================
[2019-03-24 06:55:55,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0562703e-07 1.0778673e-06 6.7490333e-07 9.9999428e-01 3.7464874e-06], sum to 1.0000
[2019-03-24 06:55:55,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6076
[2019-03-24 06:55:55,505] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 77.0, 1.0, 2.0, 0.2192910019004724, 1.0, 2.0, 0.2192910019004724, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531346.4804360439, 531346.4804360439, 163673.7044967184], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1711800.0000, 
sim time next is 1712400.0000, 
raw observation next is [23.1, 77.66666666666667, 1.0, 2.0, 0.2198638837657984, 1.0, 2.0, 0.2198638837657984, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532347.2901269749, 532347.2901269754, 163783.7810980862], 
processed observation next is [1.0, 0.8260869565217391, 0.41111111111111115, 0.7766666666666667, 1.0, 1.0, 0.07126652829261715, 1.0, 1.0, 0.07126652829261715, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19012403218820534, 0.1901240321882055, 0.31496880980401193], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.2277921], dtype=float32), -0.6286229]. 
=============================================
[2019-03-24 06:55:55,781] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8926885e-08 2.8249135e-06 2.0402192e-06 9.9999046e-01 4.6544842e-06], sum to 1.0000
[2019-03-24 06:55:55,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9097090e-05 8.5250585e-06 1.9931715e-05 9.9990642e-01 4.6019184e-05], sum to 1.0000
[2019-03-24 06:55:55,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2937
[2019-03-24 06:55:55,797] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 64.33333333333334, 1.0, 2.0, 0.4897500393203457, 1.0, 2.0, 0.4897500393203457, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1168725.057566071, 1168725.057566072, 234493.6764139544], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1776000.0000, 
sim time next is 1776600.0000, 
raw observation next is [25.6, 64.0, 1.0, 2.0, 0.5228904237645151, 1.0, 2.0, 0.5228904237645151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1245261.637362061, 1245261.637362061, 244883.4931482836], 
processed observation next is [1.0, 0.5652173913043478, 0.5037037037037038, 0.64, 1.0, 1.0, 0.43201240924347034, 1.0, 1.0, 0.43201240924347034, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4447362990578789, 0.4447362990578789, 0.47092979451593], 
reward next is 0.5291, 
noisyNet noise sample is [array([0.23381722], dtype=float32), -0.65783364]. 
=============================================
[2019-03-24 06:55:55,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7544
[2019-03-24 06:55:55,806] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 65.5, 1.0, 2.0, 0.6476518364408584, 1.0, 2.0, 0.6476518364408584, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1496035.492899308, 1496035.492899308, 285767.1220378362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1786200.0000, 
sim time next is 1786800.0000, 
raw observation next is [26.8, 65.0, 1.0, 2.0, 0.6101190805491641, 1.0, 2.0, 0.6101190805491641, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1414824.446673609, 1414824.44667361, 272679.2517031364], 
processed observation next is [1.0, 0.6956521739130435, 0.5481481481481482, 0.65, 1.0, 1.0, 0.5358560482728144, 1.0, 1.0, 0.5358560482728144, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5052944452405747, 0.505294445240575, 0.5243831763521855], 
reward next is 0.4756, 
noisyNet noise sample is [array([0.19164144], dtype=float32), 0.38985625]. 
=============================================
[2019-03-24 06:55:56,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5665362e-07 3.6183056e-07 2.6011682e-08 9.9999774e-01 1.3097570e-06], sum to 1.0000
[2019-03-24 06:55:56,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6573
[2019-03-24 06:55:56,488] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 65.0, 1.0, 2.0, 0.4463347676401531, 1.0, 2.0, 0.4463347676401531, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1065743.863576788, 1065743.863576788, 221364.1438125536], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1774800.0000, 
sim time next is 1775400.0000, 
raw observation next is [25.46666666666667, 64.66666666666667, 1.0, 2.0, 0.4057787747254277, 1.0, 2.0, 0.4057787747254277, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 969577.7461778058, 969577.7461778063, 209699.5266054978], 
processed observation next is [1.0, 0.5652173913043478, 0.4987654320987655, 0.6466666666666667, 1.0, 1.0, 0.292593779435033, 1.0, 1.0, 0.292593779435033, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3462777664920735, 0.34627776649207365, 0.4032683203951881], 
reward next is 0.5967, 
noisyNet noise sample is [array([0.6862755], dtype=float32), -1.054654]. 
=============================================
[2019-03-24 06:55:58,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4163700e-07 3.0231267e-06 5.9202398e-07 9.9999535e-01 7.9558936e-07], sum to 1.0000
[2019-03-24 06:55:58,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1637
[2019-03-24 06:55:58,361] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 91.16666666666667, 1.0, 2.0, 0.2113488812235018, 1.0, 2.0, 0.2113488812235018, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515123.395589265, 515123.395589265, 162072.5442616495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1894200.0000, 
sim time next is 1894800.0000, 
raw observation next is [20.9, 91.33333333333334, 1.0, 2.0, 0.2127234858528262, 1.0, 2.0, 0.2127234858528262, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518296.6349332784, 518296.6349332784, 162360.8779940363], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9133333333333334, 1.0, 1.0, 0.06276605458669784, 1.0, 1.0, 0.06276605458669784, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18510594104759942, 0.18510594104759942, 0.312232457680839], 
reward next is 0.6878, 
noisyNet noise sample is [array([0.505392], dtype=float32), 1.1985047]. 
=============================================
[2019-03-24 06:56:05,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4725467e-08 3.3402563e-07 1.1563230e-07 9.9998879e-01 1.0778126e-05], sum to 1.0000
[2019-03-24 06:56:05,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-24 06:56:05,093] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.11666666666667, 89.66666666666667, 1.0, 2.0, 0.231494757958125, 1.0, 2.0, 0.231494757958125, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554713.3335544587, 554713.333554459, 166108.9765891244], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2099400.0000, 
sim time next is 2100000.0000, 
raw observation next is [22.23333333333333, 89.33333333333334, 1.0, 2.0, 0.2330099895560109, 1.0, 2.0, 0.2330099895560109, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557604.3524556154, 557604.3524556154, 166413.5025267944], 
processed observation next is [0.0, 0.30434782608695654, 0.37901234567901226, 0.8933333333333334, 1.0, 1.0, 0.08691665423334631, 1.0, 1.0, 0.08691665423334631, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19914441159129123, 0.19914441159129123, 0.3200259663976815], 
reward next is 0.6800, 
noisyNet noise sample is [array([1.3072321], dtype=float32), 0.28756893]. 
=============================================
[2019-03-24 06:56:05,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.72515 ]
 [66.705666]
 [66.67236 ]
 [66.665344]
 [66.681076]], R is [[66.76931763]
 [66.78218079]
 [66.79553223]
 [66.80951691]
 [66.82420349]].
[2019-03-24 06:56:05,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2147679e-08 1.1393008e-06 1.8834820e-08 9.9999142e-01 7.4440109e-06], sum to 1.0000
[2019-03-24 06:56:05,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0731
[2019-03-24 06:56:05,476] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 91.0, 1.0, 2.0, 0.2100657427224897, 1.0, 2.0, 0.2100657427224897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512096.7450176506, 512096.7450176506, 161801.8118731399], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1893600.0000, 
sim time next is 1894200.0000, 
raw observation next is [20.9, 91.16666666666667, 1.0, 2.0, 0.2113488812235018, 1.0, 2.0, 0.2113488812235018, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515123.395589265, 515123.395589265, 162072.5442616495], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9116666666666667, 1.0, 1.0, 0.06112962050416879, 1.0, 1.0, 0.06112962050416879, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18397264128188034, 0.18397264128188034, 0.31167796973394135], 
reward next is 0.6883, 
noisyNet noise sample is [array([0.16086052], dtype=float32), 1.8413258]. 
=============================================
[2019-03-24 06:56:22,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6714002e-06 3.5626101e-05 2.0570637e-06 9.9993479e-01 1.7895794e-05], sum to 1.0000
[2019-03-24 06:56:22,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3891
[2019-03-24 06:56:22,945] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.36666666666667, 41.0, 1.0, 2.0, 0.2039271724675269, 1.0, 2.0, 0.2039271724675269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.2374046114, 498394.2374046114, 160540.7926174974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2398800.0000, 
sim time next is 2399400.0000, 
raw observation next is [29.2, 41.5, 1.0, 2.0, 0.2026928573449139, 1.0, 2.0, 0.2026928573449139, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495609.8301924938, 495609.8301924938, 160287.8167043847], 
processed observation next is [1.0, 0.782608695652174, 0.637037037037037, 0.415, 1.0, 1.0, 0.05082483017251655, 1.0, 1.0, 0.05082483017251655, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1770035107830335, 0.1770035107830335, 0.30824580135458596], 
reward next is 0.6918, 
noisyNet noise sample is [array([1.6240919], dtype=float32), 1.2198135]. 
=============================================
[2019-03-24 06:56:27,831] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 06:56:27,834] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:56:27,835] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:27,836] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:56:27,837] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:27,838] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:56:27,840] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:56:27,842] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:56:27,841] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:27,842] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:27,844] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:27,850] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-24 06:56:27,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-24 06:56:27,912] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-24 06:56:27,945] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-24 06:56:27,987] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-24 06:56:44,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:56:44,007] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.04166894, 85.93433897, 1.0, 2.0, 0.186065970852002, 1.0, 2.0, 0.186065970852002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 474052.1521333189, 474052.1521333194, 157248.0027750942]
[2019-03-24 06:56:44,007] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:56:44,010] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0204532e-07 1.8589252e-06 5.1217847e-07 9.9999309e-01 4.0435575e-06], sampled 0.18803088044763294
[2019-03-24 06:56:49,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:56:49,907] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 30.0, 1.0, 2.0, 0.2114992787003887, 1.0, 2.0, 0.2114992787003887, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514080.3190623773, 514080.3190623778, 162056.1563373542]
[2019-03-24 06:56:49,910] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:56:49,913] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2443965e-07 6.5326697e-07 1.6162939e-07 9.9999774e-01 1.4449502e-06], sampled 0.592349345263643
[2019-03-24 06:56:55,301] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:56:55,301] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.599587735, 87.64912957499999, 1.0, 2.0, 0.2000822598560034, 1.0, 2.0, 0.2000822598560034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487249.8276855718, 487249.8276855718, 159671.0698938991]
[2019-03-24 06:56:55,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:56:55,305] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9468739e-07 9.6871861e-07 2.4832860e-07 9.9999642e-01 2.1944713e-06], sampled 0.3969327786636685
[2019-03-24 06:57:08,925] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:57:08,927] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.04091181, 78.66338707, 1.0, 2.0, 0.3222858848571826, 1.0, 2.0, 0.3222858848571826, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734599.2038950127, 734599.2038950127, 185894.9715267758]
[2019-03-24 06:57:08,929] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:57:08,932] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0540834e-07 5.6831146e-07 1.3802726e-07 9.9999797e-01 1.2414744e-06], sampled 0.8487948240100729
[2019-03-24 06:57:23,111] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:57:23,113] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.16666666666667, 66.16666666666666, 1.0, 2.0, 0.3794854111232666, 1.0, 2.0, 0.3794854111232666, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 865049.9609580856, 865049.9609580851, 200630.5792130247]
[2019-03-24 06:57:23,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:57:23,117] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4828671e-08 5.1038131e-07 1.2431966e-07 9.9999809e-01 1.1345486e-06], sampled 0.06226546690296486
[2019-03-24 06:58:03,924] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904989], dtype=float32), 0.0054982114]
[2019-03-24 06:58:03,925] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.299941628072149, 1.0, 2.0, 0.299941628072149, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683646.3286370652, 683646.3286370657, 180446.9059883591]
[2019-03-24 06:58:03,928] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:58:03,931] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3333371e-07 6.8676707e-07 1.7233236e-07 9.9999738e-01 1.5629890e-06], sampled 0.09675814280811001
[2019-03-24 06:58:15,805] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5936 2410678421.6284 22.0000
[2019-03-24 06:58:16,515] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668561410.2358 68.0000
[2019-03-24 06:58:16,587] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3654 2465978245.1590 46.0000
[2019-03-24 06:58:16,657] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473084.7055 47.0000
[2019-03-24 06:58:16,678] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 06:58:17,693] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 700000, evaluation results [700000.0, 7523.01586001269, 2668561410.235784, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.593576303426, 2410678421.628421, 22.0, 6905.908355438081, 2495473084.7055235, 47.0, 7478.365444537186, 2465978245.1589665, 46.0]
[2019-03-24 06:58:19,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3217377e-08 1.2618908e-06 1.5755511e-07 9.9999785e-01 6.9352353e-07], sum to 1.0000
[2019-03-24 06:58:19,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3668
[2019-03-24 06:58:19,306] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.93333333333333, 41.83333333333334, 1.0, 2.0, 0.1873730234334288, 1.0, 2.0, 0.1873730234334288, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464610.7189233036, 464610.7189233041, 157291.8586038618], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2499000.0000, 
sim time next is 2499600.0000, 
raw observation next is [27.76666666666667, 42.66666666666667, 1.0, 2.0, 0.1884045582791906, 1.0, 2.0, 0.1884045582791906, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466986.9778884682, 466986.9778884687, 157502.381693877], 
processed observation next is [1.0, 0.9565217391304348, 0.5839506172839507, 0.4266666666666667, 1.0, 1.0, 0.033814950332369746, 1.0, 1.0, 0.033814950332369746, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16678106353159577, 0.16678106353159597, 0.30288919556514804], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.44346085], dtype=float32), -0.66728944]. 
=============================================
[2019-03-24 06:58:27,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8677038e-08 8.2458644e-09 5.9561622e-10 1.0000000e+00 5.6778138e-08], sum to 1.0000
[2019-03-24 06:58:27,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1804
[2019-03-24 06:58:27,774] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 56.0, 1.0, 2.0, 0.318992088433641, 1.0, 2.0, 0.318992088433641, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727087.960380671, 727087.960380671, 185080.9667401479], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2739600.0000, 
sim time next is 2740200.0000, 
raw observation next is [31.25, 54.33333333333334, 1.0, 2.0, 0.3170419142052306, 1.0, 2.0, 0.3170419142052306, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722640.7762249318, 722640.7762249318, 184600.7000028833], 
processed observation next is [0.0, 0.7391304347826086, 0.7129629629629629, 0.5433333333333334, 1.0, 1.0, 0.18695465976813166, 1.0, 1.0, 0.18695465976813166, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2580859915089042, 0.2580859915089042, 0.35500134615939094], 
reward next is 0.6450, 
noisyNet noise sample is [array([-1.3949404], dtype=float32), 0.32759154]. 
=============================================
[2019-03-24 06:58:30,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9989098e-07 3.0247659e-08 5.2664735e-08 9.9999952e-01 2.6347240e-07], sum to 1.0000
[2019-03-24 06:58:30,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5363
[2019-03-24 06:58:30,837] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.06666666666667, 74.33333333333334, 1.0, 2.0, 0.339581764318749, 1.0, 2.0, 0.339581764318749, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774042.3038097547, 774042.3038097551, 190230.8433140083], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2751600.0000, 
sim time next is 2752200.0000, 
raw observation next is [27.8, 75.5, 1.0, 2.0, 0.3383982351478064, 1.0, 2.0, 0.3383982351478064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771343.2113268252, 771343.2113268252, 189930.7997517955], 
processed observation next is [0.0, 0.8695652173913043, 0.5851851851851853, 0.755, 1.0, 1.0, 0.21237885136643622, 1.0, 1.0, 0.21237885136643622, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.275479718331009, 0.275479718331009, 0.3652515379842221], 
reward next is 0.6347, 
noisyNet noise sample is [array([0.74966043], dtype=float32), 0.5964523]. 
=============================================
[2019-03-24 06:58:30,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9310514e-05 2.3452545e-05 1.5943159e-07 9.9986887e-01 5.8109192e-05], sum to 1.0000
[2019-03-24 06:58:30,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1493
[2019-03-24 06:58:30,956] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.45, 86.83333333333334, 1.0, 2.0, 0.2385199155737947, 1.0, 2.0, 0.2385199155737947, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571340.7734158846, 571340.773415885, 167654.9867008235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2596200.0000, 
sim time next is 2596800.0000, 
raw observation next is [22.3, 87.66666666666667, 1.0, 2.0, 0.2375895716365208, 1.0, 2.0, 0.2375895716365208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569528.2011578564, 569528.2011578564, 167464.4267631104], 
processed observation next is [0.0, 0.043478260869565216, 0.38148148148148153, 0.8766666666666667, 1.0, 1.0, 0.09236853766252477, 1.0, 1.0, 0.09236853766252477, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20340292898494872, 0.20340292898494872, 0.32204697454444303], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.34159762], dtype=float32), -0.009521243]. 
=============================================
[2019-03-24 06:58:36,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3506200e-07 2.0290046e-05 5.1570082e-06 9.9994063e-01 3.3791486e-05], sum to 1.0000
[2019-03-24 06:58:36,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-24 06:58:36,686] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 79.83333333333334, 1.0, 2.0, 0.4433127249328996, 1.0, 2.0, 0.4433127249328996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1010642.443289328, 1010642.443289328, 218409.7130712544], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2913000.0000, 
sim time next is 2913600.0000, 
raw observation next is [28.0, 80.66666666666667, 1.0, 2.0, 0.340798768878576, 1.0, 2.0, 0.340798768878576, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776817.7483616743, 776817.7483616743, 190540.7268590092], 
processed observation next is [1.0, 0.7391304347826086, 0.5925925925925926, 0.8066666666666668, 1.0, 1.0, 0.2152366296173524, 1.0, 1.0, 0.2152366296173524, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2774349101291694, 0.2774349101291694, 0.36642447472886386], 
reward next is 0.6336, 
noisyNet noise sample is [array([-0.42466298], dtype=float32), 0.069752574]. 
=============================================
[2019-03-24 06:58:45,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3371165e-07 9.5282481e-08 1.1473412e-06 9.9999821e-01 1.8035834e-07], sum to 1.0000
[2019-03-24 06:58:45,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0128
[2019-03-24 06:58:45,257] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3426003654825171, 1.0, 2.0, 0.3426003654825171, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780926.4050572179, 780926.4050572179, 190998.2983898652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2929200.0000, 
sim time next is 2929800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3425109631862427, 1.0, 2.0, 0.3425109631862427, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780722.5168627085, 780722.5168627085, 190975.5275569774], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.21727495617409845, 1.0, 1.0, 0.21727495617409845, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27882947030811017, 0.27882947030811017, 0.36726062991726427], 
reward next is 0.6327, 
noisyNet noise sample is [array([1.5491631], dtype=float32), -0.24154903]. 
=============================================
[2019-03-24 06:58:49,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3458635e-06 3.1132402e-06 1.6986556e-07 9.9998212e-01 1.2327203e-05], sum to 1.0000
[2019-03-24 06:58:49,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8408
[2019-03-24 06:58:49,752] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 98.16666666666667, 1.0, 2.0, 0.257809178362602, 1.0, 2.0, 0.257809178362602, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607290.5358897154, 607290.5358897154, 171591.162812706], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3045000.0000, 
sim time next is 3045600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2447696844527983, 1.0, 2.0, 0.2447696844527983, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583048.2446076545, 583048.2446076545, 168922.2791264664], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 1.0, 1.0, 1.0, 0.10091629101523605, 1.0, 1.0, 0.10091629101523605, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20823151593130518, 0.20823151593130518, 0.32485053678166614], 
reward next is 0.6751, 
noisyNet noise sample is [array([1.6282521], dtype=float32), 1.0983558]. 
=============================================
[2019-03-24 06:59:01,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3620946e-08 2.1162160e-08 3.0234922e-08 9.9999797e-01 1.8888206e-06], sum to 1.0000
[2019-03-24 06:59:01,646] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-24 06:59:01,652] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 89.0, 1.0, 2.0, 0.3061005040339315, 1.0, 2.0, 0.3061005040339315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697690.424491093, 697690.4244910935, 181930.8991773509], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [24.33333333333333, 91.5, 1.0, 2.0, 0.3065440853142758, 1.0, 2.0, 0.3065440853142758, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698701.933609694, 698701.933609694, 182038.3109747709], 
processed observation next is [0.0, 0.9130434782608695, 0.45679012345678993, 0.915, 1.0, 1.0, 0.1744572444217569, 1.0, 1.0, 0.1744572444217569, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.249536404860605, 0.249536404860605, 0.3500736749514825], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.26592606], dtype=float32), -2.1500795]. 
=============================================
[2019-03-24 06:59:05,427] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 06:59:05,427] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:59:05,428] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:59:05,429] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:59:05,430] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:05,428] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:05,431] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:59:05,431] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:59:05,431] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:05,435] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:05,434] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:05,447] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-24 06:59:05,477] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-24 06:59:05,477] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-24 06:59:05,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-24 06:59:05,573] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-24 06:59:08,727] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:08,729] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.66666666666667, 42.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 307876.9400685005, 307876.9400685005, 112287.5461200585]
[2019-03-24 06:59:08,731] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:59:08,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.6322171e-07 3.4701288e-06 1.1432744e-06 9.9998832e-01 6.1862443e-06], sampled 0.8537146564258155
[2019-03-24 06:59:08,782] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:08,782] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.4, 54.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 267099.2668805602, 267099.2668805606, 106980.0894415637]
[2019-03-24 06:59:08,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:59:08,787] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0198597e-06 3.9611591e-06 1.3311401e-06 9.9998617e-01 7.4823633e-06], sampled 0.9553062097176397
[2019-03-24 06:59:13,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:13,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.66666666666667, 61.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392991.1579316388, 392991.1579316388, 149821.8400958263]
[2019-03-24 06:59:13,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:59:13,609] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4207569e-07 2.6025425e-06 8.3991915e-07 9.9999094e-01 4.9680275e-06], sampled 0.5674258600802703
[2019-03-24 06:59:15,096] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:15,097] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 43.5, 1.0, 2.0, 0.5669437500977523, 1.0, 2.0, 0.5669437500977523, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1370494.018816667, 1370494.018816668, 260145.6744549468]
[2019-03-24 06:59:15,099] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:59:15,102] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0539176e-06 7.5278717e-06 2.6829832e-06 9.9997485e-01 1.2892488e-05], sampled 0.036915413069806835
[2019-03-24 06:59:28,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:28,743] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.84481689, 56.715460295, 1.0, 2.0, 0.1794277150897242, 1.0, 2.0, 0.1794277150897242, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 445464.1540020238, 445464.1540020243, 155650.2414275816]
[2019-03-24 06:59:28,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:59:28,748] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.8100964e-07 1.6668153e-06 5.0861757e-07 9.9999440e-01 3.1299735e-06], sampled 0.558175759169602
[2019-03-24 06:59:40,376] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:40,377] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.2, 47.5, 1.0, 2.0, 0.2882652484343242, 1.0, 2.0, 0.2882652484343242, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657021.3655516154, 657021.3655516158, 177668.6943416017]
[2019-03-24 06:59:40,379] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:59:40,384] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8834451e-07 2.3576843e-06 7.7917707e-07 9.9999213e-01 4.1937133e-06], sampled 0.8995856002915126
[2019-03-24 06:59:54,005] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 06:59:54,005] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.749105265, 83.70486428999999, 1.0, 2.0, 0.6359491026621691, 1.0, 2.0, 0.6359491026621691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1450221.031623654, 1450221.031623655, 280630.6438009036]
[2019-03-24 06:59:54,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:59:54,009] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1929702e-06 4.4832586e-06 1.5582073e-06 9.9998510e-01 7.6260471e-06], sampled 0.8885003285096553
[2019-03-24 07:00:16,955] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00907612], dtype=float32), 0.005377349]
[2019-03-24 07:00:16,956] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.5, 70.5, 1.0, 2.0, 0.4200503183825084, 1.0, 2.0, 0.4200503183825084, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957576.8231761511, 957576.8231761511, 211767.7279433137]
[2019-03-24 07:00:16,958] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:00:16,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6323585e-07 1.1565480e-06 3.5176041e-07 9.9999595e-01 2.2155409e-06], sampled 0.9377864849977432
[2019-03-24 07:00:53,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.1307 2410754736.8988 22.0000
[2019-03-24 07:00:54,051] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:00:54,058] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2565 2438842291.4689 34.0000
[2019-03-24 07:00:54,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6295 2465994106.9459 46.0000
[2019-03-24 07:00:54,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0917 2668496507.7118 68.0000
[2019-03-24 07:00:55,260] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 725000, evaluation results [725000.0, 7523.091712791175, 2668496507.711827, 68.0, 7122.256506796611, 2438842291.468926, 34.0, 7796.130717783003, 2410754736.898837, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.629529078766, 2465994106.945852, 46.0]
[2019-03-24 07:00:56,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7537541e-06 2.2060262e-07 1.0933929e-07 9.9999285e-01 1.0364290e-06], sum to 1.0000
[2019-03-24 07:00:56,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3078
[2019-03-24 07:00:56,818] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4316716214628026, 1.0, 2.0, 0.4316716214628026, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 984086.58980934, 984086.5898093404, 215059.7093693725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3380400.0000, 
sim time next is 3381000.0000, 
raw observation next is [24.0, 94.00000000000001, 1.0, 2.0, 0.426467392598861, 1.0, 2.0, 0.426467392598861, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 972214.9253807148, 972214.9253807152, 213578.174082256], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.9400000000000002, 1.0, 1.0, 0.3172230864272155, 1.0, 1.0, 0.3172230864272155, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34721961620739816, 0.3472196162073983, 0.4107272578504923], 
reward next is 0.5893, 
noisyNet noise sample is [array([-2.2588353], dtype=float32), -1.2359017]. 
=============================================
[2019-03-24 07:00:56,832] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.889126]
 [54.70347 ]
 [54.296814]
 [54.832123]
 [54.898888]], R is [[53.22262573]
 [53.27682114]
 [53.32577133]
 [53.36631012]
 [53.39701843]].
[2019-03-24 07:00:57,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1050959e-07 9.3594247e-07 4.5304304e-07 9.9998295e-01 1.5522868e-05], sum to 1.0000
[2019-03-24 07:00:57,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0414
[2019-03-24 07:00:57,099] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 80.66666666666667, 1.0, 2.0, 0.3273916353147424, 1.0, 2.0, 0.3273916353147424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 746242.6114527314, 746242.6114527319, 187164.1475414264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3356400.0000, 
sim time next is 3357000.0000, 
raw observation next is [26.9, 81.5, 1.0, 2.0, 0.331234195322207, 1.0, 2.0, 0.331234195322207, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755005.4932539192, 755005.4932539192, 188125.3441463246], 
processed observation next is [0.0, 0.8695652173913043, 0.5518518518518518, 0.815, 1.0, 1.0, 0.2038502325264369, 1.0, 1.0, 0.2038502325264369, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26964481901925685, 0.26964481901925685, 0.3617795079737012], 
reward next is 0.6382, 
noisyNet noise sample is [array([-0.4032502], dtype=float32), -0.60107905]. 
=============================================
[2019-03-24 07:00:57,125] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.02201 ]
 [68.00723 ]
 [67.936806]
 [67.87481 ]
 [67.87629 ]], R is [[67.99195099]
 [67.95210266]
 [67.91342163]
 [67.87319946]
 [67.83113861]].
[2019-03-24 07:00:57,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.514932e-06 8.074710e-05 4.990458e-06 9.995882e-01 3.195078e-04], sum to 1.0000
[2019-03-24 07:00:57,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-24 07:00:57,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 93.66666666666667, 1.0, 2.0, 0.3291465741246498, 1.0, 2.0, 0.3291465741246498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750244.7021354008, 750244.7021354008, 187602.2448020706], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3370800.0000, 
sim time next is 3371400.0000, 
raw observation next is [24.65, 93.5, 1.0, 2.0, 0.3264885609160157, 1.0, 2.0, 0.3264885609160157, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744183.1827555321, 744183.1827555321, 186938.7077786363], 
processed observation next is [1.0, 0.0, 0.46851851851851845, 0.935, 1.0, 1.0, 0.19820066775716155, 1.0, 1.0, 0.19820066775716155, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26577970812697577, 0.26577970812697577, 0.35949751495891596], 
reward next is 0.6405, 
noisyNet noise sample is [array([-0.14932942], dtype=float32), 0.70998055]. 
=============================================
[2019-03-24 07:01:04,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9909346e-07 2.2901670e-06 7.2184633e-07 9.9997830e-01 1.7815515e-05], sum to 1.0000
[2019-03-24 07:01:04,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9635
[2019-03-24 07:01:04,137] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.3250827099963046, 1.0, 2.0, 0.3250827099963046, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 740977.201290164, 740977.2012901645, 186589.031268666], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3523200.0000, 
sim time next is 3523800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.324880839400366, 1.0, 2.0, 0.324880839400366, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740516.8453362356, 740516.8453362356, 186538.8443461038], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 1.0, 0.19628671357186428, 1.0, 1.0, 0.19628671357186428, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2644703019057984, 0.2644703019057984, 0.3587285468194304], 
reward next is 0.6413, 
noisyNet noise sample is [array([-1.5606208], dtype=float32), -0.46330532]. 
=============================================
[2019-03-24 07:01:11,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4153529e-09 2.6047834e-08 4.3448427e-09 1.0000000e+00 1.9919447e-08], sum to 1.0000
[2019-03-24 07:01:11,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5355
[2019-03-24 07:01:11,342] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.3140958770699018, 1.0, 2.0, 0.3140958770699018, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715922.6717271695, 715922.6717271695, 183877.6368933692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3802800.0000, 
sim time next is 3803400.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.3147884232590946, 1.0, 2.0, 0.3147884232590946, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717501.9396928785, 717501.939692879, 184047.3537154075], 
processed observation next is [0.0, 0.0, 0.5370370370370371, 0.79, 1.0, 1.0, 0.18427193245130313, 1.0, 1.0, 0.18427193245130313, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2562506927474566, 0.25625069274745677, 0.35393721868347594], 
reward next is 0.6461, 
noisyNet noise sample is [array([0.7374242], dtype=float32), -0.22831468]. 
=============================================
[2019-03-24 07:01:24,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1179531e-09 4.4511108e-08 8.4181913e-08 9.9999750e-01 2.3947887e-06], sum to 1.0000
[2019-03-24 07:01:24,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4700
[2019-03-24 07:01:24,870] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 94.66666666666666, 1.0, 2.0, 0.3580733831055674, 1.0, 2.0, 0.3580733831055674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816214.5217972418, 816214.5217972418, 194981.4499209473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3908400.0000, 
sim time next is 3909000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.36061127549972, 1.0, 2.0, 0.36061127549972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822002.6521444863, 822002.6521444863, 195642.7187413992], 
processed observation next is [0.0, 0.21739130434782608, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.2388229470234762, 1.0, 1.0, 0.2388229470234762, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29357237576588796, 0.29357237576588796, 0.37623599757961385], 
reward next is 0.6238, 
noisyNet noise sample is [array([0.54474306], dtype=float32), 2.0392125]. 
=============================================
[2019-03-24 07:01:24,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.040085]
 [62.106846]
 [62.11013 ]
 [62.142403]
 [62.13029 ]], R is [[61.97018433]
 [61.97551727]
 [61.98188782]
 [61.98914719]
 [61.99710846]].
[2019-03-24 07:01:38,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6951670e-07 1.9984438e-05 8.4874591e-06 9.9990273e-01 6.7936111e-05], sum to 1.0000
[2019-03-24 07:01:38,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9726
[2019-03-24 07:01:38,713] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 34.66666666666667, 1.0, 2.0, 0.247713933837108, 1.0, 2.0, 0.247713933837108, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584237.374422597, 584237.3744225975, 169339.0855907859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4212600.0000, 
sim time next is 4213200.0000, 
raw observation next is [33.66666666666667, 35.33333333333334, 1.0, 2.0, 0.2461609524152308, 1.0, 2.0, 0.2461609524152308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580029.0256224555, 580029.025622456, 168966.8376079697], 
processed observation next is [1.0, 0.782608695652174, 0.8024691358024693, 0.35333333333333344, 1.0, 1.0, 0.1025725623990843, 1.0, 1.0, 0.1025725623990843, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20715322343659126, 0.20715322343659143, 0.3249362261691725], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.41181615], dtype=float32), 1.1078645]. 
=============================================
[2019-03-24 07:01:42,866] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 07:01:42,867] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:01:42,868] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:01:42,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:42,869] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:42,869] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:01:42,870] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:42,870] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:01:42,870] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:01:42,871] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:42,871] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:42,890] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-24 07:01:42,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-24 07:01:42,951] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-24 07:01:42,952] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-24 07:01:43,007] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-24 07:02:00,246] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:00,247] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.13333333333333, 39.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378655.3390983913, 378655.3390983913, 147400.3536907723]
[2019-03-24 07:02:00,250] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:00,253] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4064877e-07 1.5756394e-06 8.9469103e-07 9.9999237e-01 4.9461746e-06], sampled 0.4817504076773602
[2019-03-24 07:02:02,055] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:02,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.84436439, 45.86995881, 1.0, 2.0, 0.4076288842328979, 1.0, 2.0, 0.4076288842328979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 949278.3147305778, 949278.3147305782, 209223.0627369909]
[2019-03-24 07:02:02,059] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:02:02,063] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5611672e-06 7.9520842e-06 4.9294358e-06 9.9996412e-01 2.1513548e-05], sampled 0.48534581055368775
[2019-03-24 07:02:07,560] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:07,561] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.1925323478340619, 1.0, 2.0, 0.1925323478340619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473286.5749511608, 473286.5749511613, 158244.0192416633]
[2019-03-24 07:02:07,561] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:07,564] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4107312e-07 3.1590885e-06 1.8782657e-06 9.9998462e-01 9.7449511e-06], sampled 0.6953907711931037
[2019-03-24 07:02:13,552] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:13,553] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.4, 53.0, 1.0, 2.0, 0.2265029086738206, 1.0, 2.0, 0.2265029086738206, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547625.5356842206, 547625.5356842211, 165200.3397895749]
[2019-03-24 07:02:13,554] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:13,556] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9379111e-07 2.9143860e-06 1.7269751e-06 9.9998581e-01 9.0249505e-06], sampled 0.052293697974721276
[2019-03-24 07:02:37,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:37,014] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.16666666666667, 68.83333333333334, 1.0, 2.0, 0.3835878405099009, 1.0, 2.0, 0.3835878405099009, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 874406.923618398, 874406.9236183985, 201731.3287424767]
[2019-03-24 07:02:37,016] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:02:37,019] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8457944e-07 1.7726086e-06 1.0383586e-06 9.9999130e-01 5.6380736e-06], sampled 0.7864613819698156
[2019-03-24 07:02:53,151] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:53,152] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.46666666666667, 88.0, 1.0, 2.0, 0.1921185432759887, 1.0, 2.0, 0.1921185432759887, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 474308.8287283029, 474308.8287283033, 158219.3975641608]
[2019-03-24 07:02:53,153] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:53,155] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1125344e-07 1.9371532e-06 1.1222251e-06 9.9999046e-01 6.1806727e-06], sampled 0.6727187421624075
[2019-03-24 07:02:53,177] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:53,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.08124116, 76.43518632333334, 1.0, 2.0, 0.4208403916667902, 1.0, 2.0, 0.4208403916667902, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 959379.0583126276, 959379.0583126281, 211989.9713043354]
[2019-03-24 07:02:53,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:02:53,184] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5292900e-07 1.5834180e-06 9.2619808e-07 9.9999225e-01 4.9947134e-06], sampled 0.33297527730249044
[2019-03-24 07:02:58,268] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:02:58,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.59674607, 87.05755132, 1.0, 2.0, 0.3500844226489048, 1.0, 2.0, 0.3500844226489048, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797994.5135869759, 797994.5135869763, 192914.6254570499]
[2019-03-24 07:02:58,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:02:58,272] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.3310492e-07 3.0988556e-06 1.8424466e-06 9.9998581e-01 8.7432290e-06], sampled 0.7071713585314107
[2019-03-24 07:03:18,406] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:03:18,409] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.895920855, 80.31102925833335, 1.0, 2.0, 0.1869106705128619, 1.0, 2.0, 0.1869106705128619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464314.0398310236, 464314.0398310241, 157218.4260473005]
[2019-03-24 07:03:18,410] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:03:18,414] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0402555e-07 1.8848622e-06 1.1061517e-06 9.9999046e-01 6.2176227e-06], sampled 0.1735769858916114
[2019-03-24 07:03:18,485] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:03:18,486] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.11666666666667, 80.5, 1.0, 2.0, 0.2102575300927059, 1.0, 2.0, 0.2102575300927059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513558.8855140102, 513558.8855140107, 161876.0054777848]
[2019-03-24 07:03:18,487] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:03:18,492] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6486250e-07 2.2216168e-06 1.2837980e-06 9.9998903e-01 7.0747815e-06], sampled 0.23513940367189445
[2019-03-24 07:03:25,319] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:03:25,321] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666666, 41.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399616.3727352385, 399616.372735239, 151386.9138265383]
[2019-03-24 07:03:25,323] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:03:25,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6521293e-07 2.7666943e-06 1.6327591e-06 9.9998653e-01 8.6083892e-06], sampled 0.5820768542526179
[2019-03-24 07:03:30,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00921995], dtype=float32), 0.00540889]
[2019-03-24 07:03:30,819] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.65067923, 18.88787253, 1.0, 2.0, 0.2772975113542, 1.0, 2.0, 0.2772975113542, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701099.4270973413, 701099.4270973417, 177519.304839842]
[2019-03-24 07:03:30,821] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:03:30,825] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.0845956e-07 4.5115307e-06 2.7204755e-06 9.9997914e-01 1.2698306e-05], sampled 0.6356932255945096
[2019-03-24 07:03:31,482] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.8577 2465919396.3241 46.0000
[2019-03-24 07:03:31,585] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7362 2495418209.4679 47.0000
[2019-03-24 07:03:31,667] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.8003 2438792208.7425 34.0000
[2019-03-24 07:03:31,771] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410715229.6432 22.0000
[2019-03-24 07:03:31,863] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.9029 2668620650.7144 68.0000
[2019-03-24 07:03:32,875] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 750000, evaluation results [750000.0, 7521.902915857684, 2668620650.714442, 68.0, 7121.800339649929, 2438792208.742461, 34.0, 7798.23719837083, 2410715229.643247, 22.0, 6906.736180006656, 2495418209.4679227, 47.0, 7479.85765374091, 2465919396.3241205, 46.0]
[2019-03-24 07:03:33,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7579568e-07 8.1180156e-07 6.0571358e-07 9.9999404e-01 4.1436224e-06], sum to 1.0000
[2019-03-24 07:03:33,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-24 07:03:33,114] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 60.16666666666667, 1.0, 2.0, 0.3241364034274484, 1.0, 2.0, 0.3241364034274484, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738819.1981456863, 738819.1981456868, 186354.3901307968], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4385400.0000, 
sim time next is 4386000.0000, 
raw observation next is [31.0, 61.33333333333334, 1.0, 2.0, 0.3289894793158527, 1.0, 2.0, 0.3289894793158527, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749886.4508041443, 749886.4508041447, 187563.7843509698], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6133333333333334, 1.0, 1.0, 0.20117795156649132, 1.0, 1.0, 0.20117795156649132, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26781658957290866, 0.2678165895729088, 0.36069958529032653], 
reward next is 0.6393, 
noisyNet noise sample is [array([-0.53298664], dtype=float32), 1.0677884]. 
=============================================
[2019-03-24 07:03:33,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.306786]
 [63.267616]
 [61.362614]
 [60.499653]
 [59.362915]], R is [[63.51541138]
 [63.5218811 ]
 [63.5315361 ]
 [63.54291534]
 [63.55567169]].
[2019-03-24 07:03:36,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5963935e-06 6.0043109e-05 1.3507244e-07 9.9950492e-01 4.3126527e-04], sum to 1.0000
[2019-03-24 07:03:36,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-24 07:03:36,974] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2490797028365124, 1.0, 2.0, 0.2490797028365124, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591872.2335951071, 591872.2335951076, 169833.2325458887], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4418400.0000, 
sim time next is 4419000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2491006373603111, 1.0, 2.0, 0.2491006373603111, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591918.4025396048, 591918.4025396053, 169837.8077539159], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.94, 1.0, 1.0, 0.10607218733370369, 1.0, 1.0, 0.10607218733370369, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2113994294784303, 0.21139942947843046, 0.3266111687575306], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.52047455], dtype=float32), -0.51661855]. 
=============================================
[2019-03-24 07:03:37,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.074066]
 [63.69122 ]
 [63.394543]
 [62.94584 ]
 [62.966015]], R is [[63.99478149]
 [64.02823639]
 [64.06149292]
 [64.09449768]
 [64.12708282]].
[2019-03-24 07:03:39,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.12642168e-06 1.10398556e-04 1.74061753e-07 9.99552310e-01
 3.29956529e-04], sum to 1.0000
[2019-03-24 07:03:39,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8758
[2019-03-24 07:03:39,775] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.33333333333334, 91.33333333333334, 1.0, 2.0, 0.249212584297823, 1.0, 2.0, 0.249212584297823, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 592146.8676648377, 592146.8676648382, 169861.5168251571], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4412400.0000, 
sim time next is 4413000.0000, 
raw observation next is [22.41666666666666, 90.66666666666666, 1.0, 2.0, 0.2490128551539792, 1.0, 2.0, 0.2490128551539792, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591684.3271251265, 591684.327125127, 169816.9537487256], 
processed observation next is [0.0, 0.043478260869565216, 0.38580246913580224, 0.9066666666666666, 1.0, 1.0, 0.10596768470711809, 1.0, 1.0, 0.10596768470711809, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2113158311161166, 0.21131583111611676, 0.32657106490139537], 
reward next is 0.6734, 
noisyNet noise sample is [array([-1.0509827], dtype=float32), 0.29614103]. 
=============================================
[2019-03-24 07:03:39,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.39458 ]
 [68.075134]
 [67.77687 ]
 [67.52905 ]
 [68.4822  ]], R is [[67.65142059]
 [67.64824677]
 [67.64501953]
 [67.64173126]
 [67.63835144]].
[2019-03-24 07:03:43,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0146770e-08 1.2931887e-06 1.4833248e-07 9.9998343e-01 1.5081602e-05], sum to 1.0000
[2019-03-24 07:03:43,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7832955e-07 2.5079696e-06 1.1186955e-06 9.9999046e-01 5.3568851e-06], sum to 1.0000
[2019-03-24 07:03:43,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-24 07:03:43,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0114
[2019-03-24 07:03:43,731] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333333, 98.0, 1.0, 2.0, 0.3018252630233998, 1.0, 2.0, 0.3018252630233998, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690431.5105216858, 690431.5105216863, 181023.7416647685], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4506000.0000, 
sim time next is 4506600.0000, 
raw observation next is [23.16666666666667, 99.0, 1.0, 2.0, 0.3000929518494692, 1.0, 2.0, 0.3000929518494692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687171.336339503, 687171.3363395034, 180641.7965229844], 
processed observation next is [0.0, 0.13043478260869565, 0.4135802469135804, 0.99, 1.0, 1.0, 0.1667773236303205, 1.0, 1.0, 0.1667773236303205, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24541833440696534, 0.2454183344069655, 0.3473880702365085], 
reward next is 0.6526, 
noisyNet noise sample is [array([0.24462555], dtype=float32), 0.12773417]. 
=============================================
[2019-03-24 07:03:43,734] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.297385314555131, 1.0, 2.0, 0.297385314555131, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 681892.1997830853, 681892.1997830857, 180037.6859493113], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4550400.0000, 
sim time next is 4551000.0000, 
raw observation next is [23.15, 99.16666666666667, 1.0, 2.0, 0.2982718368275319, 1.0, 2.0, 0.2982718368275319, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683335.541315483, 683335.5413154835, 180221.1673672337], 
processed observation next is [0.0, 0.6956521739130435, 0.4129629629629629, 0.9916666666666667, 1.0, 1.0, 0.16460932955658558, 1.0, 1.0, 0.16460932955658558, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24404840761267252, 0.24404840761267269, 0.3465791680139109], 
reward next is 0.6534, 
noisyNet noise sample is [array([-0.57789147], dtype=float32), -1.0807642]. 
=============================================
[2019-03-24 07:03:43,771] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.720695]
 [68.6919  ]
 [68.73592 ]
 [68.69281 ]
 [68.567604]], R is [[68.68761444]
 [68.6545105 ]
 [68.62171936]
 [68.58917236]
 [68.5567627 ]].
[2019-03-24 07:03:44,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7271213e-05 3.4493796e-04 7.9593854e-05 9.9931943e-01 2.1875089e-04], sum to 1.0000
[2019-03-24 07:03:44,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6851
[2019-03-24 07:03:44,163] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.96666666666667, 92.66666666666667, 1.0, 2.0, 0.2977362800765279, 1.0, 2.0, 0.2977362800765279, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682264.0934393437, 682264.0934393442, 180100.481966917], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4502400.0000, 
sim time next is 4503000.0000, 
raw observation next is [23.98333333333333, 93.33333333333334, 1.0, 2.0, 0.3006327523208619, 1.0, 2.0, 0.3006327523208619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687333.4916702682, 687333.4916702687, 180718.3673147646], 
processed observation next is [0.0, 0.08695652173913043, 0.4438271604938271, 0.9333333333333335, 1.0, 1.0, 0.1674199432391213, 1.0, 1.0, 0.1674199432391213, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2454762470250958, 0.24547624702509596, 0.3475353217591627], 
reward next is 0.6525, 
noisyNet noise sample is [array([1.3333179], dtype=float32), -0.022477694]. 
=============================================
[2019-03-24 07:03:44,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.48368 ]
 [64.55329 ]
 [64.81225 ]
 [64.64817 ]
 [64.275635]], R is [[64.52216339]
 [64.53059387]
 [64.53990173]
 [64.54992676]
 [64.56043243]].
[2019-03-24 07:03:46,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0428971e-06 2.9510498e-04 1.8777539e-06 9.2939711e-01 7.0302851e-02], sum to 1.0000
[2019-03-24 07:03:46,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7086
[2019-03-24 07:03:46,376] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.3001026962212248, 1.0, 2.0, 0.3001026962212248, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687505.4891411051, 687505.4891411054, 180659.5176396027], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4546800.0000, 
sim time next is 4547400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2991616186868833, 1.0, 2.0, 0.2991616186868833, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685852.9834937097, 685852.9834937102, 180458.2351849432], 
processed observation next is [0.0, 0.6521739130434783, 0.4074074074074074, 1.0, 1.0, 1.0, 0.16566859367486106, 1.0, 1.0, 0.16566859367486106, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24494749410489633, 0.2449474941048965, 0.3470350676633523], 
reward next is 0.6530, 
noisyNet noise sample is [array([-0.05547752], dtype=float32), -0.39947012]. 
=============================================
[2019-03-24 07:03:50,704] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0241355e-05 1.5127336e-04 1.4111319e-03 9.9838674e-01 4.0613031e-05], sum to 1.0000
[2019-03-24 07:03:50,715] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1449
[2019-03-24 07:03:50,718] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7140206340565604, 1.0, 2.0, 0.7140206340565604, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1628437.895905502, 1628437.895905503, 309507.1039440766], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4611600.0000, 
sim time next is 4612200.0000, 
raw observation next is [26.0, 87.33333333333334, 1.0, 2.0, 0.7156602178503839, 1.0, 2.0, 0.7156602178503839, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1632180.643919369, 1632180.643919369, 310136.0518427772], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.8733333333333334, 1.0, 1.0, 0.6615002593456951, 1.0, 1.0, 0.6615002593456951, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5829216585426318, 0.5829216585426318, 0.596415484313033], 
reward next is 0.4036, 
noisyNet noise sample is [array([1.1694641], dtype=float32), 0.060683664]. 
=============================================
[2019-03-24 07:03:50,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2519545e-06 7.5677472e-06 5.0299691e-06 9.9979347e-01 1.9272917e-04], sum to 1.0000
[2019-03-24 07:03:51,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3507
[2019-03-24 07:03:51,004] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.3357922964911056, 1.0, 2.0, 0.3357922964911056, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765400.2823636717, 765400.2823636722, 189272.6684231294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4644000.0000, 
sim time next is 4644600.0000, 
raw observation next is [27.83333333333334, 79.83333333333334, 1.0, 2.0, 0.3405443659561286, 1.0, 2.0, 0.3405443659561286, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776237.5679420478, 776237.5679420478, 190475.7757903064], 
processed observation next is [1.0, 0.782608695652174, 0.58641975308642, 0.7983333333333335, 1.0, 1.0, 0.21493376899539118, 1.0, 1.0, 0.21493376899539118, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27722770283644566, 0.27722770283644566, 0.3662995688275123], 
reward next is 0.6337, 
noisyNet noise sample is [array([1.4520153], dtype=float32), -2.8256147]. 
=============================================
[2019-03-24 07:03:51,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6430486e-06 2.6450392e-05 6.6122889e-06 9.9958402e-01 3.7730395e-04], sum to 1.0000
[2019-03-24 07:03:51,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8373
[2019-03-24 07:03:51,674] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.3606710245668486, 1.0, 2.0, 0.3606710245668486, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822138.9214071416, 822138.9214071416, 195658.4205081731], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4656600.0000, 
sim time next is 4657200.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.3612917273243594, 1.0, 2.0, 0.3612917273243594, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823554.5551030238, 823554.5551030242, 195820.4774093132], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.94, 1.0, 1.0, 0.23963300871947546, 1.0, 1.0, 0.23963300871947546, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2941266268225085, 0.2941266268225087, 0.37657784117175613], 
reward next is 0.6234, 
noisyNet noise sample is [array([0.81924367], dtype=float32), 1.8095558]. 
=============================================
[2019-03-24 07:03:57,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0197698e-05 2.0233335e-04 4.8676357e-06 9.9963033e-01 1.4232345e-04], sum to 1.0000
[2019-03-24 07:03:57,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4666
[2019-03-24 07:03:58,000] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 94.66666666666667, 1.0, 2.0, 0.4363108038922279, 1.0, 2.0, 0.4363108038922279, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 994669.4495166598, 994669.4495166603, 216388.5730436663], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4674000.0000, 
sim time next is 4674600.0000, 
raw observation next is [23.9, 94.5, 1.0, 2.0, 0.3685262551047379, 1.0, 2.0, 0.3685262551047379, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 840054.4995156914, 840054.4995156919, 197717.4070017156], 
processed observation next is [1.0, 0.08695652173913043, 0.4407407407407407, 0.945, 1.0, 1.0, 0.24824554179135466, 1.0, 1.0, 0.24824554179135466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30001946411274694, 0.3000194641127471, 0.3802257826956069], 
reward next is 0.6198, 
noisyNet noise sample is [array([-1.1609793], dtype=float32), -0.7919159]. 
=============================================
[2019-03-24 07:04:20,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5283946e-06 1.8155207e-06 1.6929019e-06 9.9915433e-01 8.4064156e-04], sum to 1.0000
[2019-03-24 07:04:20,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-24 07:04:20,401] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.16666666666667, 66.83333333333333, 1.0, 2.0, 0.3812242330512101, 1.0, 2.0, 0.3812242330512101, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 869015.9121291281, 869015.9121291286, 201096.321195422], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5148600.0000, 
sim time next is 5149200.0000, 
raw observation next is [31.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3763489553225001, 1.0, 2.0, 0.3763489553225001, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857896.3012762693, 857896.3012762693, 199793.6619118099], 
processed observation next is [0.0, 0.6086956521739131, 0.7160493827160496, 0.6766666666666667, 1.0, 1.0, 0.2575582801458335, 1.0, 1.0, 0.2575582801458335, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3063915361700962, 0.3063915361700962, 0.38421858059963443], 
reward next is 0.6158, 
noisyNet noise sample is [array([-1.8025727], dtype=float32), -2.2482035]. 
=============================================
[2019-03-24 07:04:20,673] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 07:04:20,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:04:20,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:20,679] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:04:20,679] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:20,680] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:04:20,682] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:20,682] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:04:20,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:04:20,683] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:20,684] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:20,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-24 07:04:20,696] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-24 07:04:20,696] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-24 07:04:20,781] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-24 07:04:20,782] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-24 07:05:22,012] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00914855], dtype=float32), 0.005257212]
[2019-03-24 07:05:22,014] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.57432416666667, 92.17264939333334, 1.0, 2.0, 0.311649112852563, 1.0, 2.0, 0.311649112852563, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 710343.1474074853, 710343.1474074858, 183279.6448056536]
[2019-03-24 07:05:22,015] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:05:22,020] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1470729e-05 7.5090436e-05 3.8654867e-05 9.9844223e-01 1.4225609e-03], sampled 0.6904518226594523
[2019-03-24 07:05:52,212] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00914855], dtype=float32), 0.005257212]
[2019-03-24 07:05:52,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.11666666666667, 92.83333333333334, 1.0, 2.0, 0.2230584090752948, 1.0, 2.0, 0.2230584090752948, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 539766.2916327608, 539766.2916327608, 164465.864775081]
[2019-03-24 07:05:52,215] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:05:52,218] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4057549e-05 5.3424184e-05 2.6381318e-05 9.9871802e-01 1.1881035e-03], sampled 0.2836184408504637
[2019-03-24 07:06:09,462] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6887.9363 2496281160.4772 48.0000
[2019-03-24 07:06:09,912] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7105.9432 2439748790.6765 34.0000
[2019-03-24 07:06:09,944] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7498.6678 2669488049.3020 68.0000
[2019-03-24 07:06:09,974] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7463.4908 2466630509.0458 46.0000
[2019-03-24 07:06:10,028] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7779.4698 2411368775.3249 22.0000
[2019-03-24 07:06:11,043] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 775000, evaluation results [775000.0, 7498.667796802848, 2669488049.3019676, 68.0, 7105.943151066134, 2439748790.67653, 34.0, 7779.469788692456, 2411368775.3249025, 22.0, 6887.936271735471, 2496281160.477202, 48.0, 7463.490779580312, 2466630509.0457616, 46.0]
[2019-03-24 07:06:11,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0013265  0.00170516 0.00607997 0.95955247 0.03133595], sum to 1.0000
[2019-03-24 07:06:11,783] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6895
[2019-03-24 07:06:11,787] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666666, 71.5, 1.0, 2.0, 0.867839003440764, 1.0, 2.0, 0.867839003440764, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1979633.955318024, 1979633.955318024, 372584.6846587058], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5230200.0000, 
sim time next is 5230800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.9395449295277092, 1.0, 2.0, 0.9395449295277092, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2143399.181039295, 2143399.181039296, 404791.275296461], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.7, 1.0, 1.0, 0.9280296780091776, 1.0, 1.0, 0.9280296780091776, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.765499707514034, 0.7654997075140343, 0.7784447601855019], 
reward next is 0.2216, 
noisyNet noise sample is [array([0.14139181], dtype=float32), -0.77140296]. 
=============================================
[2019-03-24 07:06:13,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2211196e-05 3.0157701e-04 1.5775148e-04 9.9863929e-01 8.7916671e-04], sum to 1.0000
[2019-03-24 07:06:13,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-24 07:06:13,272] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 73.0, 1.0, 2.0, 0.8270631180549134, 1.0, 2.0, 0.8270631180549134, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1886521.543273712, 1886521.543273712, 355064.8966891423], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5229600.0000, 
sim time next is 5230200.0000, 
raw observation next is [29.66666666666666, 71.5, 1.0, 2.0, 0.867839003440764, 1.0, 2.0, 0.867839003440764, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1979633.955318024, 1979633.955318024, 372584.6846585062], 
processed observation next is [1.0, 0.5217391304347826, 0.6543209876543208, 0.715, 1.0, 1.0, 0.8426654802866238, 1.0, 1.0, 0.8426654802866238, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7070121268992943, 0.7070121268992943, 0.7165090089586658], 
reward next is 0.2835, 
noisyNet noise sample is [array([0.29616773], dtype=float32), 0.53921556]. 
=============================================
[2019-03-24 07:06:13,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8460287e-05 6.3098472e-04 5.0007649e-05 9.9671340e-01 2.5771160e-03], sum to 1.0000
[2019-03-24 07:06:13,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6226
[2019-03-24 07:06:13,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.55, 85.0, 1.0, 2.0, 0.3642715278936485, 1.0, 2.0, 0.3642715278936485, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 830350.6078659536, 830350.607865954, 196600.5896086482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5254200.0000, 
sim time next is 5254800.0000, 
raw observation next is [27.43333333333333, 85.33333333333333, 1.0, 2.0, 0.3708641362927764, 1.0, 2.0, 0.3708641362927764, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845386.631788012, 845386.631788012, 198336.8084607064], 
processed observation next is [1.0, 0.8260869565217391, 0.5716049382716049, 0.8533333333333333, 1.0, 1.0, 0.2510287336818767, 1.0, 1.0, 0.2510287336818767, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3019237970671471, 0.3019237970671471, 0.3814169393475123], 
reward next is 0.6186, 
noisyNet noise sample is [array([-0.2304266], dtype=float32), -1.5148809]. 
=============================================
[2019-03-24 07:06:14,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2684806e-05 2.2789643e-05 2.1341759e-05 9.9785537e-01 2.0677601e-03], sum to 1.0000
[2019-03-24 07:06:14,189] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7407
[2019-03-24 07:06:14,197] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.7, 87.66666666666667, 1.0, 2.0, 0.2846751763861842, 1.0, 2.0, 0.2846751763861842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663908.82884131, 663908.8288413105, 177550.7754709265], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5289600.0000, 
sim time next is 5290200.0000, 
raw observation next is [23.6, 88.0, 1.0, 2.0, 0.2886909132163971, 1.0, 2.0, 0.2886909132163971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674268.0760706217, 674268.0760706217, 178548.4768784505], 
processed observation next is [1.0, 0.21739130434782608, 0.4296296296296297, 0.88, 1.0, 1.0, 0.15320346811475846, 1.0, 1.0, 0.15320346811475846, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2408100271680792, 0.2408100271680792, 0.3433624555354818], 
reward next is 0.6566, 
noisyNet noise sample is [array([0.8931923], dtype=float32), -1.3087833]. 
=============================================
[2019-03-24 07:06:16,851] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6326142e-05 2.6991323e-04 1.0871078e-04 9.9182820e-01 7.7567874e-03], sum to 1.0000
[2019-03-24 07:06:16,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4411
[2019-03-24 07:06:16,862] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.93333333333333, 71.66666666666666, 1.0, 2.0, 0.3153544808806656, 1.0, 2.0, 0.3153544808806656, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 718792.7681689913, 718792.7681689918, 184186.3394921747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5341800.0000, 
sim time next is 5342400.0000, 
raw observation next is [27.9, 72.0, 1.0, 2.0, 0.3140323051672341, 1.0, 2.0, 0.3140323051672341, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715777.7038419123, 715777.7038419123, 183862.3636803289], 
processed observation next is [1.0, 0.8695652173913043, 0.5888888888888888, 0.72, 1.0, 1.0, 0.18337179186575492, 1.0, 1.0, 0.18337179186575492, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2556348942292544, 0.2556348942292544, 0.35358146861601714], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.79161495], dtype=float32), -1.654213]. 
=============================================
[2019-03-24 07:06:20,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5556623e-05 1.2006435e-03 1.3232780e-04 9.9731880e-01 1.3325956e-03], sum to 1.0000
[2019-03-24 07:06:20,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1570
[2019-03-24 07:06:20,362] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 67.0, 1.0, 2.0, 0.9795312867853864, 1.0, 2.0, 0.9795312867853864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2234734.872210907, 2234734.872210907, 423526.6069178097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5491200.0000, 
sim time next is 5491800.0000, 
raw observation next is [32.84999999999999, 66.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.468009674001679, 6.9112, 121.9241200494544, 2612685.454472416, 2327553.630414167, 443050.4065078862], 
processed observation next is [1.0, 0.5652173913043478, 0.7722222222222217, 0.66, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.05568096740016788, 0.0, 0.8094493649798468, 0.9331019480258629, 0.8312691537193453, 0.8520200125151658], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6824123], dtype=float32), 1.9810013]. 
=============================================
[2019-03-24 07:06:21,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8596714e-05 1.5631058e-04 6.1447463e-05 9.9941897e-01 3.3472205e-04], sum to 1.0000
[2019-03-24 07:06:21,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5463
[2019-03-24 07:06:21,120] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.23333333333334, 68.66666666666667, 1.0, 2.0, 0.3032678299781029, 1.0, 2.0, 0.3032678299781029, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 691231.0408281235, 691231.0408281239, 181246.9282136154], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5336400.0000, 
sim time next is 5337000.0000, 
raw observation next is [28.2, 69.0, 1.0, 2.0, 0.3057606909252237, 1.0, 2.0, 0.3057606909252237, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 696915.5413460801, 696915.5413460806, 181849.0199477704], 
processed observation next is [1.0, 0.782608695652174, 0.6, 0.69, 1.0, 1.0, 0.17352463205383772, 1.0, 1.0, 0.17352463205383772, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24889840762360005, 0.24889840762360022, 0.34970965374571233], 
reward next is 0.6503, 
noisyNet noise sample is [array([0.02185621], dtype=float32), -0.721059]. 
=============================================
[2019-03-24 07:06:21,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.593506]
 [53.93757 ]
 [53.137836]
 [51.82004 ]
 [50.650875]], R is [[54.8240509 ]
 [54.92725754]
 [55.03020477]
 [55.13248444]
 [55.2352562 ]].
[2019-03-24 07:06:21,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8412638e-05 5.9060112e-05 4.3859563e-04 9.9734652e-01 2.0572948e-03], sum to 1.0000
[2019-03-24 07:06:21,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1635
[2019-03-24 07:06:21,158] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.93333333333333, 81.0, 1.0, 2.0, 0.3153027291966485, 1.0, 2.0, 0.3153027291966485, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 718674.7543909352, 718674.7543909356, 184174.0363940164], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5506800.0000, 
sim time next is 5507400.0000, 
raw observation next is [26.91666666666667, 81.0, 1.0, 2.0, 0.3193288700010083, 1.0, 2.0, 0.3193288700010083, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727855.960861539, 727855.960861539, 185164.2710584312], 
processed observation next is [1.0, 0.7391304347826086, 0.5524691358024693, 0.81, 1.0, 1.0, 0.18967722619167654, 1.0, 1.0, 0.18967722619167654, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2599485574505496, 0.2599485574505496, 0.3560851366508292], 
reward next is 0.6439, 
noisyNet noise sample is [array([0.47111094], dtype=float32), 1.4521028]. 
=============================================
[2019-03-24 07:06:24,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.00206796 0.00291256 0.00416653 0.9723865  0.01846648], sum to 1.0000
[2019-03-24 07:06:24,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8289
[2019-03-24 07:06:24,094] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 84.0, 1.0, 2.0, 0.9348882460166484, 1.0, 2.0, 0.9348882460166484, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9259356886369, 2132763.127641858, 2132763.127641857, 402647.1491287069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5480400.0000, 
sim time next is 5481000.0000, 
raw observation next is [29.55, 83.5, 1.0, 2.0, 0.9366095619398256, 1.0, 2.0, 0.9366095619398256, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.926042583057, 2136694.666630961, 2136694.666630961, 403439.4636891619], 
processed observation next is [1.0, 0.43478260869565216, 0.65, 0.835, 1.0, 1.0, 0.9245351927855067, 1.0, 1.0, 0.9245351927855067, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809462128603674, 0.7631052380824861, 0.7631052380824861, 0.7758451224791575], 
reward next is 0.2242, 
noisyNet noise sample is [array([0.4051247], dtype=float32), -0.5322253]. 
=============================================
[2019-03-24 07:06:24,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[38.921753]
 [38.200085]
 [38.237812]
 [38.4981  ]
 [38.523808]], R is [[39.42328644]
 [39.25473022]
 [38.86218262]
 [38.47356033]
 [38.28358078]].
[2019-03-24 07:06:30,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2339229e-05 1.3756357e-05 5.4928246e-06 9.7403061e-01 2.5927769e-02], sum to 1.0000
[2019-03-24 07:06:30,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9527
[2019-03-24 07:06:30,510] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.243822784048576, 1.0, 2.0, 0.243822784048576, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579382.8688996459, 579382.8688996463, 168652.2576531641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5747400.0000, 
sim time next is 5748000.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.2453958377663688, 1.0, 2.0, 0.2453958377663688, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 582361.5866653147, 582361.5866653152, 168973.0671301892], 
processed observation next is [0.0, 0.5217391304347826, 0.5432098765432101, 0.63, 1.0, 1.0, 0.10166171162662953, 1.0, 1.0, 0.10166171162662953, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2079862809518981, 0.20798628095189828, 0.3249482060195946], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.87782985], dtype=float32), 0.54579043]. 
=============================================
[2019-03-24 07:06:30,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.725624]
 [67.6782  ]
 [67.66014 ]
 [67.61322 ]
 [67.48892 ]], R is [[67.71726227]
 [67.71575928]
 [67.71484375]
 [67.71443176]
 [67.71432495]].
[2019-03-24 07:06:35,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4546429e-05 6.0282281e-04 4.9315870e-05 9.7856587e-01 2.0747349e-02], sum to 1.0000
[2019-03-24 07:06:35,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7915
[2019-03-24 07:06:35,264] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 82.0, 1.0, 2.0, 0.9032357225123205, 1.0, 2.0, 0.9032357225123205, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156513, 2060470.824033854, 2060470.824033854, 388260.2103049882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [27.43333333333334, 83.0, 1.0, 2.0, 0.8968199227020177, 1.0, 2.0, 0.8968199227020177, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2045818.268647984, 2045818.268647984, 385386.5694367572], 
processed observation next is [1.0, 0.6521739130434783, 0.5716049382716052, 0.83, 1.0, 1.0, 0.8771665746452592, 1.0, 1.0, 0.8771665746452592, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7306493816599943, 0.7306493816599943, 0.74112801814761], 
reward next is 0.2589, 
noisyNet noise sample is [array([-1.1290976], dtype=float32), -0.26196286]. 
=============================================
[2019-03-24 07:06:35,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[50.37153 ]
 [50.61367 ]
 [49.894997]
 [47.562004]
 [47.74778 ]], R is [[51.09418869]
 [50.83659363]
 [50.55643082]
 [50.26789474]
 [49.76521683]].
[2019-03-24 07:06:39,726] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9905031e-06 8.3719187e-06 8.8736215e-06 9.9970692e-01 2.7382866e-04], sum to 1.0000
[2019-03-24 07:06:39,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7881
[2019-03-24 07:06:39,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 94.66666666666667, 1.0, 2.0, 0.2772571851330488, 1.0, 2.0, 0.2772571851330488, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645859.8968338273, 645859.8968338273, 175770.9587763768], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5703600.0000, 
sim time next is 5704200.0000, 
raw observation next is [22.8, 95.0, 1.0, 2.0, 0.2758778996721094, 1.0, 2.0, 0.2758778996721094, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643418.6941042024, 643418.6941042028, 175483.9399403202], 
processed observation next is [0.0, 0.0, 0.4, 0.95, 1.0, 1.0, 0.137949880562035, 1.0, 1.0, 0.137949880562035, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22979239075150087, 0.22979239075150099, 0.3374691152698466], 
reward next is 0.6625, 
noisyNet noise sample is [array([-1.0491464], dtype=float32), -0.37567008]. 
=============================================
[2019-03-24 07:06:44,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3312230e-06 3.7811417e-06 3.9089068e-06 9.9780375e-01 2.1862262e-03], sum to 1.0000
[2019-03-24 07:06:44,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8312
[2019-03-24 07:06:44,139] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 74.0, 1.0, 2.0, 0.2098301113950156, 1.0, 2.0, 0.2098301113950156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512707.8581950245, 512707.8581950249, 161791.0943869451], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5868000.0000, 
sim time next is 5868600.0000, 
raw observation next is [22.81666666666667, 75.0, 1.0, 2.0, 0.2088550365994444, 1.0, 2.0, 0.2088550365994444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510604.2328041503, 510604.2328041508, 161592.2589063716], 
processed observation next is [1.0, 0.9565217391304348, 0.4006172839506174, 0.75, 1.0, 1.0, 0.058160757856481435, 1.0, 1.0, 0.058160757856481435, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18235865457291084, 0.182358654572911, 0.3107543440507146], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.05584317], dtype=float32), -0.34594038]. 
=============================================
[2019-03-24 07:06:45,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1213494e-07 1.0615619e-06 2.4853204e-08 9.9984884e-01 1.4974277e-04], sum to 1.0000
[2019-03-24 07:06:45,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-24 07:06:45,855] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 76.66666666666667, 1.0, 2.0, 0.2624121841715263, 1.0, 2.0, 0.2624121841715263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616638.670052224, 616638.6700522244, 172579.2458294253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6043200.0000, 
sim time next is 6043800.0000, 
raw observation next is [24.81666666666666, 77.33333333333333, 1.0, 2.0, 0.2615631003589471, 1.0, 2.0, 0.2615631003589471, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614851.3761995293, 614851.3761995297, 172393.7081871113], 
processed observation next is [1.0, 0.9565217391304348, 0.4746913580246911, 0.7733333333333333, 1.0, 1.0, 0.12090845280827034, 1.0, 1.0, 0.12090845280827034, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2195897772141176, 0.21958977721411777, 0.331526361898291], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.43551087], dtype=float32), -0.09886784]. 
=============================================
[2019-03-24 07:06:56,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7504807e-05 3.7139349e-04 1.6169550e-05 9.9822134e-01 1.3335765e-03], sum to 1.0000
[2019-03-24 07:06:56,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2180
[2019-03-24 07:06:56,846] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.51666666666667, 82.16666666666667, 1.0, 2.0, 0.2707778900608456, 1.0, 2.0, 0.2707778900608456, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631615.4367466507, 631615.4367466512, 174301.5795472342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6137400.0000, 
sim time next is 6138000.0000, 
raw observation next is [24.4, 83.0, 1.0, 2.0, 0.2712815204243149, 1.0, 2.0, 0.2712815204243149, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632764.8064042099, 632764.8064042099, 174417.1924275692], 
processed observation next is [1.0, 0.043478260869565216, 0.4592592592592592, 0.83, 1.0, 1.0, 0.1324780005051368, 1.0, 1.0, 0.1324780005051368, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2259874308586464, 0.2259874308586464, 0.33541767774532544], 
reward next is 0.6646, 
noisyNet noise sample is [array([0.14082526], dtype=float32), 0.32000902]. 
=============================================
[2019-03-24 07:06:56,869] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.77219 ]
 [62.202213]
 [62.29766 ]
 [62.85561 ]
 [63.86    ]], R is [[61.97758484]
 [62.02261734]
 [62.06735992]
 [62.11168289]
 [62.15559769]].
[2019-03-24 07:06:59,199] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 07:06:59,203] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:06:59,204] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:06:59,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:59,205] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:59,206] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:06:59,206] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:06:59,208] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:59,208] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:06:59,209] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:59,210] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:59,217] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-24 07:06:59,217] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-24 07:06:59,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-24 07:06:59,311] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-24 07:06:59,334] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-24 07:07:27,342] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:07:27,344] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.44210294666667, 55.68279977, 1.0, 2.0, 0.3249314150559628, 1.0, 2.0, 0.3249314150559628, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 787688.807570073, 787688.8075700735, 188514.7185240643]
[2019-03-24 07:07:27,345] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:07:27,347] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4564415e-06 7.3431816e-06 3.3307872e-06 9.9976820e-01 2.1861530e-04], sampled 0.04301066111673213
[2019-03-24 07:07:27,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:07:27,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.11969445, 56.18331966, 1.0, 2.0, 0.2027665206384049, 1.0, 2.0, 0.2027665206384049, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 499087.0646064261, 499087.0646064266, 160406.8969845218]
[2019-03-24 07:07:27,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:07:27,711] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2715096e-06 4.0547384e-06 1.7231766e-06 9.9984384e-01 1.4911416e-04], sampled 0.29743951485359
[2019-03-24 07:07:46,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:07:46,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666667, 40.66666666666667, 1.0, 2.0, 0.3853932198896741, 1.0, 2.0, 0.3853932198896741, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880157.2090665933, 880157.2090665933, 202294.055659929]
[2019-03-24 07:07:46,382] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:07:46,384] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6834804e-06 5.2097976e-06 2.2726540e-06 9.9981970e-01 1.7116246e-04], sampled 0.4374203481470722
[2019-03-24 07:07:47,357] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:07:47,358] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.86666666666667, 68.66666666666667, 1.0, 2.0, 0.684193660843757, 1.0, 2.0, 0.684193660843757, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 123.4485127171005, 1563292.762751216, 1563292.762751217, 298605.8737950948]
[2019-03-24 07:07:47,359] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:07:47,362] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0741450e-05 2.8038110e-05 1.4206882e-05 9.9937564e-01 5.7143113e-04], sampled 0.7618678476836338
[2019-03-24 07:07:54,583] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:07:54,584] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.427615285839258, 1.0, 2.0, 0.427615285839258, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 974833.4345644091, 974833.4345644095, 213905.9030998202]
[2019-03-24 07:07:54,588] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:07:54,590] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2168931e-06 6.6623566e-06 2.9763355e-06 9.9978024e-01 2.0788539e-04], sampled 0.36420421905303135
[2019-03-24 07:08:42,586] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00931983], dtype=float32), 0.005468461]
[2019-03-24 07:08:42,587] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.66666666666667, 79.33333333333334, 1.0, 2.0, 0.2611430654382526, 1.0, 2.0, 0.2611430654382526, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 612336.4326784028, 612336.4326784032, 172229.7640434643]
[2019-03-24 07:08:42,588] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:08:42,590] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1580580e-06 3.7507482e-06 1.5777429e-06 9.9985588e-01 1.3768814e-04], sampled 0.6924143100505786
[2019-03-24 07:08:47,994] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.2661 2495514823.0312 47.0000
[2019-03-24 07:08:48,235] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.3643 2438931186.4708 34.0000
[2019-03-24 07:08:48,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.1524 2668661046.2620 68.0000
[2019-03-24 07:08:48,523] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7791.2370 2410868158.5747 22.0000
[2019-03-24 07:08:48,596] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7476.2243 2466054139.4090 46.0000
[2019-03-24 07:08:49,614] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 800000, evaluation results [800000.0, 7521.15239979751, 2668661046.261967, 68.0, 7120.364323139281, 2438931186.470761, 34.0, 7791.237016812766, 2410868158.5746603, 22.0, 6905.266056676644, 2495514823.031244, 47.0, 7476.2243458767025, 2466054139.408974, 46.0]
[2019-03-24 07:08:50,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8206271e-05 7.2410053e-06 3.8104686e-06 9.9964917e-01 2.9148447e-04], sum to 1.0000
[2019-03-24 07:08:50,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7688
[2019-03-24 07:08:50,771] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.88333333333333, 54.16666666666666, 1.0, 2.0, 0.7890547268365329, 1.0, 2.0, 0.7890547268365329, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1799737.490644726, 1799737.490644726, 339250.7959237409], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6187800.0000, 
sim time next is 6188400.0000, 
raw observation next is [29.9, 54.0, 1.0, 2.0, 0.790280957316825, 1.0, 2.0, 0.790280957316825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802537.194716822, 1802537.194716823, 339753.0911562902], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.54, 1.0, 1.0, 0.7503344729962202, 1.0, 1.0, 0.7503344729962202, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6437632838274364, 0.6437632838274367, 0.6533713291467119], 
reward next is 0.3466, 
noisyNet noise sample is [array([0.13170496], dtype=float32), 0.24822235]. 
=============================================
[2019-03-24 07:08:51,785] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0037245e-06 9.1140356e-07 3.3327378e-05 9.6752411e-01 3.2440651e-02], sum to 1.0000
[2019-03-24 07:08:51,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9356
[2019-03-24 07:08:51,799] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.81666666666667, 68.33333333333334, 1.0, 2.0, 0.2752304888512216, 1.0, 2.0, 0.2752304888512216, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 640059.2006199057, 640059.2006199062, 175247.7512941536], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6124200.0000, 
sim time next is 6124800.0000, 
raw observation next is [26.73333333333333, 68.66666666666667, 1.0, 2.0, 0.2745348664785741, 1.0, 2.0, 0.2745348664785741, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638755.6873130937, 638755.6873130937, 175100.2586669781], 
processed observation next is [1.0, 0.9130434782608695, 0.545679012345679, 0.6866666666666668, 1.0, 1.0, 0.13635103152211203, 1.0, 1.0, 0.13635103152211203, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22812703118324776, 0.22812703118324776, 0.3367312666672656], 
reward next is 0.6633, 
noisyNet noise sample is [array([-0.61428934], dtype=float32), -0.48442447]. 
=============================================
[2019-03-24 07:08:54,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2826971e-08 1.1940907e-06 1.8959113e-06 9.9995506e-01 4.1823532e-05], sum to 1.0000
[2019-03-24 07:08:54,527] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-24 07:08:54,537] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.48333333333333, 75.66666666666667, 1.0, 2.0, 0.2470767242791209, 1.0, 2.0, 0.2470767242791209, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 586975.894170772, 586975.8941707725, 169376.4114395933], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6223800.0000, 
sim time next is 6224400.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.2467034958958033, 1.0, 2.0, 0.2467034958958033, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586428.135918589, 586428.135918589, 169306.5127252169], 
processed observation next is [0.0, 0.043478260869565216, 0.4592592592592592, 0.76, 1.0, 1.0, 0.10321844749500392, 1.0, 1.0, 0.10321844749500392, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20943861997092464, 0.20943861997092464, 0.325589447548494], 
reward next is 0.6744, 
noisyNet noise sample is [array([0.17120233], dtype=float32), 1.4573746]. 
=============================================
[2019-03-24 07:08:57,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5757395e-06 1.0498744e-05 1.1403997e-05 9.9994218e-01 3.3388777e-05], sum to 1.0000
[2019-03-24 07:08:57,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9563
[2019-03-24 07:08:57,245] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.68333333333333, 64.33333333333334, 1.0, 2.0, 0.3081334365307339, 1.0, 2.0, 0.3081334365307339, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 702326.1805748445, 702326.1805748449, 182423.8255650784], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6289800.0000, 
sim time next is 6290400.0000, 
raw observation next is [28.56666666666667, 64.66666666666667, 1.0, 2.0, 0.3069354503750172, 1.0, 2.0, 0.3069354503750172, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699594.3739285092, 699594.3739285097, 182133.1945298701], 
processed observation next is [0.0, 0.8260869565217391, 0.6135802469135804, 0.6466666666666667, 1.0, 1.0, 0.1749231552083538, 1.0, 1.0, 0.1749231552083538, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24985513354589614, 0.2498551335458963, 0.35025614332667326], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.7273102], dtype=float32), 0.11904956]. 
=============================================
[2019-03-24 07:09:01,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2360523e-04 3.1776828e-05 1.5234349e-05 9.9977988e-01 4.9518985e-05], sum to 1.0000
[2019-03-24 07:09:01,568] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0842
[2019-03-24 07:09:01,580] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.73333333333333, 56.0, 1.0, 2.0, 0.331683957346638, 1.0, 2.0, 0.331683957346638, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756031.1731693605, 756031.173169361, 188238.3656399633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6369600.0000, 
sim time next is 6370200.0000, 
raw observation next is [31.6, 56.5, 1.0, 2.0, 0.3304426026494678, 1.0, 2.0, 0.3304426026494678, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753200.2736883287, 753200.2736883292, 187927.1129187724], 
processed observation next is [0.0, 0.7391304347826086, 0.725925925925926, 0.565, 1.0, 1.0, 0.20290786029698546, 1.0, 1.0, 0.20290786029698546, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26900009774583167, 0.26900009774583183, 0.36139829407456225], 
reward next is 0.6386, 
noisyNet noise sample is [array([1.6095191], dtype=float32), 0.12968375]. 
=============================================
[2019-03-24 07:09:03,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7744072e-05 5.2572186e-06 8.0161750e-05 9.9876875e-01 1.0481400e-03], sum to 1.0000
[2019-03-24 07:09:03,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0419
[2019-03-24 07:09:03,918] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.9, 57.0, 1.0, 2.0, 0.9486901569233114, 1.0, 2.0, 0.9486901569233114, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2164287.623262284, 2164287.623262284, 409026.4193946104], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6442200.0000, 
sim time next is 6442800.0000, 
raw observation next is [32.06666666666666, 56.0, 1.0, 2.0, 0.9580051584194889, 1.0, 2.0, 0.9580051584194889, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2185564.345708913, 2185564.345708913, 413370.477216593], 
processed observation next is [1.0, 0.5652173913043478, 0.7432098765432097, 0.56, 1.0, 1.0, 0.950006140975582, 1.0, 1.0, 0.950006140975582, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7805586948960405, 0.7805586948960405, 0.794943225416525], 
reward next is 0.2051, 
noisyNet noise sample is [array([-0.521031], dtype=float32), -0.49798214]. 
=============================================
[2019-03-24 07:09:08,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4622035e-04 1.8555885e-04 2.0082858e-04 9.9873894e-01 7.2838482e-04], sum to 1.0000
[2019-03-24 07:09:08,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3416
[2019-03-24 07:09:08,282] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.28333333333333, 79.83333333333334, 1.0, 2.0, 0.8930831771765511, 1.0, 2.0, 0.8930831771765511, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2037284.311610666, 2037284.311610666, 383719.846625648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6522600.0000, 
sim time next is 6523200.0000, 
raw observation next is [28.2, 80.0, 1.0, 2.0, 0.8913299482844852, 1.0, 2.0, 0.8913299482844852, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2033280.326082734, 2033280.326082734, 382939.3162911995], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.8, 1.0, 1.0, 0.8706308908148633, 1.0, 1.0, 0.8706308908148633, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7261715450295478, 0.7261715450295478, 0.7364217620984606], 
reward next is 0.2636, 
noisyNet noise sample is [array([0.12491478], dtype=float32), -0.18561807]. 
=============================================
[2019-03-24 07:09:08,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7627458e-04 5.4132717e-05 3.2361044e-05 9.9743229e-01 2.0049978e-03], sum to 1.0000
[2019-03-24 07:09:08,679] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1656
[2019-03-24 07:09:08,682] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.45, 55.0, 1.0, 2.0, 0.9271521082554074, 1.0, 2.0, 0.9271521082554074, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2115093.750365503, 2115093.750365503, 399096.5129928699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6454200.0000, 
sim time next is 6454800.0000, 
raw observation next is [31.4, 55.0, 1.0, 2.0, 0.9332857318626218, 1.0, 2.0, 0.9332857318626218, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2129102.946827795, 2129102.946827795, 401907.7584697233], 
processed observation next is [1.0, 0.7391304347826086, 0.7185185185185184, 0.55, 1.0, 1.0, 0.9205782522174069, 1.0, 1.0, 0.9205782522174069, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7603939095813553, 0.7603939095813553, 0.7728995355186986], 
reward next is 0.2271, 
noisyNet noise sample is [array([-2.4790306], dtype=float32), -1.212011]. 
=============================================
[2019-03-24 07:09:08,778] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3991264e-05 4.0347161e-04 2.8362645e-05 9.9034369e-01 9.2005199e-03], sum to 1.0000
[2019-03-24 07:09:08,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5954
[2019-03-24 07:09:08,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 92.0, 1.0, 2.0, 0.407432738761159, 1.0, 2.0, 0.407432738761159, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928795.4531154924, 928795.4531154924, 208239.7618405019], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6413400.0000, 
sim time next is 6414000.0000, 
raw observation next is [24.83333333333333, 92.0, 1.0, 2.0, 0.4070404632583023, 1.0, 2.0, 0.4070404632583023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 927900.6691592231, 927900.6691592236, 208131.0830972093], 
processed observation next is [1.0, 0.21739130434782608, 0.4753086419753085, 0.92, 1.0, 1.0, 0.294095789593217, 1.0, 1.0, 0.294095789593217, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.331393096128294, 0.33139309612829415, 0.4002520828792487], 
reward next is 0.5997, 
noisyNet noise sample is [array([-1.4465146], dtype=float32), 1.3955622]. 
=============================================
[2019-03-24 07:09:08,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[47.550655]
 [47.397114]
 [47.198215]
 [46.83758 ]
 [46.392918]], R is [[47.69021606]
 [47.81285477]
 [47.93360138]
 [48.0433197 ]
 [48.15590668]].
[2019-03-24 07:09:12,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1690916e-07 2.8329485e-05 5.9566614e-06 9.9880266e-01 1.1625965e-03], sum to 1.0000
[2019-03-24 07:09:12,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2067
[2019-03-24 07:09:12,204] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.26666666666667, 33.66666666666667, 1.0, 2.0, 0.542165284409727, 1.0, 2.0, 0.542165284409727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1334128.952196959, 1334128.95219696, 252563.0754894479], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6625200.0000, 
sim time next is 6625800.0000, 
raw observation next is [29.4, 32.0, 1.0, 2.0, 0.5411077824741001, 1.0, 2.0, 0.5411077824741001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1336545.499455274, 1336545.499455274, 252342.0180982941], 
processed observation next is [1.0, 0.6956521739130435, 0.6444444444444444, 0.32, 1.0, 1.0, 0.4536997410405953, 1.0, 1.0, 0.4536997410405953, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4773376783768836, 0.4773376783768836, 0.48527311172748866], 
reward next is 0.5147, 
noisyNet noise sample is [array([-0.31964096], dtype=float32), -0.7859219]. 
=============================================
[2019-03-24 07:09:14,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0958298e-07 1.4103970e-05 1.0579880e-05 9.9916089e-01 8.1410306e-04], sum to 1.0000
[2019-03-24 07:09:14,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1968
[2019-03-24 07:09:14,640] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 48.0, 1.0, 2.0, 0.1795503787343153, 1.0, 2.0, 0.1795503787343153, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446203.4047953138, 446203.4047953143, 155687.5617842744], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6634800.0000, 
sim time next is 6635400.0000, 
raw observation next is [26.01666666666667, 50.16666666666666, 1.0, 2.0, 0.1813721487330975, 1.0, 2.0, 0.1813721487330975, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 450192.4326572225, 450192.432657223, 156050.9963762665], 
processed observation next is [1.0, 0.8260869565217391, 0.5191358024691359, 0.5016666666666666, 1.0, 1.0, 0.02544303420606846, 1.0, 1.0, 0.02544303420606846, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16078301166329376, 0.16078301166329392, 0.30009806995435867], 
reward next is 0.6999, 
noisyNet noise sample is [array([1.0105689], dtype=float32), -0.7271273]. 
=============================================
[2019-03-24 07:09:15,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2427335e-05 1.5106552e-05 3.5984149e-06 9.9903905e-01 8.9985220e-04], sum to 1.0000
[2019-03-24 07:09:15,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9319
[2019-03-24 07:09:15,299] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.08333333333333, 47.83333333333334, 1.0, 2.0, 0.3063740616114449, 1.0, 2.0, 0.3063740616114449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774970.2248256936, 774970.2248256941, 184619.1968849979], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6684600.0000, 
sim time next is 6685200.0000, 
raw observation next is [24.3, 47.0, 1.0, 2.0, 0.2883030057207824, 1.0, 2.0, 0.2883030057207824, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728967.7305796852, 728967.7305796852, 180170.0566784459], 
processed observation next is [1.0, 0.391304347826087, 0.4555555555555556, 0.47, 1.0, 1.0, 0.1527416734771219, 1.0, 1.0, 0.1527416734771219, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2603456180641733, 0.2603456180641733, 0.34648087822778056], 
reward next is 0.6535, 
noisyNet noise sample is [array([0.77607965], dtype=float32), 1.7897658]. 
=============================================
[2019-03-24 07:09:18,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8922244e-04 3.9447779e-05 1.8301846e-05 9.9807799e-01 1.6750460e-03], sum to 1.0000
[2019-03-24 07:09:18,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6697
[2019-03-24 07:09:18,089] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.3, 47.0, 1.0, 2.0, 0.2883030057207824, 1.0, 2.0, 0.2883030057207824, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728967.7305796852, 728967.7305796852, 180170.0566784459], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6685200.0000, 
sim time next is 6685800.0000, 
raw observation next is [24.53333333333333, 46.16666666666667, 1.0, 2.0, 0.3235001999871316, 1.0, 2.0, 0.3235001999871316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 817214.6726329754, 817214.6726329757, 188927.1708407351], 
processed observation next is [1.0, 0.391304347826087, 0.46419753086419746, 0.4616666666666667, 1.0, 1.0, 0.1946430952227757, 1.0, 1.0, 0.1946430952227757, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2918623830832055, 0.2918623830832056, 0.36332148238602907], 
reward next is 0.6367, 
noisyNet noise sample is [array([-0.8224468], dtype=float32), 2.5652187]. 
=============================================
[2019-03-24 07:09:20,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3281906e-07 1.2978185e-03 3.2159428e-06 9.9868900e-01 9.4716188e-06], sum to 1.0000
[2019-03-24 07:09:20,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-24 07:09:20,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333333, 44.0, 1.0, 2.0, 0.1812108131039259, 1.0, 2.0, 0.1812108131039259, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449124.5917373394, 449124.5917373399, 155998.5510126361], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6632400.0000, 
sim time next is 6633000.0000, 
raw observation next is [27.15, 45.0, 1.0, 2.0, 0.1812068310801177, 1.0, 2.0, 0.1812068310801177, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449362.2901478648, 449362.2901478652, 156004.7964931622], 
processed observation next is [1.0, 0.782608695652174, 0.561111111111111, 0.45, 1.0, 1.0, 0.025246227476330596, 1.0, 1.0, 0.025246227476330596, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.160486532195666, 0.16048653219566614, 0.30000922402531194], 
reward next is 0.7000, 
noisyNet noise sample is [array([1.0127032], dtype=float32), 2.525324]. 
=============================================
[2019-03-24 07:09:20,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.15914]
 [68.0084 ]
 [68.01335]
 [67.51422]
 [67.05235]], R is [[68.25065613]
 [68.26815796]
 [68.28569794]
 [68.30436707]
 [68.32550049]].
[2019-03-24 07:09:26,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2503664e-08 3.2798154e-05 2.5827492e-07 9.9987197e-01 9.4977404e-05], sum to 1.0000
[2019-03-24 07:09:26,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2516
[2019-03-24 07:09:26,567] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.83333333333333, 56.33333333333333, 1.0, 2.0, 0.2297511307382504, 1.0, 2.0, 0.2297511307382504, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554124.7510177665, 554124.7510177665, 165863.2308257618], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6982800.0000, 
sim time next is 6983400.0000, 
raw observation next is [26.56666666666667, 57.16666666666667, 1.0, 2.0, 0.2281299752434236, 1.0, 2.0, 0.2281299752434236, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 551063.4179216871, 551063.4179216876, 165538.6899945167], 
processed observation next is [0.0, 0.8260869565217391, 0.5395061728395063, 0.5716666666666668, 1.0, 1.0, 0.08110711338502809, 1.0, 1.0, 0.08110711338502809, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19680836354345968, 0.19680836354345985, 0.3183436346048398], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.15939127], dtype=float32), -1.4561728]. 
=============================================
[2019-03-24 07:09:26,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6892692e-05 2.1121630e-06 3.8526414e-06 9.9968016e-01 2.7690799e-04], sum to 1.0000
[2019-03-24 07:09:26,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-24 07:09:26,871] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 48.66666666666667, 1.0, 2.0, 0.2593705197748464, 1.0, 2.0, 0.2593705197748464, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608064.3328104336, 608064.3328104336, 171819.5373765496], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6873600.0000, 
sim time next is 6874200.0000, 
raw observation next is [30.5, 48.5, 1.0, 2.0, 0.2618033478448454, 1.0, 2.0, 0.2618033478448454, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612454.0834738021, 612454.0834738021, 172316.5960569629], 
processed observation next is [0.0, 0.5652173913043478, 0.6851851851851852, 0.485, 1.0, 1.0, 0.12119446172005402, 1.0, 1.0, 0.12119446172005402, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2187336012406436, 0.2187336012406436, 0.3313780693403133], 
reward next is 0.6686, 
noisyNet noise sample is [array([1.885361], dtype=float32), -1.1825589]. 
=============================================
[2019-03-24 07:09:28,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3977713e-04 6.7333866e-07 2.2691104e-07 9.9968171e-01 1.7755972e-04], sum to 1.0000
[2019-03-24 07:09:28,027] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8137
[2019-03-24 07:09:28,036] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.56666666666667, 57.66666666666667, 1.0, 2.0, 0.2274962566188795, 1.0, 2.0, 0.2274962566188795, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548808.4836853119, 548808.4836853123, 165373.0962397124], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6896400.0000, 
sim time next is 6897000.0000, 
raw observation next is [26.43333333333333, 57.83333333333334, 1.0, 2.0, 0.2254522799218161, 1.0, 2.0, 0.2254522799218161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 544704.7356019778, 544704.7356019783, 164956.7563190085], 
processed observation next is [0.0, 0.8260869565217391, 0.5345679012345678, 0.5783333333333335, 1.0, 1.0, 0.07791938085930489, 1.0, 1.0, 0.07791938085930489, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19453740557213492, 0.19453740557213509, 0.3172245313827087], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.57622117], dtype=float32), 0.47852024]. 
=============================================
[2019-03-24 07:09:28,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.2869 ]
 [70.34233]
 [70.34599]
 [70.39128]
 [70.41158]], R is [[70.23134613]
 [70.21100616]
 [70.19015503]
 [70.16879272]
 [70.146698  ]].
[2019-03-24 07:09:28,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6429264e-04 2.8341424e-06 2.3342131e-05 9.9952531e-01 2.8414605e-04], sum to 1.0000
[2019-03-24 07:09:28,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1743
[2019-03-24 07:09:28,488] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.2073638212567954, 1.0, 2.0, 0.2073638212567954, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507460.5128610235, 507460.5128610239, 161291.134301305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6914400.0000, 
sim time next is 6915000.0000, 
raw observation next is [23.13333333333334, 72.66666666666667, 1.0, 2.0, 0.2077776500464718, 1.0, 2.0, 0.2077776500464718, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508346.5577404366, 508346.5577404366, 161375.0788261303], 
processed observation next is [0.0, 0.0, 0.4123456790123459, 0.7266666666666667, 1.0, 1.0, 0.05687815481722834, 1.0, 1.0, 0.05687815481722834, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1815523420501559, 0.1815523420501559, 0.3103366900502506], 
reward next is 0.6897, 
noisyNet noise sample is [array([-0.41018796], dtype=float32), -0.309763]. 
=============================================
[2019-03-24 07:09:28,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.9966  ]
 [66.83984 ]
 [67.409325]
 [68.06197 ]
 [68.79837 ]], R is [[66.72637939]
 [66.74893951]
 [66.77140045]
 [66.79373169]
 [66.81591797]].
[2019-03-24 07:09:30,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6745502e-09 6.3827785e-05 8.2240319e-07 9.9988353e-01 5.1798623e-05], sum to 1.0000
[2019-03-24 07:09:30,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3062
[2019-03-24 07:09:30,525] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.01666666666667, 54.66666666666667, 1.0, 2.0, 0.2439503399831069, 1.0, 2.0, 0.2439503399831069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580873.9321538435, 580873.9321538439, 168729.6643857385], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6889800.0000, 
sim time next is 6890400.0000, 
raw observation next is [27.9, 55.0, 1.0, 2.0, 0.2429626983136425, 1.0, 2.0, 0.2429626983136425, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578971.3012254849, 578971.3012254854, 168526.9601640731], 
processed observation next is [0.0, 0.782608695652174, 0.5888888888888888, 0.55, 1.0, 1.0, 0.0987651170400506, 1.0, 1.0, 0.0987651170400506, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20677546472338748, 0.20677546472338765, 0.3240903080078329], 
reward next is 0.6759, 
noisyNet noise sample is [array([0.11116517], dtype=float32), 0.52697444]. 
=============================================
[2019-03-24 07:09:30,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8175872e-07 1.2479984e-06 1.2127276e-07 9.9995780e-01 4.0355731e-05], sum to 1.0000
[2019-03-24 07:09:30,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-24 07:09:30,712] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.38333333333333, 82.5, 1.0, 2.0, 0.2204590044726639, 1.0, 2.0, 0.2204590044726639, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534115.1438866328, 534115.1438866332, 163924.4531786128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6936600.0000, 
sim time next is 6937200.0000, 
raw observation next is [22.5, 82.0, 1.0, 2.0, 0.2211634621576676, 1.0, 2.0, 0.2211634621576676, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535399.3223902775, 535399.322390278, 164062.0510017773], 
processed observation next is [0.0, 0.30434782608695654, 0.3888888888888889, 0.82, 1.0, 1.0, 0.07281364542579477, 1.0, 1.0, 0.07281364542579477, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1912140437108134, 0.19121404371081357, 0.3155039442341871], 
reward next is 0.6845, 
noisyNet noise sample is [array([0.65258056], dtype=float32), -1.3780775]. 
=============================================
[2019-03-24 07:09:32,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9149085e-07 7.3966653e-06 4.3048313e-08 9.9997187e-01 2.0144511e-05], sum to 1.0000
[2019-03-24 07:09:32,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4153
[2019-03-24 07:09:32,212] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.3, 79.33333333333334, 1.0, 2.0, 0.2108022123910465, 1.0, 2.0, 0.2108022123910465, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514719.3723218971, 514719.3723218975, 161986.7895341069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6922200.0000, 
sim time next is 6922800.0000, 
raw observation next is [22.2, 80.0, 1.0, 2.0, 0.2104875587781755, 1.0, 2.0, 0.2104875587781755, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514015.9767045443, 514015.9767045448, 161921.6892760701], 
processed observation next is [0.0, 0.13043478260869565, 0.37777777777777777, 0.8, 1.0, 1.0, 0.0601042366406851, 1.0, 1.0, 0.0601042366406851, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18357713453733723, 0.18357713453733743, 0.3113878639924425], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.31942236], dtype=float32), -0.064561315]. 
=============================================
[2019-03-24 07:09:37,684] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 07:09:37,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:09:37,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,690] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:09:37,694] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:09:37,695] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,696] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,696] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:09:37,697] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:09:37,698] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,698] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-24 07:09:37,716] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-24 07:09:37,773] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-24 07:09:37,774] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-24 07:09:37,774] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-24 07:09:49,066] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:09:49,068] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.13333333333333, 48.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 381789.9455762798, 381789.9455762793, 148251.9244888393]
[2019-03-24 07:09:49,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:09:49,073] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.0152785e-07 1.7472233e-06 7.9089892e-07 9.9997699e-01 1.9628804e-05], sampled 0.2595464546115839
[2019-03-24 07:10:17,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:10:17,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.12046100666667, 66.29317397, 1.0, 2.0, 0.650834286017497, 1.0, 2.0, 0.650834286017497, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1484198.160078753, 1484198.160078754, 285975.6629307625]
[2019-03-24 07:10:17,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:10:17,427] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.3347223e-07 1.5763846e-06 7.1348597e-07 9.9997878e-01 1.8234094e-05], sampled 0.5820351301134704
[2019-03-24 07:10:23,756] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:10:23,758] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.3262702696253163, 1.0, 2.0, 0.3262702696253163, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743685.3781458905, 743685.3781458905, 186884.5566237755]
[2019-03-24 07:10:23,759] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:10:23,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0058939e-07 8.9638263e-07 3.8899839e-07 9.9998629e-01 1.1889017e-05], sampled 0.8678243170544524
[2019-03-24 07:10:25,414] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:10:25,416] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.345268543948954, 1.0, 2.0, 0.345268543948954, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787011.3977760584, 787011.3977760584, 191679.1565895552]
[2019-03-24 07:10:25,417] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:10:25,419] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7060769e-07 8.5386660e-07 3.6157610e-07 9.9998748e-01 1.0965501e-05], sampled 0.5896232729002436
[2019-03-24 07:10:34,751] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:10:34,754] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.41666666666666, 69.83333333333334, 1.0, 2.0, 0.3730080305145167, 1.0, 2.0, 0.3730080305145167, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 850276.3600845488, 850276.3600845493, 198905.0839846278]
[2019-03-24 07:10:34,755] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:10:34,759] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6515164e-07 8.3648951e-07 3.5317331e-07 9.9998772e-01 1.0763436e-05], sampled 0.15123256057041623
[2019-03-24 07:11:21,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00942928], dtype=float32), 0.005596676]
[2019-03-24 07:11:21,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 65.0, 1.0, 2.0, 0.1827126594916472, 1.0, 2.0, 0.1827126594916472, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454688.1008646925, 454688.100864693, 156361.66359891]
[2019-03-24 07:11:21,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:11:21,061] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2243115e-07 1.1785029e-06 5.1397262e-07 9.9998331e-01 1.4365377e-05], sampled 0.8034025771372726
[2019-03-24 07:11:25,415] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6907.5456 2495396487.2794 47.0000
[2019-03-24 07:11:26,265] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.6861 2668463605.2651 68.0000
[2019-03-24 07:11:26,524] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3875 2465957027.8405 46.0000
[2019-03-24 07:11:26,599] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 07:11:26,764] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5694 2410739079.4483 22.0000
[2019-03-24 07:11:27,780] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 825000, evaluation results [825000.0, 7521.686098672169, 2668463605.2651095, 68.0, 7121.435945869477, 2438873699.591536, 34.0, 7797.569400512738, 2410739079.4482546, 22.0, 6907.545580254984, 2495396487.27943, 47.0, 7478.387514501627, 2465957027.8405285, 46.0]
[2019-03-24 07:11:30,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5570039e-08 1.6872235e-08 3.0868338e-07 9.9999797e-01 1.6384760e-06], sum to 1.0000
[2019-03-24 07:11:30,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9446
[2019-03-24 07:11:30,411] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.8, 81.66666666666667, 1.0, 2.0, 0.1905233214166776, 1.0, 2.0, 0.1905233214166776, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473044.4377594563, 473044.4377594568, 157962.0329152295], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7114200.0000, 
sim time next is 7114800.0000, 
raw observation next is [20.9, 81.33333333333334, 1.0, 2.0, 0.2681493040448312, 1.0, 2.0, 0.2681493040448312, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664506.3975472844, 664506.3975472848, 175099.2204948778], 
processed observation next is [1.0, 0.34782608695652173, 0.32962962962962955, 0.8133333333333335, 1.0, 1.0, 0.12874917148194193, 1.0, 1.0, 0.12874917148194193, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23732371340974442, 0.2373237134097446, 0.33672927018245735], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.5270731], dtype=float32), 0.06443337]. 
=============================================
[2019-03-24 07:11:36,061] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4936950e-06 2.4591711e-06 2.6656246e-06 9.9977821e-01 2.1510913e-04], sum to 1.0000
[2019-03-24 07:11:36,071] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0753
[2019-03-24 07:11:36,074] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.61666666666667, 84.83333333333334, 1.0, 2.0, 0.1871125864727297, 1.0, 2.0, 0.1871125864727297, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463442.7697381815, 463442.7697381815, 157222.1771203793], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7264200.0000, 
sim time next is 7264800.0000, 
raw observation next is [20.6, 85.0, 1.0, 2.0, 0.1870482192297443, 1.0, 2.0, 0.1870482192297443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463253.4410386446, 463253.4410386451, 157207.7991281645], 
processed observation next is [1.0, 0.08695652173913043, 0.3185185185185186, 0.85, 1.0, 1.0, 0.03220026098779082, 1.0, 1.0, 0.03220026098779082, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16544765751380164, 0.16544765751380183, 0.3023226906310856], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.45847133], dtype=float32), 0.034695055]. 
=============================================
[2019-03-24 07:11:40,097] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8894743e-07 1.8535939e-06 1.9202535e-06 9.9998677e-01 9.0930544e-06], sum to 1.0000
[2019-03-24 07:11:40,106] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-24 07:11:40,109] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.21666666666667, 96.0, 1.0, 2.0, 0.1857436871372909, 1.0, 2.0, 0.1857436871372909, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460442.8929499286, 460442.8929499286, 156946.4343445412], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7368600.0000, 
sim time next is 7369200.0000, 
raw observation next is [19.2, 96.0, 1.0, 2.0, 0.1891549949065384, 1.0, 2.0, 0.1891549949065384, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 468979.2119544508, 468979.2119544512, 157661.0200399523], 
processed observation next is [1.0, 0.30434782608695654, 0.26666666666666666, 0.96, 1.0, 1.0, 0.03470832726968856, 1.0, 1.0, 0.03470832726968856, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16749257569801815, 0.1674925756980183, 0.3031942693076006], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.3897072], dtype=float32), -1.1798254]. 
=============================================
[2019-03-24 07:11:42,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1371542e-06 4.1520329e-06 3.3026913e-07 9.9998951e-01 2.9050591e-06], sum to 1.0000
[2019-03-24 07:11:42,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8516
[2019-03-24 07:11:42,463] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 85.5, 1.0, 2.0, 0.1970104077935823, 1.0, 2.0, 0.1970104077935823, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485211.8978875158, 485211.8978875158, 159205.2299176122], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7345800.0000, 
sim time next is 7346400.0000, 
raw observation next is [20.86666666666667, 85.33333333333334, 1.0, 2.0, 0.1958814721322169, 1.0, 2.0, 0.1958814721322169, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 482818.7871124611, 482818.7871124616, 158980.6772992474], 
processed observation next is [1.0, 0.0, 0.3283950617283952, 0.8533333333333334, 1.0, 1.0, 0.04271603825263917, 1.0, 1.0, 0.04271603825263917, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17243528111159326, 0.17243528111159342, 0.30573207172932193], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.51451737], dtype=float32), 0.36120972]. 
=============================================
[2019-03-24 07:11:45,159] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2758173e-06 2.3639286e-05 8.3390578e-06 9.9996161e-01 5.1850830e-06], sum to 1.0000
[2019-03-24 07:11:45,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-24 07:11:45,171] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.5554015028221434, 1.0, 2.0, 0.5554015028221434, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1305058.974232873, 1305058.974232873, 254828.2246681509], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7318200.0000, 
sim time next is 7318800.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.5181796693076478, 1.0, 2.0, 0.5181796693076478, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1218471.075253907, 1218471.075253907, 242749.1100066867], 
processed observation next is [1.0, 0.7391304347826086, 0.5518518518518518, 0.61, 1.0, 1.0, 0.42640436822339023, 1.0, 1.0, 0.42640436822339023, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4351682411621096, 0.4351682411621096, 0.4668252115513206], 
reward next is 0.5332, 
noisyNet noise sample is [array([0.7773976], dtype=float32), -0.96215063]. 
=============================================
[2019-03-24 07:11:50,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8325334e-06 1.4847093e-06 7.8044138e-08 9.9999082e-01 3.7787365e-06], sum to 1.0000
[2019-03-24 07:11:50,961] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4569
[2019-03-24 07:11:50,966] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 67.33333333333333, 1.0, 2.0, 0.2835062027741669, 1.0, 2.0, 0.2835062027741669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651426.3207557809, 651426.3207557809, 176813.4401413588], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7563000.0000, 
sim time next is 7563600.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.2858721136108377, 1.0, 2.0, 0.2858721136108377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 655585.9463034619, 655585.9463034624, 177307.2955517736], 
processed observation next is [0.0, 0.5652173913043478, 0.5925925925925926, 0.66, 1.0, 1.0, 0.1498477542986163, 1.0, 1.0, 0.1498477542986163, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23413783796552212, 0.2341378379655223, 0.3409755683687954], 
reward next is 0.6590, 
noisyNet noise sample is [array([-0.95911515], dtype=float32), -0.36825615]. 
=============================================
[2019-03-24 07:11:51,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3726676e-06 2.0715603e-05 6.3987372e-06 9.9991775e-01 4.9764196e-05], sum to 1.0000
[2019-03-24 07:11:51,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6247
[2019-03-24 07:11:51,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.2212003150433047, 1.0, 2.0, 0.2212003150433047, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533990.1053613863, 533990.1053613867, 164015.1311433844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7529400.0000, 
sim time next is 7530000.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.2209365517504825, 1.0, 2.0, 0.2209365517504825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533357.3265483236, 533357.3265483236, 163958.1032575911], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.07254351398866964, 1.0, 1.0, 0.07254351398866964, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19048475948154414, 0.19048475948154414, 0.31530404472613677], 
reward next is 0.6847, 
noisyNet noise sample is [array([-1.2314562], dtype=float32), 0.28094903]. 
=============================================
[2019-03-24 07:11:51,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.7994  ]
 [67.75276 ]
 [67.81186 ]
 [67.853035]
 [67.82922 ]], R is [[67.9265213 ]
 [67.93183899]
 [67.9370575 ]
 [67.942276  ]
 [67.9474411 ]].
[2019-03-24 07:11:52,526] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0643770e-08 6.9853891e-06 2.5379302e-07 9.9998748e-01 5.1376092e-06], sum to 1.0000
[2019-03-24 07:11:52,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7387
[2019-03-24 07:11:52,539] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.18333333333333, 94.33333333333334, 1.0, 2.0, 0.2217407438502643, 1.0, 2.0, 0.2217407438502643, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534754.4986671214, 534754.4986671214, 164112.1958533221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7546200.0000, 
sim time next is 7546800.0000, 
raw observation next is [21.36666666666667, 93.66666666666667, 1.0, 2.0, 0.2241587993474501, 1.0, 2.0, 0.2241587993474501, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 539650.2029755566, 539650.2029755566, 164602.5144717284], 
processed observation next is [0.0, 0.34782608695652173, 0.3469135802469137, 0.9366666666666668, 1.0, 1.0, 0.07637952303267867, 1.0, 1.0, 0.07637952303267867, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19273221534841306, 0.19273221534841306, 0.3165432970610162], 
reward next is 0.6835, 
noisyNet noise sample is [array([-0.8508534], dtype=float32), -1.5004561]. 
=============================================
[2019-03-24 07:12:02,232] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5084049e-07 1.4502005e-04 7.4480471e-05 9.9973279e-01 4.7497058e-05], sum to 1.0000
[2019-03-24 07:12:02,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7319
[2019-03-24 07:12:02,244] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.26666666666667, 71.5, 1.0, 2.0, 0.1868766114541456, 1.0, 2.0, 0.1868766114541456, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463768.0554727734, 463768.0554727738, 157198.5414384817], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7769400.0000, 
sim time next is 7770000.0000, 
raw observation next is [22.13333333333333, 72.0, 1.0, 2.0, 0.1865163262551211, 1.0, 2.0, 0.1865163262551211, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463228.8661981116, 463228.866198112, 157132.7604993769], 
processed observation next is [1.0, 0.9565217391304348, 0.3753086419753085, 0.72, 1.0, 1.0, 0.03156705506562035, 1.0, 1.0, 0.03156705506562035, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16543888078503988, 0.16543888078504002, 0.3021783855757248], 
reward next is 0.6978, 
noisyNet noise sample is [array([-1.3137653], dtype=float32), -0.6682776]. 
=============================================
[2019-03-24 07:12:02,256] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.281292]
 [63.313812]
 [63.274555]
 [63.319992]
 [63.386276]], R is [[63.28003693]
 [63.34493256]
 [63.40892792]
 [63.47158051]
 [63.53300095]].
[2019-03-24 07:12:04,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:04,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:04,858] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-24 07:12:06,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:06,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:06,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-24 07:12:07,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0449091e-07 4.8940120e-07 4.9561044e-07 9.9998236e-01 1.6514419e-05], sum to 1.0000
[2019-03-24 07:12:07,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0643
[2019-03-24 07:12:07,931] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.9, 75.5, 1.0, 2.0, 0.2426599205028385, 1.0, 2.0, 0.2426599205028385, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599453.0694460467, 599453.0694460472, 169179.5044552398], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7889400.0000, 
sim time next is 7890000.0000, 
raw observation next is [22.03333333333333, 74.66666666666667, 1.0, 2.0, 0.205903630145068, 1.0, 2.0, 0.205903630145068, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508886.7422677322, 508886.7422677326, 161131.3053153912], 
processed observation next is [1.0, 0.30434782608695654, 0.37160493827160485, 0.7466666666666667, 1.0, 1.0, 0.054647178744128555, 1.0, 1.0, 0.054647178744128555, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18174526509561864, 0.1817452650956188, 0.30986789483729077], 
reward next is 0.6901, 
noisyNet noise sample is [array([-0.16720018], dtype=float32), -1.5083599]. 
=============================================
[2019-03-24 07:12:07,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.328278]
 [62.396225]
 [62.577053]
 [62.899807]
 [63.00263 ]], R is [[62.59088135]
 [62.63962936]
 [62.69021606]
 [62.73773956]
 [62.79856491]].
[2019-03-24 07:12:09,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4478083e-10 1.4104769e-06 6.0507477e-06 9.9999213e-01 3.5560220e-07], sum to 1.0000
[2019-03-24 07:12:09,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7047
[2019-03-24 07:12:09,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666667, 54.66666666666667, 1.0, 2.0, 0.2540642029455502, 1.0, 2.0, 0.2540642029455502, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598684.9647947743, 598684.9647947743, 170749.2113746476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7928400.0000, 
sim time next is 7929000.0000, 
raw observation next is [28.45, 55.5, 1.0, 2.0, 0.253479521248068, 1.0, 2.0, 0.253479521248068, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597734.3183553835, 597734.3183553835, 170635.2805372262], 
processed observation next is [1.0, 0.782608695652174, 0.6092592592592593, 0.555, 1.0, 1.0, 0.1112851443429381, 1.0, 1.0, 0.1112851443429381, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2134765422697798, 0.2134765422697798, 0.32814477026389655], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.5494829], dtype=float32), -1.1868382]. 
=============================================
[2019-03-24 07:12:09,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.01073 ]
 [70.179245]
 [70.63676 ]
 [70.72911 ]
 [70.88202 ]], R is [[69.81407166]
 [69.78756714]
 [69.7615509 ]
 [69.73596191]
 [69.71048737]].
[2019-03-24 07:12:09,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:09,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:09,974] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-24 07:12:10,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:10,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:10,277] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-24 07:12:11,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:11,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:11,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-24 07:12:11,871] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:11,871] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:11,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-24 07:12:11,948] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:11,949] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:11,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-24 07:12:12,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:12,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:12,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-24 07:12:12,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:12,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:12,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-24 07:12:13,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7607385e-07 1.6782388e-04 2.7401253e-05 9.9978739e-01 1.6693277e-05], sum to 1.0000
[2019-03-24 07:12:13,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0932
[2019-03-24 07:12:13,029] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.86666666666667, 38.16666666666667, 1.0, 2.0, 0.5614010084222754, 1.0, 2.0, 0.5614010084222754, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1356743.988578918, 1356743.988578919, 258260.1512160154], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 58200.0000, 
sim time next is 58800.0000, 
raw observation next is [29.83333333333333, 38.33333333333334, 1.0, 2.0, 0.5546823519939128, 1.0, 2.0, 0.5546823519939128, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1340294.921889279, 1340294.921889279, 255996.5239468424], 
processed observation next is [1.0, 0.6956521739130435, 0.6604938271604937, 0.3833333333333334, 1.0, 1.0, 0.4698599428498962, 1.0, 1.0, 0.4698599428498962, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47867675781759966, 0.47867675781759966, 0.49230100759008155], 
reward next is 0.5077, 
noisyNet noise sample is [array([0.19419624], dtype=float32), 0.9022612]. 
=============================================
[2019-03-24 07:12:13,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:13,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:13,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-24 07:12:13,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:13,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:13,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-24 07:12:13,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:13,242] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:13,255] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-24 07:12:13,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:13,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:13,667] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-24 07:12:14,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7182508e-06 2.3575160e-07 9.8321827e-08 9.9999762e-01 3.5977254e-07], sum to 1.0000
[2019-03-24 07:12:14,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0099
[2019-03-24 07:12:14,201] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.03333333333334, 9.333333333333334, 1.0, 2.0, 0.1947555488486667, 1.0, 2.0, 0.1947555488486667, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500161.5197685089, 500161.5197685094, 159061.0807684199], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 152400.0000, 
sim time next is 153000.0000, 
raw observation next is [34.75, 10.0, 1.0, 2.0, 0.1932196086084632, 1.0, 2.0, 0.1932196086084632, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495983.6781783893, 495983.6781783898, 158740.3931156684], 
processed observation next is [1.0, 0.782608695652174, 0.8425925925925926, 0.1, 1.0, 1.0, 0.03954715310531334, 1.0, 1.0, 0.03954715310531334, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17713702792085334, 0.1771370279208535, 0.3052699867609008], 
reward next is 0.6947, 
noisyNet noise sample is [array([-0.58193755], dtype=float32), 0.34388903]. 
=============================================
[2019-03-24 07:12:14,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.71457 ]
 [65.82445 ]
 [66.340775]
 [66.39186 ]
 [66.52701 ]], R is [[65.62660217]
 [65.6644516 ]
 [65.70056915]
 [65.73679352]
 [65.7720871 ]].
[2019-03-24 07:12:14,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:14,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:14,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-24 07:12:15,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:15,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:15,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-24 07:12:15,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:12:15,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:15,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-24 07:12:16,198] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 07:12:16,201] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:12:16,201] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:12:16,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,202] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:12:16,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:12:16,205] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,202] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,206] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:12:16,207] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,206] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,217] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-24 07:12:16,241] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-24 07:12:16,266] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-24 07:12:16,266] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-24 07:12:16,328] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-24 07:12:44,009] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00940735], dtype=float32), 0.00613969]
[2019-03-24 07:12:44,011] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.016079945, 62.146866765, 1.0, 2.0, 0.2294100064878983, 1.0, 2.0, 0.2294100064878983, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553034.0272512218, 553034.0272512223, 165778.4182191783]
[2019-03-24 07:12:44,013] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:12:44,016] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0823030e-07 8.7834098e-07 3.6400721e-07 9.9999380e-01 4.7566873e-06], sampled 0.010087061139012143
[2019-03-24 07:12:55,795] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00940735], dtype=float32), 0.00613969]
[2019-03-24 07:12:55,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 59.0, 1.0, 2.0, 0.3345151030176292, 1.0, 2.0, 0.3345151030176292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935537, 188950.1021701645]
[2019-03-24 07:12:55,797] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:12:55,799] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.13017016e-07 5.08347512e-07 1.99582331e-07 9.99996305e-01
 2.83779900e-06], sampled 0.9368735855795305
[2019-03-24 07:13:22,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00940735], dtype=float32), 0.00613969]
[2019-03-24 07:13:22,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.16666666666667, 90.66666666666666, 1.0, 2.0, 0.3875411441483678, 1.0, 2.0, 0.3875411441483678, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 883423.8632069572, 883423.8632069577, 202796.7219879826]
[2019-03-24 07:13:22,937] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:13:22,942] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8013127e-07 7.7776826e-07 3.1557994e-07 9.9999440e-01 4.3411060e-06], sampled 0.44013217135187455
[2019-03-24 07:14:04,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:14:04,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5310 2410758929.7108 22.0000
[2019-03-24 07:14:04,944] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 07:14:04,945] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668561410.2358 68.0000
[2019-03-24 07:14:05,140] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6534 2465958740.4841 46.0000
[2019-03-24 07:14:06,155] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 850000, evaluation results [850000.0, 7523.01586001269, 2668561410.235784, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7797.530965338176, 2410758929.7107716, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.6533711920765, 2465958740.484093, 46.0]
[2019-03-24 07:14:07,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4694509e-07 1.2017582e-05 5.2071450e-06 9.9996459e-01 1.7405884e-05], sum to 1.0000
[2019-03-24 07:14:07,869] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0655
[2019-03-24 07:14:07,872] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 10.0, 1.0, 2.0, 0.176324300662668, 1.0, 2.0, 0.176324300662668, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454925.6274993494, 454925.6274993498, 140610.1286939211], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 169200.0000, 
sim time next is 169800.0000, 
raw observation next is [30.65, 10.33333333333333, 1.0, 2.0, 0.1756841979948275, 1.0, 2.0, 0.1756841979948275, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453273.6420878447, 453273.6420878452, 140166.8712568842], 
processed observation next is [1.0, 1.0, 0.6907407407407407, 0.1033333333333333, 1.0, 1.0, 0.01867166427955656, 1.0, 1.0, 0.01867166427955656, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16188344360280169, 0.16188344360280185, 0.26955167549400805], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.6110379], dtype=float32), 0.22659592]. 
=============================================
[2019-03-24 07:14:09,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1574614e-07 8.2960039e-05 9.3403105e-07 9.9989367e-01 2.1903455e-05], sum to 1.0000
[2019-03-24 07:14:09,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5974
[2019-03-24 07:14:09,431] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 48.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 350528.4930086173, 350528.4930086177, 135190.1846412239], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 263400.0000, 
sim time next is 264000.0000, 
raw observation next is [21.5, 48.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347259.913176196, 347259.9131761965, 133676.8408395369], 
processed observation next is [0.0, 0.043478260869565216, 0.35185185185185186, 0.4866666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12402139756292714, 0.12402139756292732, 0.25707084776834016], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2464318], dtype=float32), 0.7607442]. 
=============================================
[2019-03-24 07:14:09,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.06735 ]
 [57.95922 ]
 [57.58218 ]
 [57.854084]
 [57.559307]], R is [[57.79539871]
 [57.21744537]
 [56.6452713 ]
 [56.07881927]
 [55.51803207]].
[2019-03-24 07:14:11,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.84984718e-06 1.03908942e-05 1.25904298e-05 9.99855161e-01
 1.16020834e-04], sum to 1.0000
[2019-03-24 07:14:11,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3055
[2019-03-24 07:14:11,116] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.25, 19.5, 1.0, 2.0, 0.5851689396343487, 1.0, 2.0, 0.5851689396343487, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1414565.724532063, 1414565.724532063, 266383.5316872178], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 135000.0000, 
sim time next is 135600.0000, 
raw observation next is [36.63333333333333, 18.0, 1.0, 2.0, 0.6111766177971842, 1.0, 2.0, 0.6111766177971842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1480377.265555342, 1480377.265555342, 275586.7754165134], 
processed observation next is [1.0, 0.5652173913043478, 0.9123456790123456, 0.18, 1.0, 1.0, 0.5371150211871241, 1.0, 1.0, 0.5371150211871241, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.528706166269765, 0.528706166269765, 0.5299745681086796], 
reward next is 0.4700, 
noisyNet noise sample is [array([-0.28519344], dtype=float32), -0.7680218]. 
=============================================
[2019-03-24 07:14:13,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9770849e-07 3.1090170e-07 5.9549353e-07 9.9998987e-01 8.6119580e-06], sum to 1.0000
[2019-03-24 07:14:13,810] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5836
[2019-03-24 07:14:13,813] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.06666666666667, 56.00000000000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 317541.3434937785, 317541.3434937785, 126251.9989461887], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 192000.0000, 
sim time next is 192600.0000, 
raw observation next is [20.25, 57.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 319345.2341425883, 319345.2341425883, 130120.6917891224], 
processed observation next is [0.0, 0.21739130434782608, 0.3055555555555556, 0.57, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11405186933663868, 0.11405186933663868, 0.25023209959446613], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19369589], dtype=float32), 1.1568584]. 
=============================================
[2019-03-24 07:14:25,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2228996e-05 3.2000738e-04 1.0558657e-05 9.9841845e-01 1.2287602e-03], sum to 1.0000
[2019-03-24 07:14:25,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0231
[2019-03-24 07:14:25,555] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.85, 31.0, 1.0, 2.0, 0.1913721967473141, 1.0, 2.0, 0.1913721967473141, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469316.1816520071, 469316.1816520075, 157967.8527836822], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 581400.0000, 
sim time next is 582000.0000, 
raw observation next is [31.7, 31.33333333333334, 1.0, 2.0, 0.1911485772370554, 1.0, 2.0, 0.1911485772370554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469154.5109029746, 469154.510902975, 157933.979068151], 
processed observation next is [1.0, 0.7391304347826086, 0.7296296296296296, 0.3133333333333334, 1.0, 1.0, 0.03708163956792308, 1.0, 1.0, 0.03708163956792308, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16755518246534806, 0.1675551824653482, 0.30371919051567503], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.37594378], dtype=float32), -0.77393425]. 
=============================================
[2019-03-24 07:14:25,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.170563]
 [59.024963]
 [57.760174]
 [55.741863]
 [55.517704]], R is [[58.97687912]
 [59.08332825]
 [59.18677521]
 [59.25416946]
 [59.13781357]].
[2019-03-24 07:14:25,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.8311826e-06 1.7130522e-05 3.8427052e-06 9.9993384e-01 3.6363948e-05], sum to 1.0000
[2019-03-24 07:14:25,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-24 07:14:25,974] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.78333333333333, 43.83333333333334, 1.0, 2.0, 0.4698270628659647, 1.0, 2.0, 0.4698270628659647, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1160528.03503912, 1160528.03503912, 229605.1070321109], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 467400.0000, 
sim time next is 468000.0000, 
raw observation next is [27.1, 43.0, 1.0, 2.0, 0.4859404157201352, 1.0, 2.0, 0.4859404157201352, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1198045.705688767, 1198045.705688767, 234530.0521395837], 
processed observation next is [1.0, 0.43478260869565216, 0.5592592592592593, 0.43, 1.0, 1.0, 0.3880243044287324, 1.0, 1.0, 0.3880243044287324, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.42787346631741674, 0.42787346631741674, 0.451019331037661], 
reward next is 0.5490, 
noisyNet noise sample is [array([1.2922345], dtype=float32), -1.461475]. 
=============================================
[2019-03-24 07:14:25,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[49.762917]
 [49.517982]
 [49.28436 ]
 [49.030743]
 [48.724697]], R is [[50.06303406]
 [50.12085724]
 [50.18558121]
 [50.26567078]
 [50.34817505]].
[2019-03-24 07:14:28,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0461885e-08 1.5313085e-06 4.4310363e-07 9.9999630e-01 1.7242959e-06], sum to 1.0000
[2019-03-24 07:14:28,327] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6655
[2019-03-24 07:14:28,331] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.56666666666667, 33.0, 1.0, 2.0, 0.1763152979834488, 1.0, 2.0, 0.1763152979834488, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 440273.863345943, 440273.8633459435, 155073.3977098659], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 501000.0000, 
sim time next is 501600.0000, 
raw observation next is [29.33333333333334, 34.0, 1.0, 2.0, 0.1752462322590833, 1.0, 2.0, 0.1752462322590833, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437403.2762807363, 437403.2762807363, 154848.0949508866], 
processed observation next is [1.0, 0.8260869565217391, 0.6419753086419755, 0.34, 1.0, 1.0, 0.018150276498908702, 1.0, 1.0, 0.018150276498908702, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15621545581454868, 0.15621545581454868, 0.2977847979824742], 
reward next is 0.7022, 
noisyNet noise sample is [array([-1.6200156], dtype=float32), 0.4309841]. 
=============================================
[2019-03-24 07:14:32,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.0043210e-07 1.6546586e-05 1.7395224e-06 9.9997330e-01 7.5518042e-06], sum to 1.0000
[2019-03-24 07:14:32,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-24 07:14:32,116] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 62.66666666666667, 1.0, 2.0, 0.2439498026589847, 1.0, 2.0, 0.2439498026589847, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612657.8134748919, 612657.8134748919, 169691.2016702749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 546000.0000, 
sim time next is 546600.0000, 
raw observation next is [22.6, 61.83333333333334, 1.0, 2.0, 0.2431621486803658, 1.0, 2.0, 0.2431621486803658, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 610325.6266807457, 610325.6266807462, 169506.5549063403], 
processed observation next is [1.0, 0.30434782608695654, 0.39259259259259266, 0.6183333333333334, 1.0, 1.0, 0.09900255795281644, 1.0, 1.0, 0.09900255795281644, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21797343810026634, 0.2179734381002665, 0.3259741440506544], 
reward next is 0.6740, 
noisyNet noise sample is [array([-2.2808144], dtype=float32), -1.049964]. 
=============================================
[2019-03-24 07:14:32,940] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7349157e-07 1.6506074e-05 8.5567817e-06 9.9991477e-01 5.9939950e-05], sum to 1.0000
[2019-03-24 07:14:32,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-24 07:14:32,959] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.2, 73.0, 1.0, 2.0, 0.1671628387626095, 1.0, 2.0, 0.1671628387626095, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423802.9791165702, 423802.9791165707, 153319.7382353472], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 529200.0000, 
sim time next is 529800.0000, 
raw observation next is [20.11666666666667, 73.5, 1.0, 2.0, 0.1863789996238509, 1.0, 2.0, 0.1863789996238509, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472470.4378310318, 472470.4378310322, 157291.9559258861], 
processed observation next is [1.0, 0.13043478260869565, 0.30061728395061743, 0.735, 1.0, 1.0, 0.031403570980774884, 1.0, 1.0, 0.031403570980774884, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16873944208251135, 0.16873944208251151, 0.30248453062670405], 
reward next is 0.6975, 
noisyNet noise sample is [array([1.463953], dtype=float32), 0.54169476]. 
=============================================
[2019-03-24 07:14:34,560] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1788638e-07 2.4399392e-06 2.2297542e-07 9.9999690e-01 8.7229957e-08], sum to 1.0000
[2019-03-24 07:14:34,565] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5978
[2019-03-24 07:14:34,570] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.65, 38.5, 1.0, 2.0, 0.6357925910164247, 1.0, 2.0, 0.6357925910164247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1516502.002323612, 1516502.002323612, 283575.6756830607], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 642600.0000, 
sim time next is 643200.0000, 
raw observation next is [31.0, 37.66666666666667, 1.0, 2.0, 0.6055169733795261, 1.0, 2.0, 0.6055169733795261, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1442776.486180793, 1442776.486180794, 272721.4851558193], 
processed observation next is [1.0, 0.43478260869565216, 0.7037037037037037, 0.3766666666666667, 1.0, 1.0, 0.5303773492613406, 1.0, 1.0, 0.5303773492613406, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5152773164931403, 0.5152773164931407, 0.5244643945304217], 
reward next is 0.4755, 
noisyNet noise sample is [array([0.47538683], dtype=float32), -0.52865005]. 
=============================================
[2019-03-24 07:14:37,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.0731425e-08 2.0375830e-06 5.2156702e-06 9.9999249e-01 2.4859489e-07], sum to 1.0000
[2019-03-24 07:14:37,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3951
[2019-03-24 07:14:37,177] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.36666666666667, 17.33333333333334, 1.0, 2.0, 0.2974375620678816, 1.0, 2.0, 0.2974375620678816, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 734199.8958716878, 734199.8958716883, 182059.1179752483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 666600.0000, 
sim time next is 667200.0000, 
raw observation next is [35.13333333333334, 17.66666666666667, 1.0, 2.0, 0.2078164969234734, 1.0, 2.0, 0.2078164969234734, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 517133.9881786137, 517133.9881786142, 161629.1513120753], 
processed observation next is [1.0, 0.7391304347826086, 0.8567901234567904, 0.17666666666666672, 1.0, 1.0, 0.05692440109937309, 1.0, 1.0, 0.05692440109937309, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18469071006379062, 0.1846907100637908, 0.3108252909847602], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.5667329], dtype=float32), -0.07794517]. 
=============================================
[2019-03-24 07:14:47,649] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.3154583e-08 8.9623870e-07 2.6255503e-07 9.9997449e-01 2.4166400e-05], sum to 1.0000
[2019-03-24 07:14:47,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7983
[2019-03-24 07:14:47,661] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.73333333333333, 65.33333333333333, 1.0, 2.0, 0.1788686108294333, 1.0, 2.0, 0.1788686108294333, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446791.7393445487, 446791.7393445491, 155604.9438243966], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 895200.0000, 
sim time next is 895800.0000, 
raw observation next is [22.86666666666667, 65.16666666666667, 1.0, 2.0, 0.1803727553022695, 1.0, 2.0, 0.1803727553022695, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449963.6903938617, 449963.6903938621, 155902.9008826382], 
processed observation next is [0.0, 0.34782608695652173, 0.4024691358024693, 0.6516666666666667, 1.0, 1.0, 0.024253280121749415, 1.0, 1.0, 0.024253280121749415, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16070131799780774, 0.16070131799780787, 0.2998132709281504], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.6303759], dtype=float32), -0.19367023]. 
=============================================
[2019-03-24 07:14:49,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5637887e-06 1.5273609e-07 7.5987509e-07 9.9999142e-01 5.1688016e-06], sum to 1.0000
[2019-03-24 07:14:49,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5153
[2019-03-24 07:14:49,983] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.7, 70.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394907.3273808458, 394907.3273808463, 150300.5728580232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1113600.0000, 
sim time next is 1114200.0000, 
raw observation next is [20.55, 70.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393141.887761579, 393141.8877615795, 149994.6579125962], 
processed observation next is [1.0, 0.9130434782608695, 0.3166666666666667, 0.705, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1404078170577068, 0.14040781705770697, 0.28845126521653114], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55119437], dtype=float32), 1.1176397]. 
=============================================
[2019-03-24 07:14:50,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9879701e-06 9.7757202e-06 1.4023132e-05 9.9973732e-01 2.3694728e-04], sum to 1.0000
[2019-03-24 07:14:50,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2804
[2019-03-24 07:14:50,643] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 356301.6846647687, 356301.6846647692, 144075.2470882389], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1126800.0000, 
sim time next is 1127400.0000, 
raw observation next is [19.18333333333333, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 355117.9015901437, 355117.9015901437, 143891.5623215272], 
processed observation next is [1.0, 0.043478260869565216, 0.2660493827160493, 0.74, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12682782199647988, 0.12682782199647988, 0.27671454292601383], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.96012], dtype=float32), -0.8771013]. 
=============================================
[2019-03-24 07:14:52,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3866241e-07 8.4122303e-06 4.1368889e-06 9.9997473e-01 1.1991064e-05], sum to 1.0000
[2019-03-24 07:14:52,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2647
[2019-03-24 07:14:52,685] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.71666666666667, 47.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 373448.2280913516, 373448.228091352, 146758.6458987748], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1021800.0000, 
sim time next is 1022400.0000, 
raw observation next is [24.2, 44.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367218.2193331146, 367218.219333115, 145745.0973013996], 
processed observation next is [1.0, 0.8695652173913043, 0.45185185185185184, 0.44, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13114936404754093, 0.13114936404754107, 0.28027903327192233], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2021579], dtype=float32), 2.3629675]. 
=============================================
[2019-03-24 07:14:53,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1142610e-05 2.6696733e-05 1.0612469e-04 9.9930429e-01 4.7176561e-04], sum to 1.0000
[2019-03-24 07:14:53,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6782
[2019-03-24 07:14:53,606] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.13333333333333, 49.66666666666667, 1.0, 2.0, 0.1883393734138694, 1.0, 2.0, 0.1883393734138694, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466969.4616661393, 466969.4616661398, 157492.7896073075], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 933000.0000, 
sim time next is 933600.0000, 
raw observation next is [25.96666666666667, 50.33333333333334, 1.0, 2.0, 0.1878362233302355, 1.0, 2.0, 0.1878362233302355, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465887.3678392748, 465887.3678392748, 157392.8228145827], 
processed observation next is [0.0, 0.8260869565217391, 0.517283950617284, 0.5033333333333334, 1.0, 1.0, 0.033138361107423214, 1.0, 1.0, 0.033138361107423214, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16638834565688387, 0.16638834565688387, 0.30267850541265906], 
reward next is 0.6973, 
noisyNet noise sample is [array([2.762197], dtype=float32), 0.35308316]. 
=============================================
[2019-03-24 07:14:53,950] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 07:14:53,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:14:53,953] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:53,954] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:14:53,955] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:53,955] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:14:53,957] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:14:53,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:14:53,958] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:53,959] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:53,960] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:53,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-24 07:14:54,004] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-24 07:14:54,033] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-24 07:14:54,034] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-24 07:14:54,096] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-24 07:15:05,066] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:15:05,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 387782.5609744489, 387782.5609744494, 149222.9858628557]
[2019-03-24 07:15:05,068] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:15:05,073] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7171697e-06 5.3849417e-06 2.2679742e-06 9.9997568e-01 1.5027131e-05], sampled 0.9499759210761762
[2019-03-24 07:15:45,632] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:15:45,633] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.93333333333333, 67.0, 1.0, 2.0, 0.8220696551466528, 1.0, 2.0, 0.8220696551466528, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1875119.554882132, 1875119.554882132, 352959.4459999232]
[2019-03-24 07:15:45,634] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:15:45,636] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.6832063e-07 2.8806965e-06 1.1802842e-06 9.9998689e-01 8.2146644e-06], sampled 0.39695049877162003
[2019-03-24 07:15:51,168] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:15:51,170] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.8, 86.33333333333334, 1.0, 2.0, 0.3534631991126995, 1.0, 2.0, 0.3534631991126995, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805700.2611628551, 805700.2611628551, 193786.0875367936]
[2019-03-24 07:15:51,171] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:15:51,176] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0313546e-06 6.3536322e-06 2.6969915e-06 9.9997342e-01 1.5439715e-05], sampled 0.7453190290288926
[2019-03-24 07:15:56,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:15:56,692] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.32926422166667, 80.92316152333333, 1.0, 2.0, 0.237684644204719, 1.0, 2.0, 0.237684644204719, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 568492.7291508918, 568492.7291508922, 167435.9448563543]
[2019-03-24 07:15:56,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:15:56,697] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1852861e-06 6.7758920e-06 2.9013686e-06 9.9997151e-01 1.6624632e-05], sampled 0.6002633860954295
[2019-03-24 07:16:01,337] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:16:01,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 92.33333333333334, 1.0, 2.0, 0.3139551506374245, 1.0, 2.0, 0.3139551506374245, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715601.7624871001, 715601.7624871006, 183843.5818038674]
[2019-03-24 07:16:01,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:16:01,343] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5281611e-06 7.7416116e-06 3.3223021e-06 9.9996781e-01 1.8543818e-05], sampled 0.6050456402747755
[2019-03-24 07:16:18,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:16:18,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.408375675, 60.35515024, 1.0, 2.0, 0.3406924211405825, 1.0, 2.0, 0.3406924211405825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 776575.2162073592, 776575.2162073597, 190513.4649502358]
[2019-03-24 07:16:18,954] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:16:18,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.4340463e-06 1.2772045e-05 5.7207944e-06 9.9994814e-01 2.8978349e-05], sampled 0.7046252975399205
[2019-03-24 07:16:22,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00929436], dtype=float32), 0.0060096267]
[2019-03-24 07:16:22,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.25, 87.66666666666667, 1.0, 2.0, 0.2692762018530793, 1.0, 2.0, 0.2692762018530793, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 622415.6633479374, 622415.6633479379, 173686.1215735119]
[2019-03-24 07:16:22,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:16:22,931] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.3756648e-07 3.0854878e-06 1.2539219e-06 9.9998569e-01 9.0552112e-06], sampled 0.13995638582355152
[2019-03-24 07:16:41,886] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 07:16:42,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495478653.7976 47.0000
[2019-03-24 07:16:42,464] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8367 2410756474.1006 22.0000
[2019-03-24 07:16:42,470] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.2030 2466054151.0131 46.0000
[2019-03-24 07:16:42,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2611 2438818444.1480 34.0000
[2019-03-24 07:16:43,614] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 875000, evaluation results [875000.0, 7523.727130323888, 2668527814.010175, 68.0, 7122.261117668267, 2438818444.147978, 34.0, 7796.836723009689, 2410756474.1006002, 22.0, 6905.908355438081, 2495478653.797567, 47.0, 7478.202950869978, 2466054151.0130725, 46.0]
[2019-03-24 07:16:44,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8928976e-06 1.3094503e-04 1.6948181e-06 9.9984372e-01 2.0785763e-05], sum to 1.0000
[2019-03-24 07:16:44,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6089
[2019-03-24 07:16:44,780] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 50.0, 1.0, 2.0, 0.164317869110313, 1.0, 2.0, 0.164317869110313, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411516.1970969381, 411516.1970969386, 152652.8302885026], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1014000.0000, 
sim time next is 1014600.0000, 
raw observation next is [24.68333333333333, 51.5, 1.0, 2.0, 0.1655353801639259, 1.0, 2.0, 0.1655353801639259, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415363.803548023, 415363.8035480235, 152916.3515118492], 
processed observation next is [1.0, 0.7391304347826086, 0.46975308641975294, 0.515, 1.0, 1.0, 0.006589738290387985, 1.0, 1.0, 0.006589738290387985, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14834421555286537, 0.14834421555286553, 0.29406990675355615], 
reward next is 0.7059, 
noisyNet noise sample is [array([-1.4261559], dtype=float32), 0.29623246]. 
=============================================
[2019-03-24 07:16:47,574] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3158275e-04 1.9422539e-04 2.9230781e-05 9.9959415e-01 5.0724931e-05], sum to 1.0000
[2019-03-24 07:16:47,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2964
[2019-03-24 07:16:47,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347270.8559488918, 347270.8559488923, 142704.8451277902], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1134000.0000, 
sim time next is 1134600.0000, 
raw observation next is [18.96666666666667, 75.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397386.799626735, 397386.7996267354, 150091.5439287806], 
processed observation next is [1.0, 0.13043478260869565, 0.25802469135802475, 0.7516666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1419238570095482, 0.14192385700954835, 0.2886375844784242], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02006342], dtype=float32), -0.9430346]. 
=============================================
[2019-03-24 07:16:49,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0342446e-05 4.4976972e-05 2.4347353e-05 9.9967337e-01 2.1701014e-04], sum to 1.0000
[2019-03-24 07:16:49,297] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-24 07:16:49,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.83333333333333, 86.0, 1.0, 2.0, 0.1787211598608911, 1.0, 2.0, 0.1787211598608911, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446289.704179424, 446289.704179424, 155571.1257017825], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1300200.0000, 
sim time next is 1300800.0000, 
raw observation next is [19.76666666666667, 86.0, 1.0, 2.0, 0.176600118926641, 1.0, 2.0, 0.176600118926641, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441391.2680962296, 441391.2680962301, 155141.9151817043], 
processed observation next is [1.0, 0.043478260869565216, 0.2876543209876544, 0.86, 1.0, 1.0, 0.019762046341239268, 1.0, 1.0, 0.019762046341239268, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15763973860579628, 0.15763973860579647, 0.2983498368878929], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.02524786], dtype=float32), -0.5137532]. 
=============================================
[2019-03-24 07:16:55,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8782741e-07 2.6413434e-06 2.7946582e-08 9.9999630e-01 8.3239763e-07], sum to 1.0000
[2019-03-24 07:16:55,683] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7692
[2019-03-24 07:16:55,692] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.1765994885594478, 1.0, 2.0, 0.1765994885594478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441811.366940091, 441811.3669400915, 155151.6460932349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1204200.0000, 
sim time next is 1204800.0000, 
raw observation next is [18.93333333333333, 92.66666666666667, 1.0, 2.0, 0.1762098210214545, 1.0, 2.0, 0.1762098210214545, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 440785.6547891964, 440785.6547891969, 155070.0086443108], 
processed observation next is [1.0, 0.9565217391304348, 0.25679012345679, 0.9266666666666667, 1.0, 1.0, 0.019297405977922014, 1.0, 1.0, 0.019297405977922014, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15742344813899872, 0.1574234481389989, 0.2982115550852131], 
reward next is 0.7018, 
noisyNet noise sample is [array([1.3106258], dtype=float32), -0.17837338]. 
=============================================
[2019-03-24 07:17:01,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8969990e-07 4.0210696e-07 1.9913809e-05 9.9994040e-01 3.8625654e-05], sum to 1.0000
[2019-03-24 07:17:01,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3389
[2019-03-24 07:17:01,828] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 42.66666666666667, 1.0, 2.0, 0.1788935070312323, 1.0, 2.0, 0.1788935070312323, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 444885.2974389539, 444885.2974389544, 155559.9911528964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1365600.0000, 
sim time next is 1366200.0000, 
raw observation next is [27.25, 44.0, 1.0, 2.0, 0.1795295545825282, 1.0, 2.0, 0.1795295545825282, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446159.4689171146, 446159.4689171151, 155683.4705358749], 
processed observation next is [1.0, 0.8260869565217391, 0.5648148148148148, 0.44, 1.0, 1.0, 0.023249469741105, 1.0, 1.0, 0.023249469741105, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15934266747039807, 0.15934266747039827, 0.2993912894920671], 
reward next is 0.7006, 
noisyNet noise sample is [array([-0.88966686], dtype=float32), 0.6612412]. 
=============================================
[2019-03-24 07:17:03,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7265621e-06 8.7854875e-07 1.5261763e-07 9.9999285e-01 3.4641364e-06], sum to 1.0000
[2019-03-24 07:17:03,773] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0392
[2019-03-24 07:17:03,781] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 31.33333333333334, 1.0, 2.0, 0.5118244714644212, 1.0, 2.0, 0.5118244714644212, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1251953.207101441, 1251953.207101441, 242452.7147138636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1351200.0000, 
sim time next is 1351800.0000, 
raw observation next is [30.85, 31.0, 1.0, 2.0, 0.5038865330488532, 1.0, 2.0, 0.5038865330488532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1233904.285710089, 1233904.28571009, 239958.6072573215], 
processed observation next is [1.0, 0.6521739130434783, 0.6981481481481482, 0.31, 1.0, 1.0, 0.40938872982006336, 1.0, 1.0, 0.40938872982006336, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44068010203931746, 0.4406801020393179, 0.4614588601102337], 
reward next is 0.5385, 
noisyNet noise sample is [array([-0.56972384], dtype=float32), 0.43746302]. 
=============================================
[2019-03-24 07:17:10,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2208900e-06 6.8600020e-06 3.3622248e-07 9.9998677e-01 4.7685630e-06], sum to 1.0000
[2019-03-24 07:17:10,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3707
[2019-03-24 07:17:10,928] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.4802317142109481, 1.0, 2.0, 0.4802317142109481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1181300.764449236, 1181300.764449236, 232685.7053442867], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1588800.0000, 
sim time next is 1589400.0000, 
raw observation next is [24.65, 56.5, 1.0, 2.0, 0.4857274279584676, 1.0, 2.0, 0.4857274279584676, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1193224.129061286, 1193224.129061286, 234350.7028143463], 
processed observation next is [1.0, 0.391304347826087, 0.46851851851851845, 0.565, 1.0, 1.0, 0.3877707475696042, 1.0, 1.0, 0.3877707475696042, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.426151474664745, 0.426151474664745, 0.4506744284891275], 
reward next is 0.5493, 
noisyNet noise sample is [array([0.91294414], dtype=float32), -0.28078207]. 
=============================================
[2019-03-24 07:17:14,506] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8242756e-09 1.4276193e-07 2.6836264e-07 9.9999952e-01 1.4087416e-07], sum to 1.0000
[2019-03-24 07:17:14,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1601
[2019-03-24 07:17:14,522] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 48.5, 1.0, 2.0, 0.1773103009674692, 1.0, 2.0, 0.1773103009674692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 442474.4928361179, 442474.4928361183, 155271.9438176735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1626600.0000, 
sim time next is 1627200.0000, 
raw observation next is [25.7, 49.0, 1.0, 2.0, 0.1759950883510266, 1.0, 2.0, 0.1759950883510266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439350.7593225829, 439350.7593225829, 155004.3226546576], 
processed observation next is [1.0, 0.8695652173913043, 0.5074074074074074, 0.49, 1.0, 1.0, 0.019041771846460224, 1.0, 1.0, 0.019041771846460224, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15691098547235105, 0.15691098547235105, 0.2980852358743415], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.94471747], dtype=float32), 0.684818]. 
=============================================
[2019-03-24 07:17:16,520] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7035262e-07 6.7868955e-06 9.0602853e-08 9.9998617e-01 6.8368904e-06], sum to 1.0000
[2019-03-24 07:17:16,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2172
[2019-03-24 07:17:16,534] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.4, 88.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 398291.2026140668, 398291.2026140673, 150800.1946610723], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1666800.0000, 
sim time next is 1667400.0000, 
raw observation next is [18.43333333333333, 87.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 404203.7703401896, 404203.7703401901, 151678.4920622294], 
processed observation next is [1.0, 0.30434782608695654, 0.2382716049382715, 0.8766666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14435848940721058, 0.14435848940721074, 0.2916894078119796], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9929839], dtype=float32), 1.2305344]. 
=============================================
[2019-03-24 07:17:18,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4370676e-07 1.8973870e-07 3.4445343e-08 9.9999928e-01 3.0173766e-07], sum to 1.0000
[2019-03-24 07:17:18,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1329
[2019-03-24 07:17:18,557] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.03333333333333, 64.0, 1.0, 2.0, 0.161829112204638, 1.0, 2.0, 0.161829112204638, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408365.3295990556, 408365.3295990556, 152211.3399042892], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1646400.0000, 
sim time next is 1647000.0000, 
raw observation next is [21.95, 64.5, 1.0, 2.0, 0.1617098001648326, 1.0, 2.0, 0.1617098001648326, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408082.1401107759, 408082.1401107759, 152187.600647946], 
processed observation next is [1.0, 0.043478260869565216, 0.36851851851851847, 0.645, 1.0, 1.0, 0.00203547638670548, 1.0, 1.0, 0.00203547638670548, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14574362146813424, 0.14574362146813424, 0.29266846278451153], 
reward next is 0.7073, 
noisyNet noise sample is [array([2.0679607], dtype=float32), 1.233176]. 
=============================================
[2019-03-24 07:17:18,576] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.407272]
 [60.101433]
 [59.912426]
 [59.347107]
 [59.02636 ]], R is [[60.62066269]
 [60.72174454]
 [60.82197571]
 [60.92134094]
 [61.01976395]].
[2019-03-24 07:17:23,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2584398e-07 1.2435302e-06 7.8946101e-07 9.9995685e-01 4.0972911e-05], sum to 1.0000
[2019-03-24 07:17:23,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7707
[2019-03-24 07:17:23,607] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 81.0, 1.0, 2.0, 0.1858775295535796, 1.0, 2.0, 0.1858775295535796, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464088.758813089, 464088.7588130895, 157062.243562704], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1839600.0000, 
sim time next is 1840200.0000, 
raw observation next is [20.65, 80.16666666666667, 1.0, 2.0, 0.193363460398622, 1.0, 2.0, 0.193363460398622, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 482412.4538137118, 482412.4538137122, 158608.7645752997], 
processed observation next is [1.0, 0.30434782608695654, 0.3203703703703703, 0.8016666666666667, 1.0, 1.0, 0.03971840523645477, 1.0, 1.0, 0.03971840523645477, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17229016207632564, 0.1722901620763258, 0.3050168549524994], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.45112833], dtype=float32), 1.3544036]. 
=============================================
[2019-03-24 07:17:31,623] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 07:17:31,626] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:17:31,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:31,627] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:17:31,628] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:31,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:17:31,630] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:17:31,633] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:17:31,634] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:31,634] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:31,636] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:31,647] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-24 07:17:31,680] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-24 07:17:31,709] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-24 07:17:31,738] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-24 07:17:31,770] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-24 07:17:34,829] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00942339], dtype=float32), 0.0062316116]
[2019-03-24 07:17:34,831] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [12.35, 79.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 199056.8798237769, 199056.8798237774, 90038.03039933379]
[2019-03-24 07:17:34,831] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:17:34,834] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.9288247e-07 3.3065014e-06 1.0021081e-06 9.9998987e-01 4.9703062e-06], sampled 0.14436912482796782
[2019-03-24 07:17:35,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00942339], dtype=float32), 0.0062316116]
[2019-03-24 07:17:35,101] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 41.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 323053.7768871312, 323053.7768871316, 129317.6998454203]
[2019-03-24 07:17:35,101] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:17:35,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.4966299e-07 1.9825404e-06 5.7124885e-07 9.9999392e-01 3.0317292e-06], sampled 0.2002452589238708
[2019-03-24 07:18:27,001] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00942339], dtype=float32), 0.0062316116]
[2019-03-24 07:18:27,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.8, 89.66666666666667, 1.0, 2.0, 0.600476602755905, 1.0, 2.0, 0.600476602755905, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1369257.081406697, 1369257.081406697, 268206.3901440089]
[2019-03-24 07:18:27,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:18:27,008] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7443280e-07 8.4043825e-07 2.2478416e-07 9.9999750e-01 1.2966733e-06], sampled 0.8887440159692178
[2019-03-24 07:18:49,007] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00942339], dtype=float32), 0.0062316116]
[2019-03-24 07:18:49,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.58333333333334, 79.0, 1.0, 2.0, 0.3137526915300597, 1.0, 2.0, 0.3137526915300597, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715140.0797457624, 715140.0797457624, 183793.7708238225]
[2019-03-24 07:18:49,020] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:18:49,022] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2933612e-07 6.6956693e-07 1.6781865e-07 9.9999809e-01 9.8689793e-07], sampled 0.8663060659758153
[2019-03-24 07:19:19,370] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438821249.6650 34.0000
[2019-03-24 07:19:19,545] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495453487.2610 47.0000
[2019-03-24 07:19:19,660] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6534 2465987022.5647 46.0000
[2019-03-24 07:19:19,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410715229.6432 22.0000
[2019-03-24 07:19:19,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 07:19:20,950] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 900000, evaluation results [900000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438821249.664991, 34.0, 7798.23719837083, 2410715229.643247, 22.0, 6905.908355438081, 2495453487.260967, 47.0, 7477.653364256054, 2465987022.564663, 46.0]
[2019-03-24 07:19:21,612] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8698296e-06 3.7949455e-06 1.3794150e-06 9.9997675e-01 1.6249598e-05], sum to 1.0000
[2019-03-24 07:19:21,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-24 07:19:21,623] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.25, 90.83333333333334, 1.0, 2.0, 0.2190543957093246, 1.0, 2.0, 0.2190543957093246, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539390.7833547582, 539390.7833547586, 163902.3862826866], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1926600.0000, 
sim time next is 1927200.0000, 
raw observation next is [20.3, 90.66666666666667, 1.0, 2.0, 0.2042447259758445, 1.0, 2.0, 0.2042447259758445, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 502676.4447020435, 502676.444702044, 160718.3111486819], 
processed observation next is [1.0, 0.30434782608695654, 0.3074074074074074, 0.9066666666666667, 1.0, 1.0, 0.05267229282838631, 1.0, 1.0, 0.05267229282838631, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17952730167930125, 0.17952730167930142, 0.3090736752859268], 
reward next is 0.6909, 
noisyNet noise sample is [array([0.2941879], dtype=float32), 0.46110204]. 
=============================================
[2019-03-24 07:19:31,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.24249259e-08 4.10498586e-08 8.92679353e-09 9.99986410e-01
 1.36187555e-05], sum to 1.0000
[2019-03-24 07:19:31,426] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6401
[2019-03-24 07:19:31,433] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.08333333333334, 91.66666666666667, 1.0, 2.0, 0.215583781916092, 1.0, 2.0, 0.215583781916092, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523264.6111227972, 523264.6111227972, 162906.2051318331], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2088600.0000, 
sim time next is 2089200.0000, 
raw observation next is [20.96666666666667, 92.33333333333334, 1.0, 2.0, 0.215139205563306, 1.0, 2.0, 0.215139205563306, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 522483.6514258181, 522483.6514258186, 162821.1073877338], 
processed observation next is [0.0, 0.17391304347826086, 0.3320987654320988, 0.9233333333333335, 1.0, 1.0, 0.0656419113848881, 1.0, 1.0, 0.0656419113848881, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18660130408064932, 0.1866013040806495, 0.31311751420718037], 
reward next is 0.6869, 
noisyNet noise sample is [array([0.6439347], dtype=float32), -0.9825183]. 
=============================================
[2019-03-24 07:19:32,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2059109e-10 1.1453101e-07 1.5939035e-08 9.9999976e-01 6.6698021e-08], sum to 1.0000
[2019-03-24 07:19:32,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-24 07:19:32,885] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 80.0, 1.0, 2.0, 0.2891310735618507, 1.0, 2.0, 0.2891310735618507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664968.2585509312, 664968.2585509316, 178170.4710156432], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2157600.0000, 
sim time next is 2158200.0000, 
raw observation next is [25.45, 80.5, 1.0, 2.0, 0.2886471067152093, 1.0, 2.0, 0.2886471067152093, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663989.3012820509, 663989.3012820514, 178062.3624389384], 
processed observation next is [0.0, 1.0, 0.4981481481481481, 0.805, 1.0, 1.0, 0.15315131751810634, 1.0, 1.0, 0.15315131751810634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23713903617216103, 0.2371390361721612, 0.34242762007488153], 
reward next is 0.6576, 
noisyNet noise sample is [array([-2.0588024], dtype=float32), -1.6034279]. 
=============================================
[2019-03-24 07:19:34,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5809284e-07 6.1788128e-06 4.9718137e-06 9.9997652e-01 1.1756913e-05], sum to 1.0000
[2019-03-24 07:19:34,544] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1275
[2019-03-24 07:19:34,553] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.21666666666667, 84.33333333333334, 1.0, 2.0, 0.8375809500868462, 1.0, 2.0, 0.8375809500868462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1910538.258496572, 1910538.258496572, 359527.7264539695], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2213400.0000, 
sim time next is 2214000.0000, 
raw observation next is [26.0, 85.0, 1.0, 2.0, 0.8059522007072797, 1.0, 2.0, 0.8059522007072797, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1838318.226255963, 1838318.226255963, 346219.5540820985], 
processed observation next is [1.0, 0.6521739130434783, 0.5185185185185185, 0.85, 1.0, 1.0, 0.7689907151277139, 1.0, 1.0, 0.7689907151277139, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.656542223662844, 0.656542223662844, 0.6658068347732663], 
reward next is 0.3342, 
noisyNet noise sample is [array([1.3072602], dtype=float32), -1.0084457]. 
=============================================
[2019-03-24 07:19:34,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[60.059868]
 [59.925232]
 [59.707306]
 [59.66959 ]
 [60.102966]], R is [[60.02516937]
 [59.73352051]
 [59.42601776]
 [59.09584808]
 [58.75754547]].
[2019-03-24 07:19:35,053] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7030434e-05 7.0295545e-07 1.0595039e-07 9.9997926e-01 2.9046525e-06], sum to 1.0000
[2019-03-24 07:19:35,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8772
[2019-03-24 07:19:35,063] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.7, 94.33333333333334, 1.0, 2.0, 0.2678285697576995, 1.0, 2.0, 0.2678285697576995, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627374.44539685, 627374.44539685, 173738.9826357356], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2233200.0000, 
sim time next is 2233800.0000, 
raw observation next is [22.7, 94.5, 1.0, 2.0, 0.2674532006907441, 1.0, 2.0, 0.2674532006907441, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626252.462116853, 626252.462116853, 173641.4002601909], 
processed observation next is [1.0, 0.8695652173913043, 0.39629629629629626, 0.945, 1.0, 1.0, 0.12792047701279058, 1.0, 1.0, 0.12792047701279058, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2236615936131618, 0.2236615936131618, 0.3339257697311363], 
reward next is 0.6661, 
noisyNet noise sample is [array([0.8588046], dtype=float32), -0.029016025]. 
=============================================
[2019-03-24 07:19:35,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1322248e-07 6.5463468e-07 6.5736356e-07 9.9998152e-01 1.7189008e-05], sum to 1.0000
[2019-03-24 07:19:35,155] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6713
[2019-03-24 07:19:35,162] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 90.0, 1.0, 2.0, 0.3010923264240455, 1.0, 2.0, 0.3010923264240455, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695980.1132782093, 695980.1132782098, 181196.757556768], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2175600.0000, 
sim time next is 2176200.0000, 
raw observation next is [23.8, 90.0, 1.0, 2.0, 0.2984444348922416, 1.0, 2.0, 0.2984444348922416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690598.6426850564, 690598.6426850569, 180593.094012376], 
processed observation next is [1.0, 0.17391304347826086, 0.43703703703703706, 0.9, 1.0, 1.0, 0.16481480344314475, 1.0, 1.0, 0.16481480344314475, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24664237238752015, 0.24664237238752032, 0.34729441156226154], 
reward next is 0.6527, 
noisyNet noise sample is [array([-1.1020807], dtype=float32), -0.32710505]. 
=============================================
[2019-03-24 07:19:43,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2940284e-07 7.2437297e-07 1.8608341e-06 9.9986172e-01 1.3543888e-04], sum to 1.0000
[2019-03-24 07:19:43,697] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4879
[2019-03-24 07:19:43,703] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.9, 96.0, 1.0, 2.0, 0.2620474532787277, 1.0, 2.0, 0.2620474532787277, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620776.2417387862, 620776.2417387867, 172709.5955977149], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2343600.0000, 
sim time next is 2344200.0000, 
raw observation next is [21.86666666666667, 96.0, 1.0, 2.0, 0.269846005930769, 1.0, 2.0, 0.269846005930769, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639480.4373979013, 639480.4373979018, 174522.8684941073], 
processed observation next is [1.0, 0.13043478260869565, 0.36543209876543226, 0.96, 1.0, 1.0, 0.13076905467948693, 1.0, 1.0, 0.13076905467948693, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22838587049925047, 0.22838587049925063, 0.33562090095020636], 
reward next is 0.6644, 
noisyNet noise sample is [array([2.1288764], dtype=float32), -0.3536968]. 
=============================================
[2019-03-24 07:19:47,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8250234e-07 1.2411276e-06 1.1941729e-06 9.9999619e-01 9.6572887e-07], sum to 1.0000
[2019-03-24 07:19:47,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2097
[2019-03-24 07:19:47,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.1, 81.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 390277.3472577308, 390277.3472577312, 148976.3710978029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2437200.0000, 
sim time next is 2437800.0000, 
raw observation next is [18.66666666666667, 78.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396365.0269854169, 396365.0269854169, 149969.2362069631], 
processed observation next is [1.0, 0.21739130434782608, 0.24691358024691376, 0.7833333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14155893820907747, 0.14155893820907747, 0.28840237732108287], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73308814], dtype=float32), -0.5653089]. 
=============================================
[2019-03-24 07:19:49,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6228225e-07 1.7404284e-07 1.2072243e-07 9.9999952e-01 1.2843044e-07], sum to 1.0000
[2019-03-24 07:19:49,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-24 07:19:49,806] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666667, 45.33333333333334, 1.0, 2.0, 0.2284145630381357, 1.0, 2.0, 0.2284145630381357, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 565370.2354881595, 565370.2354881599, 166030.1667796647], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2446800.0000, 
sim time next is 2447400.0000, 
raw observation next is [27.73333333333333, 43.66666666666666, 1.0, 2.0, 0.2320927857910254, 1.0, 2.0, 0.2320927857910254, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573317.1574458887, 573317.1574458887, 166813.8665173149], 
processed observation next is [1.0, 0.30434782608695654, 0.5827160493827159, 0.4366666666666666, 1.0, 1.0, 0.08582474498931596, 1.0, 1.0, 0.08582474498931596, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20475612765924597, 0.20475612765924597, 0.3207958971486825], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.20528843], dtype=float32), -0.09533778]. 
=============================================
[2019-03-24 07:19:51,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8223903e-05 8.2794148e-05 3.5203386e-05 9.9974591e-01 1.0785990e-04], sum to 1.0000
[2019-03-24 07:19:51,601] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3743
[2019-03-24 07:19:51,604] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 30.0, 1.0, 2.0, 0.6119236039382384, 1.0, 2.0, 0.6119236039382384, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1470178.021323208, 1470178.021323208, 275433.8816020504], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2548800.0000, 
sim time next is 2549400.0000, 
raw observation next is [32.7, 30.0, 1.0, 2.0, 0.5881277621862789, 1.0, 2.0, 0.5881277621862789, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1412846.367108712, 1412846.367108712, 267097.3829405769], 
processed observation next is [1.0, 0.5217391304347826, 0.7666666666666667, 0.3, 1.0, 1.0, 0.5096759073646178, 1.0, 1.0, 0.5096759073646178, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5045879882531115, 0.5045879882531115, 0.5136488133472632], 
reward next is 0.4864, 
noisyNet noise sample is [array([2.1239817], dtype=float32), -0.25438622]. 
=============================================
[2019-03-24 07:19:55,158] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5969628e-07 8.0052978e-08 6.6963526e-07 9.9999905e-01 2.3997602e-08], sum to 1.0000
[2019-03-24 07:19:55,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1262
[2019-03-24 07:19:55,182] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 57.0, 1.0, 2.0, 0.210138343209716, 1.0, 2.0, 0.210138343209716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520407.2735467567, 520407.2735467572, 162063.326210928], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2525400.0000, 
sim time next is 2526000.0000, 
raw observation next is [25.06666666666667, 56.0, 1.0, 2.0, 0.210434164471111, 1.0, 2.0, 0.210434164471111, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520588.9740563903, 520588.9740563903, 162112.0296284561], 
processed observation next is [1.0, 0.21739130434782608, 0.4839506172839507, 0.56, 1.0, 1.0, 0.06004067198941784, 1.0, 1.0, 0.06004067198941784, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18592463359156797, 0.18592463359156797, 0.31175390313164636], 
reward next is 0.6882, 
noisyNet noise sample is [array([0.30209604], dtype=float32), 1.0150969]. 
=============================================
[2019-03-24 07:19:55,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.67572]
 [64.62626]
 [64.65396]
 [64.77774]
 [64.72876]], R is [[64.58461761]
 [64.62711334]
 [64.67144775]
 [64.70441437]
 [64.75009918]].
[2019-03-24 07:19:57,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4757499e-08 7.4708538e-07 5.5049732e-08 9.9999797e-01 1.2328720e-06], sum to 1.0000
[2019-03-24 07:19:57,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1764
[2019-03-24 07:19:57,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 78.16666666666667, 1.0, 2.0, 0.2565907121580846, 1.0, 2.0, 0.2565907121580846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 604473.9438091654, 604473.9438091659, 171316.0478033794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [24.8, 79.0, 1.0, 2.0, 0.2628622585752615, 1.0, 2.0, 0.2628622585752615, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616238.4676442336, 616238.4676442341, 172617.952840016], 
processed observation next is [0.0, 0.34782608695652173, 0.4740740740740741, 0.79, 1.0, 1.0, 0.1224550697324542, 1.0, 1.0, 0.1224550697324542, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22008516701579772, 0.2200851670157979, 0.3319576016154154], 
reward next is 0.6680, 
noisyNet noise sample is [array([-2.4057608], dtype=float32), -0.25112513]. 
=============================================
[2019-03-24 07:20:01,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.57547043e-07 9.69918619e-05 1.47037545e-05 9.99886870e-01
 1.11714792e-06], sum to 1.0000
[2019-03-24 07:20:01,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7427
[2019-03-24 07:20:01,633] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 89.83333333333333, 1.0, 2.0, 0.2982329993180726, 1.0, 2.0, 0.2982329993180726, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690245.2612547623, 690245.2612547628, 180548.5822127197], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2785800.0000, 
sim time next is 2786400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.3022526007931394, 1.0, 2.0, 0.3022526007931394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698698.5881410378, 698698.5881410383, 181479.0174245057], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.89, 1.0, 1.0, 0.16934833427754695, 1.0, 1.0, 0.16934833427754695, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24953521005037066, 0.24953521005037083, 0.3489981104317417], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.20627011], dtype=float32), -1.4650884]. 
=============================================
[2019-03-24 07:20:03,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4390737e-09 3.4535797e-06 1.3692122e-08 9.9999630e-01 2.4451074e-07], sum to 1.0000
[2019-03-24 07:20:03,201] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2866
[2019-03-24 07:20:03,204] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 78.16666666666667, 1.0, 2.0, 0.2565907121580846, 1.0, 2.0, 0.2565907121580846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 604473.9438091654, 604473.9438091659, 171316.0478033794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [24.8, 79.0, 1.0, 2.0, 0.2628622585752615, 1.0, 2.0, 0.2628622585752615, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616238.4676442336, 616238.4676442341, 172617.952840016], 
processed observation next is [0.0, 0.34782608695652173, 0.4740740740740741, 0.79, 1.0, 1.0, 0.1224550697324542, 1.0, 1.0, 0.1224550697324542, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22008516701579772, 0.2200851670157979, 0.3319576016154154], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.42610395], dtype=float32), 0.9304113]. 
=============================================
[2019-03-24 07:20:03,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8674118e-07 9.7094312e-07 3.1250660e-09 9.9999845e-01 3.3475320e-08], sum to 1.0000
[2019-03-24 07:20:03,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5454
[2019-03-24 07:20:03,971] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.75, 53.5, 1.0, 2.0, 0.2750304564049979, 1.0, 2.0, 0.2750304564049979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638682.5362806624, 638682.5362806629, 175158.6773499851], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2721000.0000, 
sim time next is 2721600.0000, 
raw observation next is [30.0, 52.0, 1.0, 2.0, 0.2730878401217403, 1.0, 2.0, 0.2730878401217403, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 635052.6554485344, 635052.6554485349, 174748.0329657556], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.52, 1.0, 1.0, 0.1346283810973099, 1.0, 1.0, 0.1346283810973099, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.226804519803048, 0.22680451980304817, 0.33605390954953], 
reward next is 0.6639, 
noisyNet noise sample is [array([-0.5180379], dtype=float32), 0.2388565]. 
=============================================
[2019-03-24 07:20:04,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0696858e-06 2.8625036e-05 5.4660632e-07 9.9993372e-01 3.2075768e-05], sum to 1.0000
[2019-03-24 07:20:04,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6348
[2019-03-24 07:20:04,145] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.15, 58.33333333333334, 1.0, 2.0, 0.3330265303605508, 1.0, 2.0, 0.3330265303605508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 759092.9119825372, 759092.9119825377, 188575.5009970822], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.3345151030176292, 1.0, 2.0, 0.3345151030176292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935537, 188950.1021701645], 
processed observation next is [1.0, 0.8260869565217391, 0.7037037037037037, 0.59, 1.0, 1.0, 0.20775607502098717, 1.0, 1.0, 0.20775607502098717, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27231700621198335, 0.27231700621198346, 0.36336558109647016], 
reward next is 0.6366, 
noisyNet noise sample is [array([-1.8627441], dtype=float32), 0.6361897]. 
=============================================
[2019-03-24 07:20:09,194] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 07:20:09,195] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:20:09,198] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:20:09,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:09,199] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:20:09,200] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:20:09,205] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:20:09,199] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:09,209] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:09,207] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:09,213] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:09,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-24 07:20:09,229] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-24 07:20:09,285] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-24 07:20:09,287] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-24 07:20:09,287] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-24 07:20:21,285] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:20:21,286] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 57.0, 1.0, 2.0, 0.211489297107799, 1.0, 2.0, 0.211489297107799, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515774.1423784401, 515774.1423784406, 162112.9976801042]
[2019-03-24 07:20:21,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:20:21,291] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.1744309e-08 2.4731403e-07 1.0206336e-07 9.9999952e-01 1.2035045e-07], sampled 0.8093817008542381
[2019-03-24 07:20:24,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:20:24,332] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [16.07564716333333, 65.27243149666667, 1.0, 2.0, 0.2182571060475781, 1.0, 2.0, 0.2182571060475781, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563154.1191340764, 563154.1191340764, 145454.4936574762]
[2019-03-24 07:20:24,333] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:20:24,337] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3828512e-07 5.1299537e-07 2.2441264e-07 9.9999893e-01 2.6765730e-07], sampled 0.5827676181460164
[2019-03-24 07:20:59,226] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:20:59,228] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.16666666666667, 76.5, 1.0, 2.0, 0.3995032450651951, 1.0, 2.0, 0.3995032450651951, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 910708.4094350635, 910708.4094350644, 206055.5541068527]
[2019-03-24 07:20:59,230] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:20:59,232] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.3345269e-08 2.9410776e-07 1.2112142e-07 9.9999940e-01 1.3554920e-07], sampled 0.12571951476248677
[2019-03-24 07:21:10,827] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:21:10,829] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.82430660333333, 101.2016496333333, 1.0, 2.0, 0.2636818685619028, 1.0, 2.0, 0.2636818685619028, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 619471.101330894, 619471.1013308945, 172864.1741138413]
[2019-03-24 07:21:10,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:21:10,832] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0264921e-08 1.3209899e-07 5.0810133e-08 9.9999976e-01 5.8839916e-08], sampled 0.03980897409695017
[2019-03-24 07:21:14,889] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:21:14,890] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.12072692, 97.73975831, 1.0, 2.0, 0.8486092305312741, 1.0, 2.0, 0.8486092305312741, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1935721.239692148, 1935721.239692148, 364253.831097828]
[2019-03-24 07:21:14,890] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:21:14,896] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.01993464e-07 3.92745562e-07 1.67108141e-07 9.99999166e-01
 1.83921728e-07], sampled 0.7881186518577453
[2019-03-24 07:21:34,369] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00940055], dtype=float32), 0.0062971986]
[2019-03-24 07:21:34,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.45, 63.83333333333334, 1.0, 2.0, 0.3203859063759886, 1.0, 2.0, 0.3203859063759886, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730266.4435185647, 730266.4435185647, 185424.9010611246]
[2019-03-24 07:21:34,372] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:21:34,375] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7983597e-08 1.5940105e-07 6.3476264e-08 9.9999964e-01 7.3823315e-08], sampled 0.20072853884671937
[2019-03-24 07:21:56,667] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:21:57,163] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0693 2668515290.8788 68.0000
[2019-03-24 07:21:57,284] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 07:21:57,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473084.7055 47.0000
[2019-03-24 07:21:57,365] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:21:58,380] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 925000, evaluation results [925000.0, 7523.069339413286, 2668515290.878837, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495473084.7055235, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 07:21:58,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6898134e-08 2.4347555e-08 1.5463183e-07 9.9999976e-01 2.8592831e-08], sum to 1.0000
[2019-03-24 07:21:58,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9027
[2019-03-24 07:21:58,705] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.6029667584991648, 1.0, 2.0, 0.6029667584991648, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1387872.982018078, 1387872.982018079, 269698.8467142412], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2886600.0000, 
sim time next is 2887200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5560352676974031, 1.0, 2.0, 0.5560352676974031, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1281009.815068739, 1281009.815068739, 253894.3434354413], 
processed observation next is [1.0, 0.43478260869565216, 0.4074074074074074, 0.94, 1.0, 1.0, 0.4714705567826227, 1.0, 1.0, 0.4714705567826227, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4575035053816925, 0.4575035053816925, 0.48825835276046403], 
reward next is 0.5117, 
noisyNet noise sample is [array([-1.2634476], dtype=float32), 0.82989645]. 
=============================================
[2019-03-24 07:22:04,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3593035e-08 6.2535065e-07 1.2738350e-07 9.9999881e-01 4.7132326e-07], sum to 1.0000
[2019-03-24 07:22:04,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-24 07:22:04,460] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 91.33333333333334, 1.0, 2.0, 0.3532580441472717, 1.0, 2.0, 0.3532580441472717, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805232.3758621824, 805232.3758621824, 193731.930120068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2954400.0000, 
sim time next is 2955000.0000, 
raw observation next is [24.75, 90.66666666666666, 1.0, 2.0, 0.3501438124449665, 1.0, 2.0, 0.3501438124449665, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 798129.9592200142, 798129.9592200146, 192928.7522279826], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9066666666666666, 1.0, 1.0, 0.22636168148210298, 1.0, 1.0, 0.22636168148210298, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2850464140071479, 0.2850464140071481, 0.3710168312076588], 
reward next is 0.6290, 
noisyNet noise sample is [array([-1.058191], dtype=float32), -0.9281905]. 
=============================================
[2019-03-24 07:22:04,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.5213  ]
 [58.433548]
 [58.529648]
 [58.370167]
 [58.243168]], R is [[58.61315536]
 [58.65446091]
 [58.69702911]
 [58.73571396]
 [58.76331329]].
[2019-03-24 07:22:07,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4013070e-07 4.4943047e-07 2.1118801e-08 9.9999738e-01 1.7365211e-06], sum to 1.0000
[2019-03-24 07:22:07,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1332
[2019-03-24 07:22:07,568] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 99.33333333333334, 1.0, 2.0, 0.298299629046298, 1.0, 2.0, 0.298299629046298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682702.4555437241, 682702.4555437246, 180193.3431436331], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3023400.0000, 
sim time next is 3024000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2967300166883472, 1.0, 2.0, 0.2967300166883472, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 680169.8014152587, 680169.8014152591, 179869.9496520011], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.16277382939088952, 1.0, 1.0, 0.16277382939088952, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24291778621973523, 0.2429177862197354, 0.34590374933077134], 
reward next is 0.6541, 
noisyNet noise sample is [array([-2.1754408], dtype=float32), 2.3950658]. 
=============================================
[2019-03-24 07:22:07,580] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.66986]
 [64.63381]
 [64.60875]
 [64.61337]
 [64.61923]], R is [[62.69808197]
 [62.72457504]
 [62.75007629]
 [62.77428818]
 [62.7971344 ]].
[2019-03-24 07:22:10,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8941449e-06 4.1251669e-06 2.4588013e-05 9.9994767e-01 2.0582274e-05], sum to 1.0000
[2019-03-24 07:22:10,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8878
[2019-03-24 07:22:10,863] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.2762999781745969, 1.0, 2.0, 0.2762999781745969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642219.1395899624, 642219.1395899629, 175482.0451163226], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3189600.0000, 
sim time next is 3190200.0000, 
raw observation next is [27.83333333333334, 64.83333333333334, 1.0, 2.0, 0.2823891332322728, 1.0, 2.0, 0.2823891332322728, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 653014.6792162065, 653014.679216207, 176752.2864428659], 
processed observation next is [1.0, 0.9565217391304348, 0.58641975308642, 0.6483333333333334, 1.0, 1.0, 0.14570134908603907, 1.0, 1.0, 0.14570134908603907, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23321952829150233, 0.2332195282915025, 0.3399082431593575], 
reward next is 0.6601, 
noisyNet noise sample is [array([1.2032112], dtype=float32), 1.8906329]. 
=============================================
[2019-03-24 07:22:16,630] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2106445e-07 3.7686993e-06 4.0047888e-07 9.9997079e-01 2.4779516e-05], sum to 1.0000
[2019-03-24 07:22:16,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4558
[2019-03-24 07:22:16,645] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.2762999781745969, 1.0, 2.0, 0.2762999781745969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642219.1395899624, 642219.1395899629, 175482.0451163226], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3189600.0000, 
sim time next is 3190200.0000, 
raw observation next is [27.83333333333334, 64.83333333333334, 1.0, 2.0, 0.2823891332322728, 1.0, 2.0, 0.2823891332322728, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 653014.6792162065, 653014.679216207, 176752.2864428659], 
processed observation next is [1.0, 0.9565217391304348, 0.58641975308642, 0.6483333333333334, 1.0, 1.0, 0.14570134908603907, 1.0, 1.0, 0.14570134908603907, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23321952829150233, 0.2332195282915025, 0.3399082431593575], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.02562508], dtype=float32), -1.069527]. 
=============================================
[2019-03-24 07:22:17,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4411311e-06 1.0669467e-06 4.8345969e-06 9.9994743e-01 4.4166958e-05], sum to 1.0000
[2019-03-24 07:22:17,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9411
[2019-03-24 07:22:17,331] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.93333333333334, 34.0, 1.0, 2.0, 0.6977703679175353, 1.0, 2.0, 0.6977703679175353, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1641788.13788022, 1641788.137880221, 305740.4531237379], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3151200.0000, 
sim time next is 3151800.0000, 
raw observation next is [32.95, 35.0, 1.0, 2.0, 0.6945472789233135, 1.0, 2.0, 0.6945472789233135, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1627618.993982029, 1627618.993982029, 304219.1110316794], 
processed observation next is [1.0, 0.4782608695652174, 0.775925925925926, 0.35, 1.0, 1.0, 0.6363658082420398, 1.0, 1.0, 0.6363658082420398, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5812924978507246, 0.5812924978507246, 0.5850367519839988], 
reward next is 0.4150, 
noisyNet noise sample is [array([-0.17114702], dtype=float32), 1.7837789]. 
=============================================
[2019-03-24 07:22:17,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9615864e-07 1.5386629e-05 2.7174040e-06 9.9998140e-01 4.0644238e-07], sum to 1.0000
[2019-03-24 07:22:17,656] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5189
[2019-03-24 07:22:17,660] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 68.0, 1.0, 2.0, 0.2588151596578614, 1.0, 2.0, 0.2588151596578614, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611036.1802359472, 611036.1802359472, 171880.1197784659], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3199200.0000, 
sim time next is 3199800.0000, 
raw observation next is [26.0, 66.5, 1.0, 2.0, 0.252652581954845, 1.0, 2.0, 0.252652581954845, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599139.4748597388, 599139.4748597393, 170590.8469420274], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.665, 1.0, 1.0, 0.11030069280338693, 1.0, 1.0, 0.11030069280338693, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21397838387847815, 0.2139783838784783, 0.32805932104236035], 
reward next is 0.6719, 
noisyNet noise sample is [array([2.3478017], dtype=float32), -0.95420945]. 
=============================================
[2019-03-24 07:22:24,316] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0886821e-05 1.5547579e-04 2.4382116e-05 9.9952281e-01 2.3639631e-04], sum to 1.0000
[2019-03-24 07:22:24,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2967
[2019-03-24 07:22:24,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.8853062039879771, 1.0, 2.0, 0.8853062039879771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2019523.56833876, 2019523.568338761, 380266.2689412729], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3507600.0000, 
sim time next is 3508200.0000, 
raw observation next is [28.25, 84.0, 1.0, 2.0, 0.8964738699266329, 1.0, 2.0, 0.8964738699266329, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2045027.951966734, 2045027.951966734, 385232.8206164863], 
processed observation next is [1.0, 0.6086956521739131, 0.6018518518518519, 0.84, 1.0, 1.0, 0.8767546070555153, 1.0, 1.0, 0.8767546070555153, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7303671257024049, 0.7303671257024049, 0.7408323473393967], 
reward next is 0.2592, 
noisyNet noise sample is [array([-0.30863202], dtype=float32), -0.90438336]. 
=============================================
[2019-03-24 07:22:33,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3111236e-06 1.0769573e-05 3.4417670e-05 9.9993026e-01 2.0320433e-05], sum to 1.0000
[2019-03-24 07:22:33,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9926
[2019-03-24 07:22:33,011] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.8853062039879771, 1.0, 2.0, 0.8853062039879771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2019523.56833876, 2019523.568338761, 380266.2689412729], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3507600.0000, 
sim time next is 3508200.0000, 
raw observation next is [28.25, 84.0, 1.0, 2.0, 0.8964738699266329, 1.0, 2.0, 0.8964738699266329, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2045027.951966734, 2045027.951966734, 385232.8206164863], 
processed observation next is [1.0, 0.6086956521739131, 0.6018518518518519, 0.84, 1.0, 1.0, 0.8767546070555153, 1.0, 1.0, 0.8767546070555153, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7303671257024049, 0.7303671257024049, 0.7408323473393967], 
reward next is 0.2592, 
noisyNet noise sample is [array([-1.1395503], dtype=float32), -0.062998496]. 
=============================================
[2019-03-24 07:22:33,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2060681e-07 8.6135078e-06 5.6718345e-06 9.9997628e-01 8.6487044e-06], sum to 1.0000
[2019-03-24 07:22:33,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-24 07:22:33,393] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666666, 92.0, 1.0, 2.0, 0.3181088455087074, 1.0, 2.0, 0.3181088455087074, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725073.8069179513, 725073.8069179513, 184863.0605453438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3462000.0000, 
sim time next is 3462600.0000, 
raw observation next is [24.58333333333334, 91.5, 1.0, 2.0, 0.3140691330898749, 1.0, 2.0, 0.3140691330898749, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715861.685375062, 715861.6853750625, 183871.0692790148], 
processed observation next is [1.0, 0.043478260869565216, 0.4660493827160496, 0.915, 1.0, 1.0, 0.18341563463080343, 1.0, 1.0, 0.18341563463080343, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25566488763395073, 0.2556648876339509, 0.35359821015195153], 
reward next is 0.6464, 
noisyNet noise sample is [array([-0.90296644], dtype=float32), 1.6919352]. 
=============================================
[2019-03-24 07:22:46,815] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 07:22:46,816] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:22:46,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:22:46,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:46,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:22:46,820] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:46,821] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:46,820] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:22:46,822] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:22:46,827] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:46,828] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:46,840] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-24 07:22:46,870] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-24 07:22:46,899] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-24 07:22:46,900] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-24 07:22:46,968] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-24 07:22:55,989] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:22:55,992] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666666, 44.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 345901.4132491503, 345901.4132491503, 142300.1539031226]
[2019-03-24 07:22:55,993] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:22:55,995] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.3715459e-07 2.1390592e-06 1.1116593e-06 9.9999321e-01 2.8215502e-06], sampled 0.6890794932589945
[2019-03-24 07:23:05,772] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:23:05,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.25, 47.16666666666666, 1.0, 2.0, 0.1763364466115195, 1.0, 2.0, 0.1763364466115195, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439683.7128565921, 439683.7128565926, 155061.8514977556]
[2019-03-24 07:23:05,774] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:23:05,777] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.8592938e-07 1.6174740e-06 8.4923403e-07 9.9999464e-01 2.3388473e-06], sampled 0.5696604463764735
[2019-03-24 07:23:07,546] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:23:07,548] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.38782444, 77.40187598, 1.0, 2.0, 0.2165946548075507, 1.0, 2.0, 0.2165946548075507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523963.937829238, 523963.9378292385, 163060.8566519515]
[2019-03-24 07:23:07,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:23:07,552] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8360903e-07 1.3449728e-06 6.8586417e-07 9.9999583e-01 1.7944201e-06], sampled 0.33148321140011827
[2019-03-24 07:23:53,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:23:53,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.18471309333333, 91.80871063166666, 1.0, 2.0, 0.3947027874952181, 1.0, 2.0, 0.3947027874952181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 899758.8527248027, 899758.852724803, 204741.5119585345]
[2019-03-24 07:23:53,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:23:53,597] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5457433e-07 9.1484128e-07 4.5928954e-07 9.9999714e-01 1.2142596e-06], sampled 0.4351164421063163
[2019-03-24 07:24:15,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:24:15,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.4, 83.0, 1.0, 2.0, 0.3332068345023824, 1.0, 2.0, 0.3332068345023824, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 759504.0966511505, 759504.096651151, 188620.5101970909]
[2019-03-24 07:24:15,566] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:24:15,569] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9409094e-07 1.0474297e-06 5.2873003e-07 9.9999666e-01 1.4043065e-06], sampled 0.452044361463537
[2019-03-24 07:24:25,195] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00947165], dtype=float32), 0.006316039]
[2019-03-24 07:24:25,197] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 71.0, 1.0, 2.0, 0.2989682157146168, 1.0, 2.0, 0.2989682157146168, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685511.4105536679, 685511.4105536684, 180416.759193651]
[2019-03-24 07:24:25,199] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:24:25,204] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0198302e-07 1.0739093e-06 5.4121324e-07 9.9999666e-01 1.4410596e-06], sampled 0.051494324401327174
[2019-03-24 07:24:34,188] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6534 2465958740.4841 46.0000
[2019-03-24 07:24:34,309] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:24:34,401] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668535969.8193 68.0000
[2019-03-24 07:24:34,448] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:24:34,453] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7123.0756 2438814092.2345 34.0000
[2019-03-24 07:24:35,469] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 950000, evaluation results [950000.0, 7523.015860012835, 2668535969.8192725, 68.0, 7123.075619344037, 2438814092.234496, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.6533711920765, 2465958740.484093, 46.0]
[2019-03-24 07:24:55,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0426915e-07 5.2050530e-07 1.7189449e-06 9.9998856e-01 8.5876454e-06], sum to 1.0000
[2019-03-24 07:24:55,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6250
[2019-03-24 07:24:55,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.95, 94.5, 1.0, 2.0, 0.2232097344218568, 1.0, 2.0, 0.2232097344218568, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539944.9223391166, 539944.9223391169, 164492.008853359], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4151400.0000, 
sim time next is 4152000.0000, 
raw observation next is [20.9, 95.0, 1.0, 2.0, 0.2231407717893957, 1.0, 2.0, 0.2231407717893957, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539714.438554441, 539714.4385544414, 164474.6890808803], 
processed observation next is [1.0, 0.043478260869565216, 0.32962962962962955, 0.95, 1.0, 1.0, 0.0751675854635663, 1.0, 1.0, 0.0751675854635663, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19275515662658607, 0.19275515662658624, 0.31629747900169286], 
reward next is 0.6837, 
noisyNet noise sample is [array([0.04856132], dtype=float32), -0.19942604]. 
=============================================
[2019-03-24 07:24:55,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.81807 ]
 [59.398846]
 [59.034836]
 [59.416157]
 [59.508766]], R is [[58.84331894]
 [58.93855667]
 [59.03272247]
 [59.1255455 ]
 [59.21699905]].
[2019-03-24 07:24:55,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9900595e-08 6.1974146e-07 1.0524117e-06 9.9999523e-01 3.1248489e-06], sum to 1.0000
[2019-03-24 07:24:55,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1284
[2019-03-24 07:24:55,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 75.0, 1.0, 2.0, 0.2361227791778534, 1.0, 2.0, 0.2361227791778534, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578687.4934094183, 578687.4934094183, 167580.1257154174], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [22.33333333333334, 76.33333333333333, 1.0, 2.0, 0.2114942248750234, 1.0, 2.0, 0.2114942248750234, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518974.22468535, 518974.22468535, 162216.835742526], 
processed observation next is [1.0, 0.21739130434782608, 0.38271604938271625, 0.7633333333333333, 1.0, 1.0, 0.061302648660742136, 1.0, 1.0, 0.061302648660742136, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.185347937387625, 0.185347937387625, 0.3119554533510115], 
reward next is 0.6880, 
noisyNet noise sample is [array([1.045503], dtype=float32), -0.33895996]. 
=============================================
[2019-03-24 07:24:58,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3168283e-05 6.9928155e-06 3.0215747e-07 9.9997723e-01 2.3186526e-06], sum to 1.0000
[2019-03-24 07:24:58,181] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9532
[2019-03-24 07:24:58,185] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 37.33333333333334, 1.0, 2.0, 0.8873407914774734, 1.0, 2.0, 0.8873407914774734, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2027287.668206344, 2027287.668206344, 381338.45771893], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4288800.0000, 
sim time next is 4289400.0000, 
raw observation next is [33.5, 39.0, 1.0, 2.0, 0.8863585080903759, 1.0, 2.0, 0.8863585080903759, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2021926.758094542, 2021926.758094542, 380729.513329046], 
processed observation next is [1.0, 0.6521739130434783, 0.7962962962962963, 0.39, 1.0, 1.0, 0.8647125096313998, 1.0, 1.0, 0.8647125096313998, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7221166993194793, 0.7221166993194793, 0.7321721410173962], 
reward next is 0.2678, 
noisyNet noise sample is [array([0.7000076], dtype=float32), 1.5965965]. 
=============================================
[2019-03-24 07:24:59,054] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6623991e-06 4.2735464e-05 2.7372773e-05 9.9989665e-01 2.8510476e-05], sum to 1.0000
[2019-03-24 07:24:59,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1549
[2019-03-24 07:24:59,068] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 74.0, 1.0, 2.0, 0.3270086671050585, 1.0, 2.0, 0.3270086671050585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745369.265544091, 745369.2655440915, 187068.5476734326], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4452000.0000, 
sim time next is 4452600.0000, 
raw observation next is [27.9, 74.0, 1.0, 2.0, 0.3298292187703059, 1.0, 2.0, 0.3298292187703059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 751801.4605059855, 751801.460505986, 187773.2051735356], 
processed observation next is [0.0, 0.5217391304347826, 0.5888888888888888, 0.74, 1.0, 1.0, 0.20217764139322134, 1.0, 1.0, 0.20217764139322134, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26850052160928056, 0.26850052160928073, 0.3611023176414146], 
reward next is 0.6389, 
noisyNet noise sample is [array([-0.22517338], dtype=float32), -1.6600477]. 
=============================================
[2019-03-24 07:25:04,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.10943944e-07 4.70053294e-07 4.71280691e-06 9.99967098e-01
 2.76265528e-05], sum to 1.0000
[2019-03-24 07:25:04,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-24 07:25:04,360] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2486268879095557, 1.0, 2.0, 0.2486268879095557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590800.471093143, 590800.4710931435, 169731.2899026204], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4420200.0000, 
sim time next is 4420800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2484352284413173, 1.0, 2.0, 0.2484352284413173, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590350.1716416434, 590350.1716416439, 169688.3010186216], 
processed observation next is [0.0, 0.17391304347826086, 0.37037037037037035, 0.94, 1.0, 1.0, 0.10528003385871107, 1.0, 1.0, 0.10528003385871107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21083934701487264, 0.2108393470148728, 0.3263236558050415], 
reward next is 0.6737, 
noisyNet noise sample is [array([-1.7865463], dtype=float32), 1.4568717]. 
=============================================
[2019-03-24 07:25:05,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7548281e-06 1.6273338e-05 9.8685791e-07 9.9996889e-01 7.0127053e-06], sum to 1.0000
[2019-03-24 07:25:05,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2133
[2019-03-24 07:25:05,389] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 83.83333333333333, 1.0, 2.0, 0.3151454628661216, 1.0, 2.0, 0.3151454628661216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718316.1266784486, 718316.1266784486, 184134.9309224018], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4320600.0000, 
sim time next is 4321200.0000, 
raw observation next is [25.66666666666667, 83.66666666666667, 1.0, 2.0, 0.3123946450877317, 1.0, 2.0, 0.3123946450877317, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 712043.2314131394, 712043.2314131398, 183461.5860675673], 
processed observation next is [1.0, 0.0, 0.506172839506173, 0.8366666666666667, 1.0, 1.0, 0.18142219653301392, 1.0, 1.0, 0.18142219653301392, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2543011540761212, 0.25430115407612136, 0.3528107424376294], 
reward next is 0.6472, 
noisyNet noise sample is [array([1.208631], dtype=float32), 0.15306184]. 
=============================================
[2019-03-24 07:25:12,417] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7980192e-06 8.5928994e-05 2.5430945e-04 9.9940193e-01 2.5605212e-04], sum to 1.0000
[2019-03-24 07:25:12,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7719
[2019-03-24 07:25:12,434] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.13333333333333, 96.0, 1.0, 2.0, 0.2844835710732909, 1.0, 2.0, 0.2844835710732909, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657772.7668545742, 657772.7668545747, 177241.3644904346], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4566000.0000, 
sim time next is 4566600.0000, 
raw observation next is [23.1, 97.0, 1.0, 2.0, 0.286217641252597, 1.0, 2.0, 0.286217641252597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660526.4577357398, 660526.4577357402, 177590.8823515607], 
processed observation next is [0.0, 0.8695652173913043, 0.41111111111111115, 0.97, 1.0, 1.0, 0.15025909672928217, 1.0, 1.0, 0.15025909672928217, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23590230633419276, 0.23590230633419293, 0.3415209275991552], 
reward next is 0.6585, 
noisyNet noise sample is [array([0.41867793], dtype=float32), 0.480465]. 
=============================================
[2019-03-24 07:25:13,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6460875e-05 2.4543505e-03 4.1627056e-05 9.9726129e-01 2.1618984e-04], sum to 1.0000
[2019-03-24 07:25:13,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2594
[2019-03-24 07:25:13,979] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.23333333333333, 87.66666666666666, 1.0, 2.0, 0.6320931460079583, 1.0, 2.0, 0.6320931460079583, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1441419.616667844, 1441419.616667844, 279256.4265214584], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4610400.0000, 
sim time next is 4611000.0000, 
raw observation next is [25.61666666666667, 88.33333333333334, 1.0, 2.0, 0.6601467308648834, 1.0, 2.0, 0.6601467308648834, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1505455.644000886, 1505455.644000886, 289353.1017964956], 
processed observation next is [1.0, 0.34782608695652173, 0.5043209876543211, 0.8833333333333334, 1.0, 1.0, 0.5954127748391469, 1.0, 1.0, 0.5954127748391469, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5376627300003164, 0.5376627300003164, 0.5564482726855685], 
reward next is 0.4436, 
noisyNet noise sample is [array([-0.27540514], dtype=float32), -2.0582478]. 
=============================================
[2019-03-24 07:25:13,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[52.54667 ]
 [53.354534]
 [54.709087]
 [56.187683]
 [56.241825]], R is [[52.04247284]
 [51.98501587]
 [51.94188309]
 [51.96027756]
 [52.08679199]].
[2019-03-24 07:25:20,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2147535e-05 2.5512631e-05 2.0183979e-05 9.9953270e-01 4.0949715e-04], sum to 1.0000
[2019-03-24 07:25:20,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1003
[2019-03-24 07:25:20,676] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.3057945904652278, 1.0, 2.0, 0.3057945904652278, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701371.7237633112, 701371.7237633116, 182074.086876688], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4690800.0000, 
sim time next is 4691400.0000, 
raw observation next is [23.3, 98.33333333333334, 1.0, 2.0, 0.3315928266905243, 1.0, 2.0, 0.3315928266905243, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758412.3333690261, 758412.3333690261, 188342.0564307913], 
processed observation next is [1.0, 0.30434782608695654, 0.41851851851851857, 0.9833333333333334, 1.0, 1.0, 0.20427717463157657, 1.0, 1.0, 0.20427717463157657, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27086154763179504, 0.27086154763179504, 0.36219626236690633], 
reward next is 0.6378, 
noisyNet noise sample is [array([-1.0777423], dtype=float32), -0.20153289]. 
=============================================
[2019-03-24 07:25:23,937] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 07:25:23,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:25:23,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:23,941] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:25:23,942] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:23,943] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:25:23,944] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:23,946] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:25:23,948] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:23,948] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:25:23,949] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:23,963] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-24 07:25:23,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-24 07:25:23,993] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-24 07:25:24,058] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-24 07:25:24,093] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-24 07:25:35,466] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:25:35,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.0, 50.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 250722.1058557278, 250722.1058557282, 99008.42510373845]
[2019-03-24 07:25:35,469] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:25:35,471] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8288742e-05 5.3081923e-05 4.0892101e-05 9.9964392e-01 2.4381965e-04], sampled 0.059199750815648766
[2019-03-24 07:25:36,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:25:36,743] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.5, 26.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411719.2554687688, 411719.2554687692, 144833.9297412385]
[2019-03-24 07:25:36,745] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:25:36,748] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4547266e-05 4.3493030e-05 3.3133096e-05 9.9970990e-01 1.9888810e-04], sampled 0.018211724726791445
[2019-03-24 07:25:40,565] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:25:40,567] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.1, 17.66666666666667, 1.0, 2.0, 0.4515074555037267, 1.0, 2.0, 0.4515074555037267, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1097666.653649967, 1097666.653649968, 223562.1696831508]
[2019-03-24 07:25:40,568] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:25:40,570] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4015513e-06 2.9551502e-05 2.2204978e-05 9.9980038e-01 1.3844456e-04], sampled 0.6054413200910574
[2019-03-24 07:26:13,688] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:26:13,690] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.55752010333333, 100.8542202166667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 12.08647929473663, 6.9112, 138.8485191001233, 5348064.312123196, 2330028.874907609, 441250.7491365546]
[2019-03-24 07:26:13,692] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:26:13,694] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9489145e-05 5.5982127e-05 4.3102613e-05 9.9964595e-01 2.3550191e-04], sampled 0.23595808888205205
[2019-03-24 07:26:13,697] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 5348064.312123196 W.
[2019-03-24 07:26:41,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:26:41,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.33333333333333, 29.33333333333334, 1.0, 2.0, 0.2425877409807575, 1.0, 2.0, 0.2425877409807575, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 573420.3066514675, 573420.3066514679, 168247.8626915528]
[2019-03-24 07:26:41,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:26:41,061] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.0835839e-06 1.3869937e-05 1.0126050e-05 9.9989831e-01 7.3631672e-05], sampled 0.8746041517067223
[2019-03-24 07:26:47,004] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:26:47,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.53903798333334, 73.66440812333333, 1.0, 2.0, 0.3404743104293474, 1.0, 2.0, 0.3404743104293474, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 776077.802382298, 776077.8023822985, 190457.6897039798]
[2019-03-24 07:26:47,006] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:26:47,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6934921e-06 2.4430195e-05 1.8339508e-05 9.9982953e-01 1.1996900e-04], sampled 0.630066170250862
[2019-03-24 07:26:56,011] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:26:56,012] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 77.0, 1.0, 2.0, 0.2102054592183699, 1.0, 2.0, 0.2102054592183699, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513210.8926760508, 513210.8926760508, 161857.5581855318]
[2019-03-24 07:26:56,015] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:26:56,017] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8483436e-06 2.5017001e-05 1.8927996e-05 9.9982834e-01 1.1983233e-04], sampled 0.2737491144731312
[2019-03-24 07:27:00,918] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:27:00,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.43333333333334, 86.5, 1.0, 2.0, 0.1877252858469309, 1.0, 2.0, 0.1877252858469309, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464796.6551620231, 464796.6551620236, 157346.0957084257]
[2019-03-24 07:27:00,921] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:27:00,925] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9828393e-06 2.2284923e-05 1.6706561e-05 9.9983704e-01 1.1693805e-04], sampled 0.3535328824195856
[2019-03-24 07:27:09,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00946505], dtype=float32), 0.0063262214]
[2019-03-24 07:27:09,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.5, 67.0, 1.0, 2.0, 0.1737311091042235, 1.0, 2.0, 0.1737311091042235, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438566.3778876394, 438566.3778876399, 154638.4536443008]
[2019-03-24 07:27:09,024] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:27:09,026] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.7926825e-06 2.4590328e-05 1.8393293e-05 9.9982065e-01 1.2866066e-04], sampled 0.579513451448991
[2019-03-24 07:27:11,109] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.7040 2410752305.1956 22.0000
[2019-03-24 07:27:11,128] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.0147 2438921860.9717 34.0000
[2019-03-24 07:27:11,131] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.7064 2668545304.8092 68.0000
[2019-03-24 07:27:11,282] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7475.5708 2466006283.3624 46.0000
[2019-03-24 07:27:11,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7362 2495443416.7524 47.0000
[2019-03-24 07:27:12,353] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 975000, evaluation results [975000.0, 7521.706381186342, 2668545304.809215, 68.0, 7120.014699497663, 2438921860.971732, 34.0, 7797.703956052216, 2410752305.195639, 22.0, 6906.736180006656, 2495443416.7523727, 47.0, 7475.570765484261, 2466006283.3624034, 46.0]
[2019-03-24 07:27:17,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5915294e-04 5.8121252e-04 9.4783691e-06 9.9797219e-01 1.0779393e-03], sum to 1.0000
[2019-03-24 07:27:17,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7796
[2019-03-24 07:27:17,580] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.86666666666667, 81.33333333333333, 1.0, 2.0, 0.3782439788599923, 1.0, 2.0, 0.3782439788599923, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 862218.4818826258, 862218.4818826258, 200299.9905181215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4902000.0000, 
sim time next is 4902600.0000, 
raw observation next is [29.43333333333333, 85.16666666666667, 1.0, 2.0, 0.3880774803309469, 1.0, 2.0, 0.3880774803309469, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884647.1801359908, 884647.1801359908, 202943.1184161977], 
processed observation next is [1.0, 0.7391304347826086, 0.6456790123456789, 0.8516666666666667, 1.0, 1.0, 0.2715208099177939, 1.0, 1.0, 0.2715208099177939, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3159454214771396, 0.3159454214771396, 0.39027522772345713], 
reward next is 0.6097, 
noisyNet noise sample is [array([1.1083138], dtype=float32), -0.28851387]. 
=============================================
[2019-03-24 07:27:20,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3001073e-06 1.3524143e-04 2.6220482e-04 9.9917835e-01 4.1996266e-04], sum to 1.0000
[2019-03-24 07:27:20,968] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4133
[2019-03-24 07:27:20,973] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.8, 77.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 9.352289708458908, 6.9112, 121.9159551815408, 3578765.33464031, 2328812.643979803, 443051.4195114633], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4888800.0000, 
sim time next is 4889400.0000, 
raw observation next is [31.66666666666666, 77.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8961504373177863, 1.0, 1.0, 0.9977734948820727, 7.223283603078649, 6.9112, 121.94756008, 3061889.422330775, 2902046.519797827, 540361.753382637], 
processed observation next is [1.0, 0.6086956521739131, 0.7283950617283949, 0.7733333333333334, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 0.8763695682354599, 1.0, 0.5, 0.9972168686025908, 0.03120836030786487, 0.0, 0.8096049824067558, 1.0935319365467053, 1.036445185642081, 1.039157218043533], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4158219], dtype=float32), 0.17662497]. 
=============================================
[2019-03-24 07:27:23,546] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1925185e-03 4.0945321e-04 7.9596299e-04 9.5687473e-01 3.7727289e-02], sum to 1.0000
[2019-03-24 07:27:23,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9938
[2019-03-24 07:27:23,564] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.08333333333334, 83.0, 1.0, 2.0, 0.6364122768678513, 1.0, 2.0, 0.6364122768678513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1451278.256843212, 1451278.256843213, 280792.5065613946], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [25.1, 83.0, 1.0, 2.0, 0.3886728638864512, 1.0, 2.0, 0.3886728638864512, 1.0, 1.0, 0.6187798574986928, 6.911199999999999, 6.9112, 121.94756008, 1329391.894489985, 1329391.894489985, 292155.7790805828], 
processed observation next is [1.0, 0.4782608695652174, 0.4851851851851852, 0.83, 1.0, 1.0, 0.27222959986482287, 1.0, 1.0, 0.27222959986482287, 1.0, 0.5, 0.5234748218733659, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.47478281946070894, 0.47478281946070894, 0.5618380366934285], 
reward next is 0.4382, 
noisyNet noise sample is [array([-0.46621138], dtype=float32), 1.1764984]. 
=============================================
[2019-03-24 07:27:23,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3653234e-04 1.5739420e-04 6.9283007e-05 9.9658942e-01 3.0473552e-03], sum to 1.0000
[2019-03-24 07:27:23,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8106
[2019-03-24 07:27:23,827] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.2898623476294708, 1.0, 2.0, 0.2898623476294708, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677255.5437700968, 677255.5437700973, 178838.9036752381], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4941600.0000, 
sim time next is 4942200.0000, 
raw observation next is [24.41666666666667, 80.66666666666667, 1.0, 2.0, 0.2865917482679181, 1.0, 2.0, 0.2865917482679181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671589.649656333, 671589.6496563335, 178148.0442343393], 
processed observation next is [1.0, 0.17391304347826086, 0.4598765432098767, 0.8066666666666668, 1.0, 1.0, 0.15070446222371203, 1.0, 1.0, 0.15070446222371203, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23985344630583322, 0.23985344630583338, 0.3425923927583448], 
reward next is 0.6574, 
noisyNet noise sample is [array([1.0558516], dtype=float32), 1.1825774]. 
=============================================
[2019-03-24 07:27:25,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9033247e-07 8.9968836e-07 1.8888570e-05 9.9973255e-01 2.4738850e-04], sum to 1.0000
[2019-03-24 07:27:25,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3602
[2019-03-24 07:27:25,883] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.08333333333333, 66.83333333333333, 1.0, 2.0, 0.3699080262252259, 1.0, 2.0, 0.3699080262252259, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 843205.9752796657, 843205.9752796661, 198084.553018016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5062200.0000, 
sim time next is 5062800.0000, 
raw observation next is [31.26666666666667, 67.66666666666667, 1.0, 2.0, 0.3782453836522323, 1.0, 2.0, 0.3782453836522323, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 862221.6859499045, 862221.685949905, 200299.4512294068], 
processed observation next is [0.0, 0.6086956521739131, 0.7135802469135804, 0.6766666666666667, 1.0, 1.0, 0.2598159329193242, 1.0, 1.0, 0.2598159329193242, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3079363164106802, 0.30793631641068037, 0.38519125236424384], 
reward next is 0.6148, 
noisyNet noise sample is [array([1.1649654], dtype=float32), 2.762452]. 
=============================================
[2019-03-24 07:27:27,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2989587e-05 1.6802387e-06 1.6266016e-04 9.7998786e-01 1.9764850e-02], sum to 1.0000
[2019-03-24 07:27:27,254] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-24 07:27:27,258] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 74.16666666666667, 1.0, 2.0, 0.4120724110653449, 1.0, 2.0, 0.4120724110653449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 939378.6666979357, 939378.6666979361, 209532.6929726229], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5069400.0000, 
sim time next is 5070000.0000, 
raw observation next is [31.0, 73.33333333333334, 1.0, 2.0, 0.4048295641439407, 1.0, 2.0, 0.4048295641439407, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 922857.6078973544, 922857.6078973539, 207522.4108679318], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.7333333333333334, 1.0, 1.0, 0.29146376683802466, 1.0, 1.0, 0.29146376683802466, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32959200282048373, 0.32959200282048357, 0.39908155936140727], 
reward next is 0.6009, 
noisyNet noise sample is [array([0.57183087], dtype=float32), -0.47207713]. 
=============================================
[2019-03-24 07:27:27,275] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.35198 ]
 [63.110703]
 [62.994232]
 [63.027515]
 [63.076756]], R is [[63.45333481]
 [63.41585541]
 [63.36415482]
 [63.31253815]
 [63.26154709]].
[2019-03-24 07:27:52,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3671725e-04 4.2433324e-04 1.5251912e-04 9.6692955e-01 3.2356985e-02], sum to 1.0000
[2019-03-24 07:27:52,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-24 07:27:52,970] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 92.16666666666667, 1.0, 2.0, 0.4438712369178768, 1.0, 2.0, 0.4438712369178768, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1011916.552038062, 1011916.552038062, 218572.278304665], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5471400.0000, 
sim time next is 5472000.0000, 
raw observation next is [27.4, 92.0, 1.0, 2.0, 0.4557906887051068, 1.0, 2.0, 0.4557906887051068, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1039108.376563733, 1039108.376563733, 222051.2968743258], 
processed observation next is [1.0, 0.34782608695652173, 0.5703703703703703, 0.92, 1.0, 1.0, 0.3521317722679843, 1.0, 1.0, 0.3521317722679843, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3711101344870475, 0.3711101344870475, 0.42702172475831884], 
reward next is 0.5730, 
noisyNet noise sample is [array([-1.0455712], dtype=float32), -0.6921058]. 
=============================================
[2019-03-24 07:27:52,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[53.94053 ]
 [53.51043 ]
 [53.0513  ]
 [52.622932]
 [53.58434 ]], R is [[53.9743576 ]
 [54.01428604]
 [54.0506134 ]
 [54.07701874]
 [54.11691284]].
[2019-03-24 07:28:00,818] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 07:28:00,819] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:28:00,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:00,820] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:28:00,821] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:28:00,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:28:00,822] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:28:00,826] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:00,827] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:00,827] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:00,829] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:00,839] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-24 07:28:00,870] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-24 07:28:00,901] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-24 07:28:00,902] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-24 07:28:00,978] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-24 07:28:08,377] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:28:08,378] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.80183109, 48.84097540666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 334194.8832851492, 334194.8832851496, 135039.6873462782]
[2019-03-24 07:28:08,379] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:28:08,382] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7072161e-05 5.8976937e-05 4.2307831e-05 9.9748468e-01 2.3768749e-03], sampled 0.003702716139158291
[2019-03-24 07:28:14,783] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:28:14,786] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.43333333333334, 60.66666666666666, 1.0, 2.0, 0.1990893188942527, 1.0, 2.0, 0.1990893188942527, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491177.7974385218, 491177.7974385218, 159665.9608638424]
[2019-03-24 07:28:14,787] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:28:14,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7856426e-05 2.9633025e-05 2.0320655e-05 9.9837947e-01 1.5526529e-03], sampled 0.0014657990098597695
[2019-03-24 07:28:48,645] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:28:48,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666667, 63.33333333333334, 1.0, 2.0, 0.2092647275976574, 1.0, 2.0, 0.2092647275976574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 511541.7282188719, 511541.7282188724, 161677.5127277402]
[2019-03-24 07:28:48,649] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:28:48,652] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8555271e-05 3.0243153e-05 2.0803483e-05 9.9835974e-01 1.5706455e-03], sampled 0.7413466297158241
[2019-03-24 07:29:00,243] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:29:00,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.33044201833333, 31.06604611166667, 1.0, 2.0, 0.1834304702366901, 1.0, 2.0, 0.1834304702366901, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453974.2294216631, 453974.2294216636, 156441.680939199]
[2019-03-24 07:29:00,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:29:00,248] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.8574170e-06 1.5167619e-05 1.0002570e-05 9.9895251e-01 1.0135800e-03], sampled 0.9067103330513142
[2019-03-24 07:29:02,438] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:29:02,438] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.66666666666667, 86.5, 1.0, 2.0, 0.2217569323735654, 1.0, 2.0, 0.2217569323735654, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538031.79373807, 538031.7937380704, 164233.4466595127]
[2019-03-24 07:29:02,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:29:02,443] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3147233e-05 2.2064558e-05 1.4850772e-05 9.9861872e-01 1.3313073e-03], sampled 0.5651756201529042
[2019-03-24 07:29:25,466] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:29:25,467] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.08333333333334, 69.83333333333333, 1.0, 2.0, 0.445709953709596, 1.0, 2.0, 0.445709953709596, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1016111.150495412, 1016111.150495412, 219104.118938101]
[2019-03-24 07:29:25,470] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:29:25,473] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2290375e-05 3.5566249e-05 2.4992594e-05 9.9809402e-01 1.8231953e-03], sampled 0.2708467239689831
[2019-03-24 07:29:29,452] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00965849], dtype=float32), 0.0064121843]
[2019-03-24 07:29:29,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.82144916333333, 54.96056973333333, 1.0, 2.0, 0.378408238729705, 1.0, 2.0, 0.378408238729705, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 862593.127888152, 862593.1278881525, 200343.6475284606]
[2019-03-24 07:29:29,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:29:29,457] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0081500e-05 1.6885249e-05 1.1320566e-05 9.9884367e-01 1.1179388e-03], sampled 0.8358824255273408
[2019-03-24 07:29:50,800] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7111.3636 2439373287.9360 34.0000
[2019-03-24 07:29:51,106] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7782.4750 2411375150.7414 22.0000
[2019-03-24 07:29:51,112] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7506.8510 2669248825.3041 68.0000
[2019-03-24 07:29:51,153] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7460.7885 2466737919.3943 47.0000
[2019-03-24 07:29:51,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6888.8707 2496234362.7144 47.0000
[2019-03-24 07:29:52,176] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1000000, evaluation results [1000000.0, 7506.850950924037, 2669248825.304102, 68.0, 7111.363638249853, 2439373287.9359584, 34.0, 7782.474966937958, 2411375150.7414217, 22.0, 6888.870737145125, 2496234362.714384, 47.0, 7460.788518088047, 2466737919.3943214, 47.0]
[2019-03-24 07:29:53,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.35387211e-06 2.44686021e-06 1.31232355e-05 9.99892116e-01
 9.09529408e-05], sum to 1.0000
[2019-03-24 07:29:53,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9747
[2019-03-24 07:29:53,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.96666666666667, 68.0, 1.0, 2.0, 0.3027120121678162, 1.0, 2.0, 0.3027120121678162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689963.6086002332, 689963.6086002332, 181112.7062851473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5764800.0000, 
sim time next is 5765400.0000, 
raw observation next is [27.8, 68.5, 1.0, 2.0, 0.3013494480627449, 1.0, 2.0, 0.3013494480627449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686856.5603912566, 686856.560391257, 180784.734747611], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.685, 1.0, 1.0, 0.16827315245564867, 1.0, 1.0, 0.16827315245564867, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24530591442544877, 0.24530591442544894, 0.3476629514377134], 
reward next is 0.6523, 
noisyNet noise sample is [array([1.8214085], dtype=float32), -0.65706426]. 
=============================================
[2019-03-24 07:29:57,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9927695e-05 6.0155602e-05 4.3547992e-04 9.9894339e-01 5.4109405e-04], sum to 1.0000
[2019-03-24 07:29:57,987] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4766
[2019-03-24 07:29:57,996] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 55.0, 1.0, 2.0, 0.2023143853424256, 1.0, 2.0, 0.2023143853424256, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 494743.9299157856, 494743.929915786, 160209.9722558808], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5857200.0000, 
sim time next is 5857800.0000, 
raw observation next is [26.03333333333333, 56.33333333333334, 1.0, 2.0, 0.2049788314741467, 1.0, 2.0, 0.2049788314741467, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500618.4191055541, 500618.4191055546, 160751.8296500981], 
processed observation next is [1.0, 0.8260869565217391, 0.519753086419753, 0.5633333333333335, 1.0, 1.0, 0.05354622794541273, 1.0, 1.0, 0.05354622794541273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1787922925376979, 0.17879229253769807, 0.30913813394249634], 
reward next is 0.6909, 
noisyNet noise sample is [array([-0.4935583], dtype=float32), -0.500461]. 
=============================================
[2019-03-24 07:29:58,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5143890e-05 2.1625760e-04 2.1914644e-05 9.9073619e-01 8.9904806e-03], sum to 1.0000
[2019-03-24 07:29:58,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5525
[2019-03-24 07:29:58,978] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 80.0, 1.0, 2.0, 0.270879986002225, 1.0, 2.0, 0.270879986002225, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631996.4142400585, 631996.414240059, 174331.765467217], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5778000.0000, 
sim time next is 5778600.0000, 
raw observation next is [24.7, 80.33333333333334, 1.0, 2.0, 0.2694867311298421, 1.0, 2.0, 0.2694867311298421, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629364.2588961768, 629364.2588961768, 174037.3000183375], 
processed observation next is [0.0, 0.9130434782608695, 0.4703703703703703, 0.8033333333333335, 1.0, 1.0, 0.1303413465831454, 1.0, 1.0, 0.1303413465831454, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22477294960577743, 0.22477294960577743, 0.3346871154198798], 
reward next is 0.6653, 
noisyNet noise sample is [array([-2.7196536], dtype=float32), 0.16775078]. 
=============================================
[2019-03-24 07:29:59,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6856235e-05 6.5335473e-05 2.0141119e-06 9.9512094e-01 4.7948156e-03], sum to 1.0000
[2019-03-24 07:29:59,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3709
[2019-03-24 07:29:59,650] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.45, 92.5, 1.0, 2.0, 0.251942629293833, 1.0, 2.0, 0.251942629293833, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 606330.9244808882, 606330.9244808886, 170779.3367163569], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5803800.0000, 
sim time next is 5804400.0000, 
raw observation next is [21.4, 93.0, 1.0, 2.0, 0.2344860546456536, 1.0, 2.0, 0.2344860546456536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 564253.9347890046, 564253.9347890051, 166859.7282397398], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.93, 1.0, 1.0, 0.08867387457815906, 1.0, 1.0, 0.08867387457815906, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20151926242464452, 0.20151926242464469, 0.3208840927687304], 
reward next is 0.6791, 
noisyNet noise sample is [array([-1.3334533], dtype=float32), 0.11724049]. 
=============================================
[2019-03-24 07:30:00,514] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3964863e-06 4.4698439e-07 2.4911835e-05 9.9505192e-01 4.9133208e-03], sum to 1.0000
[2019-03-24 07:30:00,521] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1298
[2019-03-24 07:30:00,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 79.33333333333333, 1.0, 2.0, 0.2737988743691966, 1.0, 2.0, 0.2737988743691966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 637530.8138214416, 637530.8138214421, 174951.4755247133], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5776800.0000, 
sim time next is 5777400.0000, 
raw observation next is [24.9, 79.66666666666667, 1.0, 2.0, 0.2723991677818478, 1.0, 2.0, 0.2723991677818478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 634914.955542841, 634914.9555428415, 174655.7294583765], 
processed observation next is [0.0, 0.8695652173913043, 0.47777777777777775, 0.7966666666666667, 1.0, 1.0, 0.13380853307362833, 1.0, 1.0, 0.13380853307362833, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22675534126530036, 0.22675534126530053, 0.3358764028045702], 
reward next is 0.6641, 
noisyNet noise sample is [array([-1.1602005], dtype=float32), -0.32086408]. 
=============================================
[2019-03-24 07:30:10,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2836603e-07 7.2036141e-06 1.7378998e-06 9.9970955e-01 2.8135255e-04], sum to 1.0000
[2019-03-24 07:30:10,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2239
[2019-03-24 07:30:10,128] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 82.5, 1.0, 2.0, 0.2278095862137129, 1.0, 2.0, 0.2278095862137129, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549577.7700985556, 549577.7700985556, 165442.2319996111], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5963400.0000, 
sim time next is 5964000.0000, 
raw observation next is [22.6, 82.0, 1.0, 2.0, 0.2259012218181717, 1.0, 2.0, 0.2259012218181717, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545593.1030755366, 545593.103075537, 165047.6274228446], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.82, 1.0, 1.0, 0.07845383549782346, 1.0, 1.0, 0.07845383549782346, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19485467966983447, 0.19485467966983464, 0.3173992835054704], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.79662865], dtype=float32), -0.8019782]. 
=============================================
[2019-03-24 07:30:10,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.476143]
 [61.537792]
 [62.022945]
 [62.976387]
 [65.2948  ]], R is [[61.35614014]
 [61.42442322]
 [61.49134064]
 [61.55702591]
 [61.62142181]].
[2019-03-24 07:30:10,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1435621e-06 1.0858994e-06 1.1823574e-05 9.9740356e-01 2.5814548e-03], sum to 1.0000
[2019-03-24 07:30:10,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3991
[2019-03-24 07:30:10,864] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.98333333333333, 72.5, 1.0, 2.0, 0.2718059496035817, 1.0, 2.0, 0.2718059496035817, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 633864.6358115331, 633864.6358115335, 174533.2338171368], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6130200.0000, 
sim time next is 6130800.0000, 
raw observation next is [25.9, 73.0, 1.0, 2.0, 0.271246143438689, 1.0, 2.0, 0.271246143438689, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 632606.9720262836, 632606.9720262841, 174405.5372669667], 
processed observation next is [1.0, 1.0, 0.5148148148148147, 0.73, 1.0, 1.0, 0.13243588504605835, 1.0, 1.0, 0.13243588504605835, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22593106143795844, 0.2259310614379586, 0.33539526397493596], 
reward next is 0.6646, 
noisyNet noise sample is [array([-1.0409379], dtype=float32), -1.6555811]. 
=============================================
[2019-03-24 07:30:18,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4318892e-07 3.6633105e-06 5.0763623e-07 9.9977201e-01 2.2330032e-04], sum to 1.0000
[2019-03-24 07:30:18,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9819
[2019-03-24 07:30:18,639] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333333, 90.0, 1.0, 2.0, 0.2855108213919884, 1.0, 2.0, 0.2855108213919884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671889.6252172565, 671889.625217257, 178014.2025548578], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6147600.0000, 
sim time next is 6148200.0000, 
raw observation next is [22.86666666666667, 90.0, 1.0, 2.0, 0.2830956816986133, 1.0, 2.0, 0.2830956816986133, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667076.1333464056, 667076.1333464056, 177478.393525483], 
processed observation next is [1.0, 0.13043478260869565, 0.4024691358024693, 0.9, 1.0, 1.0, 0.1465424782126349, 1.0, 1.0, 0.1465424782126349, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23824147619514485, 0.23824147619514485, 0.34130460293362114], 
reward next is 0.6587, 
noisyNet noise sample is [array([-1.0703732], dtype=float32), 0.6903376]. 
=============================================
[2019-03-24 07:30:33,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3547111e-03 5.1623385e-04 1.1107450e-02 9.7857350e-01 7.4481908e-03], sum to 1.0000
[2019-03-24 07:30:33,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6557
[2019-03-24 07:30:33,535] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 52.0, 1.0, 2.0, 0.1892680141492854, 1.0, 2.0, 0.1892680141492854, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469053.9367859669, 469053.9367859674, 157678.8300729014], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6573600.0000, 
sim time next is 6574200.0000, 
raw observation next is [25.6, 51.66666666666667, 1.0, 2.0, 0.3238930973224321, 1.0, 2.0, 0.3238930973224321, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 801849.6634839317, 801849.6634839321, 188725.0823950894], 
processed observation next is [1.0, 0.08695652173913043, 0.5037037037037038, 0.5166666666666667, 1.0, 1.0, 0.1951108301457525, 1.0, 1.0, 0.1951108301457525, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2863748798156899, 0.28637487981569004, 0.3629328507597873], 
reward next is 0.6371, 
noisyNet noise sample is [array([-0.49021816], dtype=float32), -0.14554974]. 
=============================================
[2019-03-24 07:30:34,110] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0398276e-06 3.0007693e-06 3.1107629e-06 9.9986506e-01 1.2379803e-04], sum to 1.0000
[2019-03-24 07:30:34,118] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5265
[2019-03-24 07:30:34,124] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 67.66666666666667, 1.0, 2.0, 0.3358046630654842, 1.0, 2.0, 0.3358046630654842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765428.4846351668, 765428.4846351673, 189275.2408455001], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6470400.0000, 
sim time next is 6471000.0000, 
raw observation next is [29.2, 68.0, 1.0, 2.0, 0.3365217758626736, 1.0, 2.0, 0.3365217758626736, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767063.8794604953, 767063.8794604953, 189456.2679071896], 
processed observation next is [1.0, 0.9130434782608695, 0.637037037037037, 0.68, 1.0, 1.0, 0.21014497126508766, 1.0, 1.0, 0.21014497126508766, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2739513855216055, 0.2739513855216055, 0.3643389767445954], 
reward next is 0.6357, 
noisyNet noise sample is [array([-0.11720997], dtype=float32), 0.4465392]. 
=============================================
[2019-03-24 07:30:34,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.693954]
 [60.67773 ]
 [60.62877 ]
 [60.265293]
 [60.096607]], R is [[60.76136017]
 [60.78975677]
 [60.81941986]
 [60.84542465]
 [60.87065887]].
[2019-03-24 07:30:36,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7708896e-07 2.3390967e-06 8.0189784e-06 9.9458474e-01 5.4041944e-03], sum to 1.0000
[2019-03-24 07:30:36,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0265
[2019-03-24 07:30:36,838] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 88.5, 1.0, 2.0, 0.4474779258489503, 1.0, 2.0, 0.4474779258489503, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1020144.383376394, 1020144.383376394, 219618.3228178492], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6507000.0000, 
sim time next is 6507600.0000, 
raw observation next is [26.3, 88.66666666666666, 1.0, 2.0, 0.4206709489893439, 1.0, 2.0, 0.4206709489893439, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 958992.5424854669, 958992.5424854669, 211940.4442127736], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.8866666666666666, 1.0, 1.0, 0.3103225583206474, 1.0, 1.0, 0.3103225583206474, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3424973366019525, 0.3424973366019525, 0.4075777773322569], 
reward next is 0.5924, 
noisyNet noise sample is [array([-0.7718117], dtype=float32), 1.3763282]. 
=============================================
[2019-03-24 07:30:40,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4558160e-05 1.4860940e-04 2.3816197e-05 9.9593782e-01 3.8051102e-03], sum to 1.0000
[2019-03-24 07:30:40,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7458
[2019-03-24 07:30:40,495] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.4082204655863468, 1.0, 2.0, 0.4082204655863468, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 211666.4459675247], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6603600.0000, 
sim time next is 6604200.0000, 
raw observation next is [26.8, 39.5, 1.0, 2.0, 0.4166703159867465, 1.0, 2.0, 0.4166703159867465, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1040861.333171437, 1040861.333171437, 214077.0765948426], 
processed observation next is [1.0, 0.43478260869565216, 0.5481481481481482, 0.395, 1.0, 1.0, 0.30555989998422206, 1.0, 1.0, 0.30555989998422206, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37173619041837036, 0.37173619041837036, 0.41168668575931266], 
reward next is 0.5883, 
noisyNet noise sample is [array([0.30226317], dtype=float32), -0.22775657]. 
=============================================
[2019-03-24 07:30:40,505] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 07:30:40,506] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:30:40,506] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:30:40,507] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:40,508] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:40,509] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:30:40,511] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:30:40,508] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:30:40,513] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:40,512] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:40,515] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:40,530] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-24 07:30:40,530] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-24 07:30:40,561] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-24 07:30:40,589] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-24 07:30:40,651] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-24 07:31:01,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00962229], dtype=float32), 0.006487979]
[2019-03-24 07:31:01,889] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.40157201333333, 44.59644073333334, 1.0, 2.0, 0.1824106504648519, 1.0, 2.0, 0.1824106504648519, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 452798.1099143441, 452798.1099143445, 156267.9254756918]
[2019-03-24 07:31:01,890] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:31:01,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2071376e-06 6.8230020e-06 5.2242972e-06 9.9982762e-01 1.5413892e-04], sampled 0.3059672579012471
[2019-03-24 07:31:56,102] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00962229], dtype=float32), 0.006487979]
[2019-03-24 07:31:56,104] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.90083164, 79.8771319, 1.0, 2.0, 0.2740671185588452, 1.0, 2.0, 0.2740671185588452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 637949.0348531125, 637949.034853113, 175004.3630610126]
[2019-03-24 07:31:56,104] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:31:56,108] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.7684451e-06 6.0881734e-06 4.7525109e-06 9.9983454e-01 1.4886298e-04], sampled 0.07133954971019385
[2019-03-24 07:32:01,800] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00962229], dtype=float32), 0.006487979]
[2019-03-24 07:32:01,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.386726655, 74.49960267, 1.0, 2.0, 0.2303474222293875, 1.0, 2.0, 0.2303474222293875, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549355.5718679964, 549355.5718679964, 165751.93698425]
[2019-03-24 07:32:01,804] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:32:01,806] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5195582e-06 6.8873919e-06 5.4130023e-06 9.9981540e-01 1.6580342e-04], sampled 0.9968001112339296
[2019-03-24 07:32:11,849] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00962229], dtype=float32), 0.006487979]
[2019-03-24 07:32:11,851] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.74383914, 26.68519509, 1.0, 2.0, 0.1607629365430929, 1.0, 2.0, 0.1607629365430929, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412089.5248310518, 412089.5248310518, 152051.0466763635]
[2019-03-24 07:32:11,852] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:32:11,854] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5759703e-06 4.9922241e-06 3.8135850e-06 9.9986386e-01 1.2271377e-04], sampled 0.583015028458795
[2019-03-24 07:32:20,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00962229], dtype=float32), 0.006487979]
[2019-03-24 07:32:20,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.65898099666667, 90.00854472666666, 1.0, 2.0, 0.2060792554928112, 1.0, 2.0, 0.2060792554928112, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 505111.0467723511, 505111.0467723515, 161043.6570085098]
[2019-03-24 07:32:20,230] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:32:20,234] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.1683695e-06 6.6817702e-06 5.1579073e-06 9.9982893e-01 1.5304977e-04], sampled 0.42241606265887177
[2019-03-24 07:32:27,458] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.0814 2410821550.9957 22.0000
[2019-03-24 07:32:27,558] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6903.9174 2495617809.9823 47.0000
[2019-03-24 07:32:27,728] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.0512 2668660363.7876 68.0000
[2019-03-24 07:32:27,884] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438823943.2105 34.0000
[2019-03-24 07:32:27,980] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3655 2465965318.3758 46.0000
[2019-03-24 07:32:28,997] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1025000, evaluation results [1025000.0, 7521.051183028155, 2668660363.787599, 68.0, 7121.435945869477, 2438823943.210535, 34.0, 7796.0814448339725, 2410821550.9957495, 22.0, 6903.917436216376, 2495617809.982325, 47.0, 7478.365512649802, 2465965318.375804, 46.0]
[2019-03-24 07:32:30,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3838992e-06 2.9790144e-05 5.9828708e-06 9.9987543e-01 8.5355437e-05], sum to 1.0000
[2019-03-24 07:32:30,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1945
[2019-03-24 07:32:30,679] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394748.5963924241, 394748.5963924245, 149781.4689122092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6679200.0000, 
sim time next is 6679800.0000, 
raw observation next is [23.0, 50.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385824.5072976518, 385824.5072976518, 148489.8307674018], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.505, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1377944668920185, 0.1377944668920185, 0.28555736686038813], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2852347], dtype=float32), -0.46379685]. 
=============================================
[2019-03-24 07:32:30,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1300337e-04 1.5319916e-05 4.9520208e-05 9.9797088e-01 1.7511768e-03], sum to 1.0000
[2019-03-24 07:32:30,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0418
[2019-03-24 07:32:30,799] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 50.66666666666666, 1.0, 2.0, 0.2217230506779791, 1.0, 2.0, 0.2217230506779791, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550800.5076378606, 550800.5076378606, 164611.5982806282], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6576000.0000, 
sim time next is 6576600.0000, 
raw observation next is [25.6, 50.33333333333334, 1.0, 2.0, 0.2136621711323669, 1.0, 2.0, 0.2136621711323669, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 531418.7537157466, 531418.753715747, 162877.6586076702], 
processed observation next is [1.0, 0.08695652173913043, 0.5037037037037038, 0.5033333333333334, 1.0, 1.0, 0.06388353706234155, 1.0, 1.0, 0.06388353706234155, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18979241204133807, 0.18979241204133823, 0.3132262665532119], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.6832356], dtype=float32), 1.8302591]. 
=============================================
[2019-03-24 07:32:30,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1709403e-04 1.6028414e-05 5.0330058e-05 9.9787152e-01 1.8450529e-03], sum to 1.0000
[2019-03-24 07:32:30,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-24 07:32:30,899] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 49.33333333333334, 1.0, 2.0, 0.2328959471630182, 1.0, 2.0, 0.2328959471630182, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580078.5884446373, 580078.5884446377, 167110.0128744592], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6578400.0000, 
sim time next is 6579000.0000, 
raw observation next is [25.6, 49.0, 1.0, 2.0, 0.2449385530091136, 1.0, 2.0, 0.2449385530091136, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610469.1675760486, 610469.1675760486, 169824.5835697291], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.49, 1.0, 1.0, 0.10111732501084952, 1.0, 1.0, 0.10111732501084952, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21802470270573165, 0.21802470270573165, 0.3265857376340944], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.6832356], dtype=float32), 1.8302591]. 
=============================================
[2019-03-24 07:32:30,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[58.55128 ]
 [58.48213 ]
 [58.67382 ]
 [58.7372  ]
 [58.703804]], R is [[58.25567245]
 [58.35174942]
 [58.44145203]
 [58.54222107]
 [58.64357376]].
[2019-03-24 07:32:34,361] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7984036e-06 4.0321383e-06 2.3629418e-06 9.9980396e-01 1.8488472e-04], sum to 1.0000
[2019-03-24 07:32:34,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8267
[2019-03-24 07:32:34,372] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.56666666666667, 38.66666666666666, 1.0, 2.0, 0.3276459470561685, 1.0, 2.0, 0.3276459470561685, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 824238.6104015054, 824238.6104015063, 189941.2755687556], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6691200.0000, 
sim time next is 6691800.0000, 
raw observation next is [26.78333333333333, 37.83333333333334, 1.0, 2.0, 0.3309982159935595, 1.0, 2.0, 0.3309982159935595, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832510.5006622548, 832510.5006622552, 190801.2135055885], 
processed observation next is [1.0, 0.43478260869565216, 0.5475308641975308, 0.3783333333333334, 1.0, 1.0, 0.2035693047542375, 1.0, 1.0, 0.2035693047542375, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2973251788079481, 0.2973251788079483, 0.3669254105876702], 
reward next is 0.6331, 
noisyNet noise sample is [array([1.6731001], dtype=float32), -0.3480162]. 
=============================================
[2019-03-24 07:32:34,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9455890e-07 3.1132694e-07 6.7584989e-07 9.9999011e-01 8.5965903e-06], sum to 1.0000
[2019-03-24 07:32:34,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2107
[2019-03-24 07:32:34,394] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.91666666666667, 75.16666666666667, 1.0, 2.0, 0.1726357838592382, 1.0, 2.0, 0.1726357838592382, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 432869.3515947949, 432869.3515947954, 154357.5334962196], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6736200.0000, 
sim time next is 6736800.0000, 
raw observation next is [20.83333333333334, 75.33333333333334, 1.0, 2.0, 0.1721864844374127, 1.0, 2.0, 0.1721864844374127, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 432035.0809444826, 432035.0809444831, 154271.5844108268], 
processed observation next is [1.0, 1.0, 0.3271604938271607, 0.7533333333333334, 1.0, 1.0, 0.014507719568348437, 1.0, 1.0, 0.014507719568348437, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15429824319445806, 0.15429824319445826, 0.2966761238669746], 
reward next is 0.7033, 
noisyNet noise sample is [array([1.4043736], dtype=float32), -0.061980914]. 
=============================================
[2019-03-24 07:32:36,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0613568e-07 5.6807708e-06 1.4771844e-07 9.9981970e-01 1.7403587e-04], sum to 1.0000
[2019-03-24 07:32:36,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1631
[2019-03-24 07:32:36,086] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.93333333333334, 78.33333333333334, 1.0, 2.0, 0.2440125681029227, 1.0, 2.0, 0.2440125681029227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 581423.9595103266, 581423.9595103271, 168759.9650824474], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6819600.0000, 
sim time next is 6820200.0000, 
raw observation next is [23.85, 79.0, 1.0, 2.0, 0.2439838770404038, 1.0, 2.0, 0.2439838770404038, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581216.2608609654, 581216.2608609654, 168747.8764633466], 
processed observation next is [1.0, 0.9565217391304348, 0.43888888888888894, 0.79, 1.0, 1.0, 0.09998080600048072, 1.0, 1.0, 0.09998080600048072, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20757723602177333, 0.20757723602177333, 0.3245151470448973], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.03811873], dtype=float32), 0.74316984]. 
=============================================
[2019-03-24 07:32:38,775] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0790202e-06 2.2594943e-06 3.1199477e-07 9.9997950e-01 1.0816093e-05], sum to 1.0000
[2019-03-24 07:32:38,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-24 07:32:38,786] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.36666666666667, 74.33333333333334, 1.0, 2.0, 0.2390616927548897, 1.0, 2.0, 0.2390616927548897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571272.1156407197, 571272.1156407197, 167721.6252904769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6816000.0000, 
sim time next is 6816600.0000, 
raw observation next is [24.3, 75.0, 1.0, 2.0, 0.2395906718704284, 1.0, 2.0, 0.2395906718704284, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572217.097322016, 572217.0973220165, 167826.6079728255], 
processed observation next is [1.0, 0.9130434782608695, 0.4555555555555556, 0.75, 1.0, 1.0, 0.0947507998457481, 1.0, 1.0, 0.0947507998457481, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20436324904357714, 0.2043632490435773, 0.3227434768708183], 
reward next is 0.6773, 
noisyNet noise sample is [array([2.4040627], dtype=float32), 1.3800459]. 
=============================================
[2019-03-24 07:32:41,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.08024401e-04 1.05105455e-05 3.37132624e-05 9.97203469e-01
 2.54430226e-03], sum to 1.0000
[2019-03-24 07:32:41,795] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-24 07:32:41,802] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 48.83333333333334, 1.0, 2.0, 0.2567061206950114, 1.0, 2.0, 0.2567061206950114, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603097.0513937526, 603097.051393753, 171269.8667140707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6873000.0000, 
sim time next is 6873600.0000, 
raw observation next is [30.33333333333334, 48.66666666666667, 1.0, 2.0, 0.2593705197748464, 1.0, 2.0, 0.2593705197748464, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608064.3328104336, 608064.3328104336, 171819.5373765496], 
processed observation next is [0.0, 0.5652173913043478, 0.6790123456790126, 0.4866666666666667, 1.0, 1.0, 0.11829823782719806, 1.0, 1.0, 0.11829823782719806, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21716583314658341, 0.21716583314658341, 0.33042218726259537], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.8916464], dtype=float32), 0.9896857]. 
=============================================
[2019-03-24 07:32:42,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9611564e-08 1.2120309e-07 7.2682963e-07 9.9998105e-01 1.8063032e-05], sum to 1.0000
[2019-03-24 07:32:43,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3731
[2019-03-24 07:32:43,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.1, 76.0, 1.0, 2.0, 0.1965308304601389, 1.0, 2.0, 0.1965308304601389, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484484.0206114701, 484484.0206114706, 159118.3426875747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6837600.0000, 
sim time next is 6838200.0000, 
raw observation next is [22.05, 76.0, 1.0, 2.0, 0.1950497137968435, 1.0, 2.0, 0.1950497137968435, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481180.6212695008, 481180.6212695012, 158819.1081132688], 
processed observation next is [0.0, 0.13043478260869565, 0.37222222222222223, 0.76, 1.0, 1.0, 0.04172584975814701, 1.0, 1.0, 0.04172584975814701, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17185022188196458, 0.17185022188196472, 0.30542136175628615], 
reward next is 0.6946, 
noisyNet noise sample is [array([0.90758634], dtype=float32), -1.3811039]. 
=============================================
[2019-03-24 07:32:43,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0259146e-06 6.2101353e-06 3.6894960e-06 9.9992418e-01 6.4801694e-05], sum to 1.0000
[2019-03-24 07:32:43,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4931
[2019-03-24 07:32:43,706] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 76.0, 1.0, 2.0, 0.2050879932082439, 1.0, 2.0, 0.2050879932082439, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500890.9799163814, 500890.9799163814, 160775.1452078877], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6850800.0000, 
sim time next is 6851400.0000, 
raw observation next is [22.88333333333333, 76.0, 1.0, 2.0, 0.2068725735940424, 1.0, 2.0, 0.2068725735940424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 504578.8113450795, 504578.81134508, 161131.138996528], 
processed observation next is [0.0, 0.30434782608695654, 0.4030864197530863, 0.76, 1.0, 1.0, 0.05580068285005048, 1.0, 1.0, 0.05580068285005048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18020671833752838, 0.18020671833752855, 0.30986757499332307], 
reward next is 0.6901, 
noisyNet noise sample is [array([-2.1664164], dtype=float32), 1.801689]. 
=============================================
[2019-03-24 07:32:48,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5916750e-07 1.7327169e-07 9.6907561e-06 9.9998677e-01 3.2518744e-06], sum to 1.0000
[2019-03-24 07:32:48,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9330
[2019-03-24 07:32:48,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.7, 83.0, 1.0, 2.0, 0.29258772041102, 1.0, 2.0, 0.29258772041102, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713309.0340733031, 713309.0340733036, 180621.7606596754], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7009200.0000, 
sim time next is 7009800.0000, 
raw observation next is [21.6, 83.66666666666667, 1.0, 2.0, 0.3152636547572605, 1.0, 2.0, 0.3152636547572605, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768185.8993674755, 768185.899367476, 186202.8655384502], 
processed observation next is [1.0, 0.13043478260869565, 0.3555555555555556, 0.8366666666666667, 1.0, 1.0, 0.1848376842348339, 1.0, 1.0, 0.1848376842348339, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27435210691695555, 0.2743521069169557, 0.3580824337277888], 
reward next is 0.6419, 
noisyNet noise sample is [array([0.129072], dtype=float32), 0.6633799]. 
=============================================
[2019-03-24 07:32:51,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8355938e-07 1.2020929e-05 8.1262891e-07 9.9947840e-01 5.0841289e-04], sum to 1.0000
[2019-03-24 07:32:51,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3131
[2019-03-24 07:32:51,098] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 66.0, 1.0, 2.0, 0.2183731477321422, 1.0, 2.0, 0.2183731477321422, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530800.7187549783, 530800.7187549787, 163534.4451212568], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6991200.0000, 
sim time next is 6991800.0000, 
raw observation next is [24.46666666666667, 66.66666666666667, 1.0, 2.0, 0.2177520378737337, 1.0, 2.0, 0.2177520378737337, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529509.7766815685, 529509.7766815688, 163407.7875459346], 
processed observation next is [0.0, 0.9565217391304348, 0.46172839506172847, 0.6666666666666667, 1.0, 1.0, 0.06875242604015917, 1.0, 1.0, 0.06875242604015917, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1891106345291316, 0.1891106345291317, 0.3142457452806435], 
reward next is 0.6858, 
noisyNet noise sample is [array([-1.260812], dtype=float32), 0.9393813]. 
=============================================
[2019-03-24 07:32:55,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3660223e-06 1.2290664e-06 2.0401854e-05 9.9996185e-01 1.0142023e-05], sum to 1.0000
[2019-03-24 07:32:55,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6184
[2019-03-24 07:32:55,353] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.56666666666667, 85.33333333333334, 1.0, 2.0, 0.2201075091245459, 1.0, 2.0, 0.2201075091245459, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 544049.110297694, 544049.1102976945, 164188.8706649968], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7266000.0000, 
sim time next is 7266600.0000, 
raw observation next is [20.55, 85.5, 1.0, 2.0, 0.2029444675306771, 1.0, 2.0, 0.2029444675306771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 502023.6804105814, 502023.6804105819, 160516.072662369], 
processed observation next is [1.0, 0.08695652173913043, 0.3166666666666667, 0.855, 1.0, 1.0, 0.05112436610794893, 1.0, 1.0, 0.05112436610794893, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17929417157520763, 0.1792941715752078, 0.30868475511994037], 
reward next is 0.6913, 
noisyNet noise sample is [array([0.8710883], dtype=float32), 0.17637153]. 
=============================================
[2019-03-24 07:33:04,725] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.64146739e-07 2.25886424e-06 1.02750484e-07 9.99976277e-01
 2.07149587e-05], sum to 1.0000
[2019-03-24 07:33:04,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5573
[2019-03-24 07:33:04,742] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 96.0, 1.0, 2.0, 0.1891549949065384, 1.0, 2.0, 0.1891549949065384, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 468979.2119544508, 468979.2119544512, 157661.0200399523], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [19.16666666666667, 95.83333333333333, 1.0, 2.0, 0.222882832629442, 1.0, 2.0, 0.222882832629442, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 552510.2683927509, 552510.2683927513, 164836.2071641823], 
processed observation next is [1.0, 0.30434782608695654, 0.2654320987654323, 0.9583333333333333, 1.0, 1.0, 0.07486051503505001, 1.0, 1.0, 0.07486051503505001, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19732509585455388, 0.19732509585455404, 0.31699270608496594], 
reward next is 0.6830, 
noisyNet noise sample is [array([-0.13414468], dtype=float32), -0.24487591]. 
=============================================
[2019-03-24 07:33:11,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.51875207e-07 1.78227168e-07 1.12425866e-07 9.99999046e-01
 4.19660495e-07], sum to 1.0000
[2019-03-24 07:33:11,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3130
[2019-03-24 07:33:11,698] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.36666666666667, 90.33333333333334, 1.0, 2.0, 0.1996023602708376, 1.0, 2.0, 0.1996023602708376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491122.6129650562, 491122.6129650567, 159734.7773662702], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7413600.0000, 
sim time next is 7414200.0000, 
raw observation next is [20.3, 90.5, 1.0, 2.0, 0.1987220509917572, 1.0, 2.0, 0.1987220509917572, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489289.4955323222, 489289.4955323226, 159559.9033510637], 
processed observation next is [1.0, 0.8260869565217391, 0.3074074074074074, 0.905, 1.0, 1.0, 0.046097679752091884, 1.0, 1.0, 0.046097679752091884, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17474624840440078, 0.17474624840440092, 0.30684596798281477], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.15277001], dtype=float32), -0.29503536]. 
=============================================
[2019-03-24 07:33:13,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9785407e-06 1.2668403e-07 2.8644627e-07 9.9993515e-01 6.2475352e-05], sum to 1.0000
[2019-03-24 07:33:13,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1757
[2019-03-24 07:33:13,678] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 93.66666666666667, 1.0, 2.0, 0.2414994723369975, 1.0, 2.0, 0.2414994723369975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574402.9506259514, 574402.9506259514, 168155.7719895334], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7510800.0000, 
sim time next is 7511400.0000, 
raw observation next is [21.95, 94.0, 1.0, 2.0, 0.2411304556541509, 1.0, 2.0, 0.2411304556541509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573627.2464989118, 573627.2464989118, 168077.7166028548], 
processed observation next is [0.0, 0.9565217391304348, 0.36851851851851847, 0.94, 1.0, 1.0, 0.09658387577875106, 1.0, 1.0, 0.09658387577875106, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20486687374961135, 0.20486687374961135, 0.3232263780824131], 
reward next is 0.6768, 
noisyNet noise sample is [array([-0.91415036], dtype=float32), -0.4187679]. 
=============================================
[2019-03-24 07:33:17,564] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 07:33:17,566] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:33:17,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:17,567] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:33:17,568] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:17,568] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:33:17,569] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:17,570] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:33:17,570] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:17,571] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:33:17,571] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:17,596] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-24 07:33:17,626] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-24 07:33:17,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-24 07:33:17,627] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-24 07:33:17,715] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-24 07:33:47,646] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00969699], dtype=float32), 0.0067826933]
[2019-03-24 07:33:47,646] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 77.66666666666666, 1.0, 2.0, 0.3268903076941369, 1.0, 2.0, 0.3268903076941369, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 789190.3434142526, 789190.343414254, 188904.5724703626]
[2019-03-24 07:33:47,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:33:47,650] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.2356460e-07 1.1338144e-06 6.0740416e-07 9.9998403e-01 1.3512418e-05], sampled 0.5982177675588852
[2019-03-24 07:33:53,252] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00969699], dtype=float32), 0.0067826933]
[2019-03-24 07:33:53,253] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 67.33333333333334, 1.0, 2.0, 0.2957925818399542, 1.0, 2.0, 0.2957925818399542, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678899.5503618886, 678899.5503618891, 179688.9595810836]
[2019-03-24 07:33:53,254] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:33:53,257] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9755594e-07 6.4589608e-07 3.3032117e-07 9.9999058e-01 8.1084045e-06], sampled 0.030674163257910503
[2019-03-24 07:34:01,979] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00969699], dtype=float32), 0.0067826933]
[2019-03-24 07:34:01,980] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.2, 70.33333333333334, 1.0, 2.0, 0.405017576923755, 1.0, 2.0, 0.405017576923755, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 923286.4637895274, 923286.4637895274, 207574.0379710796]
[2019-03-24 07:34:01,980] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:34:01,982] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0763007e-07 4.9732165e-07 2.5091853e-07 9.9999213e-01 6.7682558e-06], sampled 0.5847414385865211
[2019-03-24 07:34:40,339] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00969699], dtype=float32), 0.0067826933]
[2019-03-24 07:34:40,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 66.0, 1.0, 2.0, 0.3399986765120319, 1.0, 2.0, 0.3399986765120319, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774993.09342585, 774993.0934258505, 190337.0299987523]
[2019-03-24 07:34:40,343] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:34:40,346] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3254243e-07 3.8049529e-07 1.9113646e-07 9.9999392e-01 5.2859828e-06], sampled 0.7645778111892421
[2019-03-24 07:34:45,558] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00969699], dtype=float32), 0.0067826933]
[2019-03-24 07:34:45,559] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 91.5, 1.0, 2.0, 0.2635104451403691, 1.0, 2.0, 0.2635104451403691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 612167.9307065371, 612167.9307065376, 172510.1300532078]
[2019-03-24 07:34:45,560] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:34:45,563] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.8110772e-07 6.1067522e-07 3.1227202e-07 9.9999046e-01 8.2025826e-06], sampled 0.3602680382332386
[2019-03-24 07:35:03,633] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0851 2668494907.5392 68.0000
[2019-03-24 07:35:03,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5185 2410717485.2201 22.0000
[2019-03-24 07:35:04,195] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:35:04,225] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2560 2438846906.2922 34.0000
[2019-03-24 07:35:04,227] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7476.4021 2466015806.2384 46.0000
[2019-03-24 07:35:05,239] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1050000, evaluation results [1050000.0, 7523.085099490553, 2668494907.5392137, 68.0, 7122.256019127809, 2438846906.29219, 34.0, 7797.518498262271, 2410717485.220095, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7476.40206146826, 2466015806.23839, 46.0]
[2019-03-24 07:35:06,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0425848e-07 7.4913419e-07 2.6759417e-05 9.9988985e-01 8.2075829e-05], sum to 1.0000
[2019-03-24 07:35:06,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9498
[2019-03-24 07:35:06,640] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.26666666666667, 81.33333333333334, 1.0, 2.0, 0.5384811421545163, 1.0, 2.0, 0.5384811421545163, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1253809.276179431, 1253809.276179432, 248763.3687709358], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7639800.0000, 
sim time next is 7640400.0000, 
raw observation next is [24.53333333333333, 80.66666666666667, 1.0, 2.0, 0.5278344200509202, 1.0, 2.0, 0.5278344200509202, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1224772.301429021, 1224772.30142902, 245132.1156304112], 
processed observation next is [1.0, 0.43478260869565216, 0.46419753086419746, 0.8066666666666668, 1.0, 1.0, 0.4378981191082383, 1.0, 1.0, 0.4378981191082383, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4374186790817932, 0.4374186790817929, 0.47140791467386767], 
reward next is 0.5286, 
noisyNet noise sample is [array([0.5941583], dtype=float32), 0.24230316]. 
=============================================
[2019-03-24 07:35:07,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3850340e-09 3.2269419e-08 3.4775405e-09 9.9999964e-01 3.5442395e-07], sum to 1.0000
[2019-03-24 07:35:07,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6606
[2019-03-24 07:35:07,422] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.2858647266096653, 1.0, 2.0, 0.2858647266096653, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 655819.8805342345, 655819.8805342349, 177317.9769250496], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7570800.0000, 
sim time next is 7571400.0000, 
raw observation next is [28.0, 65.33333333333333, 1.0, 2.0, 0.2854333145832407, 1.0, 2.0, 0.2854333145832407, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 655540.1877735581, 655540.1877735585, 177251.3501526416], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.6533333333333333, 1.0, 1.0, 0.14932537450385802, 1.0, 1.0, 0.14932537450385802, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2341214956334136, 0.23412149563341378, 0.3408679810627723], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.39878798], dtype=float32), -1.0137646]. 
=============================================
[2019-03-24 07:35:09,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0891631e-06 4.5598667e-06 1.2695883e-06 9.9987471e-01 1.1832736e-04], sum to 1.0000
[2019-03-24 07:35:09,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6666
[2019-03-24 07:35:09,029] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.7, 67.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 344300.839220677, 344300.839220677, 142154.0156691054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7693800.0000, 
sim time next is 7694400.0000, 
raw observation next is [19.7, 66.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 334976.514701707, 334976.5147017075, 140693.757313996], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.66, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11963446953632392, 0.11963446953632412, 0.27056491791153076], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10588095], dtype=float32), -0.7348714]. 
=============================================
[2019-03-24 07:35:09,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8649393e-07 7.2149214e-06 1.1328344e-05 9.9974066e-01 2.4002160e-04], sum to 1.0000
[2019-03-24 07:35:09,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-24 07:35:09,466] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.85, 91.0, 1.0, 2.0, 0.1943562002379381, 1.0, 2.0, 0.1943562002379381, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481238.3611880448, 481238.3611880452, 158724.3890315779], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7619400.0000, 
sim time next is 7620000.0000, 
raw observation next is [19.76666666666667, 91.33333333333333, 1.0, 2.0, 0.1898209646485033, 1.0, 2.0, 0.1898209646485033, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470318.2628548548, 470318.2628548553, 157790.4138766149], 
processed observation next is [1.0, 0.17391304347826086, 0.2876543209876544, 0.9133333333333333, 1.0, 1.0, 0.03550114839107534, 1.0, 1.0, 0.03550114839107534, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16797080816244814, 0.1679708081624483, 0.30344310360887483], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.49100065], dtype=float32), 0.52692807]. 
=============================================
[2019-03-24 07:35:09,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.324894]
 [62.338127]
 [62.28984 ]
 [62.392143]
 [61.776066]], R is [[62.38653946]
 [62.45743561]
 [62.52880478]
 [62.58991241]
 [62.66007614]].
[2019-03-24 07:35:09,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1826672e-05 4.1565301e-05 5.8806843e-05 9.9964106e-01 2.0674085e-04], sum to 1.0000
[2019-03-24 07:35:09,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3826
[2019-03-24 07:35:09,922] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.35, 88.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 392634.253731626, 392634.2537316264, 149930.2696879089], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7705800.0000, 
sim time next is 7706400.0000, 
raw observation next is [18.26666666666667, 90.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391551.9362631736, 391551.9362631741, 149844.353496089], 
processed observation next is [1.0, 0.17391304347826086, 0.23209876543209887, 0.9033333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1398399772368477, 0.1398399772368479, 0.2881622182617096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5419493], dtype=float32), -0.3576584]. 
=============================================
[2019-03-24 07:35:12,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5000361e-06 2.1784184e-07 4.5762968e-06 9.9992383e-01 6.6824970e-05], sum to 1.0000
[2019-03-24 07:35:12,650] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8757
[2019-03-24 07:35:12,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.61666666666667, 85.33333333333334, 1.0, 2.0, 0.170412091637291, 1.0, 2.0, 0.170412091637291, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427448.1318835791, 427448.1318835796, 153905.4791698796], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7685400.0000, 
sim time next is 7686000.0000, 
raw observation next is [19.6, 86.0, 1.0, 2.0, 0.1711593989526257, 1.0, 2.0, 0.1711593989526257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428982.3128328909, 428982.3128328909, 154050.9996510482], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.86, 1.0, 1.0, 0.01328499875312582, 1.0, 1.0, 0.01328499875312582, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1532079688688896, 0.1532079688688896, 0.2962519224058619], 
reward next is 0.7037, 
noisyNet noise sample is [array([-0.87626886], dtype=float32), -1.4265401]. 
=============================================
[2019-03-24 07:35:12,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.11367]
 [63.07685]
 [63.04152]
 [63.0179 ]
 [63.01877]], R is [[63.28907013]
 [63.36021042]
 [63.43072128]
 [63.5005455 ]
 [63.57008362]].
[2019-03-24 07:35:15,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:15,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:15,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-24 07:35:18,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:18,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:18,213] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-24 07:35:20,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.10914698e-06 1.10040382e-05 9.11128595e-08 9.99972820e-01
 1.49697735e-05], sum to 1.0000
[2019-03-24 07:35:20,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0080
[2019-03-24 07:35:20,575] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.21666666666667, 73.5, 1.0, 2.0, 0.2120919583212907, 1.0, 2.0, 0.2120919583212907, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 517250.1240211853, 517250.1240211858, 162242.2035343327], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7863000.0000, 
sim time next is 7863600.0000, 
raw observation next is [23.13333333333333, 74.0, 1.0, 2.0, 0.2115494161831772, 1.0, 2.0, 0.2115494161831772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515992.4159968882, 515992.4159968887, 162128.2539356707], 
processed observation next is [1.0, 0.0, 0.41234567901234553, 0.74, 1.0, 1.0, 0.061368352599020494, 1.0, 1.0, 0.061368352599020494, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18428300571317435, 0.18428300571317455, 0.31178510372244367], 
reward next is 0.6882, 
noisyNet noise sample is [array([-0.9644066], dtype=float32), 0.46844697]. 
=============================================
[2019-03-24 07:35:20,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:20,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:20,715] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-24 07:35:21,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:21,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:21,952] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-24 07:35:22,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:22,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:22,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-24 07:35:22,369] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:22,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:22,415] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-24 07:35:23,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:23,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:23,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-24 07:35:23,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:23,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:23,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-24 07:35:23,653] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1059995: loss 0.0340
[2019-03-24 07:35:23,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1059995: learning rate 0.0000
[2019-03-24 07:35:23,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:23,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:23,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-24 07:35:24,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7191158e-05 2.2581140e-05 1.4486205e-05 9.9976665e-01 1.1913420e-04], sum to 1.0000
[2019-03-24 07:35:24,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4669
[2019-03-24 07:35:24,697] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 46.0, 1.0, 2.0, 0.6090137888630807, 1.0, 2.0, 0.6090137888630807, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419178.773913367, 1419178.773913368, 272609.5695898793], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 126000.0000, 
sim time next is 126600.0000, 
raw observation next is [30.88333333333333, 44.0, 1.0, 2.0, 0.6736515759708157, 1.0, 2.0, 0.6736515759708157, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1569653.208699377, 1569653.208699378, 295939.3894676986], 
processed observation next is [1.0, 0.4782608695652174, 0.6993827160493825, 0.44, 1.0, 1.0, 0.6114899713938282, 1.0, 1.0, 0.6114899713938282, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.560590431678349, 0.5605904316783493, 0.5691142105148049], 
reward next is 0.4309, 
noisyNet noise sample is [array([-0.77875334], dtype=float32), 0.06213621]. 
=============================================
[2019-03-24 07:35:24,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:24,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:24,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-24 07:35:25,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:25,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:25,134] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-24 07:35:25,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:25,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:25,276] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-24 07:35:25,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:25,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:25,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-24 07:35:25,853] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1061097: loss 0.0481
[2019-03-24 07:35:25,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1061097: learning rate 0.0000
[2019-03-24 07:35:25,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:25,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:25,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-24 07:35:26,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:26,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:26,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-24 07:35:26,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:35:26,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:26,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-24 07:35:27,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7864603e-05 9.4441864e-05 8.6553706e-07 9.9979550e-01 5.1406780e-05], sum to 1.0000
[2019-03-24 07:35:27,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7749
[2019-03-24 07:35:27,678] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.45, 40.0, 1.0, 2.0, 0.4642426993068308, 1.0, 2.0, 0.4642426993068308, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1149821.103461384, 1149821.103461384, 227973.9863542515], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 41400.0000, 
sim time next is 42000.0000, 
raw observation next is [27.63333333333333, 39.66666666666667, 1.0, 2.0, 0.4548845928804295, 1.0, 2.0, 0.4548845928804295, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1125525.340256907, 1125525.340256907, 225113.3899309355], 
processed observation next is [1.0, 0.4782608695652174, 0.5790123456790122, 0.3966666666666667, 1.0, 1.0, 0.35105308676241603, 1.0, 1.0, 0.35105308676241603, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4019733358060382, 0.4019733358060382, 0.43291036525179905], 
reward next is 0.5671, 
noisyNet noise sample is [array([-1.0901052], dtype=float32), 2.4568317]. 
=============================================
[2019-03-24 07:35:27,678] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1062037: loss 0.0095
[2019-03-24 07:35:27,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1062037: learning rate 0.0000
[2019-03-24 07:35:27,688] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.229153]
 [58.13688 ]
 [58.083088]
 [58.28401 ]
 [58.343582]], R is [[58.43658066]
 [58.4138031 ]
 [58.39644241]
 [58.38295364]
 [58.39222336]].
[2019-03-24 07:35:28,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.33507965e-05 4.29981264e-05 4.12974550e-05 9.99770820e-01
 1.31446955e-04], sum to 1.0000
[2019-03-24 07:35:28,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8267
[2019-03-24 07:35:28,258] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.96666666666667, 10.33333333333333, 1.0, 2.0, 0.1766266265268594, 1.0, 2.0, 0.1766266265268594, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455705.8753163369, 455705.8753163374, 141435.0937938669], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 168600.0000, 
sim time next is 169200.0000, 
raw observation next is [30.9, 10.0, 1.0, 2.0, 0.176324300662668, 1.0, 2.0, 0.176324300662668, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454925.6274993494, 454925.6274993498, 140610.1286939211], 
processed observation next is [1.0, 1.0, 0.7, 0.1, 1.0, 1.0, 0.01943369126508094, 1.0, 1.0, 0.01943369126508094, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1624734383926248, 0.16247343839262493, 0.270404093642156], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.8045471], dtype=float32), -0.9190327]. 
=============================================
[2019-03-24 07:35:29,164] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1062853: loss 0.0044
[2019-03-24 07:35:29,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1062856: learning rate 0.0000
[2019-03-24 07:35:29,194] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8488058e-07 7.3214801e-07 2.1791871e-07 9.9999809e-01 3.5343035e-07], sum to 1.0000
[2019-03-24 07:35:29,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-24 07:35:29,206] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 77.0, 1.0, 2.0, 0.1979155132939742, 1.0, 2.0, 0.1979155132939742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491976.6283981489, 491976.6283981493, 159519.1156770576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 103200.0000, 
sim time next is 103800.0000, 
raw observation next is [21.2, 77.0, 1.0, 2.0, 0.1948903544723478, 1.0, 2.0, 0.1948903544723478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 485114.1888441481, 485114.1888441486, 158901.5459343069], 
processed observation next is [1.0, 0.17391304347826086, 0.34074074074074073, 0.77, 1.0, 1.0, 0.041536136276604504, 1.0, 1.0, 0.041536136276604504, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1732550674443386, 0.17325506744433877, 0.30557989602751323], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.230894], dtype=float32), -0.45062798]. 
=============================================
[2019-03-24 07:35:29,797] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1063182: loss 0.0567
[2019-03-24 07:35:29,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1063182: learning rate 0.0000
[2019-03-24 07:35:29,932] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1063250: loss 0.0462
[2019-03-24 07:35:29,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1063250: learning rate 0.0000
[2019-03-24 07:35:31,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4901285e-06 2.3258320e-04 2.6028936e-06 9.9954033e-01 2.1991112e-04], sum to 1.0000
[2019-03-24 07:35:31,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2102
[2019-03-24 07:35:31,068] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.03333333333333, 76.33333333333334, 1.0, 2.0, 0.2099592979102282, 1.0, 2.0, 0.2099592979102282, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 517322.1323777917, 517322.1323777921, 161951.7460579623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [21.95, 76.5, 1.0, 2.0, 0.2053862202276909, 1.0, 2.0, 0.2053862202276909, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506676.9649014154, 506676.9649014154, 160995.1420074643], 
processed observation next is [1.0, 0.13043478260869565, 0.36851851851851847, 0.765, 1.0, 1.0, 0.054031214556774884, 1.0, 1.0, 0.054031214556774884, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18095605889336264, 0.18095605889336264, 0.30960604232204675], 
reward next is 0.6904, 
noisyNet noise sample is [array([1.0051353], dtype=float32), -0.13139027]. 
=============================================
[2019-03-24 07:35:31,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.908833]
 [63.97363 ]
 [63.772465]
 [63.592655]
 [63.60367 ]], R is [[63.76036072]
 [63.81130981]
 [63.8537941 ]
 [63.89332199]
 [63.93033218]].
[2019-03-24 07:35:31,860] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064259: loss 0.0058
[2019-03-24 07:35:31,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064260: learning rate 0.0000
[2019-03-24 07:35:31,906] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064280: loss 0.0119
[2019-03-24 07:35:31,912] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064281: learning rate 0.0000
[2019-03-24 07:35:31,974] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064322: loss 0.0127
[2019-03-24 07:35:31,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064323: learning rate 0.0000
[2019-03-24 07:35:33,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1237325e-06 5.4361310e-02 1.6438182e-05 9.4472784e-01 8.9335354e-04], sum to 1.0000
[2019-03-24 07:35:33,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3003
[2019-03-24 07:35:33,469] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.34999999999999, 13.5, 1.0, 2.0, 0.1899701906919613, 1.0, 2.0, 0.1899701906919613, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 486420.5655855501, 486420.5655855506, 158064.7012088819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 225000.0000, 
sim time next is 225600.0000, 
raw observation next is [33.36666666666667, 13.66666666666667, 1.0, 2.0, 0.1903488822060597, 1.0, 2.0, 0.1903488822060597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 487123.8338677238, 487123.8338677243, 158143.2694542498], 
processed observation next is [0.0, 0.6086956521739131, 0.7913580246913581, 0.1366666666666667, 1.0, 1.0, 0.036129621673880584, 1.0, 1.0, 0.036129621673880584, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17397279780990135, 0.17397279780990152, 0.3041216720274034], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.174059], dtype=float32), -2.0386107]. 
=============================================
[2019-03-24 07:35:33,485] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1065107: loss 0.0229
[2019-03-24 07:35:33,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1065108: learning rate 0.0000
[2019-03-24 07:35:33,749] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065238: loss 0.0191
[2019-03-24 07:35:33,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065240: learning rate 0.0000
[2019-03-24 07:35:33,926] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1065330: loss 0.0092
[2019-03-24 07:35:33,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1065330: learning rate 0.0000
[2019-03-24 07:35:34,475] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1065625: loss 0.0488
[2019-03-24 07:35:34,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1065625: learning rate 0.0000
[2019-03-24 07:35:35,034] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1065914: loss 0.0093
[2019-03-24 07:35:35,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1065914: learning rate 0.0000
[2019-03-24 07:35:35,870] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066350: loss 0.1122
[2019-03-24 07:35:35,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066351: learning rate 0.0000
[2019-03-24 07:35:36,062] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066452: loss 0.0790
[2019-03-24 07:35:36,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066453: learning rate 0.0000
[2019-03-24 07:35:37,036] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1066958: loss 3.1525
[2019-03-24 07:35:37,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1066961: learning rate 0.0000
[2019-03-24 07:35:37,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1099360e-05 2.4417691e-06 6.7452715e-06 9.9994171e-01 2.8002831e-05], sum to 1.0000
[2019-03-24 07:35:37,786] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-24 07:35:37,790] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 31.5, 1.0, 2.0, 0.1664759154716744, 1.0, 2.0, 0.1664759154716744, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423641.5986202279, 423641.5986202284, 153196.3780011558], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 311400.0000, 
sim time next is 312000.0000, 
raw observation next is [27.76666666666667, 31.33333333333333, 1.0, 2.0, 0.1664760321578643, 1.0, 2.0, 0.1664760321578643, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423735.6798993679, 423735.6798993684, 153197.1861335443], 
processed observation next is [0.0, 0.6086956521739131, 0.5839506172839507, 0.3133333333333333, 1.0, 1.0, 0.007709562092695593, 1.0, 1.0, 0.007709562092695593, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1513341713926314, 0.15133417139263156, 0.29460997333373906], 
reward next is 0.7054, 
noisyNet noise sample is [array([-0.90798956], dtype=float32), -0.29364663]. 
=============================================
[2019-03-24 07:35:37,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.015804]
 [59.927937]
 [59.866035]
 [59.798344]
 [59.68716 ]], R is [[60.16413498]
 [60.2678833 ]
 [60.37058258]
 [60.47221375]
 [60.57283401]].
[2019-03-24 07:35:40,503] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1068764: loss 3.0744
[2019-03-24 07:35:40,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1068767: learning rate 0.0000
[2019-03-24 07:35:42,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1069846: loss 1.4705
[2019-03-24 07:35:42,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1069846: learning rate 0.0000
[2019-03-24 07:35:43,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9524643e-04 9.5683261e-04 1.3163402e-03 9.9382532e-01 3.5063429e-03], sum to 1.0000
[2019-03-24 07:35:43,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5570
[2019-03-24 07:35:43,975] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.35, 56.0, 1.0, 2.0, 0.1795959769848328, 1.0, 2.0, 0.1795959769848328, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463369.247094969, 463369.2470949694, 152635.3170330223], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 354600.0000, 
sim time next is 355200.0000, 
raw observation next is [20.16666666666666, 56.66666666666667, 1.0, 2.0, 0.1736004220605688, 1.0, 2.0, 0.1736004220605688, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447895.8302987866, 447895.8302987866, 149847.5680718794], 
processed observation next is [1.0, 0.08695652173913043, 0.3024691358024689, 0.5666666666666668, 1.0, 1.0, 0.016190978643534287, 1.0, 1.0, 0.016190978643534287, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15996279653528092, 0.15996279653528092, 0.2881684001382296], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.61390394], dtype=float32), -0.4832137]. 
=============================================
[2019-03-24 07:35:44,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1070759: loss 3.3168
[2019-03-24 07:35:44,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1070759: learning rate 0.0000
[2019-03-24 07:35:45,214] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1071224: loss 1.3590
[2019-03-24 07:35:45,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1071224: learning rate 0.0000
[2019-03-24 07:35:45,277] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1071259: loss 1.4693
[2019-03-24 07:35:45,280] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1071259: learning rate 0.0000
[2019-03-24 07:35:47,132] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072227: loss 1.9428
[2019-03-24 07:35:47,135] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072227: learning rate 0.0000
[2019-03-24 07:35:47,142] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072232: loss 1.9624
[2019-03-24 07:35:47,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072232: learning rate 0.0000
[2019-03-24 07:35:47,676] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072515: loss 1.7704
[2019-03-24 07:35:47,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072516: learning rate 0.0000
[2019-03-24 07:35:48,544] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072963: loss 0.4911
[2019-03-24 07:35:48,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072963: learning rate 0.0000
[2019-03-24 07:35:49,139] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1073272: loss 1.5916
[2019-03-24 07:35:49,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1073273: learning rate 0.0000
[2019-03-24 07:35:49,277] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1073346: loss 1.4897
[2019-03-24 07:35:49,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1073346: learning rate 0.0000
[2019-03-24 07:35:50,116] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1073778: loss 2.0370
[2019-03-24 07:35:50,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1073778: learning rate 0.0000
[2019-03-24 07:35:50,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073853: loss 1.9307
[2019-03-24 07:35:50,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073853: learning rate 0.0000
[2019-03-24 07:35:51,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074356: loss 1.9806
[2019-03-24 07:35:51,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074356: learning rate 0.0000
[2019-03-24 07:35:51,317] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074413: loss 2.0518
[2019-03-24 07:35:51,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074413: learning rate 0.0000
[2019-03-24 07:35:52,442] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 07:35:52,443] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:35:52,444] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:35:52,445] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:52,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:52,446] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:35:52,446] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:52,447] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:35:52,447] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:52,448] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:35:52,449] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:35:52,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-24 07:35:52,466] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-24 07:35:52,528] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-24 07:35:52,529] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-24 07:35:52,602] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-24 07:35:55,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:35:55,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.75, 49.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 289602.5189416819, 289602.5189416824, 112608.8796069252]
[2019-03-24 07:35:55,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:35:55,045] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7121727e-05 2.1574504e-05 1.2455716e-05 9.9987054e-01 7.8295183e-05], sampled 0.6560186062725033
[2019-03-24 07:36:37,168] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:36:37,169] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.26666666666667, 34.33333333333334, 1.0, 2.0, 0.2840257192326283, 1.0, 2.0, 0.2840257192326283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647505.829575778, 647505.829575778, 176679.5710846093]
[2019-03-24 07:36:37,170] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:36:37,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5889909e-06 2.1017170e-06 1.0655789e-06 9.9998558e-01 9.6813865e-06], sampled 0.9803357599030669
[2019-03-24 07:36:40,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:36:40,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.17353951333333, 107.9661253366667, 1.0, 2.0, 0.2930536992434266, 1.0, 2.0, 0.2930536992434266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684333.7312685252, 684333.7312685252, 179585.2630610027]
[2019-03-24 07:36:40,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:36:40,291] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8589064e-06 4.9095474e-06 2.6268590e-06 9.9996781e-01 2.0809131e-05], sampled 0.8740109017996867
[2019-03-24 07:36:46,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:36:46,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 67.33333333333334, 1.0, 2.0, 0.938281940904694, 1.0, 2.0, 0.938281940904694, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.3246637748647, 2140506.089937528, 2140506.089937528, 404266.5894780933]
[2019-03-24 07:36:46,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:36:46,599] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.2974976e-07 8.2711961e-07 4.1625424e-07 9.9999356e-01 4.4794206e-06], sampled 0.516017976940082
[2019-03-24 07:36:58,227] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:36:58,228] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.03333333333333, 77.66666666666666, 1.0, 2.0, 0.2160711649092846, 1.0, 2.0, 0.2160711649092846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523685.6599072816, 523685.6599072821, 162983.9635364758]
[2019-03-24 07:36:58,229] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:58,233] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.8987205e-06 4.9962791e-06 2.6879848e-06 9.9996614e-01 2.2259082e-05], sampled 0.20371583834699503
[2019-03-24 07:37:02,870] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:37:02,871] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.04708869, 60.38289941000001, 1.0, 2.0, 0.6930757677203742, 1.0, 2.0, 0.6930757677203742, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1580627.369344058, 1580627.369344058, 301551.8068909493]
[2019-03-24 07:37:02,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:37:02,877] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.0156275e-07 1.0500603e-06 5.2887435e-07 9.9999201e-01 5.5869345e-06], sampled 0.8229273415385189
[2019-03-24 07:37:21,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:37:21,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.15, 45.0, 1.0, 2.0, 0.1812068310801177, 1.0, 2.0, 0.1812068310801177, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449362.2901478648, 449362.2901478652, 156004.7964931622]
[2019-03-24 07:37:21,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:37:21,904] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6992174e-06 4.8131533e-06 2.5880813e-06 9.9996924e-01 1.9714573e-05], sampled 0.15180631400607658
[2019-03-24 07:37:25,875] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00960761], dtype=float32), 0.0069918996]
[2019-03-24 07:37:25,876] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.75, 94.0, 1.0, 2.0, 0.2586583156918171, 1.0, 2.0, 0.2586583156918171, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 606155.5970218506, 606155.5970218511, 171646.3682256851]
[2019-03-24 07:37:25,877] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:37:25,881] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.8702669e-06 4.8762472e-06 2.6235382e-06 9.9996734e-01 2.1355319e-05], sampled 0.21344047632141705
[2019-03-24 07:37:38,720] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8643 2410729549.3540 22.0000
[2019-03-24 07:37:39,458] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7476.1676 2466052858.5753 46.0000
[2019-03-24 07:37:39,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3745 2668509944.6151 68.0000
[2019-03-24 07:37:39,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7313 2495467624.4370 47.0000
[2019-03-24 07:37:39,638] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:37:40,655] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 7522.374490849826, 2668509944.6150527, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7796.86425245599, 2410729549.3539805, 22.0, 6906.7313458696335, 2495467624.4370494, 47.0, 7476.1676430314155, 2466052858.5752983, 46.0]
[2019-03-24 07:37:40,710] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1075029: loss 3.2450
[2019-03-24 07:37:40,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1075029: learning rate 0.0000
[2019-03-24 07:37:41,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1627134e-07 1.0236070e-06 3.0096817e-06 9.9998975e-01 6.0360544e-06], sum to 1.0000
[2019-03-24 07:37:41,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-24 07:37:41,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.6, 17.16666666666667, 1.0, 2.0, 0.6601921414399322, 1.0, 2.0, 0.6601921414399322, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1615643.054362857, 1615643.054362858, 293932.9947578507], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 665400.0000, 
sim time next is 666000.0000, 
raw observation next is [35.6, 17.0, 1.0, 2.0, 0.6470200250759335, 1.0, 2.0, 0.6470200250759335, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1584889.599860192, 1584889.599860192, 289092.4249948118], 
processed observation next is [1.0, 0.7391304347826086, 0.8740740740740741, 0.17, 1.0, 1.0, 0.579785744138016, 1.0, 1.0, 0.579785744138016, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5660319999500686, 0.5660319999500686, 0.5559469711438689], 
reward next is 0.4441, 
noisyNet noise sample is [array([0.220148], dtype=float32), 1.0221075]. 
=============================================
[2019-03-24 07:37:41,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.798065]
 [65.74185 ]
 [65.57668 ]
 [65.349915]
 [65.251816]], R is [[65.61921692]
 [65.39777374]
 [65.17728424]
 [64.95877838]
 [64.74765778]].
[2019-03-24 07:37:41,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9134424e-06 1.7712599e-06 2.3600023e-07 9.9997783e-01 1.5265379e-05], sum to 1.0000
[2019-03-24 07:37:41,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9737
[2019-03-24 07:37:41,854] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.98333333333333, 19.5, 1.0, 2.0, 0.1975589423812907, 1.0, 2.0, 0.1975589423812907, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 494349.4806851472, 494349.4806851476, 159518.8037840684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 670200.0000, 
sim time next is 670800.0000, 
raw observation next is [33.76666666666667, 20.0, 1.0, 2.0, 0.1965615514252461, 1.0, 2.0, 0.1965615514252461, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491880.0231953904, 491880.0231953904, 159309.9374685406], 
processed observation next is [1.0, 0.782608695652174, 0.806172839506173, 0.2, 1.0, 1.0, 0.04352565645862629, 1.0, 1.0, 0.04352565645862629, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17567143685549658, 0.17567143685549658, 0.30636526436257805], 
reward next is 0.6936, 
noisyNet noise sample is [array([-0.9398162], dtype=float32), 1.3609507]. 
=============================================
[2019-03-24 07:37:43,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0320522e-05 1.1207521e-05 1.9574096e-05 9.9929297e-01 5.8580219e-04], sum to 1.0000
[2019-03-24 07:37:43,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2102
[2019-03-24 07:37:43,798] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.36666666666667, 77.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389873.3271422603, 389873.3271422607, 149383.8081806892], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 535800.0000, 
sim time next is 536400.0000, 
raw observation next is [19.3, 78.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 387705.0573579395, 387705.05735794, 149046.8721985553], 
processed observation next is [1.0, 0.21739130434782608, 0.27037037037037037, 0.78, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1384660919135498, 0.13846609191355, 0.28662860038183713], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7366489], dtype=float32), -0.9422042]. 
=============================================
[2019-03-24 07:37:44,272] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1076780: loss 1.1172
[2019-03-24 07:37:44,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1076780: learning rate 0.0000
[2019-03-24 07:37:46,374] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1077828: loss 0.8510
[2019-03-24 07:37:46,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1077830: learning rate 0.0000
[2019-03-24 07:37:47,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4831275e-05 2.1907003e-05 2.5955111e-07 9.9991822e-01 3.4833916e-05], sum to 1.0000
[2019-03-24 07:37:47,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-24 07:37:47,240] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 53.66666666666667, 1.0, 2.0, 0.480859408046255, 1.0, 2.0, 0.480859408046255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1190234.201342223, 1190234.201342224, 233065.8145379805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 721200.0000, 
sim time next is 721800.0000, 
raw observation next is [24.9, 53.5, 1.0, 2.0, 0.515391373653976, 1.0, 2.0, 0.515391373653976, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1270274.318836835, 1270274.318836835, 243861.0094392532], 
processed observation next is [1.0, 0.34782608695652173, 0.47777777777777775, 0.535, 1.0, 1.0, 0.42308496863568573, 1.0, 1.0, 0.42308496863568573, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4536693995845839, 0.4536693995845839, 0.46896347969087154], 
reward next is 0.5310, 
noisyNet noise sample is [array([-0.11958767], dtype=float32), -0.56611836]. 
=============================================
[2019-03-24 07:37:48,226] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1078735: loss 0.2609
[2019-03-24 07:37:48,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1078736: learning rate 0.0000
[2019-03-24 07:37:49,137] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1079149: loss 0.2165
[2019-03-24 07:37:49,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1079149: learning rate 0.0000
[2019-03-24 07:37:49,356] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1079243: loss 0.3289
[2019-03-24 07:37:49,359] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1079244: learning rate 0.0000
[2019-03-24 07:37:51,431] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080297: loss 0.1459
[2019-03-24 07:37:51,437] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080298: learning rate 0.0000
[2019-03-24 07:37:51,444] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080302: loss 0.1370
[2019-03-24 07:37:51,449] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080302: learning rate 0.0000
[2019-03-24 07:37:51,912] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080545: loss 0.1861
[2019-03-24 07:37:51,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080545: learning rate 0.0000
[2019-03-24 07:37:52,614] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080909: loss 0.1730
[2019-03-24 07:37:52,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080909: learning rate 0.0000
[2019-03-24 07:37:53,195] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1081214: loss 0.3668
[2019-03-24 07:37:53,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1081215: learning rate 0.0000
[2019-03-24 07:37:53,413] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1081325: loss 0.1258
[2019-03-24 07:37:53,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1081325: learning rate 0.0000
[2019-03-24 07:37:54,319] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1081801: loss 0.1298
[2019-03-24 07:37:54,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1081801: learning rate 0.0000
[2019-03-24 07:37:54,344] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1081807: loss 0.1570
[2019-03-24 07:37:54,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1081808: learning rate 0.0000
[2019-03-24 07:37:55,455] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082383: loss 0.3054
[2019-03-24 07:37:55,456] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082383: loss 0.2335
[2019-03-24 07:37:55,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082383: learning rate 0.0000
[2019-03-24 07:37:55,459] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082384: learning rate 0.0000
[2019-03-24 07:37:56,629] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1082996: loss 4.2674
[2019-03-24 07:37:56,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1082996: learning rate 0.0000
[2019-03-24 07:37:58,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2936683e-05 6.4165397e-05 3.7198272e-06 9.9984705e-01 6.2083564e-05], sum to 1.0000
[2019-03-24 07:37:58,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0281
[2019-03-24 07:37:58,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.03333333333333, 55.83333333333334, 1.0, 2.0, 0.3954765207582441, 1.0, 2.0, 0.3954765207582441, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 970576.5169143386, 970576.5169143381, 207646.6443915436], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 990600.0000, 
sim time next is 991200.0000, 
raw observation next is [25.06666666666667, 55.66666666666667, 1.0, 2.0, 0.4099014879292809, 1.0, 2.0, 0.4099014879292809, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1006356.126249028, 1006356.126249029, 211726.1509044866], 
processed observation next is [1.0, 0.4782608695652174, 0.4839506172839507, 0.5566666666666668, 1.0, 1.0, 0.297501771344382, 1.0, 1.0, 0.297501771344382, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35941290223179573, 0.35941290223179606, 0.4071656748163204], 
reward next is 0.5928, 
noisyNet noise sample is [array([1.7047901], dtype=float32), 0.7373782]. 
=============================================
[2019-03-24 07:37:58,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4112697e-06 6.7340493e-06 3.3969213e-06 9.9994648e-01 4.2087209e-05], sum to 1.0000
[2019-03-24 07:37:58,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5855
[2019-03-24 07:37:58,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.13333333333333, 38.0, 1.0, 2.0, 0.2078178474678771, 1.0, 2.0, 0.2078178474678771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507559.7391736134, 507559.7391736138, 161354.5919859576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 844800.0000, 
sim time next is 845400.0000, 
raw observation next is [29.91666666666666, 38.5, 1.0, 2.0, 0.2066154716205683, 1.0, 2.0, 0.2066154716205683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 505122.4370312022, 505122.4370312027, 161115.5512205311], 
processed observation next is [0.0, 0.782608695652174, 0.66358024691358, 0.385, 1.0, 1.0, 0.0554946090721051, 1.0, 1.0, 0.0554946090721051, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1804008703682865, 0.1804008703682867, 0.3098375985010214], 
reward next is 0.6902, 
noisyNet noise sample is [array([-1.0210168], dtype=float32), -0.21924841]. 
=============================================
[2019-03-24 07:38:00,182] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1084857: loss 3.9230
[2019-03-24 07:38:00,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1084858: learning rate 0.0000
[2019-03-24 07:38:01,915] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1085765: loss 4.0335
[2019-03-24 07:38:01,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1085765: learning rate 0.0000
[2019-03-24 07:38:03,837] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1086769: loss 3.4513
[2019-03-24 07:38:03,838] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1086769: learning rate 0.0000
[2019-03-24 07:38:04,351] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1087041: loss 1.6719
[2019-03-24 07:38:04,353] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1087042: learning rate 0.0000
[2019-03-24 07:38:04,844] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1087298: loss 3.4280
[2019-03-24 07:38:04,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1087298: learning rate 0.0000
[2019-03-24 07:38:06,638] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088229: loss 3.1752
[2019-03-24 07:38:06,640] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088230: learning rate 0.0000
[2019-03-24 07:38:06,665] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088244: loss 3.1162
[2019-03-24 07:38:06,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088244: learning rate 0.0000
[2019-03-24 07:38:07,545] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088705: loss 1.3143
[2019-03-24 07:38:07,546] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088705: learning rate 0.0000
[2019-03-24 07:38:07,739] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088801: loss 3.4996
[2019-03-24 07:38:07,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088801: learning rate 0.0000
[2019-03-24 07:38:08,469] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1089185: loss 3.2585
[2019-03-24 07:38:08,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1089186: learning rate 0.0000
[2019-03-24 07:38:09,045] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1089454: loss 3.4705
[2019-03-24 07:38:09,047] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1089454: learning rate 0.0000
[2019-03-24 07:38:09,737] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089822: loss 4.0007
[2019-03-24 07:38:09,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089822: learning rate 0.0000
[2019-03-24 07:38:09,879] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1089894: loss 4.1003
[2019-03-24 07:38:09,882] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1089895: learning rate 0.0000
[2019-03-24 07:38:10,798] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090372: loss 4.5129
[2019-03-24 07:38:10,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090372: learning rate 0.0000
[2019-03-24 07:38:10,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090436: loss 4.2965
[2019-03-24 07:38:10,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090436: learning rate 0.0000
[2019-03-24 07:38:10,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1051091e-05 7.0538808e-06 8.4253268e-05 9.9985707e-01 5.6789116e-07], sum to 1.0000
[2019-03-24 07:38:10,993] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5799
[2019-03-24 07:38:10,996] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 43.0, 1.0, 2.0, 0.4681889312152054, 1.0, 2.0, 0.4681889312152054, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1160073.291595634, 1160073.291595634, 229189.6084925423], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1092600.0000, 
sim time next is 1093200.0000, 
raw observation next is [26.56666666666666, 43.33333333333334, 1.0, 2.0, 0.4857248982326257, 1.0, 2.0, 0.4857248982326257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1202842.044527814, 1202842.044527814, 234593.5029036018], 
processed observation next is [1.0, 0.6521739130434783, 0.5395061728395059, 0.4333333333333334, 1.0, 1.0, 0.3877677359912211, 1.0, 1.0, 0.3877677359912211, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4295864444742193, 0.4295864444742193, 0.45114135173769576], 
reward next is 0.5489, 
noisyNet noise sample is [array([-0.27135053], dtype=float32), 1.0357189]. 
=============================================
[2019-03-24 07:38:11,964] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1090985: loss 0.1073
[2019-03-24 07:38:11,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1090985: learning rate 0.0000
[2019-03-24 07:38:15,455] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1092807: loss 0.0427
[2019-03-24 07:38:15,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1092807: learning rate 0.0000
[2019-03-24 07:38:16,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4036479e-08 1.3314381e-06 3.7291880e-08 9.9999630e-01 2.3066436e-06], sum to 1.0000
[2019-03-24 07:38:16,443] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3219
[2019-03-24 07:38:16,447] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.56666666666667, 86.0, 1.0, 2.0, 0.1720798506584532, 1.0, 2.0, 0.1720798506584532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 431215.9328493627, 431215.9328493631, 154237.8829126674], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1302600.0000, 
sim time next is 1303200.0000, 
raw observation next is [19.5, 86.0, 1.0, 2.0, 0.1710340669397839, 1.0, 2.0, 0.1710340669397839, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 428952.4487423316, 428952.4487423321, 154031.4694168013], 
processed observation next is [1.0, 0.08695652173913043, 0.2777777777777778, 0.86, 1.0, 1.0, 0.013135793975933212, 1.0, 1.0, 0.013135793975933212, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1531973031222613, 0.15319730312226146, 0.2962143642630794], 
reward next is 0.7038, 
noisyNet noise sample is [array([1.0658549], dtype=float32), -0.25907022]. 
=============================================
[2019-03-24 07:38:17,531] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1093935: loss 0.0468
[2019-03-24 07:38:17,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1093935: learning rate 0.0000
[2019-03-24 07:38:19,122] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1094789: loss 0.0454
[2019-03-24 07:38:19,125] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1094792: learning rate 0.0000
[2019-03-24 07:38:19,594] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1095034: loss 0.0441
[2019-03-24 07:38:19,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1095034: learning rate 0.0000
[2019-03-24 07:38:19,794] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1095141: loss 0.0429
[2019-03-24 07:38:19,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1095143: learning rate 0.0000
[2019-03-24 07:38:21,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5636516e-06 2.0715927e-06 5.2219110e-07 9.9994719e-01 4.5712066e-05], sum to 1.0000
[2019-03-24 07:38:21,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1240
[2019-03-24 07:38:21,557] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 48.0, 1.0, 2.0, 0.3742617756600344, 1.0, 2.0, 0.3742617756600344, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922078.2870309242, 922078.2870309247, 201890.9320375942], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1333800.0000, 
sim time next is 1334400.0000, 
raw observation next is [26.66666666666667, 46.33333333333333, 1.0, 2.0, 0.3873723491274703, 1.0, 2.0, 0.3873723491274703, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 955065.4809056662, 955065.4809056658, 205508.3473424116], 
processed observation next is [1.0, 0.43478260869565216, 0.5432098765432101, 0.46333333333333326, 1.0, 1.0, 0.27068136800889325, 1.0, 1.0, 0.27068136800889325, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3410948146091665, 0.34109481460916635, 0.39520836027386846], 
reward next is 0.6048, 
noisyNet noise sample is [array([0.17193837], dtype=float32), 0.28329086]. 
=============================================
[2019-03-24 07:38:21,645] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096171: loss 0.0407
[2019-03-24 07:38:21,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096172: learning rate 0.0000
[2019-03-24 07:38:21,967] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096338: loss 0.0506
[2019-03-24 07:38:21,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096339: learning rate 0.0000
[2019-03-24 07:38:22,633] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096686: loss 0.0455
[2019-03-24 07:38:22,637] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096686: learning rate 0.0000
[2019-03-24 07:38:22,801] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096776: loss 0.0539
[2019-03-24 07:38:22,804] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096776: learning rate 0.0000
[2019-03-24 07:38:23,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1097122: loss 0.0522
[2019-03-24 07:38:23,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1097123: learning rate 0.0000
[2019-03-24 07:38:24,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1097479: loss 0.0346
[2019-03-24 07:38:24,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097479: learning rate 0.0000
[2019-03-24 07:38:24,686] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1097754: loss 0.0636
[2019-03-24 07:38:24,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1097754: learning rate 0.0000
[2019-03-24 07:38:25,183] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1098021: loss 0.0450
[2019-03-24 07:38:25,190] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1098023: learning rate 0.0000
[2019-03-24 07:38:25,534] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098207: loss 0.0361
[2019-03-24 07:38:25,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098207: learning rate 0.0000
[2019-03-24 07:38:26,332] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098622: loss 0.0528
[2019-03-24 07:38:26,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098624: learning rate 0.0000
[2019-03-24 07:38:26,867] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1098898: loss 1.1360
[2019-03-24 07:38:26,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1098898: learning rate 0.0000
[2019-03-24 07:38:27,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4961519e-07 6.9406083e-06 2.5215347e-06 9.9988484e-01 1.0561391e-04], sum to 1.0000
[2019-03-24 07:38:27,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3378
[2019-03-24 07:38:27,341] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 43.0, 1.0, 2.0, 0.1755005921358199, 1.0, 2.0, 0.1755005921358199, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438822.4442228759, 438822.4442228763, 154919.3039105129], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1467600.0000, 
sim time next is 1468200.0000, 
raw observation next is [26.58333333333334, 44.0, 1.0, 2.0, 0.1752258095233263, 1.0, 2.0, 0.1752258095233263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438376.5815098548, 438376.5815098552, 154868.2823026318], 
processed observation next is [0.0, 1.0, 0.5401234567901236, 0.44, 1.0, 1.0, 0.018125963718245604, 1.0, 1.0, 0.018125963718245604, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15656306482494814, 0.1565630648249483, 0.29782361981275346], 
reward next is 0.7022, 
noisyNet noise sample is [array([-0.97521377], dtype=float32), -1.132393]. 
=============================================
[2019-03-24 07:38:28,960] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 07:38:28,962] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:38:28,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:28,963] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:38:28,965] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:38:28,965] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:28,967] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:38:28,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:38:28,969] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:28,967] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:28,970] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:28,984] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-24 07:38:29,015] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-24 07:38:29,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-24 07:38:29,045] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-24 07:38:29,078] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-24 07:38:33,613] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:38:33,614] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.33333333333334, 23.33333333333334, 1.0, 2.0, 0.1723686244474371, 1.0, 2.0, 0.1723686244474371, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438469.1821924837, 438469.1821924837, 154401.0574811651]
[2019-03-24 07:38:33,614] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:38:33,618] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.2854840e-07 9.3863997e-07 5.5014118e-07 9.9999416e-01 3.5268367e-06], sampled 0.672588591260055
[2019-03-24 07:38:38,770] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:38:38,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.750964965, 56.12088245, 1.0, 2.0, 0.2516199296414883, 1.0, 2.0, 0.2516199296414883, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 587716.824663364, 587716.8246633644, 169961.8320478283]
[2019-03-24 07:38:38,773] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:38:38,775] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.7076410e-07 1.1322763e-06 6.6093298e-07 9.9999321e-01 4.1311346e-06], sampled 0.5491257917442178
[2019-03-24 07:38:42,793] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:38:42,794] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 59.83333333333334, 1.0, 2.0, 0.1650685411122317, 1.0, 2.0, 0.1650685411122317, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413387.7990175602, 413387.7990175607, 152804.4312730576]
[2019-03-24 07:38:42,794] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:38:42,798] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0040294e-06 1.2842207e-06 7.6180794e-07 9.9999213e-01 4.7121653e-06], sampled 0.3852200023413813
[2019-03-24 07:39:01,240] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:39:01,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.83333333333334, 53.5, 1.0, 2.0, 0.2920768945591866, 1.0, 2.0, 0.2920768945591866, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665712.7368063543, 665712.7368063543, 178570.3462869568]
[2019-03-24 07:39:01,243] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:39:01,247] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4108290e-07 5.6812900e-07 3.2859785e-07 9.9999642e-01 2.2419745e-06], sampled 0.8558391348578317
[2019-03-24 07:39:29,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:39:29,710] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 91.5, 1.0, 2.0, 0.2953794673070044, 1.0, 2.0, 0.2953794673070044, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673243.3911757643, 673243.3911757643, 179355.7283003301]
[2019-03-24 07:39:29,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:39:29,715] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6510867e-07 3.3610851e-07 1.9543600e-07 9.9999762e-01 1.5301937e-06], sampled 0.4034772353308351
[2019-03-24 07:39:53,195] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:39:53,196] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.08333333333334, 88.66666666666667, 1.0, 2.0, 0.2485919562690784, 1.0, 2.0, 0.2485919562690784, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 586409.0072541793, 586409.0072541797, 169540.7757761291]
[2019-03-24 07:39:53,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:39:53,200] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7568597e-07 6.0158038e-07 3.5257798e-07 9.9999619e-01 2.4295280e-06], sampled 0.6119223706613517
[2019-03-24 07:40:05,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00973522], dtype=float32), 0.0071401154]
[2019-03-24 07:40:05,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.25270661, 96.72000321, 1.0, 2.0, 0.182611470712828, 1.0, 2.0, 0.182611470712828, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453099.3965406459, 453099.3965406463, 156304.2416503219]
[2019-03-24 07:40:05,681] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:40:05,684] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.3130564e-07 1.1878512e-06 6.9883941e-07 9.9999273e-01 4.4218496e-06], sampled 0.774128551644434
[2019-03-24 07:40:15,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:40:15,614] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:40:15,649] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3215 2668558731.0632 68.0000
[2019-03-24 07:40:15,861] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7476.9652 2465918647.4712 46.0000
[2019-03-24 07:40:15,899] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:40:16,915] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1100000, evaluation results [1100000.0, 7522.321517233905, 2668558731.063227, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7476.965224439365, 2465918647.471204, 46.0]
[2019-03-24 07:40:18,579] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1100827: loss 1.3265
[2019-03-24 07:40:18,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1100827: learning rate 0.0000
[2019-03-24 07:40:20,606] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1101828: loss 1.1495
[2019-03-24 07:40:20,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1101829: learning rate 0.0000
[2019-03-24 07:40:22,996] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1102997: loss 0.5681
[2019-03-24 07:40:22,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1102998: learning rate 0.0000
[2019-03-24 07:40:23,251] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1103121: loss 0.5469
[2019-03-24 07:40:23,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1103122: learning rate 0.0000
[2019-03-24 07:40:23,427] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1103208: loss 0.4210
[2019-03-24 07:40:23,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1103210: learning rate 0.0000
[2019-03-24 07:40:25,371] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104174: loss 0.2171
[2019-03-24 07:40:25,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104174: learning rate 0.0000
[2019-03-24 07:40:25,753] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104362: loss 0.1691
[2019-03-24 07:40:25,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104362: learning rate 0.0000
[2019-03-24 07:40:25,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5020195e-07 1.6174929e-06 1.0460762e-06 9.9999392e-01 2.8281740e-06], sum to 1.0000
[2019-03-24 07:40:25,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1145
[2019-03-24 07:40:25,845] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.21666666666667, 44.5, 1.0, 2.0, 0.4689107882150476, 1.0, 2.0, 0.4689107882150476, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1150572.338783535, 1150572.338783535, 229124.1543521319], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1605000.0000, 
sim time next is 1605600.0000, 
raw observation next is [27.3, 44.0, 1.0, 2.0, 0.4708402669860464, 1.0, 2.0, 0.4708402669860464, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1155526.45746458, 1155526.45746458, 229720.4112641807], 
processed observation next is [1.0, 0.6086956521739131, 0.5666666666666667, 0.44, 1.0, 1.0, 0.37004793688815046, 1.0, 1.0, 0.37004793688815046, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.41268802052306425, 0.41268802052306425, 0.44177002166188595], 
reward next is 0.5582, 
noisyNet noise sample is [array([2.3276944], dtype=float32), -1.0181901]. 
=============================================
[2019-03-24 07:40:26,182] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104581: loss 0.0792
[2019-03-24 07:40:26,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104581: learning rate 0.0000
[2019-03-24 07:40:26,387] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104681: loss 0.0637
[2019-03-24 07:40:26,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104681: learning rate 0.0000
[2019-03-24 07:40:27,474] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1105169: loss 0.0297
[2019-03-24 07:40:27,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1105169: learning rate 0.0000
[2019-03-24 07:40:28,386] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1105631: loss 0.0270
[2019-03-24 07:40:28,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1105631: learning rate 0.0000
[2019-03-24 07:40:28,604] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1105741: loss 0.0282
[2019-03-24 07:40:28,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1105742: learning rate 0.0000
[2019-03-24 07:40:29,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1106034: loss 0.0483
[2019-03-24 07:40:29,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1106034: learning rate 0.0000
[2019-03-24 07:40:29,291] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106105: loss 0.0377
[2019-03-24 07:40:29,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106105: learning rate 0.0000
[2019-03-24 07:40:30,175] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106566: loss 0.0196
[2019-03-24 07:40:30,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106566: learning rate 0.0000
[2019-03-24 07:40:30,708] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1106840: loss 1.8981
[2019-03-24 07:40:30,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1106841: learning rate 0.0000
[2019-03-24 07:40:30,835] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7199990e-09 5.2705541e-08 3.7139888e-08 9.9999964e-01 4.0582390e-07], sum to 1.0000
[2019-03-24 07:40:30,844] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3908
[2019-03-24 07:40:30,849] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.2, 76.5, 1.0, 2.0, 0.2274867969941293, 1.0, 2.0, 0.2274867969941293, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 559125.820300898, 559125.8203008985, 165716.1264342444], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1755000.0000, 
sim time next is 1755600.0000, 
raw observation next is [22.36666666666667, 75.66666666666666, 1.0, 2.0, 0.2172398526057273, 1.0, 2.0, 0.2172398526057273, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533678.1439400094, 533678.1439400099, 163472.2240456045], 
processed observation next is [1.0, 0.30434782608695654, 0.38395061728395075, 0.7566666666666666, 1.0, 1.0, 0.06814268167348489, 1.0, 1.0, 0.06814268167348489, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19059933712143193, 0.1905993371214321, 0.3143696616261625], 
reward next is 0.6856, 
noisyNet noise sample is [array([0.76710767], dtype=float32), 0.61760634]. 
=============================================
[2019-03-24 07:40:33,609] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2281929e-05 2.2740672e-07 3.5121504e-06 9.9994302e-01 3.1008767e-05], sum to 1.0000
[2019-03-24 07:40:33,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9884
[2019-03-24 07:40:33,623] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.15, 68.83333333333333, 1.0, 2.0, 0.2126698173571643, 1.0, 2.0, 0.2126698173571643, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 516561.2024618753, 516561.2024618757, 162293.8178887221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1792200.0000, 
sim time next is 1792800.0000, 
raw observation next is [23.7, 70.0, 1.0, 2.0, 0.2092779255190496, 1.0, 2.0, 0.2092779255190496, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510298.116349639, 510298.1163496395, 161637.8681156604], 
processed observation next is [1.0, 0.782608695652174, 0.4333333333333333, 0.7, 1.0, 1.0, 0.058664197046487634, 1.0, 1.0, 0.058664197046487634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18224932726772822, 0.18224932726772838, 0.31084205406857773], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.93752736], dtype=float32), -0.8679154]. 
=============================================
[2019-03-24 07:40:33,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9295169e-07 4.0755179e-07 6.7818625e-08 9.9999881e-01 1.3847855e-07], sum to 1.0000
[2019-03-24 07:40:33,664] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7359
[2019-03-24 07:40:33,667] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 86.0, 1.0, 2.0, 0.4125498761147424, 1.0, 2.0, 0.4125498761147424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 982441.3704539834, 982441.3704539839, 211488.0980973554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1940400.0000, 
sim time next is 1941000.0000, 
raw observation next is [22.85, 84.5, 1.0, 2.0, 0.4994713560123311, 1.0, 2.0, 0.4994713560123311, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1184899.532161277, 1184899.532161278, 237261.3678029178], 
processed observation next is [1.0, 0.4782608695652174, 0.4018518518518519, 0.845, 1.0, 1.0, 0.4041325666813466, 1.0, 1.0, 0.4041325666813466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4231784043433132, 0.42317840434331355, 0.45627186115945734], 
reward next is 0.5437, 
noisyNet noise sample is [array([-1.1987332], dtype=float32), -0.7713884]. 
=============================================
[2019-03-24 07:40:33,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.91621]
 [65.16657]
 [65.13809]
 [65.04554]
 [64.89509]], R is [[64.5068512 ]
 [64.4550705 ]
 [64.43730927]
 [64.41735077]
 [64.38051605]].
[2019-03-24 07:40:34,501] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1108817: loss 1.0595
[2019-03-24 07:40:34,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1108817: learning rate 0.0000
[2019-03-24 07:40:35,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6302380e-06 3.2659455e-07 2.9461356e-07 9.9997723e-01 1.9411154e-05], sum to 1.0000
[2019-03-24 07:40:35,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1685
[2019-03-24 07:40:35,630] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 67.0, 1.0, 2.0, 0.3036343606421023, 1.0, 2.0, 0.3036343606421023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692066.842424881, 692066.8424248814, 181335.2194637382], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2052000.0000, 
sim time next is 2052600.0000, 
raw observation next is [28.26666666666667, 67.66666666666667, 1.0, 2.0, 0.3039554497199648, 1.0, 2.0, 0.3039554497199648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692799.0241078826, 692799.0241078826, 181412.6789129824], 
processed observation next is [0.0, 0.782608695652174, 0.6024691358024692, 0.6766666666666667, 1.0, 1.0, 0.17137553538091047, 1.0, 1.0, 0.17137553538091047, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24742822289567237, 0.24742822289567237, 0.34887053637112003], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.20995091], dtype=float32), -1.6141847]. 
=============================================
[2019-03-24 07:40:36,305] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1109766: loss 1.2864
[2019-03-24 07:40:36,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1109766: learning rate 0.0000
[2019-03-24 07:40:38,666] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1111001: loss 1.0954
[2019-03-24 07:40:38,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1111002: learning rate 0.0000
[2019-03-24 07:40:38,790] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1111066: loss 1.3533
[2019-03-24 07:40:38,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1111067: learning rate 0.0000
[2019-03-24 07:40:39,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1111323: loss 1.1910
[2019-03-24 07:40:39,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1111323: learning rate 0.0000
[2019-03-24 07:40:40,241] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7343638e-07 1.2084243e-07 1.1689970e-06 9.9999833e-01 2.6616448e-07], sum to 1.0000
[2019-03-24 07:40:40,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4757
[2019-03-24 07:40:40,253] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 65.83333333333333, 1.0, 2.0, 0.2478401190704347, 1.0, 2.0, 0.2478401190704347, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 169376.884818386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2031000.0000, 
sim time next is 2031600.0000, 
raw observation next is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.2504241516434226, 1.0, 2.0, 0.2504241516434226, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589735.301661165, 589735.301661165, 169909.9335585545], 
processed observation next is [0.0, 0.5217391304347826, 0.5432098765432101, 0.6566666666666667, 1.0, 1.0, 0.10764779957550306, 1.0, 1.0, 0.10764779957550306, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2106197505932732, 0.2106197505932732, 0.32674987222798946], 
reward next is 0.6733, 
noisyNet noise sample is [array([-2.0052207], dtype=float32), 0.7394691]. 
=============================================
[2019-03-24 07:40:41,188] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112306: loss 1.4003
[2019-03-24 07:40:41,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112306: learning rate 0.0000
[2019-03-24 07:40:41,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112524: loss 1.4994
[2019-03-24 07:40:41,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112524: learning rate 0.0000
[2019-03-24 07:40:41,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5906137e-08 3.2948318e-08 3.8477679e-06 9.9999547e-01 6.4871415e-07], sum to 1.0000
[2019-03-24 07:40:41,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-24 07:40:41,836] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.93333333333333, 89.83333333333333, 1.0, 2.0, 0.3105008625892939, 1.0, 2.0, 0.3105008625892939, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716624.3122771775, 716624.3122771779, 183433.0882529484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2173800.0000, 
sim time next is 2174400.0000, 
raw observation next is [23.9, 90.0, 1.0, 2.0, 0.3065076765293447, 1.0, 2.0, 0.3065076765293447, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 707693.4592780896, 707693.45927809, 182472.1911327162], 
processed observation next is [1.0, 0.17391304347826086, 0.4407407407407407, 0.9, 1.0, 1.0, 0.17441390063017226, 1.0, 1.0, 0.17441390063017226, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2527476640278891, 0.2527476640278893, 0.3509080598706081], 
reward next is 0.6491, 
noisyNet noise sample is [array([0.5280498], dtype=float32), 0.7160934]. 
=============================================
[2019-03-24 07:40:41,854] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112653: loss 1.3305
[2019-03-24 07:40:41,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112654: learning rate 0.0000
[2019-03-24 07:40:41,898] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112675: loss 1.5000
[2019-03-24 07:40:41,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112675: learning rate 0.0000
[2019-03-24 07:40:42,551] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1113014: loss 1.5095
[2019-03-24 07:40:42,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1113014: learning rate 0.0000
[2019-03-24 07:40:43,042] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4424239e-07 5.9413305e-06 3.6522249e-07 9.9998331e-01 1.0085314e-05], sum to 1.0000
[2019-03-24 07:40:43,049] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9605
[2019-03-24 07:40:43,060] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.6, 90.0, 1.0, 2.0, 0.1877612486287922, 1.0, 2.0, 0.1877612486287922, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466739.9671854263, 466739.9671854268, 157404.8556324938], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1983600.0000, 
sim time next is 1984200.0000, 
raw observation next is [19.58333333333334, 90.16666666666667, 1.0, 2.0, 0.1853844905207197, 1.0, 2.0, 0.1853844905207197, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461361.325647461, 461361.3256474615, 156920.8672077361], 
processed observation next is [1.0, 1.0, 0.2808641975308644, 0.9016666666666667, 1.0, 1.0, 0.030219631572285358, 1.0, 1.0, 0.030219631572285358, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16477190201695036, 0.16477190201695055, 0.3017708984764156], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.4083132], dtype=float32), 0.41346344]. 
=============================================
[2019-03-24 07:40:43,503] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1113513: loss 1.2584
[2019-03-24 07:40:43,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1113515: learning rate 0.0000
[2019-03-24 07:40:43,648] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113588: loss 1.0913
[2019-03-24 07:40:43,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113588: learning rate 0.0000
[2019-03-24 07:40:44,284] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1113919: loss 1.5254
[2019-03-24 07:40:44,285] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1113920: learning rate 0.0000
[2019-03-24 07:40:44,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4792616e-08 2.6631032e-08 2.0797877e-07 9.9999821e-01 1.5717015e-06], sum to 1.0000
[2019-03-24 07:40:44,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-24 07:40:44,352] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.13333333333333, 88.16666666666667, 1.0, 2.0, 0.1847592388334995, 1.0, 2.0, 0.1847592388334995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 458121.9777834929, 458121.9777834934, 156743.8376630054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2009400.0000, 
sim time next is 2010000.0000, 
raw observation next is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.1852465198595403, 1.0, 2.0, 0.1852465198595403, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459134.2362695792, 459134.2362695796, 156840.1768261299], 
processed observation next is [0.0, 0.2608695652173913, 0.3061728395061729, 0.8733333333333334, 1.0, 1.0, 0.030055380785167018, 1.0, 1.0, 0.030055380785167018, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16397651295342114, 0.1639765129534213, 0.3016157246656344], 
reward next is 0.6984, 
noisyNet noise sample is [array([-1.7198427], dtype=float32), -0.71855634]. 
=============================================
[2019-03-24 07:40:44,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.62213]
 [68.67954]
 [68.70909]
 [68.73885]
 [68.77789]], R is [[68.5786438 ]
 [68.59143066]
 [68.60424042]
 [68.61697388]
 [68.62963867]].
[2019-03-24 07:40:44,620] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114093: loss 1.4180
[2019-03-24 07:40:44,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114093: learning rate 0.0000
[2019-03-24 07:40:44,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9708090e-07 7.7810482e-06 1.2947301e-07 9.9998975e-01 1.9678826e-06], sum to 1.0000
[2019-03-24 07:40:44,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-24 07:40:44,767] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 78.0, 1.0, 2.0, 0.248550229236727, 1.0, 2.0, 0.248550229236727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 589586.8436731203, 589586.8436731207, 169671.1479088235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2070000.0000, 
sim time next is 2070600.0000, 
raw observation next is [24.1, 78.33333333333333, 1.0, 2.0, 0.2462686582139507, 1.0, 2.0, 0.2462686582139507, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584972.8072490746, 584972.8072490746, 169191.3509471924], 
processed observation next is [0.0, 1.0, 0.4481481481481482, 0.7833333333333333, 1.0, 1.0, 0.10270078358803654, 1.0, 1.0, 0.10270078358803654, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20891885973181235, 0.20891885973181235, 0.3253679825907546], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.52475893], dtype=float32), 1.3335629]. 
=============================================
[2019-03-24 07:40:45,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114685: loss 1.1733
[2019-03-24 07:40:45,748] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114685: learning rate 0.0000
[2019-03-24 07:40:45,954] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1114793: loss 0.0404
[2019-03-24 07:40:45,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1114793: learning rate 0.0000
[2019-03-24 07:40:45,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0754607e-08 3.3873459e-07 8.4681920e-07 9.9999666e-01 2.0873442e-06], sum to 1.0000
[2019-03-24 07:40:45,963] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0462
[2019-03-24 07:40:45,966] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 89.0, 1.0, 2.0, 0.3043776365826105, 1.0, 2.0, 0.3043776365826105, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 702135.375749167, 702135.3757491675, 181924.288811727], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [24.1, 89.0, 1.0, 2.0, 0.2962385736815409, 1.0, 2.0, 0.2962385736815409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683388.009593508, 683388.0095935084, 179963.176817713], 
processed observation next is [1.0, 0.2608695652173913, 0.4481481481481482, 0.89, 1.0, 1.0, 0.1621887781923106, 1.0, 1.0, 0.1621887781923106, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2440671462833957, 0.24406714628339587, 0.3460830323417558], 
reward next is 0.6539, 
noisyNet noise sample is [array([0.97917765], dtype=float32), 1.1067832]. 
=============================================
[2019-03-24 07:40:47,787] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2117014e-07 1.2917267e-06 7.6175729e-06 9.9998045e-01 1.0093771e-05], sum to 1.0000
[2019-03-24 07:40:47,794] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9016
[2019-03-24 07:40:47,799] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 82.0, 1.0, 2.0, 0.2326336836090689, 1.0, 2.0, 0.2326336836090689, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 557391.4249669245, 557391.4249669248, 166357.7242134448], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2077200.0000, 
sim time next is 2077800.0000, 
raw observation next is [23.0, 82.33333333333334, 1.0, 2.0, 0.2319796655136876, 1.0, 2.0, 0.2319796655136876, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 556297.262468197, 556297.2624681966, 166232.1929100401], 
processed observation next is [0.0, 0.043478260869565216, 0.4074074074074074, 0.8233333333333335, 1.0, 1.0, 0.08569007799248524, 1.0, 1.0, 0.08569007799248524, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1986775937386418, 0.19867759373864163, 0.3196772940577694], 
reward next is 0.6803, 
noisyNet noise sample is [array([-1.547105], dtype=float32), -1.1153879]. 
=============================================
[2019-03-24 07:40:49,710] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1116755: loss 0.0390
[2019-03-24 07:40:49,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1116757: learning rate 0.0000
[2019-03-24 07:40:49,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5885386e-07 1.1927893e-05 3.9895063e-08 9.9998748e-01 1.7834498e-07], sum to 1.0000
[2019-03-24 07:40:49,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7342
[2019-03-24 07:40:49,993] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.7, 83.33333333333334, 1.0, 2.0, 0.2297685709109851, 1.0, 2.0, 0.2297685709109851, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 552498.8467869574, 552498.8467869578, 165804.3109701218], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2079600.0000, 
sim time next is 2080200.0000, 
raw observation next is [22.6, 83.66666666666666, 1.0, 2.0, 0.2281323637616385, 1.0, 2.0, 0.2281323637616385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549077.8126293137, 549077.8126293137, 165465.0344728531], 
processed observation next is [0.0, 0.043478260869565216, 0.39259259259259266, 0.8366666666666666, 1.0, 1.0, 0.08110995685909346, 1.0, 1.0, 0.08110995685909346, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19609921879618344, 0.19609921879618344, 0.31820198937087135], 
reward next is 0.6818, 
noisyNet noise sample is [array([1.934479], dtype=float32), 1.9257059]. 
=============================================
[2019-03-24 07:40:51,608] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1117742: loss 0.0943
[2019-03-24 07:40:51,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1117743: learning rate 0.0000
[2019-03-24 07:40:53,898] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1118941: loss 0.1322
[2019-03-24 07:40:53,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1118943: learning rate 0.0000
[2019-03-24 07:40:54,277] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1119140: loss 0.0947
[2019-03-24 07:40:54,279] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1119140: learning rate 0.0000
[2019-03-24 07:40:54,632] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1119320: loss 0.1701
[2019-03-24 07:40:54,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1119322: learning rate 0.0000
[2019-03-24 07:40:56,327] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6840866e-06 9.0280747e-07 1.4799504e-07 9.9999475e-01 2.5626459e-06], sum to 1.0000
[2019-03-24 07:40:56,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8615
[2019-03-24 07:40:56,339] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.7, 96.66666666666666, 1.0, 2.0, 0.274116558273841, 1.0, 2.0, 0.274116558273841, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638414.9162715869, 638414.9162715874, 175032.0775166821], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2240400.0000, 
sim time next is 2241000.0000, 
raw observation next is [22.7, 97.0, 1.0, 2.0, 0.2749021039081432, 1.0, 2.0, 0.2749021039081432, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639731.074887062, 639731.0748870624, 175191.4075144262], 
processed observation next is [1.0, 0.9565217391304348, 0.39629629629629626, 0.97, 1.0, 1.0, 0.1367882189382657, 1.0, 1.0, 0.1367882189382657, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2284753838882364, 0.22847538388823657, 0.33690655291235805], 
reward next is 0.6631, 
noisyNet noise sample is [array([-0.41794157], dtype=float32), -1.2328428]. 
=============================================
[2019-03-24 07:40:56,358] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.61996 ]
 [65.63347 ]
 [65.612854]
 [65.56891 ]
 [65.58226 ]], R is [[65.65305328]
 [65.65991974]
 [65.66713715]
 [65.67470551]
 [65.68249512]].
[2019-03-24 07:40:56,384] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120232: loss 0.1835
[2019-03-24 07:40:56,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120233: learning rate 0.0000
[2019-03-24 07:40:56,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120457: loss 0.1154
[2019-03-24 07:40:56,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120459: learning rate 0.0000
[2019-03-24 07:40:57,042] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120575: loss 0.0741
[2019-03-24 07:40:57,045] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120576: learning rate 0.0000
[2019-03-24 07:40:57,136] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120622: loss 0.0559
[2019-03-24 07:40:57,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120622: learning rate 0.0000
[2019-03-24 07:40:58,079] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1121114: loss 0.1172
[2019-03-24 07:40:58,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1121114: learning rate 0.0000
[2019-03-24 07:40:58,920] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1121550: loss 0.0481
[2019-03-24 07:40:58,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1121550: learning rate 0.0000
[2019-03-24 07:40:59,227] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121709: loss 0.0641
[2019-03-24 07:40:59,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121709: learning rate 0.0000
[2019-03-24 07:40:59,622] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1121912: loss 0.0707
[2019-03-24 07:40:59,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1121913: learning rate 0.0000
[2019-03-24 07:40:59,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9267229e-06 2.2995276e-07 3.6395956e-08 9.9999130e-01 4.4017384e-07], sum to 1.0000
[2019-03-24 07:40:59,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-24 07:40:59,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.212456485814649, 1.0, 2.0, 0.212456485814649, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 517196.4885496756, 517196.488549676, 162288.3054051384], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2271600.0000, 
sim time next is 2272200.0000, 
raw observation next is [20.4, 96.16666666666666, 1.0, 2.0, 0.2364269209142487, 1.0, 2.0, 0.2364269209142487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575128.0967309882, 575128.0967309887, 167510.548989769], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.9616666666666666, 1.0, 1.0, 0.09098442965981987, 1.0, 1.0, 0.09098442965981987, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20540289168963866, 0.20540289168963882, 0.3221356711341712], 
reward next is 0.6779, 
noisyNet noise sample is [array([0.07808163], dtype=float32), -0.63340884]. 
=============================================
[2019-03-24 07:41:00,222] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122224: loss 0.1195
[2019-03-24 07:41:00,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122230: learning rate 0.0000
[2019-03-24 07:41:00,740] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122486: loss 0.0680
[2019-03-24 07:41:00,744] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122486: learning rate 0.0000
[2019-03-24 07:41:01,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1122640: loss 1.6082
[2019-03-24 07:41:01,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1122642: learning rate 0.0000
[2019-03-24 07:41:03,432] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9830031e-07 1.6605743e-07 3.5142057e-07 9.9999833e-01 5.3399140e-07], sum to 1.0000
[2019-03-24 07:41:03,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3280
[2019-03-24 07:41:03,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.9, 90.33333333333333, 1.0, 2.0, 0.2342111253467618, 1.0, 2.0, 0.2342111253467618, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562350.2558331783, 562350.2558331783, 166751.6064289811], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2329800.0000, 
sim time next is 2330400.0000, 
raw observation next is [21.9, 90.66666666666667, 1.0, 2.0, 0.2346639707125132, 1.0, 2.0, 0.2346639707125132, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 563050.4496225804, 563050.4496225809, 166836.820506778], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.9066666666666667, 1.0, 1.0, 0.08888567941965855, 1.0, 1.0, 0.08888567941965855, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20108944629377873, 0.2010894462937789, 0.3208400394361115], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.604406], dtype=float32), -1.254333]. 
=============================================
[2019-03-24 07:41:03,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0260393e-07 5.0738623e-07 1.6350124e-07 9.9999857e-01 7.4589269e-07], sum to 1.0000
[2019-03-24 07:41:03,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1652
[2019-03-24 07:41:03,885] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.93333333333334, 37.66666666666667, 1.0, 2.0, 0.186024995448557, 1.0, 2.0, 0.186024995448557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461555.644439016, 461555.6444390165, 157017.1279362744], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2495400.0000, 
sim time next is 2496000.0000, 
raw observation next is [28.76666666666667, 38.33333333333334, 1.0, 2.0, 0.1868388555755911, 1.0, 2.0, 0.1868388555755911, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463494.3185337572, 463494.3185337576, 157185.5774465319], 
processed observation next is [1.0, 0.9130434782608695, 0.6209876543209878, 0.3833333333333334, 1.0, 1.0, 0.031951018542370355, 1.0, 1.0, 0.031951018542370355, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16553368519062756, 0.16553368519062772, 0.302279956627946], 
reward next is 0.6977, 
noisyNet noise sample is [array([-1.3276168], dtype=float32), 1.4935448]. 
=============================================
[2019-03-24 07:41:03,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.15062 ]
 [62.18112 ]
 [62.229927]
 [62.12176 ]
 [62.139313]], R is [[62.20669937]
 [62.2826767 ]
 [62.35868073]
 [62.4347496 ]
 [62.51084137]].
[2019-03-24 07:41:05,281] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1124847: loss 1.9621
[2019-03-24 07:41:05,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1124848: learning rate 0.0000
[2019-03-24 07:41:05,565] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 07:41:05,566] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:41:05,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:05,567] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:41:05,570] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:41:05,570] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:05,571] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:41:05,572] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:41:05,572] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:05,573] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:05,575] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:05,589] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-24 07:41:05,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-24 07:41:05,624] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-24 07:41:05,653] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-24 07:41:05,712] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-24 07:41:39,357] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:41:39,358] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.84658328, 32.50871217833333, 1.0, 2.0, 0.5084113325552817, 1.0, 2.0, 0.5084113325552817, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1198587.899958394, 1198587.899958394, 239776.4953981167]
[2019-03-24 07:41:39,359] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:41:39,362] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.4941746e-07 1.2374602e-06 9.3172804e-07 9.9999225e-01 4.8227344e-06], sampled 0.3129508334545167
[2019-03-24 07:41:52,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:41:52,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 67.66666666666667, 1.0, 2.0, 0.3630145509284917, 1.0, 2.0, 0.3630145509284917, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827483.80403962, 827483.80403962, 196271.303991558]
[2019-03-24 07:41:52,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:41:52,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4734138e-07 3.7201087e-07 2.7066716e-07 9.9999762e-01 1.5260432e-06], sampled 0.1363825025471661
[2019-03-24 07:41:54,078] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:41:54,081] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.2654108, 91.34943213, 1.0, 2.0, 0.3119900710166302, 1.0, 2.0, 0.3119900710166302, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 711120.6552672003, 711120.6552672008, 183362.5675734425]
[2019-03-24 07:41:54,081] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:41:54,084] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9656562e-07 4.4821215e-07 3.1241646e-07 9.9999702e-01 1.8740914e-06], sampled 0.7496960145808724
[2019-03-24 07:42:21,322] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:42:21,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 88.0, 1.0, 2.0, 0.3324364428832014, 1.0, 2.0, 0.3324364428832014, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757747.2155204386, 757747.215520439, 188427.136687977]
[2019-03-24 07:42:21,325] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:42:21,328] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.1656418e-07 6.1256844e-07 4.5251087e-07 9.9999595e-01 2.6019650e-06], sampled 0.4146654918375159
[2019-03-24 07:42:22,561] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:42:22,563] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.2, 32.0, 1.0, 2.0, 0.2438639181968299, 1.0, 2.0, 0.2438639181968299, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578254.2436053085, 578254.2436053089, 168610.1512610003]
[2019-03-24 07:42:22,564] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:42:22,567] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3323169e-07 6.5083680e-07 4.6622282e-07 9.9999583e-01 2.5876418e-06], sampled 0.5564341676260068
[2019-03-24 07:42:32,533] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:42:32,534] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.43333333333334, 75.66666666666667, 1.0, 2.0, 0.3520581188978313, 1.0, 2.0, 0.3520581188978313, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802495.7800827917, 802495.7800827917, 193423.233286392]
[2019-03-24 07:42:32,536] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:42:32,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4797566e-07 5.2117406e-07 3.7107296e-07 9.9999666e-01 2.1206661e-06], sampled 0.7757009786273426
[2019-03-24 07:42:34,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:42:34,699] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.65, 44.5, 1.0, 2.0, 0.4470191918800875, 1.0, 2.0, 0.4470191918800875, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1105437.598348637, 1105437.598348637, 222740.8298787338]
[2019-03-24 07:42:34,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:42:34,704] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0908284e-06 1.5830344e-06 1.2015970e-06 9.9999022e-01 5.9427261e-06], sampled 0.7133390260707985
[2019-03-24 07:42:36,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00970123], dtype=float32), 0.007186769]
[2019-03-24 07:42:36,654] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.35, 65.83333333333334, 1.0, 2.0, 0.1665305593362792, 1.0, 2.0, 0.1665305593362792, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421975.5587289539, 421975.5587289539, 153188.2388331748]
[2019-03-24 07:42:36,655] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:42:36,659] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1659314e-06 1.6651037e-06 1.2701021e-06 9.9998939e-01 6.5087079e-06], sampled 0.034359792097284125
[2019-03-24 07:42:51,489] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873956.1460 34.0000
[2019-03-24 07:42:52,244] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7335 2495417847.2043 47.0000
[2019-03-24 07:42:52,315] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:42:52,344] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0693 2668508174.5232 68.0000
[2019-03-24 07:42:52,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.9558 2465989904.6867 46.0000
[2019-03-24 07:42:53,442] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1125000, evaluation results [1125000.0, 7523.069316394719, 2668508174.523248, 68.0, 7121.435945869477, 2438873956.145978, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6906.733534742119, 2495417847.204281, 47.0, 7478.955848051994, 2465989904.6866508, 46.0]
[2019-03-24 07:42:54,960] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1125752: loss 1.4409
[2019-03-24 07:42:54,963] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1125754: learning rate 0.0000
[2019-03-24 07:42:57,401] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1126972: loss 1.0847
[2019-03-24 07:42:57,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1126975: learning rate 0.0000
[2019-03-24 07:42:57,781] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1127162: loss 1.3741
[2019-03-24 07:42:57,783] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1127162: learning rate 0.0000
[2019-03-24 07:42:58,144] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1127340: loss 1.1688
[2019-03-24 07:42:58,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1127340: learning rate 0.0000
[2019-03-24 07:42:59,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0376795e-05 2.0330268e-05 3.2669555e-05 9.9980193e-01 1.3462864e-04], sum to 1.0000
[2019-03-24 07:42:59,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7422
[2019-03-24 07:42:59,552] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 30.0, 1.0, 2.0, 0.6217833533196733, 1.0, 2.0, 0.6217833533196733, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1502459.7788906, 1502459.778890601, 279247.8829819781], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2545800.0000, 
sim time next is 2546400.0000, 
raw observation next is [32.2, 30.0, 1.0, 2.0, 0.6228167004267924, 1.0, 2.0, 0.6228167004267924, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1503130.011233475, 1503130.011233475, 279555.2026889687], 
processed observation next is [1.0, 0.4782608695652174, 0.7481481481481482, 0.3, 1.0, 1.0, 0.550972262412848, 1.0, 1.0, 0.550972262412848, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5368321468690982, 0.5368321468690982, 0.5376061590172475], 
reward next is 0.4624, 
noisyNet noise sample is [array([-1.9392847], dtype=float32), -0.018005641]. 
=============================================
[2019-03-24 07:42:59,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7163829e-06 1.8927644e-06 6.7607612e-06 9.9986172e-01 1.2786705e-04], sum to 1.0000
[2019-03-24 07:42:59,668] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0402
[2019-03-24 07:42:59,673] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.63333333333333, 31.33333333333334, 1.0, 2.0, 0.605293029854303, 1.0, 2.0, 0.605293029854303, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1463580.523881316, 1463580.523881316, 273419.5717371118], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2544000.0000, 
sim time next is 2544600.0000, 
raw observation next is [31.81666666666667, 30.66666666666666, 1.0, 2.0, 0.6093518164402647, 1.0, 2.0, 0.6093518164402647, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1473546.340000025, 1473546.340000025, 274858.7194006849], 
processed observation next is [1.0, 0.43478260869565216, 0.7339506172839507, 0.3066666666666666, 1.0, 1.0, 0.5349426386193628, 1.0, 1.0, 0.5349426386193628, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5262665500000089, 0.5262665500000089, 0.5285744603859325], 
reward next is 0.4714, 
noisyNet noise sample is [array([-0.9252096], dtype=float32), -1.25943]. 
=============================================
[2019-03-24 07:43:00,076] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128294: loss 1.1207
[2019-03-24 07:43:00,077] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128294: learning rate 0.0000
[2019-03-24 07:43:00,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128399: loss 1.0398
[2019-03-24 07:43:00,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128400: learning rate 0.0000
[2019-03-24 07:43:00,631] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128573: loss 0.8951
[2019-03-24 07:43:00,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128573: learning rate 0.0000
[2019-03-24 07:43:00,724] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128620: loss 1.0156
[2019-03-24 07:43:00,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128621: learning rate 0.0000
[2019-03-24 07:43:01,668] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1129080: loss 1.2489
[2019-03-24 07:43:01,670] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1129081: learning rate 0.0000
[2019-03-24 07:43:02,345] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6920474e-07 2.0744517e-06 9.8350608e-07 9.9999607e-01 4.2909119e-07], sum to 1.0000
[2019-03-24 07:43:02,353] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0954
[2019-03-24 07:43:02,358] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.78333333333333, 85.0, 1.0, 2.0, 0.240331233713602, 1.0, 2.0, 0.240331233713602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574744.1121849389, 574744.1121849393, 168021.7136566857], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2595000.0000, 
sim time next is 2595600.0000, 
raw observation next is [22.6, 86.0, 1.0, 2.0, 0.2393855267193655, 1.0, 2.0, 0.2393855267193655, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572984.2352414648, 572984.2352414653, 167830.8110237041], 
processed observation next is [0.0, 0.043478260869565216, 0.39259259259259266, 0.86, 1.0, 1.0, 0.09450657942781607, 1.0, 1.0, 0.09450657942781607, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2046372268719517, 0.20463722687195188, 0.3227515596609694], 
reward next is 0.6772, 
noisyNet noise sample is [array([1.0907322], dtype=float32), 1.6932881]. 
=============================================
[2019-03-24 07:43:02,698] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129571: loss 1.0167
[2019-03-24 07:43:02,700] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129571: learning rate 0.0000
[2019-03-24 07:43:02,890] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129677: loss 0.9188
[2019-03-24 07:43:02,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129677: learning rate 0.0000
[2019-03-24 07:43:03,620] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1130038: loss 1.2575
[2019-03-24 07:43:03,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1130038: learning rate 0.0000
[2019-03-24 07:43:04,063] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130232: loss 1.0876
[2019-03-24 07:43:04,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130234: learning rate 0.0000
[2019-03-24 07:43:04,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0781830e-08 2.2000104e-06 1.5554400e-08 9.9999774e-01 4.2873907e-08], sum to 1.0000
[2019-03-24 07:43:04,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5698
[2019-03-24 07:43:04,417] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333334, 93.16666666666667, 1.0, 2.0, 0.2298944807561196, 1.0, 2.0, 0.2298944807561196, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554212.829883536, 554212.8298835364, 165885.1976299912], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2621400.0000, 
sim time next is 2622000.0000, 
raw observation next is [21.46666666666667, 93.33333333333334, 1.0, 2.0, 0.2322679390204266, 1.0, 2.0, 0.2322679390204266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558547.8121246431, 558547.8121246431, 166355.7737719215], 
processed observation next is [0.0, 0.34782608695652173, 0.35061728395061736, 0.9333333333333335, 1.0, 1.0, 0.08603326073860311, 1.0, 1.0, 0.08603326073860311, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19948136147308684, 0.19948136147308684, 0.3199149495613875], 
reward next is 0.6801, 
noisyNet noise sample is [array([-0.8881196], dtype=float32), 1.6025205]. 
=============================================
[2019-03-24 07:43:04,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.61033]
 [69.65001]
 [69.61035]
 [69.62585]
 [69.66027]], R is [[69.56951141]
 [69.55480957]
 [69.54068756]
 [69.52586365]
 [69.51040649]].
[2019-03-24 07:43:04,754] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1130533: loss 1.1743
[2019-03-24 07:43:04,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1130534: learning rate 0.0000
[2019-03-24 07:43:04,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0920911e-09 3.2160483e-07 3.7130121e-07 9.9999928e-01 3.7844647e-09], sum to 1.0000
[2019-03-24 07:43:04,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-24 07:43:04,830] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 90.5, 1.0, 2.0, 0.2683525656580963, 1.0, 2.0, 0.2683525656580963, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628566.2940291245, 628566.2940291245, 173858.5118596277], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2683800.0000, 
sim time next is 2684400.0000, 
raw observation next is [23.2, 89.33333333333334, 1.0, 2.0, 0.2654480393717106, 1.0, 2.0, 0.2654480393717106, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623030.8490510861, 623030.8490510861, 173244.7153131792], 
processed observation next is [0.0, 0.043478260869565216, 0.4148148148148148, 0.8933333333333334, 1.0, 1.0, 0.12553338020441734, 1.0, 1.0, 0.12553338020441734, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22251101751824504, 0.22251101751824504, 0.3331629140638061], 
reward next is 0.6668, 
noisyNet noise sample is [array([0.47715703], dtype=float32), 0.122853085]. 
=============================================
[2019-03-24 07:43:05,177] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1130759: loss 0.1574
[2019-03-24 07:43:05,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1130759: learning rate 0.0000
[2019-03-24 07:43:08,921] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8208784e-06 7.8620399e-09 2.4931489e-07 9.9999690e-01 1.0452299e-06], sum to 1.0000
[2019-03-24 07:43:08,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1218
[2019-03-24 07:43:08,940] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 74.66666666666667, 1.0, 2.0, 0.2678735724646416, 1.0, 2.0, 0.2678735724646416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626322.7777543446, 626322.7777543451, 173697.3758136116], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2708400.0000, 
sim time next is 2709000.0000, 
raw observation next is [25.9, 72.5, 1.0, 2.0, 0.2687591121745064, 1.0, 2.0, 0.2687591121745064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628056.3840254659, 628056.3840254659, 173886.7879500353], 
processed observation next is [0.0, 0.34782608695652173, 0.5148148148148147, 0.725, 1.0, 1.0, 0.129475133541079, 1.0, 1.0, 0.129475133541079, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2243058514376664, 0.2243058514376664, 0.3343976691346833], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.20615615], dtype=float32), 0.8327554]. 
=============================================
[2019-03-24 07:43:08,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.697556]
 [62.674583]
 [62.640903]
 [62.56595 ]
 [62.57028 ]], R is [[62.79050064]
 [62.82856369]
 [62.86705017]
 [62.90642166]
 [62.94790649]].
[2019-03-24 07:43:09,211] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1132876: loss 0.2305
[2019-03-24 07:43:09,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1132876: learning rate 0.0000
[2019-03-24 07:43:10,706] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1133654: loss 0.1161
[2019-03-24 07:43:10,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1133654: learning rate 0.0000
[2019-03-24 07:43:11,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8310546e-07 2.3637419e-07 9.2045219e-08 9.9999905e-01 5.0567553e-07], sum to 1.0000
[2019-03-24 07:43:11,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-24 07:43:11,731] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 52.5, 1.0, 2.0, 0.4622571163131358, 1.0, 2.0, 0.4622571163131358, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1053860.63032497, 1053860.630324971, 223957.8140696882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [32.5, 53.0, 1.0, 2.0, 0.3219999970500136, 1.0, 2.0, 0.3219999970500136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733947.2563339, 733947.2563339004, 185824.6983002449], 
processed observation next is [1.0, 0.7391304347826086, 0.7592592592592593, 0.53, 1.0, 1.0, 0.19285713934525428, 1.0, 1.0, 0.19285713934525428, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26212402011925, 0.2621240201192501, 0.3573551890389325], 
reward next is 0.6426, 
noisyNet noise sample is [array([0.8983021], dtype=float32), -0.105486505]. 
=============================================
[2019-03-24 07:43:11,761] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.4515199e-06 9.7666771e-06 6.5931481e-06 9.9995899e-01 1.5083709e-05], sum to 1.0000
[2019-03-24 07:43:11,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9907
[2019-03-24 07:43:11,772] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3826817149186156, 1.0, 2.0, 0.3826817149186156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 872340.1912388051, 872340.1912388055, 201484.9198710899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3744203310446477, 1.0, 2.0, 0.3744203310446477, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853497.5089342609, 853497.5089342614, 199277.6919983268], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.2552622988626759, 1.0, 1.0, 0.2552622988626759, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3048205389050932, 0.30482053890509336, 0.3832263307660131], 
reward next is 0.6168, 
noisyNet noise sample is [array([-1.7011489], dtype=float32), -1.9756113]. 
=============================================
[2019-03-24 07:43:13,121] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1134920: loss 0.0969
[2019-03-24 07:43:13,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1134921: learning rate 0.0000
[2019-03-24 07:43:13,797] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1135281: loss 0.0749
[2019-03-24 07:43:13,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1135281: learning rate 0.0000
[2019-03-24 07:43:14,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1135412: loss 0.0547
[2019-03-24 07:43:14,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1135412: learning rate 0.0000
[2019-03-24 07:43:15,638] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136248: loss 0.0232
[2019-03-24 07:43:15,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136248: learning rate 0.0000
[2019-03-24 07:43:15,783] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136328: loss 0.0212
[2019-03-24 07:43:15,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136329: learning rate 0.0000
[2019-03-24 07:43:16,430] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136657: loss 0.0916
[2019-03-24 07:43:16,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136657: learning rate 0.0000
[2019-03-24 07:43:16,531] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136710: loss 0.0560
[2019-03-24 07:43:16,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136711: learning rate 0.0000
[2019-03-24 07:43:17,131] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1137026: loss 0.1767
[2019-03-24 07:43:17,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1137026: learning rate 0.0000
[2019-03-24 07:43:18,309] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137645: loss 0.1361
[2019-03-24 07:43:18,312] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137646: learning rate 0.0000
[2019-03-24 07:43:18,352] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137670: loss 0.1205
[2019-03-24 07:43:18,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137671: learning rate 0.0000
[2019-03-24 07:43:18,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3069788e-06 1.1451791e-06 3.6781737e-05 9.9995542e-01 3.5590736e-07], sum to 1.0000
[2019-03-24 07:43:18,425] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8959
[2019-03-24 07:43:18,428] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.58333333333333, 91.5, 1.0, 2.0, 0.2610655814844557, 1.0, 2.0, 0.2610655814844557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616533.4396606985, 616533.439660699, 172403.1895593779], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2857800.0000, 
sim time next is 2858400.0000, 
raw observation next is [22.5, 91.0, 1.0, 2.0, 0.2582395340138144, 1.0, 2.0, 0.2582395340138144, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611542.9561815572, 611542.9561815572, 171827.6816110364], 
processed observation next is [1.0, 0.08695652173913043, 0.3888888888888889, 0.91, 1.0, 1.0, 0.11695182620692189, 1.0, 1.0, 0.11695182620692189, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21840819863627042, 0.21840819863627042, 0.33043784925199304], 
reward next is 0.6696, 
noisyNet noise sample is [array([0.5219753], dtype=float32), 0.9515591]. 
=============================================
[2019-03-24 07:43:19,060] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1138033: loss 0.2311
[2019-03-24 07:43:19,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1138033: learning rate 0.0000
[2019-03-24 07:43:19,096] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3506905e-08 9.6317386e-08 1.4002835e-07 9.9999976e-01 3.9088924e-08], sum to 1.0000
[2019-03-24 07:43:19,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7412
[2019-03-24 07:43:19,110] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.91666666666667, 96.66666666666666, 1.0, 2.0, 0.3136410544764912, 1.0, 2.0, 0.3136410544764912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714885.505488679, 714885.5054886795, 183766.2895717174], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3019800.0000, 
sim time next is 3020400.0000, 
raw observation next is [23.9, 96.0, 1.0, 2.0, 0.3101367177361369, 1.0, 2.0, 0.3101367177361369, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706894.3493659104, 706894.3493659109, 182910.8880733984], 
processed observation next is [1.0, 1.0, 0.4407407407407407, 0.96, 1.0, 1.0, 0.17873418778111533, 1.0, 1.0, 0.17873418778111533, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2524622676306823, 0.25246226763068247, 0.3517517078334585], 
reward next is 0.6482, 
noisyNet noise sample is [array([0.57245684], dtype=float32), 0.033602253]. 
=============================================
[2019-03-24 07:43:19,424] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138222: loss 0.3355
[2019-03-24 07:43:19,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138222: learning rate 0.0000
[2019-03-24 07:43:19,903] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1138474: loss 0.2224
[2019-03-24 07:43:19,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1138474: learning rate 0.0000
[2019-03-24 07:43:20,056] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1138550: loss 0.1302
[2019-03-24 07:43:20,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1138552: learning rate 0.0000
[2019-03-24 07:43:21,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0672033e-04 8.2134948e-06 3.9136472e-07 9.9984550e-01 3.9064995e-05], sum to 1.0000
[2019-03-24 07:43:21,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2767
[2019-03-24 07:43:21,894] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 88.66666666666667, 1.0, 2.0, 0.4875589249148515, 1.0, 2.0, 0.4875589249148515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1111585.912002437, 1111585.912002437, 231561.7810801252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2946000.0000, 
sim time next is 2946600.0000, 
raw observation next is [25.25, 90.0, 1.0, 2.0, 0.4431105183885679, 1.0, 2.0, 0.4431105183885679, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1010181.158943819, 1010181.158943819, 218349.7132093252], 
processed observation next is [1.0, 0.08695652173913043, 0.49074074074074076, 0.9, 1.0, 1.0, 0.33703633141496186, 1.0, 1.0, 0.33703633141496186, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3607789853370782, 0.3607789853370782, 0.41990329463331766], 
reward next is 0.5801, 
noisyNet noise sample is [array([0.7788517], dtype=float32), 0.58389884]. 
=============================================
[2019-03-24 07:43:22,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3011936e-08 4.7431943e-08 4.2292790e-08 9.9999988e-01 1.8860828e-08], sum to 1.0000
[2019-03-24 07:43:22,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9716
[2019-03-24 07:43:22,536] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3231812157256156, 1.0, 2.0, 0.3231812157256156, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736640.9481982864, 736640.9481982864, 186116.714240394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2937000.0000, 
sim time next is 2937600.0000, 
raw observation next is [25.1, 91.0, 1.0, 2.0, 0.3228363041091028, 1.0, 2.0, 0.3228363041091028, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735854.3988570881, 735854.3988570881, 186031.2105590427], 
processed observation next is [1.0, 0.0, 0.4851851851851852, 0.91, 1.0, 1.0, 0.19385274298702715, 1.0, 1.0, 0.19385274298702715, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26280514244896, 0.26280514244896, 0.35775232799815904], 
reward next is 0.6422, 
noisyNet noise sample is [array([-1.1764901], dtype=float32), 1.218633]. 
=============================================
[2019-03-24 07:43:23,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5219052e-07 3.4579868e-06 1.4701252e-06 9.9998605e-01 8.2919414e-06], sum to 1.0000
[2019-03-24 07:43:24,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2726
[2019-03-24 07:43:24,005] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.96666666666667, 52.16666666666667, 1.0, 2.0, 0.800298368411099, 1.0, 2.0, 0.800298368411099, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1827565.032186125, 1827565.032186125, 343991.9547047764], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3142200.0000, 
sim time next is 3142800.0000, 
raw observation next is [30.0, 52.0, 1.0, 2.0, 0.7759137513898071, 1.0, 2.0, 0.7759137513898071, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1772594.6239051, 1772594.623905101, 334052.646582344], 
processed observation next is [1.0, 0.391304347826087, 0.6666666666666666, 0.52, 1.0, 1.0, 0.733230656416437, 1.0, 1.0, 0.733230656416437, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6330695085375357, 0.6330695085375361, 0.642408935735277], 
reward next is 0.3576, 
noisyNet noise sample is [array([1.0327219], dtype=float32), -1.2082207]. 
=============================================
[2019-03-24 07:43:24,679] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1140901: loss 0.4020
[2019-03-24 07:43:24,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1140901: learning rate 0.0000
[2019-03-24 07:43:26,292] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1141749: loss 0.3622
[2019-03-24 07:43:26,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1141749: learning rate 0.0000
[2019-03-24 07:43:27,359] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4624538e-08 9.5873695e-08 2.1760671e-08 9.9999452e-01 5.2611213e-06], sum to 1.0000
[2019-03-24 07:43:27,372] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7761
[2019-03-24 07:43:27,380] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 46.66666666666666, 1.0, 2.0, 0.4175652008942268, 1.0, 2.0, 0.4175652008942268, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9562837326655, 1012127.242157875, 1012127.242157875, 213536.5421527697], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3118200.0000, 
sim time next is 3118800.0000, 
raw observation next is [28.26666666666667, 48.33333333333334, 1.0, 2.0, 0.3757738047997738, 1.0, 2.0, 0.3757738047997738, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 905087.4077804441, 905087.4077804445, 201678.1451764767], 
processed observation next is [1.0, 0.08695652173913043, 0.6024691358024692, 0.48333333333333345, 1.0, 1.0, 0.25687357714258785, 1.0, 1.0, 0.25687357714258785, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32324550277873004, 0.32324550277873015, 0.38784258687783985], 
reward next is 0.6122, 
noisyNet noise sample is [array([-2.186175], dtype=float32), -0.44777122]. 
=============================================
[2019-03-24 07:43:27,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4503259e-06 2.8775718e-05 2.5263064e-06 9.9985766e-01 1.0762873e-04], sum to 1.0000
[2019-03-24 07:43:27,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-24 07:43:27,881] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333334, 98.16666666666667, 1.0, 2.0, 0.4182625528527835, 1.0, 2.0, 0.4182625528527835, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 953498.7692084492, 953498.7692084496, 211262.9176388569], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3039000.0000, 
sim time next is 3039600.0000, 
raw observation next is [25.26666666666667, 96.33333333333334, 1.0, 2.0, 0.3940944949224653, 1.0, 2.0, 0.3940944949224653, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 898371.3849022567, 898371.3849022571, 204574.3770598155], 
processed observation next is [1.0, 0.17391304347826086, 0.49135802469135814, 0.9633333333333334, 1.0, 1.0, 0.2786839225267444, 1.0, 1.0, 0.2786839225267444, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32084692317937735, 0.3208469231793775, 0.3934122635765683], 
reward next is 0.6066, 
noisyNet noise sample is [array([-1.1581651], dtype=float32), -1.136816]. 
=============================================
[2019-03-24 07:43:28,661] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1142986: loss 0.4766
[2019-03-24 07:43:28,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1142986: learning rate 0.0000
[2019-03-24 07:43:28,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7702996e-08 3.5846554e-07 6.2543052e-08 9.9999928e-01 2.8370863e-07], sum to 1.0000
[2019-03-24 07:43:28,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3466
[2019-03-24 07:43:28,868] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 80.16666666666667, 1.0, 2.0, 0.3477978216861221, 1.0, 2.0, 0.3477978216861221, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 792779.6609605873, 792779.6609605878, 192326.8894879677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3096600.0000, 
sim time next is 3097200.0000, 
raw observation next is [27.66666666666667, 77.33333333333334, 1.0, 2.0, 0.3457753863863001, 1.0, 2.0, 0.3457753863863001, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788167.2976332989, 788167.2976332989, 191808.7042618723], 
processed observation next is [1.0, 0.8695652173913043, 0.580246913580247, 0.7733333333333334, 1.0, 1.0, 0.2211611742694049, 1.0, 1.0, 0.2211611742694049, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.281488320583321, 0.281488320583321, 0.3688628928112929], 
reward next is 0.6311, 
noisyNet noise sample is [array([-0.46882164], dtype=float32), -0.99631107]. 
=============================================
[2019-03-24 07:43:29,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1143330: loss 0.6161
[2019-03-24 07:43:29,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1143330: learning rate 0.0000
[2019-03-24 07:43:29,581] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1143466: loss 0.6151
[2019-03-24 07:43:29,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1143467: learning rate 0.0000
[2019-03-24 07:43:30,898] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144156: loss 0.5747
[2019-03-24 07:43:30,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144157: learning rate 0.0000
[2019-03-24 07:43:31,266] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144343: loss 0.5565
[2019-03-24 07:43:31,269] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144343: learning rate 0.0000
[2019-03-24 07:43:31,898] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144676: loss 0.6842
[2019-03-24 07:43:31,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144678: learning rate 0.0000
[2019-03-24 07:43:32,087] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144773: loss 0.6322
[2019-03-24 07:43:32,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144773: learning rate 0.0000
[2019-03-24 07:43:32,686] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1145084: loss 0.6672
[2019-03-24 07:43:32,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1145084: learning rate 0.0000
[2019-03-24 07:43:33,794] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145654: loss 0.7666
[2019-03-24 07:43:33,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145655: learning rate 0.0000
[2019-03-24 07:43:34,086] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145808: loss 0.6872
[2019-03-24 07:43:34,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145809: learning rate 0.0000
[2019-03-24 07:43:34,288] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1145909: loss 0.6856
[2019-03-24 07:43:34,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1145909: learning rate 0.0000
[2019-03-24 07:43:34,680] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146116: loss 0.7089
[2019-03-24 07:43:34,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146117: learning rate 0.0000
[2019-03-24 07:43:35,349] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1146463: loss 5.4922
[2019-03-24 07:43:35,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1146463: learning rate 0.0000
[2019-03-24 07:43:35,377] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146475: loss 0.6939
[2019-03-24 07:43:35,380] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146475: learning rate 0.0000
[2019-03-24 07:43:36,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6635395e-05 5.3699834e-05 5.9983067e-06 9.9959117e-01 2.8245425e-04], sum to 1.0000
[2019-03-24 07:43:36,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5189
[2019-03-24 07:43:36,489] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 79.66666666666667, 1.0, 2.0, 0.2795681987055294, 1.0, 2.0, 0.2795681987055294, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 646898.5404758933, 646898.5404758938, 176109.8797042479], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [25.25, 83.33333333333333, 1.0, 2.0, 0.2898767630580447, 1.0, 2.0, 0.2898767630580447, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 665288.9219030767, 665288.9219030772, 178279.0814977318], 
processed observation next is [0.0, 0.043478260869565216, 0.49074074074074076, 0.8333333333333333, 1.0, 1.0, 0.1546151941167199, 1.0, 1.0, 0.1546151941167199, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23760318639395597, 0.23760318639395614, 0.34284438749563806], 
reward next is 0.6572, 
noisyNet noise sample is [array([1.8667709], dtype=float32), 1.4089457]. 
=============================================
[2019-03-24 07:43:39,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0553096e-05 1.0340944e-05 1.2154324e-04 9.9983525e-01 2.3166722e-06], sum to 1.0000
[2019-03-24 07:43:39,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7830
[2019-03-24 07:43:39,708] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.2694604741525915, 1.0, 2.0, 0.2694604741525915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631231.9948262519, 631231.9948262523, 174118.112246421], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3308400.0000, 
sim time next is 3309000.0000, 
raw observation next is [22.18333333333334, 98.33333333333334, 1.0, 2.0, 0.2691831693727759, 1.0, 2.0, 0.2691831693727759, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 630756.4488575594, 630756.4488575597, 174061.6464848638], 
processed observation next is [0.0, 0.30434782608695654, 0.37716049382716077, 0.9833333333333334, 1.0, 1.0, 0.12997996353901894, 1.0, 1.0, 0.12997996353901894, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2252701603062712, 0.2252701603062713, 0.334733935547815], 
reward next is 0.6653, 
noisyNet noise sample is [array([-1.406592], dtype=float32), -1.5490533]. 
=============================================
[2019-03-24 07:43:39,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.19434]
 [65.12065]
 [65.10928]
 [65.09926]
 [65.05913]], R is [[65.23731232]
 [65.25009918]
 [65.26255035]
 [65.27469635]
 [65.28675079]].
[2019-03-24 07:43:40,185] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1148989: loss 4.9398
[2019-03-24 07:43:40,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1148990: learning rate 0.0000
[2019-03-24 07:43:40,458] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8792427e-07 1.9026598e-07 2.1224572e-05 9.9997449e-01 3.7421212e-06], sum to 1.0000
[2019-03-24 07:43:40,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0281
[2019-03-24 07:43:40,470] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 70.33333333333334, 1.0, 2.0, 0.3432793752285633, 1.0, 2.0, 0.3432793752285633, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 782474.9360816183, 782474.9360816188, 191171.6964068203], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3435600.0000, 
sim time next is 3436200.0000, 
raw observation next is [29.0, 72.5, 1.0, 2.0, 0.3420992090443336, 1.0, 2.0, 0.3420992090443336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 779783.4834207941, 779783.4834207946, 190871.0950271586], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.725, 1.0, 1.0, 0.21678477267182572, 1.0, 1.0, 0.21678477267182572, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2784941012217122, 0.27849410122171236, 0.3670597981291511], 
reward next is 0.6329, 
noisyNet noise sample is [array([0.10916341], dtype=float32), -0.26664394]. 
=============================================
[2019-03-24 07:43:41,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1641226e-05 5.9871871e-07 3.8409478e-08 9.9997437e-01 3.3635995e-06], sum to 1.0000
[2019-03-24 07:43:41,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4580
[2019-03-24 07:43:41,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.05, 78.5, 1.0, 2.0, 0.329078271411494, 1.0, 2.0, 0.329078271411494, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750088.9392471437, 750088.9392471442, 187585.2558640577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3331800.0000, 
sim time next is 3332400.0000, 
raw observation next is [27.06666666666667, 78.33333333333334, 1.0, 2.0, 0.3288347107231262, 1.0, 2.0, 0.3288347107231262, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749533.5045223185, 749533.504522319, 187524.3612921424], 
processed observation next is [0.0, 0.5652173913043478, 0.5580246913580248, 0.7833333333333334, 1.0, 1.0, 0.2009937032418169, 1.0, 1.0, 0.2009937032418169, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26769053732939946, 0.2676905373293996, 0.36062377171565846], 
reward next is 0.6394, 
noisyNet noise sample is [array([2.3487973], dtype=float32), 0.49381286]. 
=============================================
[2019-03-24 07:43:41,484] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1149666: loss 4.6497
[2019-03-24 07:43:41,487] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1149669: learning rate 0.0000
[2019-03-24 07:43:42,117] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 07:43:42,121] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:43:42,122] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:43:42,123] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:42,125] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:42,125] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:43:42,127] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:43:42,129] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:42,128] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:43:42,130] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:42,131] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:42,146] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-24 07:43:42,178] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-24 07:43:42,210] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-24 07:43:42,210] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-24 07:43:42,281] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-24 07:44:28,379] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00974186], dtype=float32), 0.007079353]
[2019-03-24 07:44:28,381] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.56292669, 69.70961571333333, 1.0, 2.0, 0.2768530609857451, 1.0, 2.0, 0.2768530609857451, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643886.0975224567, 643886.0975224571, 175628.8710320297]
[2019-03-24 07:44:28,384] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:44:28,387] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7536546e-06 2.7904805e-06 2.0648013e-06 9.9998510e-01 8.3985460e-06], sampled 0.06625481101140207
[2019-03-24 07:44:40,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00974186], dtype=float32), 0.007079353]
[2019-03-24 07:44:40,072] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.5, 78.0, 1.0, 2.0, 0.2644185054701096, 1.0, 2.0, 0.2644185054701096, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 623140.0001813814, 623140.0001813818, 173118.0009305341]
[2019-03-24 07:44:40,073] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:44:40,078] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4259404e-06 2.3022917e-06 1.6986075e-06 9.9998760e-01 6.9747521e-06], sampled 0.6227849400521779
[2019-03-24 07:45:06,814] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00974186], dtype=float32), 0.007079353]
[2019-03-24 07:45:06,815] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.439735265, 53.65776888000001, 1.0, 2.0, 0.3005984133306789, 1.0, 2.0, 0.3005984133306789, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685143.9849791954, 685143.9849791954, 180604.7382851462]
[2019-03-24 07:45:06,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:45:06,823] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4578129e-06 2.3071464e-06 1.7476079e-06 9.9998724e-01 7.2199637e-06], sampled 0.47403847005518684
[2019-03-24 07:45:27,604] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:45:28,208] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:45:28,272] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7520.9653 2668577180.3087 68.0000
[2019-03-24 07:45:28,311] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.2334 2410718517.5402 22.0000
[2019-03-24 07:45:28,370] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.4321 2465983108.1172 46.0000
[2019-03-24 07:45:29,383] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1150000, evaluation results [1150000.0, 7520.965276612854, 2668577180.3086867, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7796.233416073564, 2410718517.5402093, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.432085654345, 2465983108.117151, 46.0]
[2019-03-24 07:45:31,100] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1150841: loss 5.6191
[2019-03-24 07:45:31,103] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1150842: learning rate 0.0000
[2019-03-24 07:45:31,701] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1151141: loss 5.7126
[2019-03-24 07:45:31,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1151142: learning rate 0.0000
[2019-03-24 07:45:32,393] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1151479: loss 5.3835
[2019-03-24 07:45:32,395] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1151479: learning rate 0.0000
[2019-03-24 07:45:33,953] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152249: loss 4.8167
[2019-03-24 07:45:33,955] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152249: learning rate 0.0000
[2019-03-24 07:45:34,365] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152448: loss 4.7575
[2019-03-24 07:45:34,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152449: learning rate 0.0000
[2019-03-24 07:45:34,836] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152678: loss 6.1453
[2019-03-24 07:45:34,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152678: learning rate 0.0000
[2019-03-24 07:45:34,989] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152755: loss 6.1386
[2019-03-24 07:45:34,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152756: learning rate 0.0000
[2019-03-24 07:45:35,766] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1153070: loss 4.8823
[2019-03-24 07:45:35,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1153070: learning rate 0.0000
[2019-03-24 07:45:36,977] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153680: loss 6.3495
[2019-03-24 07:45:36,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153680: learning rate 0.0000
[2019-03-24 07:45:37,040] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153710: loss 6.2251
[2019-03-24 07:45:37,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153710: learning rate 0.0000
[2019-03-24 07:45:37,353] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1153864: loss 6.2029
[2019-03-24 07:45:37,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1153864: learning rate 0.0000
[2019-03-24 07:45:38,013] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154193: loss 6.3497
[2019-03-24 07:45:38,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154194: learning rate 0.0000
[2019-03-24 07:45:38,454] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154413: loss 6.8745
[2019-03-24 07:45:38,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154414: learning rate 0.0000
[2019-03-24 07:45:38,684] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1154524: loss 0.2141
[2019-03-24 07:45:38,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1154524: learning rate 0.0000
[2019-03-24 07:45:43,742] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1157038: loss 0.1987
[2019-03-24 07:45:43,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1157038: learning rate 0.0000
[2019-03-24 07:45:45,016] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1157697: loss 0.1701
[2019-03-24 07:45:45,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1157697: learning rate 0.0000
[2019-03-24 07:45:46,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0742296e-06 6.8148320e-06 4.4982670e-08 9.9995792e-01 3.0126343e-05], sum to 1.0000
[2019-03-24 07:45:46,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-24 07:45:46,710] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.95, 86.5, 1.0, 2.0, 0.3330471660884704, 1.0, 2.0, 0.3330471660884704, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 759139.9718717037, 759139.9718717042, 188581.3004198768], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3691800.0000, 
sim time next is 3692400.0000, 
raw observation next is [26.96666666666667, 87.33333333333333, 1.0, 2.0, 0.3392579067487189, 1.0, 2.0, 0.3392579067487189, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 773303.7308432779, 773303.7308432783, 190149.529602547], 
processed observation next is [1.0, 0.7391304347826086, 0.554320987654321, 0.8733333333333333, 1.0, 1.0, 0.2134022699389511, 1.0, 1.0, 0.2134022699389511, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2761799038725992, 0.2761799038725994, 0.36567217231259036], 
reward next is 0.6343, 
noisyNet noise sample is [array([-0.35586065], dtype=float32), 0.55853003]. 
=============================================
[2019-03-24 07:45:47,132] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1158799: loss 0.1440
[2019-03-24 07:45:47,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1158800: learning rate 0.0000
[2019-03-24 07:45:47,600] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1159048: loss 0.1264
[2019-03-24 07:45:47,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1159048: learning rate 0.0000
[2019-03-24 07:45:48,546] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1159545: loss 0.1404
[2019-03-24 07:45:48,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1159547: learning rate 0.0000
[2019-03-24 07:45:49,966] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160294: loss 0.1377
[2019-03-24 07:45:49,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160294: learning rate 0.0000
[2019-03-24 07:45:50,250] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160447: loss 0.1342
[2019-03-24 07:45:50,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160447: learning rate 0.0000
[2019-03-24 07:45:50,562] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160608: loss 0.1493
[2019-03-24 07:45:50,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160608: learning rate 0.0000
[2019-03-24 07:45:50,892] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160780: loss 0.1374
[2019-03-24 07:45:50,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160780: learning rate 0.0000
[2019-03-24 07:45:51,489] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1161087: loss 0.1521
[2019-03-24 07:45:51,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1161088: learning rate 0.0000
[2019-03-24 07:45:52,659] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161698: loss 0.2027
[2019-03-24 07:45:52,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161699: learning rate 0.0000
[2019-03-24 07:45:52,763] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161754: loss 0.1721
[2019-03-24 07:45:52,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161755: learning rate 0.0000
[2019-03-24 07:45:53,050] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1161904: loss 0.1327
[2019-03-24 07:45:53,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1161904: learning rate 0.0000
[2019-03-24 07:45:53,565] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162169: loss 0.1369
[2019-03-24 07:45:53,567] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162169: learning rate 0.0000
[2019-03-24 07:45:53,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162285: loss 0.1653
[2019-03-24 07:45:53,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162285: learning rate 0.0000
[2019-03-24 07:45:54,068] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1162430: loss 0.0864
[2019-03-24 07:45:54,071] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1162431: learning rate 0.0000
[2019-03-24 07:45:57,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.5230619e-07 2.9516693e-07 1.6301655e-06 9.9998748e-01 9.8106630e-06], sum to 1.0000
[2019-03-24 07:45:57,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9657
[2019-03-24 07:45:57,401] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 90.66666666666667, 1.0, 2.0, 0.3598961964935162, 1.0, 2.0, 0.3598961964935162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 820371.7785381494, 820371.7785381499, 195456.0302521869], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3895800.0000, 
sim time next is 3896400.0000, 
raw observation next is [26.33333333333334, 90.33333333333334, 1.0, 2.0, 0.361484882782857, 1.0, 2.0, 0.361484882782857, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823995.0843311968, 823995.0843311973, 195870.7675396059], 
processed observation next is [0.0, 0.08695652173913043, 0.5308641975308644, 0.9033333333333334, 1.0, 1.0, 0.2398629556938774, 1.0, 1.0, 0.2398629556938774, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2942839586897132, 0.29428395868971335, 0.37667455296078056], 
reward next is 0.6233, 
noisyNet noise sample is [array([0.89492804], dtype=float32), 1.4854989]. 
=============================================
[2019-03-24 07:45:59,352] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1165196: loss 0.1225
[2019-03-24 07:45:59,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1165198: learning rate 0.0000
[2019-03-24 07:46:00,131] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1165611: loss 0.1535
[2019-03-24 07:46:00,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1165612: learning rate 0.0000
[2019-03-24 07:46:01,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2176248e-06 1.3273140e-06 6.4170632e-07 9.9998963e-01 2.6072578e-07], sum to 1.0000
[2019-03-24 07:46:01,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6519
[2019-03-24 07:46:01,168] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.55, 95.0, 1.0, 2.0, 0.3594508180227944, 1.0, 2.0, 0.3594508180227944, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 819356.010025374, 819356.0100253735, 195339.93061768], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [25.4, 95.33333333333334, 1.0, 2.0, 0.3568607458157899, 1.0, 2.0, 0.3568607458157899, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813448.8948747708, 813448.8948747708, 194666.1324792104], 
processed observation next is [0.0, 0.17391304347826086, 0.49629629629629624, 0.9533333333333335, 1.0, 1.0, 0.23435803073308323, 1.0, 1.0, 0.23435803073308323, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29051746245527527, 0.29051746245527527, 0.37435794707540465], 
reward next is 0.6256, 
noisyNet noise sample is [array([0.8292122], dtype=float32), 1.9589449]. 
=============================================
[2019-03-24 07:46:02,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1684699e-06 3.0015583e-06 3.2364719e-07 9.9996114e-01 2.8321690e-05], sum to 1.0000
[2019-03-24 07:46:02,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2158
[2019-03-24 07:46:02,128] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.13333333333333, 85.66666666666667, 1.0, 2.0, 0.624696539511553, 1.0, 2.0, 0.624696539511553, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1424536.773515118, 1424536.773515118, 276640.4128083876], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4020000.0000, 
sim time next is 4020600.0000, 
raw observation next is [26.16666666666666, 84.83333333333333, 1.0, 2.0, 0.6217198543034171, 1.0, 2.0, 0.6217198543034171, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1417742.558806703, 1417742.558806704, 275592.677717005], 
processed observation next is [1.0, 0.5217391304347826, 0.5246913580246911, 0.8483333333333333, 1.0, 1.0, 0.5496664932183537, 1.0, 1.0, 0.5496664932183537, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.506336628145251, 0.5063366281452514, 0.5299859186865481], 
reward next is 0.4700, 
noisyNet noise sample is [array([1.5038383], dtype=float32), 0.53858227]. 
=============================================
[2019-03-24 07:46:02,324] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1166742: loss 0.0699
[2019-03-24 07:46:02,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1166743: learning rate 0.0000
[2019-03-24 07:46:02,947] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1167071: loss 0.1565
[2019-03-24 07:46:02,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1167071: learning rate 0.0000
[2019-03-24 07:46:03,947] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1167595: loss 0.0946
[2019-03-24 07:46:03,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1167596: learning rate 0.0000
[2019-03-24 07:46:05,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1846096e-06 2.0868079e-06 2.3884131e-06 9.9988079e-01 1.0946878e-04], sum to 1.0000
[2019-03-24 07:46:05,158] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-24 07:46:05,162] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.7, 97.0, 1.0, 2.0, 0.224002714086155, 1.0, 2.0, 0.224002714086155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541472.8789749192, 541472.8789749192, 164650.5087882211], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [20.58333333333333, 97.5, 1.0, 2.0, 0.3031456878434028, 1.0, 2.0, 0.3031456878434028, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732046.9172706469, 732046.9172706469, 182975.8513420371], 
processed observation next is [1.0, 0.08695652173913043, 0.31790123456790104, 0.975, 1.0, 1.0, 0.17041153314690807, 1.0, 1.0, 0.17041153314690807, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2614453275966596, 0.2614453275966596, 0.3518766371962252], 
reward next is 0.6481, 
noisyNet noise sample is [array([-1.3215096], dtype=float32), -0.8742581]. 
=============================================
[2019-03-24 07:46:05,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.03302 ]
 [56.99155 ]
 [57.01781 ]
 [56.808655]
 [56.84324 ]], R is [[57.38913345]
 [57.49860764]
 [57.60684204]
 [57.71399689]
 [57.82036209]].
[2019-03-24 07:46:05,412] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168360: loss 0.0775
[2019-03-24 07:46:05,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168361: learning rate 0.0000
[2019-03-24 07:46:05,588] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168454: loss 0.0654
[2019-03-24 07:46:05,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168454: learning rate 0.0000
[2019-03-24 07:46:06,060] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168698: loss 0.1089
[2019-03-24 07:46:06,061] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168698: learning rate 0.0000
[2019-03-24 07:46:06,152] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168751: loss 0.1056
[2019-03-24 07:46:06,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168753: learning rate 0.0000
[2019-03-24 07:46:06,919] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1169147: loss 0.1266
[2019-03-24 07:46:06,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1169147: learning rate 0.0000
[2019-03-24 07:46:07,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.742390e-08 9.658737e-09 5.426727e-09 9.999918e-01 8.119194e-06], sum to 1.0000
[2019-03-24 07:46:07,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2815
[2019-03-24 07:46:07,691] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 53.5, 1.0, 2.0, 0.259420155540428, 1.0, 2.0, 0.259420155540428, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 608149.5258026049, 608149.5258026052, 171829.5119838299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4221000.0000, 
sim time next is 4221600.0000, 
raw observation next is [29.26666666666667, 56.33333333333333, 1.0, 2.0, 0.26924756968063, 1.0, 2.0, 0.26924756968063, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625960.756420276, 625960.7564202765, 173850.9267554477], 
processed observation next is [1.0, 0.8695652173913043, 0.6395061728395063, 0.5633333333333332, 1.0, 1.0, 0.1300566305721786, 1.0, 1.0, 0.1300566305721786, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22355741300724144, 0.2235574130072416, 0.3343287052989379], 
reward next is 0.6657, 
noisyNet noise sample is [array([-1.0052238], dtype=float32), 1.1676335]. 
=============================================
[2019-03-24 07:46:07,885] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169650: loss 0.0558
[2019-03-24 07:46:07,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169650: learning rate 0.0000
[2019-03-24 07:46:07,930] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169674: loss 0.0776
[2019-03-24 07:46:07,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169674: learning rate 0.0000
[2019-03-24 07:46:08,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5146851e-07 2.5356962e-06 1.0101521e-06 9.9998271e-01 1.2905494e-05], sum to 1.0000
[2019-03-24 07:46:08,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5987
[2019-03-24 07:46:08,058] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.7, 78.0, 1.0, 2.0, 0.7072000374982509, 1.0, 2.0, 0.7072000374982509, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1612868.396860319, 1612868.396860319, 306899.2555608415], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4035600.0000, 
sim time next is 4036200.0000, 
raw observation next is [26.58333333333333, 79.83333333333333, 1.0, 2.0, 0.3844860021359284, 1.0, 2.0, 0.3844860021359284, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 876455.4969245587, 876455.4969245591, 201970.6745350719], 
processed observation next is [1.0, 0.7391304347826086, 0.5401234567901233, 0.7983333333333333, 1.0, 1.0, 0.26724524063801, 1.0, 1.0, 0.26724524063801, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31301982033019954, 0.3130198203301997, 0.38840514333667675], 
reward next is 0.6116, 
noisyNet noise sample is [array([0.17780906], dtype=float32), 0.14739628]. 
=============================================
[2019-03-24 07:46:08,368] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1169904: loss 0.0275
[2019-03-24 07:46:08,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1169905: learning rate 0.0000
[2019-03-24 07:46:08,730] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170089: loss 0.0565
[2019-03-24 07:46:08,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170089: learning rate 0.0000
[2019-03-24 07:46:09,065] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170263: loss 0.0645
[2019-03-24 07:46:09,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170263: learning rate 0.0000
[2019-03-24 07:46:09,174] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1170327: loss 0.4453
[2019-03-24 07:46:09,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1170328: learning rate 0.0000
[2019-03-24 07:46:10,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7636729e-06 8.6944056e-06 1.1454140e-04 9.9985814e-01 1.5852704e-05], sum to 1.0000
[2019-03-24 07:46:10,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2519
[2019-03-24 07:46:10,447] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.2245231851789679, 1.0, 2.0, 0.2245231851789679, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 542653.5568961143, 542653.5568961147, 164761.1222670652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2234989128774162, 1.0, 2.0, 0.2234989128774162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540600.4585407497, 540600.4585407497, 164553.3585424161], 
processed observation next is [1.0, 0.043478260869565216, 0.3333333333333333, 0.94, 1.0, 1.0, 0.07559394390168594, 1.0, 1.0, 0.07559394390168594, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19307159233598206, 0.19307159233598206, 0.3164487664277233], 
reward next is 0.6836, 
noisyNet noise sample is [array([0.52418375], dtype=float32), -0.90565425]. 
=============================================
[2019-03-24 07:46:14,512] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1173104: loss 1.0460
[2019-03-24 07:46:14,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1173104: learning rate 0.0000
[2019-03-24 07:46:15,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1173591: loss 0.8863
[2019-03-24 07:46:15,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1173591: learning rate 0.0000
[2019-03-24 07:46:17,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.68526411e-07 1.12031075e-05 2.91419866e-07 9.99985933e-01
 1.93270625e-06], sum to 1.0000
[2019-03-24 07:46:17,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5917
[2019-03-24 07:46:17,174] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 34.66666666666667, 1.0, 2.0, 0.247713933837108, 1.0, 2.0, 0.247713933837108, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584237.374422597, 584237.3744225975, 169339.0855907859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4212600.0000, 
sim time next is 4213200.0000, 
raw observation next is [33.66666666666667, 35.33333333333334, 1.0, 2.0, 0.2461609524152308, 1.0, 2.0, 0.2461609524152308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580029.0256224555, 580029.025622456, 168966.8376079697], 
processed observation next is [1.0, 0.782608695652174, 0.8024691358024693, 0.35333333333333344, 1.0, 1.0, 0.1025725623990843, 1.0, 1.0, 0.1025725623990843, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20715322343659126, 0.20715322343659143, 0.3249362261691725], 
reward next is 0.6751, 
noisyNet noise sample is [array([2.2266624], dtype=float32), -0.3963634]. 
=============================================
[2019-03-24 07:46:17,953] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1174909: loss 0.3327
[2019-03-24 07:46:17,955] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1174909: learning rate 0.0000
[2019-03-24 07:46:18,134] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 07:46:18,136] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:46:18,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:18,137] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:46:18,138] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:46:18,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:46:18,139] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:18,140] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:46:18,140] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:18,140] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:18,142] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:18,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-24 07:46:18,161] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-24 07:46:18,192] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-24 07:46:18,193] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-24 07:46:18,306] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-24 07:46:25,313] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:46:25,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.40061478666667, 76.46396589, 1.0, 2.0, 0.3679915617619189, 1.0, 2.0, 0.3679915617619189, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 918527.3337941851, 918527.3337941855, 200461.5029145531]
[2019-03-24 07:46:25,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:46:25,320] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5812052e-06 6.5670556e-06 4.2817742e-06 9.9995899e-01 2.6592010e-05], sampled 0.9056123968905581
[2019-03-24 07:46:25,449] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:46:25,451] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.7, 38.5, 1.0, 2.0, 0.548148745581095, 1.0, 2.0, 0.548148745581095, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1325329.977698648, 1325329.977698649, 253845.1462346071]
[2019-03-24 07:46:25,451] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:46:25,453] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0551497e-06 1.0987247e-05 7.4825330e-06 9.9993253e-01 4.2894731e-05], sampled 0.5501330373281998
[2019-03-24 07:46:29,735] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:46:29,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.81034665, 40.46200014, 1.0, 2.0, 0.1961523248955228, 1.0, 2.0, 0.1961523248955228, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482981.0279943142, 482981.0279943142, 159022.2274815254]
[2019-03-24 07:46:29,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:46:29,740] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5069684e-06 2.9333582e-06 1.8216016e-06 9.9998105e-01 1.2680504e-05], sampled 0.057790131729403726
[2019-03-24 07:47:01,924] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:47:01,925] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 83.83333333333333, 1.0, 2.0, 0.3070420189095077, 1.0, 2.0, 0.3070420189095077, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699837.3852161071, 699837.3852161071, 182159.3046998449]
[2019-03-24 07:47:01,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:47:01,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0761223e-06 2.1209403e-06 1.3228505e-06 9.9998569e-01 9.7751745e-06], sampled 0.9319383714932115
[2019-03-24 07:47:37,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:47:37,765] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.8, 67.0, 1.0, 2.0, 0.2459259451153791, 1.0, 2.0, 0.2459259451153791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585044.8665275387, 585044.8665275392, 169150.9784517979]
[2019-03-24 07:47:37,766] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:47:37,768] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3525624e-06 2.6694704e-06 1.6475109e-06 9.9998295e-01 1.1453630e-05], sampled 0.8889236595164173
[2019-03-24 07:47:44,700] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00981545], dtype=float32), 0.007173076]
[2019-03-24 07:47:44,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.13333333333333, 57.0, 1.0, 2.0, 0.3045293946708508, 1.0, 2.0, 0.3045293946708508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694107.7965591272, 694107.7965591276, 181551.8232061413]
[2019-03-24 07:47:44,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:47:44,705] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6051381e-07 1.6848734e-06 1.1162437e-06 9.9998879e-01 7.5682301e-06], sampled 0.6609664406947837
[2019-03-24 07:48:04,412] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:48:04,473] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:48:04,743] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495498084.6449 47.0000
[2019-03-24 07:48:04,781] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3913 2668473641.4405 68.0000
[2019-03-24 07:48:04,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.7066 2465959250.2302 46.0000
[2019-03-24 07:48:05,842] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1175000, evaluation results [1175000.0, 7522.391347924439, 2668473641.440499, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495498084.6448736, 47.0, 7477.706583698502, 2465959250.2302403, 46.0]
[2019-03-24 07:48:05,968] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1175062: loss 0.3028
[2019-03-24 07:48:05,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1175062: learning rate 0.0000
[2019-03-24 07:48:07,104] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1175618: loss 0.2064
[2019-03-24 07:48:07,110] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1175618: learning rate 0.0000
[2019-03-24 07:48:07,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2346209e-07 7.3460939e-08 7.9545856e-07 9.9999595e-01 2.9956204e-06], sum to 1.0000
[2019-03-24 07:48:07,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6319
[2019-03-24 07:48:07,592] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3058501178386741, 1.0, 2.0, 0.3058501178386741, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697213.2288315509, 697213.2288315514, 181875.0161113854], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4558800.0000, 
sim time next is 4559400.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3052380314269475, 1.0, 2.0, 0.3052380314269475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695828.6758620971, 695828.6758620975, 181727.5332365895], 
processed observation next is [0.0, 0.782608695652174, 0.4444444444444444, 0.94, 1.0, 1.0, 0.1729024183654137, 1.0, 1.0, 0.1729024183654137, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24851024137932037, 0.24851024137932054, 0.3494760254549798], 
reward next is 0.6505, 
noisyNet noise sample is [array([1.616465], dtype=float32), 0.31813654]. 
=============================================
[2019-03-24 07:48:08,656] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176388: loss 0.3114
[2019-03-24 07:48:08,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176388: learning rate 0.0000
[2019-03-24 07:48:08,791] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176453: loss 0.2958
[2019-03-24 07:48:08,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176456: learning rate 0.0000
[2019-03-24 07:48:09,345] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176732: loss 0.3296
[2019-03-24 07:48:09,349] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176733: learning rate 0.0000
[2019-03-24 07:48:09,384] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176754: loss 0.3057
[2019-03-24 07:48:09,387] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176755: learning rate 0.0000
[2019-03-24 07:48:10,085] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1177104: loss 0.3243
[2019-03-24 07:48:10,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1177105: learning rate 0.0000
[2019-03-24 07:48:11,146] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177622: loss 0.7228
[2019-03-24 07:48:11,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177622: learning rate 0.0000
[2019-03-24 07:48:11,390] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177748: loss 0.5092
[2019-03-24 07:48:11,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177750: learning rate 0.0000
[2019-03-24 07:48:11,740] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177922: loss 0.4703
[2019-03-24 07:48:11,743] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177923: learning rate 0.0000
[2019-03-24 07:48:11,950] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178021: loss 0.5881
[2019-03-24 07:48:11,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178021: learning rate 0.0000
[2019-03-24 07:48:12,472] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178277: loss 0.4297
[2019-03-24 07:48:12,474] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178277: learning rate 0.0000
[2019-03-24 07:48:12,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0530120e-06 1.9521062e-06 3.3820321e-05 9.9958915e-01 3.7011137e-04], sum to 1.0000
[2019-03-24 07:48:12,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5557
[2019-03-24 07:48:12,650] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 67.5, 1.0, 2.0, 0.338210982085585, 1.0, 2.0, 0.338210982085585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770916.1730125907, 770916.1730125912, 189883.6291407847], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4458600.0000, 
sim time next is 4459200.0000, 
raw observation next is [29.66666666666667, 68.33333333333333, 1.0, 2.0, 0.3455382761450003, 1.0, 2.0, 0.3455382761450003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787626.5461416054, 787626.5461416054, 191748.4526485352], 
processed observation next is [0.0, 0.6086956521739131, 0.6543209876543211, 0.6833333333333332, 1.0, 1.0, 0.22087890017261944, 1.0, 1.0, 0.22087890017261944, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2812951950505733, 0.2812951950505733, 0.36874702432410617], 
reward next is 0.6313, 
noisyNet noise sample is [array([0.59232205], dtype=float32), -0.41292584]. 
=============================================
[2019-03-24 07:48:12,921] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1178507: loss 0.0485
[2019-03-24 07:48:12,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1178508: learning rate 0.0000
[2019-03-24 07:48:18,294] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1181084: loss 0.0102
[2019-03-24 07:48:18,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1181084: learning rate 0.0000
[2019-03-24 07:48:19,271] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1181594: loss 0.0321
[2019-03-24 07:48:19,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1181594: learning rate 0.0000
[2019-03-24 07:48:19,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0712398e-05 5.2833561e-06 2.0593777e-06 9.9994898e-01 2.3018900e-05], sum to 1.0000
[2019-03-24 07:48:19,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0856
[2019-03-24 07:48:19,360] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 94.0, 1.0, 2.0, 0.2958065419483465, 1.0, 2.0, 0.2958065419483465, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677587.3943299591, 677587.3943299591, 179626.1539755768], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4539000.0000, 
sim time next is 4539600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3004773175959792, 1.0, 2.0, 0.3004773175959792, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685717.9525835878, 685717.9525835878, 180618.0148378171], 
processed observation next is [0.0, 0.5652173913043478, 0.4444444444444444, 0.94, 1.0, 1.0, 0.16723490189997522, 1.0, 1.0, 0.16723490189997522, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2448992687798528, 0.2448992687798528, 0.34734233622657135], 
reward next is 0.6527, 
noisyNet noise sample is [array([-1.4645052], dtype=float32), 0.30555356]. 
=============================================
[2019-03-24 07:48:20,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0216164e-07 7.5088991e-07 4.9204328e-07 9.9992955e-01 6.8778761e-05], sum to 1.0000
[2019-03-24 07:48:20,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9094
[2019-03-24 07:48:20,279] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 95.5, 1.0, 2.0, 0.2888393088797185, 1.0, 2.0, 0.2888393088797185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667570.8440646087, 667570.8440646091, 178258.8203366056], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4509000.0000, 
sim time next is 4509600.0000, 
raw observation next is [23.2, 94.0, 1.0, 2.0, 0.2851540469897751, 1.0, 2.0, 0.2851540469897751, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660971.600547736, 660971.6005477365, 177477.3248477926], 
processed observation next is [0.0, 0.17391304347826086, 0.4148148148148148, 0.94, 1.0, 1.0, 0.1489929130830656, 1.0, 1.0, 0.1489929130830656, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23606128590990574, 0.2360612859099059, 0.34130254778421654], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.26785442], dtype=float32), -1.0032203]. 
=============================================
[2019-03-24 07:48:21,869] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1182938: loss 0.0054
[2019-03-24 07:48:21,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1182939: learning rate 0.0000
[2019-03-24 07:48:22,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9438607e-05 1.3261770e-05 4.5278493e-06 9.9995995e-01 2.8357344e-06], sum to 1.0000
[2019-03-24 07:48:22,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5100
[2019-03-24 07:48:22,081] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.31666666666667, 99.33333333333334, 1.0, 2.0, 0.25072707218126, 1.0, 2.0, 0.25072707218126, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 595537.9283003111, 595537.9283003106, 170195.0538676478], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4578600.0000, 
sim time next is 4579200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2452249089745927, 1.0, 2.0, 0.2452249089745927, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585090.7789500315, 585090.778950032, 169063.1283397494], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.10145822496975322, 1.0, 1.0, 0.10145822496975322, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2089609924821541, 0.20896099248215427, 0.32512140065336426], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.23830082], dtype=float32), 0.9297248]. 
=============================================
[2019-03-24 07:48:22,157] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1183084: loss 0.0133
[2019-03-24 07:48:22,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1183087: learning rate 0.0000
[2019-03-24 07:48:23,276] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1183668: loss 0.0105
[2019-03-24 07:48:23,279] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1183669: learning rate 0.0000
[2019-03-24 07:48:24,691] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184410: loss 0.0160
[2019-03-24 07:48:24,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184410: learning rate 0.0000
[2019-03-24 07:48:24,920] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184531: loss 0.0339
[2019-03-24 07:48:24,925] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184531: learning rate 0.0000
[2019-03-24 07:48:25,240] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184696: loss 0.0278
[2019-03-24 07:48:25,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184696: learning rate 0.0000
[2019-03-24 07:48:25,427] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184789: loss 0.0141
[2019-03-24 07:48:25,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184789: learning rate 0.0000
[2019-03-24 07:48:26,038] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1185108: loss 0.0167
[2019-03-24 07:48:26,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1185108: learning rate 0.0000
[2019-03-24 07:48:27,126] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185678: loss 0.0467
[2019-03-24 07:48:27,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185680: learning rate 0.0000
[2019-03-24 07:48:27,494] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1185866: loss 0.0104
[2019-03-24 07:48:27,497] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1185867: learning rate 0.0000
[2019-03-24 07:48:27,540] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185890: loss 0.0107
[2019-03-24 07:48:27,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185890: learning rate 0.0000
[2019-03-24 07:48:27,726] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185987: loss 0.0085
[2019-03-24 07:48:27,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185987: learning rate 0.0000
[2019-03-24 07:48:28,002] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186124: loss 0.0097
[2019-03-24 07:48:28,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186125: learning rate 0.0000
[2019-03-24 07:48:28,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8484310e-06 2.6020460e-05 2.0411153e-05 9.9903715e-01 9.0962317e-04], sum to 1.0000
[2019-03-24 07:48:28,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6810
[2019-03-24 07:48:28,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.91666666666667, 75.66666666666667, 1.0, 2.0, 0.8652083056674167, 1.0, 2.0, 0.8652083056674167, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1973626.420263577, 1973626.420263577, 371436.9804131464], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4716600.0000, 
sim time next is 4717200.0000, 
raw observation next is [28.53333333333333, 78.33333333333334, 1.0, 2.0, 0.7728320966611355, 1.0, 2.0, 0.7728320966611355, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1762699.142898408, 1762699.142898408, 332656.8754104113], 
processed observation next is [1.0, 0.6086956521739131, 0.6123456790123456, 0.7833333333333334, 1.0, 1.0, 0.7295620198346852, 1.0, 1.0, 0.7295620198346852, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6295354081780029, 0.6295354081780029, 0.6397247604046371], 
reward next is 0.3603, 
noisyNet noise sample is [array([-1.6553677], dtype=float32), 1.76976]. 
=============================================
[2019-03-24 07:48:28,769] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1186526: loss 1.9215
[2019-03-24 07:48:28,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1186527: learning rate 0.0000
[2019-03-24 07:48:33,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1189000: loss 1.8080
[2019-03-24 07:48:33,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1189000: learning rate 0.0000
[2019-03-24 07:48:34,838] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1189699: loss 1.5446
[2019-03-24 07:48:34,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1189699: learning rate 0.0000
[2019-03-24 07:48:37,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1190875: loss 2.9353
[2019-03-24 07:48:37,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1190875: learning rate 0.0000
[2019-03-24 07:48:37,394] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1191037: loss 2.2400
[2019-03-24 07:48:37,399] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1191037: learning rate 0.0000
[2019-03-24 07:48:38,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6399352e-05 9.3619667e-07 4.4593176e-06 9.9988258e-01 9.5641750e-05], sum to 1.0000
[2019-03-24 07:48:38,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4089
[2019-03-24 07:48:38,358] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 91.0, 1.0, 2.0, 0.7103594153894139, 1.0, 2.0, 0.7103594153894139, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1620080.332145074, 1620080.332145074, 308105.3548766685], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4972800.0000, 
sim time next is 4973400.0000, 
raw observation next is [25.1, 92.0, 1.0, 2.0, 0.7312959810328427, 1.0, 2.0, 0.7312959810328427, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1667873.856699749, 1667873.856699749, 316182.1566665737], 
processed observation next is [1.0, 0.5652173913043478, 0.4851851851851852, 0.92, 1.0, 1.0, 0.6801142631343365, 1.0, 1.0, 0.6801142631343365, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5956692345356246, 0.5956692345356246, 0.6080426089741803], 
reward next is 0.3920, 
noisyNet noise sample is [array([0.6160068], dtype=float32), 1.2541814]. 
=============================================
[2019-03-24 07:48:38,863] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1191786: loss 2.8539
[2019-03-24 07:48:38,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1191787: learning rate 0.0000
[2019-03-24 07:48:40,066] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192416: loss 3.6840
[2019-03-24 07:48:40,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192417: learning rate 0.0000
[2019-03-24 07:48:40,215] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192494: loss 3.4244
[2019-03-24 07:48:40,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192494: learning rate 0.0000
[2019-03-24 07:48:40,452] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192619: loss 3.2606
[2019-03-24 07:48:40,455] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192619: learning rate 0.0000
[2019-03-24 07:48:40,467] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192621: loss 3.2305
[2019-03-24 07:48:40,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192623: learning rate 0.0000
[2019-03-24 07:48:41,304] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1193064: loss 3.9577
[2019-03-24 07:48:41,306] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1193064: learning rate 0.0000
[2019-03-24 07:48:42,599] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193738: loss 4.4425
[2019-03-24 07:48:42,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193738: learning rate 0.0000
[2019-03-24 07:48:43,010] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193951: loss 4.2248
[2019-03-24 07:48:43,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193953: learning rate 0.0000
[2019-03-24 07:48:43,019] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1193957: loss 4.3856
[2019-03-24 07:48:43,020] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1193957: learning rate 0.0000
[2019-03-24 07:48:43,163] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194032: loss 4.5251
[2019-03-24 07:48:43,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194032: learning rate 0.0000
[2019-03-24 07:48:43,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194250: loss 4.8195
[2019-03-24 07:48:43,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194251: learning rate 0.0000
[2019-03-24 07:48:43,585] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1194253: loss 0.0957
[2019-03-24 07:48:43,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1194253: learning rate 0.0000
[2019-03-24 07:48:48,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1196898: loss 0.0213
[2019-03-24 07:48:48,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1196898: learning rate 0.0000
[2019-03-24 07:48:49,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1494898e-05 1.1176590e-05 6.0407942e-06 9.9989736e-01 7.3947216e-05], sum to 1.0000
[2019-03-24 07:48:49,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8602
[2019-03-24 07:48:49,780] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.3006251768640724, 1.0, 2.0, 0.3006251768640724, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688110.7512944147, 688110.7512944147, 180755.9686453624], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5376000.0000, 
sim time next is 5376600.0000, 
raw observation next is [24.25, 91.0, 1.0, 2.0, 0.3000194564182052, 1.0, 2.0, 0.3000194564182052, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686250.1481521316, 686250.148152132, 180586.8384520988], 
processed observation next is [1.0, 0.21739130434782608, 0.4537037037037037, 0.91, 1.0, 1.0, 0.16668982906929192, 1.0, 1.0, 0.16668982906929192, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2450893386257613, 0.24508933862576146, 0.34728238163865155], 
reward next is 0.6527, 
noisyNet noise sample is [array([-1.0371311], dtype=float32), -0.85733205]. 
=============================================
[2019-03-24 07:48:50,276] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1197731: loss 0.0344
[2019-03-24 07:48:50,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1197732: learning rate 0.0000
[2019-03-24 07:48:50,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6090246e-07 8.1154511e-08 8.1707121e-08 9.9999142e-01 8.2512734e-06], sum to 1.0000
[2019-03-24 07:48:50,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3048
[2019-03-24 07:48:50,639] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 70.66666666666667, 1.0, 2.0, 0.4094707982695763, 1.0, 2.0, 0.4094707982695763, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 933444.3020307726, 933444.302030773, 208808.5947088135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5152800.0000, 
sim time next is 5153400.0000, 
raw observation next is [31.5, 70.5, 1.0, 2.0, 0.4200503183825084, 1.0, 2.0, 0.4200503183825084, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957576.8231761511, 957576.8231761511, 211767.7279433137], 
processed observation next is [0.0, 0.6521739130434783, 0.7222222222222222, 0.705, 1.0, 1.0, 0.309583712360129, 1.0, 1.0, 0.309583712360129, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3419917225629111, 0.3419917225629111, 0.4072456306602186], 
reward next is 0.5928, 
noisyNet noise sample is [array([0.90791756], dtype=float32), 0.6662548]. 
=============================================
[2019-03-24 07:48:52,304] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1198783: loss 0.0956
[2019-03-24 07:48:52,307] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1198784: learning rate 0.0000
[2019-03-24 07:48:52,864] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1199077: loss 0.0326
[2019-03-24 07:48:52,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1199077: learning rate 0.0000
[2019-03-24 07:48:54,270] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1199815: loss 0.0468
[2019-03-24 07:48:54,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1199815: learning rate 0.0000
[2019-03-24 07:48:54,628] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 07:48:54,630] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:48:54,630] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:48:54,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:48:54,631] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:48:54,632] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:48:54,631] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:48:54,633] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:48:54,636] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:48:54,633] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:48:54,637] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:48:54,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-24 07:48:54,684] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-24 07:48:54,713] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-24 07:48:54,742] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-24 07:48:54,772] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-24 07:49:10,376] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:49:10,379] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.00290963, 56.16928885333333, 1.0, 2.0, 0.2492244316455221, 1.0, 2.0, 0.2492244316455221, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621010.2098037686, 621010.209803769, 170797.0209365099]
[2019-03-24 07:49:10,380] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:49:10,381] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0376682e-06 3.7980701e-06 3.0096282e-06 9.9997962e-01 1.0507931e-05], sampled 0.8746755330703909
[2019-03-24 07:49:36,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:49:36,512] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 58.0, 1.0, 2.0, 0.2557320712357746, 1.0, 2.0, 0.2557320712357746, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 602785.415473458, 602785.4154734585, 171135.2609700691]
[2019-03-24 07:49:36,513] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:49:36,518] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5502469e-06 1.9550141e-06 1.5143686e-06 9.9998927e-01 5.6891304e-06], sampled 0.4122828991484382
[2019-03-24 07:49:43,538] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:49:43,539] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.16666666666667, 95.0, 1.0, 2.0, 0.4156350854682401, 1.0, 2.0, 0.4156350854682401, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 947505.3191706669, 947505.3191706673, 210525.6016106269]
[2019-03-24 07:49:43,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:49:43,543] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.5656864e-06 3.2247735e-06 2.5506411e-06 9.9998260e-01 9.0268240e-06], sampled 0.6510357447394809
[2019-03-24 07:49:45,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:49:45,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.35032950166666, 59.77902672333333, 1.0, 2.0, 0.3903899772805147, 1.0, 2.0, 0.3903899772805147, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 889921.7238851052, 889921.7238851057, 203568.8660018534]
[2019-03-24 07:49:45,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:49:45,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3187987e-06 1.6829706e-06 1.2829864e-06 9.9999082e-01 4.8698835e-06], sampled 0.9280925732632307
[2019-03-24 07:49:54,035] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:49:54,036] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.13333333333334, 79.33333333333334, 1.0, 2.0, 0.2667803799814777, 1.0, 2.0, 0.2667803799814777, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620844.689277963, 620844.6892779635, 173311.0426248617]
[2019-03-24 07:49:54,037] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:49:54,042] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3301591e-06 1.7294328e-06 1.2963160e-06 9.9999082e-01 4.7890726e-06], sampled 0.2129554616871896
[2019-03-24 07:50:01,777] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:50:01,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.15683956, 95.41162731, 1.0, 2.0, 0.2610802399564118, 1.0, 2.0, 0.2610802399564118, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614824.1503064745, 614824.1503064749, 172331.4497881992]
[2019-03-24 07:50:01,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:50:01,787] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2710216e-06 1.6429979e-06 1.2337234e-06 9.9999118e-01 4.6534669e-06], sampled 0.3802314495380178
[2019-03-24 07:50:07,318] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:50:07,319] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.4, 84.0, 1.0, 2.0, 0.9348882460166484, 1.0, 2.0, 0.9348882460166484, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9259356886369, 2132763.127641858, 2132763.127641857, 402647.1491287069]
[2019-03-24 07:50:07,320] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:50:07,322] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4531921e-05 2.8807724e-05 2.5330979e-05 9.9984968e-01 7.1603368e-05], sampled 0.7659303367701035
[2019-03-24 07:50:16,202] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:50:16,204] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.65775329, 75.80920112333334, 1.0, 2.0, 0.3271904737637833, 1.0, 2.0, 0.3271904737637833, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745783.8692893467, 745783.8692893472, 187114.02502929]
[2019-03-24 07:50:16,206] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:50:16,208] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6673110e-06 2.1551130e-06 1.6283648e-06 9.9998856e-01 5.9041331e-06], sampled 0.3627031041487201
[2019-03-24 07:50:16,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:50:16,711] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.21666666666667, 67.83333333333333, 1.0, 2.0, 0.6487943442785037, 1.0, 2.0, 0.6487943442785037, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1480003.833754446, 1480003.833754446, 285257.0699899112]
[2019-03-24 07:50:16,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:50:16,716] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.10269011e-05 1.32242585e-05 1.12287953e-05 9.99931216e-01
 3.32097843e-05], sampled 0.08309654854069926
[2019-03-24 07:50:29,838] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00986196], dtype=float32), 0.0071915737]
[2019-03-24 07:50:29,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.8, 73.0, 1.0, 2.0, 0.5792156037021553, 1.0, 2.0, 0.5792156037021553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1320734.170197035, 1320734.170197035, 260969.6530660605]
[2019-03-24 07:50:29,841] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:50:29,843] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.94897097e-06 4.92657819e-06 3.94267954e-06 9.99974489e-01
 1.27861285e-05], sampled 0.011196448047011587
[2019-03-24 07:50:41,024] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.5930 2668600874.5696 68.0000
[2019-03-24 07:50:41,039] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2606 2438847622.0174 34.0000
[2019-03-24 07:50:41,051] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454110.0746 47.0000
[2019-03-24 07:50:41,060] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:50:41,285] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 07:50:42,301] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1200000, evaluation results [1200000.0, 7521.592988438613, 2668600874.5696144, 68.0, 7122.260633411203, 2438847622.017374, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495454110.074621, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 07:50:42,967] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200328: loss 0.0740
[2019-03-24 07:50:42,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200330: learning rate 0.0000
[2019-03-24 07:50:43,287] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200488: loss 0.0770
[2019-03-24 07:50:43,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200489: learning rate 0.0000
[2019-03-24 07:50:43,645] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200673: loss 0.0531
[2019-03-24 07:50:43,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200673: learning rate 0.0000
[2019-03-24 07:50:43,781] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200740: loss 0.0780
[2019-03-24 07:50:43,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200740: learning rate 0.0000
[2019-03-24 07:50:44,427] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1201064: loss 0.0519
[2019-03-24 07:50:44,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1201066: learning rate 0.0000
[2019-03-24 07:50:45,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7395963e-06 1.4399648e-04 3.1923122e-05 9.9977738e-01 4.5024572e-05], sum to 1.0000
[2019-03-24 07:50:45,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3653
[2019-03-24 07:50:45,912] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333333, 85.33333333333333, 1.0, 2.0, 0.3708641362927764, 1.0, 2.0, 0.3708641362927764, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845386.631788012, 845386.631788012, 198336.8084607064], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5254800.0000, 
sim time next is 5255400.0000, 
raw observation next is [27.31666666666667, 85.66666666666667, 1.0, 2.0, 0.364773121825026, 1.0, 2.0, 0.364773121825026, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831494.6027075688, 831494.6027075688, 196732.0385823118], 
processed observation next is [1.0, 0.8260869565217391, 0.5672839506172841, 0.8566666666666667, 1.0, 1.0, 0.24377752598217384, 1.0, 1.0, 0.24377752598217384, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.296962358109846, 0.296962358109846, 0.3783308434275227], 
reward next is 0.6217, 
noisyNet noise sample is [array([-0.11932336], dtype=float32), 0.93008155]. 
=============================================
[2019-03-24 07:50:45,966] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201828: loss 0.1442
[2019-03-24 07:50:45,968] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201828: learning rate 0.0000
[2019-03-24 07:50:46,018] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201847: loss 0.1481
[2019-03-24 07:50:46,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201847: learning rate 0.0000
[2019-03-24 07:50:46,172] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201923: loss 0.1394
[2019-03-24 07:50:46,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201923: learning rate 0.0000
[2019-03-24 07:50:46,615] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202143: loss 0.0822
[2019-03-24 07:50:46,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202145: learning rate 0.0000
[2019-03-24 07:50:46,649] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202161: loss 0.0653
[2019-03-24 07:50:46,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202161: learning rate 0.0000
[2019-03-24 07:50:46,996] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1202329: loss 0.0544
[2019-03-24 07:50:46,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1202330: learning rate 0.0000
[2019-03-24 07:50:52,235] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1204921: loss 0.0890
[2019-03-24 07:50:52,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1204921: learning rate 0.0000
[2019-03-24 07:50:53,911] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1205749: loss 0.0799
[2019-03-24 07:50:53,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1205749: learning rate 0.0000
[2019-03-24 07:50:56,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8527836e-05 7.3965231e-05 2.4749213e-04 9.9952304e-01 1.1705706e-04], sum to 1.0000
[2019-03-24 07:50:56,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7053
[2019-03-24 07:50:56,070] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.3648914392559721, 1.0, 2.0, 0.3648914392559721, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831764.4517768071, 831764.4517768071, 196762.2422466041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5542800.0000, 
sim time next is 5543400.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.3626201345815314, 1.0, 2.0, 0.3626201345815314, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 826584.255721865, 826584.255721865, 196167.0519974957], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.24121444593039454, 1.0, 1.0, 0.24121444593039454, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29520866275780894, 0.29520866275780894, 0.3772443307644148], 
reward next is 0.6228, 
noisyNet noise sample is [array([-0.61799616], dtype=float32), -0.20501196]. 
=============================================
[2019-03-24 07:50:56,079] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1206792: loss 0.0884
[2019-03-24 07:50:56,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1206792: learning rate 0.0000
[2019-03-24 07:50:56,730] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1207127: loss 0.0855
[2019-03-24 07:50:56,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1207128: learning rate 0.0000
[2019-03-24 07:50:58,101] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1207841: loss 0.0716
[2019-03-24 07:50:58,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1207842: learning rate 0.0000
[2019-03-24 07:50:59,098] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208364: loss 0.0747
[2019-03-24 07:50:59,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208364: learning rate 0.0000
[2019-03-24 07:50:59,322] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208476: loss 0.0709
[2019-03-24 07:50:59,323] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208476: learning rate 0.0000
[2019-03-24 07:50:59,621] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208635: loss 0.0691
[2019-03-24 07:50:59,624] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208636: learning rate 0.0000
[2019-03-24 07:50:59,816] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208734: loss 0.0813
[2019-03-24 07:50:59,818] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208735: learning rate 0.0000
[2019-03-24 07:51:00,341] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1209007: loss 0.0716
[2019-03-24 07:51:00,343] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1209008: learning rate 0.0000
[2019-03-24 07:51:01,864] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209795: loss 0.0727
[2019-03-24 07:51:01,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209795: learning rate 0.0000
[2019-03-24 07:51:01,977] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209851: loss 0.0890
[2019-03-24 07:51:01,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209851: learning rate 0.0000
[2019-03-24 07:51:02,110] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209920: loss 0.0739
[2019-03-24 07:51:02,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209921: learning rate 0.0000
[2019-03-24 07:51:02,578] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210166: loss 0.0715
[2019-03-24 07:51:02,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210166: learning rate 0.0000
[2019-03-24 07:51:02,662] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210207: loss 0.0747
[2019-03-24 07:51:02,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210207: learning rate 0.0000
[2019-03-24 07:51:02,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1363604e-05 2.9525970e-04 2.0209914e-06 9.9884653e-01 8.4484444e-04], sum to 1.0000
[2019-03-24 07:51:02,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4888
[2019-03-24 07:51:02,719] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.56666666666667, 66.33333333333334, 1.0, 2.0, 0.354064346641723, 1.0, 2.0, 0.354064346641723, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807071.2659015554, 807071.2659015554, 193941.9461392535], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5674800.0000, 
sim time next is 5675400.0000, 
raw observation next is [30.65, 66.0, 1.0, 2.0, 0.3594461443086003, 1.0, 2.0, 0.3594461443086003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3507572464, 819345.3507572464, 195339.1920975982], 
processed observation next is [0.0, 0.6956521739130435, 0.6907407407407407, 0.66, 1.0, 1.0, 0.237435886081667, 1.0, 1.0, 0.237435886081667, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29262333955615943, 0.29262333955615943, 0.3756522924953811], 
reward next is 0.6243, 
noisyNet noise sample is [array([-1.24878], dtype=float32), 1.1020241]. 
=============================================
[2019-03-24 07:51:02,803] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1210279: loss 1.1408
[2019-03-24 07:51:02,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1210279: learning rate 0.0000
[2019-03-24 07:51:04,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5665841e-05 3.4437612e-06 1.0377948e-05 9.9332738e-01 6.6431887e-03], sum to 1.0000
[2019-03-24 07:51:04,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8886
[2019-03-24 07:51:04,491] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.2971369542302772, 1.0, 2.0, 0.2971369542302772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679366.6065600972, 679366.6065600977, 179881.3220794702], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5634000.0000, 
sim time next is 5634600.0000, 
raw observation next is [23.56666666666667, 96.83333333333334, 1.0, 2.0, 0.2985562186360441, 1.0, 2.0, 0.2985562186360441, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682046.2381021536, 682046.2381021541, 180192.9430664705], 
processed observation next is [0.0, 0.21739130434782608, 0.4283950617283952, 0.9683333333333334, 1.0, 1.0, 0.16494787932862393, 1.0, 1.0, 0.16494787932862393, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2435879421793406, 0.24358794217934077, 0.3465248905124433], 
reward next is 0.6535, 
noisyNet noise sample is [array([0.8833803], dtype=float32), 0.9593516]. 
=============================================
[2019-03-24 07:51:07,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4216984e-07 6.2523029e-08 4.1047265e-08 9.9998808e-01 1.1557677e-05], sum to 1.0000
[2019-03-24 07:51:07,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2264
[2019-03-24 07:51:07,354] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 67.0, 1.0, 2.0, 0.3042230769434114, 1.0, 2.0, 0.3042230769434114, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 693409.2968825321, 693409.2968825325, 181477.2154149665], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5763600.0000, 
sim time next is 5764200.0000, 
raw observation next is [28.13333333333334, 67.5, 1.0, 2.0, 0.303849223952719, 1.0, 2.0, 0.303849223952719, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692556.7966661617, 692556.7966661622, 181386.9355959177], 
processed observation next is [0.0, 0.7391304347826086, 0.5975308641975311, 0.675, 1.0, 1.0, 0.1712490761341893, 1.0, 1.0, 0.1712490761341893, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24734171309505776, 0.24734171309505792, 0.3488210299921494], 
reward next is 0.6512, 
noisyNet noise sample is [array([-0.481281], dtype=float32), 1.8625958]. 
=============================================
[2019-03-24 07:51:07,884] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1212889: loss 0.6014
[2019-03-24 07:51:07,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1212891: learning rate 0.0000
[2019-03-24 07:51:09,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6110106e-06 2.5537252e-06 1.0983596e-07 9.9992073e-01 7.5044663e-05], sum to 1.0000
[2019-03-24 07:51:09,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4986
[2019-03-24 07:51:09,168] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.58333333333333, 82.0, 1.0, 2.0, 0.2235968579954677, 1.0, 2.0, 0.2235968579954677, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540644.6661157013, 540644.6661157018, 164567.6981792405], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5734200.0000, 
sim time next is 5734800.0000, 
raw observation next is [22.8, 81.0, 1.0, 2.0, 0.2270927555526731, 1.0, 2.0, 0.2270927555526731, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548334.2882927607, 548334.2882927607, 165303.2352150193], 
processed observation next is [0.0, 0.391304347826087, 0.4, 0.81, 1.0, 1.0, 0.07987232803889656, 1.0, 1.0, 0.07987232803889656, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1958336743902717, 0.1958336743902717, 0.3178908369519602], 
reward next is 0.6821, 
noisyNet noise sample is [array([0.1845136], dtype=float32), -0.856391]. 
=============================================
[2019-03-24 07:51:09,581] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1213769: loss 0.4704
[2019-03-24 07:51:09,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1213770: learning rate 0.0000
[2019-03-24 07:51:11,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3446978e-04 4.3174939e-04 8.6518688e-05 9.9809462e-01 1.2526900e-03], sum to 1.0000
[2019-03-24 07:51:11,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9893
[2019-03-24 07:51:11,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.4, 93.0, 1.0, 2.0, 0.2344860546456536, 1.0, 2.0, 0.2344860546456536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 564253.9347890046, 564253.9347890051, 166859.7282397398], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5804400.0000, 
sim time next is 5805000.0000, 
raw observation next is [21.35, 93.5, 1.0, 2.0, 0.2309912573550228, 1.0, 2.0, 0.2309912573550228, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 555942.4647455821, 555942.4647455825, 166092.1857932279], 
processed observation next is [1.0, 0.17391304347826086, 0.3462962962962963, 0.935, 1.0, 1.0, 0.08451340161312237, 1.0, 1.0, 0.08451340161312237, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19855088026627932, 0.19855088026627948, 0.31940804960236135], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.50501806], dtype=float32), 0.41567695]. 
=============================================
[2019-03-24 07:51:11,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.284443]
 [58.166843]
 [58.60349 ]
 [58.580276]
 [58.58636 ]], R is [[58.39011765]
 [58.48533249]
 [58.57205582]
 [58.66621017]
 [58.7596283 ]].
[2019-03-24 07:51:11,522] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1214769: loss 0.5182
[2019-03-24 07:51:11,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1214771: learning rate 0.0000
[2019-03-24 07:51:12,134] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1215090: loss 0.2521
[2019-03-24 07:51:12,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1215090: learning rate 0.0000
[2019-03-24 07:51:12,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2165711e-06 1.1252631e-05 6.4886867e-06 9.9992025e-01 5.9881768e-05], sum to 1.0000
[2019-03-24 07:51:12,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2606
[2019-03-24 07:51:12,701] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.73333333333333, 70.0, 1.0, 2.0, 0.2112795646724403, 1.0, 2.0, 0.2112795646724403, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515299.8323312066, 515299.8323312071, 162069.36447719], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [23.55, 71.0, 1.0, 2.0, 0.2108399278276796, 1.0, 2.0, 0.2108399278276796, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514446.9521744301, 514446.9521744305, 161982.7193364648], 
processed observation next is [1.0, 0.9130434782608695, 0.4277777777777778, 0.71, 1.0, 1.0, 0.06052372360438048, 1.0, 1.0, 0.06052372360438048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18373105434801074, 0.18373105434801087, 0.31150522949320153], 
reward next is 0.6885, 
noisyNet noise sample is [array([-0.5977709], dtype=float32), 0.70818865]. 
=============================================
[2019-03-24 07:51:13,781] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1215950: loss 0.1247
[2019-03-24 07:51:13,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1215950: learning rate 0.0000
[2019-03-24 07:51:14,652] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216406: loss 0.0652
[2019-03-24 07:51:14,654] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216406: learning rate 0.0000
[2019-03-24 07:51:15,053] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216611: loss 0.0241
[2019-03-24 07:51:15,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216612: learning rate 0.0000
[2019-03-24 07:51:15,143] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216657: loss 0.0290
[2019-03-24 07:51:15,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216658: learning rate 0.0000
[2019-03-24 07:51:15,405] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216796: loss 0.0191
[2019-03-24 07:51:15,411] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216797: learning rate 0.0000
[2019-03-24 07:51:15,621] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216906: loss 0.0151
[2019-03-24 07:51:15,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216906: learning rate 0.0000
[2019-03-24 07:51:17,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1217742: loss 0.0163
[2019-03-24 07:51:17,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1217743: learning rate 0.0000
[2019-03-24 07:51:17,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217857: loss 0.0308
[2019-03-24 07:51:17,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217858: learning rate 0.0000
[2019-03-24 07:51:17,754] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1218013: loss 0.0428
[2019-03-24 07:51:17,758] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1218013: learning rate 0.0000
[2019-03-24 07:51:17,822] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218046: loss 0.0443
[2019-03-24 07:51:17,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218047: learning rate 0.0000
[2019-03-24 07:51:17,871] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218077: loss 0.0873
[2019-03-24 07:51:17,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218077: learning rate 0.0000
[2019-03-24 07:51:18,205] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1218251: loss 0.0570
[2019-03-24 07:51:18,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1218252: learning rate 0.0000
[2019-03-24 07:51:19,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5325076e-05 3.2214757e-06 1.1971351e-06 9.9995887e-01 1.4112695e-06], sum to 1.0000
[2019-03-24 07:51:19,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7401
[2019-03-24 07:51:19,192] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.43333333333333, 79.33333333333334, 1.0, 2.0, 0.2593711157719226, 1.0, 2.0, 0.2593711157719226, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610664.5473227823, 610664.5473227823, 171934.5307800341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6045600.0000, 
sim time next is 6046200.0000, 
raw observation next is [24.3, 80.0, 1.0, 2.0, 0.2588086965302965, 1.0, 2.0, 0.2588086965302965, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609750.712859758, 609750.712859758, 171823.9145835238], 
processed observation next is [1.0, 1.0, 0.4555555555555556, 0.8, 1.0, 1.0, 0.11762940063130534, 1.0, 1.0, 0.11762940063130534, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21776811173562785, 0.21776811173562785, 0.330430604968315], 
reward next is 0.6696, 
noisyNet noise sample is [array([-1.2695272], dtype=float32), 0.64697874]. 
=============================================
[2019-03-24 07:51:21,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5296479e-03 1.3629116e-05 5.2953555e-06 9.9300957e-01 5.4418319e-03], sum to 1.0000
[2019-03-24 07:51:21,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0282
[2019-03-24 07:51:21,083] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.73333333333333, 61.66666666666667, 1.0, 2.0, 0.263923510296337, 1.0, 2.0, 0.263923510296337, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616481.9504262084, 616481.9504262089, 172760.2385117674], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6028800.0000, 
sim time next is 6029400.0000, 
raw observation next is [27.61666666666667, 62.33333333333333, 1.0, 2.0, 0.2645240532514774, 1.0, 2.0, 0.2645240532514774, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618437.1895338099, 618437.1895338104, 172923.2955813412], 
processed observation next is [1.0, 0.782608695652174, 0.5783950617283952, 0.6233333333333333, 1.0, 1.0, 0.12443339672794926, 1.0, 1.0, 0.12443339672794926, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22087042483350353, 0.2208704248335037, 0.33254479919488694], 
reward next is 0.6675, 
noisyNet noise sample is [array([-0.8261894], dtype=float32), 0.81688595]. 
=============================================
[2019-03-24 07:51:23,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3540908e-07 6.9454160e-07 2.6886548e-06 9.9993312e-01 6.2588711e-05], sum to 1.0000
[2019-03-24 07:51:23,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4575
[2019-03-24 07:51:23,082] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 69.5, 1.0, 2.0, 0.2681356703597977, 1.0, 2.0, 0.2681356703597977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626787.68662295, 626787.68662295, 173751.2214179221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [26.23333333333333, 70.0, 1.0, 2.0, 0.267668324258318, 1.0, 2.0, 0.267668324258318, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626073.4126661815, 626073.4126661819, 173660.3816687487], 
processed observation next is [1.0, 0.8695652173913043, 0.5271604938271603, 0.7, 1.0, 1.0, 0.1281765764979976, 1.0, 1.0, 0.1281765764979976, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22359764738077909, 0.22359764738077925, 0.3339622724399014], 
reward next is 0.6660, 
noisyNet noise sample is [array([-0.8080828], dtype=float32), 1.7960848]. 
=============================================
[2019-03-24 07:51:23,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.83868 ]
 [65.97348 ]
 [66.09455 ]
 [66.27505 ]
 [66.202065]], R is [[65.7522049 ]
 [65.76054382]
 [65.76868439]
 [65.7766571 ]
 [65.78453064]].
[2019-03-24 07:51:23,192] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1220842: loss 0.0135
[2019-03-24 07:51:23,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1220843: learning rate 0.0000
[2019-03-24 07:51:24,747] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1221650: loss 0.0217
[2019-03-24 07:51:24,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1221650: learning rate 0.0000
[2019-03-24 07:51:26,955] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1222807: loss 0.0162
[2019-03-24 07:51:26,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1222807: learning rate 0.0000
[2019-03-24 07:51:27,402] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0469488e-05 3.7039533e-06 8.6226532e-07 9.9992216e-01 6.2829575e-05], sum to 1.0000
[2019-03-24 07:51:27,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5344
[2019-03-24 07:51:27,417] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 52.33333333333333, 1.0, 2.0, 0.8791546462896319, 1.0, 2.0, 0.8791546462896319, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 2005475.134777303, 2005475.134777304, 377546.4468223053], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6100800.0000, 
sim time next is 6101400.0000, 
raw observation next is [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.8793549688147437, 1.0, 2.0, 0.8793549688147437, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 2005932.611794998, 2005932.611794997, 377634.7505327138], 
processed observation next is [1.0, 0.6086956521739131, 0.6827160493827159, 0.5266666666666667, 1.0, 1.0, 0.856374962874695, 1.0, 1.0, 0.856374962874695, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.7164045042124992, 0.7164045042124989, 0.7262206741013727], 
reward next is 0.2738, 
noisyNet noise sample is [array([1.7791351], dtype=float32), 0.10344934]. 
=============================================
[2019-03-24 07:51:27,547] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1223112: loss 0.0365
[2019-03-24 07:51:27,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1223112: learning rate 0.0000
[2019-03-24 07:51:27,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7169393e-05 4.1779676e-06 5.7891411e-05 9.9979526e-01 8.5598032e-05], sum to 1.0000
[2019-03-24 07:51:27,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4790
[2019-03-24 07:51:27,664] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 65.0, 1.0, 2.0, 0.7840591579100845, 1.0, 2.0, 0.7840591579100845, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1788331.801683654, 1788331.801683654, 337210.046812196], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6087600.0000, 
sim time next is 6088200.0000, 
raw observation next is [28.23333333333333, 64.16666666666667, 1.0, 2.0, 0.7566168655087355, 1.0, 2.0, 0.7566168655087355, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1725679.222717207, 1725679.222717207, 326152.5162155685], 
processed observation next is [1.0, 0.4782608695652174, 0.6012345679012344, 0.6416666666666667, 1.0, 1.0, 0.7102581732246851, 1.0, 1.0, 0.7102581732246851, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6163140081132882, 0.6163140081132882, 0.6272163773376318], 
reward next is 0.3728, 
noisyNet noise sample is [array([-0.64816576], dtype=float32), 0.042952612]. 
=============================================
[2019-03-24 07:51:28,113] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.18820815e-07 2.25566714e-06 5.12870884e-06 9.99989390e-01
 3.05259277e-06], sum to 1.0000
[2019-03-24 07:51:28,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-24 07:51:28,127] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.76666666666667, 73.83333333333334, 1.0, 2.0, 0.2709455054453174, 1.0, 2.0, 0.2709455054453174, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631937.0368069194, 631937.0368069198, 174337.2561857837], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [25.63333333333334, 74.66666666666667, 1.0, 2.0, 0.2708116207426811, 1.0, 2.0, 0.2708116207426811, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631659.3949750967, 631659.3949750972, 174307.8062158496], 
processed observation next is [1.0, 1.0, 0.5049382716049385, 0.7466666666666667, 1.0, 1.0, 0.1319185961222394, 1.0, 1.0, 0.1319185961222394, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22559264106253454, 0.2255926410625347, 0.3352073196458646], 
reward next is 0.6648, 
noisyNet noise sample is [array([0.3797021], dtype=float32), 1.457517]. 
=============================================
[2019-03-24 07:51:28,141] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.24905 ]
 [68.21903 ]
 [68.16264 ]
 [68.189316]
 [68.20775 ]], R is [[68.2110672 ]
 [68.19368744]
 [68.17635345]
 [68.15895081]
 [68.14151764]].
[2019-03-24 07:51:29,320] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224041: loss 0.0319
[2019-03-24 07:51:29,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224041: learning rate 0.0000
[2019-03-24 07:51:30,073] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224437: loss 0.0127
[2019-03-24 07:51:30,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224437: learning rate 0.0000
[2019-03-24 07:51:30,163] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224485: loss 0.0126
[2019-03-24 07:51:30,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224485: learning rate 0.0000
[2019-03-24 07:51:30,249] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224525: loss 0.0152
[2019-03-24 07:51:30,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224525: learning rate 0.0000
[2019-03-24 07:51:31,057] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224950: loss 0.0192
[2019-03-24 07:51:31,059] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224950: learning rate 0.0000
[2019-03-24 07:51:31,150] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 07:51:31,151] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:51:31,154] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:51:31,155] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:31,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:31,158] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:51:31,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:51:31,157] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1225000: loss 0.0229
[2019-03-24 07:51:31,160] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:51:31,159] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:31,161] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:31,163] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:31,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1225000: learning rate 0.0000
[2019-03-24 07:51:31,186] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-24 07:51:31,217] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-24 07:51:31,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-24 07:51:31,281] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-24 07:51:31,282] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-24 07:51:53,506] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00996232], dtype=float32), 0.007330863]
[2019-03-24 07:51:53,507] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.22870238666667, 61.85729300166667, 1.0, 2.0, 0.2335039884538959, 1.0, 2.0, 0.2335039884538959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 564446.4847566291, 564446.4847566296, 166736.6594231865]
[2019-03-24 07:51:53,508] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:51:53,511] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6029270e-06 4.7841518e-06 2.7851447e-06 9.9995172e-01 3.8181144e-05], sampled 0.14582472046110895
[2019-03-24 07:52:47,801] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00996232], dtype=float32), 0.007330863]
[2019-03-24 07:52:47,805] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.15, 84.0, 1.0, 2.0, 0.2182650589444149, 1.0, 2.0, 0.2182650589444149, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529204.6763012668, 529204.6763012672, 163464.2357529307]
[2019-03-24 07:52:47,806] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:52:47,808] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3833256e-06 4.3707410e-06 2.5593258e-06 9.9995434e-01 3.6322544e-05], sampled 0.38170887469895187
[2019-03-24 07:52:50,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00996232], dtype=float32), 0.007330863]
[2019-03-24 07:52:50,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.62909267, 85.83419175, 1.0, 2.0, 0.2723273364348449, 1.0, 2.0, 0.2723273364348449, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643299.2292638903, 643299.2292638903, 175015.6700974165]
[2019-03-24 07:52:50,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:52:50,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.9211430e-06 8.7853196e-06 5.3345243e-06 9.9991500e-01 6.5875254e-05], sampled 0.9387034428788235
[2019-03-24 07:53:06,940] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00996232], dtype=float32), 0.007330863]
[2019-03-24 07:53:06,942] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 65.0, 1.0, 2.0, 0.2389329439130924, 1.0, 2.0, 0.2389329439130924, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590268.7102833192, 590268.7102833197, 168341.5201945409]
[2019-03-24 07:53:06,945] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:53:06,948] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.303520e-06 9.347900e-06 5.739572e-06 9.999130e-01 6.666041e-05], sampled 0.10304218048134106
[2019-03-24 07:53:11,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00996232], dtype=float32), 0.007330863]
[2019-03-24 07:53:11,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.16666666666666, 75.0, 1.0, 2.0, 0.2542346263311371, 1.0, 2.0, 0.2542346263311371, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598094.6477220455, 598094.647722046, 170744.4173429954]
[2019-03-24 07:53:11,705] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:53:11,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7660637e-06 5.0503081e-06 2.9436676e-06 9.9994934e-01 3.9977051e-05], sampled 0.9585704223005188
[2019-03-24 07:53:17,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.5960 2438852947.7860 34.0000
[2019-03-24 07:53:17,314] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7263 2495357706.3366 47.0000
[2019-03-24 07:53:17,636] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6563 2466000715.1053 46.0000
[2019-03-24 07:53:17,711] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.6574 2668530154.8105 68.0000
[2019-03-24 07:53:17,805] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.9511 2410790597.4898 22.0000
[2019-03-24 07:53:18,822] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1225000, evaluation results [1225000.0, 7521.65743433451, 2668530154.810455, 68.0, 7121.596024076846, 2438852947.7859845, 34.0, 7796.951118957734, 2410790597.4898252, 22.0, 6906.726304166055, 2495357706.336649, 47.0, 7477.656322107676, 2466000715.105284, 46.0]
[2019-03-24 07:53:20,195] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225682: loss 0.0210
[2019-03-24 07:53:20,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225682: learning rate 0.0000
[2019-03-24 07:53:20,614] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225890: loss 0.0457
[2019-03-24 07:53:20,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225890: learning rate 0.0000
[2019-03-24 07:53:20,809] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1225985: loss 0.0192
[2019-03-24 07:53:20,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1225985: learning rate 0.0000
[2019-03-24 07:53:20,859] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1226009: loss 0.0238
[2019-03-24 07:53:20,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1226010: learning rate 0.0000
[2019-03-24 07:53:20,935] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226044: loss 0.0160
[2019-03-24 07:53:20,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226046: learning rate 0.0000
[2019-03-24 07:53:21,345] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1226248: loss 27.6889
[2019-03-24 07:53:21,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1226249: learning rate 0.0000
[2019-03-24 07:53:22,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1319036e-06 3.4937042e-05 9.0955206e-07 9.9994087e-01 1.9214649e-05], sum to 1.0000
[2019-03-24 07:53:22,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9621
[2019-03-24 07:53:22,469] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333334, 67.0, 1.0, 2.0, 0.3492590417399289, 1.0, 2.0, 0.3492590417399289, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796112.1347950981, 796112.1347950986, 192702.3395666664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6349200.0000, 
sim time next is 6349800.0000, 
raw observation next is [29.91666666666666, 66.5, 1.0, 2.0, 0.3497207520191988, 1.0, 2.0, 0.3497207520191988, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797165.1191299831, 797165.1191299836, 192821.0390138023], 
processed observation next is [0.0, 0.4782608695652174, 0.66358024691358, 0.665, 1.0, 1.0, 0.2258580381180938, 1.0, 1.0, 0.2258580381180938, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2847018282607083, 0.28470182826070844, 0.3708096904111583], 
reward next is 0.6292, 
noisyNet noise sample is [array([-0.00552021], dtype=float32), -1.0920987]. 
=============================================
[2019-03-24 07:53:26,863] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1228995: loss 32.6199
[2019-03-24 07:53:26,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1228998: learning rate 0.0000
[2019-03-24 07:53:28,139] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1229641: loss 34.3786
[2019-03-24 07:53:28,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1229641: learning rate 0.0000
[2019-03-24 07:53:29,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2781524e-05 8.1848499e-05 1.8019638e-05 9.9931085e-01 5.6639302e-04], sum to 1.0000
[2019-03-24 07:53:29,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0066
[2019-03-24 07:53:29,786] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.21666666666667, 61.16666666666666, 1.0, 2.0, 0.8236580259801084, 1.0, 2.0, 0.8236580259801084, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1878746.398078567, 1878746.398078567, 353627.6932256557], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6439800.0000, 
sim time next is 6440400.0000, 
raw observation next is [31.4, 60.0, 1.0, 2.0, 0.8747334693442015, 1.0, 2.0, 0.8747334693442015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1995378.542340819, 1995378.54234082, 375603.5284353696], 
processed observation next is [1.0, 0.5652173913043478, 0.7185185185185184, 0.6, 1.0, 1.0, 0.850873177790716, 1.0, 1.0, 0.850873177790716, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7126351936931496, 0.71263519369315, 0.7223144777603262], 
reward next is 0.2777, 
noisyNet noise sample is [array([-0.5396741], dtype=float32), -0.39913645]. 
=============================================
[2019-03-24 07:53:30,633] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1230872: loss 36.8060
[2019-03-24 07:53:30,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1230874: learning rate 0.0000
[2019-03-24 07:53:30,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4376133e-05 4.2220154e-06 5.0935441e-06 9.9983644e-01 5.9785056e-05], sum to 1.0000
[2019-03-24 07:53:30,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6872
[2019-03-24 07:53:30,912] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 88.66666666666666, 1.0, 2.0, 0.4206709489903827, 1.0, 2.0, 0.4206709489903827, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 958992.5424878366, 958992.5424878361, 211940.4441297685], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6507600.0000, 
sim time next is 6508200.0000, 
raw observation next is [26.3, 88.83333333333334, 1.0, 2.0, 0.4137529670171948, 1.0, 2.0, 0.4137529670171948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 943212.0947301729, 943212.0947301734, 209999.4748959977], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.8883333333333334, 1.0, 1.0, 0.3020868654966604, 1.0, 1.0, 0.3020868654966604, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3368614624036332, 0.33686146240363335, 0.4038451440307648], 
reward next is 0.5962, 
noisyNet noise sample is [array([1.8375996], dtype=float32), 2.2509542]. 
=============================================
[2019-03-24 07:53:31,158] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1231132: loss 36.4635
[2019-03-24 07:53:31,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1231133: learning rate 0.0000
[2019-03-24 07:53:33,146] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232058: loss 37.5802
[2019-03-24 07:53:33,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232058: learning rate 0.0000
[2019-03-24 07:53:33,862] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232437: loss 40.9288
[2019-03-24 07:53:33,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232438: learning rate 0.0000
[2019-03-24 07:53:33,952] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232485: loss 41.2577
[2019-03-24 07:53:33,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232485: learning rate 0.0000
[2019-03-24 07:53:34,028] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232524: loss 41.0108
[2019-03-24 07:53:34,031] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232524: learning rate 0.0000
[2019-03-24 07:53:34,740] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232895: loss 43.1393
[2019-03-24 07:53:34,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232895: learning rate 0.0000
[2019-03-24 07:53:34,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0541389e-05 1.4643589e-04 2.1555309e-06 9.9975151e-01 6.9338377e-05], sum to 1.0000
[2019-03-24 07:53:34,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0267
[2019-03-24 07:53:34,799] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.03333333333334, 84.0, 1.0, 2.0, 0.9224918245338531, 1.0, 2.0, 0.9224918245338531, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2104449.809176323, 2104449.809176322, 396969.8752079434], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6427200.0000, 
sim time next is 6427800.0000, 
raw observation next is [27.25, 83.0, 1.0, 2.0, 0.9315593178024367, 1.0, 2.0, 0.9315593178024367, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2125159.794847666, 2125159.794847666, 401115.893437602], 
processed observation next is [1.0, 0.391304347826087, 0.5648148148148148, 0.83, 1.0, 1.0, 0.9185229973838532, 1.0, 1.0, 0.9185229973838532, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7589856410170235, 0.7589856410170235, 0.7713767181492346], 
reward next is 0.2286, 
noisyNet noise sample is [array([0.38889402], dtype=float32), -0.46430248]. 
=============================================
[2019-03-24 07:53:34,958] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1233001: loss 44.4829
[2019-03-24 07:53:34,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1233002: learning rate 0.0000
[2019-03-24 07:53:35,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4426248e-04 1.1113353e-05 1.8823827e-06 9.9983954e-01 3.2009784e-06], sum to 1.0000
[2019-03-24 07:53:35,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6839
[2019-03-24 07:53:35,057] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 78.5, 1.0, 2.0, 0.8581470831692877, 1.0, 2.0, 0.8581470831692877, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1957501.414774489, 1957501.414774489, 368367.6441551358], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6539400.0000, 
sim time next is 6540000.0000, 
raw observation next is [27.8, 78.33333333333334, 1.0, 2.0, 0.8282159694623413, 1.0, 2.0, 0.8282159694623413, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1889153.965278663, 1889153.965278663, 355551.785241109], 
processed observation next is [1.0, 0.6956521739130435, 0.5851851851851853, 0.7833333333333334, 1.0, 1.0, 0.7954952017408825, 1.0, 1.0, 0.7954952017408825, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6746978447423796, 0.6746978447423796, 0.6837534331559789], 
reward next is 0.3162, 
noisyNet noise sample is [array([1.1472995], dtype=float32), -1.2296649]. 
=============================================
[2019-03-24 07:53:35,073] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.924736]
 [54.93222 ]
 [55.05771 ]
 [55.705883]
 [55.574333]], R is [[54.90422058]
 [54.64677811]
 [54.39465714]
 [54.14107132]
 [53.94750214]].
[2019-03-24 07:53:35,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3331798e-05 2.6025957e-05 1.0062764e-05 9.9949789e-01 4.3278257e-04], sum to 1.0000
[2019-03-24 07:53:35,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2363
[2019-03-24 07:53:35,575] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333333, 76.66666666666667, 1.0, 2.0, 0.9145591702371692, 1.0, 2.0, 0.9145591702371692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2086332.168487531, 2086332.168487532, 393366.7329146349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6432000.0000, 
sim time next is 6432600.0000, 
raw observation next is [29.06666666666667, 75.83333333333333, 1.0, 2.0, 0.9232091705517824, 1.0, 2.0, 0.9232091705517824, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2106088.196617948, 2106088.196617949, 397297.4750325977], 
processed observation next is [1.0, 0.43478260869565216, 0.6320987654320989, 0.7583333333333333, 1.0, 1.0, 0.9085823458949791, 1.0, 1.0, 0.9085823458949791, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7521743559349814, 0.7521743559349817, 0.7640336058319187], 
reward next is 0.2360, 
noisyNet noise sample is [array([-0.00530058], dtype=float32), 1.1825131]. 
=============================================
[2019-03-24 07:53:36,278] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1233686: loss 49.6974
[2019-03-24 07:53:36,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1233686: learning rate 0.0000
[2019-03-24 07:53:36,705] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1233914: loss 53.6858
[2019-03-24 07:53:36,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1233918: learning rate 0.0000
[2019-03-24 07:53:36,795] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1233954: loss 53.5432
[2019-03-24 07:53:36,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1233954: learning rate 0.0000
[2019-03-24 07:53:36,893] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234009: loss 51.4506
[2019-03-24 07:53:36,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234009: learning rate 0.0000
[2019-03-24 07:53:36,990] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234059: loss 52.3311
[2019-03-24 07:53:36,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234059: learning rate 0.0000
[2019-03-24 07:53:37,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1977318e-04 6.6341549e-05 1.0864579e-04 9.9953568e-01 6.9612266e-05], sum to 1.0000
[2019-03-24 07:53:37,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8220
[2019-03-24 07:53:37,258] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.03333333333333, 81.50000000000001, 1.0, 2.0, 0.8656684217778875, 1.0, 2.0, 0.8656684217778875, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1974677.151373651, 1974677.151373651, 371637.5930076711], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6516600.0000, 
sim time next is 6517200.0000, 
raw observation next is [28.16666666666667, 81.0, 1.0, 2.0, 0.879598692626364, 1.0, 2.0, 0.879598692626364, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2006489.204747908, 2006489.204747908, 377744.4510156796], 
processed observation next is [1.0, 0.43478260869565216, 0.5987654320987656, 0.81, 1.0, 1.0, 0.856665110269481, 1.0, 1.0, 0.856665110269481, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7166032874099671, 0.7166032874099671, 0.7264316365686145], 
reward next is 0.2736, 
noisyNet noise sample is [array([-0.13233934], dtype=float32), 0.84749275]. 
=============================================
[2019-03-24 07:53:37,323] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1234232: loss 0.1991
[2019-03-24 07:53:37,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1234234: learning rate 0.0000
[2019-03-24 07:53:38,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.711525e-05 2.269293e-05 7.063220e-04 9.985624e-01 6.215195e-04], sum to 1.0000
[2019-03-24 07:53:38,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8734
[2019-03-24 07:53:38,878] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.2921230803013927, 1.0, 2.0, 0.2921230803013927, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731495.7052364491, 731495.7052364496, 180992.0566288206], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.2808174926873738, 1.0, 2.0, 0.2808174926873738, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 704049.6869426618, 704049.6869426622, 178273.6607902298], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.1438303484373498, 1.0, 1.0, 0.1438303484373498, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514463167652363, 0.2514463167652365, 0.34283396305813424], 
reward next is 0.6572, 
noisyNet noise sample is [array([0.15596075], dtype=float32), 0.71309847]. 
=============================================
[2019-03-24 07:53:42,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.69309242e-05 1.20626384e-04 1.12195255e-06 9.99839187e-01
 2.21924383e-05], sum to 1.0000
[2019-03-24 07:53:42,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1327
[2019-03-24 07:53:42,179] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.41666666666667, 79.33333333333334, 1.0, 2.0, 0.2327172697597935, 1.0, 2.0, 0.2327172697597935, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 589105.0529601002, 589105.0529601007, 167234.0254064913], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6747000.0000, 
sim time next is 6747600.0000, 
raw observation next is [19.33333333333334, 79.66666666666667, 1.0, 2.0, 0.190525488236354, 1.0, 2.0, 0.190525488236354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482246.7349984543, 482246.7349984543, 158142.5758708687], 
processed observation next is [1.0, 0.08695652173913043, 0.27160493827160515, 0.7966666666666667, 1.0, 1.0, 0.03633986694804049, 1.0, 1.0, 0.03633986694804049, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17223097678516225, 0.17223097678516225, 0.304120338213209], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.2130287], dtype=float32), 1.4382715]. 
=============================================
[2019-03-24 07:53:42,577] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1236963: loss 0.1177
[2019-03-24 07:53:42,579] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1236963: learning rate 0.0000
[2019-03-24 07:53:42,666] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5569954e-05 1.9219910e-05 3.2900743e-06 9.9993038e-01 3.1576838e-05], sum to 1.0000
[2019-03-24 07:53:42,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5453
[2019-03-24 07:53:42,677] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.96666666666667, 70.33333333333333, 1.0, 2.0, 0.2670508038362583, 1.0, 2.0, 0.2670508038362583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626247.2946647964, 626247.2946647969, 173590.2779432267], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [25.93333333333334, 68.66666666666667, 1.0, 2.0, 0.2593056362072646, 1.0, 2.0, 0.2593056362072646, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611491.1949608648, 611491.1949608653, 171962.0554762362], 
processed observation next is [1.0, 0.0, 0.5160493827160496, 0.6866666666666668, 1.0, 1.0, 0.11822099548483882, 1.0, 1.0, 0.11822099548483882, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21838971248602315, 0.21838971248602332, 0.3306962605312234], 
reward next is 0.6693, 
noisyNet noise sample is [array([0.7235363], dtype=float32), -0.44896013]. 
=============================================
[2019-03-24 07:53:43,775] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1237587: loss 0.0455
[2019-03-24 07:53:43,777] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1237588: learning rate 0.0000
[2019-03-24 07:53:46,243] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1238871: loss 0.1316
[2019-03-24 07:53:46,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1238871: learning rate 0.0000
[2019-03-24 07:53:46,617] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1239066: loss 0.1135
[2019-03-24 07:53:46,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1239066: learning rate 0.0000
[2019-03-24 07:53:48,288] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1239938: loss 0.2296
[2019-03-24 07:53:48,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1239938: learning rate 0.0000
[2019-03-24 07:53:48,908] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6057228e-07 2.1877050e-07 3.4427902e-07 9.9997962e-01 1.9130335e-05], sum to 1.0000
[2019-03-24 07:53:48,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4324
[2019-03-24 07:53:48,929] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 44.0, 1.0, 2.0, 0.1629612796558925, 1.0, 2.0, 0.1629612796558925, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410125.1578786338, 410125.1578786342, 152420.3888262332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6724800.0000, 
sim time next is 6725400.0000, 
raw observation next is [25.71666666666667, 45.5, 1.0, 2.0, 0.16572314674107, 1.0, 2.0, 0.16572314674107, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 416937.2491633596, 416937.2491633601, 152976.4149770621], 
processed observation next is [1.0, 0.8695652173913043, 0.5080246913580247, 0.455, 1.0, 1.0, 0.006813269929845233, 1.0, 1.0, 0.006813269929845233, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14890616041548557, 0.14890616041548574, 0.2941854134174271], 
reward next is 0.7058, 
noisyNet noise sample is [array([0.87596256], dtype=float32), -1.7534302]. 
=============================================
[2019-03-24 07:53:49,063] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240341: loss 0.1677
[2019-03-24 07:53:49,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240342: learning rate 0.0000
[2019-03-24 07:53:49,320] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240477: loss 0.1455
[2019-03-24 07:53:49,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240478: learning rate 0.0000
[2019-03-24 07:53:49,499] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240566: loss 0.1427
[2019-03-24 07:53:49,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240566: learning rate 0.0000
[2019-03-24 07:53:49,872] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240760: loss 0.1371
[2019-03-24 07:53:49,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240760: learning rate 0.0000
[2019-03-24 07:53:50,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6648213e-07 4.8189935e-07 3.8877516e-07 9.9997497e-01 2.3693930e-05], sum to 1.0000
[2019-03-24 07:53:50,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8602
[2019-03-24 07:53:50,551] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.03333333333333, 54.66666666666667, 1.0, 2.0, 0.5990771351190145, 1.0, 2.0, 0.5990771351190145, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1407023.540550826, 1407023.540550826, 269634.5488089349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6798000.0000, 
sim time next is 6798600.0000, 
raw observation next is [28.05, 55.0, 1.0, 2.0, 0.605320839700714, 1.0, 2.0, 0.605320839700714, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1419905.429312388, 1419905.429312388, 271732.5981252954], 
processed observation next is [1.0, 0.6956521739130435, 0.5944444444444444, 0.55, 1.0, 1.0, 0.5301438567865643, 1.0, 1.0, 0.5301438567865643, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5071090818972814, 0.5071090818972814, 0.5225626887024912], 
reward next is 0.4774, 
noisyNet noise sample is [array([-0.25899032], dtype=float32), -0.104733236]. 
=============================================
[2019-03-24 07:53:50,579] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1241126: loss 0.0416
[2019-03-24 07:53:50,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1241127: learning rate 0.0000
[2019-03-24 07:53:51,487] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1241600: loss 0.0381
[2019-03-24 07:53:51,488] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1241601: learning rate 0.0000
[2019-03-24 07:53:52,170] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1241960: loss 0.0514
[2019-03-24 07:53:52,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1241960: learning rate 0.0000
[2019-03-24 07:53:52,317] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242036: loss 0.0370
[2019-03-24 07:53:52,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242036: learning rate 0.0000
[2019-03-24 07:53:52,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1242050: loss 0.0362
[2019-03-24 07:53:52,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1242052: learning rate 0.0000
[2019-03-24 07:53:52,415] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242081: loss 0.0401
[2019-03-24 07:53:52,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242081: learning rate 0.0000
[2019-03-24 07:53:52,799] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1242284: loss 0.5288
[2019-03-24 07:53:52,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1242284: learning rate 0.0000
[2019-03-24 07:53:53,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5918353e-06 1.7027398e-05 6.7423343e-08 9.9997640e-01 4.8446836e-06], sum to 1.0000
[2019-03-24 07:53:53,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0344
[2019-03-24 07:53:53,527] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 51.0, 1.0, 2.0, 0.4353775307552872, 1.0, 2.0, 0.4353775307552872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1069040.859015245, 1069040.859015245, 219097.4211279342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6778800.0000, 
sim time next is 6779400.0000, 
raw observation next is [26.01666666666667, 50.83333333333333, 1.0, 2.0, 0.4414794494571121, 1.0, 2.0, 0.4414794494571121, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1082622.515825025, 1082622.515825026, 220857.9551618259], 
processed observation next is [1.0, 0.4782608695652174, 0.5191358024691359, 0.5083333333333333, 1.0, 1.0, 0.33509458268703823, 1.0, 1.0, 0.33509458268703823, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3866508985089375, 0.38665089850893786, 0.42472683684966517], 
reward next is 0.5753, 
noisyNet noise sample is [array([0.31984898], dtype=float32), -0.9203949]. 
=============================================
[2019-03-24 07:53:55,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3449577e-07 2.4449866e-07 5.8773963e-07 9.9999547e-01 3.1846562e-06], sum to 1.0000
[2019-03-24 07:53:55,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8573
[2019-03-24 07:53:55,626] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.85, 79.0, 1.0, 2.0, 0.2439838770404038, 1.0, 2.0, 0.2439838770404038, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581216.2608609654, 581216.2608609654, 168747.8764633466], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6820200.0000, 
sim time next is 6820800.0000, 
raw observation next is [23.76666666666667, 79.66666666666667, 1.0, 2.0, 0.2433716506664356, 1.0, 2.0, 0.2433716506664356, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579644.676771157, 579644.6767711574, 168606.2072210605], 
processed observation next is [1.0, 0.9565217391304348, 0.43580246913580256, 0.7966666666666667, 1.0, 1.0, 0.09925196507909, 1.0, 1.0, 0.09925196507909, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2070159559896989, 0.20701595598969907, 0.3242427061943471], 
reward next is 0.6758, 
noisyNet noise sample is [array([-0.16353822], dtype=float32), 0.64499754]. 
=============================================
[2019-03-24 07:53:56,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9135055e-09 5.9112431e-08 6.8704637e-08 9.9999905e-01 8.4368151e-07], sum to 1.0000
[2019-03-24 07:53:56,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7016
[2019-03-24 07:53:56,072] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.03333333333333, 55.33333333333334, 1.0, 2.0, 0.2217869681527884, 1.0, 2.0, 0.2217869681527884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535239.85087827, 535239.8508782705, 164136.193209089], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6862800.0000, 
sim time next is 6863400.0000, 
raw observation next is [27.3, 54.0, 1.0, 2.0, 0.2219813617201607, 1.0, 2.0, 0.2219813617201607, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535687.1572695961, 535687.1572695966, 164177.5696335325], 
processed observation next is [0.0, 0.43478260869565216, 0.5666666666666667, 0.54, 1.0, 1.0, 0.07378733538114368, 1.0, 1.0, 0.07378733538114368, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19131684188199863, 0.1913168418819988, 0.31572609544910096], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.83040583], dtype=float32), -1.120742]. 
=============================================
[2019-03-24 07:53:56,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1390993e-09 7.8455713e-09 1.4334887e-08 9.9995816e-01 4.1891562e-05], sum to 1.0000
[2019-03-24 07:53:56,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8322
[2019-03-24 07:53:56,943] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.73333333333333, 76.0, 1.0, 2.0, 0.1877204501317122, 1.0, 2.0, 0.1877204501317122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 465181.9442717601, 465181.9442717605, 157356.5742240644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6843000.0000, 
sim time next is 6843600.0000, 
raw observation next is [21.7, 76.0, 1.0, 2.0, 0.1868771394327528, 1.0, 2.0, 0.1868771394327528, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463304.754480261, 463304.7544802614, 157185.5548863517], 
processed observation next is [0.0, 0.21739130434782608, 0.3592592592592592, 0.76, 1.0, 1.0, 0.031996594562800955, 1.0, 1.0, 0.031996594562800955, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16546598374295035, 0.16546598374295052, 0.30227991324298403], 
reward next is 0.6977, 
noisyNet noise sample is [array([-2.7219572], dtype=float32), -0.26530424]. 
=============================================
[2019-03-24 07:53:57,941] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1244956: loss 0.5598
[2019-03-24 07:53:57,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1244957: learning rate 0.0000
[2019-03-24 07:53:58,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0883775e-07 7.0696060e-06 8.8143497e-06 9.9995816e-01 2.5370624e-05], sum to 1.0000
[2019-03-24 07:53:58,646] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8011
[2019-03-24 07:53:58,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 68.66666666666667, 1.0, 2.0, 0.2160898892493642, 1.0, 2.0, 0.2160898892493642, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 526068.7254053584, 526068.725405358, 163069.8568158956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6993600.0000, 
sim time next is 6994200.0000, 
raw observation next is [23.93333333333334, 69.33333333333333, 1.0, 2.0, 0.215509297928754, 1.0, 2.0, 0.215509297928754, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524869.5953252534, 524869.5953252534, 162952.1007687987], 
processed observation next is [0.0, 0.9565217391304348, 0.4419753086419756, 0.6933333333333332, 1.0, 1.0, 0.06608249753423096, 1.0, 1.0, 0.06608249753423096, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18745342690187622, 0.18745342690187622, 0.31336942455538214], 
reward next is 0.6866, 
noisyNet noise sample is [array([-1.20519], dtype=float32), -1.321799]. 
=============================================
[2019-03-24 07:53:59,201] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1245605: loss 0.5975
[2019-03-24 07:53:59,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1245606: learning rate 0.0000
[2019-03-24 07:54:01,620] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1246854: loss 0.6063
[2019-03-24 07:54:01,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1246854: learning rate 0.0000
[2019-03-24 07:54:01,979] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1247038: loss 0.6843
[2019-03-24 07:54:01,981] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1247038: learning rate 0.0000
[2019-03-24 07:54:03,898] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248036: loss 0.5130
[2019-03-24 07:54:03,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248036: learning rate 0.0000
[2019-03-24 07:54:04,438] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248318: loss 0.6134
[2019-03-24 07:54:04,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248318: learning rate 0.0000
[2019-03-24 07:54:04,799] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248505: loss 0.5991
[2019-03-24 07:54:04,802] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248505: learning rate 0.0000
[2019-03-24 07:54:04,924] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248572: loss 0.6423
[2019-03-24 07:54:04,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248573: learning rate 0.0000
[2019-03-24 07:54:05,466] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248852: loss 0.7744
[2019-03-24 07:54:05,469] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248852: learning rate 0.0000
[2019-03-24 07:54:06,080] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1249174: loss 0.7482
[2019-03-24 07:54:06,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1249174: learning rate 0.0000
[2019-03-24 07:54:06,899] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1249604: loss 0.5120
[2019-03-24 07:54:06,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1249604: learning rate 0.0000
[2019-03-24 07:54:06,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6612778e-06 2.4008921e-06 1.1381441e-05 9.9993074e-01 4.7758487e-05], sum to 1.0000
[2019-03-24 07:54:06,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5037
[2019-03-24 07:54:06,936] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 67.0, 1.0, 2.0, 0.6605179937145185, 1.0, 2.0, 0.6605179937145185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1532741.902395358, 1532741.902395358, 290786.8490866334], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7041600.0000, 
sim time next is 7042200.0000, 
raw observation next is [26.56666666666667, 66.16666666666667, 1.0, 2.0, 0.6109552046890346, 1.0, 2.0, 0.6109552046890346, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1417880.413631566, 1417880.413631566, 273023.3563077681], 
processed observation next is [1.0, 0.5217391304347826, 0.5395061728395063, 0.6616666666666667, 1.0, 1.0, 0.5368514341536127, 1.0, 1.0, 0.5368514341536127, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5063858620112736, 0.5063858620112736, 0.5250449159764771], 
reward next is 0.4750, 
noisyNet noise sample is [array([0.40725404], dtype=float32), -0.99661404]. 
=============================================
[2019-03-24 07:54:07,414] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1249865: loss 0.7618
[2019-03-24 07:54:07,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1249866: learning rate 0.0000
[2019-03-24 07:54:07,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2979438e-07 3.9691904e-06 2.1224364e-06 9.9998701e-01 6.7338215e-06], sum to 1.0000
[2019-03-24 07:54:07,523] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-24 07:54:07,527] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 81.0, 1.0, 2.0, 0.31148732664388, 1.0, 2.0, 0.31148732664388, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769649.5339403786, 769649.5339403786, 185557.0523284099], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7115400.0000, 
sim time next is 7116000.0000, 
raw observation next is [21.1, 80.66666666666666, 1.0, 2.0, 0.3328057154143609, 1.0, 2.0, 0.3328057154143609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 820667.874850471, 820667.8748504715, 190928.2598316713], 
processed observation next is [1.0, 0.34782608695652173, 0.3370370370370371, 0.8066666666666665, 1.0, 1.0, 0.20572108977900105, 1.0, 1.0, 0.20572108977900105, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29309566958945393, 0.2930956695894541, 0.36716973044552176], 
reward next is 0.6328, 
noisyNet noise sample is [array([0.55639243], dtype=float32), 0.44228107]. 
=============================================
[2019-03-24 07:54:07,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.512856]
 [65.96807 ]
 [66.58579 ]
 [66.24885 ]
 [66.1646  ]], R is [[65.00892639]
 [65.0019989 ]
 [65.01525116]
 [65.06132507]
 [65.10006714]].
[2019-03-24 07:54:07,600] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1249960: loss 0.7156
[2019-03-24 07:54:07,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1249960: learning rate 0.0000
[2019-03-24 07:54:07,668] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 07:54:07,671] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:54:07,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:54:07,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:07,677] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:54:07,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:54:07,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:54:07,682] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:07,686] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:07,687] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:07,689] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:07,707] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-24 07:54:07,741] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-24 07:54:07,741] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-24 07:54:07,800] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-24 07:54:07,832] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-24 07:54:20,701] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0100587], dtype=float32), 0.007511741]
[2019-03-24 07:54:20,703] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.79219866666667, 63.73570321333334, 1.0, 2.0, 0.2107666556194985, 1.0, 2.0, 0.2107666556194985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512999.6614082333, 512999.6614082333, 161923.9240531613]
[2019-03-24 07:54:20,704] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:54:20,705] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.4988828e-07 1.0952742e-06 7.5884651e-07 9.9999297e-01 4.6647256e-06], sampled 0.941662457492395
[2019-03-24 07:55:20,829] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0100587], dtype=float32), 0.007511741]
[2019-03-24 07:55:20,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.92780682, 93.73773557, 1.0, 2.0, 0.3736119801676535, 1.0, 2.0, 0.3736119801676535, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851653.8355928403, 851653.8355928403, 199065.5836666767]
[2019-03-24 07:55:20,832] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:55:20,835] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2001947e-07 6.4024562e-07 4.4980877e-07 9.9999571e-01 2.9631092e-06], sampled 0.8115541776977024
[2019-03-24 07:55:26,220] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0100587], dtype=float32), 0.007511741]
[2019-03-24 07:55:26,221] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.16168350666667, 53.90533107333333, 1.0, 2.0, 0.4599002043733506, 1.0, 2.0, 0.4599002043733506, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1055040.634744983, 1055040.634744983, 223575.3928678939]
[2019-03-24 07:55:26,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:55:26,225] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.9167513e-07 1.1585088e-06 8.2653588e-07 9.9999237e-01 4.9918231e-06], sampled 0.25890115655039825
[2019-03-24 07:55:30,449] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0100587], dtype=float32), 0.007511741]
[2019-03-24 07:55:30,450] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 83.66666666666667, 1.0, 2.0, 0.2354144622172078, 1.0, 2.0, 0.2354144622172078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 562926.8860351336, 562926.8860351341, 166927.3898163916]
[2019-03-24 07:55:30,451] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:55:30,456] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1764171e-07 6.3376302e-07 4.4428819e-07 9.9999571e-01 3.0383803e-06], sampled 0.8103293536788795
[2019-03-24 07:55:49,458] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0100587], dtype=float32), 0.007511741]
[2019-03-24 07:55:49,459] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 370221.6292048049, 370221.6292048054, 146560.3017755266]
[2019-03-24 07:55:49,462] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:55:49,467] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.2173687e-07 8.4027550e-07 5.7448233e-07 9.9999452e-01 3.7261032e-06], sampled 0.0010055886180252438
[2019-03-24 07:55:53,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.6102 2668511040.5012 68.0000
[2019-03-24 07:55:53,741] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438826745.7357 34.0000
[2019-03-24 07:55:53,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6534 2465933447.5495 46.0000
[2019-03-24 07:55:53,885] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473358.3550 47.0000
[2019-03-24 07:55:54,161] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:55:55,176] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1250000, evaluation results [1250000.0, 7521.610245721528, 2668511040.5011926, 68.0, 7121.435945869477, 2438826745.735712, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495473358.35503, 47.0, 7477.653358418825, 2465933447.5495496, 46.0]
[2019-03-24 07:55:55,284] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250056: loss 0.7172
[2019-03-24 07:55:55,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250056: learning rate 0.0000
[2019-03-24 07:55:55,414] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250121: loss 0.7783
[2019-03-24 07:55:55,415] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250121: learning rate 0.0000
[2019-03-24 07:55:55,480] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1250149: loss 0.5776
[2019-03-24 07:55:55,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1250149: learning rate 0.0000
[2019-03-24 07:55:59,515] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.47595163e-06 1.00524964e-07 2.52242648e-06 9.99984741e-01
 3.04916557e-06], sum to 1.0000
[2019-03-24 07:55:59,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1055
[2019-03-24 07:55:59,526] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 76.66666666666667, 1.0, 2.0, 0.3879122288309842, 1.0, 2.0, 0.3879122288309842, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 941294.4765670439, 941294.4765670439, 205225.8812852615], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7209600.0000, 
sim time next is 7210200.0000, 
raw observation next is [22.5, 76.33333333333333, 1.0, 2.0, 0.3912090994968183, 1.0, 2.0, 0.3912090994968183, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 951007.4520393739, 951007.4520393753, 206191.5961085076], 
processed observation next is [1.0, 0.43478260869565216, 0.3888888888888889, 0.7633333333333333, 1.0, 1.0, 0.27524892797240275, 1.0, 1.0, 0.27524892797240275, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3396455185854907, 0.3396455185854912, 0.39652230020866847], 
reward next is 0.6035, 
noisyNet noise sample is [array([-0.35833317], dtype=float32), -0.84922504]. 
=============================================
[2019-03-24 07:55:59,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1257487e-06 1.3962590e-06 1.7615407e-06 9.9995637e-01 3.9326962e-05], sum to 1.0000
[2019-03-24 07:55:59,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7046
[2019-03-24 07:55:59,827] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.8, 92.0, 1.0, 2.0, 0.1878599360664534, 1.0, 2.0, 0.1878599360664534, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464979.2943907435, 464979.294390744, 157369.9818334488], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7173000.0000, 
sim time next is 7173600.0000, 
raw observation next is [19.8, 92.33333333333334, 1.0, 2.0, 0.1884041085610878, 1.0, 2.0, 0.1884041085610878, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466068.3401501114, 466068.3401501119, 157476.7844928975], 
processed observation next is [1.0, 0.0, 0.2888888888888889, 0.9233333333333335, 1.0, 1.0, 0.03381441495367595, 1.0, 1.0, 0.03381441495367595, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1664529786250398, 0.16645297862503997, 0.30283997017864905], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.4511093], dtype=float32), -0.2816307]. 
=============================================
[2019-03-24 07:56:01,059] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1252921: loss 0.8206
[2019-03-24 07:56:01,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1252922: learning rate 0.0000
[2019-03-24 07:56:02,441] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1253597: loss 0.7055
[2019-03-24 07:56:02,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1253597: learning rate 0.0000
[2019-03-24 07:56:04,874] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1254813: loss 0.7346
[2019-03-24 07:56:04,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1254815: learning rate 0.0000
[2019-03-24 07:56:05,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1255095: loss 0.5511
[2019-03-24 07:56:05,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1255096: learning rate 0.0000
[2019-03-24 07:56:07,283] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256009: loss 0.5009
[2019-03-24 07:56:07,285] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256010: learning rate 0.0000
[2019-03-24 07:56:08,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256408: loss 0.4058
[2019-03-24 07:56:08,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256408: learning rate 0.0000
[2019-03-24 07:56:08,319] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256525: loss 0.3775
[2019-03-24 07:56:08,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256525: learning rate 0.0000
[2019-03-24 07:56:08,545] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256630: loss 0.4950
[2019-03-24 07:56:08,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256631: learning rate 0.0000
[2019-03-24 07:56:09,237] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256924: loss 0.4768
[2019-03-24 07:56:09,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256924: learning rate 0.0000
[2019-03-24 07:56:09,716] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1257169: loss 0.5467
[2019-03-24 07:56:09,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1257169: learning rate 0.0000
[2019-03-24 07:56:10,627] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1257646: loss 0.2851
[2019-03-24 07:56:10,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1257646: learning rate 0.0000
[2019-03-24 07:56:11,065] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1257879: loss 0.3168
[2019-03-24 07:56:11,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1257879: learning rate 0.0000
[2019-03-24 07:56:11,223] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1257957: loss 0.4434
[2019-03-24 07:56:11,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1257957: learning rate 0.0000
[2019-03-24 07:56:11,346] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258025: loss 0.3607
[2019-03-24 07:56:11,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258026: learning rate 0.0000
[2019-03-24 07:56:11,361] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258029: loss 0.4277
[2019-03-24 07:56:11,364] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258029: learning rate 0.0000
[2019-03-24 07:56:11,719] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1258216: loss 0.2365
[2019-03-24 07:56:11,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1258216: learning rate 0.0000
[2019-03-24 07:56:13,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7707119e-07 8.4988713e-08 1.1185542e-07 9.9999905e-01 5.2604099e-07], sum to 1.0000
[2019-03-24 07:56:13,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7174
[2019-03-24 07:56:13,078] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.4, 95.0, 1.0, 2.0, 0.1840718212091583, 1.0, 2.0, 0.1840718212091583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456024.1728566895, 456024.17285669, 156588.9165497995], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7452000.0000, 
sim time next is 7452600.0000, 
raw observation next is [19.46666666666667, 94.83333333333334, 1.0, 2.0, 0.1848717565687425, 1.0, 2.0, 0.1848717565687425, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 457696.764529846, 457696.7645298464, 156747.0549288667], 
processed observation next is [0.0, 0.2608695652173913, 0.2765432098765433, 0.9483333333333335, 1.0, 1.0, 0.029609234010407732, 1.0, 1.0, 0.029609234010407732, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16346313018923073, 0.16346313018923084, 0.3014366440939744], 
reward next is 0.6986, 
noisyNet noise sample is [array([-2.1621695], dtype=float32), -0.7912835]. 
=============================================
[2019-03-24 07:56:13,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2846129e-07 2.4203845e-07 2.2512751e-07 9.9999785e-01 1.0557569e-06], sum to 1.0000
[2019-03-24 07:56:13,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1347
[2019-03-24 07:56:13,246] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.73333333333333, 94.16666666666667, 1.0, 2.0, 0.1884357974106444, 1.0, 2.0, 0.1884357974106444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 465229.4147697346, 465229.4147697351, 157455.7875775105], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7455000.0000, 
sim time next is 7455600.0000, 
raw observation next is [19.8, 94.0, 1.0, 2.0, 0.1892988598591801, 1.0, 2.0, 0.1892988598591801, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467033.3135124873, 467033.3135124877, 157625.998794133], 
processed observation next is [0.0, 0.30434782608695654, 0.2888888888888889, 0.94, 1.0, 1.0, 0.0348795950704525, 1.0, 1.0, 0.0348795950704525, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16679761196874546, 0.1667976119687456, 0.30312692075794806], 
reward next is 0.6969, 
noisyNet noise sample is [array([-0.24993683], dtype=float32), 2.058582]. 
=============================================
[2019-03-24 07:56:13,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2414780e-07 2.0627899e-06 2.6302627e-07 9.9999666e-01 9.4070970e-07], sum to 1.0000
[2019-03-24 07:56:13,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3127
[2019-03-24 07:56:13,732] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.05, 96.0, 1.0, 2.0, 0.226781868574336, 1.0, 2.0, 0.226781868574336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545855.2887666344, 545855.2887666349, 165170.5554243931], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7522200.0000, 
sim time next is 7522800.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.2255352627355045, 1.0, 2.0, 0.2255352627355045, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543329.6124198138, 543329.6124198142, 164916.3044994368], 
processed observation next is [0.0, 0.043478260869565216, 0.3333333333333333, 0.96, 1.0, 1.0, 0.07801816992321965, 1.0, 1.0, 0.07801816992321965, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1940462901499335, 0.19404629014993366, 0.31714673942199384], 
reward next is 0.6829, 
noisyNet noise sample is [array([0.9804813], dtype=float32), -0.082433395]. 
=============================================
[2019-03-24 07:56:15,663] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4071842e-07 1.6950073e-06 1.6322101e-06 9.9999547e-01 7.0656534e-07], sum to 1.0000
[2019-03-24 07:56:15,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0472
[2019-03-24 07:56:15,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.45, 94.33333333333334, 1.0, 2.0, 0.187249038961033, 1.0, 2.0, 0.187249038961033, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463883.1605687615, 463883.160568762, 157253.7841253919], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7441800.0000, 
sim time next is 7442400.0000, 
raw observation next is [19.4, 94.66666666666667, 1.0, 2.0, 0.187952691326957, 1.0, 2.0, 0.187952691326957, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 465695.9027814753, 465695.9027814748, 157403.6264200333], 
processed observation next is [0.0, 0.13043478260869565, 0.274074074074074, 0.9466666666666668, 1.0, 1.0, 0.03327701348447261, 1.0, 1.0, 0.03327701348447261, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16631996527909831, 0.16631996527909815, 0.3026992815769871], 
reward next is 0.6973, 
noisyNet noise sample is [array([-0.49691665], dtype=float32), -2.439812]. 
=============================================
[2019-03-24 07:56:16,864] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1260909: loss 0.1862
[2019-03-24 07:56:16,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1260909: learning rate 0.0000
[2019-03-24 07:56:18,126] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1261562: loss 0.1786
[2019-03-24 07:56:18,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1261562: learning rate 0.0000
[2019-03-24 07:56:20,624] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1262873: loss 0.1870
[2019-03-24 07:56:20,627] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1262874: learning rate 0.0000
[2019-03-24 07:56:20,637] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3819650e-06 2.3046506e-07 1.1394555e-06 9.9999082e-01 5.3508215e-06], sum to 1.0000
[2019-03-24 07:56:20,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8361
[2019-03-24 07:56:20,647] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333334, 76.16666666666667, 1.0, 2.0, 0.2608130530361107, 1.0, 2.0, 0.2608130530361107, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611761.8456995392, 611761.8456995392, 172163.1672080648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7585800.0000, 
sim time next is 7586400.0000, 
raw observation next is [24.96666666666667, 77.33333333333334, 1.0, 2.0, 0.2609061458294392, 1.0, 2.0, 0.2609061458294392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611864.2530964919, 611864.2530964924, 172179.2878888565], 
processed observation next is [0.0, 0.8260869565217391, 0.48024691358024696, 0.7733333333333334, 1.0, 1.0, 0.12012636408266573, 1.0, 1.0, 0.12012636408266573, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2185229475344614, 0.21852294753446155, 0.33111401517087785], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.21852688], dtype=float32), -1.8702154]. 
=============================================
[2019-03-24 07:56:21,196] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1263174: loss 0.1861
[2019-03-24 07:56:21,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1263176: learning rate 0.0000
[2019-03-24 07:56:22,841] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264035: loss 0.2391
[2019-03-24 07:56:22,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264036: learning rate 0.0000
[2019-03-24 07:56:23,513] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264392: loss 0.2166
[2019-03-24 07:56:23,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264392: learning rate 0.0000
[2019-03-24 07:56:23,875] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264574: loss 0.2084
[2019-03-24 07:56:23,880] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264574: learning rate 0.0000
[2019-03-24 07:56:24,205] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264745: loss 0.2193
[2019-03-24 07:56:24,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264746: learning rate 0.0000
[2019-03-24 07:56:24,784] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1265046: loss 0.2033
[2019-03-24 07:56:24,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1265047: learning rate 0.0000
[2019-03-24 07:56:24,865] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1265087: loss 0.2075
[2019-03-24 07:56:24,867] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1265087: learning rate 0.0000
[2019-03-24 07:56:25,777] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265561: loss 0.2681
[2019-03-24 07:56:25,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265562: learning rate 0.0000
[2019-03-24 07:56:26,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1354597e-06 7.3570882e-06 2.3173134e-05 9.9981004e-01 1.5734590e-04], sum to 1.0000
[2019-03-24 07:56:26,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0726
[2019-03-24 07:56:26,181] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.76666666666667, 80.66666666666667, 1.0, 2.0, 0.1625121584491247, 1.0, 2.0, 0.1625121584491247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 409770.8072932655, 409770.8072932659, 152343.6982530946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7681200.0000, 
sim time next is 7681800.0000, 
raw observation next is [19.73333333333333, 81.33333333333334, 1.0, 2.0, 0.1633231357204959, 1.0, 2.0, 0.1633231357204959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411568.2498900262, 411568.2498900267, 152503.0766012587], 
processed observation next is [1.0, 0.9130434782608695, 0.28641975308641965, 0.8133333333333335, 1.0, 1.0, 0.003956113952971298, 1.0, 1.0, 0.003956113952971298, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14698866067500937, 0.14698866067500954, 0.2932751473101129], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.39428192], dtype=float32), 0.23211262]. 
=============================================
[2019-03-24 07:56:26,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1265861: loss 0.3373
[2019-03-24 07:56:26,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1265861: learning rate 0.0000
[2019-03-24 07:56:26,419] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1265896: loss 0.3361
[2019-03-24 07:56:26,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1265897: learning rate 0.0000
[2019-03-24 07:56:26,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265998: loss 0.2967
[2019-03-24 07:56:26,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265998: learning rate 0.0000
[2019-03-24 07:56:26,677] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266028: loss 0.3147
[2019-03-24 07:56:26,679] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266028: learning rate 0.0000
[2019-03-24 07:56:27,645] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:27,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:27,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-24 07:56:29,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5809795e-07 1.9059498e-06 2.8709712e-06 9.9990487e-01 9.0247238e-05], sum to 1.0000
[2019-03-24 07:56:29,733] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-24 07:56:29,738] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.63333333333333, 68.33333333333334, 1.0, 2.0, 0.4352453237523865, 1.0, 2.0, 0.4352453237523865, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1043854.891752088, 1043854.891752088, 218276.5266664441], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7726800.0000, 
sim time next is 7727400.0000, 
raw observation next is [25.0, 67.0, 1.0, 2.0, 0.4490577286549465, 1.0, 2.0, 0.4490577286549465, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1074009.232930964, 1074009.232930964, 222234.3634560692], 
processed observation next is [1.0, 0.43478260869565216, 0.48148148148148145, 0.67, 1.0, 1.0, 0.34411634363684107, 1.0, 1.0, 0.34411634363684107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3835747260467729, 0.3835747260467729, 0.42737377587705616], 
reward next is 0.5726, 
noisyNet noise sample is [array([1.3402166], dtype=float32), 0.22989541]. 
=============================================
[2019-03-24 07:56:29,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2953216e-06 2.3156836e-06 9.5614050e-06 9.9998248e-01 3.4092955e-06], sum to 1.0000
[2019-03-24 07:56:29,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-24 07:56:29,818] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333334, 46.0, 1.0, 2.0, 0.6229239491956022, 1.0, 2.0, 0.6229239491956022, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1471609.438195808, 1471609.438195808, 278378.0758449709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7741200.0000, 
sim time next is 7741800.0000, 
raw observation next is [29.5, 46.5, 1.0, 2.0, 0.6293567022825001, 1.0, 2.0, 0.6293567022825001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1484686.083948816, 1484686.083948816, 280588.5627015592], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.465, 1.0, 1.0, 0.5587579789077382, 1.0, 1.0, 0.5587579789077382, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.53024502998172, 0.53024502998172, 0.5395933898106908], 
reward next is 0.4604, 
noisyNet noise sample is [array([0.8028011], dtype=float32), -1.420456]. 
=============================================
[2019-03-24 07:56:32,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:32,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:32,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-24 07:56:33,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4802856e-07 1.0241150e-07 1.1483318e-06 9.9999046e-01 8.0560685e-06], sum to 1.0000
[2019-03-24 07:56:33,215] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4732
[2019-03-24 07:56:33,218] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 44.33333333333334, 1.0, 2.0, 0.3973196040368522, 1.0, 2.0, 0.3973196040368522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 981608.8916058931, 981608.8916058936, 208331.0966826588], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7809600.0000, 
sim time next is 7810200.0000, 
raw observation next is [27.1, 44.0, 1.0, 2.0, 0.4247636292333848, 1.0, 2.0, 0.4247636292333848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1047429.499671392, 1047429.499671393, 216116.423933182], 
processed observation next is [1.0, 0.391304347826087, 0.5592592592592593, 0.44, 1.0, 1.0, 0.3151947967064105, 1.0, 1.0, 0.3151947967064105, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3740819641683543, 0.37408196416835465, 0.4156085075638115], 
reward next is 0.5844, 
noisyNet noise sample is [array([-0.3334045], dtype=float32), 0.43183526]. 
=============================================
[2019-03-24 07:56:33,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3518862e-06 3.7753014e-06 7.5474702e-07 9.9998534e-01 1.7718712e-06], sum to 1.0000
[2019-03-24 07:56:33,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2212
[2019-03-24 07:56:33,292] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.11666666666667, 58.0, 1.0, 2.0, 0.177174470288171, 1.0, 2.0, 0.177174470288171, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446602.3152498361, 446602.3152498365, 155338.7710020328], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7798200.0000, 
sim time next is 7798800.0000, 
raw observation next is [23.33333333333334, 57.0, 1.0, 2.0, 0.1607662855696851, 1.0, 2.0, 0.1607662855696851, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 405081.6681245171, 405081.6681245176, 151987.1939574419], 
processed observation next is [1.0, 0.2608695652173913, 0.4197530864197533, 0.57, 1.0, 1.0, 0.0009122447258156073, 1.0, 1.0, 0.0009122447258156073, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14467202433018467, 0.14467202433018486, 0.29228306530277287], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.49302998], dtype=float32), 0.55278635]. 
=============================================
[2019-03-24 07:56:33,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:33,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:33,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-24 07:56:35,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:35,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:36,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-24 07:56:36,550] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:36,550] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:36,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-24 07:56:38,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:38,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:38,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-24 07:56:38,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:38,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:38,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-24 07:56:39,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:39,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:39,048] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-24 07:56:39,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:39,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:39,252] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-24 07:56:39,589] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:39,590] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:39,611] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-24 07:56:39,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:39,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:39,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-24 07:56:39,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6642339e-07 1.0699983e-06 3.6628037e-06 9.9999130e-01 2.9496898e-06], sum to 1.0000
[2019-03-24 07:56:39,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-24 07:56:39,820] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.73333333333333, 69.33333333333334, 1.0, 2.0, 0.408420141760557, 1.0, 2.0, 0.408420141760557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 992958.4442041615, 992958.444204162, 211021.3950895372], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 116400.0000, 
sim time next is 117000.0000, 
raw observation next is [24.15, 67.5, 1.0, 2.0, 0.4565992034688543, 1.0, 2.0, 0.4565992034688543, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1104714.86054733, 1104714.86054733, 224918.1417197218], 
processed observation next is [1.0, 0.34782608695652173, 0.44999999999999996, 0.675, 1.0, 1.0, 0.35309428984387414, 1.0, 1.0, 0.35309428984387414, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3945410216240464, 0.3945410216240464, 0.43253488792254197], 
reward next is 0.5675, 
noisyNet noise sample is [array([2.30776], dtype=float32), 0.43461972]. 
=============================================
[2019-03-24 07:56:39,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.52217 ]
 [65.496216]
 [65.85593 ]
 [65.86717 ]
 [65.82321 ]], R is [[63.88167953]
 [63.83705139]
 [63.85337448]
 [63.89949799]
 [63.94884491]].
[2019-03-24 07:56:40,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:40,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:40,336] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-24 07:56:40,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:40,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:40,592] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-24 07:56:40,869] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:40,869] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:40,890] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-24 07:56:40,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:40,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:40,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:56:40,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:40,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-24 07:56:41,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-24 07:56:41,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8817180e-06 3.4292279e-06 2.4114348e-05 9.9996305e-01 2.4992839e-06], sum to 1.0000
[2019-03-24 07:56:41,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3927
[2019-03-24 07:56:41,659] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.06666666666667, 44.0, 1.0, 2.0, 0.3280739310701481, 1.0, 2.0, 0.3280739310701481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 827410.6786398209, 827410.6786398214, 190081.0849794888], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 34800.0000, 
sim time next is 35400.0000, 
raw observation next is [25.28333333333333, 43.5, 1.0, 2.0, 0.3226391435307158, 1.0, 2.0, 0.3226391435307158, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 813383.660504012, 813383.6605040125, 188685.8635194905], 
processed observation next is [1.0, 0.391304347826087, 0.49197530864197525, 0.435, 1.0, 1.0, 0.19361802801275693, 1.0, 1.0, 0.19361802801275693, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2904941644657186, 0.29049416446571874, 0.36285742984517405], 
reward next is 0.6371, 
noisyNet noise sample is [array([-0.62213486], dtype=float32), -0.5755648]. 
=============================================
[2019-03-24 07:56:44,167] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 07:56:44,169] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:56:44,170] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:44,171] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:56:44,171] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:56:44,171] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:44,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:56:44,172] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:44,173] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:44,173] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:56:44,175] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:44,192] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-24 07:56:44,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-24 07:56:44,256] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-24 07:56:44,256] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-24 07:56:44,300] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-24 07:57:12,025] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01007294], dtype=float32), 0.007975402]
[2019-03-24 07:57:12,026] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.16666666666666, 37.0, 1.0, 2.0, 0.284115830766468, 1.0, 2.0, 0.284115830766468, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667164.527618477, 667164.5276184775, 177620.8267258134]
[2019-03-24 07:57:12,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:57:12,031] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6942433e-07 6.1776962e-07 8.0717160e-07 9.9999559e-01 2.6452337e-06], sampled 0.9909335493677106
[2019-03-24 07:57:35,640] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01007294], dtype=float32), 0.007975402]
[2019-03-24 07:57:35,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.389064975, 65.298504335, 1.0, 2.0, 0.4467510015449511, 1.0, 2.0, 0.4467510015449511, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1018486.065644428, 1018486.065644428, 219409.7305388945]
[2019-03-24 07:57:35,644] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:57:35,647] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8850939e-07 3.2106001e-07 4.2378952e-07 9.9999762e-01 1.4513083e-06], sampled 0.14575996646851352
[2019-03-24 07:58:04,655] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01007294], dtype=float32), 0.007975402]
[2019-03-24 07:58:04,657] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.4, 88.0, 1.0, 2.0, 0.2869928257341229, 1.0, 2.0, 0.2869928257341229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660662.7567025634, 660662.7567025634, 177694.4045585046]
[2019-03-24 07:58:04,658] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:04,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3094852e-07 5.5593688e-07 7.1870073e-07 9.9999595e-01 2.4037772e-06], sampled 0.6245304920472464
[2019-03-24 07:58:12,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01007294], dtype=float32), 0.007975402]
[2019-03-24 07:58:12,305] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.74160871666667, 47.05926316, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339987.1934304159, 339987.1934304159, 141778.1281374303]
[2019-03-24 07:58:12,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:58:12,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1766404e-07 6.9407059e-07 9.1635502e-07 9.9999487e-01 3.0429014e-06], sampled 0.23751573802015058
[2019-03-24 07:58:25,330] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01007294], dtype=float32), 0.007975402]
[2019-03-24 07:58:25,330] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 91.0, 1.0, 2.0, 0.2315532249476658, 1.0, 2.0, 0.2315532249476658, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553482.7959838343, 553482.7959838348, 166067.3756540687]
[2019-03-24 07:58:25,332] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:25,335] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8231241e-07 4.7865404e-07 6.2298955e-07 9.9999642e-01 2.1858639e-06], sampled 0.3581542469635002
[2019-03-24 07:58:30,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 07:58:30,309] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 07:58:30,315] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 07:58:30,461] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 07:58:30,567] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6345 2465981390.5545 46.0000
[2019-03-24 07:58:31,583] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1275000, evaluation results [1275000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.634450214236, 2465981390.554531, 46.0]
[2019-03-24 07:58:38,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3205533e-06 3.0768977e-06 2.8603233e-07 9.9997199e-01 2.3354989e-05], sum to 1.0000
[2019-03-24 07:58:38,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7832
[2019-03-24 07:58:38,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.61666666666667, 12.5, 1.0, 2.0, 0.1910948918489953, 1.0, 2.0, 0.1910948918489953, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489897.1683008009, 489897.1683008014, 158298.4290307036], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 155400.0000, 
sim time next is 156000.0000, 
raw observation next is [33.33333333333334, 13.0, 1.0, 2.0, 0.1883730782931911, 1.0, 2.0, 0.1883730782931911, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482985.0130672455, 482985.0130672455, 157732.782973859], 
processed observation next is [1.0, 0.8260869565217391, 0.7901234567901239, 0.13, 1.0, 1.0, 0.03377747415856084, 1.0, 1.0, 0.03377747415856084, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17249464752401625, 0.17249464752401625, 0.3033322749497288], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.96860254], dtype=float32), 1.1191169]. 
=============================================
[2019-03-24 07:58:38,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.754623]
 [57.818058]
 [57.941788]
 [57.934383]
 [57.7332  ]], R is [[57.93146133]
 [58.04772568]
 [58.1632843 ]
 [58.27726364]
 [58.38966751]].
[2019-03-24 07:58:43,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1532386e-06 3.1812338e-05 1.6104314e-05 9.9983537e-01 1.1348877e-04], sum to 1.0000
[2019-03-24 07:58:43,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7693
[2019-03-24 07:58:43,525] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 34.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 372373.8369667386, 372373.8369667391, 135488.6019185948], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 289800.0000, 
sim time next is 290400.0000, 
raw observation next is [24.33333333333333, 33.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 374468.6611776741, 374468.6611776745, 136269.4603650265], 
processed observation next is [0.0, 0.34782608695652173, 0.45679012345678993, 0.3366666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13373880756345502, 0.13373880756345516, 0.2620566545481279], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1382182], dtype=float32), 2.7328618]. 
=============================================
[2019-03-24 07:58:45,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3910121e-05 1.2672899e-04 6.5815361e-04 9.9816257e-01 1.0186452e-03], sum to 1.0000
[2019-03-24 07:58:45,159] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7500
[2019-03-24 07:58:45,163] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 34.0, 1.0, 2.0, 0.1752462322590833, 1.0, 2.0, 0.1752462322590833, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437403.2762807363, 437403.2762807363, 154848.0949508866], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 501600.0000, 
sim time next is 502200.0000, 
raw observation next is [29.1, 35.0, 1.0, 2.0, 0.1743323033962179, 1.0, 2.0, 0.1743323033962179, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 434944.1649709155, 434944.1649709159, 154655.6501871678], 
processed observation next is [1.0, 0.8260869565217391, 0.6333333333333334, 0.35, 1.0, 1.0, 0.017062265947878467, 1.0, 1.0, 0.017062265947878467, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15533720177532695, 0.1553372017753271, 0.29741471189839963], 
reward next is 0.7026, 
noisyNet noise sample is [array([-1.6023806], dtype=float32), 0.82677114]. 
=============================================
[2019-03-24 07:58:50,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.220192e-07 9.395627e-05 4.076645e-06 9.998952e-01 5.829381e-06], sum to 1.0000
[2019-03-24 07:58:50,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9297
[2019-03-24 07:58:50,503] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.73333333333333, 26.33333333333334, 1.0, 2.0, 0.39312373125336, 1.0, 2.0, 0.39312373125336, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 988905.8145031254, 988905.8145031249, 207509.603791287], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 391200.0000, 
sim time next is 391800.0000, 
raw observation next is [29.86666666666667, 26.16666666666667, 1.0, 2.0, 0.3966217565166484, 1.0, 2.0, 0.3966217565166484, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 996988.4072515157, 996988.4072515147, 208480.2892672782], 
processed observation next is [1.0, 0.5217391304347826, 0.6617283950617285, 0.2616666666666667, 1.0, 1.0, 0.28169256728172426, 1.0, 1.0, 0.28169256728172426, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.3560672883041127, 0.3560672883041124, 0.4009236332063042], 
reward next is 0.5991, 
noisyNet noise sample is [array([1.3666036], dtype=float32), 0.023427045]. 
=============================================
[2019-03-24 07:58:52,768] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0905694e-03 4.1511172e-05 8.4619451e-04 9.9793756e-01 8.4215753e-05], sum to 1.0000
[2019-03-24 07:58:52,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0404
[2019-03-24 07:58:52,777] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.93333333333334, 63.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399084.9834768666, 399084.9834768671, 151007.3059005868], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 520800.0000, 
sim time next is 521400.0000, 
raw observation next is [21.76666666666667, 64.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399264.6410003986, 399264.641000399, 151029.2405863146], 
processed observation next is [1.0, 0.0, 0.3617283950617285, 0.64, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1425945146429995, 0.14259451464299966, 0.29044084728137426], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22463565], dtype=float32), -0.86924326]. 
=============================================
[2019-03-24 07:58:56,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5425327e-06 2.7854905e-05 1.1049784e-04 9.9976259e-01 9.0457215e-05], sum to 1.0000
[2019-03-24 07:58:56,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7997
[2019-03-24 07:58:56,188] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.53333333333333, 63.0, 1.0, 2.0, 0.1947859019247231, 1.0, 2.0, 0.1947859019247231, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489310.0803654927, 489310.0803654932, 158974.6581030001], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 627600.0000, 
sim time next is 628200.0000, 
raw observation next is [22.8, 62.0, 1.0, 2.0, 0.1950773580899229, 1.0, 2.0, 0.1950773580899229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489518.8387678825, 489518.8387678825, 159025.934136128], 
processed observation next is [1.0, 0.2608695652173913, 0.4, 0.62, 1.0, 1.0, 0.041758759630860606, 1.0, 1.0, 0.041758759630860606, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17482815670281518, 0.17482815670281518, 0.30581910410793844], 
reward next is 0.6942, 
noisyNet noise sample is [array([1.4783932], dtype=float32), -0.4734369]. 
=============================================
[2019-03-24 07:59:05,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4471391e-04 9.9513316e-05 7.3959387e-04 9.9851757e-01 3.9860938e-04], sum to 1.0000
[2019-03-24 07:59:05,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2722
[2019-03-24 07:59:05,461] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 38.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397705.7050359992, 397705.7050359997, 150530.9775596021], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 696600.0000, 
sim time next is 697200.0000, 
raw observation next is [25.96666666666667, 38.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395881.6184483705, 395881.6184483705, 150217.8556809246], 
processed observation next is [1.0, 0.043478260869565216, 0.517283950617284, 0.3866666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14138629230298946, 0.14138629230298946, 0.2888804916940858], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5187838], dtype=float32), 0.80143404]. 
=============================================
[2019-03-24 07:59:09,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7519049e-07 1.5682768e-07 3.8349916e-07 9.9999356e-01 5.4896668e-06], sum to 1.0000
[2019-03-24 07:59:09,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5038
[2019-03-24 07:59:09,294] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.2, 65.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 395463.7512913982, 395463.7512913987, 150262.8284931651], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 883800.0000, 
sim time next is 884400.0000, 
raw observation next is [21.26666666666667, 65.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397364.309264531, 397364.309264531, 150594.9625556907], 
processed observation next is [0.0, 0.21739130434782608, 0.34320987654320995, 0.6566666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1419158247373325, 0.1419158247373325, 0.2896056972224821], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23828585], dtype=float32), -1.9827168]. 
=============================================
[2019-03-24 07:59:13,795] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0100502e-07 2.7473860e-07 2.0550683e-06 9.9999332e-01 3.4072782e-06], sum to 1.0000
[2019-03-24 07:59:13,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-24 07:59:13,806] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 52.0, 1.0, 2.0, 0.2166309700816708, 1.0, 2.0, 0.2166309700816708, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 526569.5558470949, 526569.5558470953, 163158.4306494838], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 910800.0000, 
sim time next is 911400.0000, 
raw observation next is [27.41666666666667, 51.33333333333334, 1.0, 2.0, 0.2176031808225194, 1.0, 2.0, 0.2176031808225194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528450.5809883494, 528450.5809883499, 163351.4056643445], 
processed observation next is [0.0, 0.5652173913043478, 0.5709876543209879, 0.5133333333333334, 1.0, 1.0, 0.06857521526490404, 1.0, 1.0, 0.06857521526490404, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18873235035298191, 0.18873235035298208, 0.3141373185852779], 
reward next is 0.6859, 
noisyNet noise sample is [array([0.5122039], dtype=float32), -0.9184948]. 
=============================================
[2019-03-24 07:59:17,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4562426e-04 3.0140067e-04 1.0230749e-04 9.9847049e-01 6.8020256e-04], sum to 1.0000
[2019-03-24 07:59:17,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-24 07:59:17,715] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.96666666666667, 67.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385395.3665520626, 385395.3665520631, 148815.9542411602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1047000.0000, 
sim time next is 1047600.0000, 
raw observation next is [20.9, 68.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384168.1618656706, 384168.1618656706, 148633.8424939144], 
processed observation next is [1.0, 0.13043478260869565, 0.32962962962962955, 0.68, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13720291495202522, 0.13720291495202522, 0.2858343124882969], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7250288], dtype=float32), 0.036425944]. 
=============================================
[2019-03-24 07:59:20,457] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 07:59:20,458] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:59:20,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:20,459] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:59:20,460] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:20,461] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:59:20,461] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:20,463] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:59:20,463] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:20,463] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:59:20,465] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:20,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-24 07:59:20,483] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-24 07:59:20,483] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-24 07:59:20,483] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-24 07:59:20,566] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-24 07:59:31,452] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 07:59:31,453] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.43680454, 64.09753843333333, 1.0, 2.0, 0.2028606107829703, 1.0, 2.0, 0.2028606107829703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 497110.6563613038, 497110.6563613043, 160358.6463857274]
[2019-03-24 07:59:31,456] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:59:31,457] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4379197e-05 2.8252671e-05 2.5618634e-05 9.9986720e-01 6.4477390e-05], sampled 0.6237493168135781
[2019-03-24 07:59:34,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 07:59:34,842] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666667, 22.66666666666666, 1.0, 2.0, 0.234635351159711, 1.0, 2.0, 0.234635351159711, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 581371.7929198932, 581371.7929198936, 167425.3132739818]
[2019-03-24 07:59:34,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:59:34,845] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7730612e-06 1.3860452e-05 1.2630873e-05 9.9993229e-01 3.4461587e-05], sampled 0.49524989755466076
[2019-03-24 07:59:50,027] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 07:59:50,029] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.58333333333334, 78.0, 1.0, 2.0, 0.2253530506043034, 1.0, 2.0, 0.2253530506043034, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540676.9098058568, 540676.9098058572, 164791.3818161252]
[2019-03-24 07:59:50,030] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:59:50,033] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4415921e-06 7.2424973e-06 6.6677630e-06 9.9996197e-01 2.0603522e-05], sampled 0.552120882966774
[2019-03-24 07:59:56,238] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 07:59:56,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.3022526007931394, 1.0, 2.0, 0.3022526007931394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698698.5881410378, 698698.5881410383, 181479.0174245057]
[2019-03-24 07:59:56,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:59:56,245] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1740976e-06 6.7081933e-06 6.2519725e-06 9.9996471e-01 1.9180743e-05], sampled 0.6835457669780016
[2019-03-24 08:00:04,470] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:04,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.907882965, 97.40167447333333, 1.0, 2.0, 0.3226655627453553, 1.0, 2.0, 0.3226655627453553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735465.0341684759, 735465.0341684764, 185989.4098482043]
[2019-03-24 08:00:04,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:00:04,475] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2475042e-06 1.2774442e-05 1.1692641e-05 9.9993646e-01 3.2732332e-05], sampled 0.28525415467644466
[2019-03-24 08:00:09,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:09,060] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.0, 61.5, 1.0, 2.0, 0.7729822183591103, 1.0, 2.0, 0.7729822183591103, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1763041.882971073, 1763041.882971072, 332720.3299365637]
[2019-03-24 08:00:09,061] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:09,063] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9212350e-06 4.0548189e-06 3.9992592e-06 9.9997902e-01 1.0946392e-05], sampled 0.9256591430398078
[2019-03-24 08:00:16,420] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:16,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 52.66666666666667, 1.0, 2.0, 0.6768374284700243, 1.0, 2.0, 0.6768374284700243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1572671.776817098, 1572671.776817099, 296922.309631944]
[2019-03-24 08:00:16,422] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:16,424] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3349996e-06 8.9023260e-06 8.4414796e-06 9.9995339e-01 2.4904957e-05], sampled 0.6561599409684813
[2019-03-24 08:00:25,968] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:25,970] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.73333333333333, 52.0, 1.0, 2.0, 0.2552509335121793, 1.0, 2.0, 0.2552509335121793, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 596449.8292378018, 596449.8292378023, 170793.4765797459]
[2019-03-24 08:00:25,971] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:00:25,975] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5047930e-06 1.2890341e-05 1.2528874e-05 9.9993801e-01 3.0039360e-05], sampled 0.9542003925095268
[2019-03-24 08:00:34,686] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:34,686] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.08333333333334, 57.83333333333334, 1.0, 2.0, 0.4893629377737945, 1.0, 2.0, 0.4893629377737945, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1115701.876785873, 1115701.876785873, 232114.5429643607]
[2019-03-24 08:00:34,688] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:34,691] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0273443e-06 6.3035368e-06 6.0135462e-06 9.9996746e-01 1.7204642e-05], sampled 0.7758056145536026
[2019-03-24 08:00:44,567] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:00:44,568] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 88.0, 1.0, 2.0, 0.2821273560925265, 1.0, 2.0, 0.2821273560925265, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 654135.278692659, 654135.2786926595, 176772.2637437333]
[2019-03-24 08:00:44,568] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:44,571] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0015161e-06 4.3685209e-06 3.9782822e-06 9.9997652e-01 1.3126346e-05], sampled 0.1757665009551007
[2019-03-24 08:01:01,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:01:01,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.16666666666667, 88.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 338675.9216775533, 338675.9216775533, 141316.1334312595]
[2019-03-24 08:01:01,828] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:01:01,829] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.5432913e-06 1.5465641e-05 1.3908098e-05 9.9992311e-01 3.9889059e-05], sampled 0.704262617097082
[2019-03-24 08:01:06,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01000037], dtype=float32), 0.0077422857]
[2019-03-24 08:01:06,199] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.1, 72.5, 1.0, 2.0, 0.2041353091699498, 1.0, 2.0, 0.2041353091699498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499579.5457147538, 499579.5457147538, 160606.971310575]
[2019-03-24 08:01:06,201] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:01:06,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6258751e-05 3.1471405e-05 2.9338042e-05 9.9985409e-01 6.8781374e-05], sampled 0.28527265780652056
[2019-03-24 08:01:06,438] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495471416.5651 47.0000
[2019-03-24 08:01:06,455] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.4954 2465978471.5501 46.0000
[2019-03-24 08:01:06,555] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7520.2946 2668565573.2883 68.0000
[2019-03-24 08:01:06,672] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.1599 2410750670.2005 22.0000
[2019-03-24 08:01:06,785] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2606 2438818407.1372 34.0000
[2019-03-24 08:01:07,802] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1300000, evaluation results [1300000.0, 7520.294623691396, 2668565573.2882843, 68.0, 7122.260633411203, 2438818407.137184, 34.0, 7798.159933053251, 2410750670.2004886, 22.0, 6905.908355438085, 2495471416.5650964, 47.0, 7478.495426658359, 2465978471.5500913, 46.0]
[2019-03-24 08:01:08,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3691247e-07 1.9911865e-06 3.6745976e-06 9.9999022e-01 3.7482662e-06], sum to 1.0000
[2019-03-24 08:01:08,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4992
[2019-03-24 08:01:08,174] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.83333333333333, 68.5, 1.0, 2.0, 0.3339455750341663, 1.0, 2.0, 0.3339455750341663, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832139.2166320868, 832139.2166320872, 191422.7595326804], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1177800.0000, 
sim time next is 1178400.0000, 
raw observation next is [21.76666666666667, 69.0, 1.0, 2.0, 0.3431658394490672, 1.0, 2.0, 0.3431658394490672, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 855400.0516375651, 855400.0516375656, 193827.3651361885], 
processed observation next is [1.0, 0.6521739130434783, 0.3617283950617285, 0.69, 1.0, 1.0, 0.21805457077269905, 1.0, 1.0, 0.21805457077269905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30550001844198754, 0.3055000184419877, 0.3727449329542087], 
reward next is 0.6273, 
noisyNet noise sample is [array([-0.4860924], dtype=float32), 0.76441705]. 
=============================================
[2019-03-24 08:01:13,295] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8300344e-06 1.3553076e-06 1.9612227e-07 9.9996197e-01 3.4688179e-05], sum to 1.0000
[2019-03-24 08:01:13,301] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1178
[2019-03-24 08:01:13,305] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.78333333333333, 76.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 358684.1325584982, 358684.1325584986, 144375.1586090275], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.86666666666667, 76.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 349015.4611896204, 349015.4611896209, 142961.9359409213], 
processed observation next is [1.0, 0.21739130434782608, 0.25432098765432115, 0.76, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.124648378996293, 0.12464837899629318, 0.27492679988638713], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3732909], dtype=float32), 2.1297138]. 
=============================================
[2019-03-24 08:01:13,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7239652e-05 5.9992686e-04 4.0219336e-05 9.9898750e-01 2.9505562e-04], sum to 1.0000
[2019-03-24 08:01:13,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7621
[2019-03-24 08:01:13,822] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 42.0, 1.0, 2.0, 0.3619077409566255, 1.0, 2.0, 0.3619077409566255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 906994.3503135585, 906994.3503135589, 198888.4943840916], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1084800.0000, 
sim time next is 1085400.0000, 
raw observation next is [26.45, 41.5, 1.0, 2.0, 0.4057248715101136, 1.0, 2.0, 0.4057248715101136, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013692.551218674, 1013692.551218674, 210948.6077039213], 
processed observation next is [1.0, 0.5652173913043478, 0.5351851851851852, 0.415, 1.0, 1.0, 0.2925296089406114, 1.0, 1.0, 0.2925296089406114, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3620330540066693, 0.3620330540066693, 0.4056703994306179], 
reward next is 0.5943, 
noisyNet noise sample is [array([1.802071], dtype=float32), -0.6351788]. 
=============================================
[2019-03-24 08:01:21,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8177796e-08 1.7435022e-07 4.6151133e-08 9.9999785e-01 1.9070399e-06], sum to 1.0000
[2019-03-24 08:01:21,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-24 08:01:21,862] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.35, 63.0, 1.0, 2.0, 0.306269268807315, 1.0, 2.0, 0.306269268807315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749646.4045346505, 749646.404534651, 184063.9993754499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1254600.0000, 
sim time next is 1255200.0000, 
raw observation next is [24.53333333333333, 62.33333333333333, 1.0, 2.0, 0.2739244506100475, 1.0, 2.0, 0.2739244506100475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670464.4516857876, 670464.4516857876, 176235.752078593], 
processed observation next is [1.0, 0.5217391304347826, 0.46419753086419746, 0.6233333333333333, 1.0, 1.0, 0.13562434596434225, 1.0, 1.0, 0.13562434596434225, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2394515898877813, 0.2394515898877813, 0.3389149078434481], 
reward next is 0.6611, 
noisyNet noise sample is [array([-0.07166882], dtype=float32), 0.7132411]. 
=============================================
[2019-03-24 08:01:22,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2297877e-07 3.5536530e-06 2.3643248e-07 9.9999380e-01 2.1780340e-06], sum to 1.0000
[2019-03-24 08:01:22,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7209
[2019-03-24 08:01:22,862] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.36666666666667, 86.66666666666667, 1.0, 2.0, 0.1866823601152972, 1.0, 2.0, 0.1866823601152972, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 468066.5162850836, 468066.5162850841, 157273.4550279178], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1304400.0000, 
sim time next is 1305000.0000, 
raw observation next is [19.3, 87.0, 1.0, 2.0, 0.1769373492794449, 1.0, 2.0, 0.1769373492794449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 444038.8394040145, 444038.8394040149, 155251.8171738319], 
processed observation next is [1.0, 0.08695652173913043, 0.27037037037037037, 0.87, 1.0, 1.0, 0.020163511046958217, 1.0, 1.0, 0.020163511046958217, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15858529978714805, 0.1585852997871482, 0.2985611868727536], 
reward next is 0.7014, 
noisyNet noise sample is [array([-0.42903277], dtype=float32), 0.9533827]. 
=============================================
[2019-03-24 08:01:22,893] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.403496]
 [66.56143 ]
 [66.568535]
 [66.24436 ]
 [66.490166]], R is [[66.64268494]
 [66.67380524]
 [66.69325256]
 [66.73011017]
 [66.76620483]].
[2019-03-24 08:01:31,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.71998045e-06 9.00168061e-07 1.16882056e-07 9.99994755e-01
 2.52204745e-06], sum to 1.0000
[2019-03-24 08:01:31,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5693
[2019-03-24 08:01:31,191] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 74.0, 1.0, 2.0, 0.2530807285932216, 1.0, 2.0, 0.2530807285932216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601367.0922144974, 601367.0922144974, 170738.1307192393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1539600.0000, 
sim time next is 1540200.0000, 
raw observation next is [24.2, 76.5, 1.0, 2.0, 0.2506801855988725, 1.0, 2.0, 0.2506801855988725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 596880.7825688256, 596880.7825688261, 170243.9623563238], 
processed observation next is [0.0, 0.8260869565217391, 0.45185185185185184, 0.765, 1.0, 1.0, 0.10795260190341965, 1.0, 1.0, 0.10795260190341965, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21317170806029487, 0.21317170806029503, 0.3273922353006227], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.06209102], dtype=float32), -0.8687287]. 
=============================================
[2019-03-24 08:01:33,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6054812e-06 2.7170066e-07 2.8109812e-06 9.9999404e-01 1.3618605e-06], sum to 1.0000
[2019-03-24 08:01:33,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2238
[2019-03-24 08:01:33,139] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.33333333333333, 87.0, 1.0, 2.0, 0.1617331846739739, 1.0, 2.0, 0.1617331846739739, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410544.6200389162, 410544.6200389162, 152225.2742913017], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1658400.0000, 
sim time next is 1659000.0000, 
raw observation next is [18.11666666666667, 88.5, 1.0, 2.0, 0.1625111846572361, 1.0, 2.0, 0.1625111846572361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 412680.0997343975, 412680.099734398, 152384.0144722399], 
processed observation next is [1.0, 0.17391304347826086, 0.22654320987654336, 0.885, 1.0, 1.0, 0.002989505544328689, 1.0, 1.0, 0.002989505544328689, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14738574990514197, 0.14738574990514214, 0.29304618167738444], 
reward next is 0.7070, 
noisyNet noise sample is [array([1.2959574], dtype=float32), 0.99265105]. 
=============================================
[2019-03-24 08:01:33,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.9718  ]
 [65.99463 ]
 [65.95454 ]
 [65.89902 ]
 [65.723885]], R is [[66.14884949]
 [66.19461823]
 [65.53266907]
 [65.58403015]
 [65.63047791]].
[2019-03-24 08:01:34,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0334587e-06 6.8325818e-07 2.0158703e-07 9.9997807e-01 2.0053607e-05], sum to 1.0000
[2019-03-24 08:01:34,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2139
[2019-03-24 08:01:34,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666667, 75.5, 1.0, 2.0, 0.3840570069548671, 1.0, 2.0, 0.3840570069548671, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 952374.5999458665, 952374.599945867, 204724.31667906], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1685400.0000, 
sim time next is 1686000.0000, 
raw observation next is [21.33333333333334, 75.0, 1.0, 2.0, 0.3005475468187552, 1.0, 2.0, 0.3005475468187552, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745659.2219823033, 745659.2219823038, 182915.3270324157], 
processed observation next is [1.0, 0.5217391304347826, 0.3456790123456792, 0.75, 1.0, 1.0, 0.16731850811756568, 1.0, 1.0, 0.16731850811756568, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2663068649936797, 0.2663068649936799, 0.3517602442931071], 
reward next is 0.6482, 
noisyNet noise sample is [array([-0.5882469], dtype=float32), -0.2515959]. 
=============================================
[2019-03-24 08:01:34,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.069168]
 [60.107155]
 [60.233753]
 [60.370026]
 [60.444874]], R is [[60.3818779 ]
 [60.38436127]
 [60.38599396]
 [60.39049149]
 [60.39845276]].
[2019-03-24 08:01:37,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6489861e-05 3.4023885e-06 1.1383306e-05 9.9986565e-01 1.0304021e-04], sum to 1.0000
[2019-03-24 08:01:37,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1686
[2019-03-24 08:01:37,380] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.45, 85.5, 1.0, 2.0, 0.1869940930493915, 1.0, 2.0, 0.1869940930493915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463569.3176326813, 463569.3176326817, 157209.3798209832], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1740600.0000, 
sim time next is 1741200.0000, 
raw observation next is [20.36666666666667, 86.0, 1.0, 2.0, 0.1860336584204584, 1.0, 2.0, 0.1860336584204584, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461357.2801210545, 461357.2801210549, 157012.7427230411], 
processed observation next is [1.0, 0.13043478260869565, 0.3098765432098767, 0.86, 1.0, 1.0, 0.03099245050054572, 1.0, 1.0, 0.03099245050054572, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1647704571860909, 0.16477045718609104, 0.3019475821596944], 
reward next is 0.6981, 
noisyNet noise sample is [array([-1.2264555], dtype=float32), -0.39870253]. 
=============================================
[2019-03-24 08:01:39,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6917134e-08 4.0326659e-06 1.3278812e-05 9.9997389e-01 8.7111484e-06], sum to 1.0000
[2019-03-24 08:01:39,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6223
[2019-03-24 08:01:39,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.2138694616800934, 1.0, 2.0, 0.2138694616800934, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520533.4859110983, 520533.4859110988, 162587.8027091501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1888200.0000, 
sim time next is 1888800.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.2135344624049722, 1.0, 2.0, 0.2135344624049722, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519722.3093043536, 519722.3093043536, 162516.0435757457], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 1.0, 1.0, 0.06373150286306214, 1.0, 1.0, 0.06373150286306214, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18561511046584056, 0.18561511046584056, 0.31253085303028016], 
reward next is 0.6875, 
noisyNet noise sample is [array([0.6415025], dtype=float32), -0.19097061]. 
=============================================
[2019-03-24 08:01:44,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3563325e-06 9.7772181e-07 5.7085515e-07 9.9999690e-01 1.8028055e-07], sum to 1.0000
[2019-03-24 08:01:44,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9666
[2019-03-24 08:01:44,785] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.35, 74.5, 1.0, 2.0, 0.215773376492308, 1.0, 2.0, 0.215773376492308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 524120.9759386794, 524120.9759386799, 162960.9570331465], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1709400.0000, 
sim time next is 1710000.0000, 
raw observation next is [23.3, 75.0, 1.0, 2.0, 0.2154561821075575, 1.0, 2.0, 0.2154561821075575, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523172.8795674262, 523172.8795674267, 162886.4557385904], 
processed observation next is [1.0, 0.8260869565217391, 0.41851851851851857, 0.75, 1.0, 1.0, 0.06601926441375891, 1.0, 1.0, 0.06601926441375891, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1868474569883665, 0.18684745698836666, 0.3132431841126738], 
reward next is 0.6868, 
noisyNet noise sample is [array([-0.8049458], dtype=float32), -0.23077781]. 
=============================================
[2019-03-24 08:01:44,803] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.044674]
 [61.104042]
 [60.873226]
 [60.69013 ]
 [60.394657]], R is [[61.11280823]
 [61.18829727]
 [61.26287079]
 [61.33670807]
 [61.4100914 ]].
[2019-03-24 08:01:48,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5424430e-07 2.5682421e-06 1.2454463e-07 9.9999690e-01 1.3309469e-07], sum to 1.0000
[2019-03-24 08:01:48,605] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7241
[2019-03-24 08:01:48,612] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.3, 91.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402263.365647319, 402263.365647319, 151575.9411095243], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1819800.0000, 
sim time next is 1820400.0000, 
raw observation next is [18.26666666666667, 91.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400792.4425301905, 400792.4425301905, 151346.612614995], 
processed observation next is [1.0, 0.043478260869565216, 0.23209876543209887, 0.9166666666666665, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1431401580464966, 0.1431401580464966, 0.29105117810575964], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.140906], dtype=float32), -1.0122963]. 
=============================================
[2019-03-24 08:01:49,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2249268e-06 2.9131425e-06 6.3645452e-06 9.9998248e-01 5.0919225e-06], sum to 1.0000
[2019-03-24 08:01:49,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7978
[2019-03-24 08:01:49,334] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.2139582831062573, 1.0, 2.0, 0.2139582831062573, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520752.8203539843, 520752.8203539848, 162606.9819919803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1887600.0000, 
sim time next is 1888200.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.2138694616800934, 1.0, 2.0, 0.2138694616800934, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520533.4859110983, 520533.4859110988, 162587.8027091501], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 1.0, 1.0, 0.06413031152392072, 1.0, 1.0, 0.06413031152392072, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18590481639682083, 0.185904816396821, 0.31266885136375017], 
reward next is 0.6873, 
noisyNet noise sample is [array([2.0265825], dtype=float32), 0.8825747]. 
=============================================
[2019-03-24 08:01:54,246] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1453246e-07 1.8468889e-06 4.5154891e-07 9.9999642e-01 1.0958893e-06], sum to 1.0000
[2019-03-24 08:01:54,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3233
[2019-03-24 08:01:54,259] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 92.0, 1.0, 2.0, 0.182828118341462, 1.0, 2.0, 0.182828118341462, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454199.224823771, 454199.224823771, 156364.9000392375], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1908000.0000, 
sim time next is 1908600.0000, 
raw observation next is [19.51666666666667, 92.0, 1.0, 2.0, 0.2218439743689164, 1.0, 2.0, 0.2218439743689164, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550773.661769908, 550773.6617699085, 164630.0642992169], 
processed observation next is [1.0, 0.08695652173913043, 0.2783950617283952, 0.92, 1.0, 1.0, 0.07362377901061476, 1.0, 1.0, 0.07362377901061476, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19670487920353857, 0.19670487920353874, 0.31659627749849406], 
reward next is 0.6834, 
noisyNet noise sample is [array([0.7811658], dtype=float32), -1.6432744]. 
=============================================
[2019-03-24 08:01:56,701] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 08:01:56,704] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:01:56,705] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:01:56,706] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:01:56,709] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:01:56,710] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:01:56,711] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:56,712] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:56,710] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:56,709] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:56,713] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:56,732] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-24 08:01:56,764] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-24 08:01:56,765] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-24 08:01:56,823] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-24 08:01:56,824] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-24 08:02:01,495] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:01,496] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.1, 21.5, 1.0, 2.0, 0.1743629804296878, 1.0, 2.0, 0.1743629804296878, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 443308.5518338104, 443308.5518338109, 154810.0218880503]
[2019-03-24 08:02:01,497] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:02:01,499] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3628293e-06 4.9743658e-06 4.8718534e-06 9.9997663e-01 1.1051311e-05], sampled 0.02348030632041931
[2019-03-24 08:02:04,646] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:04,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.55063765, 45.26971884, 1.0, 2.0, 0.2283322195953227, 1.0, 2.0, 0.2283322195953227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547555.382844981, 547555.3828449814, 165431.5197054559]
[2019-03-24 08:02:04,649] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:02:04,653] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2433469e-06 4.6917908e-06 4.6550435e-06 9.9997807e-01 1.0391954e-05], sampled 0.6641729142399783
[2019-03-24 08:02:05,391] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:05,393] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.21319234, 25.78862378, 1.0, 2.0, 0.2936387278244337, 1.0, 2.0, 0.2936387278244337, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714183.1281190541, 714183.1281190546, 180824.0677355691]
[2019-03-24 08:02:05,394] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:02:05,396] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7746099e-06 3.7603586e-06 3.7296579e-06 9.9998200e-01 8.7143271e-06], sampled 0.30964598834487456
[2019-03-24 08:02:11,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:11,935] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [38.66666666666667, 14.0, 1.0, 2.0, 0.5967149392454937, 1.0, 2.0, 0.5967149392454937, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1447219.253754719, 1447219.253754719, 270553.9543271465]
[2019-03-24 08:02:11,935] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:02:11,938] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7000862e-06 3.5034932e-06 3.6313877e-06 9.9998319e-01 7.9565752e-06], sampled 0.41674694878427165
[2019-03-24 08:02:22,394] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:22,395] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.91666666666667, 81.33333333333334, 1.0, 2.0, 0.1795729637898809, 1.0, 2.0, 0.1795729637898809, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 445747.8479157797, 445747.8479157801, 155678.1498415744]
[2019-03-24 08:02:22,395] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:02:22,397] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8189620e-06 3.9339634e-06 3.8097803e-06 9.9998152e-01 8.9586429e-06], sampled 0.39527249002592735
[2019-03-24 08:02:24,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:24,133] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.4, 43.66666666666667, 1.0, 2.0, 0.472045520250515, 1.0, 2.0, 0.472045520250515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1115642.29104662, 1115642.291046621, 228632.0558077574]
[2019-03-24 08:02:24,134] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:02:24,136] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0688467e-06 2.3693733e-06 2.2811046e-06 9.9998820e-01 6.0717416e-06], sampled 0.8696702819251986
[2019-03-24 08:02:27,202] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:27,203] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.683412935, 38.94691054499999, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 403578.0467637423, 403578.0467637427, 151674.2495631993]
[2019-03-24 08:02:27,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:02:27,208] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1750373e-06 4.5236702e-06 4.5542652e-06 9.9997878e-01 9.9548324e-06], sampled 0.37966801869228817
[2019-03-24 08:02:33,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:33,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.9, 55.0, 1.0, 2.0, 0.320857305149365, 1.0, 2.0, 0.320857305149365, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731341.4312654581, 731341.4312654585, 185541.8504424879]
[2019-03-24 08:02:33,175] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:02:33,179] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.9370568e-07 1.6383643e-06 1.7735972e-06 9.9999189e-01 3.7568113e-06], sampled 0.9242281967697785
[2019-03-24 08:02:55,119] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:02:55,123] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.45, 93.0, 1.0, 2.0, 0.284665073869205, 1.0, 2.0, 0.284665073869205, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658218.8365694726, 658218.8365694726, 177285.3940841139]
[2019-03-24 08:02:55,125] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:02:55,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2634701e-07 1.0146935e-06 9.5939697e-07 9.9999464e-01 2.8245615e-06], sampled 0.10149231178199847
[2019-03-24 08:03:08,133] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:03:08,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.45, 83.5, 1.0, 2.0, 0.6498297982499027, 1.0, 2.0, 0.6498297982499027, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1481905.25476884, 1481905.25476884, 285608.561402698]
[2019-03-24 08:03:08,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:03:08,139] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0652342e-06 2.3420641e-06 2.3189455e-06 9.9998820e-01 6.0408242e-06], sampled 0.8834287319019922
[2019-03-24 08:03:18,212] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:03:18,213] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.41666666666667, 79.0, 1.0, 2.0, 0.3344547051561251, 1.0, 2.0, 0.3344547051561251, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762349.8791502207, 762349.8791502207, 188934.9016683854]
[2019-03-24 08:03:18,216] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:03:18,218] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9478782e-07 1.3477197e-06 1.3055447e-06 9.9999332e-01 3.4985869e-06], sampled 0.4740542482445864
[2019-03-24 08:03:27,800] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01008908], dtype=float32), 0.0079043405]
[2019-03-24 08:03:27,800] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.9, 68.33333333333334, 1.0, 2.0, 0.2999280764994092, 1.0, 2.0, 0.2999280764994092, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683615.4272452302, 683615.4272452306, 180443.4151717881]
[2019-03-24 08:03:27,802] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:03:27,806] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8629013e-07 1.3491729e-06 1.2990890e-06 9.9999332e-01 3.5159399e-06], sampled 0.5533460664115271
[2019-03-24 08:03:41,977] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.9558 2465989904.6867 46.0000
[2019-03-24 08:03:42,309] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 08:03:42,494] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5310 2410721666.3579 22.0000
[2019-03-24 08:03:42,530] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:03:42,667] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:03:43,683] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1325000, evaluation results [1325000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7797.531024853822, 2410721666.357948, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.955848051994, 2465989904.6866508, 46.0]
[2019-03-24 08:03:44,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0623493e-05 5.8533522e-05 1.5756503e-05 9.9969935e-01 1.6579224e-04], sum to 1.0000
[2019-03-24 08:03:44,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6586
[2019-03-24 08:03:44,510] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666666, 87.66666666666667, 1.0, 2.0, 0.3862322667477813, 1.0, 2.0, 0.3862322667477813, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 930823.2108392285, 930823.210839228, 204552.653538568], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1935600.0000, 
sim time next is 1936200.0000, 
raw observation next is [21.78333333333333, 87.33333333333333, 1.0, 2.0, 0.3997376903973002, 1.0, 2.0, 0.3997376903973002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 961489.429137445, 961489.4291374455, 208233.8009452194], 
processed observation next is [1.0, 0.391304347826087, 0.3623456790123456, 0.8733333333333333, 1.0, 1.0, 0.2854020123777384, 1.0, 1.0, 0.2854020123777384, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3433890818348018, 0.343389081834802, 0.400449617202345], 
reward next is 0.5996, 
noisyNet noise sample is [array([0.38607717], dtype=float32), 0.8790746]. 
=============================================
[2019-03-24 08:03:46,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3038571e-08 6.5633594e-06 1.1982502e-07 9.9999201e-01 1.3366000e-06], sum to 1.0000
[2019-03-24 08:03:46,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4414
[2019-03-24 08:03:46,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.1827761696678923, 1.0, 2.0, 0.1827761696678923, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 454934.7871474361, 454934.7871474365, 156377.2600511274], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1987200.0000, 
sim time next is 1987800.0000, 
raw observation next is [19.5, 91.00000000000001, 1.0, 2.0, 0.1830318524048876, 1.0, 2.0, 0.1830318524048876, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455564.3234768042, 455564.3234768047, 156430.4239269007], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.9100000000000001, 1.0, 1.0, 0.027418871910580463, 1.0, 1.0, 0.027418871910580463, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16270154409885865, 0.1627015440988588, 0.3008277383209629], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.8469947], dtype=float32), 0.6183893]. 
=============================================
[2019-03-24 08:03:51,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6013545e-08 1.6209055e-08 2.5925166e-07 9.9999881e-01 9.1061941e-07], sum to 1.0000
[2019-03-24 08:03:51,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3958
[2019-03-24 08:03:51,027] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.61666666666667, 94.33333333333333, 1.0, 2.0, 0.2125951565364395, 1.0, 2.0, 0.2125951565364395, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 517242.1435533915, 517242.143553392, 162307.9542481176], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2091000.0000, 
sim time next is 2091600.0000, 
raw observation next is [20.5, 95.0, 1.0, 2.0, 0.2118266239921889, 1.0, 2.0, 0.2118266239921889, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515693.4992059682, 515693.4992059686, 162154.4926071762], 
processed observation next is [0.0, 0.21739130434782608, 0.3148148148148148, 0.95, 1.0, 1.0, 0.06169836189546298, 1.0, 1.0, 0.06169836189546298, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18417624971641722, 0.18417624971641736, 0.31183556270610807], 
reward next is 0.6882, 
noisyNet noise sample is [array([1.3482826], dtype=float32), -1.4131138]. 
=============================================
[2019-03-24 08:04:00,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3996879e-08 3.8295602e-06 3.7545551e-08 9.9999487e-01 1.2477103e-06], sum to 1.0000
[2019-03-24 08:04:00,033] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0953
[2019-03-24 08:04:00,035] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.36666666666667, 41.0, 1.0, 2.0, 0.2039271724675269, 1.0, 2.0, 0.2039271724675269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.2374046114, 498394.2374046114, 160540.7926174974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2398800.0000, 
sim time next is 2399400.0000, 
raw observation next is [29.2, 41.5, 1.0, 2.0, 0.2026928573449139, 1.0, 2.0, 0.2026928573449139, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495609.8301924938, 495609.8301924938, 160287.8167043847], 
processed observation next is [1.0, 0.782608695652174, 0.637037037037037, 0.415, 1.0, 1.0, 0.05082483017251655, 1.0, 1.0, 0.05082483017251655, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1770035107830335, 0.1770035107830335, 0.30824580135458596], 
reward next is 0.6918, 
noisyNet noise sample is [array([0.8566977], dtype=float32), 0.18418728]. 
=============================================
[2019-03-24 08:04:09,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4474259e-06 5.5130175e-05 6.8568188e-06 9.9985361e-01 7.5910917e-05], sum to 1.0000
[2019-03-24 08:04:09,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2162
[2019-03-24 08:04:09,033] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 38.5, 1.0, 2.0, 0.469022122550272, 1.0, 2.0, 0.469022122550272, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1140229.792427971, 1140229.792427971, 228847.6466573699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [29.7, 38.33333333333334, 1.0, 2.0, 0.4712740774367583, 1.0, 2.0, 0.4712740774367583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1144927.647313752, 1144927.647313753, 229510.9859520065], 
processed observation next is [1.0, 0.4782608695652174, 0.6555555555555556, 0.3833333333333334, 1.0, 1.0, 0.37056437790090274, 1.0, 1.0, 0.37056437790090274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40890273118348286, 0.4089027311834832, 0.4413672806769356], 
reward next is 0.5586, 
noisyNet noise sample is [array([-0.44709095], dtype=float32), -0.35103136]. 
=============================================
[2019-03-24 08:04:23,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0512432e-07 1.1731435e-05 1.0596279e-06 9.9998331e-01 3.5123521e-06], sum to 1.0000
[2019-03-24 08:04:23,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7510
[2019-03-24 08:04:23,142] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 92.0, 1.0, 2.0, 0.2884278288710471, 1.0, 2.0, 0.2884278288710471, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682561.490024125, 682561.4900241254, 178868.3780094936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2878200.0000, 
sim time next is 2878800.0000, 
raw observation next is [22.53333333333333, 91.33333333333334, 1.0, 2.0, 0.2758789743637144, 1.0, 2.0, 0.2758789743637144, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 652429.2697759192, 652429.2697759196, 175877.3544942953], 
processed observation next is [1.0, 0.30434782608695654, 0.3901234567901234, 0.9133333333333334, 1.0, 1.0, 0.13795115995680285, 1.0, 1.0, 0.13795115995680285, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2330104534913997, 0.23301045349139987, 0.3382256817197986], 
reward next is 0.6618, 
noisyNet noise sample is [array([0.5369936], dtype=float32), -0.26833498]. 
=============================================
[2019-03-24 08:04:31,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9567174e-08 3.0014343e-07 5.5048865e-08 9.9999940e-01 1.0687766e-07], sum to 1.0000
[2019-03-24 08:04:31,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5901
[2019-03-24 08:04:31,507] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3605292322116807, 1.0, 2.0, 0.3605292322116807, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821815.5366538906, 821815.5366538906, 195620.4800461393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2962200.0000, 
sim time next is 2962800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3907195398501945, 1.0, 2.0, 0.3907195398501945, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 890673.4217528201, 890673.4217528206, 203655.923824421], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.27466611886927916, 1.0, 1.0, 0.27466611886927916, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3180976506260072, 0.31809765062600737, 0.3916460073546558], 
reward next is 0.6084, 
noisyNet noise sample is [array([0.2778452], dtype=float32), -1.164766]. 
=============================================
[2019-03-24 08:04:32,760] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 08:04:32,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:04:32,764] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:04:32,765] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:32,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:04:32,768] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:04:32,766] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:32,774] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:32,771] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:04:32,776] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:32,777] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:32,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-24 08:04:32,824] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-24 08:04:32,854] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-24 08:04:32,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-24 08:04:32,885] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-24 08:04:49,656] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01003342], dtype=float32), 0.0079088155]
[2019-03-24 08:04:49,660] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.35, 32.0, 1.0, 2.0, 0.2101466219834977, 1.0, 2.0, 0.2101466219834977, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510704.0123534539, 510704.0123534544, 161764.1990592305]
[2019-03-24 08:04:49,660] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:04:49,663] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1032712e-07 2.4960460e-07 1.3501509e-07 9.9999940e-01 7.6213936e-08], sampled 0.936368137170851
[2019-03-24 08:05:02,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01003342], dtype=float32), 0.0079088155]
[2019-03-24 08:05:02,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666666, 78.0, 1.0, 2.0, 0.4891628621258308, 1.0, 2.0, 0.4891628621258308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1159859.567133451, 1159859.567133452, 234026.1915529892]
[2019-03-24 08:05:02,443] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:05:02,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0215453e-07 1.0313205e-06 6.2598588e-07 9.9999750e-01 3.5345576e-07], sampled 0.9558795728808462
[2019-03-24 08:05:49,242] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01003342], dtype=float32), 0.0079088155]
[2019-03-24 08:05:49,244] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.05, 87.5, 1.0, 2.0, 0.282671083392027, 1.0, 2.0, 0.282671083392027, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678957.2955178521, 678957.2955178525, 177887.7583997405]
[2019-03-24 08:05:49,245] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:05:49,250] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5599070e-07 3.4340007e-07 1.9064886e-07 9.9999917e-01 1.1034582e-07], sampled 0.8598171997756968
[2019-03-24 08:05:50,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01003342], dtype=float32), 0.0079088155]
[2019-03-24 08:05:50,767] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 44.0, 1.0, 2.0, 0.6045712787209997, 1.0, 2.0, 0.6045712787209997, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1378602.507916496, 1378602.507916496, 269616.8502000958]
[2019-03-24 08:05:50,769] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:05:50,774] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.0880178e-07 8.4023833e-07 5.1694053e-07 9.9999797e-01 2.7355682e-07], sampled 0.7216938777439198
[2019-03-24 08:06:18,303] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5310 2410721666.3579 22.0000
[2019-03-24 08:06:18,411] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7313 2495450836.4413 47.0000
[2019-03-24 08:06:18,575] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3781 2668540571.9406 68.0000
[2019-03-24 08:06:18,691] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3185 2465959841.1842 46.0000
[2019-03-24 08:06:18,789] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:06:19,805] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1350000, evaluation results [1350000.0, 7522.378092962498, 2668540571.9405866, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.531024853822, 2410721666.357948, 22.0, 6906.73134061905, 2495450836.441296, 47.0, 7478.318521483953, 2465959841.1841807, 46.0]
[2019-03-24 08:06:21,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6311397e-07 1.0179501e-07 2.3587709e-06 9.9999702e-01 3.5588417e-07], sum to 1.0000
[2019-03-24 08:06:21,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0298
[2019-03-24 08:06:21,292] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3578338806341264, 1.0, 2.0, 0.3578338806341264, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 815668.2946214838, 815668.2946214842, 194918.448396757], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3815165306411335, 1.0, 2.0, 0.3815165306411335, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869682.5942395737, 869682.5942395737, 201172.988028332], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2637101555251589, 1.0, 1.0, 0.2637101555251589, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31060092651413346, 0.31060092651413346, 0.3868711308237154], 
reward next is 0.6131, 
noisyNet noise sample is [array([-0.5837367], dtype=float32), 0.28242448]. 
=============================================
[2019-03-24 08:06:21,310] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.546528]
 [60.56786 ]
 [60.730972]
 [60.742344]
 [60.699856]], R is [[60.47819519]
 [60.49856949]
 [60.50155258]
 [60.53121185]
 [60.56184769]].
[2019-03-24 08:06:23,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3292400e-06 3.9172075e-05 5.2906262e-06 9.9994314e-01 9.9549334e-06], sum to 1.0000
[2019-03-24 08:06:23,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2491
[2019-03-24 08:06:23,609] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 85.66666666666667, 1.0, 2.0, 0.7459150862535349, 1.0, 2.0, 0.7459150862535349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1701247.539727448, 1701247.539727448, 321913.1919447332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2972400.0000, 
sim time next is 2973000.0000, 
raw observation next is [27.66666666666667, 84.83333333333333, 1.0, 2.0, 0.7613486612561772, 1.0, 2.0, 0.7613486612561772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1736481.91363824, 1736481.913638241, 328042.7956480741], 
processed observation next is [1.0, 0.391304347826087, 0.580246913580247, 0.8483333333333333, 1.0, 1.0, 0.7158912634002109, 1.0, 1.0, 0.7158912634002109, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6201721120136571, 0.6201721120136574, 0.6308515300924502], 
reward next is 0.3691, 
noisyNet noise sample is [array([-0.5746612], dtype=float32), 0.2336133]. 
=============================================
[2019-03-24 08:06:23,620] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[51.492012]
 [51.533173]
 [51.987392]
 [52.54751 ]
 [52.984295]], R is [[51.30857468]
 [51.17642593]
 [51.04687119]
 [50.94734573]
 [50.88156128]].
[2019-03-24 08:06:32,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1980376e-10 4.1130360e-08 2.0039364e-09 1.0000000e+00 6.7570380e-09], sum to 1.0000
[2019-03-24 08:06:32,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-24 08:06:32,117] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 49.0, 1.0, 2.0, 0.2866104560153719, 1.0, 2.0, 0.2866104560153719, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 662021.3457446035, 662021.345744604, 177711.8081246642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3261600.0000, 
sim time next is 3262200.0000, 
raw observation next is [30.56666666666667, 51.0, 1.0, 2.0, 0.2845816540498327, 1.0, 2.0, 0.2845816540498327, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657859.371571572, 657859.371571572, 177257.8157173704], 
processed observation next is [0.0, 0.782608695652174, 0.6876543209876544, 0.51, 1.0, 1.0, 0.1483114929164675, 1.0, 1.0, 0.1483114929164675, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23494977556127572, 0.23494977556127572, 0.34088041484109693], 
reward next is 0.6591, 
noisyNet noise sample is [array([-1.3422226], dtype=float32), 0.36227182]. 
=============================================
[2019-03-24 08:06:39,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4451167e-06 1.6730466e-05 1.0665414e-06 9.9997950e-01 1.3507389e-06], sum to 1.0000
[2019-03-24 08:06:39,822] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2507
[2019-03-24 08:06:39,827] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.88333333333333, 61.5, 1.0, 2.0, 0.2441189702445382, 1.0, 2.0, 0.2441189702445382, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580319.4988413113, 580319.4988413113, 168728.2002941257], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3228600.0000, 
sim time next is 3229200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.2485870297836777, 1.0, 2.0, 0.2485870297836777, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588867.9253580329, 588867.9253580329, 169645.610820636], 
processed observation next is [0.0, 0.391304347826087, 0.5555555555555556, 0.62, 1.0, 1.0, 0.10546074974247345, 1.0, 1.0, 0.10546074974247345, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21030997334215462, 0.21030997334215462, 0.32624155927045384], 
reward next is 0.6738, 
noisyNet noise sample is [array([1.8238194], dtype=float32), -0.7246339]. 
=============================================
[2019-03-24 08:06:41,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2587474e-06 7.4570590e-07 5.0129379e-06 9.9998653e-01 5.5317551e-06], sum to 1.0000
[2019-03-24 08:06:41,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1588
[2019-03-24 08:06:41,190] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.2, 76.0, 1.0, 2.0, 0.2279811600386111, 1.0, 2.0, 0.2279811600386111, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 552176.2378203196, 552176.2378203201, 165559.152381461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3560400.0000, 
sim time next is 3561000.0000, 
raw observation next is [23.16666666666666, 78.16666666666667, 1.0, 2.0, 0.2531863556125822, 1.0, 2.0, 0.2531863556125822, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611570.4708657942, 611570.4708657947, 171143.8101000124], 
processed observation next is [1.0, 0.21739130434782608, 0.41358024691358003, 0.7816666666666667, 1.0, 1.0, 0.1109361376340264, 1.0, 1.0, 0.1109361376340264, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21841802530921223, 0.2184180253092124, 0.3291227117307931], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.01840966], dtype=float32), 1.1488903]. 
=============================================
[2019-03-24 08:06:41,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[56.4132  ]
 [56.382774]
 [56.375557]
 [56.291443]
 [56.239555]], R is [[56.41614532]
 [56.53360367]
 [56.64852905]
 [56.75839233]
 [56.86347961]].
[2019-03-24 08:06:44,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7031605e-07 4.8911333e-09 6.2733446e-10 9.9999952e-01 2.9664143e-08], sum to 1.0000
[2019-03-24 08:06:44,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4710
[2019-03-24 08:06:44,199] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.45, 93.0, 1.0, 2.0, 0.2636637616049805, 1.0, 2.0, 0.2636637616049805, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621764.1691819209, 621764.1691819214, 172961.5807859324], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3288600.0000, 
sim time next is 3289200.0000, 
raw observation next is [22.26666666666667, 92.66666666666666, 1.0, 2.0, 0.2582057444391901, 1.0, 2.0, 0.2582057444391901, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611514.9687537698, 611514.9687537698, 171822.1267365873], 
processed observation next is [0.0, 0.043478260869565216, 0.38024691358024704, 0.9266666666666665, 1.0, 1.0, 0.11691160052284534, 1.0, 1.0, 0.11691160052284534, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21839820312634634, 0.21839820312634634, 0.33042716680112943], 
reward next is 0.6696, 
noisyNet noise sample is [array([-1.1252127], dtype=float32), 0.5057925]. 
=============================================
[2019-03-24 08:06:52,469] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3494172e-06 1.3884385e-06 2.1539250e-07 9.9999571e-01 1.9194164e-07], sum to 1.0000
[2019-03-24 08:06:52,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6019
[2019-03-24 08:06:52,480] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.23333333333333, 80.66666666666667, 1.0, 2.0, 0.3144084797339372, 1.0, 2.0, 0.3144084797339372, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716635.5239556778, 716635.5239556782, 183954.2777810627], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [25.85, 81.5, 1.0, 2.0, 0.3088793027521369, 1.0, 2.0, 0.3088793027521369, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 704027.0084034174, 704027.0084034179, 182605.0133199575], 
processed observation next is [1.0, 0.8260869565217391, 0.5129629629629631, 0.815, 1.0, 1.0, 0.17723726518111532, 1.0, 1.0, 0.17723726518111532, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514382172869348, 0.25143821728693494, 0.35116348715376444], 
reward next is 0.6488, 
noisyNet noise sample is [array([-0.67181563], dtype=float32), -0.69457203]. 
=============================================
[2019-03-24 08:06:54,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0191496e-06 5.5771284e-06 5.7694990e-05 9.9992228e-01 8.3691803e-06], sum to 1.0000
[2019-03-24 08:06:54,048] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-24 08:06:54,051] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8162894469935054, 1.0, 2.0, 0.8162894469935054, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1861921.307523084, 1861921.307523084, 350532.2891278192], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.8300459556600093, 1.0, 2.0, 0.8300459556600093, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1893332.573443381, 1893332.573443381, 356327.1333006516], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7976737567381063, 1.0, 1.0, 0.7976737567381063, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6761902048012075, 0.6761902048012075, 0.6852444871166378], 
reward next is 0.3148, 
noisyNet noise sample is [array([-0.3079138], dtype=float32), -0.59257746]. 
=============================================
[2019-03-24 08:06:56,313] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3032470e-07 1.3103283e-05 4.6440240e-07 9.9998415e-01 1.5102258e-06], sum to 1.0000
[2019-03-24 08:06:56,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0051
[2019-03-24 08:06:56,327] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 91.0, 1.0, 2.0, 0.2735261283048296, 1.0, 2.0, 0.2735261283048296, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635175.3685198958, 635175.3685198958, 174808.1182285153], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3627000.0000, 
sim time next is 3627600.0000, 
raw observation next is [23.4, 94.0, 1.0, 2.0, 0.2778880288681138, 1.0, 2.0, 0.2778880288681138, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642794.033011329, 642794.0330113295, 175706.5790970335], 
processed observation next is [1.0, 1.0, 0.42222222222222217, 0.94, 1.0, 1.0, 0.1403428915096593, 1.0, 1.0, 0.1403428915096593, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2295692975040461, 0.22956929750404625, 0.3378972674942952], 
reward next is 0.6621, 
noisyNet noise sample is [array([-0.28819767], dtype=float32), 0.44278345]. 
=============================================
[2019-03-24 08:06:57,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00387915e-07 4.04177899e-06 9.88164714e-08 9.99995708e-01
 5.86789328e-09], sum to 1.0000
[2019-03-24 08:06:57,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9433
[2019-03-24 08:06:57,466] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 91.0, 1.0, 2.0, 0.2816340440128402, 1.0, 2.0, 0.2816340440128402, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652516.1608652441, 652516.1608652441, 176633.8892535918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3623400.0000, 
sim time next is 3624000.0000, 
raw observation next is [23.8, 88.0, 1.0, 2.0, 0.2760024210994689, 1.0, 2.0, 0.2760024210994689, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641986.4578980848, 641986.4578980852, 175433.8724553789], 
processed observation next is [1.0, 0.9565217391304348, 0.43703703703703706, 0.88, 1.0, 1.0, 0.13809812035651056, 1.0, 1.0, 0.13809812035651056, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22928087782074455, 0.22928087782074472, 0.33737283164495946], 
reward next is 0.6626, 
noisyNet noise sample is [array([-0.98209745], dtype=float32), 1.3982091]. 
=============================================
[2019-03-24 08:06:57,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.32487 ]
 [68.22707 ]
 [68.217545]
 [68.12269 ]
 [67.95589 ]], R is [[68.31564331]
 [68.2928009 ]
 [68.26805115]
 [68.24175262]
 [68.21458435]].
[2019-03-24 08:06:58,220] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2227930e-05 5.8542440e-08 9.6132781e-06 9.9994755e-01 6.5387246e-07], sum to 1.0000
[2019-03-24 08:06:58,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9087
[2019-03-24 08:06:58,231] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.16666666666666, 95.83333333333334, 1.0, 2.0, 0.4657033055440938, 1.0, 2.0, 0.4657033055440938, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.4372032593953, 1072095.038365433, 1072095.038365433, 225549.5362567511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3636600.0000, 
sim time next is 3637200.0000, 
raw observation next is [23.13333333333333, 96.66666666666667, 1.0, 2.0, 0.3740681396553603, 1.0, 2.0, 0.3740681396553603, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 859339.153209922, 859339.1532099224, 199504.3926293343], 
processed observation next is [1.0, 0.08695652173913043, 0.41234567901234553, 0.9666666666666667, 1.0, 1.0, 0.2548430233992384, 1.0, 1.0, 0.2548430233992384, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.306906840432115, 0.30690684043211514, 0.38366229351795056], 
reward next is 0.6163, 
noisyNet noise sample is [array([0.6123393], dtype=float32), 0.07234879]. 
=============================================
[2019-03-24 08:07:00,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5610352e-05 5.7488096e-06 2.7433846e-06 9.9997437e-01 1.5567439e-06], sum to 1.0000
[2019-03-24 08:07:00,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-24 08:07:00,648] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.2915147309325513, 1.0, 2.0, 0.2915147309325513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668579.4998041617, 668579.4998041622, 178644.671563305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3631200.0000, 
sim time next is 3631800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2914607373343325, 1.0, 2.0, 0.2914607373343325, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668455.3379705658, 668455.3379705658, 178631.8303853816], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.15650087777896723, 1.0, 1.0, 0.15650087777896723, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23873404927520206, 0.23873404927520206, 0.34352275074111843], 
reward next is 0.6565, 
noisyNet noise sample is [array([-0.3346846], dtype=float32), 0.8036987]. 
=============================================
[2019-03-24 08:07:08,838] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 08:07:08,840] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:07:08,840] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:07:08,841] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:07:08,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:08,842] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:08,843] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:07:08,846] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:08,846] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:07:08,842] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:08,849] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:08,863] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-24 08:07:08,894] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-24 08:07:08,925] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-24 08:07:08,956] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-24 08:07:08,957] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-24 08:07:22,531] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:07:22,532] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.65, 77.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 386385.5895275315, 386385.589527532, 149035.8833359382]
[2019-03-24 08:07:22,534] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:07:22,536] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3136072e-07 1.1104730e-06 6.8696704e-07 9.9999750e-01 3.2034339e-07], sampled 0.49230409602595804
[2019-03-24 08:07:26,963] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:07:26,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 30.0, 1.0, 2.0, 0.2118626703512496, 1.0, 2.0, 0.2118626703512496, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514934.2664558938, 514934.2664558938, 162132.8370557471]
[2019-03-24 08:07:26,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:07:26,971] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4743263e-07 3.9917245e-07 2.3990478e-07 9.9999917e-01 1.0433533e-07], sampled 0.3568408494946882
[2019-03-24 08:07:28,823] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:07:28,825] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.91666666666667, 62.16666666666666, 1.0, 2.0, 0.1994670038927495, 1.0, 2.0, 0.1994670038927495, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509016.9949127916, 509016.9949127916, 160050.8228023804]
[2019-03-24 08:07:28,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:07:28,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.8711394e-07 9.8918269e-07 6.2083501e-07 9.9999774e-01 3.0221958e-07], sampled 0.7591872864598195
[2019-03-24 08:07:46,669] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:07:46,669] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333333, 85.66666666666667, 1.0, 2.0, 0.7459150862535349, 1.0, 2.0, 0.7459150862535349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1701247.539727448, 1701247.539727448, 321913.1919447332]
[2019-03-24 08:07:46,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:07:46,673] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.6082532e-07 1.6214813e-06 1.0660699e-06 9.9999619e-01 4.9654079e-07], sampled 0.648969535779862
[2019-03-24 08:07:57,721] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:07:57,722] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.9, 54.0, 1.0, 2.0, 0.5597751266359815, 1.0, 2.0, 0.5597751266359815, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1276368.835152854, 1276368.835152854, 254489.5728758471]
[2019-03-24 08:07:57,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:07:57,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8923591e-07 4.9691027e-07 3.1548356e-07 9.9999893e-01 1.3127604e-07], sampled 0.39255025755110606
[2019-03-24 08:08:18,485] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:08:18,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 62.66666666666667, 1.0, 2.0, 0.7926729984973034, 1.0, 2.0, 0.7926729984973034, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1807998.678924507, 1807998.678924507, 340736.8387900622]
[2019-03-24 08:08:18,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:08:18,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.4747301e-07 1.1014131e-06 7.3770968e-07 9.9999738e-01 3.1132683e-07], sampled 0.3872376223606683
[2019-03-24 08:08:23,782] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:08:23,785] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.33750355, 86.21605753333333, 1.0, 2.0, 0.2615238007072697, 1.0, 2.0, 0.2615238007072697, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616332.383256615, 616332.3832566155, 172453.2362155082]
[2019-03-24 08:08:23,786] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:08:23,787] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4052672e-07 3.8295164e-07 2.3144514e-07 9.9999917e-01 9.9065154e-08], sampled 0.6899812854540275
[2019-03-24 08:08:27,227] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:08:27,229] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 84.0, 1.0, 2.0, 0.2325733120838929, 1.0, 2.0, 0.2325733120838929, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 559119.1993514259, 559119.1993514263, 166416.883096048]
[2019-03-24 08:08:27,230] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:08:27,232] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6353617e-07 9.3810826e-07 5.8420483e-07 9.9999785e-01 2.6275782e-07], sampled 0.9044748023936786
[2019-03-24 08:08:28,570] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01004575], dtype=float32), 0.007924885]
[2019-03-24 08:08:28,571] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.82216461166666, 72.99271795166666, 1.0, 2.0, 0.2332476849809337, 1.0, 2.0, 0.2332476849809337, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556411.6876695799, 556411.6876695799, 166395.1186355229]
[2019-03-24 08:08:28,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:08:28,577] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5447488e-07 6.6395177e-07 4.1283417e-07 9.9999833e-01 1.8009247e-07], sampled 0.3910557620277184
[2019-03-24 08:08:54,337] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:08:54,345] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:08:54,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:08:54,417] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:08:54,448] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3655 2465940860.4540 46.0000
[2019-03-24 08:08:55,462] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1375000, evaluation results [1375000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.365512649934, 2465940860.453995, 46.0]
[2019-03-24 08:08:59,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2182912e-07 1.5294319e-06 3.6555743e-08 9.9999833e-01 1.2318445e-09], sum to 1.0000
[2019-03-24 08:08:59,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6269
[2019-03-24 08:08:59,976] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.75, 70.0, 1.0, 2.0, 0.3583415624769044, 1.0, 2.0, 0.3583415624769044, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 816826.1521088869, 816826.1521088873, 195051.4472534538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.36122555982814, 1.0, 2.0, 0.36122555982814, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823403.6470985591, 823403.6470985591, 195803.4423160545], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666666, 0.7, 1.0, 1.0, 0.23955423789064284, 1.0, 1.0, 0.23955423789064284, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29407273110662824, 0.29407273110662824, 0.3765450813770279], 
reward next is 0.6235, 
noisyNet noise sample is [array([0.6015982], dtype=float32), 0.8121949]. 
=============================================
[2019-03-24 08:09:00,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4884222e-05 3.9639458e-06 1.4212585e-05 9.9993503e-01 1.8778466e-06], sum to 1.0000
[2019-03-24 08:09:00,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-24 08:09:00,093] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.06666666666667, 87.33333333333333, 1.0, 2.0, 0.802422378408377, 1.0, 2.0, 0.802422378408377, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1830258.709865392, 1830258.709865391, 344756.1742605966], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4016400.0000, 
sim time next is 4017000.0000, 
raw observation next is [26.03333333333333, 88.16666666666667, 1.0, 2.0, 0.8260449031980148, 1.0, 2.0, 0.8260449031980148, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1884196.556949317, 1884196.556949317, 354633.9733680312], 
processed observation next is [1.0, 0.4782608695652174, 0.519753086419753, 0.8816666666666667, 1.0, 1.0, 0.7929105990452557, 1.0, 1.0, 0.7929105990452557, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6729273417676133, 0.6729273417676133, 0.681988410323137], 
reward next is 0.3180, 
noisyNet noise sample is [array([-0.9153866], dtype=float32), -1.2529198]. 
=============================================
[2019-03-24 08:09:00,104] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[51.82355 ]
 [52.19779 ]
 [52.027157]
 [51.89577 ]
 [51.335934]], R is [[51.63825989]
 [51.45888519]
 [51.32818985]
 [51.21450424]
 [51.11603165]].
[2019-03-24 08:09:00,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3408119e-08 1.3708737e-06 9.0982297e-08 9.9999785e-01 7.2076813e-07], sum to 1.0000
[2019-03-24 08:09:00,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4967
[2019-03-24 08:09:01,004] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.75, 69.83333333333333, 1.0, 2.0, 0.3667464043587109, 1.0, 2.0, 0.3667464043587109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 835995.122372612, 835995.1223726125, 197250.3691490061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3874200.0000, 
sim time next is 3874800.0000, 
raw observation next is [29.6, 70.66666666666667, 1.0, 2.0, 0.3640845690994012, 1.0, 2.0, 0.3640845690994012, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 829924.2078165864, 829924.2078165868, 196551.3084917182], 
processed observation next is [0.0, 0.8695652173913043, 0.6518518518518519, 0.7066666666666667, 1.0, 1.0, 0.24295782035643, 1.0, 1.0, 0.24295782035643, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29640150279163796, 0.2964015027916381, 0.37798328556099653], 
reward next is 0.6220, 
noisyNet noise sample is [array([-0.48684895], dtype=float32), 1.1164814]. 
=============================================
[2019-03-24 08:09:12,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.48857779e-08 2.46059173e-08 1.16893535e-08 1.00000000e+00
 7.95700039e-09], sum to 1.0000
[2019-03-24 08:09:12,060] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9498
[2019-03-24 08:09:12,066] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 47.83333333333333, 1.0, 2.0, 0.2407188459994791, 1.0, 2.0, 0.2407188459994791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 573425.37135514, 573425.3713551403, 168017.9727229614], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4219800.0000, 
sim time next is 4220400.0000, 
raw observation next is [29.53333333333334, 50.66666666666667, 1.0, 2.0, 0.2501330445429423, 1.0, 2.0, 0.2501330445429423, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591217.5206607566, 591217.5206607571, 169938.436062424], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493829, 0.5066666666666667, 1.0, 1.0, 0.1073012435035027, 1.0, 1.0, 0.1073012435035027, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2111491145216988, 0.21114911452169896, 0.3268046847354308], 
reward next is 0.6732, 
noisyNet noise sample is [array([1.7026323], dtype=float32), 0.14891802]. 
=============================================
[2019-03-24 08:09:13,604] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0785761e-05 1.5034494e-06 1.1916022e-05 9.9993014e-01 4.5602435e-05], sum to 1.0000
[2019-03-24 08:09:13,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9634
[2019-03-24 08:09:13,622] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 72.0, 1.0, 2.0, 0.6799656078158018, 1.0, 2.0, 0.6799656078158018, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1550698.086608561, 1550698.086608561, 296649.5947548952], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4180200.0000, 
sim time next is 4180800.0000, 
raw observation next is [27.66666666666667, 70.0, 1.0, 2.0, 0.6918421611618985, 1.0, 2.0, 0.6918421611618985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1577811.109785243, 1577811.109785243, 301087.6022366504], 
processed observation next is [1.0, 0.391304347826087, 0.580246913580247, 0.7, 1.0, 1.0, 0.633145429954641, 1.0, 1.0, 0.633145429954641, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5635039677804439, 0.5635039677804439, 0.5790146196858662], 
reward next is 0.4210, 
noisyNet noise sample is [array([1.9779199], dtype=float32), -0.7585334]. 
=============================================
[2019-03-24 08:09:18,255] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3247214e-07 3.8898244e-07 4.5125205e-07 9.9999583e-01 3.2355335e-06], sum to 1.0000
[2019-03-24 08:09:18,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3603
[2019-03-24 08:09:18,270] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.91666666666666, 36.33333333333334, 1.0, 2.0, 0.6848944958489357, 1.0, 2.0, 0.6848944958489357, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1618548.274796141, 1618548.274796141, 301153.631270617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4273800.0000, 
sim time next is 4274400.0000, 
raw observation next is [31.93333333333334, 36.66666666666667, 1.0, 2.0, 0.6295556952503563, 1.0, 2.0, 0.6295556952503563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1487125.862071081, 1487125.862071081, 280742.3009809763], 
processed observation next is [1.0, 0.4782608695652174, 0.7382716049382719, 0.3666666666666667, 1.0, 1.0, 0.5589948752980431, 1.0, 1.0, 0.5589948752980431, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5311163793111003, 0.5311163793111003, 0.5398890403480314], 
reward next is 0.4601, 
noisyNet noise sample is [array([0.36994082], dtype=float32), 1.1996213]. 
=============================================
[2019-03-24 08:09:20,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5428949e-07 2.6895279e-07 1.6695699e-08 9.9999881e-01 2.2610242e-07], sum to 1.0000
[2019-03-24 08:09:20,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3943
[2019-03-24 08:09:20,073] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 76.0, 1.0, 2.0, 0.338956760940869, 1.0, 2.0, 0.338956760940869, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 772616.9537954936, 772616.953795494, 190072.4381794323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4393800.0000, 
sim time next is 4394400.0000, 
raw observation next is [27.93333333333333, 77.0, 1.0, 2.0, 0.3430404537540631, 1.0, 2.0, 0.3430404537540631, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 781930.0579557329, 781930.0579557334, 191110.5345669321], 
processed observation next is [1.0, 0.8695652173913043, 0.5901234567901233, 0.77, 1.0, 1.0, 0.21790530208817038, 1.0, 1.0, 0.21790530208817038, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27926073498419035, 0.2792607349841905, 0.3675202587825617], 
reward next is 0.6325, 
noisyNet noise sample is [array([0.36823735], dtype=float32), 0.1488388]. 
=============================================
[2019-03-24 08:09:21,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9375940e-07 1.7545552e-06 7.7810552e-07 9.9999499e-01 2.0913599e-06], sum to 1.0000
[2019-03-24 08:09:21,371] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4031
[2019-03-24 08:09:21,376] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.03333333333333, 92.0, 1.0, 2.0, 0.3855086997585194, 1.0, 2.0, 0.3855086997585194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 881233.1213373102, 881233.1213373106, 202364.6222217996], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4330200.0000, 
sim time next is 4330800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.417431143064727, 1.0, 2.0, 0.417431143064727, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 951602.2560966006, 951602.2560966006, 211028.0036343176], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.3064656465056274, 1.0, 1.0, 0.3064656465056274, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3398579486059288, 0.3398579486059288, 0.4058230839121492], 
reward next is 0.5942, 
noisyNet noise sample is [array([0.93819124], dtype=float32), 0.3259286]. 
=============================================
[2019-03-24 08:09:22,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3935079e-07 4.7512117e-08 5.8706041e-07 9.9999881e-01 5.0712219e-07], sum to 1.0000
[2019-03-24 08:09:22,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2997
[2019-03-24 08:09:22,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 54.5, 1.0, 2.0, 0.2877391941224455, 1.0, 2.0, 0.2877391941224455, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660874.225245118, 660874.2252451185, 177797.3024715394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4301400.0000, 
sim time next is 4302000.0000, 
raw observation next is [30.0, 55.0, 1.0, 2.0, 0.287387809933166, 1.0, 2.0, 0.287387809933166, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660778.4310300383, 660778.4310300387, 177749.1009954621], 
processed observation next is [1.0, 0.8260869565217391, 0.6666666666666666, 0.55, 1.0, 1.0, 0.15165215468234045, 1.0, 1.0, 0.15165215468234045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23599229679644224, 0.2359922967964424, 0.3418251942220425], 
reward next is 0.6582, 
noisyNet noise sample is [array([0.62274575], dtype=float32), 1.1511544]. 
=============================================
[2019-03-24 08:09:22,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[65.66929 ]
 [65.670166]
 [65.48855 ]
 [65.59805 ]
 [65.68355 ]], R is [[65.32505035]
 [65.32987976]
 [65.33426666]
 [65.33802032]
 [65.34185028]].
[2019-03-24 08:09:22,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2600951e-06 1.5454436e-06 1.0187664e-06 9.9998844e-01 1.8038145e-06], sum to 1.0000
[2019-03-24 08:09:22,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0137
[2019-03-24 08:09:22,547] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 82.5, 1.0, 2.0, 0.7496378004585069, 1.0, 2.0, 0.7496378004585069, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1709746.253824693, 1709746.253824693, 323382.5889510302], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4350600.0000, 
sim time next is 4351200.0000, 
raw observation next is [26.4, 81.33333333333334, 1.0, 2.0, 0.7365103124796059, 1.0, 2.0, 0.7365103124796059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1679777.413800771, 1679777.413800771, 318217.1795475397], 
processed observation next is [1.0, 0.34782608695652173, 0.5333333333333333, 0.8133333333333335, 1.0, 1.0, 0.6863218005709594, 1.0, 1.0, 0.6863218005709594, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5999205049288469, 0.5999205049288469, 0.6119561145144994], 
reward next is 0.3880, 
noisyNet noise sample is [array([-0.9722607], dtype=float32), -2.1039472]. 
=============================================
[2019-03-24 08:09:28,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3676509e-07 1.3360011e-06 2.5048658e-08 9.9999583e-01 2.5807708e-06], sum to 1.0000
[2019-03-24 08:09:28,668] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7958
[2019-03-24 08:09:28,672] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.95, 85.0, 1.0, 2.0, 0.2901997939701543, 1.0, 2.0, 0.2901997939701543, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666572.7158675704, 666572.7158675708, 178382.2803347774], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4437000.0000, 
sim time next is 4437600.0000, 
raw observation next is [25.3, 84.66666666666667, 1.0, 2.0, 0.2979503430561294, 1.0, 2.0, 0.2979503430561294, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679901.0577988403, 679901.0577988407, 180009.6809143985], 
processed observation next is [0.0, 0.34782608695652173, 0.49259259259259264, 0.8466666666666667, 1.0, 1.0, 0.1642265988763445, 1.0, 1.0, 0.1642265988763445, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2428218063567287, 0.24282180635672881, 0.34617246329692014], 
reward next is 0.6538, 
noisyNet noise sample is [array([0.10741716], dtype=float32), 2.0477147]. 
=============================================
[2019-03-24 08:09:35,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2683973e-06 1.3537311e-05 4.8232505e-06 9.9997437e-01 4.9884547e-06], sum to 1.0000
[2019-03-24 08:09:35,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0484
[2019-03-24 08:09:35,270] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.3059969904485996, 1.0, 2.0, 0.3059969904485996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697548.339781623, 697548.3397816235, 181910.5696138874], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4558200.0000, 
sim time next is 4558800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3058501178386741, 1.0, 2.0, 0.3058501178386741, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697213.2288315509, 697213.2288315514, 181875.0161113854], 
processed observation next is [0.0, 0.782608695652174, 0.4444444444444444, 0.94, 1.0, 1.0, 0.17363109266508822, 1.0, 1.0, 0.17363109266508822, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24900472458269676, 0.24900472458269693, 0.34975964636804885], 
reward next is 0.6502, 
noisyNet noise sample is [array([0.10344553], dtype=float32), 0.20645586]. 
=============================================
[2019-03-24 08:09:36,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3716388e-07 3.9010815e-06 2.5760673e-07 9.9999559e-01 9.4083653e-08], sum to 1.0000
[2019-03-24 08:09:36,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3126
[2019-03-24 08:09:36,355] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2452249089745927, 1.0, 2.0, 0.2452249089745927, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585090.7789500315, 585090.778950032, 169063.1283397494], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2435121854540588, 1.0, 2.0, 0.2435121854540588, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 581640.2062659097, 581640.2062659102, 168704.5583842187], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.09941926839768905, 1.0, 1.0, 0.09941926839768905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20772864509496775, 0.2077286450949679, 0.3244318430465744], 
reward next is 0.6756, 
noisyNet noise sample is [array([-0.5200356], dtype=float32), 2.4762475]. 
=============================================
[2019-03-24 08:09:37,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4046370e-08 2.1605850e-09 8.1241758e-08 9.9999976e-01 1.7383569e-07], sum to 1.0000
[2019-03-24 08:09:37,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0425
[2019-03-24 08:09:37,609] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 86.5, 1.0, 2.0, 0.8002121292938151, 1.0, 2.0, 0.8002121292938151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1825212.164524829, 1825212.16452483, 343843.3072769307], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4811400.0000, 
sim time next is 4812000.0000, 
raw observation next is [28.06666666666667, 85.66666666666667, 1.0, 2.0, 0.8122420200988671, 1.0, 2.0, 0.8122420200988671, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1852679.725063776, 1852679.725063776, 348840.3323654967], 
processed observation next is [1.0, 0.6956521739130435, 0.5950617283950619, 0.8566666666666667, 1.0, 1.0, 0.7764785953557942, 1.0, 1.0, 0.7764785953557942, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.66167133037992, 0.66167133037992, 0.6708467930105706], 
reward next is 0.3292, 
noisyNet noise sample is [array([-1.2426319], dtype=float32), 2.2141736]. 
=============================================
[2019-03-24 08:09:37,623] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.82679 ]
 [60.28041 ]
 [60.444767]
 [59.330185]
 [58.816666]], R is [[60.49230957]
 [60.22615051]
 [59.95622635]
 [59.73852921]
 [59.43435669]].
[2019-03-24 08:09:44,499] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 08:09:44,500] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:09:44,500] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:09:44,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:09:44,502] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:09:44,503] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:09:44,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:09:44,505] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:09:44,505] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:09:44,505] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:09:44,507] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:09:44,528] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-24 08:09:44,528] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-24 08:09:44,558] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-24 08:09:44,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-24 08:09:44,660] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-24 08:09:48,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:09:48,603] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.36666666666667, 29.33333333333333, 1.0, 2.0, 0.1708954560560906, 1.0, 2.0, 0.1708954560560906, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434851.0870105112, 434851.0870105112, 154099.4525153806]
[2019-03-24 08:09:48,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:09:48,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7631223e-07 1.4146049e-06 1.1897464e-06 9.9999523e-01 1.5949958e-06], sampled 0.05960623158903966
[2019-03-24 08:10:33,213] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:10:33,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.25, 82.0, 1.0, 2.0, 0.3134611471699133, 1.0, 2.0, 0.3134611471699133, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714475.2496856889, 714475.2496856893, 183722.5361498744]
[2019-03-24 08:10:33,216] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:10:33,220] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7406017e-07 6.9768009e-07 5.9101325e-07 9.9999762e-01 8.0000245e-07], sampled 0.20682412753571622
[2019-03-24 08:10:41,687] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:10:41,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.66666666666667, 78.83333333333334, 1.0, 2.0, 0.209804540757409, 1.0, 2.0, 0.209804540757409, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 510001.7774768372, 510001.7774768368, 161695.7864876447]
[2019-03-24 08:10:41,690] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:10:41,692] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8032259e-07 4.8535782e-07 3.8629730e-07 9.9999833e-01 6.3258597e-07], sampled 0.45038599471407736
[2019-03-24 08:10:56,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:10:56,415] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.52308345333334, 85.34390123833334, 1.0, 2.0, 0.4931064097432659, 1.0, 2.0, 0.4931064097432659, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1124242.905741565, 1124242.905741564, 233262.2092473475]
[2019-03-24 08:10:56,416] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:10:56,419] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6939242e-07 6.8388107e-07 5.8172623e-07 9.9999762e-01 8.3913056e-07], sampled 0.2689755941523049
[2019-03-24 08:10:57,460] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:10:57,462] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.33333333333334, 35.33333333333334, 1.0, 2.0, 0.9466787890858341, 1.0, 2.0, 0.9466787890858341, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.5560743954395, 2159680.026495052, 2159680.026495052, 408183.8660400449]
[2019-03-24 08:10:57,463] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:10:57,466] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0209728e-07 7.3827414e-07 6.7204343e-07 9.9999738e-01 8.9675507e-07], sampled 0.6819919399038733
[2019-03-24 08:11:27,861] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01011278], dtype=float32), 0.008106878]
[2019-03-24 08:11:27,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.424134195, 65.45408710500001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 354293.3807774124, 354293.3807774129, 143791.5151136049]
[2019-03-24 08:11:27,864] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:11:27,867] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.3337294e-07 1.3251461e-06 1.0869991e-06 9.9999535e-01 1.6700675e-06], sampled 0.7679947092829738
[2019-03-24 08:11:29,602] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:11:29,808] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2636 2438818757.2692 34.0000
[2019-03-24 08:11:29,843] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:11:29,900] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:11:30,059] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:11:31,076] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1400000, evaluation results [1400000.0, 7523.727130323888, 2668527814.010175, 68.0, 7122.263554302433, 2438818757.2691865, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:11:32,401] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2814652e-07 4.4790283e-07 1.7844682e-06 9.9999714e-01 4.8103306e-07], sum to 1.0000
[2019-03-24 08:11:32,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9791
[2019-03-24 08:11:32,419] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6022936508474727, 1.0, 2.0, 0.6022936508474727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1373404.181671214, 1373404.181671215, 268831.3349592068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4798800.0000, 
sim time next is 4799400.0000, 
raw observation next is [26.25, 88.33333333333334, 1.0, 2.0, 0.6234549860856085, 1.0, 2.0, 0.6234549860856085, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1421702.949389113, 1421702.949389113, 276203.5052055251], 
processed observation next is [1.0, 0.5652173913043478, 0.5277777777777778, 0.8833333333333334, 1.0, 1.0, 0.551732126292391, 1.0, 1.0, 0.551732126292391, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5077510533532547, 0.5077510533532547, 0.531160586933702], 
reward next is 0.4688, 
noisyNet noise sample is [array([-1.7303168], dtype=float32), -0.045644768]. 
=============================================
[2019-03-24 08:11:35,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7096166e-07 3.5599615e-07 1.4537212e-05 9.9998462e-01 1.7984988e-07], sum to 1.0000
[2019-03-24 08:11:35,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-24 08:11:35,899] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.36666666666667, 97.33333333333333, 1.0, 2.0, 0.3539355066203271, 1.0, 2.0, 0.3539355066203271, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806777.4272089533, 806777.4272089533, 193908.2674679055], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4837200.0000, 
sim time next is 4837800.0000, 
raw observation next is [25.18333333333334, 98.66666666666667, 1.0, 2.0, 0.3535396386724554, 1.0, 2.0, 0.3535396386724554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805874.5926069347, 805874.5926069352, 193805.8928546624], 
processed observation next is [1.0, 1.0, 0.4882716049382719, 0.9866666666666667, 1.0, 1.0, 0.2304043317529231, 1.0, 1.0, 0.2304043317529231, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28781235450247666, 0.28781235450247683, 0.37270364010512], 
reward next is 0.6273, 
noisyNet noise sample is [array([0.90109384], dtype=float32), -0.35721928]. 
=============================================
[2019-03-24 08:11:37,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1019642e-06 4.3027860e-05 5.9835511e-06 9.9994707e-01 8.5223274e-07], sum to 1.0000
[2019-03-24 08:11:37,223] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0526
[2019-03-24 08:11:37,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3125206.820137525 W.
[2019-03-24 08:11:37,238] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 85.66666666666666, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9515344554570703, 1.0, 1.0, 0.9977734948820727, 7.223294659383785, 6.9112, 121.94756008, 3125206.820137525, 2965358.25478895, 552651.8413457456], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4894800.0000, 
sim time next is 4895400.0000, 
raw observation next is [30.16666666666666, 87.33333333333334, 1.0, 2.0, 0.8454559393549071, 1.0, 2.0, 0.7360926316538883, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2519419.439796573, 2519419.439796573, 470613.5746960005], 
processed observation next is [1.0, 0.6521739130434783, 0.6728395061728393, 0.8733333333333334, 1.0, 1.0, 0.8160189754225085, 1.0, 1.0, 0.6858245614927241, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8997926570702046, 0.8997926570702046, 0.9050261051846163], 
reward next is 0.0950, 
noisyNet noise sample is [array([1.1252729], dtype=float32), -0.61030775]. 
=============================================
[2019-03-24 08:11:39,883] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2836511e-07 2.1454271e-05 1.0829276e-04 9.9985528e-01 1.4258830e-05], sum to 1.0000
[2019-03-24 08:11:39,888] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9043
[2019-03-24 08:11:39,891] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.3412179080733336, 1.0, 2.0, 0.3412179080733336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 786929.7742990463, 786929.7742990467, 191086.385944484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4939200.0000, 
sim time next is 4939800.0000, 
raw observation next is [24.08333333333333, 87.33333333333334, 1.0, 2.0, 0.3280537612750141, 1.0, 2.0, 0.3280537612750141, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758828.0958117247, 758828.0958117251, 187860.7605778918], 
processed observation next is [1.0, 0.17391304347826086, 0.4475308641975307, 0.8733333333333334, 1.0, 1.0, 0.20006400151787396, 1.0, 1.0, 0.20006400151787396, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2710100342184731, 0.27101003421847325, 0.3612706934190227], 
reward next is 0.6387, 
noisyNet noise sample is [array([2.3734477], dtype=float32), 1.4545188]. 
=============================================
[2019-03-24 08:11:45,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7599499e-05 7.9427075e-05 4.0157649e-04 9.9907124e-01 3.7017794e-04], sum to 1.0000
[2019-03-24 08:11:45,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0337
[2019-03-24 08:11:45,145] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 100.0, 1.0, 2.0, 0.3758835418673776, 1.0, 2.0, 0.3758835418673776, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856834.7873136892, 856834.7873136896, 199667.3659845272], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5208600.0000, 
sim time next is 5209200.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3826474181568456, 1.0, 2.0, 0.3826474181568456, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 872261.965737222, 872261.9657372225, 201476.3105889573], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 1.0, 1.0, 1.0, 0.26505645018672097, 1.0, 1.0, 0.26505645018672097, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31152213062043643, 0.3115221306204366, 0.3874544434403025], 
reward next is 0.6125, 
noisyNet noise sample is [array([-0.9514944], dtype=float32), -0.15471523]. 
=============================================
[2019-03-24 08:11:46,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4701509e-07 5.0936724e-06 2.3956557e-06 9.9998665e-01 4.9666228e-06], sum to 1.0000
[2019-03-24 08:11:46,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-24 08:11:46,804] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 94.33333333333334, 1.0, 2.0, 0.2989103399475675, 1.0, 2.0, 0.2989103399475675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686116.8299516359, 686116.8299516364, 180439.0518924074], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5005200.0000, 
sim time next is 5005800.0000, 
raw observation next is [23.4, 94.5, 1.0, 2.0, 0.2940355054493946, 1.0, 2.0, 0.2940355054493946, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677551.926417933, 677551.9264179334, 179399.7777749939], 
processed observation next is [1.0, 0.9565217391304348, 0.42222222222222217, 0.945, 1.0, 1.0, 0.15956607791594596, 1.0, 1.0, 0.15956607791594596, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2419828308635475, 0.24198283086354766, 0.34499957264421904], 
reward next is 0.6550, 
noisyNet noise sample is [array([-0.34354186], dtype=float32), 1.1827743]. 
=============================================
[2019-03-24 08:11:53,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2830973e-06 2.1991800e-05 7.8976416e-05 9.9974662e-01 1.5008115e-04], sum to 1.0000
[2019-03-24 08:11:53,013] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7409
[2019-03-24 08:11:53,018] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3375206538152269, 1.0, 2.0, 0.3375206538152269, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769341.8530389293, 769341.8530389298, 189708.5899916575], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5186400.0000, 
sim time next is 5187000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3374247315256905, 1.0, 2.0, 0.3374247315256905, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 189684.3275013023], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.21121991848296492, 1.0, 1.0, 0.21121991848296492, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27468682101846253, 0.27468682101846253, 0.36477755288711977], 
reward next is 0.6352, 
noisyNet noise sample is [array([2.4616187], dtype=float32), -0.567148]. 
=============================================
[2019-03-24 08:11:53,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[57.896595]
 [57.899704]
 [58.134445]
 [58.38978 ]
 [59.447304]], R is [[57.82445526]
 [57.88138962]
 [57.93778992]
 [57.99387741]
 [58.04995346]].
[2019-03-24 08:11:54,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.9680601e-07 1.4013915e-05 7.7463737e-06 9.9991608e-01 6.1421117e-05], sum to 1.0000
[2019-03-24 08:11:54,745] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3842
[2019-03-24 08:11:54,753] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 91.0, 1.0, 2.0, 0.4363828315767415, 1.0, 2.0, 0.4363828315767415, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 994833.7595512843, 994833.7595512847, 216409.0788226841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5212800.0000, 
sim time next is 5213400.0000, 
raw observation next is [24.75, 90.66666666666667, 1.0, 2.0, 0.4857455267525058, 1.0, 2.0, 0.4857455267525058, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1107448.556364205, 1107448.556364206, 231009.0795816323], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.9066666666666667, 1.0, 1.0, 0.3877922937529831, 1.0, 1.0, 0.3877922937529831, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.39551734155864465, 0.395517341558645, 0.4442482299646775], 
reward next is 0.5558, 
noisyNet noise sample is [array([0.21921042], dtype=float32), -0.26885846]. 
=============================================
[2019-03-24 08:11:58,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4249742e-04 4.9430189e-05 8.4160842e-05 9.9939191e-01 3.3190273e-04], sum to 1.0000
[2019-03-24 08:11:58,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5840
[2019-03-24 08:11:58,528] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.31666666666667, 93.0, 1.0, 2.0, 0.3651073866174274, 1.0, 2.0, 0.3651073866174274, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832256.9677400822, 832256.9677400826, 196818.8455033211], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5547000.0000, 
sim time next is 5547600.0000, 
raw observation next is [25.3, 93.0, 1.0, 2.0, 0.3640793314053942, 1.0, 2.0, 0.3640793314053942, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829912.2621236675, 829912.2621236675, 196549.1306898749], 
processed observation next is [1.0, 0.21739130434782608, 0.49259259259259264, 0.93, 1.0, 1.0, 0.2429515850064217, 1.0, 1.0, 0.2429515850064217, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2963972364727384, 0.2963972364727384, 0.37797909748052866], 
reward next is 0.6220, 
noisyNet noise sample is [array([-0.31421995], dtype=float32), -2.58321]. 
=============================================
[2019-03-24 08:12:06,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3546732e-05 5.6647266e-05 4.7652989e-05 9.9973077e-01 1.5133305e-04], sum to 1.0000
[2019-03-24 08:12:06,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-24 08:12:06,495] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.26666666666667, 84.33333333333334, 1.0, 2.0, 0.650713594032382, 1.0, 2.0, 0.650713594032382, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1483922.660797451, 1483922.660797451, 285927.8514900625], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5390400.0000, 
sim time next is 5391000.0000, 
raw observation next is [26.45, 83.5, 1.0, 2.0, 0.6498297982499027, 1.0, 2.0, 0.6498297982499027, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1481905.25476884, 1481905.25476884, 285608.561402698], 
processed observation next is [1.0, 0.391304347826087, 0.5351851851851852, 0.835, 1.0, 1.0, 0.5831307122022651, 1.0, 1.0, 0.5831307122022651, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5292518767031572, 0.5292518767031572, 0.5492472334667269], 
reward next is 0.4508, 
noisyNet noise sample is [array([-0.11968049], dtype=float32), 1.499231]. 
=============================================
[2019-03-24 08:12:06,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[50.604053]
 [51.185596]
 [51.68634 ]
 [52.416424]
 [53.24661 ]], R is [[49.98286057]
 [49.93317032]
 [49.87913895]
 [49.82854462]
 [49.77723312]].
[2019-03-24 08:12:12,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2498871e-07 5.4740823e-08 1.2457209e-06 9.9999750e-01 6.7655913e-07], sum to 1.0000
[2019-03-24 08:12:12,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7083
[2019-03-24 08:12:12,574] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 90.0, 1.0, 2.0, 0.3441242705309054, 1.0, 2.0, 0.3441242705309054, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 784401.7855293088, 784401.7855293093, 191386.8946707757], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5526000.0000, 
sim time next is 5526600.0000, 
raw observation next is [25.88333333333333, 90.16666666666667, 1.0, 2.0, 0.3443748956553997, 1.0, 2.0, 0.3443748956553997, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 784973.3565493093, 784973.3565493098, 191450.8843472338], 
processed observation next is [1.0, 1.0, 0.5141975308641974, 0.9016666666666667, 1.0, 1.0, 0.21949392339928536, 1.0, 1.0, 0.21949392339928536, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28034762733903906, 0.28034762733903923, 0.3681747775908342], 
reward next is 0.6318, 
noisyNet noise sample is [array([0.31076497], dtype=float32), 1.1960987]. 
=============================================
[2019-03-24 08:12:15,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0655514e-07 9.2561402e-07 2.0826940e-07 9.9999654e-01 2.1015217e-06], sum to 1.0000
[2019-03-24 08:12:15,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1558
[2019-03-24 08:12:15,587] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 97.16666666666667, 1.0, 2.0, 0.3024654567488945, 1.0, 2.0, 0.3024654567488945, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689523.973377983, 689523.9733779834, 181059.4387949383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5619000.0000, 
sim time next is 5619600.0000, 
raw observation next is [23.6, 97.0, 1.0, 2.0, 0.3021053860761325, 1.0, 2.0, 0.3021053860761325, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689021.9729937362, 689021.9729937366, 180988.8204102546], 
processed observation next is [0.0, 0.043478260869565216, 0.4296296296296297, 0.97, 1.0, 1.0, 0.16917307866206252, 1.0, 1.0, 0.16917307866206252, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24607927606919147, 0.24607927606919164, 0.3480554238658742], 
reward next is 0.6519, 
noisyNet noise sample is [array([0.67985576], dtype=float32), 1.2198157]. 
=============================================
[2019-03-24 08:12:17,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0303979e-07 1.4987597e-07 2.1662602e-07 9.9999940e-01 1.5312204e-07], sum to 1.0000
[2019-03-24 08:12:17,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4374
[2019-03-24 08:12:17,381] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 93.0, 1.0, 2.0, 0.349444409211407, 1.0, 2.0, 0.349444409211407, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796534.8868371932, 796534.8868371936, 192750.0272945036], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5601600.0000, 
sim time next is 5602200.0000, 
raw observation next is [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.348755956268064, 1.0, 2.0, 0.348755956268064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794964.7911373801, 794964.7911373801, 192573.0348714601], 
processed observation next is [1.0, 0.8695652173913043, 0.50679012345679, 0.9316666666666668, 1.0, 1.0, 0.22470947174769523, 1.0, 1.0, 0.22470947174769523, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2839159968347786, 0.2839159968347786, 0.37033275936819254], 
reward next is 0.6297, 
noisyNet noise sample is [array([-1.2422962], dtype=float32), 0.66634357]. 
=============================================
[2019-03-24 08:12:19,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4581237e-04 2.6038950e-04 6.8066950e-04 9.9864393e-01 2.6928511e-04], sum to 1.0000
[2019-03-24 08:12:19,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1431
[2019-03-24 08:12:19,063] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.23333333333333, 46.66666666666666, 1.0, 2.0, 0.3822600584728901, 1.0, 2.0, 0.3822600584728901, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945228.8692937287, 945228.8692937287, 204165.6638321503], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5827800.0000, 
sim time next is 5828400.0000, 
raw observation next is [26.4, 45.0, 1.0, 2.0, 0.3968974647175758, 1.0, 2.0, 0.3968974647175758, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 983270.732296659, 983270.7322966595, 208277.1282900385], 
processed observation next is [1.0, 0.4782608695652174, 0.5333333333333333, 0.45, 1.0, 1.0, 0.2820207913304474, 1.0, 1.0, 0.2820207913304474, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35116811867737824, 0.3511681186773784, 0.4005329390193048], 
reward next is 0.5995, 
noisyNet noise sample is [array([-0.4380931], dtype=float32), 0.79004437]. 
=============================================
[2019-03-24 08:12:20,124] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 08:12:20,127] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:12:20,127] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:20,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:12:20,129] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:20,131] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:12:20,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:12:20,135] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:12:20,134] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:20,135] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:20,138] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:20,169] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-24 08:12:20,198] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-24 08:12:20,200] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-24 08:12:20,231] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-24 08:12:20,231] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-24 08:12:30,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:12:30,265] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.9, 15.66666666666667, 1.0, 2.0, 0.1633796140818007, 1.0, 2.0, 0.1633796140818007, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421518.5012772046, 421518.5012772051, 138964.7123163499]
[2019-03-24 08:12:30,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:12:30,267] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1853462e-06 2.6972293e-06 3.5489966e-06 9.9998820e-01 4.3274672e-06], sampled 0.6204604311783566
[2019-03-24 08:12:37,591] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:12:37,592] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666667, 41.5, 1.0, 2.0, 0.1612550053236334, 1.0, 2.0, 0.1612550053236334, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 407401.147130906, 407401.1471309065, 152103.4479156746]
[2019-03-24 08:12:37,592] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:12:37,595] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.4755938e-07 1.5400324e-06 2.0186858e-06 9.9999321e-01 2.6206603e-06], sampled 0.06352050898233141
[2019-03-24 08:12:59,646] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:12:59,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 90.0, 1.0, 2.0, 0.2278401496816776, 1.0, 2.0, 0.2278401496816776, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 546867.8768614327, 546867.8768614331, 165343.1579510584]
[2019-03-24 08:12:59,650] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:12:59,653] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.3894413e-07 1.5231867e-06 1.9793406e-06 9.9999321e-01 2.6188739e-06], sampled 0.8841400999028645
[2019-03-24 08:13:06,170] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:13:06,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.69697708333333, 108.6518677716667, 1.0, 2.0, 0.4014306155580858, 1.0, 2.0, 0.4014306155580858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 915104.6703121078, 915104.6703121081, 206584.1194779681]
[2019-03-24 08:13:06,174] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:13:06,175] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3626179e-07 1.0766602e-06 1.4265402e-06 9.9999523e-01 1.7541909e-06], sampled 0.6494088851939172
[2019-03-24 08:13:16,593] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:13:16,593] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.2560051816653796, 1.0, 2.0, 0.2560051816653796, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 608167.1048801392, 608167.1048801397, 171397.3938161436]
[2019-03-24 08:13:16,595] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:13:16,599] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.1290302e-07 1.4273285e-06 1.9685920e-06 9.9999356e-01 2.3535899e-06], sampled 0.40215778716546324
[2019-03-24 08:13:44,238] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.010239], dtype=float32), 0.008092642]
[2019-03-24 08:13:44,239] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 62.0, 1.0, 2.0, 0.4293851020453507, 1.0, 2.0, 0.4293851020453507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 978870.6568003949, 978870.6568003953, 214408.3722835428]
[2019-03-24 08:13:44,240] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:13:44,244] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1767422e-06 2.6524899e-06 3.5605742e-06 9.9998832e-01 4.2333500e-06], sampled 0.7715416097002498
[2019-03-24 08:14:04,816] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:14:05,139] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5310 2410721666.3579 22.0000
[2019-03-24 08:14:05,264] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 08:14:05,285] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:14:05,361] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6534 2465958740.4841 46.0000
[2019-03-24 08:14:06,377] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1425000, evaluation results [1425000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7797.531024853822, 2410721666.357948, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.6533711920765, 2465958740.484093, 46.0]
[2019-03-24 08:14:12,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1969132e-07 1.7365372e-06 2.2867926e-06 9.9999523e-01 5.9281825e-07], sum to 1.0000
[2019-03-24 08:14:12,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6539
[2019-03-24 08:14:12,166] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.2783256630986457, 1.0, 2.0, 0.2783256630986457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668893.4249924573, 668893.4249924573, 176869.7713942257], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5798400.0000, 
sim time next is 5799000.0000, 
raw observation next is [21.95, 88.5, 1.0, 2.0, 0.2730459305866958, 1.0, 2.0, 0.2730459305866958, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 656226.9849621672, 656226.9849621677, 175625.8622600185], 
processed observation next is [1.0, 0.08695652173913043, 0.36851851851851847, 0.885, 1.0, 1.0, 0.13457848879368547, 1.0, 1.0, 0.13457848879368547, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23436678034363115, 0.23436678034363131, 0.3377420428077279], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.38913828], dtype=float32), 0.7587801]. 
=============================================
[2019-03-24 08:14:12,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.890884]
 [60.671654]
 [60.575485]
 [60.251358]
 [59.593544]], R is [[61.30385208]
 [61.3506813 ]
 [61.39508438]
 [61.4198761 ]
 [61.41907501]].
[2019-03-24 08:14:12,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3305082e-06 4.4355138e-06 4.7058643e-06 9.9998057e-01 2.9706132e-06], sum to 1.0000
[2019-03-24 08:14:12,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7824
[2019-03-24 08:14:12,340] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.7, 90.5, 1.0, 2.0, 0.2379361117874687, 1.0, 2.0, 0.2379361117874687, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572586.5997612873, 572586.5997612878, 167626.4947874862], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5801400.0000, 
sim time next is 5802000.0000, 
raw observation next is [21.63333333333333, 91.0, 1.0, 2.0, 0.2340893405392069, 1.0, 2.0, 0.2340893405392069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 563491.4813876618, 563491.4813876622, 166779.1966015845], 
processed observation next is [1.0, 0.13043478260869565, 0.35679012345678995, 0.91, 1.0, 1.0, 0.08820159588000823, 1.0, 1.0, 0.08820159588000823, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20124695763845063, 0.2012469576384508, 0.32072922423381633], 
reward next is 0.6793, 
noisyNet noise sample is [array([0.5486249], dtype=float32), -0.4686512]. 
=============================================
[2019-03-24 08:14:12,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.8817  ]
 [62.705418]
 [61.96766 ]
 [61.792736]
 [61.495174]], R is [[62.86867905]
 [62.91763687]
 [62.9637146 ]
 [62.99853516]
 [63.03364563]].
[2019-03-24 08:14:20,140] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8618617e-07 2.4860149e-06 7.9507035e-06 9.9997747e-01 1.1907713e-05], sum to 1.0000
[2019-03-24 08:14:20,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3639
[2019-03-24 08:14:20,156] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333333, 67.33333333333334, 1.0, 2.0, 0.7097549039254576, 1.0, 2.0, 0.7097549039254576, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1618700.404850269, 1618700.404850269, 307873.2051934707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6003600.0000, 
sim time next is 6004200.0000, 
raw observation next is [27.71666666666667, 66.66666666666666, 1.0, 2.0, 0.7172566973075247, 1.0, 2.0, 0.7172566973075247, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1635825.010888154, 1635825.010888154, 310748.3357436709], 
processed observation next is [1.0, 0.4782608695652174, 0.5820987654320988, 0.6666666666666665, 1.0, 1.0, 0.6634008301280057, 1.0, 1.0, 0.6634008301280057, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5842232181743406, 0.5842232181743406, 0.5975929533532133], 
reward next is 0.4024, 
noisyNet noise sample is [array([0.06295392], dtype=float32), 1.9104466]. 
=============================================
[2019-03-24 08:14:27,189] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9928973e-06 6.8963691e-06 5.3727422e-06 9.9998498e-01 7.3656241e-07], sum to 1.0000
[2019-03-24 08:14:27,194] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7091
[2019-03-24 08:14:27,200] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 62.5, 1.0, 2.0, 0.755923474042412, 1.0, 2.0, 0.755923474042412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1724096.220793693, 1724096.220793693, 325876.4681635748], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6089400.0000, 
sim time next is 6090000.0000, 
raw observation next is [28.63333333333333, 61.66666666666667, 1.0, 2.0, 0.7212920661453879, 1.0, 2.0, 0.7212920661453879, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1645036.824199598, 1645036.824199599, 312302.9483210302], 
processed observation next is [1.0, 0.4782608695652174, 0.6160493827160493, 0.6166666666666667, 1.0, 1.0, 0.6682048406492713, 1.0, 1.0, 0.6682048406492713, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5875131514998565, 0.5875131514998568, 0.600582592925058], 
reward next is 0.3994, 
noisyNet noise sample is [array([0.26123476], dtype=float32), -1.1238407]. 
=============================================
[2019-03-24 08:14:27,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.730362]
 [61.021355]
 [60.342793]
 [59.67531 ]
 [59.339615]], R is [[61.83818054]
 [61.59311295]
 [61.35018158]
 [61.10946274]
 [60.84988785]].
[2019-03-24 08:14:33,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3464402e-06 6.7814026e-06 2.7569983e-04 9.9966872e-01 4.0351915e-05], sum to 1.0000
[2019-03-24 08:14:33,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1930
[2019-03-24 08:14:33,940] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 83.0, 1.0, 2.0, 0.3396440124618191, 1.0, 2.0, 0.3396440124618191, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774184.2638142337, 774184.2638142342, 190246.4953154273], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6396000.0000, 
sim time next is 6396600.0000, 
raw observation next is [26.41666666666667, 83.5, 1.0, 2.0, 0.3379396157719526, 1.0, 2.0, 0.3379396157719526, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770297.3113893031, 770297.3113893031, 189814.5727421084], 
processed observation next is [1.0, 0.0, 0.5339506172839508, 0.835, 1.0, 1.0, 0.21183287591899116, 1.0, 1.0, 0.21183287591899116, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2751061826390368, 0.2751061826390368, 0.36502802450405464], 
reward next is 0.6350, 
noisyNet noise sample is [array([0.85844624], dtype=float32), 1.7906882]. 
=============================================
[2019-03-24 08:14:34,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4113483e-06 5.2375917e-06 3.8010651e-06 9.9997818e-01 1.0405621e-05], sum to 1.0000
[2019-03-24 08:14:34,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9091
[2019-03-24 08:14:34,360] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.13333333333333, 73.0, 1.0, 2.0, 0.6310606387245071, 1.0, 2.0, 0.6310606387245071, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1446233.107752339, 1446233.107752339, 279249.2439681414], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [26.3, 72.0, 1.0, 2.0, 0.6400376804659464, 1.0, 2.0, 0.6400376804659464, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1466440.633461346, 1466440.633461346, 282434.1165391657], 
processed observation next is [1.0, 0.43478260869565216, 0.5296296296296297, 0.72, 1.0, 1.0, 0.5714734291261268, 1.0, 1.0, 0.5714734291261268, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5237287976647664, 0.5237287976647664, 0.543142531806088], 
reward next is 0.4569, 
noisyNet noise sample is [array([-0.13590503], dtype=float32), -1.4416939]. 
=============================================
[2019-03-24 08:14:37,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2188574e-06 2.0992161e-06 4.6818559e-06 9.9999082e-01 1.0974440e-07], sum to 1.0000
[2019-03-24 08:14:37,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9551
[2019-03-24 08:14:37,672] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.13333333333333, 86.33333333333334, 1.0, 2.0, 0.2494655896696091, 1.0, 2.0, 0.2494655896696091, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591291.9303601382, 591291.9303601382, 169858.0129901739], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6243600.0000, 
sim time next is 6244200.0000, 
raw observation next is [23.25, 86.0, 1.0, 2.0, 0.251427834115825, 1.0, 2.0, 0.251427834115825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595132.6421985306, 595132.6421985311, 170267.1337418701], 
processed observation next is [0.0, 0.2608695652173913, 0.4166666666666667, 0.86, 1.0, 1.0, 0.1088426596616964, 1.0, 1.0, 0.1088426596616964, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21254737221376094, 0.2125473722137611, 0.3274367956574425], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.49135473], dtype=float32), 0.8686739]. 
=============================================
[2019-03-24 08:14:37,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6710292e-08 2.4416011e-06 4.1930755e-07 9.9999690e-01 2.8660389e-07], sum to 1.0000
[2019-03-24 08:14:37,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9885
[2019-03-24 08:14:37,787] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.56666666666667, 72.33333333333334, 1.0, 2.0, 0.3396449583056551, 1.0, 2.0, 0.3396449583056551, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774186.4208586239, 774186.4208586239, 190247.0161580945], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6344400.0000, 
sim time next is 6345000.0000, 
raw observation next is [28.8, 71.5, 1.0, 2.0, 0.3434475485169818, 1.0, 2.0, 0.3434475485169818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782858.4679592135, 782858.4679592135, 191214.2911889849], 
processed observation next is [0.0, 0.43478260869565216, 0.6222222222222222, 0.715, 1.0, 1.0, 0.2183899387106926, 1.0, 1.0, 0.2183899387106926, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2795923099854334, 0.2795923099854334, 0.3677197907480479], 
reward next is 0.6323, 
noisyNet noise sample is [array([2.263314], dtype=float32), 0.7648677]. 
=============================================
[2019-03-24 08:14:37,799] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.859543]
 [63.90724 ]
 [63.915257]
 [63.872303]
 [63.91043 ]], R is [[63.82824707]
 [63.82410431]
 [63.82287216]
 [63.82055664]
 [63.81931686]].
[2019-03-24 08:14:40,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9678958e-05 2.7726102e-05 1.0802636e-05 9.9984562e-01 6.6112669e-05], sum to 1.0000
[2019-03-24 08:14:40,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7839
[2019-03-24 08:14:40,423] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 38.0, 1.0, 2.0, 0.4472043966633893, 1.0, 2.0, 0.4472043966633893, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1112916.399112345, 1112916.399112346, 222954.4885925779], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6607200.0000, 
sim time next is 6607800.0000, 
raw observation next is [27.65, 38.5, 1.0, 2.0, 0.4775863436201391, 1.0, 2.0, 0.4775863436201391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1184779.651485537, 1184779.651485538, 232113.1148042365], 
processed observation next is [1.0, 0.4782608695652174, 0.5796296296296296, 0.385, 1.0, 1.0, 0.37807898050016553, 1.0, 1.0, 0.37807898050016553, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4231355898162632, 0.4231355898162636, 0.44637137462353177], 
reward next is 0.5536, 
noisyNet noise sample is [array([-1.0206589], dtype=float32), 1.3358979]. 
=============================================
[2019-03-24 08:14:43,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0668675e-06 2.8223187e-05 7.2629759e-06 9.9988258e-01 7.4912590e-05], sum to 1.0000
[2019-03-24 08:14:43,086] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0921
[2019-03-24 08:14:43,089] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.03333333333333, 91.83333333333334, 1.0, 2.0, 0.4348614398186609, 1.0, 2.0, 0.4348614398186609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 991363.1580063124, 991363.1580063129, 215973.0247950317], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6419400.0000, 
sim time next is 6420000.0000, 
raw observation next is [25.06666666666667, 91.66666666666667, 1.0, 2.0, 0.460847842131773, 1.0, 2.0, 0.460847842131773, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1050645.543398869, 1050645.543398869, 223540.0050288624], 
processed observation next is [1.0, 0.30434782608695654, 0.4839506172839507, 0.9166666666666667, 1.0, 1.0, 0.35815219301401546, 1.0, 1.0, 0.35815219301401546, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37523055121388177, 0.37523055121388177, 0.4298846250555046], 
reward next is 0.5701, 
noisyNet noise sample is [array([-1.632095], dtype=float32), 0.118329614]. 
=============================================
[2019-03-24 08:14:43,107] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.34717 ]
 [52.591743]
 [52.576073]
 [52.475433]
 [52.277977]], R is [[52.09082031]
 [52.15457916]
 [52.24155045]
 [52.33512497]
 [52.42377853]].
[2019-03-24 08:14:44,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7586453e-08 7.2155251e-07 3.7694717e-06 9.9999070e-01 4.7981603e-06], sum to 1.0000
[2019-03-24 08:14:44,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-24 08:14:44,135] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.61666666666667, 61.33333333333334, 1.0, 2.0, 0.3405075733747485, 1.0, 2.0, 0.3405075733747485, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776153.6603915689, 776153.6603915689, 190465.9974923322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6375000.0000, 
sim time next is 6375600.0000, 
raw observation next is [30.5, 62.0, 1.0, 2.0, 0.3415556798571076, 1.0, 2.0, 0.3415556798571076, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 778543.9297498509, 778543.9297498513, 190732.4123416666], 
processed observation next is [0.0, 0.8260869565217391, 0.6851851851851852, 0.62, 1.0, 1.0, 0.2161377141156043, 1.0, 1.0, 0.2161377141156043, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2780514034820896, 0.2780514034820898, 0.3667931006570512], 
reward next is 0.6332, 
noisyNet noise sample is [array([0.8629062], dtype=float32), 0.5895434]. 
=============================================
[2019-03-24 08:14:44,379] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7658645e-05 4.9731370e-05 1.8997431e-04 9.9972242e-01 1.0263677e-05], sum to 1.0000
[2019-03-24 08:14:44,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7924
[2019-03-24 08:14:44,394] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 82.0, 1.0, 2.0, 0.9424097450083547, 1.0, 2.0, 0.9424097450083547, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2149942.599737494, 2149942.599737493, 406114.5703660969], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6428400.0000, 
sim time next is 6429000.0000, 
raw observation next is [27.68333333333333, 81.0, 1.0, 2.0, 0.9506543866929255, 1.0, 2.0, 0.9506543866929255, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2168774.147359445, 2168774.147359445, 409940.0785519322], 
processed observation next is [1.0, 0.391304347826087, 0.580864197530864, 0.81, 1.0, 1.0, 0.9412552222534827, 1.0, 1.0, 0.9412552222534827, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7745621954855162, 0.7745621954855162, 0.7883463049075619], 
reward next is 0.2117, 
noisyNet noise sample is [array([1.0749995], dtype=float32), 0.61538047]. 
=============================================
[2019-03-24 08:14:44,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.70741 ]
 [46.70254 ]
 [47.261913]
 [47.95385 ]
 [49.224804]], R is [[46.54545975]
 [46.29901505]
 [46.06464767]
 [45.84059525]
 [45.6262207 ]].
[2019-03-24 08:14:45,924] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1865946e-07 5.9321053e-07 7.5528674e-06 9.9999011e-01 1.1094507e-06], sum to 1.0000
[2019-03-24 08:14:45,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1543
[2019-03-24 08:14:45,940] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 85.0, 1.0, 2.0, 0.3342817224055553, 1.0, 2.0, 0.3342817224055553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 761955.3894890773, 761955.3894890777, 188890.9935665231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6398400.0000, 
sim time next is 6399000.0000, 
raw observation next is [26.0, 85.5, 1.0, 2.0, 0.3339310685126382, 1.0, 2.0, 0.3339310685126382, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761155.7188445315, 761155.7188445315, 188802.6856362282], 
processed observation next is [1.0, 0.043478260869565216, 0.5185185185185185, 0.855, 1.0, 1.0, 0.20706079584837883, 1.0, 1.0, 0.20706079584837883, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2718413281587612, 0.2718413281587612, 0.3630820877619773], 
reward next is 0.6369, 
noisyNet noise sample is [array([1.8211012], dtype=float32), -2.3234973]. 
=============================================
[2019-03-24 08:14:45,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.938675]
 [57.34407 ]
 [57.701935]
 [57.626236]
 [57.7611  ]], R is [[56.61151123]
 [56.68214417]
 [56.75159073]
 [56.8197937 ]
 [56.88656616]].
[2019-03-24 08:14:46,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5302013e-08 1.7371990e-07 2.5571298e-06 9.9999714e-01 1.5020790e-07], sum to 1.0000
[2019-03-24 08:14:46,086] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1891
[2019-03-24 08:14:46,097] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.25, 27.83333333333333, 1.0, 2.0, 0.2471135565169156, 1.0, 2.0, 0.2471135565169156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 617004.0482559678, 617004.0482559681, 170342.3224438697], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6714600.0000, 
sim time next is 6715200.0000, 
raw observation next is [30.0, 28.66666666666667, 1.0, 2.0, 0.1767989085455926, 1.0, 2.0, 0.1767989085455926, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 443939.2932163822, 443939.2932163826, 155228.2667740958], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666666, 0.28666666666666674, 1.0, 1.0, 0.019998700649515002, 1.0, 1.0, 0.019998700649515002, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15854974757727935, 0.15854974757727952, 0.2985158976424919], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.22681236], dtype=float32), 0.6880642]. 
=============================================
[2019-03-24 08:14:50,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9425370e-05 1.7278559e-06 6.2793320e-06 9.9996734e-01 5.2143996e-06], sum to 1.0000
[2019-03-24 08:14:50,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-24 08:14:50,745] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 34.0, 1.0, 2.0, 0.4198190401669231, 1.0, 2.0, 0.4198190401669231, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050552.434940243, 1050552.434940243, 215019.7411601296], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6696000.0000, 
sim time next is 6696600.0000, 
raw observation next is [28.05, 33.5, 1.0, 2.0, 0.4141005405500501, 1.0, 2.0, 0.4141005405500501, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1036723.646791521, 1036723.646791521, 213379.9705491455], 
processed observation next is [1.0, 0.5217391304347826, 0.5944444444444444, 0.335, 1.0, 1.0, 0.3025006435119644, 1.0, 1.0, 0.3025006435119644, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3702584452826861, 0.3702584452826861, 0.41034609720989523], 
reward next is 0.5897, 
noisyNet noise sample is [array([-0.7854817], dtype=float32), -0.6091061]. 
=============================================
[2019-03-24 08:14:50,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8640556e-07 8.4220728e-06 2.3588860e-05 9.9982893e-01 1.3816230e-04], sum to 1.0000
[2019-03-24 08:14:50,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-24 08:14:50,928] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 51.66666666666667, 1.0, 2.0, 0.3238930972935522, 1.0, 2.0, 0.3238930972935522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 801849.6634839317, 801849.6634839321, 188725.0823894466], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6574200.0000, 
sim time next is 6574800.0000, 
raw observation next is [25.6, 51.33333333333334, 1.0, 2.0, 0.2788035378973432, 1.0, 2.0, 0.2788035378973432, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689841.9660170166, 689841.966017017, 177595.6157897971], 
processed observation next is [1.0, 0.08695652173913043, 0.5037037037037038, 0.5133333333333334, 1.0, 1.0, 0.14143278321112285, 1.0, 1.0, 0.14143278321112285, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24637213072036307, 0.24637213072036324, 0.3415300303649944], 
reward next is 0.6585, 
noisyNet noise sample is [array([-0.36523744], dtype=float32), -0.26445478]. 
=============================================
[2019-03-24 08:14:51,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7790131e-06 3.4230870e-05 1.5164745e-05 9.9992216e-01 2.5637079e-05], sum to 1.0000
[2019-03-24 08:14:51,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7896
[2019-03-24 08:14:51,094] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 80.66666666666667, 1.0, 2.0, 0.804593926539352, 1.0, 2.0, 0.804593926539352, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1835216.9190579, 1835216.919057901, 345656.2804061183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6531600.0000, 
sim time next is 6532200.0000, 
raw observation next is [27.25, 80.5, 1.0, 2.0, 0.7778089652274194, 1.0, 2.0, 0.7778089652274194, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1774061.809581004, 1774061.809581003, 334670.0039349765], 
processed observation next is [1.0, 0.6086956521739131, 0.5648148148148148, 0.805, 1.0, 1.0, 0.7354868633659755, 1.0, 1.0, 0.7354868633659755, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6335935034217872, 0.6335935034217868, 0.6435961614134164], 
reward next is 0.3564, 
noisyNet noise sample is [array([0.41781467], dtype=float32), -0.14295843]. 
=============================================
[2019-03-24 08:14:53,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0276219e-06 1.1926627e-06 1.0890249e-05 9.9997723e-01 9.6226622e-06], sum to 1.0000
[2019-03-24 08:14:53,722] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0483
[2019-03-24 08:14:53,727] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 35.83333333333334, 1.0, 2.0, 0.3649941265317933, 1.0, 2.0, 0.3649941265317933, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 903550.2024457743, 903550.2024457748, 199489.5264846016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6612600.0000, 
sim time next is 6613200.0000, 
raw observation next is [29.0, 35.0, 1.0, 2.0, 0.4086911239419554, 1.0, 2.0, 0.4086911239419554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1011576.091824191, 1011576.091824192, 211589.9457804531], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.35, 1.0, 1.0, 0.2960608618356612, 1.0, 1.0, 0.2960608618356612, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3612771756514968, 0.36127717565149714, 0.4069037418854867], 
reward next is 0.5931, 
noisyNet noise sample is [array([0.5833452], dtype=float32), -0.34844646]. 
=============================================
[2019-03-24 08:14:54,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6455048e-07 1.4530477e-06 1.8257032e-06 9.9998999e-01 6.2341023e-06], sum to 1.0000
[2019-03-24 08:14:54,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2671
[2019-03-24 08:14:54,907] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.2387346321064457, 1.0, 2.0, 0.2387346321064457, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569136.8154963773, 569136.8154963778, 167594.3369700218], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6807600.0000, 
sim time next is 6808200.0000, 
raw observation next is [25.83333333333334, 65.83333333333334, 1.0, 2.0, 0.238299535704571, 1.0, 2.0, 0.238299535704571, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568422.0054060976, 568422.0054060976, 167510.7972705936], 
processed observation next is [1.0, 0.8260869565217391, 0.5123456790123458, 0.6583333333333334, 1.0, 1.0, 0.09321373298163213, 1.0, 1.0, 0.09321373298163213, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2030078590736063, 0.2030078590736063, 0.3221361485972954], 
reward next is 0.6779, 
noisyNet noise sample is [array([-0.24317513], dtype=float32), 0.23416023]. 
=============================================
[2019-03-24 08:14:55,364] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 08:14:55,370] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:14:55,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:14:55,373] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:14:55,374] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:14:55,374] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:14:55,374] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:14:55,374] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:14:55,375] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:14:55,376] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:14:55,377] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:14:55,392] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-24 08:14:55,393] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-24 08:14:55,450] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-24 08:14:55,493] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-24 08:14:55,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-24 08:15:09,821] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:09,823] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.53936134, 57.405406565, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 297403.0605650281, 297403.0605650286, 114600.9873507349]
[2019-03-24 08:15:09,824] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:15:09,826] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2827978e-06 3.1064396e-06 3.6616700e-06 9.9998689e-01 5.0963658e-06], sampled 0.9370509642991361
[2019-03-24 08:15:10,834] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:10,835] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.75, 38.0, 1.0, 2.0, 0.1646533638050645, 1.0, 2.0, 0.1646533638050645, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413175.200462512, 413175.2004625124, 152738.3665340194]
[2019-03-24 08:15:10,837] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:15:10,839] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.9715439e-07 2.2078514e-06 2.6253585e-06 9.9999058e-01 3.5317048e-06], sampled 0.3588104856363108
[2019-03-24 08:15:11,181] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:11,182] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.51413324833333, 84.98260414, 1.0, 2.0, 0.161768744319289, 1.0, 2.0, 0.161768744319289, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406529.4754315627, 406529.4754315632, 152168.6438178652]
[2019-03-24 08:15:11,183] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:15:11,187] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.2846300e-07 1.6108627e-06 1.8695621e-06 9.9999297e-01 2.8127133e-06], sampled 0.1886998959681614
[2019-03-24 08:15:15,170] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:15,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.1, 50.33333333333334, 1.0, 2.0, 0.1710537282698043, 1.0, 2.0, 0.1710537282698043, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 428492.682627695, 428492.6826276955, 154024.4224867391]
[2019-03-24 08:15:15,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:15:15,175] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6612260e-07 2.1480043e-06 2.6060450e-06 9.9999106e-01 3.3869317e-06], sampled 0.995238257625905
[2019-03-24 08:15:16,489] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:16,490] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.83278014, 70.54848765666668, 1.0, 2.0, 0.301702085887806, 1.0, 2.0, 0.301702085887806, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694221.2167512283, 694221.2167512288, 181193.1362911768]
[2019-03-24 08:15:16,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:15:16,496] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.3231416e-07 1.8362822e-06 2.1863821e-06 9.9999225e-01 3.1169495e-06], sampled 0.2660528811405002
[2019-03-24 08:15:19,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:19,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 59.5, 1.0, 2.0, 0.1956513324478205, 1.0, 2.0, 0.1956513324478205, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 480771.1000726537, 480771.1000726542, 158887.6993175575]
[2019-03-24 08:15:19,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:15:19,383] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7648176e-07 1.7195425e-06 2.0408274e-06 9.9999285e-01 2.7386072e-06], sampled 0.37704127199004245
[2019-03-24 08:15:28,555] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:28,557] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 81.33333333333334, 1.0, 2.0, 0.2904636896870724, 1.0, 2.0, 0.2904636896870724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668976.3965621237, 668976.3965621241, 178532.2895235974]
[2019-03-24 08:15:28,559] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:15:28,561] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.9847199e-07 1.2835995e-06 1.5445603e-06 9.9999464e-01 2.0616744e-06], sampled 0.926972377887609
[2019-03-24 08:15:47,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:15:47,802] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.69734635, 100.93952714, 1.0, 2.0, 0.3334575263811096, 1.0, 2.0, 0.3334575263811096, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769263.1183489726, 769263.1183489731, 189126.3209297457]
[2019-03-24 08:15:47,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:15:47,806] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4321150e-07 1.8741532e-06 2.2070226e-06 9.9999189e-01 3.2414164e-06], sampled 0.39802829484581104
[2019-03-24 08:16:09,953] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:16:09,955] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.3614672617310966, 1.0, 2.0, 0.3614672617310966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823954.8960268161, 823954.8960268166, 195866.5275668519]
[2019-03-24 08:16:09,957] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:16:09,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2705292e-07 1.0962236e-06 1.3311093e-06 9.9999535e-01 1.7810103e-06], sampled 0.3360308488464627
[2019-03-24 08:16:11,523] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01016901], dtype=float32), 0.008140352]
[2019-03-24 08:16:11,526] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.92144403666666, 45.59385154333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367405.9088887523, 367405.9088887527, 145517.0171955791]
[2019-03-24 08:16:11,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:16:11,529] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.8173995e-07 1.6975781e-06 2.0282446e-06 9.9999273e-01 2.8685438e-06], sampled 0.8283669947860085
[2019-03-24 08:16:39,998] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454269.9342 47.0000
[2019-03-24 08:16:40,085] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:16:40,150] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.8840 2465925919.9710 46.0000
[2019-03-24 08:16:40,178] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.9106 2410717406.8600 22.0000
[2019-03-24 08:16:40,427] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:16:41,444] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1450000, evaluation results [1450000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7796.910618623569, 2410717406.860038, 22.0, 6905.908355438081, 2495454269.934179, 47.0, 7479.883964392372, 2465925919.9710255, 46.0]
[2019-03-24 08:16:41,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7551504e-05 7.3988808e-06 5.9690541e-07 9.9990797e-01 2.6464919e-05], sum to 1.0000
[2019-03-24 08:16:41,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8038
[2019-03-24 08:16:41,659] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 44.5, 1.0, 2.0, 0.2693958724090916, 1.0, 2.0, 0.2693958724090916, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 680605.9432795127, 680605.9432795132, 175636.6660226844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6687000.0000, 
sim time next is 6687600.0000, 
raw observation next is [25.23333333333333, 43.66666666666667, 1.0, 2.0, 0.3372720176872854, 1.0, 2.0, 0.3372720176872854, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850761.0153813863, 850761.0153813863, 192461.1324311674], 
processed observation next is [1.0, 0.391304347826087, 0.49012345679012337, 0.4366666666666667, 1.0, 1.0, 0.21103811629438735, 1.0, 1.0, 0.21103811629438735, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30384321977906653, 0.30384321977906653, 0.37011756236762966], 
reward next is 0.6299, 
noisyNet noise sample is [array([-0.01560861], dtype=float32), -0.083339736]. 
=============================================
[2019-03-24 08:16:45,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2519801e-06 8.2544041e-08 2.7725075e-06 9.9999511e-01 6.7670527e-07], sum to 1.0000
[2019-03-24 08:16:45,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1820
[2019-03-24 08:16:45,944] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.85, 63.5, 1.0, 2.0, 0.1664542840097758, 1.0, 2.0, 0.1664542840097758, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421144.1511864439, 421144.1511864444, 153164.1124762875], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6766200.0000, 
sim time next is 6766800.0000, 
raw observation next is [22.1, 62.33333333333334, 1.0, 2.0, 0.1652743501940392, 1.0, 2.0, 0.1652743501940392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417867.5302177183, 417867.5302177188, 152920.2571945979], 
processed observation next is [1.0, 0.30434782608695654, 0.3740740740740741, 0.6233333333333334, 1.0, 1.0, 0.006278988326237125, 1.0, 1.0, 0.006278988326237125, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1492384036491851, 0.14923840364918528, 0.2940774176819191], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.38973883], dtype=float32), 2.3448226]. 
=============================================
[2019-03-24 08:16:50,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1962657e-06 2.0132765e-07 1.2811397e-06 9.9998951e-01 7.6991637e-06], sum to 1.0000
[2019-03-24 08:16:50,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2278
[2019-03-24 08:16:50,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 79.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367883.4379565184, 367883.4379565189, 145992.5143932036], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6759600.0000, 
sim time next is 6760200.0000, 
raw observation next is [19.25, 77.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 369614.9354489314, 369614.9354489319, 146278.773144636], 
processed observation next is [1.0, 0.21739130434782608, 0.26851851851851855, 0.775, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13200533408890408, 0.13200533408890425, 0.28130533297045385], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6642388], dtype=float32), 1.2277435]. 
=============================================
[2019-03-24 08:16:53,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7948723e-07 5.1707802e-06 4.3482851e-07 9.9999368e-01 5.8352083e-07], sum to 1.0000
[2019-03-24 08:16:53,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4643
[2019-03-24 08:16:53,355] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 49.33333333333333, 1.0, 2.0, 0.2498694910577819, 1.0, 2.0, 0.2498694910577819, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590381.864098681, 590381.8640986815, 169869.821792896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 1.0, 2.0, 0.2522280354851481, 1.0, 2.0, 0.2522280354851481, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594869.1208354981, 594869.1208354981, 170355.7457783256], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 1.0, 1.0, 0.10979528033946204, 1.0, 1.0, 0.10979528033946204, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21245325744124932, 0.21245325744124932, 0.32760720341985694], 
reward next is 0.6724, 
noisyNet noise sample is [array([-1.5605147], dtype=float32), 1.5873845]. 
=============================================
[2019-03-24 08:16:58,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7660198e-07 8.4128906e-06 1.8127705e-05 9.9997211e-01 1.0606373e-06], sum to 1.0000
[2019-03-24 08:16:58,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9593
[2019-03-24 08:16:58,356] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 71.0, 1.0, 2.0, 0.7008695221250191, 1.0, 2.0, 0.7008695221250191, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1631387.40233759, 1631387.40233759, 306123.5948720749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7056000.0000, 
sim time next is 7056600.0000, 
raw observation next is [25.15, 72.16666666666667, 1.0, 2.0, 0.5852919571691828, 1.0, 2.0, 0.5852919571691828, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1367489.646209453, 1367489.646209453, 264570.2861159547], 
processed observation next is [1.0, 0.6956521739130435, 0.487037037037037, 0.7216666666666667, 1.0, 1.0, 0.5062999490109319, 1.0, 1.0, 0.5062999490109319, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4883891593605189, 0.4883891593605189, 0.5087890117614513], 
reward next is 0.4912, 
noisyNet noise sample is [array([-0.43756264], dtype=float32), -0.4988591]. 
=============================================
[2019-03-24 08:17:01,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9319914e-06 1.7608859e-06 8.6845694e-06 9.9998510e-01 2.5565212e-06], sum to 1.0000
[2019-03-24 08:17:01,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9044
[2019-03-24 08:17:01,209] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.8, 95.0, 1.0, 2.0, 0.1948399377939021, 1.0, 2.0, 0.1948399377939021, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479785.0833465313, 479785.0833465317, 158749.3234220416], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7178400.0000, 
sim time next is 7179000.0000, 
raw observation next is [19.78333333333333, 94.83333333333334, 1.0, 2.0, 0.2231129502630383, 1.0, 2.0, 0.2231129502630383, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 549211.2350413621, 549211.2350413625, 164781.5549990142], 
processed observation next is [1.0, 0.08695652173913043, 0.28827160493827153, 0.9483333333333335, 1.0, 1.0, 0.0751344645988551, 1.0, 1.0, 0.0751344645988551, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19614686965762934, 0.19614686965762945, 0.316887605767335], 
reward next is 0.6831, 
noisyNet noise sample is [array([-0.31008002], dtype=float32), -0.5811818]. 
=============================================
[2019-03-24 08:17:01,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.64215 ]
 [66.44719 ]
 [66.24176 ]
 [65.769684]
 [65.73482 ]], R is [[66.95892334]
 [66.98404694]
 [67.00910187]
 [67.03408051]
 [67.05899811]].
[2019-03-24 08:17:05,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2490583e-07 6.3360062e-07 2.1223995e-07 9.9999690e-01 2.0281620e-06], sum to 1.0000
[2019-03-24 08:17:05,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-24 08:17:05,693] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.01666666666667, 80.66666666666667, 1.0, 2.0, 0.4416958840245058, 1.0, 2.0, 0.4416958840245058, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1054787.728149049, 1054787.728149049, 220002.2293359069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7030200.0000, 
sim time next is 7030800.0000, 
raw observation next is [23.2, 80.0, 1.0, 2.0, 0.4567040618671316, 1.0, 2.0, 0.4567040618671316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1088547.427384163, 1088547.427384163, 224373.0433459647], 
processed observation next is [1.0, 0.391304347826087, 0.4148148148148148, 0.8, 1.0, 1.0, 0.3532191212703948, 1.0, 1.0, 0.3532191212703948, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3887669383514868, 0.3887669383514868, 0.43148662181916286], 
reward next is 0.5685, 
noisyNet noise sample is [array([0.5681888], dtype=float32), -0.7574641]. 
=============================================
[2019-03-24 08:17:07,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2127802e-08 3.4861619e-06 1.7616233e-06 9.9999368e-01 1.0227454e-06], sum to 1.0000
[2019-03-24 08:17:07,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2243
[2019-03-24 08:17:07,227] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.7, 79.0, 1.0, 2.0, 0.2423513308019321, 1.0, 2.0, 0.2423513308019321, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578810.4308872506, 578810.4308872506, 168442.497408462], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7063200.0000, 
sim time next is 7063800.0000, 
raw observation next is [23.68333333333333, 79.16666666666667, 1.0, 2.0, 0.2442952401967896, 1.0, 2.0, 0.2442952401967896, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583359.0863427835, 583359.086342784, 168874.0423652414], 
processed observation next is [1.0, 0.782608695652174, 0.4327160493827159, 0.7916666666666667, 1.0, 1.0, 0.10035147642474954, 1.0, 1.0, 0.10035147642474954, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2083425308367084, 0.20834253083670856, 0.32475777377931037], 
reward next is 0.6752, 
noisyNet noise sample is [array([-1.8954407], dtype=float32), -1.0714126]. 
=============================================
[2019-03-24 08:17:09,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2264018e-06 6.7620990e-06 1.4268307e-04 9.9984407e-01 1.2109113e-06], sum to 1.0000
[2019-03-24 08:17:09,557] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4572
[2019-03-24 08:17:09,563] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.7, 93.0, 1.0, 2.0, 0.1872101328817424, 1.0, 2.0, 0.1872101328817424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463156.6129633099, 463156.6129633103, 157227.1852522611], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7185600.0000, 
sim time next is 7186200.0000, 
raw observation next is [19.68333333333333, 92.83333333333333, 1.0, 2.0, 0.2077388038338349, 1.0, 2.0, 0.2077388038338349, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513956.2273574833, 513956.2273574837, 161536.7043894696], 
processed observation next is [1.0, 0.17391304347826086, 0.28456790123456777, 0.9283333333333332, 1.0, 1.0, 0.05683190932599391, 1.0, 1.0, 0.05683190932599391, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18355579548481546, 0.1835557954848156, 0.3106475084412877], 
reward next is 0.6894, 
noisyNet noise sample is [array([0.9656007], dtype=float32), -0.04315059]. 
=============================================
[2019-03-24 08:17:17,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6950490e-08 2.2139337e-08 4.4284320e-06 9.9999237e-01 3.1394738e-06], sum to 1.0000
[2019-03-24 08:17:17,114] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0313
[2019-03-24 08:17:17,119] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.11666666666667, 90.16666666666667, 1.0, 2.0, 0.2103837262064487, 1.0, 2.0, 0.2103837262064487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512068.8412023121, 512068.8412023125, 161842.2557310632], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7287000.0000, 
sim time next is 7287600.0000, 
raw observation next is [21.23333333333333, 89.33333333333334, 1.0, 2.0, 0.2826022742558936, 1.0, 2.0, 0.2826022742558936, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686600.3761833212, 686600.3761833217, 178141.1696383191], 
processed observation next is [1.0, 0.34782608695652173, 0.34197530864197523, 0.8933333333333334, 1.0, 1.0, 0.14595508839987337, 1.0, 1.0, 0.14595508839987337, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24521442006547187, 0.24521442006547203, 0.34257917238138286], 
reward next is 0.6574, 
noisyNet noise sample is [array([0.66527605], dtype=float32), -1.1638757]. 
=============================================
[2019-03-24 08:17:19,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2994359e-10 3.1195893e-07 3.9401243e-07 9.9999905e-01 1.8818436e-07], sum to 1.0000
[2019-03-24 08:17:19,826] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-24 08:17:19,837] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 96.0, 1.0, 2.0, 0.1927336831230265, 1.0, 2.0, 0.1927336831230265, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475811.9773171485, 475811.977317149, 158346.7640068617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7362000.0000, 
sim time next is 7362600.0000, 
raw observation next is [19.46666666666667, 96.0, 1.0, 2.0, 0.2015010326349842, 1.0, 2.0, 0.2015010326349842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 497543.3544593946, 497543.3544593951, 160185.6442399925], 
processed observation next is [1.0, 0.21739130434782608, 0.2765432098765433, 0.96, 1.0, 1.0, 0.049405991232124045, 1.0, 1.0, 0.049405991232124045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1776940551640695, 0.1776940551640697, 0.3080493158461394], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.6811086], dtype=float32), -1.2070302]. 
=============================================
[2019-03-24 08:17:22,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5570773e-09 2.1003796e-09 8.5703045e-09 1.0000000e+00 9.6589821e-09], sum to 1.0000
[2019-03-24 08:17:22,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3907
[2019-03-24 08:17:22,999] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 62.0, 1.0, 2.0, 0.2567814082614762, 1.0, 2.0, 0.2567814082614762, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441992, 171329.0931738438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7578000.0000, 
sim time next is 7578600.0000, 
raw observation next is [27.13333333333333, 63.16666666666667, 1.0, 2.0, 0.2563912364240551, 1.0, 2.0, 0.2563912364240551, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603236.6153911421, 603236.6153911425, 171237.0634810197], 
processed observation next is [0.0, 0.7391304347826086, 0.5604938271604937, 0.6316666666666667, 1.0, 1.0, 0.11475147193339892, 1.0, 1.0, 0.11475147193339892, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2154416483539793, 0.21544164835397947, 0.3293020451558071], 
reward next is 0.6707, 
noisyNet noise sample is [array([0.6237371], dtype=float32), -0.7501894]. 
=============================================
[2019-03-24 08:17:30,766] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 08:17:30,767] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:17:30,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:30,768] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:17:30,770] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:17:30,770] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:30,772] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:30,773] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:17:30,771] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:17:30,779] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:30,781] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:30,798] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-24 08:17:30,799] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-24 08:17:30,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-24 08:17:30,859] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-24 08:17:30,922] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-24 08:17:46,696] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01012452], dtype=float32), 0.008338103]
[2019-03-24 08:17:46,696] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.23333333333333, 88.0, 1.0, 2.0, 0.168496940956711, 1.0, 2.0, 0.168496940956711, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423026.4329418746, 423026.4329418746, 153522.7374305232]
[2019-03-24 08:17:46,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:17:46,700] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.713029e-07 5.797247e-07 8.433352e-07 9.999976e-01 7.100091e-07], sampled 0.2418477946598545
[2019-03-24 08:17:53,937] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01012452], dtype=float32), 0.008338103]
[2019-03-24 08:17:53,939] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.05278738, 73.59439913, 1.0, 2.0, 0.4618698961458376, 1.0, 2.0, 0.4618698961458376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1052977.233461459, 1052977.23346146, 223841.8410356086]
[2019-03-24 08:17:53,939] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:17:53,942] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6144817e-07 7.3529606e-07 1.1091792e-06 9.9999702e-01 8.5787997e-07], sampled 0.6456165728388072
[2019-03-24 08:18:09,480] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01012452], dtype=float32), 0.008338103]
[2019-03-24 08:18:09,481] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.34794161, 51.42068235, 1.0, 2.0, 0.31718409929233, 1.0, 2.0, 0.31718409929233, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 724113.1045838402, 724113.1045838407, 184692.4935078541]
[2019-03-24 08:18:09,482] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:18:09,487] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.1487235e-07 8.3815627e-07 1.2633004e-06 9.9999654e-01 9.7545364e-07], sampled 0.4189235016526629
[2019-03-24 08:18:18,428] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01012452], dtype=float32), 0.008338103]
[2019-03-24 08:18:18,430] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.92763294333333, 107.4839019, 1.0, 2.0, 0.3685342814953488, 1.0, 2.0, 0.3685342814953488, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 840072.8056761003, 840072.8056761008, 197721.0053760335]
[2019-03-24 08:18:18,431] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:18:18,433] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5173022e-07 3.2504821e-07 4.9451188e-07 9.9999869e-01 3.8457424e-07], sampled 0.8267161462735062
[2019-03-24 08:19:15,118] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.6057 2410682814.8906 22.0000
[2019-03-24 08:19:15,300] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7362 2495418209.4679 47.0000
[2019-03-24 08:19:15,364] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:19:15,522] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:19:15,586] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:19:16,604] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1475000, evaluation results [1475000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.60570358432, 2410682814.8906136, 22.0, 6906.736180006656, 2495418209.4679227, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:19:18,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6881752e-07 4.8920379e-07 1.0564297e-07 9.9999559e-01 2.9082923e-06], sum to 1.0000
[2019-03-24 08:19:18,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1666
[2019-03-24 08:19:18,610] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.88333333333334, 62.0, 1.0, 2.0, 0.270385354882859, 1.0, 2.0, 0.270385354882859, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 629579.1059708691, 629579.1059708695, 174159.0649697188], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7575000.0000, 
sim time next is 7575600.0000, 
raw observation next is [27.76666666666667, 62.0, 1.0, 2.0, 0.2680240956784229, 1.0, 2.0, 0.2680240956784229, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625425.2358546399, 625425.2358546404, 173675.3059149976], 
processed observation next is [0.0, 0.6956521739130435, 0.5839506172839507, 0.62, 1.0, 1.0, 0.1286001139028844, 1.0, 1.0, 0.1286001139028844, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2233661556623714, 0.22336615566237156, 0.3339909729134569], 
reward next is 0.6660, 
noisyNet noise sample is [array([-1.9593091], dtype=float32), -1.4044353]. 
=============================================
[2019-03-24 08:19:19,253] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1337806e-08 5.5035727e-08 2.2543472e-06 9.9999726e-01 4.7345208e-07], sum to 1.0000
[2019-03-24 08:19:19,261] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1125
[2019-03-24 08:19:19,269] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 51.0, 1.0, 2.0, 0.6603100179067697, 1.0, 2.0, 0.6603100179067697, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1541651.907852864, 1541651.907852865, 291144.0901639015], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7749000.0000, 
sim time next is 7749600.0000, 
raw observation next is [29.06666666666667, 51.33333333333333, 1.0, 2.0, 0.6211322834183874, 1.0, 2.0, 0.6211322834183874, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1450317.141564518, 1450317.141564518, 277004.2316599761], 
processed observation next is [1.0, 0.6956521739130435, 0.6320987654320989, 0.5133333333333333, 1.0, 1.0, 0.5489670040695088, 1.0, 1.0, 0.5489670040695088, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5179704077016135, 0.5179704077016135, 0.5327004454999541], 
reward next is 0.4673, 
noisyNet noise sample is [array([-0.61485094], dtype=float32), 1.6959656]. 
=============================================
[2019-03-24 08:19:19,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.04667968e-07 1.02439294e-07 1.14870645e-07 9.99998689e-01
 3.67530333e-07], sum to 1.0000
[2019-03-24 08:19:19,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6917
[2019-03-24 08:19:19,860] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.53333333333333, 91.0, 1.0, 2.0, 0.216774134813391, 1.0, 2.0, 0.216774134813391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 531361.303964551, 531361.3039645514, 163335.6338512193], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7629600.0000, 
sim time next is 7630200.0000, 
raw observation next is [20.6, 91.0, 1.0, 2.0, 0.219041731074344, 1.0, 2.0, 0.219041731074344, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536393.4888470233, 536393.4888470238, 163810.152163445], 
processed observation next is [1.0, 0.30434782608695654, 0.3185185185185186, 0.91, 1.0, 1.0, 0.07028777508850476, 1.0, 1.0, 0.07028777508850476, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1915691031596512, 0.19156910315965137, 0.31501952339124034], 
reward next is 0.6850, 
noisyNet noise sample is [array([1.0991958], dtype=float32), -0.26324007]. 
=============================================
[2019-03-24 08:19:23,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:23,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:23,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-24 08:19:28,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:28,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:28,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-24 08:19:29,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:29,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:29,066] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-24 08:19:30,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7090371e-07 6.5165623e-06 1.3588446e-05 9.9997950e-01 1.5998965e-07], sum to 1.0000
[2019-03-24 08:19:30,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8363
[2019-03-24 08:19:30,483] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.76666666666667, 56.33333333333334, 1.0, 2.0, 0.2205768443686038, 1.0, 2.0, 0.2205768443686038, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532945.2151819239, 532945.2151819244, 163897.0749991644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7845600.0000, 
sim time next is 7846200.0000, 
raw observation next is [26.45, 58.0, 1.0, 2.0, 0.2209080344782676, 1.0, 2.0, 0.2209080344782676, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533705.5357258641, 533705.5357258646, 163967.3731776379], 
processed observation next is [1.0, 0.8260869565217391, 0.5351851851851852, 0.58, 1.0, 1.0, 0.07250956485508046, 1.0, 1.0, 0.07250956485508046, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19060911990209434, 0.1906091199020945, 0.3153218714954575], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.8268272], dtype=float32), -2.0456424]. 
=============================================
[2019-03-24 08:19:30,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:30,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:30,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-24 08:19:31,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:31,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:31,440] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-24 08:19:32,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2329052e-07 9.9809477e-06 4.0504360e-06 9.9998188e-01 3.7192044e-06], sum to 1.0000
[2019-03-24 08:19:32,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-24 08:19:32,738] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.86666666666667, 71.0, 1.0, 2.0, 0.3703147331063389, 1.0, 2.0, 0.3703147331063389, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909209.7447827826, 909209.7447827826, 200735.8965920577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [23.15, 70.0, 1.0, 2.0, 0.4167561930338657, 1.0, 2.0, 0.4167561930338657, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1018057.081495708, 1018057.081495709, 213541.6596650025], 
processed observation next is [1.0, 0.34782608695652173, 0.4129629629629629, 0.7, 1.0, 1.0, 0.3056621345641258, 1.0, 1.0, 0.3056621345641258, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3635918148198957, 0.36359181481989605, 0.4106570378173125], 
reward next is 0.5893, 
noisyNet noise sample is [array([0.08161467], dtype=float32), 0.3844598]. 
=============================================
[2019-03-24 08:19:32,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.012466]
 [60.68834 ]
 [60.844376]
 [60.835655]
 [60.826397]], R is [[59.93581009]
 [59.95042038]
 [60.02904892]
 [60.12246704]
 [60.21540451]].
[2019-03-24 08:19:33,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:33,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:33,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-24 08:19:35,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:35,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:35,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:35,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:35,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-24 08:19:35,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-24 08:19:36,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:36,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:36,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:36,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:36,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-24 08:19:36,437] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:36,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:36,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-24 08:19:36,517] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-24 08:19:36,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:36,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:36,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:36,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:36,999] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-24 08:19:37,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-24 08:19:37,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:37,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:37,512] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-24 08:19:38,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:38,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:38,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-24 08:19:38,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:19:38,218] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:19:38,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-24 08:19:39,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4696745e-07 1.0690571e-07 1.1609485e-07 9.9999666e-01 3.0365293e-06], sum to 1.0000
[2019-03-24 08:19:39,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6800
[2019-03-24 08:19:39,305] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.68333333333334, 34.33333333333334, 1.0, 2.0, 0.1617443779644574, 1.0, 2.0, 0.1617443779644574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 412609.0895792873, 412609.0895792877, 152244.365750256], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 328200.0000, 
sim time next is 328800.0000, 
raw observation next is [26.56666666666667, 34.66666666666667, 1.0, 2.0, 0.1608866840212579, 1.0, 2.0, 0.1608866840212579, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410521.6753973809, 410521.6753973814, 152071.8935259866], 
processed observation next is [0.0, 0.8260869565217391, 0.5395061728395063, 0.34666666666666673, 1.0, 1.0, 0.0010555762157831942, 1.0, 1.0, 0.0010555762157831942, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14661488407049317, 0.14661488407049336, 0.2924459490884358], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.34078032], dtype=float32), -0.9800062]. 
=============================================
[2019-03-24 08:19:43,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4986809e-07 1.4594978e-06 1.6023210e-06 9.9997497e-01 2.1636864e-05], sum to 1.0000
[2019-03-24 08:19:43,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3663
[2019-03-24 08:19:43,949] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 14.5, 1.0, 2.0, 0.1816884175204382, 1.0, 2.0, 0.1816884175204382, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467321.3374159841, 467321.3374159846, 156349.4490595902], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 160200.0000, 
sim time next is 160800.0000, 
raw observation next is [31.93333333333334, 14.33333333333333, 1.0, 2.0, 0.1818195843265601, 1.0, 2.0, 0.1818195843265601, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467989.592787864, 467989.592787864, 156374.1055150606], 
processed observation next is [1.0, 0.8695652173913043, 0.7382716049382719, 0.1433333333333333, 1.0, 1.0, 0.025975695626857247, 1.0, 1.0, 0.025975695626857247, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16713914028138, 0.16713914028138, 0.30071943368280885], 
reward next is 0.6993, 
noisyNet noise sample is [array([-0.15071775], dtype=float32), 0.42962638]. 
=============================================
[2019-03-24 08:19:48,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.13721435e-05 8.69113137e-06 5.01285649e-05 9.99874473e-01
 5.53229365e-05], sum to 1.0000
[2019-03-24 08:19:48,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5268
[2019-03-24 08:19:48,313] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.81666666666667, 67.33333333333334, 1.0, 2.0, 0.1799391383521524, 1.0, 2.0, 0.1799391383521524, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 447758.4551323598, 447758.4551323603, 155784.0082638554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 201000.0000, 
sim time next is 201600.0000, 
raw observation next is [23.0, 68.0, 1.0, 2.0, 0.1855099074889761, 1.0, 2.0, 0.1855099074889761, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459907.0458982203, 459907.0458982203, 156898.7606303332], 
processed observation next is [0.0, 0.34782608695652173, 0.4074074074074074, 0.68, 1.0, 1.0, 0.03036893748687632, 1.0, 1.0, 0.03036893748687632, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16425251639222155, 0.16425251639222155, 0.3017283858275639], 
reward next is 0.6983, 
noisyNet noise sample is [array([0.16806854], dtype=float32), -0.92877734]. 
=============================================
[2019-03-24 08:19:54,513] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0329315e-04 1.2276262e-03 1.5415851e-04 9.9821401e-01 2.0094674e-04], sum to 1.0000
[2019-03-24 08:19:54,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6967
[2019-03-24 08:19:54,526] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.85, 47.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 360843.946708479, 360843.9467084795, 144510.3309357931], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 345000.0000, 
sim time next is 345600.0000, 
raw observation next is [22.7, 48.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 358821.2042698291, 358821.2042698296, 144190.8237130015], 
processed observation next is [1.0, 0.0, 0.39629629629629626, 0.48, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12815043009636753, 0.12815043009636773, 0.277290045601926], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2661731], dtype=float32), -0.6673995]. 
=============================================
[2019-03-24 08:19:57,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4628978e-06 1.9408768e-07 5.7287161e-07 9.9999547e-01 1.3528336e-06], sum to 1.0000
[2019-03-24 08:19:57,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5056
[2019-03-24 08:19:57,594] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 24.0, 1.0, 2.0, 0.4944417788110746, 1.0, 2.0, 0.4944417788110746, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1237279.032345827, 1237279.032345827, 237597.4507936629], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 396000.0000, 
sim time next is 396600.0000, 
raw observation next is [30.7, 24.16666666666666, 1.0, 2.0, 0.4847707529725432, 1.0, 2.0, 0.4847707529725432, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1212855.63592136, 1212855.63592136, 234555.5065232571], 
processed observation next is [1.0, 0.6086956521739131, 0.6925925925925925, 0.2416666666666666, 1.0, 1.0, 0.38663184877683715, 1.0, 1.0, 0.38663184877683715, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.43316272711477144, 0.43316272711477144, 0.4510682817754944], 
reward next is 0.5489, 
noisyNet noise sample is [array([-1.3797439], dtype=float32), -0.31012627]. 
=============================================
[2019-03-24 08:20:02,469] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9261553e-08 2.5507970e-07 1.3970620e-05 9.9998331e-01 2.3376924e-06], sum to 1.0000
[2019-03-24 08:20:02,479] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1050
[2019-03-24 08:20:02,482] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.05, 31.0, 1.0, 2.0, 0.1782491519362481, 1.0, 2.0, 0.1782491519362481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 445513.3244456208, 445513.3244456212, 155482.994509681], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [29.8, 32.0, 1.0, 2.0, 0.1772838663943734, 1.0, 2.0, 0.1772838663943734, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 442907.6813709484, 442907.6813709493, 155278.6303307574], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.32, 1.0, 1.0, 0.0205760314218731, 1.0, 1.0, 0.0205760314218731, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.1581813147753387, 0.15818131477533903, 0.29861275063607196], 
reward next is 0.7014, 
noisyNet noise sample is [array([-0.83860004], dtype=float32), 1.4019995]. 
=============================================
[2019-03-24 08:20:05,336] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 08:20:05,338] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:20:05,339] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:20:05,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:05,344] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:20:05,345] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:20:05,345] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:05,345] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:20:05,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:05,347] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:05,348] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:05,371] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-24 08:20:05,371] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-24 08:20:05,428] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-24 08:20:05,429] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-24 08:20:05,491] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-24 08:20:22,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:20:22,224] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.26666666666667, 81.0, 1.0, 2.0, 0.1749394057160916, 1.0, 2.0, 0.1749394057160916, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438048.4804608754, 438048.4804608754, 154818.1235121167]
[2019-03-24 08:20:22,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:20:22,228] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2937302e-06 4.4688181e-06 7.4635336e-06 9.9998033e-01 5.4479851e-06], sampled 0.030903488123266154
[2019-03-24 08:20:26,100] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:20:26,101] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.28333333333333, 68.0, 1.0, 2.0, 0.2539527629686004, 1.0, 2.0, 0.2539527629686004, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597712.5638536019, 597712.5638536019, 170692.9079292731]
[2019-03-24 08:20:26,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:20:26,105] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4680264e-07 1.5285126e-06 2.6058988e-06 9.9999321e-01 1.8561938e-06], sampled 0.855148406865014
[2019-03-24 08:20:43,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:20:43,952] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.39372227, 104.8094911, 1.0, 2.0, 0.2800501388029877, 1.0, 2.0, 0.2800501388029877, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650344.3967344064, 650344.3967344064, 176332.3393046542]
[2019-03-24 08:20:43,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:20:43,956] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.6766499e-07 1.0077240e-06 1.7056465e-06 9.9999547e-01 1.3780076e-06], sampled 0.7827631297163462
[2019-03-24 08:20:50,700] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:20:50,701] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.15, 70.0, 1.0, 2.0, 0.3379936470542599, 1.0, 2.0, 0.3379936470542599, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770420.5318281946, 770420.5318281951, 189827.9732687357]
[2019-03-24 08:20:50,702] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:20:50,707] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.7769777e-07 9.8848750e-07 1.7420846e-06 9.9999559e-01 1.1812843e-06], sampled 0.11350272417211638
[2019-03-24 08:21:07,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:21:07,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.56377101666667, 55.27695354666667, 1.0, 2.0, 0.6368127797522056, 1.0, 2.0, 0.6368127797522056, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1452192.431876362, 1452192.431876362, 280936.554142994]
[2019-03-24 08:21:07,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:21:07,863] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0170997e-07 6.2497520e-07 1.1702081e-06 9.9999714e-01 8.0747549e-07], sampled 0.4052445675287386
[2019-03-24 08:21:20,608] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:21:20,610] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.99577535333334, 74.13232985333333, 1.0, 2.0, 0.5421388613458319, 1.0, 2.0, 0.5421388613458319, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1236123.13522876, 1236123.13522876, 248721.5192850782]
[2019-03-24 08:21:20,611] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:21:20,614] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.7168820e-07 9.8296073e-07 1.7394117e-06 9.9999547e-01 1.2935693e-06], sampled 0.9627849436782742
[2019-03-24 08:21:45,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:21:45,212] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.48532927333333, 94.71257860666668, 1.0, 2.0, 0.1727743784322514, 1.0, 2.0, 0.1727743784322514, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 433778.8572985167, 433778.8572985171, 154397.8207909036]
[2019-03-24 08:21:45,216] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:21:45,221] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0860676e-06 2.2768834e-06 3.6706454e-06 9.9998987e-01 3.0982299e-06], sampled 0.8731728154516617
[2019-03-24 08:21:49,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01021311], dtype=float32), 0.0086360015]
[2019-03-24 08:21:49,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.48190174, 87.72427636, 1.0, 2.0, 0.1973889561227124, 1.0, 2.0, 0.1973889561227124, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 486057.9991290136, 486057.999129014, 159281.8571039577]
[2019-03-24 08:21:49,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:21:49,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9194558e-06 3.8343214e-06 6.2938575e-06 9.9998331e-01 4.7033063e-06], sampled 0.8372447151880412
[2019-03-24 08:21:52,532] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:21:52,904] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3655 2465940860.4540 46.0000
[2019-03-24 08:21:52,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:21:52,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:21:53,042] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5243 2410717485.0912 22.0000
[2019-03-24 08:21:54,064] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1500000, evaluation results [1500000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.524305667465, 2410717485.091218, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.365512649934, 2465940860.453995, 46.0]
[2019-03-24 08:21:59,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8190938e-07 5.6528670e-06 8.6584345e-07 9.9998820e-01 4.7274011e-06], sum to 1.0000
[2019-03-24 08:21:59,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-24 08:21:59,291] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 37.33333333333334, 1.0, 2.0, 0.221414275381624, 1.0, 2.0, 0.221414275381624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534146.7608772811, 534146.7608772815, 164048.1155488683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 822000.0000, 
sim time next is 822600.0000, 
raw observation next is [31.5, 37.0, 1.0, 2.0, 0.2227780078146298, 1.0, 2.0, 0.2227780078146298, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536928.9737933243, 536928.9737933243, 164325.1160295072], 
processed observation next is [0.0, 0.5217391304347826, 0.7222222222222222, 0.37, 1.0, 1.0, 0.074735723588845, 1.0, 1.0, 0.074735723588845, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19176034778333012, 0.19176034778333012, 0.31600983851828307], 
reward next is 0.6840, 
noisyNet noise sample is [array([-0.8217136], dtype=float32), -1.0162483]. 
=============================================
[2019-03-24 08:22:09,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4821135e-06 8.8847891e-08 7.4889458e-06 9.9998999e-01 9.7596376e-07], sum to 1.0000
[2019-03-24 08:22:09,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7429
[2019-03-24 08:22:09,986] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 57.16666666666666, 1.0, 2.0, 0.396747381439684, 1.0, 2.0, 0.396747381439684, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 983163.202152555, 983163.2021525555, 208241.1582430362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 985800.0000, 
sim time next is 986400.0000, 
raw observation next is [24.2, 57.0, 1.0, 2.0, 0.4116614857399245, 1.0, 2.0, 0.4116614857399245, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1018380.033603192, 1018380.033603192, 212424.31745482], 
processed observation next is [1.0, 0.43478260869565216, 0.45185185185185184, 0.57, 1.0, 1.0, 0.2995970068332435, 1.0, 1.0, 0.2995970068332435, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36370715485828287, 0.36370715485828287, 0.40850830279773076], 
reward next is 0.5915, 
noisyNet noise sample is [array([2.1942413], dtype=float32), -0.7874222]. 
=============================================
[2019-03-24 08:22:14,330] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8011821e-06 3.9053706e-05 2.2692790e-05 9.9989033e-01 4.5092915e-05], sum to 1.0000
[2019-03-24 08:22:14,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2415
[2019-03-24 08:22:14,342] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.73333333333333, 76.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 360079.6861550231, 360079.6861550235, 144580.0353382539], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1140000.0000, 
sim time next is 1140600.0000, 
raw observation next is [18.71666666666667, 76.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 353751.0286089496, 353751.02860895, 143643.6334936027], 
processed observation next is [1.0, 0.17391304347826086, 0.2487654320987655, 0.7683333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12633965307462486, 0.126339653074625, 0.27623775671846673], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20046495], dtype=float32), 0.08942976]. 
=============================================
[2019-03-24 08:22:20,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8215061e-05 1.2607905e-05 3.2682881e-06 9.9991655e-01 2.9339988e-05], sum to 1.0000
[2019-03-24 08:22:20,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9085
[2019-03-24 08:22:20,488] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333333, 46.33333333333334, 1.0, 2.0, 0.4194038137476648, 1.0, 2.0, 0.4194038137476648, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1047983.722436666, 1047983.722436666, 214871.4524757495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1080600.0000, 
sim time next is 1081200.0000, 
raw observation next is [25.46666666666667, 45.66666666666667, 1.0, 2.0, 0.3495816933228602, 1.0, 2.0, 0.3495816933228602, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873795.9744029912, 873795.9744029912, 195561.4756482221], 
processed observation next is [1.0, 0.5217391304347826, 0.4987654320987655, 0.4566666666666667, 1.0, 1.0, 0.22569249205102407, 1.0, 1.0, 0.22569249205102407, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31206999085821113, 0.31206999085821113, 0.3760797608619656], 
reward next is 0.6239, 
noisyNet noise sample is [array([-0.00698477], dtype=float32), 0.07675572]. 
=============================================
[2019-03-24 08:22:23,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1401091e-05 7.3382937e-05 3.3741133e-05 9.9983227e-01 4.9089827e-05], sum to 1.0000
[2019-03-24 08:22:23,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-24 08:22:23,584] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.96666666666667, 53.00000000000001, 1.0, 2.0, 0.3736471141338013, 1.0, 2.0, 0.3736471141338013, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934057.5810703235, 934057.5810703235, 202025.2194869556], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1074000.0000, 
sim time next is 1074600.0000, 
raw observation next is [24.05, 52.5, 1.0, 2.0, 0.400678208633585, 1.0, 2.0, 0.400678208633585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1001734.421948766, 1001734.421948767, 209531.1315678734], 
processed observation next is [1.0, 0.43478260869565216, 0.4462962962962963, 0.525, 1.0, 1.0, 0.28652167694474406, 1.0, 1.0, 0.28652167694474406, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3577622935531307, 0.3577622935531311, 0.4029444837843719], 
reward next is 0.5971, 
noisyNet noise sample is [array([0.6231377], dtype=float32), -0.55498827]. 
=============================================
[2019-03-24 08:22:25,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3528021e-06 1.2751056e-07 3.1871500e-06 9.9996579e-01 2.8649112e-05], sum to 1.0000
[2019-03-24 08:22:25,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6857
[2019-03-24 08:22:25,905] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.2, 67.66666666666667, 1.0, 2.0, 0.2087949721673553, 1.0, 2.0, 0.2087949721673553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533012.6622934365, 533012.6622934369, 162037.6332423715], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1153200.0000, 
sim time next is 1153800.0000, 
raw observation next is [20.25, 67.5, 1.0, 2.0, 0.232766346128727, 1.0, 2.0, 0.232766346128727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593235.1014598651, 593235.1014598656, 167279.2863314899], 
processed observation next is [1.0, 0.34782608695652173, 0.3055555555555556, 0.675, 1.0, 1.0, 0.0866266025341988, 1.0, 1.0, 0.0866266025341988, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21186967909280896, 0.21186967909280913, 0.3216909352528652], 
reward next is 0.6783, 
noisyNet noise sample is [array([-0.843099], dtype=float32), -0.7023819]. 
=============================================
[2019-03-24 08:22:25,949] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4384917e-07 4.6447138e-07 8.4882083e-07 9.9999726e-01 1.2030112e-06], sum to 1.0000
[2019-03-24 08:22:25,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3593
[2019-03-24 08:22:25,961] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 346402.2059179703, 346402.2059179708, 142604.98562599], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1144800.0000, 
sim time next is 1145400.0000, 
raw observation next is [19.26666666666667, 73.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394163.7160089549, 394163.7160089553, 149653.9106923528], 
processed observation next is [1.0, 0.2608695652173913, 0.2691358024691359, 0.735, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1407727557174839, 0.14077275571748404, 0.28779598210067847], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6390929], dtype=float32), -0.22550167]. 
=============================================
[2019-03-24 08:22:27,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3630084e-06 2.9678733e-06 2.9657189e-05 9.9995232e-01 1.2595016e-05], sum to 1.0000
[2019-03-24 08:22:27,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5856
[2019-03-24 08:22:27,914] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.4, 88.5, 1.0, 2.0, 0.1748983623832969, 1.0, 2.0, 0.1748983623832969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437607.8744022131, 437607.8744022136, 154801.9985655017], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1200600.0000, 
sim time next is 1201200.0000, 
raw observation next is [19.33333333333333, 89.0, 1.0, 2.0, 0.1751419242484328, 1.0, 2.0, 0.1751419242484328, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438253.9756310573, 438253.9756310578, 154853.0087695233], 
processed observation next is [1.0, 0.9130434782608695, 0.27160493827160476, 0.89, 1.0, 1.0, 0.018026100295753338, 1.0, 1.0, 0.018026100295753338, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1565192770110919, 0.15651927701109208, 0.29779424763369866], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.7827629], dtype=float32), 0.2064067]. 
=============================================
[2019-03-24 08:22:29,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6646756e-09 7.4928110e-08 2.2899964e-07 9.9999964e-01 5.2538727e-08], sum to 1.0000
[2019-03-24 08:22:29,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1748
[2019-03-24 08:22:29,305] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.93333333333333, 65.0, 1.0, 2.0, 0.3183689431078686, 1.0, 2.0, 0.3183689431078686, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 799659.5752499886, 799659.575249989, 187556.221387838], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1171200.0000, 
sim time next is 1171800.0000, 
raw observation next is [22.0, 65.0, 1.0, 2.0, 0.3446659278224096, 1.0, 2.0, 0.3446659278224096, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 863278.7872275825, 863278.787227583, 194299.3182991782], 
processed observation next is [1.0, 0.5652173913043478, 0.37037037037037035, 0.65, 1.0, 1.0, 0.21984039026477337, 1.0, 1.0, 0.21984039026477337, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30831385258127947, 0.30831385258127963, 0.37365253519072733], 
reward next is 0.6263, 
noisyNet noise sample is [array([-0.44220975], dtype=float32), 0.88751787]. 
=============================================
[2019-03-24 08:22:32,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9244256e-09 9.9594928e-08 2.5594113e-07 9.9999964e-01 5.6515891e-08], sum to 1.0000
[2019-03-24 08:22:32,964] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4051
[2019-03-24 08:22:32,967] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.7, 70.0, 1.0, 2.0, 0.2091032076197918, 1.0, 2.0, 0.2091032076197918, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510396.7869806964, 510396.7869806964, 161618.285427203], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1283400.0000, 
sim time next is 1284000.0000, 
raw observation next is [23.5, 71.0, 1.0, 2.0, 0.2085440455810902, 1.0, 2.0, 0.2085440455810902, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509359.9782602221, 509359.9782602221, 161510.059801755], 
processed observation next is [1.0, 0.8695652173913043, 0.42592592592592593, 0.71, 1.0, 1.0, 0.057790530453678796, 1.0, 1.0, 0.057790530453678796, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18191427795007933, 0.18191427795007933, 0.31059626884952884], 
reward next is 0.6894, 
noisyNet noise sample is [array([0.01085777], dtype=float32), -0.23779254]. 
=============================================
[2019-03-24 08:22:32,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.46867 ]
 [69.66982 ]
 [69.68332 ]
 [69.62651 ]
 [69.727615]], R is [[69.38293457]
 [69.3782959 ]
 [69.37336731]
 [69.36807251]
 [69.36284637]].
[2019-03-24 08:22:33,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4382143e-07 1.4434874e-08 4.5933055e-07 9.9999869e-01 9.4897658e-08], sum to 1.0000
[2019-03-24 08:22:33,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-24 08:22:33,956] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 48.33333333333334, 1.0, 2.0, 0.3792099076863775, 1.0, 2.0, 0.3792099076863775, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 931043.8743901848, 931043.8743901852, 203157.0751887091], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.71666666666667, 47.66666666666667, 1.0, 2.0, 0.3871188252866785, 1.0, 2.0, 0.3871188252866785, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 950635.1070763461, 950635.1070763465, 205338.272337941], 
processed observation next is [1.0, 0.5217391304347826, 0.5450617283950618, 0.47666666666666674, 1.0, 1.0, 0.2703795539127125, 1.0, 1.0, 0.2703795539127125, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33951253824155214, 0.3395125382415523, 0.39488129295757884], 
reward next is 0.6051, 
noisyNet noise sample is [array([-0.04763817], dtype=float32), -1.0514373]. 
=============================================
[2019-03-24 08:22:38,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6146370e-08 1.2336408e-08 7.0824370e-08 9.9999964e-01 2.2433278e-07], sum to 1.0000
[2019-03-24 08:22:38,371] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.626758e-08 8.055637e-08 1.040497e-06 9.999981e-01 6.968798e-07], sum to 1.0000
[2019-03-24 08:22:38,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-24 08:22:38,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1485
[2019-03-24 08:22:38,380] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.6, 67.0, 1.0, 2.0, 0.162603387295236, 1.0, 2.0, 0.162603387295236, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410118.4835385369, 410118.4835385374, 152364.0803612978], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1386000.0000, 
sim time next is 1386600.0000, 
raw observation next is [21.51666666666667, 67.0, 1.0, 2.0, 0.16131839826079, 1.0, 2.0, 0.16131839826079, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 407230.3023363766, 407230.3023363761, 152110.9971892206], 
processed observation next is [0.0, 0.043478260869565216, 0.35246913580246925, 0.67, 1.0, 1.0, 0.0015695217390357132, 1.0, 1.0, 0.0015695217390357132, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14543939369156308, 0.1454393936915629, 0.29252114844080884], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.9936255], dtype=float32), 0.5968057]. 
=============================================
[2019-03-24 08:22:38,387] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.4, 22.0, 1.0, 2.0, 0.208697025152476, 1.0, 2.0, 0.208697025152476, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510516.1453257403, 510516.1453257408, 161568.2822268158], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1517400.0000, 
sim time next is 1518000.0000, 
raw observation next is [35.53333333333333, 21.33333333333333, 1.0, 2.0, 0.2090107926479195, 1.0, 2.0, 0.2090107926479195, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512058.5365688694, 512058.5365688698, 161660.0219053803], 
processed observation next is [0.0, 0.5652173913043478, 0.8716049382716049, 0.2133333333333333, 1.0, 1.0, 0.05834618172371368, 1.0, 1.0, 0.05834618172371368, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1828780487745962, 0.18287804877459635, 0.3108846575103467], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.34771144], dtype=float32), -0.20034155]. 
=============================================
[2019-03-24 08:22:38,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.93698 ]
 [68.93923 ]
 [68.94848 ]
 [69.01541 ]
 [68.989914]], R is [[68.87103271]
 [68.87161255]
 [68.87210083]
 [68.87110901]
 [68.87232971]].
[2019-03-24 08:22:38,504] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8029360e-05 3.0481986e-06 2.6170863e-05 9.9989831e-01 4.4033713e-06], sum to 1.0000
[2019-03-24 08:22:38,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-24 08:22:38,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.85, 45.5, 1.0, 2.0, 0.1624438409766892, 1.0, 2.0, 0.1624438409766892, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408501.5092546438, 408501.5092546442, 152309.9724354488], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1409400.0000, 
sim time next is 1410000.0000, 
raw observation next is [26.2, 44.66666666666666, 1.0, 2.0, 0.1650068292520633, 1.0, 2.0, 0.1650068292520633, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 414219.0921143289, 414219.0921143293, 152813.1498634968], 
processed observation next is [0.0, 0.30434782608695654, 0.5259259259259259, 0.44666666666666655, 1.0, 1.0, 0.005960511014361077, 1.0, 1.0, 0.005960511014361077, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14793539004083173, 0.1479353900408319, 0.29387144204518617], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.3018382], dtype=float32), 0.9068953]. 
=============================================
[2019-03-24 08:22:38,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.437225]
 [69.3376  ]
 [69.2514  ]
 [69.22217 ]
 [69.12434 ]], R is [[69.57301331]
 [69.5843811 ]
 [68.88853455]
 [68.19965363]
 [67.51765442]].
[2019-03-24 08:22:42,840] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 08:22:42,843] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:22:42,844] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:22:42,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:42,844] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:42,846] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:22:42,846] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:22:42,847] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:42,848] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:42,848] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:22:42,849] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:42,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-24 08:22:42,901] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-24 08:22:42,938] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-24 08:22:42,967] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-24 08:22:42,968] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-24 08:22:45,005] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:22:45,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.73021969, 52.782868905, 1.0, 2.0, 0.1935241835722323, 1.0, 2.0, 0.1935241835722323, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 477383.0977342177, 477383.0977342182, 158500.0890631039]
[2019-03-24 08:22:45,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:22:45,010] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.4883411e-08 1.6149232e-07 5.5404013e-07 9.9999905e-01 2.0938219e-07], sampled 0.8354192825583703
[2019-03-24 08:22:51,341] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:22:51,342] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.12533493, 43.0107693, 1.0, 2.0, 0.2751746118611698, 1.0, 2.0, 0.2751746118611698, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 627172.6548242045, 627172.654824205, 174610.8793070779]
[2019-03-24 08:22:51,342] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:22:51,344] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.1041435e-08 1.4917093e-07 5.5319748e-07 9.9999905e-01 1.8670619e-07], sampled 0.9738597606721773
[2019-03-24 08:22:57,641] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:22:57,642] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 52.66666666666667, 1.0, 2.0, 0.1787733986966827, 1.0, 2.0, 0.1787733986966827, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 451912.0672069274, 451912.0672069278, 155691.5102849182]
[2019-03-24 08:22:57,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:22:57,645] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3408849e-07 2.5088423e-07 8.1476020e-07 9.9999845e-01 3.3600045e-07], sampled 0.5016425646842112
[2019-03-24 08:23:12,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:23:12,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.75, 58.33333333333334, 1.0, 2.0, 0.2760447397648654, 1.0, 2.0, 0.2760447397648654, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 640527.8541518688, 640527.8541518693, 175371.1711899983]
[2019-03-24 08:23:12,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:23:12,954] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8081464e-08 9.2600111e-08 3.3757684e-07 9.9999940e-01 1.1920745e-07], sampled 0.3177407193368287
[2019-03-24 08:23:52,271] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:23:52,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 86.66666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.852451101234649, 6.9112, 135.8385943635465, 2864504.007135277, 2327499.455688886, 446482.433433964]
[2019-03-24 08:23:52,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:23:52,278] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4613602e-08 1.2470966e-07 4.3439491e-07 9.9999928e-01 1.6814759e-07], sampled 0.8491203579023399
[2019-03-24 08:23:52,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2864504.007135277 W.
[2019-03-24 08:24:07,860] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:24:07,861] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 51.66666666666667, 1.0, 2.0, 0.3238930972935522, 1.0, 2.0, 0.3238930972935522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 801849.6634839317, 801849.6634839321, 188725.0823894466]
[2019-03-24 08:24:07,862] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:24:07,865] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4687925e-08 1.4325995e-07 4.9304236e-07 9.9999905e-01 1.9217251e-07], sampled 0.3237858544329535
[2019-03-24 08:24:18,424] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:24:18,425] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 20.16666666666667, 1.0, 2.0, 0.4665687529611252, 1.0, 2.0, 0.4665687529611252, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1171298.411213773, 1171298.411213773, 228997.1782099976]
[2019-03-24 08:24:18,426] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:24:18,430] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2284160e-07 2.2696845e-07 7.7626720e-07 9.9999857e-01 2.9200970e-07], sampled 0.41086212409623735
[2019-03-24 08:24:23,574] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01034927], dtype=float32), 0.008765803]
[2019-03-24 08:24:23,584] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.23333333333333, 32.66666666666666, 1.0, 2.0, 0.1663611270370911, 1.0, 2.0, 0.1663611270370911, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423764.9433923911, 423764.9433923916, 153176.3018099646]
[2019-03-24 08:24:23,586] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:24:23,590] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.8315964e-08 1.6792414e-07 5.6862694e-07 9.9999893e-01 2.2209470e-07], sampled 0.029015521974855907
[2019-03-24 08:24:25,903] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:24:26,131] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:24:26,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:24:26,461] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:24:26,649] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 08:24:27,667] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1525000, evaluation results [1525000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:24:28,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0379993e-07 1.0887376e-07 2.2417557e-07 9.9999857e-01 9.4535028e-07], sum to 1.0000
[2019-03-24 08:24:28,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5914
[2019-03-24 08:24:28,712] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.06666666666667, 31.33333333333334, 1.0, 2.0, 0.1812753797258018, 1.0, 2.0, 0.1812753797258018, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452717.8716397724, 452717.8716397724, 156102.9517705586], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1457400.0000, 
sim time next is 1458000.0000, 
raw observation next is [29.9, 32.0, 1.0, 2.0, 0.1805610070996396, 1.0, 2.0, 0.1805610070996396, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 450803.696640365, 450803.6966403655, 155951.1406943187], 
processed observation next is [0.0, 0.9130434782608695, 0.6629629629629629, 0.32, 1.0, 1.0, 0.02447738940433285, 1.0, 1.0, 0.02447738940433285, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16100132022870178, 0.16100132022870198, 0.2999060397967667], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.1075088], dtype=float32), -1.7602077]. 
=============================================
[2019-03-24 08:24:28,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.54031 ]
 [66.59108 ]
 [66.67976 ]
 [66.6871  ]
 [66.751305]], R is [[66.57653809]
 [66.61057281]
 [66.64398193]
 [66.6767807 ]
 [66.70897675]].
[2019-03-24 08:24:29,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4253156e-07 9.2004802e-07 3.5360972e-07 9.9999809e-01 4.7732101e-07], sum to 1.0000
[2019-03-24 08:24:29,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0145
[2019-03-24 08:24:29,896] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.66666666666666, 20.66666666666667, 1.0, 2.0, 0.2092830679619556, 1.0, 2.0, 0.2092830679619556, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513509.3662592316, 513509.366259232, 161742.6951897192], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1518600.0000, 
sim time next is 1519200.0000, 
raw observation next is [35.8, 20.0, 1.0, 2.0, 0.2095450894720816, 1.0, 2.0, 0.2095450894720816, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514950.3441350579, 514950.3441350575, 161823.0918056608], 
processed observation next is [0.0, 0.6086956521739131, 0.8814814814814814, 0.2, 1.0, 1.0, 0.05898224937152573, 1.0, 1.0, 0.05898224937152573, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1839108371910921, 0.18391083719109194, 0.31119825347242464], 
reward next is 0.6888, 
noisyNet noise sample is [array([-2.2749755], dtype=float32), -1.3009413]. 
=============================================
[2019-03-24 08:24:30,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4031527e-07 4.2597264e-07 1.4945497e-06 9.9999547e-01 1.8384153e-06], sum to 1.0000
[2019-03-24 08:24:30,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8305
[2019-03-24 08:24:30,908] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 73.33333333333334, 1.0, 2.0, 0.2279751749731218, 1.0, 2.0, 0.2279751749731218, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 552490.8291008882, 552490.8291008887, 165569.5266614045], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1545600.0000, 
sim time next is 1546200.0000, 
raw observation next is [23.6, 72.5, 1.0, 2.0, 0.2255908156599482, 1.0, 2.0, 0.2255908156599482, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547774.7669585983, 547774.7669585987, 165084.5654966689], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.725, 1.0, 1.0, 0.07808430435708119, 1.0, 1.0, 0.07808430435708119, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19563384534235653, 0.1956338453423567, 0.3174703182628248], 
reward next is 0.6825, 
noisyNet noise sample is [array([-0.7166979], dtype=float32), -0.43136898]. 
=============================================
[2019-03-24 08:24:37,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2085964e-06 9.9250059e-08 4.8780830e-06 9.9999082e-01 9.5999917e-07], sum to 1.0000
[2019-03-24 08:24:37,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0516
[2019-03-24 08:24:37,916] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 74.5, 1.0, 2.0, 0.2809183654682825, 1.0, 2.0, 0.2809183654682825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697388.4076933098, 697388.4076933103, 178156.4137289495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1686600.0000, 
sim time next is 1687200.0000, 
raw observation next is [21.66666666666667, 74.0, 1.0, 2.0, 0.2856557712637548, 1.0, 2.0, 0.2856557712637548, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 708581.3271891727, 708581.3271891732, 179281.7764328117], 
processed observation next is [1.0, 0.5217391304347826, 0.3580246913580249, 0.74, 1.0, 1.0, 0.14959020388542238, 1.0, 1.0, 0.14959020388542238, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2530647597104188, 0.253064759710419, 0.3447726469861763], 
reward next is 0.6552, 
noisyNet noise sample is [array([-1.3548352], dtype=float32), 2.2589138]. 
=============================================
[2019-03-24 08:24:43,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9246992e-08 7.1094703e-08 1.3337221e-06 9.9999845e-01 3.8091724e-08], sum to 1.0000
[2019-03-24 08:24:43,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2772
[2019-03-24 08:24:43,720] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 83.66666666666666, 1.0, 2.0, 0.2281323637616385, 1.0, 2.0, 0.2281323637616385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549077.8126293137, 549077.8126293137, 165465.0344728531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2080200.0000, 
sim time next is 2080800.0000, 
raw observation next is [22.5, 84.0, 1.0, 2.0, 0.2262143005390883, 1.0, 2.0, 0.2262143005390883, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 544980.9924951995, 544980.9924951999, 165065.1480203501], 
processed observation next is [0.0, 0.08695652173913043, 0.3888888888888889, 0.84, 1.0, 1.0, 0.07882654826081942, 1.0, 1.0, 0.07882654826081942, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19463606874828554, 0.19463606874828568, 0.31743297696221173], 
reward next is 0.6826, 
noisyNet noise sample is [array([1.0102853], dtype=float32), -1.2817392]. 
=============================================
[2019-03-24 08:24:46,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2864203e-08 1.9190691e-07 9.3102449e-07 9.9999595e-01 2.9140708e-06], sum to 1.0000
[2019-03-24 08:24:46,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3518
[2019-03-24 08:24:46,476] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 89.0, 1.0, 2.0, 0.2142023052249495, 1.0, 2.0, 0.2142023052249495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520889.5199799223, 520889.5199799227, 162643.6171201518], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1879200.0000, 
sim time next is 1879800.0000, 
raw observation next is [21.28333333333333, 89.16666666666667, 1.0, 2.0, 0.2153644904906034, 1.0, 2.0, 0.2153644904906034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523701.4883292301, 523701.4883292301, 162892.9620614137], 
processed observation next is [1.0, 0.782608695652174, 0.3438271604938271, 0.8916666666666667, 1.0, 1.0, 0.06591010772690882, 1.0, 1.0, 0.06591010772690882, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1870362458318679, 0.1870362458318679, 0.31325569627194944], 
reward next is 0.6867, 
noisyNet noise sample is [array([-0.20558755], dtype=float32), -0.38166934]. 
=============================================
[2019-03-24 08:24:46,993] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5552299e-09 5.4002960e-08 7.6756356e-07 9.9999928e-01 3.9509938e-08], sum to 1.0000
[2019-03-24 08:24:46,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9299
[2019-03-24 08:24:47,001] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.25, 87.5, 1.0, 2.0, 0.1699483740734089, 1.0, 2.0, 0.1699483740734089, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426772.624075297, 426772.6240752974, 153820.8880624835], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1834200.0000, 
sim time next is 1834800.0000, 
raw observation next is [19.4, 86.66666666666667, 1.0, 2.0, 0.1791129571831171, 1.0, 2.0, 0.1791129571831171, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449447.047313103, 449447.0473131035, 155701.7048906885], 
processed observation next is [1.0, 0.21739130434782608, 0.274074074074074, 0.8666666666666667, 1.0, 1.0, 0.022753520456091775, 1.0, 1.0, 0.022753520456091775, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1605168026118225, 0.1605168026118227, 0.29942635555901637], 
reward next is 0.7006, 
noisyNet noise sample is [array([-0.34587488], dtype=float32), -0.013220777]. 
=============================================
[2019-03-24 08:24:47,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8808197e-09 1.8057010e-07 1.0984006e-06 9.9999857e-01 1.7478368e-07], sum to 1.0000
[2019-03-24 08:24:47,335] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9825
[2019-03-24 08:24:47,339] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.46666666666667, 76.33333333333334, 1.0, 2.0, 0.2626476646650108, 1.0, 2.0, 0.2626476646650108, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651977.4337303058, 651977.4337303058, 173838.8939430045], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1844400.0000, 
sim time next is 1845000.0000, 
raw observation next is [21.5, 76.5, 1.0, 2.0, 0.305185928300963, 1.0, 2.0, 0.305185928300963, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755358.6987496401, 755358.6987496406, 184019.4957460115], 
processed observation next is [1.0, 0.34782608695652173, 0.35185185185185186, 0.765, 1.0, 1.0, 0.1728403908344798, 1.0, 1.0, 0.1728403908344798, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2697709638391572, 0.2697709638391574, 0.3538836456654067], 
reward next is 0.6461, 
noisyNet noise sample is [array([-0.51855993], dtype=float32), -0.5448516]. 
=============================================
[2019-03-24 08:24:47,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.142456]
 [63.474922]
 [63.538513]
 [63.582233]
 [63.602425]], R is [[63.00039673]
 [63.03608704]
 [63.10351181]
 [63.17417526]
 [63.24436951]].
[2019-03-24 08:24:49,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7898860e-06 1.8686034e-06 7.5242979e-06 9.9998832e-01 4.3941924e-07], sum to 1.0000
[2019-03-24 08:24:49,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1559
[2019-03-24 08:24:49,042] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.58333333333333, 75.66666666666666, 1.0, 2.0, 0.1983583334015216, 1.0, 2.0, 0.1983583334015216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486493.8752432713, 486493.8752432713, 159424.9008176511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2019000.0000, 
sim time next is 2019600.0000, 
raw observation next is [22.8, 75.0, 1.0, 2.0, 0.2017415560773909, 1.0, 2.0, 0.2017415560773909, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493899.6004734024, 493899.6004734029, 160107.459251427], 
processed observation next is [0.0, 0.391304347826087, 0.4, 0.75, 1.0, 1.0, 0.049692328663560575, 1.0, 1.0, 0.049692328663560575, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17639271445478658, 0.17639271445478674, 0.3078989600988981], 
reward next is 0.6921, 
noisyNet noise sample is [array([1.2532995], dtype=float32), 0.28516382]. 
=============================================
[2019-03-24 08:24:55,399] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1114721e-08 1.1823787e-06 6.3732223e-06 9.9997449e-01 1.7878849e-05], sum to 1.0000
[2019-03-24 08:24:55,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7743
[2019-03-24 08:24:55,409] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 63.00000000000001, 1.0, 2.0, 0.2979765149239156, 1.0, 2.0, 0.2979765149239156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679165.3317589647, 679165.3317589652, 179975.834513232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [28.95, 63.0, 1.0, 2.0, 0.2989461386541771, 1.0, 2.0, 0.2989461386541771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 681376.336493872, 681376.3364938725, 180208.0200312425], 
processed observation next is [0.0, 0.6956521739130435, 0.6277777777777778, 0.63, 1.0, 1.0, 0.16541206982640128, 1.0, 1.0, 0.16541206982640128, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2433486916049543, 0.24334869160495445, 0.34655388467546633], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.5480865], dtype=float32), -0.539922]. 
=============================================
[2019-03-24 08:24:59,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6282736e-08 2.7200628e-09 2.2980736e-07 9.9999964e-01 8.1448420e-08], sum to 1.0000
[2019-03-24 08:24:59,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1635
[2019-03-24 08:24:59,488] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.6, 91.0, 1.0, 2.0, 0.223314067957581, 1.0, 2.0, 0.223314067957581, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538439.4723150275, 538439.472315028, 164449.8584916452], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2097000.0000, 
sim time next is 2097600.0000, 
raw observation next is [21.73333333333333, 90.66666666666667, 1.0, 2.0, 0.2257936733443443, 1.0, 2.0, 0.2257936733443443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543546.5861578501, 543546.5861578506, 164957.3808977545], 
processed observation next is [0.0, 0.2608695652173913, 0.3604938271604937, 0.9066666666666667, 1.0, 1.0, 0.07832580160040989, 1.0, 1.0, 0.07832580160040989, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19412378077066075, 0.19412378077066092, 0.31722573249568176], 
reward next is 0.6828, 
noisyNet noise sample is [array([0.3321645], dtype=float32), -0.14135313]. 
=============================================
[2019-03-24 08:25:04,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.05776564e-07 9.54338404e-08 4.87280829e-07 9.99998569e-01
 7.30730960e-07], sum to 1.0000
[2019-03-24 08:25:04,313] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8369
[2019-03-24 08:25:04,316] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.75, 97.5, 1.0, 2.0, 0.2470984980696996, 1.0, 2.0, 0.2470984980696996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584911.1993700694, 584911.1993700699, 169292.4688243327], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2259000.0000, 
sim time next is 2259600.0000, 
raw observation next is [21.6, 97.33333333333333, 1.0, 2.0, 0.2432684599210748, 1.0, 2.0, 0.2432684599210748, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577717.4862688354, 577717.4862688354, 168513.7630330767], 
processed observation next is [1.0, 0.13043478260869565, 0.3555555555555556, 0.9733333333333333, 1.0, 1.0, 0.09912911895366047, 1.0, 1.0, 0.09912911895366047, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2063276736674412, 0.2063276736674412, 0.3240649289097629], 
reward next is 0.6759, 
noisyNet noise sample is [array([-1.7017419], dtype=float32), 1.540738]. 
=============================================
[2019-03-24 08:25:10,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4117298e-09 6.2529161e-08 1.2385399e-06 9.9999845e-01 1.8227045e-07], sum to 1.0000
[2019-03-24 08:25:10,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7851
[2019-03-24 08:25:10,578] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.25, 67.66666666666667, 1.0, 2.0, 0.4746914570992422, 1.0, 2.0, 0.4746914570992422, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1108980.292274289, 1108980.29227429, 228899.2850078664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2307000.0000, 
sim time next is 2307600.0000, 
raw observation next is [26.3, 67.0, 1.0, 2.0, 0.4702290087357949, 1.0, 2.0, 0.4702290087357949, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1099915.414297986, 1099915.414297987, 227608.3499600326], 
processed observation next is [1.0, 0.7391304347826086, 0.5296296296296297, 0.67, 1.0, 1.0, 0.3693202484949939, 1.0, 1.0, 0.3693202484949939, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.39282693367785215, 0.3928269336778525, 0.437708365307755], 
reward next is 0.5623, 
noisyNet noise sample is [array([-1.880415], dtype=float32), -0.7497462]. 
=============================================
[2019-03-24 08:25:10,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5121350e-06 1.8337886e-06 2.0644864e-05 9.9987888e-01 9.7188495e-05], sum to 1.0000
[2019-03-24 08:25:10,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6914
[2019-03-24 08:25:10,981] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.73333333333333, 73.0, 1.0, 2.0, 0.6006246991723867, 1.0, 2.0, 0.6006246991723867, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1388307.085950593, 1388307.085950593, 269166.4131448966], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2301600.0000, 
sim time next is 2302200.0000, 
raw observation next is [25.8, 72.5, 1.0, 2.0, 0.6107592474058829, 1.0, 2.0, 0.6107592474058829, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1412262.860822327, 1412262.860822328, 272713.9427483684], 
processed observation next is [1.0, 0.6521739130434783, 0.5111111111111112, 0.725, 1.0, 1.0, 0.5366181516736701, 1.0, 1.0, 0.5366181516736701, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.504379593150831, 0.5043795931508314, 0.5244498899007085], 
reward next is 0.4756, 
noisyNet noise sample is [array([-1.1605413], dtype=float32), 0.1473866]. 
=============================================
[2019-03-24 08:25:16,724] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:25:16,732] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:25:16,733] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:25:16,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:16,733] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:16,734] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:25:16,735] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:25:16,736] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:16,736] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:16,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:25:16,740] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:16,752] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-24 08:25:16,788] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-24 08:25:16,788] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-24 08:25:16,850] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-24 08:25:16,852] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-24 08:25:39,313] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:25:39,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [16.07521899333333, 94.73233483333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 342205.7919331987, 342205.7919331992, 141716.3421423974]
[2019-03-24 08:25:39,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:25:39,317] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2869213e-07 3.7427452e-07 2.0250925e-06 9.9999678e-01 6.0501441e-07], sampled 0.5884254519891848
[2019-03-24 08:25:40,757] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:25:40,758] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 64.33333333333334, 1.0, 2.0, 0.3017763981016939, 1.0, 2.0, 0.3017763981016939, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687830.1311047046, 687830.1311047049, 180887.6339359414]
[2019-03-24 08:25:40,759] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:25:40,761] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6528472e-07 2.7289931e-07 1.5565216e-06 9.9999762e-01 4.1772014e-07], sampled 0.6856371735125062
[2019-03-24 08:25:42,589] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:25:42,591] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.1, 89.0, 1.0, 2.0, 0.2962385736815409, 1.0, 2.0, 0.2962385736815409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683388.009593508, 683388.0095935084, 179963.176817713]
[2019-03-24 08:25:42,593] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:25:42,595] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9190149e-07 3.1829993e-07 1.7504644e-06 9.9999726e-01 5.1120657e-07], sampled 0.4159745991133066
[2019-03-24 08:25:59,762] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:25:59,764] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.27134788166667, 55.22726710000001, 1.0, 2.0, 0.4882771268489269, 1.0, 2.0, 0.4882771268489269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1124931.197783839, 1124931.197783839, 232340.5224305542]
[2019-03-24 08:25:59,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:25:59,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.102568e-07 3.314909e-07 1.969812e-06 9.999970e-01 5.047624e-07], sampled 0.7509358791084325
[2019-03-24 08:26:44,176] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:26:44,177] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.66666666666667, 90.0, 1.0, 2.0, 0.2213793956172037, 1.0, 2.0, 0.2213793956172037, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534278.8963325875, 534278.8963325875, 164048.6349020353]
[2019-03-24 08:26:44,178] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:26:44,180] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9574519e-07 3.2218495e-07 1.7926693e-06 9.9999714e-01 5.0820830e-07], sampled 0.48699159132082315
[2019-03-24 08:26:52,314] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01027748], dtype=float32), 0.008763278]
[2019-03-24 08:26:52,315] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.2930738773076691, 1.0, 2.0, 0.2930738773076691, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672544.944337931, 672544.944337931, 179034.6100205163]
[2019-03-24 08:26:52,316] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:26:52,319] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2931736e-07 2.1428578e-07 1.2746901e-06 9.9999797e-01 3.3032106e-07], sampled 0.7260033493845673
[2019-03-24 08:27:00,875] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:27:01,033] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2636 2438818757.2692 34.0000
[2019-03-24 08:27:01,082] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:27:01,304] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:27:01,371] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:27:02,391] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1550000, evaluation results [1550000.0, 7523.727130323888, 2668527814.010175, 68.0, 7122.263554302433, 2438818757.2691865, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:27:07,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4253753e-07 1.3129009e-07 1.2676842e-05 9.9998403e-01 2.3776458e-06], sum to 1.0000
[2019-03-24 08:27:07,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7885
[2019-03-24 08:27:07,408] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.73333333333333, 23.0, 1.0, 2.0, 0.5998233267901062, 1.0, 2.0, 0.5998233267901062, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1449506.199198661, 1449506.199198661, 271467.4425686826], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2472000.0000, 
sim time next is 2472600.0000, 
raw observation next is [34.66666666666667, 23.0, 1.0, 2.0, 0.6053364643887391, 1.0, 2.0, 0.6053364643887391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1463609.976537478, 1463609.976537479, 273432.3164719258], 
processed observation next is [1.0, 0.6086956521739131, 0.8395061728395063, 0.23, 1.0, 1.0, 0.5301624576056417, 1.0, 1.0, 0.5301624576056417, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.522717848763385, 0.5227178487633853, 0.5258313778306266], 
reward next is 0.4742, 
noisyNet noise sample is [array([-0.72830975], dtype=float32), 0.120903715]. 
=============================================
[2019-03-24 08:27:19,634] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9234187e-07 1.2938936e-07 3.8263879e-06 9.9999583e-01 2.0723334e-08], sum to 1.0000
[2019-03-24 08:27:19,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7672
[2019-03-24 08:27:19,653] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 49.0, 1.0, 2.0, 0.3168375253522716, 1.0, 2.0, 0.3168375253522716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 722174.6886609298, 722174.6886609303, 184550.1061745755], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2733000.0000, 
sim time next is 2733600.0000, 
raw observation next is [32.0, 49.0, 1.0, 2.0, 0.3040036468872777, 1.0, 2.0, 0.3040036468872777, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692908.9285079209, 692908.9285079214, 181424.2211043026], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.49, 1.0, 1.0, 0.1714329129610449, 1.0, 1.0, 0.1714329129610449, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24746747446711462, 0.24746747446711478, 0.3488927328928896], 
reward next is 0.6511, 
noisyNet noise sample is [array([-1.6263194], dtype=float32), -0.07898337]. 
=============================================
[2019-03-24 08:27:26,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4872642e-06 5.5965182e-07 2.9427523e-05 9.9996686e-01 1.6633536e-06], sum to 1.0000
[2019-03-24 08:27:26,685] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0123
[2019-03-24 08:27:26,689] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7401266993424378, 1.0, 2.0, 0.7401266993424378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1688033.189957967, 1688033.189957968, 319635.7465312223], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3056400.0000, 
sim time next is 3057000.0000, 
raw observation next is [27.16666666666666, 89.0, 1.0, 2.0, 0.7686294890787482, 1.0, 2.0, 0.7686294890787482, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1753104.30061116, 1753104.300611161, 330963.0990679567], 
processed observation next is [1.0, 0.391304347826087, 0.5617283950617282, 0.89, 1.0, 1.0, 0.7245589155699383, 1.0, 1.0, 0.7245589155699383, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6261086787897, 0.6261086787897003, 0.636467498207609], 
reward next is 0.3635, 
noisyNet noise sample is [array([-0.6561108], dtype=float32), 0.11047145]. 
=============================================
[2019-03-24 08:27:26,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.955853]
 [51.36355 ]
 [52.048943]
 [53.080696]
 [53.929455]], R is [[50.40578461]
 [50.28704071]
 [50.15293503]
 [50.05660248]
 [50.00393295]].
[2019-03-24 08:27:28,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7021955e-09 5.4480942e-08 4.3215294e-07 9.9999940e-01 6.1120708e-08], sum to 1.0000
[2019-03-24 08:27:28,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6129
[2019-03-24 08:27:28,427] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 79.0, 1.0, 2.0, 0.8316496253057208, 1.0, 2.0, 0.8316496253057208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1896994.424279654, 1896994.424279654, 357006.935001942], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2912400.0000, 
sim time next is 2913000.0000, 
raw observation next is [28.25, 79.83333333333334, 1.0, 2.0, 0.4433127249328996, 1.0, 2.0, 0.4433127249328996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1010642.443289328, 1010642.443289328, 218409.7130712544], 
processed observation next is [1.0, 0.7391304347826086, 0.6018518518518519, 0.7983333333333335, 1.0, 1.0, 0.3372770534915472, 1.0, 1.0, 0.3372770534915472, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3609437297461886, 0.3609437297461886, 0.42001867898318157], 
reward next is 0.5800, 
noisyNet noise sample is [array([0.8994452], dtype=float32), 0.29706308]. 
=============================================
[2019-03-24 08:27:28,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[55.736458]
 [55.66747 ]
 [55.741917]
 [55.7667  ]
 [55.591927]], R is [[58.17551422]
 [57.9072113 ]
 [57.63734818]
 [57.39054871]
 [57.17027283]].
[2019-03-24 08:27:29,261] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3255945e-07 7.6829542e-07 1.8522960e-06 9.9999678e-01 1.7531006e-07], sum to 1.0000
[2019-03-24 08:27:29,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5767
[2019-03-24 08:27:29,272] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3605292322116807, 1.0, 2.0, 0.3605292322116807, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821815.5366538906, 821815.5366538906, 195620.4800461393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2962200.0000, 
sim time next is 2962800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3907195398501945, 1.0, 2.0, 0.3907195398501945, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 890673.4217528201, 890673.4217528206, 203655.923824421], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.27466611886927916, 1.0, 1.0, 0.27466611886927916, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3180976506260072, 0.31809765062600737, 0.3916460073546558], 
reward next is 0.6084, 
noisyNet noise sample is [array([0.82066727], dtype=float32), -0.7626514]. 
=============================================
[2019-03-24 08:27:31,327] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5581081e-07 3.9153174e-06 7.6624026e-05 9.9991870e-01 3.5235635e-07], sum to 1.0000
[2019-03-24 08:27:31,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1840
[2019-03-24 08:27:31,338] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 80.66666666666667, 1.0, 2.0, 0.852006191729787, 1.0, 2.0, 0.852006191729787, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1943478.313700173, 1943478.313700173, 365713.7392718413], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2976600.0000, 
sim time next is 2977200.0000, 
raw observation next is [28.4, 80.0, 1.0, 2.0, 0.8777104603130071, 1.0, 2.0, 0.8777104603130071, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2002177.050830031, 2002177.050830032, 376912.8106029628], 
processed observation next is [1.0, 0.4782608695652174, 0.6074074074074074, 0.8, 1.0, 1.0, 0.8544172146583419, 1.0, 1.0, 0.8544172146583419, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7150632324392968, 0.7150632324392971, 0.7248323280826208], 
reward next is 0.2752, 
noisyNet noise sample is [array([1.5763435], dtype=float32), 0.62211454]. 
=============================================
[2019-03-24 08:27:40,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5109167e-07 9.4738903e-07 3.8637122e-06 9.9999273e-01 2.1479300e-06], sum to 1.0000
[2019-03-24 08:27:40,707] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5981
[2019-03-24 08:27:40,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 36.33333333333333, 1.0, 2.0, 0.6557106201712496, 1.0, 2.0, 0.6557106201712496, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1510251.978034312, 1510251.978034312, 288483.3881428778], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3156600.0000, 
sim time next is 3157200.0000, 
raw observation next is [34.0, 36.0, 1.0, 2.0, 0.655217570055437, 1.0, 2.0, 0.655217570055437, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1507735.02580309, 1507735.02580309, 288236.1777123157], 
processed observation next is [1.0, 0.5652173913043478, 0.8148148148148148, 0.36, 1.0, 1.0, 0.5895447262564726, 1.0, 1.0, 0.5895447262564726, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.538476794929675, 0.538476794929675, 0.5543003417544533], 
reward next is 0.4457, 
noisyNet noise sample is [array([0.1203011], dtype=float32), 0.7513348]. 
=============================================
[2019-03-24 08:27:40,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7716911e-06 1.3737971e-07 2.8053071e-06 9.9999523e-01 1.5905292e-07], sum to 1.0000
[2019-03-24 08:27:40,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5040
[2019-03-24 08:27:40,881] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.13333333333333, 53.0, 1.0, 2.0, 0.2846514340199084, 1.0, 2.0, 0.2846514340199084, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657932.5927231502, 657932.5927231506, 177270.0811015037], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3262800.0000, 
sim time next is 3263400.0000, 
raw observation next is [29.7, 55.0, 1.0, 2.0, 0.2850869132235946, 1.0, 2.0, 0.2850869132235946, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 658910.105258078, 658910.1052580784, 177371.4336569433], 
processed observation next is [0.0, 0.782608695652174, 0.6555555555555556, 0.55, 1.0, 1.0, 0.1489129919328507, 1.0, 1.0, 0.1489129919328507, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2353250375921707, 0.23532503759217085, 0.3410989108787371], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.35761762], dtype=float32), -0.04159076]. 
=============================================
[2019-03-24 08:27:42,671] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4868408e-05 1.0722307e-04 1.6003829e-05 9.9986088e-01 9.3246962e-07], sum to 1.0000
[2019-03-24 08:27:42,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4506
[2019-03-24 08:27:42,683] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 83.0, 1.0, 2.0, 0.2888611602752676, 1.0, 2.0, 0.2888611602752676, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666967.5741646138, 666967.5741646138, 178232.8953569908], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3322800.0000, 
sim time next is 3323400.0000, 
raw observation next is [25.25, 82.33333333333334, 1.0, 2.0, 0.2930990607584146, 1.0, 2.0, 0.2930990607584146, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673958.2654888842, 673958.2654888846, 179106.8849685474], 
processed observation next is [0.0, 0.4782608695652174, 0.49074074074074076, 0.8233333333333335, 1.0, 1.0, 0.1584512628076364, 1.0, 1.0, 0.1584512628076364, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24069938053174436, 0.24069938053174453, 0.3444363172472066], 
reward next is 0.6556, 
noisyNet noise sample is [array([-1.986741], dtype=float32), -0.32770482]. 
=============================================
[2019-03-24 08:27:47,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.05464905e-08 1.09825145e-07 8.93291201e-08 9.99999642e-01
 8.69289067e-08], sum to 1.0000
[2019-03-24 08:27:47,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6512
[2019-03-24 08:27:47,706] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.3022732369281288, 1.0, 2.0, 0.3022732369281288, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690829.1835110302, 690829.1835110306, 181100.5352773254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3272400.0000, 
sim time next is 3273000.0000, 
raw observation next is [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.3042321995911882, 1.0, 2.0, 0.3042321995911882, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694454.6736476478, 694454.6736476483, 181530.6990638586], 
processed observation next is [0.0, 0.9130434782608695, 0.506172839506173, 0.8150000000000002, 1.0, 1.0, 0.17170499951331927, 1.0, 1.0, 0.17170499951331927, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24801952630273136, 0.24801952630273152, 0.3490974981997281], 
reward next is 0.6509, 
noisyNet noise sample is [array([-2.0911024], dtype=float32), -1.1429801]. 
=============================================
[2019-03-24 08:27:47,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.96588 ]
 [68.94188 ]
 [68.95659 ]
 [68.878586]
 [68.75523 ]], R is [[68.90818024]
 [68.87083435]
 [68.83547974]
 [68.80202484]
 [68.77023315]].
[2019-03-24 08:27:51,606] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 08:27:51,608] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:27:51,609] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:27:51,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:27:51,612] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:27:51,611] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:27:51,613] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:27:51,613] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:27:51,614] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:27:51,612] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:27:51,617] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:27:51,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-24 08:27:51,660] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-24 08:27:51,692] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-24 08:27:51,692] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-24 08:27:51,750] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-24 08:28:47,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0102214], dtype=float32), 0.008689866]
[2019-03-24 08:28:47,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.4011034676214559, 1.0, 2.0, 0.4011034676214559, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 947914.6407925192, 947914.6407925192, 207986.9003390266]
[2019-03-24 08:28:47,331] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:28:47,336] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5047035e-07 3.8849808e-07 1.8445019e-06 9.9999726e-01 2.1684713e-07], sampled 0.6464848151432943
[2019-03-24 08:28:52,632] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0102214], dtype=float32), 0.008689866]
[2019-03-24 08:28:52,633] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333333, 69.83333333333333, 1.0, 2.0, 0.2544927044147956, 1.0, 2.0, 0.2544927044147956, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599667.5236884103, 599667.5236884103, 170845.1953001095]
[2019-03-24 08:28:52,634] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:28:52,637] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7124224e-07 4.1694622e-07 1.9986774e-06 9.9999714e-01 2.2245064e-07], sampled 0.8112995557805015
[2019-03-24 08:28:52,721] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0102214], dtype=float32), 0.008689866]
[2019-03-24 08:28:52,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.3301006347078964, 1.0, 2.0, 0.3301006347078964, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 752420.4203632092, 752420.4203632097, 187840.3765285916]
[2019-03-24 08:28:52,724] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:28:52,728] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3185501e-07 3.5834904e-07 1.7265457e-06 9.9999750e-01 2.0379846e-07], sampled 0.04324271915818945
[2019-03-24 08:29:06,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0102214], dtype=float32), 0.008689866]
[2019-03-24 08:29:06,279] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.02137955333333, 64.70193040000001, 1.0, 2.0, 0.2311956803194773, 1.0, 2.0, 0.2311956803194773, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 558331.2899584947, 558331.2899584952, 166207.5515135984]
[2019-03-24 08:29:06,280] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:29:06,284] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0606556e-07 3.2232495e-07 1.5674140e-06 9.9999774e-01 1.7052997e-07], sampled 0.1758148115684216
[2019-03-24 08:29:12,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0102214], dtype=float32), 0.008689866]
[2019-03-24 08:29:12,068] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.06666666666667, 63.66666666666666, 1.0, 2.0, 0.7595116996814165, 1.0, 2.0, 0.7595116996814165, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1732288.11437216, 1732288.114372161, 327306.463301602]
[2019-03-24 08:29:12,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:29:12,072] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3257185e-06 1.9039854e-06 8.1204917e-06 9.9998760e-01 1.0769601e-06], sampled 0.3109017914186113
[2019-03-24 08:29:36,012] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:29:36,073] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 08:29:36,219] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:29:36,327] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3270 2465960889.4649 46.0000
[2019-03-24 08:29:36,333] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:29:37,352] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1575000, evaluation results [1575000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438873699.591536, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.326961235299, 2465960889.4649444, 46.0]
[2019-03-24 08:29:38,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7425027e-07 7.9616001e-08 1.7361431e-07 9.9999952e-01 2.4428859e-08], sum to 1.0000
[2019-03-24 08:29:38,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1115
[2019-03-24 08:29:38,017] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.08333333333334, 78.16666666666666, 1.0, 2.0, 0.3285112429776263, 1.0, 2.0, 0.3285112429776263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748795.8441557274, 748795.8441557278, 187443.5223563989], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3333000.0000, 
sim time next is 3333600.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.32819651576848, 1.0, 2.0, 0.32819651576848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748078.1170521571, 748078.1170521575, 187364.9023267181], 
processed observation next is [0.0, 0.6086956521739131, 0.5592592592592593, 0.78, 1.0, 1.0, 0.20023394734342861, 1.0, 1.0, 0.20023394734342861, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2671707560900561, 0.26717075609005625, 0.3603171198590733], 
reward next is 0.6397, 
noisyNet noise sample is [array([0.94489664], dtype=float32), 0.79218495]. 
=============================================
[2019-03-24 08:29:41,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1748949e-06 2.6341793e-06 5.9022877e-06 9.9998868e-01 6.2842020e-07], sum to 1.0000
[2019-03-24 08:29:41,707] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0748
[2019-03-24 08:29:41,711] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 92.5, 1.0, 2.0, 0.3327282743967538, 1.0, 2.0, 0.3327282743967538, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758412.7379660958, 758412.7379660963, 188499.4635911713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [24.4, 91.0, 1.0, 2.0, 0.3305707526156854, 1.0, 2.0, 0.3305707526156854, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753492.5181797235, 753492.518179724, 187958.1244633949], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.91, 1.0, 1.0, 0.20306041978057787, 1.0, 1.0, 0.20306041978057787, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2691044707784727, 0.2691044707784729, 0.3614579316603748], 
reward next is 0.6385, 
noisyNet noise sample is [array([0.26927617], dtype=float32), -0.46119413]. 
=============================================
[2019-03-24 08:29:50,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2088175e-05 1.3763994e-07 6.3073762e-06 9.9997556e-01 5.9793801e-06], sum to 1.0000
[2019-03-24 08:29:50,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6195
[2019-03-24 08:29:50,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.53333333333333, 88.33333333333334, 1.0, 2.0, 0.243573257593053, 1.0, 2.0, 0.243573257593053, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580428.4370370986, 580428.437037099, 168663.6552204653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3547200.0000, 
sim time next is 3547800.0000, 
raw observation next is [22.8, 85.5, 1.0, 2.0, 0.241403257941597, 1.0, 2.0, 0.241403257941597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 576311.7512919304, 576311.7512919309, 168221.2892587354], 
processed observation next is [1.0, 0.043478260869565216, 0.4, 0.855, 1.0, 1.0, 0.0969086404066631, 1.0, 1.0, 0.0969086404066631, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20582562546140373, 0.2058256254614039, 0.32350247934372195], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.15121982], dtype=float32), -0.97461027]. 
=============================================
[2019-03-24 08:29:57,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5246586e-07 2.6634908e-07 1.7526070e-05 9.9998116e-01 1.9779760e-07], sum to 1.0000
[2019-03-24 08:29:57,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7256
[2019-03-24 08:29:57,177] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 87.33333333333333, 1.0, 2.0, 0.6892496316109243, 1.0, 2.0, 0.6892496316109243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1571892.533530494, 1571892.533530495, 300115.1781140128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3678600.0000, 
sim time next is 3679200.0000, 
raw observation next is [26.0, 86.0, 1.0, 2.0, 0.6929840512571188, 1.0, 2.0, 0.6929840512571188, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1580417.985076225, 1580417.985076226, 301517.5296743877], 
processed observation next is [1.0, 0.6086956521739131, 0.5185185185185185, 0.86, 1.0, 1.0, 0.6345048229251414, 1.0, 1.0, 0.6345048229251414, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5644349946700803, 0.5644349946700807, 0.5798414032199763], 
reward next is 0.4202, 
noisyNet noise sample is [array([-0.8164897], dtype=float32), -0.2706044]. 
=============================================
[2019-03-24 08:30:06,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.45422517e-06 2.32851653e-06 1.23993295e-05 9.99978662e-01
 1.01613080e-06], sum to 1.0000
[2019-03-24 08:30:06,903] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8654
[2019-03-24 08:30:06,907] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.61666666666667, 92.83333333333333, 1.0, 2.0, 0.4590637808439791, 1.0, 2.0, 0.4590637808439791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1046575.444812252, 1046575.444812252, 223012.7921517494], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3995400.0000, 
sim time next is 3996000.0000, 
raw observation next is [24.6, 93.0, 1.0, 2.0, 0.4557705220831214, 1.0, 2.0, 0.4557705220831214, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1039062.369669316, 1039062.369669316, 222042.9188679353], 
processed observation next is [1.0, 0.2608695652173913, 0.46666666666666673, 0.93, 1.0, 1.0, 0.35210776438466834, 1.0, 1.0, 0.35210776438466834, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37109370345332715, 0.37109370345332715, 0.4270056132075679], 
reward next is 0.5730, 
noisyNet noise sample is [array([-0.88705885], dtype=float32), -1.2984738]. 
=============================================
[2019-03-24 08:30:06,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[52.562473]
 [52.534954]
 [52.41541 ]
 [52.51013 ]
 [52.555653]], R is [[52.12250137]
 [52.17240524]
 [52.21466827]
 [52.24424362]
 [52.27057648]].
[2019-03-24 08:30:07,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0572942e-08 2.1664622e-08 3.6046461e-07 9.9999964e-01 1.5308609e-08], sum to 1.0000
[2019-03-24 08:30:07,282] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7437
[2019-03-24 08:30:07,293] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 81.5, 1.0, 2.0, 0.382450334637597, 1.0, 2.0, 0.382450334637597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 871812.4494842781, 871812.4494842786, 201425.1742648725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3879000.0000, 
sim time next is 3879600.0000, 
raw observation next is [28.33333333333333, 84.0, 1.0, 2.0, 0.3921008743131995, 1.0, 2.0, 0.3921008743131995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 893824.1096936341, 893824.1096936346, 204032.9332127081], 
processed observation next is [0.0, 0.9130434782608695, 0.6049382716049381, 0.84, 1.0, 1.0, 0.27631056465857085, 1.0, 1.0, 0.27631056465857085, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.319222896319155, 0.3192228963191552, 0.39237102540905405], 
reward next is 0.6076, 
noisyNet noise sample is [array([-0.8660059], dtype=float32), 1.3562181]. 
=============================================
[2019-03-24 08:30:08,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1861240e-06 2.3718339e-07 4.2248065e-08 9.9999857e-01 4.9686857e-08], sum to 1.0000
[2019-03-24 08:30:08,321] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8732
[2019-03-24 08:30:08,327] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 90.0, 1.0, 2.0, 0.364408441018601, 1.0, 2.0, 0.364408441018601, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830662.8680706976, 830662.8680706976, 196636.1729182836], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3897000.0000, 
sim time next is 3897600.0000, 
raw observation next is [26.66666666666667, 89.66666666666666, 1.0, 2.0, 0.3684731397847942, 1.0, 2.0, 0.3684731397847942, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 839933.3569591251, 839933.3569591256, 197705.2124943161], 
processed observation next is [0.0, 0.08695652173913043, 0.5432098765432101, 0.8966666666666666, 1.0, 1.0, 0.24818230926761212, 1.0, 1.0, 0.24818230926761212, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29997619891397326, 0.2999761989139734, 0.38020233171983864], 
reward next is 0.6198, 
noisyNet noise sample is [array([-0.85758734], dtype=float32), 0.4074462]. 
=============================================
[2019-03-24 08:30:13,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3759992e-07 1.3806458e-07 1.2303907e-06 9.9999845e-01 5.6161113e-08], sum to 1.0000
[2019-03-24 08:30:13,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-24 08:30:13,525] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.2227592923029951, 1.0, 2.0, 0.2227592923029951, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541762.5891343146, 541762.589134315, 164496.5177584098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4082400.0000, 
sim time next is 4083000.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.2819343546232005, 1.0, 2.0, 0.2819343546232005, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683215.0561454595, 683215.05614546, 177923.5750770381], 
processed observation next is [1.0, 0.2608695652173913, 0.3024691358024693, 1.0, 1.0, 1.0, 0.1451599459800006, 1.0, 1.0, 0.1451599459800006, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24400537719480697, 0.24400537719480714, 0.3421607213019964], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.18708774], dtype=float32), 0.3210744]. 
=============================================
[2019-03-24 08:30:13,546] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.796803]
 [58.900326]
 [58.81934 ]
 [58.96363 ]
 [58.854458]], R is [[58.54354095]
 [58.64176941]
 [58.73926926]
 [58.83453751]
 [58.92406845]].
[2019-03-24 08:30:15,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3910459e-05 8.2570477e-07 1.2659968e-03 9.9867529e-01 3.9615124e-06], sum to 1.0000
[2019-03-24 08:30:15,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-24 08:30:15,689] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.05, 98.83333333333334, 1.0, 2.0, 0.2220453243333326, 1.0, 2.0, 0.2220453243333326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540687.1621580691, 540687.1621580696, 164363.5536876865], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.2227592923029951, 1.0, 2.0, 0.2227592923029951, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541762.5891343146, 541762.589134315, 164496.5177584098], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 1.0, 1.0, 1.0, 0.07471344321785131, 1.0, 1.0, 0.07471344321785131, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19348663897654092, 0.1934866389765411, 0.3163394572277112], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.19512913], dtype=float32), 0.36915722]. 
=============================================
[2019-03-24 08:30:16,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4648351e-06 8.5296409e-07 1.8213495e-06 9.9997902e-01 1.4864550e-05], sum to 1.0000
[2019-03-24 08:30:16,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8127
[2019-03-24 08:30:16,053] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.41666666666667, 86.5, 1.0, 2.0, 0.3214566189667648, 1.0, 2.0, 0.3214566189667648, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 732708.1213645965, 732708.121364597, 185689.3233052645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4045800.0000, 
sim time next is 4046400.0000, 
raw observation next is [25.3, 86.0, 1.0, 2.0, 0.3161592654956637, 1.0, 2.0, 0.3161592654956637, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720627.9894906314, 720627.9894906314, 184383.5250328114], 
processed observation next is [1.0, 0.8695652173913043, 0.49259259259259264, 0.86, 1.0, 1.0, 0.18590388749483774, 1.0, 1.0, 0.18590388749483774, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25736713910379694, 0.25736713910379694, 0.3545837019861757], 
reward next is 0.6454, 
noisyNet noise sample is [array([-0.31987196], dtype=float32), 0.61971426]. 
=============================================
[2019-03-24 08:30:21,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4513728e-07 4.7362843e-07 7.0846028e-05 9.9991953e-01 8.9242867e-06], sum to 1.0000
[2019-03-24 08:30:21,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7217
[2019-03-24 08:30:21,017] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 75.0, 1.0, 2.0, 0.6184768212358231, 1.0, 2.0, 0.6184768212358231, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1420141.045289003, 1420141.045289005, 274941.4450949503], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4177800.0000, 
sim time next is 4178400.0000, 
raw observation next is [26.26666666666667, 74.66666666666666, 1.0, 2.0, 0.7050979280611109, 1.0, 2.0, 0.7050979280611109, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1608069.92835075, 1608069.928350749, 306098.2446956219], 
processed observation next is [1.0, 0.34782608695652173, 0.5283950617283951, 0.7466666666666666, 1.0, 1.0, 0.6489261048346558, 1.0, 1.0, 0.6489261048346558, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.5743106886966964, 0.5743106886966961, 0.5886504705685036], 
reward next is 0.4113, 
noisyNet noise sample is [array([0.5756447], dtype=float32), 1.0077971]. 
=============================================
[2019-03-24 08:30:26,695] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 08:30:26,697] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:30:26,700] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:30:26,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:26,706] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:30:26,705] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:26,707] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:30:26,708] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:30:26,710] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:26,710] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:26,711] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:26,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-24 08:30:26,757] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-24 08:30:26,801] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-24 08:30:26,802] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-24 08:30:26,866] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-24 08:30:36,281] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:30:36,282] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.36917737, 32.97076697666667, 1.0, 2.0, 0.5141622470737561, 1.0, 2.0, 0.5141622470737561, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1221966.687678554, 1221966.687678554, 241990.0481669025]
[2019-03-24 08:30:36,282] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:30:36,284] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6478855e-07 5.3955353e-07 2.5845791e-06 9.9999607e-01 3.4762220e-07], sampled 0.8387445447215841
[2019-03-24 08:30:48,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:30:48,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.5, 70.0, 1.0, 2.0, 0.1840172852748722, 1.0, 2.0, 0.1840172852748722, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456731.6402483387, 456731.6402483387, 156601.4515573253]
[2019-03-24 08:30:48,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:30:48,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0740642e-07 3.2166716e-07 1.5904216e-06 9.9999762e-01 2.0441203e-07], sampled 0.16858840121351937
[2019-03-24 08:31:07,277] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:31:07,279] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.16666666666667, 72.33333333333334, 1.0, 2.0, 0.3801974798981064, 1.0, 2.0, 0.3801974798981064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866674.0638242326, 866674.0638242326, 200821.2486545796]
[2019-03-24 08:31:07,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:31:07,284] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9875429e-08 1.5561042e-07 8.3340848e-07 9.9999881e-01 9.4937683e-08], sampled 0.5794856387681777
[2019-03-24 08:31:07,580] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:31:07,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3661513790049614, 1.0, 2.0, 0.3661513790049614, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 834638.0289247461, 834638.0289247466, 197094.2528469589]
[2019-03-24 08:31:07,585] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:31:07,589] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.01570215e-07 1.58053396e-07 8.46843591e-07 9.99998808e-01
 9.66876286e-08], sampled 0.5214992948199029
[2019-03-24 08:31:30,120] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:31:30,121] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.6100247919589438, 1.0, 2.0, 0.6100247919589438, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1391049.434777499, 1391049.4347775, 271505.1748659646]
[2019-03-24 08:31:30,122] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:31:30,124] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0680934e-07 4.6748852e-07 2.2216909e-06 9.9999666e-01 3.1254538e-07], sampled 0.7156979397700931
[2019-03-24 08:31:43,087] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:31:43,088] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.93333333333333, 75.66666666666667, 1.0, 2.0, 0.309263519838527, 1.0, 2.0, 0.309263519838527, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714246.1106836178, 714246.1106836182, 183153.0913527244]
[2019-03-24 08:31:43,089] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:31:43,093] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3798706e-07 2.1572160e-07 1.0886009e-06 9.9999845e-01 1.4301334e-07], sampled 0.4157452072510619
[2019-03-24 08:31:56,780] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:31:56,782] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.97977425333334, 59.00590971333334, 1.0, 2.0, 0.1919551121201526, 1.0, 2.0, 0.1919551121201526, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473904.9350092739, 473904.9350092744, 158185.5264619141]
[2019-03-24 08:31:56,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:31:56,787] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6315289e-07 2.5338340e-07 1.2816996e-06 9.9999821e-01 1.5977903e-07], sampled 0.9114542563430976
[2019-03-24 08:32:05,573] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01026745], dtype=float32), 0.008780801]
[2019-03-24 08:32:05,575] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.66666666666667, 63.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 345019.4900384328, 345019.4900384333, 142371.6685162843]
[2019-03-24 08:32:05,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:32:05,578] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1810992e-07 1.8940085e-07 9.4088824e-07 9.9999857e-01 1.2830495e-07], sampled 0.8899679364899367
[2019-03-24 08:32:10,409] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:32:10,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:32:10,840] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3270 2465960889.4649 46.0000
[2019-03-24 08:32:10,883] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:32:11,064] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:32:12,077] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1600000, evaluation results [1600000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.326961235299, 2465960889.4649444, 46.0]
[2019-03-24 08:32:23,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2228796e-07 3.2066976e-07 2.6424987e-05 9.9996960e-01 3.0497156e-06], sum to 1.0000
[2019-03-24 08:32:23,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-24 08:32:23,720] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 69.5, 1.0, 2.0, 0.3278454431863631, 1.0, 2.0, 0.3278454431863631, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747277.506076592, 747277.506076592, 187277.2469141889], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4455000.0000, 
sim time next is 4455600.0000, 
raw observation next is [28.66666666666666, 68.0, 1.0, 2.0, 0.3264867516071522, 1.0, 2.0, 0.3264867516071522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744179.0566972746, 744179.056697275, 186938.3582616037], 
processed observation next is [0.0, 0.5652173913043478, 0.6172839506172837, 0.68, 1.0, 1.0, 0.19819851381803832, 1.0, 1.0, 0.19819851381803832, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2657782345347409, 0.2657782345347411, 0.3594968428107763], 
reward next is 0.6405, 
noisyNet noise sample is [array([1.0495657], dtype=float32), 0.9848835]. 
=============================================
[2019-03-24 08:32:24,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6951448e-08 1.4046083e-06 3.6456521e-07 9.9999785e-01 3.2670064e-07], sum to 1.0000
[2019-03-24 08:32:24,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-24 08:32:24,227] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 97.0, 1.0, 2.0, 0.2865225872676939, 1.0, 2.0, 0.2865225872676939, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661380.609349485, 661380.609349485, 177670.1559051647], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4513200.0000, 
sim time next is 4513800.0000, 
raw observation next is [23.05, 98.5, 1.0, 2.0, 0.2906235438758939, 1.0, 2.0, 0.2906235438758939, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668888.4367742698, 668888.4367742703, 178548.2189184174], 
processed observation next is [0.0, 0.21739130434782608, 0.40925925925925927, 0.985, 1.0, 1.0, 0.15550421889987368, 1.0, 1.0, 0.15550421889987368, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23888872741938208, 0.23888872741938225, 0.343361959458495], 
reward next is 0.6566, 
noisyNet noise sample is [array([0.49018922], dtype=float32), -1.1236013]. 
=============================================
[2019-03-24 08:32:25,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9309132e-07 2.7598844e-07 8.4503499e-06 9.9998307e-01 8.0111131e-06], sum to 1.0000
[2019-03-24 08:32:25,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1192
[2019-03-24 08:32:25,772] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2471583933610367, 1.0, 2.0, 0.2471583933610367, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590143.3257945887, 590143.3257945887, 169515.4535494786], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4590000.0000, 
sim time next is 4590600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2560473807311152, 1.0, 2.0, 0.2560473807311152, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611449.3332735699, 611449.3332735704, 171534.8985771284], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 1.0, 1.0, 1.0, 0.1143421199179943, 1.0, 1.0, 0.1143421199179943, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21837476188341784, 0.218374761883418, 0.3298748049560161], 
reward next is 0.6701, 
noisyNet noise sample is [array([0.25354382], dtype=float32), 3.245186]. 
=============================================
[2019-03-24 08:32:26,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4765675e-06 1.5219053e-06 5.1656201e-08 9.9999654e-01 3.8970455e-07], sum to 1.0000
[2019-03-24 08:32:26,189] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4850
[2019-03-24 08:32:26,197] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.26666666666667, 99.33333333333334, 1.0, 2.0, 0.2498302374598356, 1.0, 2.0, 0.2498302374598356, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594381.4311792044, 594381.4311792044, 170032.3976836103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4598400.0000, 
sim time next is 4599000.0000, 
raw observation next is [21.2, 99.5, 1.0, 2.0, 0.2483271373412128, 1.0, 2.0, 0.2483271373412128, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363582, 169720.6027860315], 
processed observation next is [1.0, 0.21739130434782608, 0.34074074074074073, 0.995, 1.0, 1.0, 0.1051513539776343, 1.0, 1.0, 0.1051513539776343, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2112425419772706, 0.21124254197727077, 0.3263857745885221], 
reward next is 0.6736, 
noisyNet noise sample is [array([1.9420716], dtype=float32), -1.0374588]. 
=============================================
[2019-03-24 08:32:26,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.10525 ]
 [59.12777 ]
 [59.227196]
 [59.287075]
 [59.25727 ]], R is [[59.27884674]
 [59.35907364]
 [59.43095398]
 [59.50938797]
 [59.58223343]].
[2019-03-24 08:32:26,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5616980e-09 1.5713434e-06 5.5791662e-07 9.9999726e-01 5.8130007e-07], sum to 1.0000
[2019-03-24 08:32:26,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6571
[2019-03-24 08:32:26,297] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.03333333333333, 99.0, 1.0, 2.0, 0.2906320651013881, 1.0, 2.0, 0.2906320651013881, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668127.4514705829, 668127.4514705833, 178512.2818211323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4567800.0000, 
sim time next is 4568400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2930612769549215, 1.0, 2.0, 0.2930612769549215, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672403.562824744, 672403.5628247445, 179026.0940785781], 
processed observation next is [0.0, 0.9130434782608695, 0.4074074074074074, 1.0, 1.0, 1.0, 0.15840628208919227, 1.0, 1.0, 0.15840628208919227, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24014412958026574, 0.2401441295802659, 0.34428095015111176], 
reward next is 0.6557, 
noisyNet noise sample is [array([0.86499834], dtype=float32), 1.0205269]. 
=============================================
[2019-03-24 08:32:34,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5776919e-05 1.5920998e-06 1.3543679e-05 9.9988687e-01 7.2235402e-05], sum to 1.0000
[2019-03-24 08:32:34,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-24 08:32:34,939] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.33333333333334, 1.0, 2.0, 0.3299095606086052, 1.0, 2.0, 0.3299095606086052, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 751984.678776327, 751984.6787763275, 187793.3921756129], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4859400.0000, 
sim time next is 4860000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3465978164796483, 1.0, 2.0, 0.3465978164796483, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790042.9272913281, 790042.9272913281, 192018.9886992693], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.22214025771386706, 1.0, 1.0, 0.22214025771386706, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28215818831833145, 0.28215818831833145, 0.3692672859601333], 
reward next is 0.6307, 
noisyNet noise sample is [array([0.30349994], dtype=float32), -0.26919848]. 
=============================================
[2019-03-24 08:32:34,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[56.06045 ]
 [56.230812]
 [56.234066]
 [56.22989 ]
 [56.28945 ]], R is [[55.67759323]
 [55.75967789]
 [55.84025574]
 [55.91883469]
 [55.99611664]].
[2019-03-24 08:32:35,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5485899e-07 4.4141916e-06 3.9044309e-05 9.9994731e-01 8.7868266e-06], sum to 1.0000
[2019-03-24 08:32:35,282] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3614
[2019-03-24 08:32:35,288] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.313456742340248, 1.0, 2.0, 0.313456742340248, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 729117.3273615327, 729117.3273615332, 184419.7585987262], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4678200.0000, 
sim time next is 4678800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3268176204383409, 1.0, 2.0, 0.3268176204383409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760019.1086499594, 760019.1086499599, 187735.5963624273], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.94, 1.0, 1.0, 0.19859240528373917, 1.0, 1.0, 0.19859240528373917, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2714353959464141, 0.27143539594641425, 0.3610299930046679], 
reward next is 0.6390, 
noisyNet noise sample is [array([0.37967038], dtype=float32), 1.1708816]. 
=============================================
[2019-03-24 08:32:36,322] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4675014e-07 6.8581204e-07 2.2129303e-05 9.9997425e-01 1.9802585e-06], sum to 1.0000
[2019-03-24 08:32:36,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0395
[2019-03-24 08:32:36,338] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.15, 91.5, 1.0, 2.0, 0.3242320671373974, 1.0, 2.0, 0.3242320671373974, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739037.3540081299, 739037.3540081299, 186377.6037248005], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4750200.0000, 
sim time next is 4750800.0000, 
raw observation next is [25.1, 92.33333333333334, 1.0, 2.0, 0.3258662500050849, 1.0, 2.0, 0.3258662500050849, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 742764.028317804, 742764.0283178044, 186783.9681274624], 
processed observation next is [1.0, 1.0, 0.4851851851851852, 0.9233333333333335, 1.0, 1.0, 0.1974598214346249, 1.0, 1.0, 0.1974598214346249, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26527286725635857, 0.26527286725635874, 0.35919993870665845], 
reward next is 0.6408, 
noisyNet noise sample is [array([1.4994568], dtype=float32), 1.0727162]. 
=============================================
[2019-03-24 08:32:37,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1859728e-06 2.7253482e-06 2.4823855e-06 9.9998617e-01 6.4368414e-06], sum to 1.0000
[2019-03-24 08:32:37,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-24 08:32:37,619] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 89.0, 1.0, 2.0, 0.6257200495750846, 1.0, 2.0, 0.6257200495750846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1426872.92533954, 1426872.925339541, 277002.2409112022], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4711200.0000, 
sim time next is 4711800.0000, 
raw observation next is [26.83333333333333, 89.0, 1.0, 2.0, 0.6610131056138305, 1.0, 2.0, 0.6610131056138305, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1507433.344486955, 1507433.344486956, 289670.4497095259], 
processed observation next is [1.0, 0.5217391304347826, 0.5493827160493825, 0.89, 1.0, 1.0, 0.5964441733497983, 1.0, 1.0, 0.5964441733497983, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.5383690516024839, 0.5383690516024843, 0.5570585571337037], 
reward next is 0.4429, 
noisyNet noise sample is [array([-0.2934976], dtype=float32), 0.3686692]. 
=============================================
[2019-03-24 08:32:39,499] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8497914e-05 1.7658627e-05 2.9835901e-06 9.9994588e-01 1.5045669e-05], sum to 1.0000
[2019-03-24 08:32:39,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0829
[2019-03-24 08:32:39,519] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666667, 81.66666666666666, 1.0, 2.0, 0.2925102841368076, 1.0, 2.0, 0.2925102841368076, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687248.4399504276, 687248.439950428, 179638.5638447714], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4945200.0000, 
sim time next is 4945800.0000, 
raw observation next is [24.08333333333333, 82.33333333333334, 1.0, 2.0, 0.2910996706831229, 1.0, 2.0, 0.2910996706831229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683753.2648210963, 683753.2648210963, 179292.6096113718], 
processed observation next is [1.0, 0.21739130434782608, 0.4475308641975307, 0.8233333333333335, 1.0, 1.0, 0.1560710365275273, 1.0, 1.0, 0.1560710365275273, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24419759457896298, 0.24419759457896298, 0.3447934800218688], 
reward next is 0.6552, 
noisyNet noise sample is [array([0.81439614], dtype=float32), -0.34857062]. 
=============================================
[2019-03-24 08:32:42,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0679256e-05 3.4949335e-06 2.4488165e-05 9.9988687e-01 1.4546011e-05], sum to 1.0000
[2019-03-24 08:32:42,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6453
[2019-03-24 08:32:42,698] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6162990643231065, 1.0, 2.0, 0.6162990643231065, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1405369.886663242, 1405369.886663242, 273691.5737308633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4957800.0000, 
sim time next is 4958400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5881618249988446, 1.0, 2.0, 0.5881618249988446, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1341151.307517322, 1341151.307517323, 263993.1295547725], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5097164583319579, 1.0, 1.0, 0.5097164583319579, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.478982609827615, 0.4789826098276153, 0.5076790952976394], 
reward next is 0.4923, 
noisyNet noise sample is [array([-0.26187885], dtype=float32), -0.33588657]. 
=============================================
[2019-03-24 08:32:50,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3784872e-07 2.7481281e-06 2.5907939e-05 9.9996817e-01 3.0921115e-06], sum to 1.0000
[2019-03-24 08:32:50,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9224
[2019-03-24 08:32:50,247] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.91666666666666, 69.16666666666666, 1.0, 2.0, 0.3980794902145851, 1.0, 2.0, 0.3980794902145851, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 907460.8934246814, 907460.8934246819, 205664.6265968092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5158200.0000, 
sim time next is 5158800.0000, 
raw observation next is [30.9, 69.0, 1.0, 2.0, 0.396621193369555, 1.0, 2.0, 0.396621193369555, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 904134.6030605014, 904134.6030605017, 205265.4657577314], 
processed observation next is [0.0, 0.7391304347826086, 0.7, 0.69, 1.0, 1.0, 0.28169189686851787, 1.0, 1.0, 0.28169189686851787, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3229052153787505, 0.3229052153787506, 0.3947412803033296], 
reward next is 0.6053, 
noisyNet noise sample is [array([1.3023837], dtype=float32), 2.9673183]. 
=============================================
[2019-03-24 08:32:56,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3362229e-06 3.3088998e-08 1.2580852e-04 9.9986911e-01 3.7150380e-06], sum to 1.0000
[2019-03-24 08:32:56,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1357
[2019-03-24 08:32:56,119] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.95, 76.5, 1.0, 2.0, 0.4049261457667788, 1.0, 2.0, 0.4049261457667788, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 923077.9099025409, 923077.9099025412, 207548.6249320805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5139000.0000, 
sim time next is 5139600.0000, 
raw observation next is [30.06666666666667, 76.33333333333333, 1.0, 2.0, 0.4110989088359898, 1.0, 2.0, 0.4110989088359898, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 937158.0705965677, 937158.0705965682, 209260.9286244454], 
processed observation next is [0.0, 0.4782608695652174, 0.669135802469136, 0.7633333333333333, 1.0, 1.0, 0.29892727242379746, 1.0, 1.0, 0.29892727242379746, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3346993109273456, 0.3346993109273458, 0.40242486273931805], 
reward next is 0.5976, 
noisyNet noise sample is [array([-0.61491853], dtype=float32), 0.28292823]. 
=============================================
[2019-03-24 08:33:01,286] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 08:33:01,287] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:33:01,288] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:33:01,289] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:01,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:01,292] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:33:01,293] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:33:01,293] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:33:01,294] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:01,295] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:01,294] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:01,320] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-24 08:33:01,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-24 08:33:01,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-24 08:33:01,379] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-24 08:33:01,460] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-24 08:33:11,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:11,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.73333333333333, 19.33333333333333, 1.0, 2.0, 0.1637140529291078, 1.0, 2.0, 0.1637140529291078, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422381.5892818728, 422381.5892818728, 145519.3669604314]
[2019-03-24 08:33:11,421] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:33:11,423] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1973248e-06 5.8644605e-06 1.8958461e-05 9.9996018e-01 1.1857646e-05], sampled 0.23873920663650638
[2019-03-24 08:33:13,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:13,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.53333333333333, 41.66666666666666, 1.0, 2.0, 0.1690124727121587, 1.0, 2.0, 0.1690124727121587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429156.373529157, 429156.373529157, 153704.8380328033]
[2019-03-24 08:33:13,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:33:13,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.53794053e-06 6.47423849e-06 2.06905515e-05 9.99956131e-01
 1.32728155e-05], sampled 0.09114872169534405
[2019-03-24 08:33:18,344] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:18,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.56666666666667, 32.66666666666666, 1.0, 2.0, 0.2171217600376014, 1.0, 2.0, 0.2171217600376014, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525094.5885578151, 525094.5885578151, 163169.0181871062]
[2019-03-24 08:33:18,347] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:33:18,350] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2758744e-06 2.4721514e-06 8.4245794e-06 9.9998248e-01 5.3282033e-06], sampled 0.26282103005054647
[2019-03-24 08:33:23,805] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:23,806] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.30172955, 83.6169117, 1.0, 2.0, 0.2216592401986307, 1.0, 2.0, 0.2216592401986307, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536284.3250668914, 536284.3250668917, 164158.2438556231]
[2019-03-24 08:33:23,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:33:23,810] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1266267e-06 3.9917095e-06 1.3338439e-05 9.9997199e-01 8.5280726e-06], sampled 0.7011503616705547
[2019-03-24 08:33:38,225] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:38,226] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 75.66666666666667, 1.0, 2.0, 0.2786152483389507, 1.0, 2.0, 0.2786152483389507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643861.3140936685, 643861.314093669, 175847.1375102193]
[2019-03-24 08:33:38,227] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:33:38,230] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1435560e-06 3.9642405e-06 1.3459374e-05 9.9997222e-01 8.2067672e-06], sampled 0.11973744918036311
[2019-03-24 08:33:55,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:33:55,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.08333333333333, 83.0, 1.0, 2.0, 0.5549192908635276, 1.0, 2.0, 0.5549192908635276, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1265287.677864691, 1265287.677864692, 252891.9704777985]
[2019-03-24 08:33:55,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:33:55,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.7081199e-06 6.6935545e-06 2.1547630e-05 9.9995446e-01 1.3640911e-05], sampled 0.27064004476316184
[2019-03-24 08:34:02,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:34:02,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.28611126333333, 85.33440524000001, 1.0, 2.0, 0.2819574567541736, 1.0, 2.0, 0.2819574567541736, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667835.1740726756, 667835.1740726761, 177352.7133773279]
[2019-03-24 08:34:02,347] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:34:02,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.16045714e-06 4.09192944e-06 1.34023785e-05 9.99971509e-01
 8.87438728e-06], sampled 0.3766600486667613
[2019-03-24 08:34:16,403] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01019593], dtype=float32), 0.008759803]
[2019-03-24 08:34:16,404] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.93333333333333, 75.66666666666667, 1.0, 2.0, 0.503195456515378, 1.0, 2.0, 0.503195456515378, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1153588.619737864, 1153588.619737864, 236678.8949577106]
[2019-03-24 08:34:16,405] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:34:16,410] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.5748064e-06 9.8690225e-06 3.0891486e-05 9.9993408e-01 1.9579371e-05], sampled 0.3355294624568924
[2019-03-24 08:34:44,251] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.7877 2438885038.9367 34.0000
[2019-03-24 08:34:45,158] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6255 2466005100.1455 46.0000
[2019-03-24 08:34:45,171] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:34:45,234] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7795.5541 2410705904.3820 22.0000
[2019-03-24 08:34:45,275] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3312 2668560061.2481 68.0000
[2019-03-24 08:34:46,292] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1625000, evaluation results [1625000.0, 7522.331206046746, 2668560061.248078, 68.0, 7120.787676430463, 2438885038.936659, 34.0, 7795.554075813984, 2410705904.3819804, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7477.62548423599, 2466005100.1454816, 46.0]
[2019-03-24 08:34:46,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3713857e-04 7.1792223e-04 8.7196362e-04 9.9691939e-01 5.5360986e-04], sum to 1.0000
[2019-03-24 08:34:46,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7158
[2019-03-24 08:34:46,503] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.23333333333333, 81.33333333333333, 1.0, 2.0, 0.7030022256718109, 1.0, 2.0, 0.7030022256718109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1603286.110812653, 1603286.110812654, 305302.7180874578], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5565000.0000, 
sim time next is 5565600.0000, 
raw observation next is [26.3, 81.0, 1.0, 2.0, 0.6585784740408049, 1.0, 2.0, 0.6585784740408049, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1501875.748543005, 1501875.748543005, 288781.2336291324], 
processed observation next is [1.0, 0.43478260869565216, 0.5296296296296297, 0.81, 1.0, 1.0, 0.5935458024295297, 1.0, 1.0, 0.5935458024295297, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5363841959082161, 0.5363841959082161, 0.55534852620987], 
reward next is 0.4447, 
noisyNet noise sample is [array([-0.14172043], dtype=float32), -0.28932607]. 
=============================================
[2019-03-24 08:34:52,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4050239e-05 4.7344934e-06 3.0781812e-05 9.9994993e-01 4.4427165e-07], sum to 1.0000
[2019-03-24 08:34:52,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-24 08:34:52,945] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 92.16666666666667, 1.0, 2.0, 0.3713741392079231, 1.0, 2.0, 0.3713741392079231, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 846549.8279931385, 846549.8279931389, 198471.9233686602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [26.56666666666667, 92.33333333333334, 1.0, 2.0, 0.3701640692918462, 1.0, 2.0, 0.3701640692918462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 843789.9471642909, 843789.9471642914, 198151.8451657889], 
processed observation next is [1.0, 0.043478260869565216, 0.5395061728395063, 0.9233333333333335, 1.0, 1.0, 0.2501953205855312, 1.0, 1.0, 0.2501953205855312, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30135355255867535, 0.3013535525586755, 0.38106124070344016], 
reward next is 0.6189, 
noisyNet noise sample is [array([-0.69431424], dtype=float32), 0.22268577]. 
=============================================
[2019-03-24 08:34:52,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.232407]
 [56.83307 ]
 [57.297394]
 [57.614502]
 [58.339546]], R is [[56.20871735]
 [56.26495361]
 [56.32011795]
 [56.37456894]
 [56.42824936]].
[2019-03-24 08:34:56,104] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4942771e-05 9.6023141e-05 2.5456428e-04 9.9955088e-01 4.3537235e-05], sum to 1.0000
[2019-03-24 08:34:56,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1566
[2019-03-24 08:34:56,116] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 86.00000000000001, 1.0, 2.0, 0.894849728479426, 1.0, 2.0, 0.894849728479426, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2041318.740725266, 2041318.740725266, 384506.590608405], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5587800.0000, 
sim time next is 5588400.0000, 
raw observation next is [26.2, 87.0, 1.0, 2.0, 0.8804908224618349, 1.0, 2.0, 0.8804908224618349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2008526.567849088, 2008526.567849088, 378136.9133743232], 
processed observation next is [1.0, 0.6956521739130435, 0.5259259259259259, 0.87, 1.0, 1.0, 0.8577271695974225, 1.0, 1.0, 0.8577271695974225, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.71733091708896, 0.71733091708896, 0.7271863718736985], 
reward next is 0.2728, 
noisyNet noise sample is [array([-1.0365413], dtype=float32), 1.2133209]. 
=============================================
[2019-03-24 08:34:57,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0161751e-05 2.2642614e-06 1.1009177e-04 9.9985552e-01 1.1962770e-05], sum to 1.0000
[2019-03-24 08:34:57,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7331
[2019-03-24 08:34:57,856] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5848109789050236, 1.0, 2.0, 0.5848109789050236, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1333503.916191851, 1333503.916191851, 262858.149694316], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5403600.0000, 
sim time next is 5404200.0000, 
raw observation next is [27.3, 82.66666666666667, 1.0, 2.0, 0.6484885027689689, 1.0, 2.0, 0.6484885027689689, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1478843.542244822, 1478843.542244822, 285125.0542259462], 
processed observation next is [1.0, 0.5652173913043478, 0.5666666666666667, 0.8266666666666667, 1.0, 1.0, 0.5815339318678201, 1.0, 1.0, 0.5815339318678201, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5281584079445792, 0.5281584079445792, 0.5483174119729735], 
reward next is 0.4517, 
noisyNet noise sample is [array([-0.06175116], dtype=float32), -1.4253331]. 
=============================================
[2019-03-24 08:35:01,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0318199e-07 4.1004701e-06 4.8572861e-06 9.9996996e-01 2.0811516e-05], sum to 1.0000
[2019-03-24 08:35:01,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9898
[2019-03-24 08:35:01,423] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 89.0, 1.0, 2.0, 0.3447074573717097, 1.0, 2.0, 0.3447074573717097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785731.7913020178, 785731.7913020178, 191535.2147855998], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5552400.0000, 
sim time next is 5553000.0000, 
raw observation next is [25.35, 88.5, 1.0, 2.0, 0.3535695656252951, 1.0, 2.0, 0.3535695656252951, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805942.8453512953, 805942.8453512958, 193812.5737098247], 
processed observation next is [1.0, 0.2608695652173913, 0.4944444444444445, 0.885, 1.0, 1.0, 0.2304399590777323, 1.0, 1.0, 0.2304399590777323, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2878367304826055, 0.28783673048260566, 0.37271648790350903], 
reward next is 0.6273, 
noisyNet noise sample is [array([0.3969149], dtype=float32), 0.6015023]. 
=============================================
[2019-03-24 08:35:01,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.811596]
 [60.73907 ]
 [60.47507 ]
 [60.744137]
 [60.48562 ]], R is [[60.72976303]
 [60.75413132]
 [60.77715302]
 [60.80881882]
 [60.83815002]].
[2019-03-24 08:35:02,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3293810e-05 1.1115711e-04 3.7739947e-04 9.9896550e-01 5.0260749e-04], sum to 1.0000
[2019-03-24 08:35:02,412] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8361
[2019-03-24 08:35:02,417] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.4333795054180013, 1.0, 2.0, 0.4333795054180013, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 987982.581766704, 987982.581766704, 215549.0242548371], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5540400.0000, 
sim time next is 5541000.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.4071080256352324, 1.0, 2.0, 0.4071080256352324, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 928054.7794752388, 928054.7794752392, 208150.4045896946], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.2941762209943243, 1.0, 1.0, 0.2941762209943243, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33144813552687097, 0.33144813552687113, 0.40028923959556656], 
reward next is 0.5997, 
noisyNet noise sample is [array([-0.19423254], dtype=float32), 1.4862015]. 
=============================================
[2019-03-24 08:35:02,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[54.936142]
 [54.891373]
 [54.761993]
 [54.942493]
 [54.77264 ]], R is [[54.8338089 ]
 [54.87095642]
 [54.90013885]
 [54.91931915]
 [54.92850494]].
[2019-03-24 08:35:02,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0859243e-07 1.2187992e-06 2.3914635e-07 9.9999702e-01 1.1838687e-06], sum to 1.0000
[2019-03-24 08:35:02,793] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7937
[2019-03-24 08:35:02,796] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 78.0, 1.0, 2.0, 0.2798981360191303, 1.0, 2.0, 0.2798981360191303, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 649077.024654945, 649077.0246549454, 176253.9234769866], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5774400.0000, 
sim time next is 5775000.0000, 
raw observation next is [25.3, 78.33333333333333, 1.0, 2.0, 0.2779448055145847, 1.0, 2.0, 0.2779448055145847, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 645248.5802993366, 645248.580299337, 175829.4669715682], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.7833333333333333, 1.0, 1.0, 0.140410482755458, 1.0, 1.0, 0.140410482755458, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23044592153547735, 0.23044592153547752, 0.3381335903299389], 
reward next is 0.6619, 
noisyNet noise sample is [array([-1.5837983], dtype=float32), -0.09995437]. 
=============================================
[2019-03-24 08:35:02,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.90504 ]
 [65.8716  ]
 [65.881935]
 [65.90937 ]
 [65.921   ]], R is [[65.89996338]
 [65.90201569]
 [65.90312958]
 [65.90354919]
 [65.90366364]].
[2019-03-24 08:35:04,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.17700183e-05 1.27058565e-05 2.03248742e-03 9.97934103e-01
 8.86555063e-06], sum to 1.0000
[2019-03-24 08:35:04,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0499
[2019-03-24 08:35:04,255] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.65, 77.0, 1.0, 2.0, 0.7418158627446616, 1.0, 2.0, 0.7418158627446616, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1691889.372940305, 1691889.372940305, 320299.050105651], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5574600.0000, 
sim time next is 5575200.0000, 
raw observation next is [28.86666666666667, 76.66666666666667, 1.0, 2.0, 0.7915032842315267, 1.0, 2.0, 0.7915032842315267, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1805327.994982198, 1805327.994982198, 340256.7574221882], 
processed observation next is [1.0, 0.5217391304347826, 0.6246913580246916, 0.7666666666666667, 1.0, 1.0, 0.7517896240851508, 1.0, 1.0, 0.7517896240851508, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6447599982079278, 0.6447599982079278, 0.6543399181195927], 
reward next is 0.3457, 
noisyNet noise sample is [array([1.5868847], dtype=float32), 0.97287166]. 
=============================================
[2019-03-24 08:35:25,232] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7626904e-06 5.4110669e-06 2.0786376e-04 9.9977452e-01 3.5127275e-06], sum to 1.0000
[2019-03-24 08:35:25,241] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1448
[2019-03-24 08:35:25,248] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.03333333333333, 71.16666666666667, 1.0, 2.0, 0.4948863108413634, 1.0, 2.0, 0.4948863108413634, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1167645.686794772, 1167645.686794772, 235574.1290190677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5997000.0000, 
sim time next is 5997600.0000, 
raw observation next is [25.2, 71.0, 1.0, 2.0, 0.5631995240578195, 1.0, 2.0, 0.5631995240578195, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1324188.916673711, 1324188.916673711, 257462.00056009], 
processed observation next is [1.0, 0.43478260869565216, 0.4888888888888889, 0.71, 1.0, 1.0, 0.47999943340216605, 1.0, 1.0, 0.47999943340216605, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.47292461309775397, 0.47292461309775397, 0.49511923184632695], 
reward next is 0.5049, 
noisyNet noise sample is [array([0.31353864], dtype=float32), 0.61017877]. 
=============================================
[2019-03-24 08:35:27,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2931396e-07 4.0774893e-08 2.2213231e-07 9.9999845e-01 1.1952501e-06], sum to 1.0000
[2019-03-24 08:35:27,534] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-24 08:35:27,537] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.58333333333333, 81.83333333333333, 1.0, 2.0, 0.2100729614455146, 1.0, 2.0, 0.2100729614455146, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515608.3905253236, 515608.3905253241, 161916.4216577735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5982600.0000, 
sim time next is 5983200.0000, 
raw observation next is [21.7, 81.0, 1.0, 2.0, 0.2082105770472528, 1.0, 2.0, 0.2082105770472528, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 511118.7475398084, 511118.7475398088, 161521.4027008803], 
processed observation next is [1.0, 0.2608695652173913, 0.3592592592592592, 0.81, 1.0, 1.0, 0.057393544103872374, 1.0, 1.0, 0.057393544103872374, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18254240983564585, 0.182542409835646, 0.31061808211707753], 
reward next is 0.6894, 
noisyNet noise sample is [array([0.86556417], dtype=float32), -0.1648947]. 
=============================================
[2019-03-24 08:35:31,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0165248e-07 3.2417509e-07 1.6102085e-05 9.9998307e-01 7.8435562e-08], sum to 1.0000
[2019-03-24 08:35:31,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6244
[2019-03-24 08:35:31,389] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666666, 87.0, 1.0, 2.0, 0.2948712389887453, 1.0, 2.0, 0.2948712389887453, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676355.6260961153, 676355.6260961153, 179447.7646193535], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6331200.0000, 
sim time next is 6331800.0000, 
raw observation next is [24.73333333333333, 87.0, 1.0, 2.0, 0.2968559800980982, 1.0, 2.0, 0.2968559800980982, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679922.7170058619, 679922.7170058624, 179873.6635824277], 
processed observation next is [0.0, 0.2608695652173913, 0.4716049382716048, 0.87, 1.0, 1.0, 0.1629237858310693, 1.0, 1.0, 0.1629237858310693, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24282954178780783, 0.242829541787808, 0.34591089150466864], 
reward next is 0.6541, 
noisyNet noise sample is [array([-0.31377256], dtype=float32), 1.2177186]. 
=============================================
[2019-03-24 08:35:32,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1921223e-06 3.5171820e-07 4.2182219e-06 9.9999416e-01 1.2586428e-07], sum to 1.0000
[2019-03-24 08:35:32,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4670
[2019-03-24 08:35:32,056] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 60.0, 1.0, 2.0, 0.6759962979312691, 1.0, 2.0, 0.6759962979312691, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1541636.749897975, 1541636.749897975, 295176.8578148026], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6091200.0000, 
sim time next is 6091800.0000, 
raw observation next is [29.05, 59.33333333333333, 1.0, 2.0, 0.5581563653292518, 1.0, 2.0, 0.5581563653292518, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1272674.757349334, 1272674.757349334, 253953.0856710169], 
processed observation next is [1.0, 0.5217391304347826, 0.6314814814814815, 0.5933333333333333, 1.0, 1.0, 0.4739956730110141, 1.0, 1.0, 0.4739956730110141, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.45452669905333354, 0.45452669905333354, 0.4883713185981094], 
reward next is 0.5116, 
noisyNet noise sample is [array([0.57969445], dtype=float32), 0.5406172]. 
=============================================
[2019-03-24 08:35:35,662] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:35:35,663] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:35:35,664] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:35:35,664] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:35:35,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:35:35,668] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:35:35,670] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:35:35,671] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:35:35,672] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:35:35,673] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:35:35,674] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:35:35,702] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-24 08:35:35,733] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-24 08:35:35,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-24 08:35:35,795] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-24 08:35:35,796] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-24 08:36:06,138] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01034279], dtype=float32), 0.00897995]
[2019-03-24 08:36:06,140] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.08333333333333, 56.66666666666666, 1.0, 2.0, 0.2974403074390742, 1.0, 2.0, 0.2974403074390742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677942.6361959893, 677942.6361959897, 179847.5425954505]
[2019-03-24 08:36:06,141] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:06,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6775374e-07 2.7809998e-07 9.3777771e-07 9.9999833e-01 3.0452532e-07], sampled 0.4901776729238595
[2019-03-24 08:36:09,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01034279], dtype=float32), 0.00897995]
[2019-03-24 08:36:09,027] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.33333333333334, 90.66666666666667, 1.0, 2.0, 0.3324666359152806, 1.0, 2.0, 0.3324666359152806, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757816.0707735464, 757816.0707735464, 188434.4792339451]
[2019-03-24 08:36:09,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:09,031] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6996847e-07 2.8383934e-07 9.5067423e-07 9.9999833e-01 3.1160724e-07], sampled 0.6253558851405594
[2019-03-24 08:36:20,004] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01034279], dtype=float32), 0.00897995]
[2019-03-24 08:36:20,006] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 62.0, 1.0, 2.0, 0.6158419959910444, 1.0, 2.0, 0.6158419959910444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1404326.66102467, 1404326.661024671, 273532.9258981791]
[2019-03-24 08:36:20,007] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:36:20,009] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.7325705e-07 6.0225216e-07 1.8957148e-06 9.9999642e-01 6.8867831e-07], sampled 0.7612784874632473
[2019-03-24 08:36:43,959] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01034279], dtype=float32), 0.00897995]
[2019-03-24 08:36:43,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.59615409666667, 97.52456666, 1.0, 2.0, 0.3219700279961206, 1.0, 2.0, 0.3219700279961206, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733878.9139914679, 733878.9139914683, 185816.9164173723]
[2019-03-24 08:36:43,961] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:36:43,966] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3707067e-07 2.3070127e-07 7.6452613e-07 9.9999857e-01 2.7084351e-07], sampled 0.5949325344146951
[2019-03-24 08:36:47,551] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01034279], dtype=float32), 0.00897995]
[2019-03-24 08:36:47,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.65, 84.0, 1.0, 2.0, 0.4949835628525509, 1.0, 2.0, 0.4949835628525509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1128525.815663395, 1128525.815663395, 233835.1701112683]
[2019-03-24 08:36:47,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:47,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4975535e-07 4.0870887e-07 1.3233280e-06 9.9999762e-01 4.7077108e-07], sampled 0.6747697401090763
[2019-03-24 08:37:19,144] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3270 2465960889.4649 46.0000
[2019-03-24 08:37:19,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2636 2438844432.4277 34.0000
[2019-03-24 08:37:19,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:37:19,607] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:37:19,714] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:37:20,730] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1650000, evaluation results [1650000.0, 7523.727130323888, 2668527814.010175, 68.0, 7122.263554302433, 2438844432.427653, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.326961235299, 2465960889.4649444, 46.0]
[2019-03-24 08:37:33,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3974963e-07 2.2105323e-06 2.0500252e-06 9.9999392e-01 1.6434536e-06], sum to 1.0000
[2019-03-24 08:37:33,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8069
[2019-03-24 08:37:33,851] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.66666666666667, 78.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401057.4183778493, 401057.4183778493, 151268.1534963652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6745200.0000, 
sim time next is 6745800.0000, 
raw observation next is [19.58333333333333, 78.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399249.4979097577, 399249.4979097577, 150974.8186885552], 
processed observation next is [1.0, 0.043478260869565216, 0.280864197530864, 0.7866666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14258910639634204, 0.14258910639634204, 0.2903361897856831], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09298655], dtype=float32), 0.9101182]. 
=============================================
[2019-03-24 08:37:49,646] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0802257e-07 1.0256846e-05 8.7611897e-06 9.9997795e-01 2.8031834e-06], sum to 1.0000
[2019-03-24 08:37:49,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3134
[2019-03-24 08:37:49,658] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.48333333333333, 53.33333333333334, 1.0, 2.0, 0.2479680831729869, 1.0, 2.0, 0.2479680831729869, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 588635.1604891283, 588635.1604891279, 169557.9809636919], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6887400.0000, 
sim time next is 6888000.0000, 
raw observation next is [28.36666666666667, 53.66666666666667, 1.0, 2.0, 0.2468724201670943, 1.0, 2.0, 0.2468724201670943, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 586483.3477726496, 586483.3477726501, 169330.1767754476], 
processed observation next is [0.0, 0.7391304347826086, 0.606172839506173, 0.5366666666666667, 1.0, 1.0, 0.1034195478179694, 1.0, 1.0, 0.1034195478179694, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20945833849023202, 0.20945833849023218, 0.3256349553373992], 
reward next is 0.6744, 
noisyNet noise sample is [array([0.01291658], dtype=float32), -0.24794406]. 
=============================================
[2019-03-24 08:37:49,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.913456]
 [63.046993]
 [63.10026 ]
 [63.16036 ]
 [63.222424]], R is [[62.8687439 ]
 [62.91398621]
 [62.95832062]
 [63.00158691]
 [63.04383087]].
[2019-03-24 08:37:52,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8191046e-07 2.6427533e-06 6.7423406e-07 9.9999583e-01 2.2626438e-07], sum to 1.0000
[2019-03-24 08:37:52,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1023
[2019-03-24 08:37:52,958] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 60.33333333333333, 1.0, 2.0, 0.253658107530693, 1.0, 2.0, 0.253658107530693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598660.9105309446, 598660.9105309446, 170697.6226692538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [27.73333333333333, 59.16666666666666, 1.0, 2.0, 0.2544083581665328, 1.0, 2.0, 0.2544083581665328, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599965.4252305895, 599965.4252305895, 170847.6656576304], 
processed observation next is [0.0, 0.43478260869565216, 0.5827160493827159, 0.5916666666666666, 1.0, 1.0, 0.1123909025792057, 1.0, 1.0, 0.1123909025792057, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21427336615378195, 0.21427336615378195, 0.3285532031877508], 
reward next is 0.6714, 
noisyNet noise sample is [array([1.6451751], dtype=float32), 0.72469085]. 
=============================================
[2019-03-24 08:37:52,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7581095e-07 1.4506907e-07 5.1451989e-06 9.9999404e-01 5.3574178e-07], sum to 1.0000
[2019-03-24 08:37:52,975] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.68768]
 [67.69174]
 [67.69221]
 [67.73695]
 [67.79784]], R is [[67.65164185]
 [67.64686584]
 [67.64244843]
 [67.63845062]
 [67.63522339]].
[2019-03-24 08:37:52,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5126
[2019-03-24 08:37:52,985] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 50.0, 1.0, 2.0, 0.2212605742874919, 1.0, 2.0, 0.2212605742874919, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534180.3803324985, 534180.3803324989, 164029.8592098227], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6865200.0000, 
sim time next is 6865800.0000, 
raw observation next is [28.26666666666667, 50.0, 1.0, 2.0, 0.2233842521004636, 1.0, 2.0, 0.2233842521004636, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538382.4795429884, 538382.4795429888, 164456.6228245764], 
processed observation next is [0.0, 0.4782608695652174, 0.6024691358024692, 0.5, 1.0, 1.0, 0.07545744297674237, 1.0, 1.0, 0.07545744297674237, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1922794569796387, 0.19227945697963886, 0.31626273620110845], 
reward next is 0.6837, 
noisyNet noise sample is [array([-1.554964], dtype=float32), 0.14646219]. 
=============================================
[2019-03-24 08:37:58,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5057401e-09 2.7438034e-07 4.5589500e-06 9.9999499e-01 2.4105782e-07], sum to 1.0000
[2019-03-24 08:37:58,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5815
[2019-03-24 08:37:58,110] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 58.0, 1.0, 2.0, 0.2212631201383623, 1.0, 2.0, 0.2212631201383623, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534152.5927552237, 534152.5927552242, 164029.1551533761], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6861600.0000, 
sim time next is 6862200.0000, 
raw observation next is [26.76666666666667, 56.66666666666667, 1.0, 2.0, 0.2215471852758275, 1.0, 2.0, 0.2215471852758275, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534728.0280825003, 534728.0280825008, 164086.6611475502], 
processed observation next is [0.0, 0.43478260869565216, 0.5469135802469137, 0.5666666666666668, 1.0, 1.0, 0.07327045866169941, 1.0, 1.0, 0.07327045866169941, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1909742957437501, 0.19097429574375027, 0.3155512714375966], 
reward next is 0.6844, 
noisyNet noise sample is [array([-0.15695742], dtype=float32), -0.5868924]. 
=============================================
[2019-03-24 08:37:59,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7782913e-07 7.7895044e-07 2.5575289e-06 9.9999583e-01 3.4259816e-07], sum to 1.0000
[2019-03-24 08:37:59,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0615
[2019-03-24 08:37:59,939] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.05, 73.5, 1.0, 2.0, 0.2085624946714633, 1.0, 2.0, 0.2085624946714633, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509972.4726175903, 509972.4726175907, 161532.6509699435], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6916200.0000, 
sim time next is 6916800.0000, 
raw observation next is [23.0, 74.0, 1.0, 2.0, 0.2088386527107666, 1.0, 2.0, 0.2088386527107666, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510471.8530456901, 510471.8530456901, 161585.7544294466], 
processed observation next is [0.0, 0.043478260869565216, 0.4074074074074074, 0.74, 1.0, 1.0, 0.05814125322710309, 1.0, 1.0, 0.05814125322710309, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18231137608774647, 0.18231137608774647, 0.31074183544124345], 
reward next is 0.6893, 
noisyNet noise sample is [array([-1.676646], dtype=float32), 0.66793114]. 
=============================================
[2019-03-24 08:38:04,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0001618e-06 1.3190790e-07 4.4581686e-08 9.9999881e-01 1.7093420e-08], sum to 1.0000
[2019-03-24 08:38:04,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8346
[2019-03-24 08:38:04,585] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 60.33333333333333, 1.0, 2.0, 0.253658107530693, 1.0, 2.0, 0.253658107530693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598660.9105309446, 598660.9105309446, 170697.6226692538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [27.73333333333333, 59.16666666666666, 1.0, 2.0, 0.2544083581665328, 1.0, 2.0, 0.2544083581665328, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599965.4252305895, 599965.4252305895, 170847.6656576304], 
processed observation next is [0.0, 0.43478260869565216, 0.5827160493827159, 0.5916666666666666, 1.0, 1.0, 0.1123909025792057, 1.0, 1.0, 0.1123909025792057, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21427336615378195, 0.21427336615378195, 0.3285532031877508], 
reward next is 0.6714, 
noisyNet noise sample is [array([-0.9321815], dtype=float32), 0.6740211]. 
=============================================
[2019-03-24 08:38:04,601] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.909218]
 [63.946808]
 [63.97426 ]
 [64.02713 ]
 [64.09215 ]], R is [[63.897892  ]
 [63.9306488 ]
 [63.96339417]
 [63.99618912]
 [64.0293808 ]].
[2019-03-24 08:38:05,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.0000496e-09 3.1713337e-06 1.0641004e-05 9.9998617e-01 2.4475918e-08], sum to 1.0000
[2019-03-24 08:38:05,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8816
[2019-03-24 08:38:05,629] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.43333333333333, 87.33333333333334, 1.0, 2.0, 0.1903587000951546, 1.0, 2.0, 0.1903587000951546, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470637.4411611672, 470637.4411611676, 157873.7442709937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [20.41666666666666, 87.66666666666667, 1.0, 2.0, 0.1902973556308619, 1.0, 2.0, 0.1902973556308619, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470332.5415418759, 470332.5415418759, 157856.6925727164], 
processed observation next is [1.0, 0.13043478260869565, 0.31172839506172817, 0.8766666666666667, 1.0, 1.0, 0.036068280512930824, 1.0, 1.0, 0.036068280512930824, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1679759076935271, 0.1679759076935271, 0.3035705626398392], 
reward next is 0.6964, 
noisyNet noise sample is [array([1.0858036], dtype=float32), -0.4999033]. 
=============================================
[2019-03-24 08:38:10,144] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 08:38:10,146] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:38:10,147] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:10,149] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:38:10,149] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:38:10,150] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:10,150] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:10,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:38:10,151] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:38:10,153] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:10,154] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:10,168] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-24 08:38:10,201] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-24 08:38:10,231] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-24 08:38:10,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-24 08:38:10,261] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-24 08:38:14,749] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:38:14,750] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.35, 29.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401409.9629100194, 401409.9629100194, 150233.9267154799]
[2019-03-24 08:38:14,751] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:38:14,753] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1316740e-07 2.6559380e-07 8.0480970e-07 9.9999857e-01 2.0586617e-07], sampled 0.22024038591761763
[2019-03-24 08:38:19,979] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:38:19,980] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 31.5, 1.0, 2.0, 0.1692842212791887, 1.0, 2.0, 0.1692842212791887, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427105.4315224565, 427105.4315224569, 153722.4333714808]
[2019-03-24 08:38:19,980] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:38:19,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9422690e-08 1.6383051e-07 5.2762971e-07 9.9999917e-01 1.2194535e-07], sampled 0.08730204128677477
[2019-03-24 08:38:40,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:38:40,591] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.01666666666667, 48.33333333333334, 1.0, 2.0, 0.3173553538878616, 1.0, 2.0, 0.3173553538878616, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723355.5434372715, 723355.5434372715, 184678.0157753858]
[2019-03-24 08:38:40,592] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:38:40,595] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7499865e-08 6.5705422e-08 2.3854290e-07 9.9999964e-01 4.7180372e-08], sampled 0.30836536629586675
[2019-03-24 08:38:53,063] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:38:53,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.22153742, 92.23851123, 1.0, 2.0, 0.591527692121571, 1.0, 2.0, 0.591527692121571, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1348833.057109259, 1348833.05710926, 265140.9192886652]
[2019-03-24 08:38:53,065] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:38:53,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.7386380e-08 1.3637332e-07 4.4683676e-07 9.9999928e-01 1.0544869e-07], sampled 0.5037509262226505
[2019-03-24 08:38:57,708] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:38:57,709] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666667, 70.66666666666667, 1.0, 2.0, 0.3677244379266021, 1.0, 2.0, 0.3677244379266021, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 838225.7601848239, 838225.7601848244, 197507.9290853706]
[2019-03-24 08:38:57,711] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:38:57,713] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8328788e-08 7.0180519e-08 2.3920398e-07 9.9999964e-01 5.1169383e-08], sampled 0.21892729412962375
[2019-03-24 08:39:00,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:39:00,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.34607165, 74.93835978, 1.0, 2.0, 0.2900230226844928, 1.0, 2.0, 0.2900230226844928, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716982.2868642092, 716982.2868642097, 180279.2410221966]
[2019-03-24 08:39:00,301] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:39:00,303] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5564121e-08 8.3415998e-08 3.0573796e-07 9.9999940e-01 6.1931836e-08], sampled 0.9001922465779658
[2019-03-24 08:39:28,465] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:39:28,466] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.16666666666667, 82.0, 1.0, 2.0, 0.3440404357023726, 1.0, 2.0, 0.3440404357023726, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784210.5934662203, 784210.5934662203, 191365.6051746999]
[2019-03-24 08:39:28,467] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:39:28,469] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.5568093e-08 6.3873046e-08 2.1558778e-07 9.9999964e-01 4.7565198e-08], sampled 0.3780036536391649
[2019-03-24 08:39:30,812] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0104357], dtype=float32), 0.009164709]
[2019-03-24 08:39:30,814] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.35480656666667, 79.91242960333334, 1.0, 2.0, 0.3057857516217978, 1.0, 2.0, 0.3057857516217978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 696972.6877650645, 696972.687765065, 181855.0412839759]
[2019-03-24 08:39:30,816] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:39:30,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.536188e-08 8.823771e-08 2.883936e-07 9.999994e-01 6.759022e-08], sampled 0.02815713112001539
[2019-03-24 08:39:53,228] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7123.0782 2438793696.0140 34.0000
[2019-03-24 08:39:53,357] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:39:53,572] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465954462.2705 46.0000
[2019-03-24 08:39:53,672] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:39:53,675] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5310 2410721666.3579 22.0000
[2019-03-24 08:39:54,692] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1675000, evaluation results [1675000.0, 7523.727130323888, 2668527814.010175, 68.0, 7123.078225363454, 2438793696.0140443, 34.0, 7797.531024853822, 2410721666.357948, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465954462.270544, 46.0]
[2019-03-24 08:39:54,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1505783e-08 1.2662865e-07 6.8429870e-07 9.9999869e-01 4.8977438e-07], sum to 1.0000
[2019-03-24 08:39:54,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5819
[2019-03-24 08:39:54,949] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.68333333333333, 79.16666666666667, 1.0, 2.0, 0.2442952401967896, 1.0, 2.0, 0.2442952401967896, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583359.0863427835, 583359.086342784, 168874.0423652414], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7063800.0000, 
sim time next is 7064400.0000, 
raw observation next is [23.66666666666667, 79.33333333333334, 1.0, 2.0, 0.2448456225643938, 1.0, 2.0, 0.2448456225643938, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584578.575163657, 584578.5751636574, 168993.7427123321], 
processed observation next is [1.0, 0.782608695652174, 0.43209876543209896, 0.7933333333333334, 1.0, 1.0, 0.10100669352904024, 1.0, 1.0, 0.10100669352904024, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2087780625584489, 0.20877806255844908, 0.3249879667544848], 
reward next is 0.6750, 
noisyNet noise sample is [array([-0.46517563], dtype=float32), -0.76544684]. 
=============================================
[2019-03-24 08:39:58,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7612034e-08 1.7911022e-07 1.0954725e-08 9.9999952e-01 1.8677753e-07], sum to 1.0000
[2019-03-24 08:39:58,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8416
[2019-03-24 08:39:58,941] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.1833163988597837, 1.0, 2.0, 0.1833163988597837, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455359.204793984, 455359.2047939844, 156465.3031379285], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7149600.0000, 
sim time next is 7150200.0000, 
raw observation next is [21.81666666666667, 74.16666666666667, 1.0, 2.0, 0.1839834393254212, 1.0, 2.0, 0.1839834393254212, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 457063.5208351429, 457063.5208351433, 156605.8703532465], 
processed observation next is [1.0, 0.782608695652174, 0.3635802469135804, 0.7416666666666667, 1.0, 1.0, 0.028551713482644268, 1.0, 1.0, 0.028551713482644268, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16323697172683674, 0.16323697172683688, 0.3011651352947048], 
reward next is 0.6988, 
noisyNet noise sample is [array([-0.42701328], dtype=float32), -0.36471152]. 
=============================================
[2019-03-24 08:40:03,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2222094e-07 2.4499776e-08 7.1646656e-07 9.9999917e-01 8.2352010e-09], sum to 1.0000
[2019-03-24 08:40:03,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3665
[2019-03-24 08:40:03,101] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.0, 96.66666666666666, 1.0, 2.0, 0.1818040278842941, 1.0, 2.0, 0.1818040278842941, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 451583.800372374, 451583.8003723745, 156149.6364020433], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7447200.0000, 
sim time next is 7447800.0000, 
raw observation next is [18.95, 96.83333333333334, 1.0, 2.0, 0.1810205465850045, 1.0, 2.0, 0.1810205465850045, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449840.4341871259, 449840.4341871263, 155992.2575844501], 
processed observation next is [0.0, 0.17391304347826086, 0.25740740740740736, 0.9683333333333334, 1.0, 1.0, 0.025024460220243443, 1.0, 1.0, 0.025024460220243443, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16065729792397354, 0.16065729792397368, 0.2999851107393271], 
reward next is 0.7000, 
noisyNet noise sample is [array([-0.06083651], dtype=float32), -1.2317709]. 
=============================================
[2019-03-24 08:40:04,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5188713e-08 1.4451254e-08 6.5057598e-08 9.9999988e-01 1.1408206e-08], sum to 1.0000
[2019-03-24 08:40:04,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5918
[2019-03-24 08:40:04,601] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 95.83333333333333, 1.0, 2.0, 0.2215753289064124, 1.0, 2.0, 0.2215753289064124, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534143.9402890571, 534143.9402890576, 164068.3390388892], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7542600.0000, 
sim time next is 7543200.0000, 
raw observation next is [21.0, 95.66666666666666, 1.0, 2.0, 0.2216358734860178, 1.0, 2.0, 0.2216358734860178, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534451.908249013, 534451.9082490135, 164087.5650936947], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 0.9566666666666666, 1.0, 1.0, 0.0733760398643069, 1.0, 1.0, 0.0733760398643069, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19087568151750464, 0.1908756815175048, 0.3155530097955667], 
reward next is 0.6844, 
noisyNet noise sample is [array([0.7271916], dtype=float32), -1.8135011]. 
=============================================
[2019-03-24 08:40:04,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1264375e-08 3.0119974e-08 2.7808287e-07 9.9999976e-01 2.7961715e-08], sum to 1.0000
[2019-03-24 08:40:04,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-24 08:40:04,732] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 95.16666666666667, 1.0, 2.0, 0.219949554669243, 1.0, 2.0, 0.219949554669243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530928.752561964, 530928.7525619644, 163742.6598402383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7545000.0000, 
sim time next is 7545600.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.2198518957070147, 1.0, 2.0, 0.2198518957070147, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530869.5181663989, 530869.5181663992, 163728.1011778418], 
processed observation next is [0.0, 0.34782608695652173, 0.3333333333333333, 0.95, 1.0, 1.0, 0.0712522567940651, 1.0, 1.0, 0.0712522567940651, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1895962564879996, 0.18959625648799971, 0.31486173303431114], 
reward next is 0.6851, 
noisyNet noise sample is [array([-1.6252986], dtype=float32), 1.5882626]. 
=============================================
[2019-03-24 08:40:17,547] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7288149e-07 2.4883917e-07 3.6584248e-07 9.9999905e-01 1.1794237e-07], sum to 1.0000
[2019-03-24 08:40:17,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9803
[2019-03-24 08:40:17,558] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.25, 72.33333333333333, 1.0, 2.0, 0.1709114654793089, 1.0, 2.0, 0.1709114654793089, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 428707.038943044, 428707.0389430444, 154007.6926545173], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7672200.0000, 
sim time next is 7672800.0000, 
raw observation next is [21.0, 72.66666666666667, 1.0, 2.0, 0.1674366419869536, 1.0, 2.0, 0.1674366419869536, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420980.2622226067, 420980.2622226067, 153319.2420809006], 
processed observation next is [1.0, 0.8260869565217391, 0.3333333333333333, 0.7266666666666667, 1.0, 1.0, 0.008853145222563806, 1.0, 1.0, 0.008853145222563806, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15035009365093097, 0.15035009365093097, 0.2948446963094243], 
reward next is 0.7052, 
noisyNet noise sample is [array([-0.6788458], dtype=float32), 0.8462204]. 
=============================================
[2019-03-24 08:40:17,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0510814e-07 3.0755707e-08 8.4784737e-08 9.9999940e-01 3.1490177e-07], sum to 1.0000
[2019-03-24 08:40:17,579] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3049
[2019-03-24 08:40:17,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.95, 96.0, 1.0, 2.0, 0.223993820720291, 1.0, 2.0, 0.223993820720291, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540092.8974711989, 540092.8974711989, 164598.2967126484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7523400.0000, 
sim time next is 7524000.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.2224161561083798, 1.0, 2.0, 0.2224161561083798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536763.7118942139, 536763.7118942144, 164272.9918662198], 
processed observation next is [0.0, 0.08695652173913043, 0.32962962962962955, 0.96, 1.0, 1.0, 0.0743049477480712, 1.0, 1.0, 0.0743049477480712, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19170132567650497, 0.19170132567650514, 0.31590959974273036], 
reward next is 0.6841, 
noisyNet noise sample is [array([-1.1232506], dtype=float32), 0.8521706]. 
=============================================
[2019-03-24 08:40:17,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.146645]
 [72.15322 ]
 [72.37272 ]
 [72.282326]
 [72.12125 ]], R is [[72.14983368]
 [72.11180115]
 [72.07353973]
 [72.03517151]
 [71.99684143]].
[2019-03-24 08:40:23,086] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:23,088] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:23,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-24 08:40:25,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1980582e-07 9.5642591e-08 3.8976353e-08 9.9999964e-01 7.2970352e-08], sum to 1.0000
[2019-03-24 08:40:25,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2844
[2019-03-24 08:40:25,525] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.6, 91.0, 1.0, 2.0, 0.219041731074344, 1.0, 2.0, 0.219041731074344, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536393.4888470233, 536393.4888470238, 163810.152163445], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7630200.0000, 
sim time next is 7630800.0000, 
raw observation next is [20.66666666666667, 91.0, 1.0, 2.0, 0.2115279231786674, 1.0, 2.0, 0.2115279231786674, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 517546.3971003098, 517546.3971003094, 162176.4660501683], 
processed observation next is [1.0, 0.30434782608695654, 0.3209876543209878, 0.91, 1.0, 1.0, 0.06134276568888975, 1.0, 1.0, 0.06134276568888975, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18483799896439634, 0.1848379989643962, 0.31187781932724673], 
reward next is 0.6881, 
noisyNet noise sample is [array([-0.3940818], dtype=float32), -0.104143575]. 
=============================================
[2019-03-24 08:40:25,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8257456e-09 3.1667736e-07 1.1414256e-07 9.9999928e-01 2.4221751e-07], sum to 1.0000
[2019-03-24 08:40:25,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3902
[2019-03-24 08:40:25,944] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 65.0, 1.0, 2.0, 0.5667172667874161, 1.0, 2.0, 0.5667172667874161, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1309902.358518068, 1309902.358518068, 257639.4662284973], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7653600.0000, 
sim time next is 7654200.0000, 
raw observation next is [26.95, 65.16666666666667, 1.0, 2.0, 0.4725357144962432, 1.0, 2.0, 0.4725357144962432, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1097089.451422337, 1097089.451422336, 227945.6784756548], 
processed observation next is [1.0, 0.6086956521739131, 0.5537037037037037, 0.6516666666666667, 1.0, 1.0, 0.3720663267812419, 1.0, 1.0, 0.3720663267812419, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3918176612222632, 0.39181766122226286, 0.43835707399164386], 
reward next is 0.5616, 
noisyNet noise sample is [array([-1.1265996], dtype=float32), 0.18805727]. 
=============================================
[2019-03-24 08:40:27,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:27,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:27,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-24 08:40:30,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:30,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:30,467] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-24 08:40:30,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2703784e-07 2.2555251e-07 3.2955612e-08 9.9999940e-01 2.0293811e-07], sum to 1.0000
[2019-03-24 08:40:30,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4688
[2019-03-24 08:40:30,848] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.03333333333333, 53.0, 1.0, 2.0, 0.4567475673580202, 1.0, 2.0, 0.4567475673580202, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1084044.414940473, 1084044.414940473, 224210.5517147765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [28.21666666666667, 52.0, 1.0, 2.0, 0.4583036661198612, 1.0, 2.0, 0.4583036661198612, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1088191.246698389, 1088191.246698389, 224692.9517827581], 
processed observation next is [1.0, 0.5217391304347826, 0.6006172839506173, 0.52, 1.0, 1.0, 0.35512341204745373, 1.0, 1.0, 0.35512341204745373, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3886397309637104, 0.3886397309637104, 0.4321018303514579], 
reward next is 0.5679, 
noisyNet noise sample is [array([0.14500935], dtype=float32), -1.4024619]. 
=============================================
[2019-03-24 08:40:31,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5595701e-08 7.3343250e-07 1.2019159e-06 9.9999809e-01 2.1502922e-08], sum to 1.0000
[2019-03-24 08:40:31,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-24 08:40:31,678] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 51.5, 1.0, 2.0, 0.5913439024650792, 1.0, 2.0, 0.5913439024650792, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1396508.014477781, 1396508.014477781, 267280.9322268679], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7906200.0000, 
sim time next is 7906800.0000, 
raw observation next is [28.53333333333333, 51.0, 1.0, 2.0, 0.5214174092475542, 1.0, 2.0, 0.5214174092475542, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1231918.864677367, 1231918.864677367, 244023.4937017762], 
processed observation next is [1.0, 0.5217391304347826, 0.6123456790123456, 0.51, 1.0, 1.0, 0.4302588205328026, 1.0, 1.0, 0.4302588205328026, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.43997102309905967, 0.43997102309905967, 0.4692759494264927], 
reward next is 0.5307, 
noisyNet noise sample is [array([-1.518651], dtype=float32), -1.656527]. 
=============================================
[2019-03-24 08:40:32,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:32,358] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:32,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-24 08:40:34,100] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:34,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:34,152] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-24 08:40:34,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:34,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:34,670] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-24 08:40:36,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:36,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:37,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-24 08:40:37,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:37,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:37,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-24 08:40:37,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.56662752e-09 1.40009977e-08 1.04416216e-07 9.99999762e-01
 1.02131352e-07], sum to 1.0000
[2019-03-24 08:40:37,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-24 08:40:37,527] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.46666666666667, 84.0, 1.0, 2.0, 0.1876395072878418, 1.0, 2.0, 0.1876395072878418, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466250.8473440796, 466250.8473440801, 157375.0125003891], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7883400.0000, 
sim time next is 7884000.0000, 
raw observation next is [20.6, 83.0, 1.0, 2.0, 0.1863085193772256, 1.0, 2.0, 0.1863085193772256, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462932.5349413293, 462932.5349413297, 157095.1772514184], 
processed observation next is [1.0, 0.2608695652173913, 0.3185185185185186, 0.83, 1.0, 1.0, 0.03131966592526856, 1.0, 1.0, 0.03131966592526856, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1653330481933319, 0.16533304819333203, 0.30210611009888155], 
reward next is 0.6979, 
noisyNet noise sample is [array([0.7295955], dtype=float32), 0.3088988]. 
=============================================
[2019-03-24 08:40:37,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.800343]
 [60.831676]
 [61.075283]
 [61.069656]
 [61.10727 ]], R is [[60.75474548]
 [60.8445549 ]
 [60.93296051]
 [61.01926422]
 [61.10437012]].
[2019-03-24 08:40:37,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:37,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:37,779] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-24 08:40:38,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:38,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:38,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:38,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:38,752] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-24 08:40:38,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-24 08:40:39,282] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:39,283] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:39,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-24 08:40:40,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:40,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:40,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-24 08:40:40,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:40,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:40,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-24 08:40:40,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:40,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:40,925] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-24 08:40:41,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:40:41,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:41,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-24 08:40:42,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7845309e-08 1.2966184e-07 3.7803159e-06 9.9999571e-01 3.4873543e-07], sum to 1.0000
[2019-03-24 08:40:42,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6912
[2019-03-24 08:40:42,058] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.43333333333333, 41.66666666666667, 1.0, 2.0, 0.3760034240126507, 1.0, 2.0, 0.3760034240126507, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 939907.2651692273, 939907.2651692268, 202668.2607006182], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 38400.0000, 
sim time next is 39000.0000, 
raw observation next is [26.66666666666667, 41.33333333333334, 1.0, 2.0, 0.3825296129812142, 1.0, 2.0, 0.3825296129812142, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954718.2471548048, 954718.2471548048, 204432.8993193983], 
processed observation next is [1.0, 0.43478260869565216, 0.5432098765432101, 0.41333333333333344, 1.0, 1.0, 0.2649162059300169, 1.0, 1.0, 0.2649162059300169, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3409708025552874, 0.3409708025552874, 0.3931401909988429], 
reward next is 0.6069, 
noisyNet noise sample is [array([-0.17547347], dtype=float32), -2.1258667]. 
=============================================
[2019-03-24 08:40:42,074] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.550327]
 [62.2846  ]
 [61.998684]
 [61.73913 ]
 [61.549755]], R is [[62.85288239]
 [62.83460617]
 [62.8150177 ]
 [62.80004501]
 [62.7842598 ]].
[2019-03-24 08:40:44,037] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 08:40:44,038] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:40:44,039] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:44,039] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:40:44,040] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:40:44,041] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:44,041] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:40:44,045] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:44,047] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:44,044] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:40:44,050] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:40:44,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-24 08:40:44,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-24 08:40:44,098] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-24 08:40:44,129] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-24 08:40:44,192] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-24 08:41:00,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01035408], dtype=float32), 0.009480432]
[2019-03-24 08:41:00,999] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 47.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391964.6393262084, 391964.6393262089, 149910.8498770537]
[2019-03-24 08:41:00,999] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:41:01,003] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3875801e-07 2.8074351e-07 7.3304972e-07 9.9999869e-01 2.5921085e-07], sampled 0.5402776755045376
[2019-03-24 08:41:03,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01035408], dtype=float32), 0.009480432]
[2019-03-24 08:41:03,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.44038527166666, 32.88346522333333, 1.0, 2.0, 0.1659751260247247, 1.0, 2.0, 0.1659751260247247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421816.019662623, 421816.0196626234, 153089.400288191]
[2019-03-24 08:41:03,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:41:03,289] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.1851248e-08 1.8905841e-07 5.0657957e-07 9.9999905e-01 1.6870669e-07], sampled 0.13572926784031414
[2019-03-24 08:41:05,073] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01035408], dtype=float32), 0.009480432]
[2019-03-24 08:41:05,076] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 46.0, 1.0, 2.0, 0.2564996049737547, 1.0, 2.0, 0.2564996049737547, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 610153.2551882918, 610153.2551882922, 171543.2752424601]
[2019-03-24 08:41:05,078] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:41:05,080] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.9190037e-08 1.4342676e-07 3.9113723e-07 9.9999928e-01 1.2885759e-07], sampled 0.4319172289509903
[2019-03-24 08:41:13,140] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01035408], dtype=float32), 0.009480432]
[2019-03-24 08:41:13,140] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.6, 24.0, 1.0, 2.0, 0.5338260425279326, 1.0, 2.0, 0.5338260425279326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1302916.448270869, 1302916.44827087, 249506.7903612916]
[2019-03-24 08:41:13,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:41:13,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.7221869e-08 1.3548147e-07 3.9110290e-07 9.9999928e-01 1.2012097e-07], sampled 0.6583270198092485
[2019-03-24 08:41:27,936] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01035408], dtype=float32), 0.009480432]
[2019-03-24 08:41:27,938] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.5, 76.5, 1.0, 2.0, 0.3527739379010245, 1.0, 2.0, 0.3527739379010245, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 804128.3033195535, 804128.303319554, 193608.1741354452]
[2019-03-24 08:41:27,940] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:41:27,942] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.8781196e-08 1.0207970e-07 2.9362712e-07 9.9999940e-01 8.9210253e-08], sampled 0.5149599922480337
[2019-03-24 08:42:27,449] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5523 2410705214.1115 22.0000
[2019-03-24 08:42:27,543] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454110.0746 47.0000
[2019-03-24 08:42:27,921] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:42:27,921] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:42:27,981] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:42:28,999] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1700000, evaluation results [1700000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.552259629344, 2410705214.1115327, 22.0, 6905.908355438081, 2495454110.074621, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:42:31,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6912332e-09 3.2025498e-09 1.5066563e-08 1.0000000e+00 3.0441040e-08], sum to 1.0000
[2019-03-24 08:42:31,013] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3495
[2019-03-24 08:42:31,019] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 68.66666666666667, 1.0, 2.0, 0.210768684785888, 1.0, 2.0, 0.210768684785888, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513859.7290058789, 513859.7290058794, 161953.6019907508], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 87000.0000, 
sim time next is 87600.0000, 
raw observation next is [23.9, 69.33333333333334, 1.0, 2.0, 0.2111953222075308, 1.0, 2.0, 0.2111953222075308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514863.406178308, 514863.4061783085, 162043.5703334514], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.6933333333333335, 1.0, 1.0, 0.06094681215182236, 1.0, 1.0, 0.06094681215182236, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1838797879208243, 0.18387978792082446, 0.3116222506412527], 
reward next is 0.6884, 
noisyNet noise sample is [array([-1.0726972], dtype=float32), -0.22700825]. 
=============================================
[2019-03-24 08:42:37,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1730787e-06 4.0430459e-06 1.6132333e-05 9.9997342e-01 4.1505605e-06], sum to 1.0000
[2019-03-24 08:42:37,847] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-24 08:42:37,853] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [17.9, 78.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 345802.984720736, 345802.9847207364, 142185.8658401286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 450000.0000, 
sim time next is 450600.0000, 
raw observation next is [18.2, 76.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 337197.6670878751, 337197.6670878755, 140947.4975904623], 
processed observation next is [1.0, 0.21739130434782608, 0.2296296296296296, 0.765, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12042773824566967, 0.12042773824566981, 0.2710528799816583], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35350075], dtype=float32), -0.4627942]. 
=============================================
[2019-03-24 08:42:38,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6433376e-07 7.0180994e-07 8.3609038e-06 9.9999058e-01 1.4832986e-07], sum to 1.0000
[2019-03-24 08:42:39,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8631
[2019-03-24 08:42:39,008] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.31666666666666, 13.16666666666667, 1.0, 2.0, 0.189043045439506, 1.0, 2.0, 0.189043045439506, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484528.4114386844, 484528.4114386844, 157871.9671095447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 223800.0000, 
sim time next is 224400.0000, 
raw observation next is [33.33333333333333, 13.33333333333333, 1.0, 2.0, 0.189617162181803, 1.0, 2.0, 0.189617162181803, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485775.5694201391, 485775.5694201391, 157991.3318827969], 
processed observation next is [0.0, 0.6086956521739131, 0.7901234567901233, 0.1333333333333333, 1.0, 1.0, 0.035258526406908325, 1.0, 1.0, 0.035258526406908325, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17349127479290682, 0.17349127479290682, 0.303829484389994], 
reward next is 0.6962, 
noisyNet noise sample is [array([-1.6608454], dtype=float32), 1.7638382]. 
=============================================
[2019-03-24 08:42:39,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6211968e-07 5.8840578e-07 1.9600129e-05 9.9997807e-01 1.1764283e-06], sum to 1.0000
[2019-03-24 08:42:39,381] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1881
[2019-03-24 08:42:39,385] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 36.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 404141.7012999702, 404141.7012999707, 151222.9210409167], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 331200.0000, 
sim time next is 331800.0000, 
raw observation next is [25.96666666666667, 36.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 402988.0726120811, 402988.0726120815, 151043.9259514955], 
processed observation next is [0.0, 0.8695652173913043, 0.517283950617284, 0.365, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14392431164717182, 0.14392431164717195, 0.2904690883682606], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3863954], dtype=float32), 0.28633776]. 
=============================================
[2019-03-24 08:42:40,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8079582e-06 1.1352470e-06 1.5099723e-06 9.9999166e-01 7.9323485e-07], sum to 1.0000
[2019-03-24 08:42:40,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5046
[2019-03-24 08:42:40,472] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 31.0, 1.0, 2.0, 0.1676711307737658, 1.0, 2.0, 0.1676711307737658, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427247.4912617077, 427247.4912617081, 153444.367634301], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 248400.0000, 
sim time next is 249000.0000, 
raw observation next is [27.36666666666667, 32.0, 1.0, 2.0, 0.1668146178595418, 1.0, 2.0, 0.1668146178595418, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425287.4233503271, 425287.4233503271, 153271.215721804], 
processed observation next is [0.0, 0.9130434782608695, 0.569135802469136, 0.32, 1.0, 1.0, 0.008112640308978326, 1.0, 1.0, 0.008112640308978326, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15188836548225967, 0.15188836548225967, 0.29475233792654615], 
reward next is 0.7052, 
noisyNet noise sample is [array([-1.3911508], dtype=float32), 0.9629214]. 
=============================================
[2019-03-24 08:42:40,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.891865]
 [49.991913]
 [50.119415]
 [50.262535]
 [50.359245]], R is [[49.91647339]
 [50.1222229 ]
 [50.32526398]
 [50.52566528]
 [50.72352982]].
[2019-03-24 08:42:49,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0221387e-06 8.8364459e-07 2.2274446e-05 9.9996471e-01 6.1570991e-06], sum to 1.0000
[2019-03-24 08:42:49,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2789
[2019-03-24 08:42:49,234] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 29.66666666666667, 1.0, 2.0, 0.1757990295364364, 1.0, 2.0, 0.1757990295364364, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442594.2863759515, 442594.2863759515, 155044.394671614], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [29.45, 30.0, 1.0, 2.0, 0.1745956960400786, 1.0, 2.0, 0.1745956960400786, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439761.6224802001, 439761.6224802005, 154799.6540260125], 
processed observation next is [1.0, 0.782608695652174, 0.6462962962962963, 0.3, 1.0, 1.0, 0.01737582861914119, 1.0, 1.0, 0.01737582861914119, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15705772231435716, 0.15705772231435733, 0.29769164235771634], 
reward next is 0.7023, 
noisyNet noise sample is [array([1.2044955], dtype=float32), -0.60746366]. 
=============================================
[2019-03-24 08:42:53,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0963918e-07 7.6942246e-07 9.7740667e-07 9.9999774e-01 2.9671801e-07], sum to 1.0000
[2019-03-24 08:42:53,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6969
[2019-03-24 08:42:53,858] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.06666666666667, 42.16666666666667, 1.0, 2.0, 0.1744332080866597, 1.0, 2.0, 0.1744332080866597, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435970.2174772228, 435970.2174772228, 154695.1868804063], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 507000.0000, 
sim time next is 507600.0000, 
raw observation next is [26.8, 43.0, 1.0, 2.0, 0.1744707560397254, 1.0, 2.0, 0.1744707560397254, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 436376.7417234749, 436376.7417234753, 154710.2455193679], 
processed observation next is [1.0, 0.9130434782608695, 0.5481481481481482, 0.43, 1.0, 1.0, 0.01722709052348261, 1.0, 1.0, 0.01722709052348261, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15584883632981245, 0.1558488363298126, 0.2975197029218613], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.41660872], dtype=float32), 0.8352818]. 
=============================================
[2019-03-24 08:42:56,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8922196e-06 2.6300800e-06 6.1966944e-07 9.9999154e-01 3.2951175e-06], sum to 1.0000
[2019-03-24 08:42:56,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8264
[2019-03-24 08:42:56,359] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.15, 50.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 366404.236453061, 366404.2364530615, 145690.0164216535], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 948600.0000, 
sim time next is 949200.0000, 
raw observation next is [23.03333333333333, 51.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 363890.6071314242, 363890.6071314247, 145307.2038753962], 
processed observation next is [0.0, 1.0, 0.4086419753086419, 0.51, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1299609311183658, 0.12996093111836596, 0.27943693052960805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8364835], dtype=float32), 0.12960687]. 
=============================================
[2019-03-24 08:43:08,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5032697e-07 3.7194166e-06 4.8097110e-07 9.9999416e-01 1.5225405e-06], sum to 1.0000
[2019-03-24 08:43:08,213] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-24 08:43:08,216] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 40.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394251.8835190024, 394251.8835190028, 150263.6759785506], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [26.03333333333333, 41.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391954.3853854141, 391954.3853854145, 149896.67797256], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.41, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13998370906621932, 0.13998370906621949, 0.28826284225492305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7090211], dtype=float32), -0.45798683]. 
=============================================
[2019-03-24 08:43:14,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9732338e-08 7.0899453e-08 1.1216201e-06 9.9999869e-01 1.1363521e-08], sum to 1.0000
[2019-03-24 08:43:14,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7275
[2019-03-24 08:43:14,500] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.36666666666667, 52.66666666666667, 1.0, 2.0, 0.4677787534311508, 1.0, 2.0, 0.4677787534311508, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1150801.785953728, 1150801.785953728, 228859.3997586971], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 998400.0000, 
sim time next is 999000.0000, 
raw observation next is [25.4, 52.5, 1.0, 2.0, 0.4865563013224787, 1.0, 2.0, 0.4865563013224787, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1195204.535127862, 1195204.535127863, 234607.6004215704], 
processed observation next is [1.0, 0.5652173913043478, 0.49629629629629624, 0.525, 1.0, 1.0, 0.38875750157437944, 1.0, 1.0, 0.38875750157437944, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42685876254566496, 0.4268587625456654, 0.45116846234917385], 
reward next is 0.5488, 
noisyNet noise sample is [array([-0.44561514], dtype=float32), -0.32078335]. 
=============================================
[2019-03-24 08:43:14,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[55.003685]
 [54.9926  ]
 [55.173397]
 [55.14151 ]
 [55.29179 ]], R is [[55.29517365]
 [55.30210876]
 [55.34692764]
 [55.40260315]
 [55.47126007]].
[2019-03-24 08:43:16,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2387161e-06 2.8294593e-05 6.3090015e-06 9.9996328e-01 9.5250130e-07], sum to 1.0000
[2019-03-24 08:43:16,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3431
[2019-03-24 08:43:16,788] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.3, 51.33333333333334, 1.0, 2.0, 0.1655826853928194, 1.0, 2.0, 0.1655826853928194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417255.7022387956, 417255.702238796, 152960.2073018737], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 942000.0000, 
sim time next is 942600.0000, 
raw observation next is [24.2, 51.16666666666666, 1.0, 2.0, 0.1632989574207985, 1.0, 2.0, 0.1632989574207985, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 412058.7820993791, 412058.7820993796, 152507.5715682474], 
processed observation next is [0.0, 0.9130434782608695, 0.45185185185185184, 0.5116666666666666, 1.0, 1.0, 0.003927330262855355, 1.0, 1.0, 0.003927330262855355, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14716385074977825, 0.14716385074977842, 0.29328379147739886], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.94502306], dtype=float32), 0.68975997]. 
=============================================
[2019-03-24 08:43:18,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9427270e-06 1.9322903e-05 3.8668606e-04 9.9949265e-01 9.1334005e-05], sum to 1.0000
[2019-03-24 08:43:18,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9784
[2019-03-24 08:43:18,327] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.33333333333334, 73.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 355351.2188606182, 355351.2188606187, 143943.6233095051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [19.4, 72.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365379.4659833656, 365379.4659833656, 145410.284828441], 
processed observation next is [1.0, 0.2608695652173913, 0.274074074074074, 0.725, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13049266642263058, 0.13049266642263058, 0.27963516313161735], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5740949], dtype=float32), 0.54293025]. 
=============================================
[2019-03-24 08:43:18,431] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 08:43:18,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:43:18,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:43:18,437] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:18,439] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:43:18,439] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:18,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:43:18,441] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:18,446] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:18,442] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:43:18,452] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:18,469] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-24 08:43:18,499] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-24 08:43:18,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-24 08:43:18,572] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-24 08:43:18,572] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-24 08:43:23,415] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01037206], dtype=float32), 0.009289406]
[2019-03-24 08:43:23,416] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.266998205, 46.19351907, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 349549.945009356, 349549.9450093564, 137580.4250312089]
[2019-03-24 08:43:23,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:43:23,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.4573200e-06 1.2368215e-05 4.0276347e-05 9.9992943e-01 1.0533149e-05], sampled 0.935697737116838
[2019-03-24 08:43:24,586] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01037206], dtype=float32), 0.009289406]
[2019-03-24 08:43:24,586] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.59193163, 64.96246699, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 342296.5387006018, 342296.5387006023, 142342.1316829475]
[2019-03-24 08:43:24,587] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:43:24,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9994078e-06 8.3828518e-06 2.7277458e-05 9.9995136e-01 7.9328192e-06], sampled 0.9487602359497431
[2019-03-24 08:43:48,571] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01037206], dtype=float32), 0.009289406]
[2019-03-24 08:43:48,572] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [37.15129397166667, 34.99313366166667, 1.0, 2.0, 0.5222652940896697, 1.0, 2.0, 0.5222652940896697, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1190774.478479407, 1190774.478479407, 242354.4668340122]
[2019-03-24 08:43:48,574] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:43:48,578] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9946566e-07 1.2687508e-06 4.9579940e-06 9.9999201e-01 1.1215805e-06], sampled 0.2787014726491053
[2019-03-24 08:44:26,760] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01037206], dtype=float32), 0.009289406]
[2019-03-24 08:44:26,760] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.26666666666667, 77.5, 1.0, 2.0, 0.3767212428160145, 1.0, 2.0, 0.3767212428160145, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 858745.41481327, 858745.4148132704, 199892.5828309801]
[2019-03-24 08:44:26,761] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:44:26,765] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0850694e-06 1.8718517e-06 7.7144741e-06 9.9998760e-01 1.6140925e-06], sampled 0.8052256051640959
[2019-03-24 08:44:52,273] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01037206], dtype=float32), 0.009289406]
[2019-03-24 08:44:52,274] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.0, 91.0, 1.0, 2.0, 0.2082753134157799, 1.0, 2.0, 0.2082753134157799, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507117.3699233218, 507117.3699233223, 161399.2118130584]
[2019-03-24 08:44:52,274] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:44:52,279] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9435924e-07 1.2711595e-06 4.8577817e-06 9.9999189e-01 1.2396780e-06], sampled 0.9751691759328281
[2019-03-24 08:45:00,882] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:45:00,927] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3230 2465955643.7427 46.0000
[2019-03-24 08:45:01,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:45:01,227] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.7302 2438857767.4262 34.0000
[2019-03-24 08:45:01,245] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8520 2410741034.0995 22.0000
[2019-03-24 08:45:02,264] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1725000, evaluation results [1725000.0, 7523.727130323888, 2668527814.010175, 68.0, 7120.730175598853, 2438857767.426182, 34.0, 7796.852034869625, 2410741034.0994663, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.322995391473, 2465955643.742655, 46.0]
[2019-03-24 08:45:07,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7059088e-06 1.2077204e-06 6.4454893e-05 9.9992347e-01 2.1000658e-06], sum to 1.0000
[2019-03-24 08:45:07,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7941
[2019-03-24 08:45:07,689] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 74.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 358066.6381955377, 358066.6381955373, 144346.3887612153], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1126200.0000, 
sim time next is 1126800.0000, 
raw observation next is [19.2, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 356301.6846647687, 356301.6846647692, 144075.2470882389], 
processed observation next is [1.0, 0.043478260869565216, 0.26666666666666666, 0.74, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1272506016659888, 0.127250601665989, 0.27706778286199785], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34464654], dtype=float32), -0.71229976]. 
=============================================
[2019-03-24 08:45:08,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9359673e-05 4.8926522e-06 1.9866935e-05 9.9990034e-01 5.5578465e-05], sum to 1.0000
[2019-03-24 08:45:08,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6245
[2019-03-24 08:45:08,467] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.23333333333333, 87.33333333333334, 1.0, 2.0, 0.1715533347388122, 1.0, 2.0, 0.1715533347388122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 430791.3083508844, 430791.3083508848, 154148.9624596754], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1305600.0000, 
sim time next is 1306200.0000, 
raw observation next is [19.16666666666667, 87.66666666666667, 1.0, 2.0, 0.1697313077836917, 1.0, 2.0, 0.1697313077836917, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426416.4743057938, 426416.4743057942, 153780.3676626415], 
processed observation next is [1.0, 0.08695652173913043, 0.2654320987654323, 0.8766666666666667, 1.0, 1.0, 0.011584890218680583, 1.0, 1.0, 0.011584890218680583, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15229159796635494, 0.15229159796635508, 0.2957314762743106], 
reward next is 0.7043, 
noisyNet noise sample is [array([-0.69962233], dtype=float32), -0.05333021]. 
=============================================
[2019-03-24 08:45:10,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7444713e-07 1.1571069e-05 1.1681033e-05 9.9996746e-01 9.0857193e-06], sum to 1.0000
[2019-03-24 08:45:10,469] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8017
[2019-03-24 08:45:10,474] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.8, 94.0, 1.0, 2.0, 0.1754570491876355, 1.0, 2.0, 0.1754570491876355, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438816.0934933131, 438816.0934933131, 154912.7272910648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1206000.0000, 
sim time next is 1206600.0000, 
raw observation next is [18.76666666666667, 94.00000000000001, 1.0, 2.0, 0.1751137335141768, 1.0, 2.0, 0.1751137335141768, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 438084.3710822266, 438084.3710822271, 154844.9210957332], 
processed observation next is [1.0, 1.0, 0.2506172839506174, 0.9400000000000002, 1.0, 1.0, 0.017992539897829528, 1.0, 1.0, 0.017992539897829528, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15645870395793807, 0.15645870395793826, 0.29777869441487154], 
reward next is 0.7022, 
noisyNet noise sample is [array([-0.8166565], dtype=float32), -0.83023506]. 
=============================================
[2019-03-24 08:45:12,800] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2777932e-10 6.5744615e-10 1.4183939e-08 1.0000000e+00 7.5541120e-09], sum to 1.0000
[2019-03-24 08:45:12,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6744
[2019-03-24 08:45:12,812] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.03333333333333, 93.0, 1.0, 2.0, 0.1610422547590967, 1.0, 2.0, 0.1610422547590967, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 407124.4579192352, 407124.4579192356, 152064.568991152], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1219200.0000, 
sim time next is 1219800.0000, 
raw observation next is [18.01666666666667, 93.0, 1.0, 2.0, 0.1603273415452707, 1.0, 2.0, 0.1603273415452707, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 405412.9230549553, 405412.9230549557, 151922.2073993908], 
processed observation next is [1.0, 0.08695652173913043, 0.2228395061728396, 0.93, 1.0, 1.0, 0.00038969231579845056, 1.0, 1.0, 0.00038969231579845056, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14479032966248404, 0.14479032966248417, 0.29215809115267466], 
reward next is 0.7078, 
noisyNet noise sample is [array([1.3192617], dtype=float32), -0.668138]. 
=============================================
[2019-03-24 08:45:14,771] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8862733e-08 2.9968447e-08 3.1384823e-07 9.9999940e-01 2.0529934e-07], sum to 1.0000
[2019-03-24 08:45:14,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7775
[2019-03-24 08:45:14,784] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.5, 69.0, 1.0, 2.0, 0.2840540251714982, 1.0, 2.0, 0.2840540251714982, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703627.5552627159, 703627.5552627159, 178872.6232866787], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1248600.0000, 
sim time next is 1249200.0000, 
raw observation next is [22.7, 68.0, 1.0, 2.0, 0.3129671165862316, 1.0, 2.0, 0.3129671165862316, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774445.343900816, 774445.343900816, 185955.5856612778], 
processed observation next is [1.0, 0.4782608695652174, 0.39629629629629626, 0.68, 1.0, 1.0, 0.1821037102217043, 1.0, 1.0, 0.1821037102217043, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27658762282172, 0.27658762282172, 0.3576068955024573], 
reward next is 0.6424, 
noisyNet noise sample is [array([2.3909745], dtype=float32), 0.33487365]. 
=============================================
[2019-03-24 08:45:17,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.23073844e-08 5.55154611e-06 1.31521620e-05 9.99980569e-01
 7.29464546e-07], sum to 1.0000
[2019-03-24 08:45:17,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6387
[2019-03-24 08:45:17,663] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.85, 31.0, 1.0, 2.0, 0.5038865330488532, 1.0, 2.0, 0.5038865330488532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1233904.285710089, 1233904.28571009, 239958.6072573215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1351800.0000, 
sim time next is 1352400.0000, 
raw observation next is [30.86666666666667, 30.66666666666667, 1.0, 2.0, 0.4956042696994848, 1.0, 2.0, 0.4956042696994848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1215025.886357903, 1215025.886357903, 237378.0276557717], 
processed observation next is [1.0, 0.6521739130434783, 0.6987654320987656, 0.3066666666666667, 1.0, 1.0, 0.3995288924993866, 1.0, 1.0, 0.3995288924993866, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4339378165563939, 0.4339378165563939, 0.45649620703033017], 
reward next is 0.5435, 
noisyNet noise sample is [array([-0.41018277], dtype=float32), -0.5617756]. 
=============================================
[2019-03-24 08:45:18,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5852860e-06 5.5545283e-06 7.8751947e-07 9.9998653e-01 4.2576616e-07], sum to 1.0000
[2019-03-24 08:45:18,524] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3851
[2019-03-24 08:45:18,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666666, 57.83333333333333, 1.0, 2.0, 0.2051539672914591, 1.0, 2.0, 0.2051539672914591, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 501690.273198464, 501690.2731984644, 160810.2000404086], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1275000.0000, 
sim time next is 1275600.0000, 
raw observation next is [25.53333333333333, 58.66666666666667, 1.0, 2.0, 0.2062660233666603, 1.0, 2.0, 0.2062660233666603, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504242.0487796246, 504242.0487796246, 161040.5202594544], 
processed observation next is [1.0, 0.782608695652174, 0.5012345679012346, 0.5866666666666667, 1.0, 1.0, 0.05507859924602417, 1.0, 1.0, 0.05507859924602417, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18008644599272305, 0.18008644599272305, 0.30969330819125845], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.4403613], dtype=float32), 0.025212744]. 
=============================================
[2019-03-24 08:45:24,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7592430e-07 6.0604193e-09 2.5418910e-07 9.9999905e-01 3.5719374e-08], sum to 1.0000
[2019-03-24 08:45:24,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-24 08:45:24,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.73333333333333, 59.66666666666667, 1.0, 2.0, 0.164241601370367, 1.0, 2.0, 0.164241601370367, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 414566.9071984936, 414566.9071984941, 152700.2910892147], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1477200.0000, 
sim time next is 1477800.0000, 
raw observation next is [22.65, 60.5, 1.0, 2.0, 0.1648717109161475, 1.0, 2.0, 0.1648717109161475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415917.5257062832, 415917.5257062832, 152823.9293857126], 
processed observation next is [0.0, 0.08695652173913043, 0.3944444444444444, 0.605, 1.0, 1.0, 0.005799655852556539, 1.0, 1.0, 0.005799655852556539, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14854197346652973, 0.14854197346652973, 0.2938921718956012], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.3835712], dtype=float32), 0.978482]. 
=============================================
[2019-03-24 08:45:27,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9613415e-08 4.4874762e-09 3.7380588e-09 9.9999988e-01 1.4713258e-07], sum to 1.0000
[2019-03-24 08:45:27,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7750
[2019-03-24 08:45:27,449] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 58.0, 1.0, 2.0, 0.2646689767405009, 1.0, 2.0, 0.2646689767405009, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621257.1205871544, 621257.1205871549, 173067.7438595639], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1535400.0000, 
sim time next is 1536000.0000, 
raw observation next is [27.7, 60.0, 1.0, 2.0, 0.2629391848771544, 1.0, 2.0, 0.2629391848771544, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618357.1735305368, 618357.1735305373, 172721.2677282809], 
processed observation next is [0.0, 0.782608695652174, 0.5814814814814815, 0.6, 1.0, 1.0, 0.12254664866327905, 1.0, 1.0, 0.12254664866327905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22084184768947743, 0.2208418476894776, 0.33215628409284786], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.5308414], dtype=float32), 2.0615652]. 
=============================================
[2019-03-24 08:45:27,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.596985]
 [65.570915]
 [65.56801 ]
 [65.65145 ]
 [65.655556]], R is [[65.58192444]
 [65.59328461]
 [65.60316467]
 [65.60858917]
 [65.61803436]].
[2019-03-24 08:45:27,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.02690777e-07 1.21140795e-08 2.03961449e-07 9.99999642e-01
 6.76181910e-09], sum to 1.0000
[2019-03-24 08:45:27,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-24 08:45:27,771] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 43.0, 1.0, 2.0, 0.1758696211803187, 1.0, 2.0, 0.1758696211803187, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436970.8759432123, 436970.8759432123, 154924.8234483199], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1618800.0000, 
sim time next is 1619400.0000, 
raw observation next is [27.33333333333334, 43.5, 1.0, 2.0, 0.177482535198608, 1.0, 2.0, 0.177482535198608, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441047.7223191002, 441047.7223191007, 155259.2868048099], 
processed observation next is [1.0, 0.7391304347826086, 0.5679012345679014, 0.435, 1.0, 1.0, 0.020812541903104744, 1.0, 1.0, 0.020812541903104744, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15751704368539293, 0.1575170436853931, 0.29857555154771137], 
reward next is 0.7014, 
noisyNet noise sample is [array([-0.38036034], dtype=float32), -0.15208499]. 
=============================================
[2019-03-24 08:45:28,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5119234e-09 4.0906567e-09 4.9825252e-07 9.9999952e-01 4.5361148e-08], sum to 1.0000
[2019-03-24 08:45:28,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4051
[2019-03-24 08:45:28,892] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.3, 31.0, 1.0, 2.0, 0.2228053590347301, 1.0, 2.0, 0.2228053590347301, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537319.9326424918, 537319.9326424918, 164343.2696630411], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1508400.0000, 
sim time next is 1509000.0000, 
raw observation next is [33.43333333333334, 30.33333333333334, 1.0, 2.0, 0.2306274598108948, 1.0, 2.0, 0.2306274598108948, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556510.1595157163, 556510.1595157163, 166066.0138740347], 
processed observation next is [0.0, 0.4782608695652174, 0.7938271604938273, 0.3033333333333334, 1.0, 1.0, 0.08408030929868429, 1.0, 1.0, 0.08408030929868429, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19875362839847008, 0.19875362839847008, 0.31935771898852827], 
reward next is 0.6806, 
noisyNet noise sample is [array([-1.121952], dtype=float32), -0.45335445]. 
=============================================
[2019-03-24 08:45:28,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.738754]
 [68.731766]
 [68.73474 ]
 [68.734116]
 [68.72758 ]], R is [[68.68437958]
 [68.68148804]
 [68.67877197]
 [68.67609406]
 [68.67313385]].
[2019-03-24 08:45:37,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2439804e-07 5.4775011e-08 2.5107538e-05 9.9997330e-01 1.4125314e-06], sum to 1.0000
[2019-03-24 08:45:37,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8095
[2019-03-24 08:45:37,575] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.11666666666667, 63.5, 1.0, 2.0, 0.161416993792377, 1.0, 2.0, 0.161416993792377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 407315.9104618744, 407315.9104618749, 152128.1970431908], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1645800.0000, 
sim time next is 1646400.0000, 
raw observation next is [22.03333333333333, 64.0, 1.0, 2.0, 0.161829112204638, 1.0, 2.0, 0.161829112204638, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408365.3295990556, 408365.3295990556, 152211.3399042892], 
processed observation next is [1.0, 0.043478260869565216, 0.37160493827160485, 0.64, 1.0, 1.0, 0.0021775145293309464, 1.0, 1.0, 0.0021775145293309464, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14584476057109128, 0.14584476057109128, 0.2927141152005561], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.85862404], dtype=float32), -0.47833422]. 
=============================================
[2019-03-24 08:45:40,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3364535e-07 3.7853366e-07 3.2908125e-07 9.9999881e-01 9.5847774e-08], sum to 1.0000
[2019-03-24 08:45:40,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8149
[2019-03-24 08:45:40,490] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.3208034528526996, 1.0, 2.0, 0.3208034528526996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 784945.8212353423, 784945.8212353428, 187694.2138694013], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1854000.0000, 
sim time next is 1854600.0000, 
raw observation next is [21.98333333333333, 78.33333333333333, 1.0, 2.0, 0.3456101660312645, 1.0, 2.0, 0.3456101660312645, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 845256.7037931122, 845256.7037931127, 194065.1195020993], 
processed observation next is [1.0, 0.4782608695652174, 0.36975308641975296, 0.7833333333333333, 1.0, 1.0, 0.22096448337055297, 1.0, 1.0, 0.22096448337055297, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3018773942118258, 0.30187739421182597, 0.3732021528886525], 
reward next is 0.6268, 
noisyNet noise sample is [array([0.33548895], dtype=float32), 0.10822879]. 
=============================================
[2019-03-24 08:45:40,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5507601e-07 6.2769141e-07 1.7839133e-07 9.9999750e-01 1.1239358e-06], sum to 1.0000
[2019-03-24 08:45:40,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4075
[2019-03-24 08:45:40,600] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.68333333333333, 86.16666666666667, 1.0, 2.0, 0.4836068683577978, 1.0, 2.0, 0.4836068683577978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1165247.378992676, 1165247.378992676, 232991.5920696673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1869000.0000, 
sim time next is 1869600.0000, 
raw observation next is [21.66666666666667, 86.33333333333334, 1.0, 2.0, 0.4505231292510062, 1.0, 2.0, 0.4505231292510062, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1084633.57789408, 1084633.577894079, 222920.9090888433], 
processed observation next is [1.0, 0.6521739130434783, 0.3580246913580249, 0.8633333333333334, 1.0, 1.0, 0.3458608681559598, 1.0, 1.0, 0.3458608681559598, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.3873691349621714, 0.38736913496217107, 0.42869405594008325], 
reward next is 0.5713, 
noisyNet noise sample is [array([-2.9450634], dtype=float32), 0.6589113]. 
=============================================
[2019-03-24 08:45:45,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7087289e-07 3.5925868e-06 4.1765111e-07 9.9999452e-01 1.0978538e-06], sum to 1.0000
[2019-03-24 08:45:45,337] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2645
[2019-03-24 08:45:45,343] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 71.0, 1.0, 2.0, 0.2910756614661515, 1.0, 2.0, 0.2910756614661515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666285.0123415362, 666285.0123415367, 178476.6113206616], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1969200.0000, 
sim time next is 1969800.0000, 
raw observation next is [27.05, 72.33333333333334, 1.0, 2.0, 0.2932347499234399, 1.0, 2.0, 0.2932347499234399, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 670326.4210376343, 670326.4210376347, 178944.6435201408], 
processed observation next is [1.0, 0.8260869565217391, 0.5574074074074075, 0.7233333333333334, 1.0, 1.0, 0.15861279752790464, 1.0, 1.0, 0.15861279752790464, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23940229322772652, 0.2394022932277267, 0.3441243144618092], 
reward next is 0.6559, 
noisyNet noise sample is [array([-0.70622724], dtype=float32), -0.55833155]. 
=============================================
[2019-03-24 08:45:48,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5148577e-08 4.0537083e-07 1.0423267e-06 9.9999845e-01 1.0297172e-07], sum to 1.0000
[2019-03-24 08:45:48,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8418
[2019-03-24 08:45:48,612] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.46666666666667, 63.0, 1.0, 2.0, 0.2857745056663004, 1.0, 2.0, 0.2857745056663004, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 656329.5663150832, 656329.5663150836, 177332.0415672844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2041800.0000, 
sim time next is 2042400.0000, 
raw observation next is [28.53333333333333, 63.00000000000001, 1.0, 2.0, 0.2879469151257465, 1.0, 2.0, 0.2879469151257465, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660437.3479950965, 660437.3479950969, 177801.4102402438], 
processed observation next is [0.0, 0.6521739130434783, 0.6123456790123456, 0.6300000000000001, 1.0, 1.0, 0.15231775610207915, 1.0, 1.0, 0.15231775610207915, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23587048142682016, 0.23587048142682032, 0.34192578892354575], 
reward next is 0.6581, 
noisyNet noise sample is [array([-1.4792204], dtype=float32), -1.4514868]. 
=============================================
[2019-03-24 08:45:49,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5903153e-06 2.2720305e-06 1.3900172e-06 9.9999070e-01 1.1033127e-06], sum to 1.0000
[2019-03-24 08:45:49,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8577
[2019-03-24 08:45:49,523] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.2, 91.0, 1.0, 2.0, 0.1961918502995944, 1.0, 2.0, 0.1961918502995944, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 483415.7507173033, 483415.7507173038, 159040.5729941595], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1926000.0000, 
sim time next is 1926600.0000, 
raw observation next is [20.25, 90.83333333333334, 1.0, 2.0, 0.2190543957093246, 1.0, 2.0, 0.2190543957093246, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539390.7833547582, 539390.7833547586, 163902.3862826866], 
processed observation next is [1.0, 0.30434782608695654, 0.3055555555555556, 0.9083333333333334, 1.0, 1.0, 0.07030285203491025, 1.0, 1.0, 0.07030285203491025, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1926395654838422, 0.19263956548384237, 0.31519689669747425], 
reward next is 0.6848, 
noisyNet noise sample is [array([-0.7226329], dtype=float32), -1.552658]. 
=============================================
[2019-03-24 08:45:49,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3833917e-06 1.3414381e-06 5.0829277e-07 9.9999642e-01 3.1718182e-07], sum to 1.0000
[2019-03-24 08:45:49,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4444
[2019-03-24 08:45:49,633] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.1832377775910615, 1.0, 2.0, 0.1832377775910615, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456069.269835466, 456069.2698354665, 156473.2049320543], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1989000.0000, 
sim time next is 1989600.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.182812219205062, 1.0, 2.0, 0.182812219205062, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455014.7011625297, 455014.7011625302, 156384.5215651548], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 1.0, 1.0, 0.02715740381554999, 1.0, 1.0, 0.02715740381554999, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16250525041518918, 0.16250525041518937, 0.30073946454837464], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.6791025], dtype=float32), -0.093450844]. 
=============================================
[2019-03-24 08:45:51,092] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:45:51,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:45:51,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:45:51,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:51,096] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:45:51,097] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:51,098] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:51,100] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:45:51,101] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:51,103] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:45:51,103] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:51,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-24 08:45:51,158] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-24 08:45:51,158] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-24 08:45:51,217] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-24 08:45:51,257] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-24 08:46:04,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:04,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.88965069333333, 65.75382913833333, 1.0, 2.0, 0.1624825535576122, 1.0, 2.0, 0.1624825535576122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 409124.090780691, 409124.0907806914, 152327.590839626]
[2019-03-24 08:46:04,026] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:46:04,028] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9368021e-08 1.3429002e-07 5.2933524e-07 9.9999917e-01 1.7209207e-07], sampled 0.6539222506494522
[2019-03-24 08:46:08,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:08,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.74640014666667, 4.038026852666666, 1.0, 2.0, 0.1837827637326471, 1.0, 2.0, 0.1837827637326471, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 474174.7897416877, 474174.7897416882, 138887.738890327]
[2019-03-24 08:46:08,539] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:46:08,544] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4518179e-07 2.6666015e-07 1.0131365e-06 9.9999821e-01 3.0544876e-07], sampled 0.6531901742997035
[2019-03-24 08:46:17,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:17,352] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.04153935833333, 85.52138013166666, 1.0, 2.0, 0.2079174690204792, 1.0, 2.0, 0.2079174690204792, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509523.0531109695, 509523.05311097, 161431.4643813528]
[2019-03-24 08:46:17,353] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:46:17,355] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3763059e-08 8.4849766e-08 3.5564818e-07 9.9999940e-01 1.0206218e-07], sampled 0.22624353148949716
[2019-03-24 08:46:25,372] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:25,373] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333334, 69.83333333333333, 1.0, 2.0, 0.2510141822148165, 1.0, 2.0, 0.2510141822148165, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595746.3759749496, 595746.3759749496, 170240.3623199768]
[2019-03-24 08:46:25,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:46:25,379] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.1445292e-08 1.1709968e-07 4.8193766e-07 9.9999917e-01 1.3764019e-07], sampled 0.9662324553983946
[2019-03-24 08:46:25,486] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:25,488] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.33333333333334, 98.0, 1.0, 2.0, 0.2728000135392988, 1.0, 2.0, 0.2728000135392988, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 637912.5164393183, 637912.5164393188, 174842.6015367736]
[2019-03-24 08:46:25,489] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:46:25,493] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.04643438e-08 9.67396971e-08 4.03565195e-07 9.99999285e-01
 1.13042795e-07], sampled 0.8568567166863086
[2019-03-24 08:46:42,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:46:42,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.49472492, 93.95240993, 1.0, 2.0, 0.2227378367464894, 1.0, 2.0, 0.2227378367464894, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 536541.8898893327, 536541.8898893332, 164305.5205851463]
[2019-03-24 08:46:42,499] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:46:42,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.88076211e-08 9.55964126e-08 3.90122807e-07 9.99999285e-01
 1.16527985e-07], sampled 0.07800559290569353
[2019-03-24 08:47:31,828] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01048794], dtype=float32), 0.009466158]
[2019-03-24 08:47:31,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.0, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 335304.0101204352, 335304.0101204347, 140910.0383700688]
[2019-03-24 08:47:31,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:47:31,831] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0025542e-07 1.9138325e-07 7.2434642e-07 9.9999869e-01 2.4438501e-07], sampled 0.8508306178343287
[2019-03-24 08:47:34,092] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:47:34,113] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:47:34,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454110.0746 47.0000
[2019-03-24 08:47:34,522] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0693 2668508174.5232 68.0000
[2019-03-24 08:47:34,571] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873956.1460 34.0000
[2019-03-24 08:47:35,585] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1750000, evaluation results [1750000.0, 7523.069316394719, 2668508174.523248, 68.0, 7121.435945869477, 2438873956.145978, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495454110.074621, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:47:36,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6709654e-09 5.5475859e-09 1.1461292e-08 1.0000000e+00 2.5241178e-08], sum to 1.0000
[2019-03-24 08:47:36,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6471
[2019-03-24 08:47:36,216] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.51666666666667, 80.33333333333334, 1.0, 2.0, 0.2373586185969601, 1.0, 2.0, 0.2373586185969601, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 566885.820670646, 566885.8206706464, 167330.5791494763], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2074200.0000, 
sim time next is 2074800.0000, 
raw observation next is [23.43333333333334, 80.66666666666667, 1.0, 2.0, 0.2362982646722037, 1.0, 2.0, 0.2362982646722037, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 564721.6582020267, 564721.6582020272, 167110.3288273362], 
processed observation next is [0.0, 0.0, 0.42345679012345705, 0.8066666666666668, 1.0, 1.0, 0.09083126746690916, 1.0, 1.0, 0.09083126746690916, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20168630650072383, 0.201686306500724, 0.32136601697564654], 
reward next is 0.6786, 
noisyNet noise sample is [array([-1.1735344], dtype=float32), -0.25814563]. 
=============================================
[2019-03-24 08:47:37,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1376010e-07 7.5417994e-08 8.7035397e-07 9.9999893e-01 2.7001201e-08], sum to 1.0000
[2019-03-24 08:47:37,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-24 08:47:37,987] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.85, 79.5, 1.0, 2.0, 0.2639055458113272, 1.0, 2.0, 0.2639055458113272, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616866.1303252892, 616866.1303252892, 172775.5830103471], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2107800.0000, 
sim time next is 2108400.0000, 
raw observation next is [25.1, 78.66666666666666, 1.0, 2.0, 0.2672753269052185, 1.0, 2.0, 0.2672753269052185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 623145.9660635698, 623145.9660635702, 173478.1702889367], 
processed observation next is [0.0, 0.391304347826087, 0.4851851851851852, 0.7866666666666666, 1.0, 1.0, 0.12770872250621249, 1.0, 1.0, 0.12770872250621249, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2225521307369892, 0.22255213073698937, 0.3336118659402629], 
reward next is 0.6664, 
noisyNet noise sample is [array([0.17453079], dtype=float32), 0.62482655]. 
=============================================
[2019-03-24 08:47:38,313] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0499360e-08 1.8790301e-07 4.6649208e-07 9.9999917e-01 9.1755304e-08], sum to 1.0000
[2019-03-24 08:47:38,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5725
[2019-03-24 08:47:38,330] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 84.0, 1.0, 2.0, 0.5145943823374858, 1.0, 2.0, 0.5145943823374858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1196059.943152403, 1196059.943152403, 241003.6632348981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2289600.0000, 
sim time next is 2290200.0000, 
raw observation next is [24.11666666666667, 83.5, 1.0, 2.0, 0.6432010768023216, 1.0, 2.0, 0.6432010768023216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1489473.822428133, 1489473.822428133, 284335.912325279], 
processed observation next is [1.0, 0.5217391304347826, 0.44876543209876557, 0.835, 1.0, 1.0, 0.575239377145621, 1.0, 1.0, 0.575239377145621, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5319549365814761, 0.5319549365814761, 0.5467998313947673], 
reward next is 0.4532, 
noisyNet noise sample is [array([-0.8624659], dtype=float32), 2.2429202]. 
=============================================
[2019-03-24 08:47:41,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4545091e-06 8.3629521e-07 9.3321150e-06 9.9998617e-01 2.2995630e-06], sum to 1.0000
[2019-03-24 08:47:41,627] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7701
[2019-03-24 08:47:41,632] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.65, 64.0, 1.0, 2.0, 0.2676869694548185, 1.0, 2.0, 0.2676869694548185, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622437.653258887, 622437.6532588865, 173495.7652412886], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [27.8, 63.66666666666667, 1.0, 2.0, 0.2699570380557748, 1.0, 2.0, 0.2699570380557748, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626644.3342059597, 626644.3342059602, 173969.5692438064], 
processed observation next is [0.0, 0.5652173913043478, 0.5851851851851853, 0.6366666666666667, 1.0, 1.0, 0.1309012357806843, 1.0, 1.0, 0.1309012357806843, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2238015479306999, 0.22380154793070006, 0.33455686393039696], 
reward next is 0.6654, 
noisyNet noise sample is [array([0.0359581], dtype=float32), 0.44531834]. 
=============================================
[2019-03-24 08:47:45,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3856631e-06 1.7615687e-06 1.5671310e-05 9.9997890e-01 2.6743530e-07], sum to 1.0000
[2019-03-24 08:47:45,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8105
[2019-03-24 08:47:45,380] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5634136878878497, 1.0, 2.0, 0.5634136878878497, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1284672.241938358, 1284672.241938358, 255690.0795536792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2198400.0000, 
sim time next is 2199000.0000, 
raw observation next is [24.31666666666667, 92.66666666666666, 1.0, 2.0, 0.5414091760016444, 1.0, 2.0, 0.5414091760016444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1234458.049476094, 1234458.049476094, 248485.3508237929], 
processed observation next is [1.0, 0.43478260869565216, 0.456172839506173, 0.9266666666666665, 1.0, 1.0, 0.45405854285910047, 1.0, 1.0, 0.45405854285910047, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44087787481289076, 0.44087787481289076, 0.4778564438919094], 
reward next is 0.5221, 
noisyNet noise sample is [array([-1.844981], dtype=float32), 0.039315823]. 
=============================================
[2019-03-24 08:47:45,401] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.786385]
 [60.014603]
 [59.94764 ]
 [59.827457]
 [59.799564]], R is [[60.983078  ]
 [60.88153839]
 [60.72343445]
 [60.57987976]
 [60.45272827]].
[2019-03-24 08:47:47,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0838932e-06 4.3847094e-06 1.3698148e-05 9.9997509e-01 5.6629588e-06], sum to 1.0000
[2019-03-24 08:47:47,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6704
[2019-03-24 08:47:47,592] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.86666666666667, 82.0, 1.0, 2.0, 0.2379479282260386, 1.0, 2.0, 0.2379479282260386, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571972.70555177, 571972.7055517705, 167604.8953821795], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2353200.0000, 
sim time next is 2353800.0000, 
raw observation next is [23.18333333333334, 78.5, 1.0, 2.0, 0.2344041717621544, 1.0, 2.0, 0.2344041717621544, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 565036.7862206021, 565036.7862206026, 166878.2042818194], 
processed observation next is [1.0, 0.21739130434782608, 0.4141975308641978, 0.785, 1.0, 1.0, 0.0885763949549457, 1.0, 1.0, 0.0885763949549457, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20179885222164362, 0.2017988522216438, 0.3209196236188835], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.5555766], dtype=float32), -0.058076475]. 
=============================================
[2019-03-24 08:47:48,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3191116e-07 1.2645923e-09 2.0400244e-06 9.9999785e-01 2.7861574e-08], sum to 1.0000
[2019-03-24 08:47:48,848] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1018
[2019-03-24 08:47:48,857] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 27.0, 1.0, 2.0, 0.1936476711733771, 1.0, 2.0, 0.1936476711733771, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 478268.723669301, 478268.7236693014, 158542.6898977712], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2484000.0000, 
sim time next is 2484600.0000, 
raw observation next is [32.4, 27.5, 1.0, 2.0, 0.1933020613742948, 1.0, 2.0, 0.1933020613742948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 477550.9348225124, 477550.9348225128, 158474.6223132711], 
processed observation next is [1.0, 0.782608695652174, 0.7555555555555555, 0.275, 1.0, 1.0, 0.03964531115987474, 1.0, 1.0, 0.03964531115987474, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17055390529375442, 0.17055390529375458, 0.3047588890639829], 
reward next is 0.6952, 
noisyNet noise sample is [array([1.3461777], dtype=float32), -0.9476462]. 
=============================================
[2019-03-24 08:47:49,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7508301e-06 5.3366020e-06 5.9526146e-06 9.9998581e-01 1.0167527e-06], sum to 1.0000
[2019-03-24 08:47:49,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0235
[2019-03-24 08:47:49,670] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.86666666666667, 37.0, 1.0, 2.0, 0.643333011771526, 1.0, 2.0, 0.643333011771526, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1539972.506217428, 1539972.506217428, 286524.9567746653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [30.83333333333333, 37.0, 1.0, 2.0, 0.6623059784164109, 1.0, 2.0, 0.6623059784164109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1583912.777033469, 1583912.77703347, 293456.3168911572], 
processed observation next is [1.0, 0.6521739130434783, 0.6975308641975307, 0.37, 1.0, 1.0, 0.5979833076385844, 1.0, 1.0, 0.5979833076385844, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5656831346548103, 0.5656831346548108, 0.5643390709445331], 
reward next is 0.4357, 
noisyNet noise sample is [array([0.306369], dtype=float32), -0.048885223]. 
=============================================
[2019-03-24 08:47:51,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2098636e-08 2.6509886e-07 8.3695284e-07 9.9999785e-01 9.3835166e-07], sum to 1.0000
[2019-03-24 08:47:51,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3214
[2019-03-24 08:47:51,337] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.40000000000001, 77.33333333333334, 1.0, 2.0, 0.5400960306956444, 1.0, 2.0, 0.5400960306956444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1242982.720894617, 1242982.720894618, 248618.6024392357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [25.45, 76.5, 1.0, 2.0, 0.5345984593583073, 1.0, 2.0, 0.5345984593583073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1232592.503803483, 1232592.503803483, 246947.9378782424], 
processed observation next is [1.0, 0.6086956521739131, 0.4981481481481481, 0.765, 1.0, 1.0, 0.4459505468551277, 1.0, 1.0, 0.4459505468551277, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4402116085012439, 0.4402116085012439, 0.47489988053508153], 
reward next is 0.5251, 
noisyNet noise sample is [array([-0.81516314], dtype=float32), 0.14049017]. 
=============================================
[2019-03-24 08:48:04,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1794146e-09 3.0388713e-07 2.1568417e-07 9.9999940e-01 1.2192613e-08], sum to 1.0000
[2019-03-24 08:48:04,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-24 08:48:04,119] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.08333333333334, 93.16666666666667, 1.0, 2.0, 0.3349821566370449, 1.0, 2.0, 0.3349821566370449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 763552.7411240079, 763552.7411240083, 189067.5558006861], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2764200.0000, 
sim time next is 2764800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3356562586298962, 1.0, 2.0, 0.3356562586298962, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765090.0448046664, 765090.0448046669, 189237.5813236369], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20911459360701926, 1.0, 1.0, 0.20911459360701926, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27324644457309516, 0.2732464445730953, 0.36391842562237864], 
reward next is 0.6361, 
noisyNet noise sample is [array([0.26221654], dtype=float32), -0.60208046]. 
=============================================
[2019-03-24 08:48:04,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2914595e-08 2.4779256e-06 2.7873104e-05 9.9996936e-01 2.2120247e-07], sum to 1.0000
[2019-03-24 08:48:04,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-24 08:48:04,741] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 43.5, 1.0, 2.0, 0.1885116225906009, 1.0, 2.0, 0.1885116225906009, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467086.0185037109, 467086.0185037113, 157519.9901226302], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2500200.0000, 
sim time next is 2500800.0000, 
raw observation next is [27.43333333333334, 44.33333333333333, 1.0, 2.0, 0.1881708185880692, 1.0, 2.0, 0.1881708185880692, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466101.4700213551, 466101.4700213551, 157445.6047226014], 
processed observation next is [1.0, 0.9565217391304348, 0.5716049382716052, 0.4433333333333333, 1.0, 1.0, 0.033536688795320464, 1.0, 1.0, 0.033536688795320464, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16646481072191252, 0.16646481072191252, 0.30278000908192576], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.25025883], dtype=float32), 0.71807176]. 
=============================================
[2019-03-24 08:48:06,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9483005e-08 4.7342191e-08 1.3212458e-07 9.9999988e-01 4.6884530e-08], sum to 1.0000
[2019-03-24 08:48:06,440] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-24 08:48:06,445] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.03333333333333, 24.0, 1.0, 2.0, 0.6848982516907883, 1.0, 2.0, 0.6848982516907883, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1654674.839258347, 1654674.839258348, 302558.1932901791], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2479200.0000, 
sim time next is 2479800.0000, 
raw observation next is [33.96666666666667, 24.0, 1.0, 2.0, 0.6762170015945554, 1.0, 2.0, 0.6762170015945554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1635326.02608297, 1635326.026082971, 299323.8719308186], 
processed observation next is [1.0, 0.6956521739130435, 0.8135802469135803, 0.24, 1.0, 1.0, 0.6145440495173279, 1.0, 1.0, 0.6145440495173279, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5840450093153464, 0.5840450093153468, 0.5756228306361896], 
reward next is 0.4244, 
noisyNet noise sample is [array([-0.372086], dtype=float32), 1.0271952]. 
=============================================
[2019-03-24 08:48:10,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0813149e-07 4.9974393e-08 2.4052022e-06 9.9999726e-01 2.5398896e-07], sum to 1.0000
[2019-03-24 08:48:10,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9066
[2019-03-24 08:48:10,033] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.23333333333333, 33.83333333333334, 1.0, 2.0, 0.7550886041498865, 1.0, 2.0, 0.7550886041498865, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1766218.63896597, 1766218.63896597, 327737.0366460191], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2566200.0000, 
sim time next is 2566800.0000, 
raw observation next is [33.2, 34.0, 1.0, 2.0, 0.754368604549465, 1.0, 2.0, 0.754368604549465, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1763856.034165013, 1763856.034165012, 327416.6611225324], 
processed observation next is [1.0, 0.7391304347826086, 0.7851851851851853, 0.34, 1.0, 1.0, 0.7075816720826964, 1.0, 1.0, 0.7075816720826964, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6299485836303619, 0.6299485836303614, 0.6296474252356392], 
reward next is 0.3704, 
noisyNet noise sample is [array([-0.30036497], dtype=float32), 0.308828]. 
=============================================
[2019-03-24 08:48:10,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.7421883e-09 4.3226067e-09 8.3863682e-08 9.9999988e-01 3.1880703e-08], sum to 1.0000
[2019-03-24 08:48:10,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5805
[2019-03-24 08:48:10,755] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.93333333333333, 53.00000000000001, 1.0, 2.0, 0.254078442086424, 1.0, 2.0, 0.254078442086424, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599650.9908132306, 599650.9908132306, 170792.8530098531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2578800.0000, 
sim time next is 2579400.0000, 
raw observation next is [28.7, 54.0, 1.0, 2.0, 0.256085433614757, 1.0, 2.0, 0.256085433614757, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 604558.1784963735, 604558.1784963739, 171256.1765532992], 
processed observation next is [1.0, 0.8695652173913043, 0.6185185185185185, 0.54, 1.0, 1.0, 0.1143874209699488, 1.0, 1.0, 0.1143874209699488, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21591363517727624, 0.2159136351772764, 0.32933880106403696], 
reward next is 0.6707, 
noisyNet noise sample is [array([0.8633088], dtype=float32), -0.010078233]. 
=============================================
[2019-03-24 08:48:12,720] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3618870e-08 5.6230380e-07 5.8515720e-08 9.9999273e-01 6.5040576e-06], sum to 1.0000
[2019-03-24 08:48:12,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4654
[2019-03-24 08:48:12,732] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 72.33333333333334, 1.0, 2.0, 0.3009100848015802, 1.0, 2.0, 0.3009100848015802, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687625.5525615738, 687625.5525615743, 180767.9832310473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2650800.0000, 
sim time next is 2651400.0000, 
raw observation next is [27.0, 71.5, 1.0, 2.0, 0.2978616507881998, 1.0, 2.0, 0.2978616507881998, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682595.3550382536, 682595.355038254, 180132.6617418067], 
processed observation next is [0.0, 0.6956521739130435, 0.5555555555555556, 0.715, 1.0, 1.0, 0.16412101284309502, 1.0, 1.0, 0.16412101284309502, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24378405537080486, 0.24378405537080503, 0.3464089648880898], 
reward next is 0.6536, 
noisyNet noise sample is [array([1.7272267], dtype=float32), 0.15191893]. 
=============================================
[2019-03-24 08:48:13,924] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.9903749e-08 7.1989746e-07 7.7457742e-07 9.9999845e-01 3.9739589e-08], sum to 1.0000
[2019-03-24 08:48:13,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3122
[2019-03-24 08:48:13,936] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.18333333333333, 87.83333333333334, 1.0, 2.0, 0.2882293419312986, 1.0, 2.0, 0.2882293419312986, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666001.9788128734, 666001.9788128738, 178106.5948996724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2667000.0000, 
sim time next is 2667600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.2864188668789183, 1.0, 2.0, 0.2864188668789183, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 662202.7005069316, 662202.7005069321, 177696.2422320624], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.15049865104633134, 1.0, 1.0, 0.15049865104633134, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2365009644667613, 0.23650096446676147, 0.34172354275396616], 
reward next is 0.6583, 
noisyNet noise sample is [array([-0.2923941], dtype=float32), 0.6883921]. 
=============================================
[2019-03-24 08:48:14,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0208215e-09 1.5675569e-06 7.7166973e-08 9.9999833e-01 2.7601354e-08], sum to 1.0000
[2019-03-24 08:48:14,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7297
[2019-03-24 08:48:14,275] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 97.0, 1.0, 2.0, 0.28741485314202, 1.0, 2.0, 0.28741485314202, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663882.5722487783, 663882.5722487788, 177902.3026708894], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2680200.0000, 
sim time next is 2680800.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.2847322437389592, 1.0, 2.0, 0.2847322437389592, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 659397.9430266212, 659397.9430266217, 177349.6884554974], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.96, 1.0, 1.0, 0.14849076635590383, 1.0, 1.0, 0.14849076635590383, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23549926536665045, 0.2354992653666506, 0.34105709318364885], 
reward next is 0.6589, 
noisyNet noise sample is [array([-1.0294613], dtype=float32), 0.2430173]. 
=============================================
[2019-03-24 08:48:14,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6307284e-06 2.0071823e-06 2.2792606e-06 9.9999201e-01 1.0914589e-06], sum to 1.0000
[2019-03-24 08:48:14,790] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-24 08:48:14,798] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333333, 85.66666666666667, 1.0, 2.0, 0.7459150862535349, 1.0, 2.0, 0.7459150862535349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1701247.539727448, 1701247.539727448, 321913.1919447332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2972400.0000, 
sim time next is 2973000.0000, 
raw observation next is [27.66666666666667, 84.83333333333333, 1.0, 2.0, 0.7613486612561772, 1.0, 2.0, 0.7613486612561772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1736481.91363824, 1736481.913638241, 328042.7956480741], 
processed observation next is [1.0, 0.391304347826087, 0.580246913580247, 0.8483333333333333, 1.0, 1.0, 0.7158912634002109, 1.0, 1.0, 0.7158912634002109, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6201721120136571, 0.6201721120136574, 0.6308515300924502], 
reward next is 0.3691, 
noisyNet noise sample is [array([-0.19204189], dtype=float32), 0.2892746]. 
=============================================
[2019-03-24 08:48:14,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.964848]
 [56.049088]
 [56.505966]
 [56.994408]
 [57.2222  ]], R is [[55.68416977]
 [55.50826263]
 [55.335392  ]
 [55.19298172]
 [55.08473969]].
[2019-03-24 08:48:22,392] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3274886e-09 2.4987872e-07 3.6264990e-07 9.9999940e-01 5.9423666e-08], sum to 1.0000
[2019-03-24 08:48:22,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-24 08:48:22,411] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.3345151030176292, 1.0, 2.0, 0.3345151030176292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935537, 188950.1021701645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2833200.0000, 
sim time next is 2833800.0000, 
raw observation next is [30.75, 60.33333333333334, 1.0, 2.0, 0.3303960515825425, 1.0, 2.0, 0.3303960515825425, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753094.1145550604, 753094.1145550609, 187915.4121273094], 
processed observation next is [1.0, 0.8260869565217391, 0.6944444444444444, 0.6033333333333334, 1.0, 1.0, 0.20285244236016964, 1.0, 1.0, 0.20285244236016964, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2689621837696644, 0.2689621837696646, 0.36137579255251806], 
reward next is 0.6386, 
noisyNet noise sample is [array([1.0152265], dtype=float32), 0.5380274]. 
=============================================
[2019-03-24 08:48:25,128] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 08:48:25,133] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:48:25,134] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:48:25,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:48:25,137] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:48:25,139] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:48:25,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:25,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:25,140] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:25,140] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:25,140] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:25,165] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-24 08:48:25,194] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-24 08:48:25,223] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-24 08:48:25,256] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-24 08:48:25,285] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-24 08:48:26,589] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:48:26,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.38187711666667, 34.744764, 1.0, 2.0, 0.286335332894241, 1.0, 2.0, 0.286335332894241, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 709162.8995925582, 709162.8995925586, 179419.3871794282]
[2019-03-24 08:48:26,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:48:26,595] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6667698e-07 2.7483640e-07 1.1297957e-06 9.9999821e-01 2.8801426e-07], sampled 0.7457878248482481
[2019-03-24 08:48:33,285] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:48:33,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.21666666666667, 66.0, 1.0, 2.0, 0.1632839179553973, 1.0, 2.0, 0.1632839179553973, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413914.1876815252, 413914.1876815257, 152531.8642294784]
[2019-03-24 08:48:33,288] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:48:33,290] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4022947e-07 3.9732515e-07 1.5468435e-06 9.9999738e-01 4.3656155e-07], sampled 0.5561053152841883
[2019-03-24 08:48:40,894] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:48:40,895] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.48216573, 81.78941359333334, 1.0, 2.0, 0.1790308330561597, 1.0, 2.0, 0.1790308330561597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446191.4516632681, 446191.4516632686, 155613.6305214077]
[2019-03-24 08:48:40,896] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:48:40,898] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4523615e-07 3.9959494e-07 1.5842994e-06 9.9999750e-01 4.1696427e-07], sampled 0.9824261421559259
[2019-03-24 08:49:10,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:10,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.5263412383169203, 1.0, 2.0, 0.5263412383169203, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1220994.354536844, 1220994.354536844, 244639.0891548952]
[2019-03-24 08:49:10,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:49:10,064] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8026391e-07 6.0829666e-07 2.3153043e-06 9.9999607e-01 6.4961284e-07], sampled 0.23659943525246752
[2019-03-24 08:49:19,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:19,154] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.293135506646086, 1.0, 2.0, 0.293135506646086, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674810.3366447721, 674810.3366447726, 179152.7652714265]
[2019-03-24 08:49:19,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:49:19,161] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8017332e-07 2.9705191e-07 1.2195189e-06 9.9999797e-01 3.0752716e-07], sampled 0.2715929382442782
[2019-03-24 08:49:22,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:22,338] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.03333333333333, 82.66666666666667, 1.0, 2.0, 0.3346143651568553, 1.0, 2.0, 0.3346143651568553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762713.9862681003, 762713.9862681008, 188975.2952146954]
[2019-03-24 08:49:22,339] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:49:22,342] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.7385957e-08 1.6342896e-07 7.0486237e-07 9.9999893e-01 1.6777622e-07], sampled 0.06379861717586177
[2019-03-24 08:49:33,839] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:33,842] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.59329351, 70.89442481666667, 1.0, 2.0, 0.6662759711887263, 1.0, 2.0, 0.6662759711887263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1519447.160569877, 1519447.160569877, 291596.3987570848]
[2019-03-24 08:49:33,844] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:49:33,849] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9024919e-07 7.7054091e-07 2.9680225e-06 9.9999499e-01 7.9290692e-07], sampled 0.3533339328798286
[2019-03-24 08:49:37,836] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:37,837] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.83333333333334, 95.0, 1.0, 2.0, 0.277243644380667, 1.0, 2.0, 0.277243644380667, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 646122.7356353016, 646122.735635302, 175781.2688838302]
[2019-03-24 08:49:37,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:49:37,841] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4115805e-07 2.3306833e-07 9.8751229e-07 9.9999845e-01 2.3831977e-07], sampled 0.4678302729874678
[2019-03-24 08:49:43,631] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01041629], dtype=float32), 0.009432335]
[2019-03-24 08:49:43,634] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.9, 55.0, 1.0, 2.0, 0.8082170420994942, 1.0, 2.0, 0.8082170420994942, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1843489.495507458, 1843489.495507458, 347160.0401757854]
[2019-03-24 08:49:43,635] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:49:43,637] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.1679177e-07 7.9592411e-07 3.2419816e-06 9.9999452e-01 8.0540838e-07], sampled 0.6555243340459268
[2019-03-24 08:50:08,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:50:08,200] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:50:08,283] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:50:08,307] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:50:08,389] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:50:09,406] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1775000, evaluation results [1775000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:50:22,093] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.11779855e-07 5.42238183e-07 7.74093735e-07 9.99998450e-01
 6.22046485e-08], sum to 1.0000
[2019-03-24 08:50:22,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2776
[2019-03-24 08:50:22,108] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.66666666666667, 1.0, 2.0, 0.3482636737572751, 1.0, 2.0, 0.3482636737572751, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793842.0865240397, 793842.0865240393, 192446.5238254955], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3340200.0000, 
sim time next is 3340800.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.3456907524250946, 1.0, 2.0, 0.3456907524250946, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 787974.2821359491, 787974.2821359496, 191787.1512582123], 
processed observation next is [0.0, 0.6956521739130435, 0.6296296296296297, 0.7, 1.0, 1.0, 0.22106041955368408, 1.0, 1.0, 0.22106041955368408, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28141938647712467, 0.28141938647712483, 0.36882144472733136], 
reward next is 0.6312, 
noisyNet noise sample is [array([-0.7669669], dtype=float32), -0.37447703]. 
=============================================
[2019-03-24 08:50:24,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3701955e-07 3.0411298e-05 2.2544079e-06 9.9995553e-01 1.1703698e-05], sum to 1.0000
[2019-03-24 08:50:24,612] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8965
[2019-03-24 08:50:24,618] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333334, 52.83333333333334, 1.0, 2.0, 0.461693558222707, 1.0, 2.0, 0.461693558222707, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1067460.590019899, 1067460.590019899, 224493.658425985], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3139800.0000, 
sim time next is 3140400.0000, 
raw observation next is [29.86666666666667, 52.66666666666667, 1.0, 2.0, 0.6989166516837929, 1.0, 2.0, 0.6989166516837929, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1606224.049591964, 1606224.049591964, 304379.7420871977], 
processed observation next is [1.0, 0.34782608695652173, 0.6617283950617285, 0.5266666666666667, 1.0, 1.0, 0.6415674424807059, 1.0, 1.0, 0.6415674424807059, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5736514462828444, 0.5736514462828444, 0.5853456578599956], 
reward next is 0.4147, 
noisyNet noise sample is [array([-1.4704322], dtype=float32), -0.65086687]. 
=============================================
[2019-03-24 08:50:25,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9377717e-07 5.2823088e-07 2.8037042e-05 9.9996865e-01 2.2003073e-06], sum to 1.0000
[2019-03-24 08:50:25,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1973
[2019-03-24 08:50:25,028] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.3305707526156854, 1.0, 2.0, 0.3305707526156854, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753492.5181797235, 753492.518179724, 187958.1244633949], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3394800.0000, 
sim time next is 3395400.0000, 
raw observation next is [24.63333333333333, 89.66666666666667, 1.0, 2.0, 0.3665919730878118, 1.0, 2.0, 0.3665919730878118, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835642.9057788991, 835642.9057788991, 197208.0155300533], 
processed observation next is [1.0, 0.30434782608695654, 0.46790123456790106, 0.8966666666666667, 1.0, 1.0, 0.24594282510453783, 1.0, 1.0, 0.24594282510453783, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2984438949210354, 0.2984438949210354, 0.3792461837116409], 
reward next is 0.6208, 
noisyNet noise sample is [array([-1.2522174], dtype=float32), 0.78055304]. 
=============================================
[2019-03-24 08:50:29,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9938838e-07 4.3416467e-06 5.7508061e-07 9.9998164e-01 1.3334091e-05], sum to 1.0000
[2019-03-24 08:50:29,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6609
[2019-03-24 08:50:29,696] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 50.0, 1.0, 2.0, 0.2529667253303508, 1.0, 2.0, 0.2529667253303508, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598617.4392451, 598617.4392451, 170608.8551367064], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3235200.0000, 
sim time next is 3235800.0000, 
raw observation next is [29.75, 48.0, 1.0, 2.0, 0.2505794943174036, 1.0, 2.0, 0.2505794943174036, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593939.5730822758, 593939.5730822758, 170109.7592380136], 
processed observation next is [0.0, 0.43478260869565216, 0.6574074074074074, 0.48, 1.0, 1.0, 0.1078327313302424, 1.0, 1.0, 0.1078327313302424, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2121212761008128, 0.2121212761008128, 0.32713415238079535], 
reward next is 0.6729, 
noisyNet noise sample is [array([1.1018299], dtype=float32), -0.2985367]. 
=============================================
[2019-03-24 08:50:29,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1580566e-07 2.0256098e-07 2.0554974e-06 9.9999702e-01 3.7461029e-07], sum to 1.0000
[2019-03-24 08:50:29,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2574
[2019-03-24 08:50:29,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 80.5, 1.0, 2.0, 0.2398968370530953, 1.0, 2.0, 0.2398968370530953, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573053.8262096564, 573053.8262096564, 167899.0017124173], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3220200.0000, 
sim time next is 3220800.0000, 
raw observation next is [23.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2408651924430334, 1.0, 2.0, 0.2408651924430334, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574877.5705442546, 574877.5705442551, 168095.2465103981], 
processed observation next is [0.0, 0.2608695652173913, 0.43209876543209896, 0.7966666666666667, 1.0, 1.0, 0.09626808624170642, 1.0, 1.0, 0.09626808624170642, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2053134180515195, 0.20531341805151967, 0.3232600894430733], 
reward next is 0.6767, 
noisyNet noise sample is [array([-0.02046177], dtype=float32), -0.23664087]. 
=============================================
[2019-03-24 08:50:37,374] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5634208e-07 7.4679662e-08 1.4233929e-06 9.9999714e-01 6.7189717e-07], sum to 1.0000
[2019-03-24 08:50:37,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9620
[2019-03-24 08:50:37,392] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 87.66666666666667, 1.0, 2.0, 0.3375663724572098, 1.0, 2.0, 0.3375663724572098, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769446.1160472883, 769446.1160472883, 189720.1451912842], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3450000.0000, 
sim time next is 3450600.0000, 
raw observation next is [25.75, 87.0, 1.0, 2.0, 0.331867358757853, 1.0, 2.0, 0.331867358757853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756449.4195105464, 756449.4195105468, 188283.939029206], 
processed observation next is [1.0, 0.9565217391304348, 0.5092592592592593, 0.87, 1.0, 1.0, 0.20460399852125358, 1.0, 1.0, 0.20460399852125358, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27016050696805227, 0.27016050696805244, 0.36208449813308846], 
reward next is 0.6379, 
noisyNet noise sample is [array([0.5315199], dtype=float32), -0.5697907]. 
=============================================
[2019-03-24 08:50:39,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6928344e-07 7.5116731e-07 7.7496315e-07 9.9999571e-01 2.3835605e-06], sum to 1.0000
[2019-03-24 08:50:39,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4205
[2019-03-24 08:50:39,909] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 74.66666666666667, 1.0, 2.0, 0.7036347312793776, 1.0, 2.0, 0.7036347312793776, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1604729.915895853, 1604729.915895853, 305543.4950668865], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3496800.0000, 
sim time next is 3497400.0000, 
raw observation next is [28.25, 73.5, 1.0, 2.0, 0.7232762568538059, 1.0, 2.0, 0.7232762568538059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1649566.307298629, 1649566.307298629, 313070.6897728621], 
processed observation next is [1.0, 0.4782608695652174, 0.6018518518518519, 0.735, 1.0, 1.0, 0.6705669724450071, 1.0, 1.0, 0.6705669724450071, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5891308240352247, 0.5891308240352247, 0.6020590187939656], 
reward next is 0.3979, 
noisyNet noise sample is [array([-1.1441185], dtype=float32), 1.312057]. 
=============================================
[2019-03-24 08:50:41,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2223500e-05 2.1606420e-06 1.0660499e-05 9.9996638e-01 8.5292213e-06], sum to 1.0000
[2019-03-24 08:50:41,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-24 08:50:41,907] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 87.33333333333333, 1.0, 2.0, 0.6892496316109243, 1.0, 2.0, 0.6892496316109243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1571892.533530494, 1571892.533530495, 300115.1781140128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3678600.0000, 
sim time next is 3679200.0000, 
raw observation next is [26.0, 86.0, 1.0, 2.0, 0.6929840512571188, 1.0, 2.0, 0.6929840512571188, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1580417.985076225, 1580417.985076226, 301517.5296743877], 
processed observation next is [1.0, 0.6086956521739131, 0.5185185185185185, 0.86, 1.0, 1.0, 0.6345048229251414, 1.0, 1.0, 0.6345048229251414, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5644349946700803, 0.5644349946700807, 0.5798414032199763], 
reward next is 0.4202, 
noisyNet noise sample is [array([-1.8681312], dtype=float32), -0.36886188]. 
=============================================
[2019-03-24 08:50:48,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4434984e-07 4.1924528e-07 6.4101291e-06 9.9998760e-01 4.9994651e-06], sum to 1.0000
[2019-03-24 08:50:48,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6206
[2019-03-24 08:50:48,434] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.5199738605920384, 1.0, 2.0, 0.5199738605920384, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1193884.850780471, 1193884.850780471, 242032.6396254572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3589200.0000, 
sim time next is 3589800.0000, 
raw observation next is [24.21666666666667, 86.16666666666667, 1.0, 2.0, 0.6098102569642808, 1.0, 2.0, 0.6098102569642808, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1399062.738525004, 1399062.738525004, 271853.557650762], 
processed observation next is [1.0, 0.5652173913043478, 0.4524691358024692, 0.8616666666666667, 1.0, 1.0, 0.5354884011479534, 1.0, 1.0, 0.5354884011479534, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.49966526375892995, 0.49966526375892995, 0.5227953031745424], 
reward next is 0.4772, 
noisyNet noise sample is [array([-0.05131926], dtype=float32), -0.4343314]. 
=============================================
[2019-03-24 08:50:49,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1166692e-09 3.0583391e-07 2.2911578e-07 9.9999940e-01 4.5989061e-09], sum to 1.0000
[2019-03-24 08:50:49,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6111
[2019-03-24 08:50:49,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.85, 80.5, 1.0, 2.0, 0.2740039075326721, 1.0, 2.0, 0.2740039075326721, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 637448.1417049621, 637448.1417049626, 174973.2955940482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3612600.0000, 
sim time next is 3613200.0000, 
raw observation next is [24.8, 79.66666666666667, 1.0, 2.0, 0.2693068971053384, 1.0, 2.0, 0.2693068971053384, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 628661.1360152798, 628661.1360152803, 173982.782858092], 
processed observation next is [1.0, 0.8260869565217391, 0.4740740740740741, 0.7966666666666667, 1.0, 1.0, 0.13012725845873618, 1.0, 1.0, 0.13012725845873618, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22452183429117137, 0.22452183429117153, 0.3345822747271], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.6058679], dtype=float32), 0.23906478]. 
=============================================
[2019-03-24 08:50:57,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1494905e-06 4.4699864e-06 8.0796935e-06 9.9997675e-01 6.6002422e-06], sum to 1.0000
[2019-03-24 08:50:57,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8896
[2019-03-24 08:50:57,133] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 94.0, 1.0, 2.0, 0.8048995588106189, 1.0, 2.0, 0.8048995588106189, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1835914.75923622, 1835914.75923622, 345783.414253315], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3745800.0000, 
sim time next is 3746400.0000, 
raw observation next is [25.8, 94.0, 1.0, 2.0, 0.7606913538743215, 1.0, 2.0, 0.7606913538743215, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1734981.272901433, 1734981.272901433, 327779.5496704396], 
processed observation next is [1.0, 0.34782608695652173, 0.5111111111111112, 0.94, 1.0, 1.0, 0.7151087546122875, 1.0, 1.0, 0.7151087546122875, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6196361688933689, 0.6196361688933689, 0.6303452878277686], 
reward next is 0.3697, 
noisyNet noise sample is [array([-1.7270532], dtype=float32), -1.4637104]. 
=============================================
[2019-03-24 08:50:59,088] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 08:50:59,089] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:50:59,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:50:59,090] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:50:59,091] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:50:59,091] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:50:59,090] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:50:59,092] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:50:59,091] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:50:59,092] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:50:59,093] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:50:59,116] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-24 08:50:59,145] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-24 08:50:59,146] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-24 08:50:59,227] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-24 08:50:59,257] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-24 08:51:08,960] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01052753], dtype=float32), 0.009646049]
[2019-03-24 08:51:08,960] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.5, 43.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 311002.7030865806, 311002.7030865811, 113142.2188078555]
[2019-03-24 08:51:08,961] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:08,963] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8348583e-07 5.1163352e-07 2.2385332e-06 9.9999571e-01 1.2778909e-06], sampled 0.6680702979369392
[2019-03-24 08:51:11,167] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01052753], dtype=float32), 0.009646049]
[2019-03-24 08:51:11,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.120269025, 46.350299895, 1.0, 2.0, 0.1630832991531258, 1.0, 2.0, 0.1630832991531258, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411188.1062413377, 411188.1062413381, 152458.4942367135]
[2019-03-24 08:51:11,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:51:11,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1470143e-07 2.1574269e-07 1.0203406e-06 9.9999797e-01 5.4781560e-07], sampled 0.7166158918313839
[2019-03-24 08:51:18,031] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01052753], dtype=float32), 0.009646049]
[2019-03-24 08:51:18,032] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.81666666666666, 22.16666666666667, 1.0, 2.0, 0.2975883448615576, 1.0, 2.0, 0.2975883448615576, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721789.196708823, 721789.1967088234, 181721.5498013529]
[2019-03-24 08:51:18,033] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:18,036] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9717589e-08 1.8456713e-07 9.0514089e-07 9.9999833e-01 4.5069967e-07], sampled 0.6564623859398158
[2019-03-24 08:51:51,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01052753], dtype=float32), 0.009646049]
[2019-03-24 08:51:51,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 78.0, 1.0, 2.0, 0.3939029343213903, 1.0, 2.0, 0.3939029343213903, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 897934.4506610561, 897934.4506610566, 204523.6314938052]
[2019-03-24 08:51:51,276] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:51,281] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9497377e-07 5.1511745e-07 2.3730274e-06 9.9999571e-01 1.1926211e-06], sampled 0.9749407187873883
[2019-03-24 08:52:10,763] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01052753], dtype=float32), 0.009646049]
[2019-03-24 08:52:10,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.83333333333334, 1.0, 2.0, 0.2899564411280959, 1.0, 2.0, 0.2899564411280959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669081.5684450326, 669081.568445033, 178473.099378731]
[2019-03-24 08:52:10,767] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:52:10,769] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.2989210e-08 1.5578043e-07 7.8458299e-07 9.9999869e-01 3.8082999e-07], sampled 0.7384724088003515
[2019-03-24 08:52:41,507] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 08:52:41,899] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:52:42,108] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:52:42,131] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:52:42,256] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:52:43,275] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1800000, evaluation results [1800000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:52:45,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9473432e-08 2.6715437e-09 1.2985871e-06 9.9999690e-01 1.7474765e-06], sum to 1.0000
[2019-03-24 08:52:45,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9872
[2019-03-24 08:52:45,124] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 95.50000000000001, 1.0, 2.0, 0.241216200654878, 1.0, 2.0, 0.241216200654878, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 576464.1170115701, 576464.1170115706, 168203.4560740078], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4144200.0000, 
sim time next is 4144800.0000, 
raw observation next is [21.6, 94.0, 1.0, 2.0, 0.2406171176559114, 1.0, 2.0, 0.2406171176559114, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575774.5950342632, 575774.5950342637, 168099.1428976338], 
processed observation next is [1.0, 1.0, 0.3555555555555556, 0.94, 1.0, 1.0, 0.09597275911418024, 1.0, 1.0, 0.09597275911418024, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20563378394080828, 0.20563378394080845, 0.3232675824954496], 
reward next is 0.6767, 
noisyNet noise sample is [array([-0.0971365], dtype=float32), 0.6567356]. 
=============================================
[2019-03-24 08:52:48,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6658696e-06 4.0078140e-07 6.5572652e-07 9.9998772e-01 9.6747344e-06], sum to 1.0000
[2019-03-24 08:52:48,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0192
[2019-03-24 08:52:48,630] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.7, 95.0, 1.0, 2.0, 0.2197843020886265, 1.0, 2.0, 0.2197843020886265, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533378.8401937499, 533378.8401937503, 163810.2016308076], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4068000.0000, 
sim time next is 4068600.0000, 
raw observation next is [20.58333333333333, 95.83333333333334, 1.0, 2.0, 0.3408611871090154, 1.0, 2.0, 0.3408611871090154, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.0200424077054, 825194.8811331657, 825194.8811331661, 192578.8242022011], 
processed observation next is [1.0, 0.08695652173913043, 0.31790123456790104, 0.9583333333333335, 1.0, 1.0, 0.21531093703454215, 1.0, 1.0, 0.21531093703454215, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8100861896864113, 0.29471245754755915, 0.2947124575475593, 0.37034389269654056], 
reward next is 0.6297, 
noisyNet noise sample is [array([0.05937385], dtype=float32), 0.39375624]. 
=============================================
[2019-03-24 08:52:52,291] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7962078e-05 5.1903648e-06 1.4471549e-04 9.9977618e-01 5.5943357e-05], sum to 1.0000
[2019-03-24 08:52:52,297] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-24 08:52:52,301] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 57.5, 1.0, 2.0, 0.6291178485130846, 1.0, 2.0, 0.6291178485130846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1434628.419661698, 1434628.419661699, 278201.0256617726], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4185000.0000, 
sim time next is 4185600.0000, 
raw observation next is [29.53333333333333, 56.0, 1.0, 2.0, 0.6404591788036279, 1.0, 2.0, 0.6404591788036279, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1460515.635548567, 1460515.635548567, 282238.0355558287], 
processed observation next is [1.0, 0.43478260869565216, 0.6493827160493827, 0.56, 1.0, 1.0, 0.5719752128614618, 1.0, 1.0, 0.5719752128614618, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5216127269816311, 0.5216127269816311, 0.5427654529919783], 
reward next is 0.4572, 
noisyNet noise sample is [array([1.0089722], dtype=float32), -0.9925225]. 
=============================================
[2019-03-24 08:52:59,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1593124e-07 1.9485533e-06 1.0519233e-07 9.9999702e-01 7.6588884e-07], sum to 1.0000
[2019-03-24 08:52:59,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8084
[2019-03-24 08:52:59,701] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.13333333333333, 93.33333333333333, 1.0, 2.0, 0.2266553825151128, 1.0, 2.0, 0.2266553825151128, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547949.9132574586, 547949.9132574586, 165232.0882495497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4134000.0000, 
sim time next is 4134600.0000, 
raw observation next is [21.35, 92.0, 1.0, 2.0, 0.2277227033092495, 1.0, 2.0, 0.2277227033092495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550027.6961038889, 550027.6961038894, 165447.5254576444], 
processed observation next is [1.0, 0.8695652173913043, 0.3462962962962963, 0.92, 1.0, 1.0, 0.08062226584434466, 1.0, 1.0, 0.08062226584434466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19643846289424605, 0.1964384628942462, 0.3181683181877777], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.6365071], dtype=float32), 0.016802404]. 
=============================================
[2019-03-24 08:53:13,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0894274e-06 7.4015986e-07 3.4736382e-04 9.9964821e-01 2.5638476e-06], sum to 1.0000
[2019-03-24 08:53:13,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0900
[2019-03-24 08:53:13,082] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 89.5, 1.0, 2.0, 0.2587484195729604, 1.0, 2.0, 0.2587484195729604, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616934.2831047607, 616934.2831047612, 172114.9879171772], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4339800.0000, 
sim time next is 4340400.0000, 
raw observation next is [22.6, 89.33333333333333, 1.0, 2.0, 0.2621148645926055, 1.0, 2.0, 0.2621148645926055, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622931.4718840994, 622931.4718840994, 172807.2350406417], 
processed observation next is [1.0, 0.21739130434782608, 0.39259259259259266, 0.8933333333333333, 1.0, 1.0, 0.12156531499119705, 1.0, 1.0, 0.12156531499119705, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22247552567289264, 0.22247552567289264, 0.3323216058473879], 
reward next is 0.6677, 
noisyNet noise sample is [array([0.4393872], dtype=float32), 0.48793948]. 
=============================================
[2019-03-24 08:53:14,318] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7466242e-08 6.4412274e-07 1.2207487e-07 9.9999928e-01 7.9707414e-09], sum to 1.0000
[2019-03-24 08:53:14,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5568
[2019-03-24 08:53:14,328] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 83.33333333333334, 1.0, 2.0, 0.2591732671839772, 1.0, 2.0, 0.2591732671839772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 612428.8256038591, 612428.8256038596, 171985.3491957318], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4404000.0000, 
sim time next is 4404600.0000, 
raw observation next is [23.25, 86.0, 1.0, 2.0, 0.257357513185722, 1.0, 2.0, 0.257357513185722, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608733.8759557354, 608733.8759557354, 171595.8915090808], 
processed observation next is [1.0, 1.0, 0.4166666666666667, 0.86, 1.0, 1.0, 0.11590180141157377, 1.0, 1.0, 0.11590180141157377, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21740495569847695, 0.21740495569847695, 0.32999209905592464], 
reward next is 0.6700, 
noisyNet noise sample is [array([-0.2874632], dtype=float32), -1.709131]. 
=============================================
[2019-03-24 08:53:15,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2514205e-09 2.9116261e-08 7.9326504e-08 9.9999976e-01 8.9832490e-08], sum to 1.0000
[2019-03-24 08:53:15,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2637
[2019-03-24 08:53:15,024] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.41666666666666, 87.33333333333334, 1.0, 2.0, 0.2921869993538565, 1.0, 2.0, 0.2921869993538565, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672520.0752758441, 672520.0752758445, 178921.6089381858], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4533000.0000, 
sim time next is 4533600.0000, 
raw observation next is [24.13333333333333, 88.66666666666667, 1.0, 2.0, 0.2892110695145482, 1.0, 2.0, 0.2892110695145482, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667138.4987845301, 667138.4987845306, 178285.4257303174], 
processed observation next is [0.0, 0.4782608695652174, 0.44938271604938257, 0.8866666666666667, 1.0, 1.0, 0.1538227018030336, 1.0, 1.0, 0.1538227018030336, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2382637495659036, 0.23826374956590377, 0.34285658794291807], 
reward next is 0.6571, 
noisyNet noise sample is [array([2.520494], dtype=float32), -1.5366375]. 
=============================================
[2019-03-24 08:53:17,279] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7470092e-08 9.6259510e-06 1.2077459e-07 9.9998891e-01 1.1377127e-06], sum to 1.0000
[2019-03-24 08:53:17,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9133
[2019-03-24 08:53:17,296] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.3035824077097188, 1.0, 2.0, 0.3035824077097188, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693767.7097930021, 693767.7097930021, 181413.5840449426], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4505400.0000, 
sim time next is 4506000.0000, 
raw observation next is [23.33333333333333, 98.0, 1.0, 2.0, 0.3018252630233998, 1.0, 2.0, 0.3018252630233998, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690431.5105216858, 690431.5105216863, 181023.7416647685], 
processed observation next is [0.0, 0.13043478260869565, 0.4197530864197529, 0.98, 1.0, 1.0, 0.1688395988373807, 1.0, 1.0, 0.1688395988373807, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24658268232917352, 0.24658268232917369, 0.34812258012455477], 
reward next is 0.6519, 
noisyNet noise sample is [array([1.2133114], dtype=float32), 0.22122681]. 
=============================================
[2019-03-24 08:53:17,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.200466]
 [63.09586 ]
 [63.49402 ]
 [63.6301  ]
 [63.618935]], R is [[63.2651825 ]
 [63.28365707]
 [63.30148697]
 [63.31909561]
 [63.33691025]].
[2019-03-24 08:53:22,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9563411e-08 4.3623167e-08 1.5870650e-06 9.9999821e-01 1.7878028e-07], sum to 1.0000
[2019-03-24 08:53:22,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1272
[2019-03-24 08:53:22,483] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 94.0, 1.0, 2.0, 0.2864726644557847, 1.0, 2.0, 0.2864726644557847, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 661016.2750577002, 661016.2750577007, 177646.4185648271], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4537800.0000, 
sim time next is 4538400.0000, 
raw observation next is [23.66666666666667, 94.0, 1.0, 2.0, 0.2911176467201151, 1.0, 2.0, 0.2911176467201151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669307.845886586, 669307.8458865865, 178630.7551837392], 
processed observation next is [0.0, 0.5217391304347826, 0.43209876543209896, 0.94, 1.0, 1.0, 0.15609243657156557, 1.0, 1.0, 0.15609243657156557, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23903851638806642, 0.23903851638806659, 0.3435206830456523], 
reward next is 0.6565, 
noisyNet noise sample is [array([0.16552049], dtype=float32), 1.1823715]. 
=============================================
[2019-03-24 08:53:23,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3409202e-07 2.5457140e-07 7.4949071e-08 9.9999893e-01 5.8360791e-07], sum to 1.0000
[2019-03-24 08:53:23,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-24 08:53:23,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333334, 90.66666666666667, 1.0, 2.0, 0.2988410663752222, 1.0, 2.0, 0.2988410663752222, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683202.1034655073, 683202.1034655077, 180286.4363225591], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4525800.0000, 
sim time next is 4526400.0000, 
raw observation next is [24.46666666666667, 90.33333333333334, 1.0, 2.0, 0.3010961905807141, 1.0, 2.0, 0.3010961905807141, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686986.6436429427, 686986.6436429431, 180759.5010535259], 
processed observation next is [0.0, 0.391304347826087, 0.46172839506172847, 0.9033333333333334, 1.0, 1.0, 0.16797165545323103, 1.0, 1.0, 0.16797165545323103, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24535237272962238, 0.24535237272962254, 0.3476144251029344], 
reward next is 0.6524, 
noisyNet noise sample is [array([1.4444866], dtype=float32), -0.22142471]. 
=============================================
[2019-03-24 08:53:23,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0194855e-06 7.0274464e-06 1.2505385e-05 9.9997258e-01 5.8526157e-06], sum to 1.0000
[2019-03-24 08:53:23,941] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8851
[2019-03-24 08:53:23,946] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 85.0, 1.0, 2.0, 0.913313267059037, 1.0, 2.0, 0.913313267059037, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2083486.6441139, 2083486.644113901, 392802.6711352256], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4802400.0000, 
sim time next is 4803000.0000, 
raw observation next is [27.41666666666667, 85.66666666666667, 1.0, 2.0, 0.8424920197100031, 1.0, 2.0, 0.8424920197100031, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1921752.554997464, 1921752.554997464, 361626.4205341723], 
processed observation next is [1.0, 0.6086956521739131, 0.5709876543209879, 0.8566666666666667, 1.0, 1.0, 0.8124904996547656, 1.0, 1.0, 0.8124904996547656, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.68634019821338, 0.68634019821338, 0.6954354241041776], 
reward next is 0.3046, 
noisyNet noise sample is [array([-0.6023711], dtype=float32), 1.1730685]. 
=============================================
[2019-03-24 08:53:23,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.00026 ]
 [50.500656]
 [50.819084]
 [51.147064]
 [51.735703]], R is [[50.30482483]
 [50.04638672]
 [49.83290482]
 [49.63750839]
 [49.46508026]].
[2019-03-24 08:53:32,728] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:53:32,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:53:32,730] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:53:32,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:53:32,730] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:53:32,732] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:53:32,732] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:53:32,733] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:53:32,733] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:53:32,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:53:32,737] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:53:32,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-24 08:53:32,786] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-24 08:53:32,816] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-24 08:53:32,817] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-24 08:53:32,845] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-24 08:53:47,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01047252], dtype=float32), 0.00963007]
[2019-03-24 08:53:47,527] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.8, 94.0, 1.0, 2.0, 0.1754570491876355, 1.0, 2.0, 0.1754570491876355, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438816.0934933131, 438816.0934933131, 154912.7272910648]
[2019-03-24 08:53:47,528] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:53:47,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7290060e-07 8.0463144e-07 3.4315049e-06 9.9999356e-01 1.6079306e-06], sampled 0.26358491845541643
[2019-03-24 08:53:47,812] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01047252], dtype=float32), 0.00963007]
[2019-03-24 08:53:47,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.8, 64.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 279885.1186937935, 279885.1186937939, 118628.8544363392]
[2019-03-24 08:53:47,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:53:47,819] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7623803e-07 6.5981283e-07 2.8220006e-06 9.9999452e-01 1.4001633e-06], sampled 0.8659403042441958
[2019-03-24 08:53:51,458] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01047252], dtype=float32), 0.00963007]
[2019-03-24 08:53:51,459] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 73.0, 1.0, 2.0, 0.3488377727314433, 1.0, 2.0, 0.3488377727314433, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 861013.7294099177, 861013.7294099182, 195124.0503206518]
[2019-03-24 08:53:51,460] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:53:51,464] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0202402e-06 1.3714438e-06 5.6715130e-06 9.9998915e-01 2.7212761e-06], sampled 0.3760080929156102
[2019-03-24 08:54:40,562] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01047252], dtype=float32), 0.00963007]
[2019-03-24 08:54:40,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.25, 63.5, 1.0, 2.0, 0.7659384903787971, 1.0, 2.0, 0.7659384903787971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1746960.61953742, 1746960.61953742, 329879.1872943498]
[2019-03-24 08:54:40,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:54:40,568] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0921527e-06 1.4276018e-06 6.1558840e-06 9.9998856e-01 2.7191888e-06], sampled 0.9926442187704779
[2019-03-24 08:54:43,285] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01047252], dtype=float32), 0.00963007]
[2019-03-24 08:54:43,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.25, 85.5, 1.0, 2.0, 0.3328750650890362, 1.0, 2.0, 0.3328750650890362, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758747.4946998043, 758747.4946998048, 188537.264375025]
[2019-03-24 08:54:43,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:54:43,292] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2370423e-07 4.5141448e-07 2.0739160e-06 9.9999619e-01 9.0486020e-07], sampled 0.7186384415941397
[2019-03-24 08:55:15,609] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 08:55:15,737] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 08:55:15,760] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:55:15,765] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.9558 2465989904.6867 46.0000
[2019-03-24 08:55:15,947] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:55:16,966] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1825000, evaluation results [1825000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.955848051994, 2465989904.6866508, 46.0]
[2019-03-24 08:55:24,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8017532e-09 2.8459636e-08 2.1830013e-07 9.9999976e-01 2.5225916e-08], sum to 1.0000
[2019-03-24 08:55:24,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5212
[2019-03-24 08:55:24,721] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 99.0, 1.0, 2.0, 0.3498655062684881, 1.0, 2.0, 0.3498655062684881, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797495.2484367747, 797495.2484367752, 192858.2007810705], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5117400.0000, 
sim time next is 5118000.0000, 
raw observation next is [24.93333333333333, 99.33333333333333, 1.0, 2.0, 0.3511384584378097, 1.0, 2.0, 0.3511384584378097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800398.3735999414, 800398.3735999414, 193186.0017862497], 
processed observation next is [0.0, 0.21739130434782608, 0.47901234567901224, 0.9933333333333333, 1.0, 1.0, 0.2275457838545354, 1.0, 1.0, 0.2275457838545354, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28585656199997905, 0.28585656199997905, 0.37151154189663405], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.7479161], dtype=float32), -0.2792683]. 
=============================================
[2019-03-24 08:55:24,753] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.44964]
 [64.47495]
 [64.4685 ]
 [64.53052]
 [64.47672]], R is [[64.40774536]
 [64.39278412]
 [64.37857819]
 [64.3651123 ]
 [64.35196686]].
[2019-03-24 08:55:32,036] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8051544e-04 6.8883572e-05 4.3816873e-04 9.9913907e-01 7.3313182e-05], sum to 1.0000
[2019-03-24 08:55:32,041] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0002
[2019-03-24 08:55:32,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2118219.824347255 W.
[2019-03-24 08:55:32,053] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.9285208004623873, 1.0, 2.0, 0.9285208004623873, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2118219.824347255, 2118219.824347255, 399723.6615389296], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5240400.0000, 
sim time next is 5241000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.9405272397401703, 1.0, 2.0, 0.9405272397401703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2145642.833930217, 2145642.833930217, 405244.6036035352], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.74, 1.0, 1.0, 0.9291990949287742, 1.0, 1.0, 0.9291990949287742, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7663010121179347, 0.7663010121179347, 0.7793165453914139], 
reward next is 0.2207, 
noisyNet noise sample is [array([0.12160525], dtype=float32), -0.28998572]. 
=============================================
[2019-03-24 08:55:32,076] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[49.085423]
 [49.067585]
 [49.105785]
 [48.693157]
 [48.230385]], R is [[48.89857483]
 [48.64088821]
 [48.41339874]
 [48.1911087 ]
 [47.939888  ]].
[2019-03-24 08:55:39,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9169525e-07 1.2322231e-06 1.1158606e-05 9.9997497e-01 1.2084007e-05], sum to 1.0000
[2019-03-24 08:55:39,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3301
[2019-03-24 08:55:39,697] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3375206538152269, 1.0, 2.0, 0.3375206538152269, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769341.8530389293, 769341.8530389298, 189708.5899916575], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5186400.0000, 
sim time next is 5187000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3374247315256905, 1.0, 2.0, 0.3374247315256905, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 189684.3275013023], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.21121991848296492, 1.0, 1.0, 0.21121991848296492, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27468682101846253, 0.27468682101846253, 0.36477755288711977], 
reward next is 0.6352, 
noisyNet noise sample is [array([-1.6602889], dtype=float32), 1.0106827]. 
=============================================
[2019-03-24 08:55:39,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.61641 ]
 [59.03939 ]
 [59.336758]
 [59.906757]
 [61.1831  ]], R is [[58.09459305]
 [58.1488266 ]
 [58.20254898]
 [58.25598907]
 [58.30944443]].
[2019-03-24 08:55:40,676] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7001749e-07 7.4822573e-08 4.1761984e-07 9.9999595e-01 3.0854694e-06], sum to 1.0000
[2019-03-24 08:55:40,682] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8287
[2019-03-24 08:55:40,687] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 76.5, 1.0, 2.0, 0.3793720344877624, 1.0, 2.0, 0.3793720344877624, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864791.3692334956, 864791.3692334956, 200600.0416545342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5164200.0000, 
sim time next is 5164800.0000, 
raw observation next is [28.9, 77.33333333333333, 1.0, 2.0, 0.3794988900893511, 1.0, 2.0, 0.3794988900893511, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 865080.7040624993, 865080.7040624997, 200633.9172069379], 
processed observation next is [0.0, 0.782608695652174, 0.6259259259259259, 0.7733333333333333, 1.0, 1.0, 0.2613082024873228, 1.0, 1.0, 0.2613082024873228, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3089573943080355, 0.3089573943080356, 0.3858344561671883], 
reward next is 0.6142, 
noisyNet noise sample is [array([0.2685125], dtype=float32), -0.84218216]. 
=============================================
[2019-03-24 08:55:45,717] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9551708e-07 1.3275816e-07 4.5741672e-08 9.9999917e-01 3.7333143e-07], sum to 1.0000
[2019-03-24 08:55:45,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5516
[2019-03-24 08:55:45,732] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.05, 73.5, 1.0, 2.0, 0.3546564337245827, 1.0, 2.0, 0.3546564337245827, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808421.6093666694, 808421.6093666699, 194094.9725232531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5664600.0000, 
sim time next is 5665200.0000, 
raw observation next is [29.16666666666666, 73.0, 1.0, 2.0, 0.3552322942610937, 1.0, 2.0, 0.3552322942610937, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809734.9480393128, 809734.9480393133, 194244.1449063258], 
processed observation next is [0.0, 0.5652173913043478, 0.6358024691358023, 0.73, 1.0, 1.0, 0.23241939792987346, 1.0, 1.0, 0.23241939792987346, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2891910528711832, 0.28919105287118335, 0.37354643251216496], 
reward next is 0.6265, 
noisyNet noise sample is [array([0.24384992], dtype=float32), 0.045641355]. 
=============================================
[2019-03-24 08:55:57,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.35645345e-05 1.15888497e-06 1.95949133e-06 9.99948978e-01
 1.42933595e-05], sum to 1.0000
[2019-03-24 08:55:57,218] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3742
[2019-03-24 08:55:57,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3164496.930922697 W.
[2019-03-24 08:55:57,229] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.4, 63.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 8.544250486720728, 6.9112, 121.9197085317072, 3164496.930922697, 2328272.565616772, 443050.4784513387], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5493600.0000, 
sim time next is 5494200.0000, 
raw observation next is [33.05, 64.0, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8329117850153454, 1.0, 1.0, 0.9977734948820727, 6.953740980349795, 6.9112, 121.94756008, 2851331.068421684, 2829542.439641995, 528085.4022987452], 
processed observation next is [1.0, 0.6086956521739131, 0.7796296296296296, 0.64, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 0.8010854583516016, 1.0, 0.5, 0.9972168686025908, 0.004254098034979492, 0.0, 0.8096049824067558, 1.0183325244363157, 1.0105508713007125, 1.01554885057451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7602579], dtype=float32), 2.7414355]. 
=============================================
[2019-03-24 08:55:57,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0638393e-08 2.7956057e-07 1.1265485e-06 9.9999809e-01 4.4200161e-07], sum to 1.0000
[2019-03-24 08:55:57,270] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-24 08:55:57,273] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.48333333333333, 71.66666666666667, 1.0, 2.0, 0.3569104809946896, 1.0, 2.0, 0.3569104809946896, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 813562.3242678285, 813562.324267829, 194679.5172086371], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5667000.0000, 
sim time next is 5667600.0000, 
raw observation next is [29.56666666666667, 71.33333333333334, 1.0, 2.0, 0.3574921540614517, 1.0, 2.0, 0.3574921540614517, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 814888.9282202241, 814888.9282202246, 194830.6439123409], 
processed observation next is [0.0, 0.6086956521739131, 0.6506172839506174, 0.7133333333333334, 1.0, 1.0, 0.2351097072160139, 1.0, 1.0, 0.2351097072160139, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29103176007865145, 0.2910317600786516, 0.37467431521604017], 
reward next is 0.6253, 
noisyNet noise sample is [array([-0.32811883], dtype=float32), 0.0300664]. 
=============================================
[2019-03-24 08:55:58,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6759032e-10 2.9405706e-07 1.2474455e-07 9.9999964e-01 6.8750650e-09], sum to 1.0000
[2019-03-24 08:55:58,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7542
[2019-03-24 08:55:58,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 62.0, 1.0, 2.0, 0.2647897452105724, 1.0, 2.0, 0.2647897452105724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618746.1974985617, 618746.1974985622, 172970.1976948891], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5752200.0000, 
sim time next is 5752800.0000, 
raw observation next is [27.9, 62.0, 1.0, 2.0, 0.2685143185404221, 1.0, 2.0, 0.2685143185404221, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625720.4503504097, 625720.4503504102, 173749.5836997961], 
processed observation next is [0.0, 0.6086956521739131, 0.5888888888888888, 0.62, 1.0, 1.0, 0.12918371254812158, 1.0, 1.0, 0.12918371254812158, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22347158941086062, 0.2234715894108608, 0.33413381480730014], 
reward next is 0.6659, 
noisyNet noise sample is [array([1.8147078], dtype=float32), 0.19209737]. 
=============================================
[2019-03-24 08:56:00,883] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3244370e-07 4.7633966e-06 2.0468033e-06 9.9999273e-01 2.9211301e-07], sum to 1.0000
[2019-03-24 08:56:00,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9966
[2019-03-24 08:56:00,897] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 90.0, 1.0, 2.0, 0.8147219095096957, 1.0, 2.0, 0.8147219095096957, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1858342.101965665, 1858342.101965665, 349874.7536350832], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5590200.0000, 
sim time next is 5590800.0000, 
raw observation next is [25.0, 91.0, 1.0, 2.0, 0.6817743015257487, 1.0, 2.0, 0.6817743015257487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1554827.097531968, 1554827.097531968, 297322.72345479], 
processed observation next is [1.0, 0.7391304347826086, 0.48148148148148145, 0.91, 1.0, 1.0, 0.6211598827687485, 1.0, 1.0, 0.6211598827687485, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5552953919757029, 0.5552953919757029, 0.5717744681822885], 
reward next is 0.4282, 
noisyNet noise sample is [array([0.6639911], dtype=float32), 0.46490932]. 
=============================================
[2019-03-24 08:56:01,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7287771e-07 4.1165345e-07 7.2562339e-06 9.9999142e-01 1.4407064e-07], sum to 1.0000
[2019-03-24 08:56:01,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0315
[2019-03-24 08:56:01,292] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.63333333333333, 96.66666666666667, 1.0, 2.0, 0.3000846499239911, 1.0, 2.0, 0.3000846499239911, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 684832.1582369971, 684832.1582369976, 180524.2302475589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5635200.0000, 
sim time next is 5635800.0000, 
raw observation next is [23.7, 96.5, 1.0, 2.0, 0.3010465198052882, 1.0, 2.0, 0.3010465198052882, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686313.4323380449, 686313.4323380453, 180719.3748683864], 
processed observation next is [0.0, 0.21739130434782608, 0.4333333333333333, 0.965, 1.0, 1.0, 0.16791252357772402, 1.0, 1.0, 0.16791252357772402, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24511194012073032, 0.24511194012073048, 0.3475372593622815], 
reward next is 0.6525, 
noisyNet noise sample is [array([2.0107727], dtype=float32), -1.3196751]. 
=============================================
[2019-03-24 08:56:02,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0856029e-08 3.6045961e-07 3.0899287e-06 9.9999630e-01 2.3329910e-07], sum to 1.0000
[2019-03-24 08:56:02,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6741
[2019-03-24 08:56:02,225] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 86.0, 1.0, 2.0, 0.3399824278103813, 1.0, 2.0, 0.3399824278103813, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774956.0374071931, 774956.0374071936, 190332.7165443612], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5652000.0000, 
sim time next is 5652600.0000, 
raw observation next is [26.65, 85.33333333333334, 1.0, 2.0, 0.3418520968543921, 1.0, 2.0, 0.3418520968543921, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 779219.9277471572, 779219.9277471586, 190807.913326534], 
processed observation next is [0.0, 0.43478260869565216, 0.5425925925925925, 0.8533333333333334, 1.0, 1.0, 0.21649059149332395, 1.0, 1.0, 0.21649059149332395, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.27829283133827043, 0.27829283133827093, 0.36693829485871926], 
reward next is 0.6331, 
noisyNet noise sample is [array([1.4393883], dtype=float32), -0.13428226]. 
=============================================
[2019-03-24 08:56:03,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7775292e-07 1.3136116e-06 1.8250471e-07 9.9999821e-01 7.6283797e-08], sum to 1.0000
[2019-03-24 08:56:03,067] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4323
[2019-03-24 08:56:03,071] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.23333333333333, 83.33333333333333, 1.0, 2.0, 0.38241958917196, 1.0, 2.0, 0.38241958917196, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 871742.3239766986, 871742.323976699, 201416.950644058], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5686800.0000, 
sim time next is 5687400.0000, 
raw observation next is [28.06666666666667, 84.66666666666667, 1.0, 2.0, 0.3842346332607396, 1.0, 2.0, 0.3842346332607396, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 875882.1612927567, 875882.1612927571, 201904.9215741586], 
processed observation next is [0.0, 0.8260869565217391, 0.5950617283950619, 0.8466666666666667, 1.0, 1.0, 0.2669459919770709, 1.0, 1.0, 0.2669459919770709, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31281505760455597, 0.31281505760455613, 0.3882786953349204], 
reward next is 0.6117, 
noisyNet noise sample is [array([-0.39773506], dtype=float32), 0.49726692]. 
=============================================
[2019-03-24 08:56:04,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1248350e-05 1.2608757e-05 3.3492841e-05 9.9993646e-01 6.2026234e-06], sum to 1.0000
[2019-03-24 08:56:04,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1735
[2019-03-24 08:56:04,558] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.03333333333333, 42.66666666666667, 1.0, 2.0, 0.5160283501347068, 1.0, 2.0, 0.5160283501347068, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1257762.443815578, 1257762.443815577, 243670.9263824936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5847000.0000, 
sim time next is 5847600.0000, 
raw observation next is [28.06666666666667, 42.33333333333334, 1.0, 2.0, 0.5157626514808595, 1.0, 2.0, 0.5157626514808595, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1257904.700422464, 1257904.700422465, 243609.2770617261], 
processed observation next is [1.0, 0.6956521739130435, 0.5950617283950619, 0.42333333333333345, 1.0, 1.0, 0.42352696604864226, 1.0, 1.0, 0.42352696604864226, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44925167872230853, 0.449251678722309, 0.4684793789648579], 
reward next is 0.5315, 
noisyNet noise sample is [array([0.7688938], dtype=float32), -2.539109]. 
=============================================
[2019-03-24 08:56:06,659] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:56:06,661] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:56:06,663] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:56:06,663] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:56:06,664] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:56:06,664] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:06,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:56:06,668] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:06,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:06,669] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:06,670] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:06,695] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-24 08:56:06,727] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-24 08:56:06,758] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-24 08:56:06,759] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-24 08:56:06,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-24 08:56:08,695] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01064709], dtype=float32), 0.009641926]
[2019-03-24 08:56:08,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.2, 41.5, 1.0, 2.0, 0.1978626682875954, 1.0, 2.0, 0.1978626682875954, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 483872.9951429921, 483872.9951429925, 159275.3341991953]
[2019-03-24 08:56:08,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:56:08,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1693770e-07 3.1815875e-07 1.8627409e-06 9.9999702e-01 4.8959743e-07], sampled 0.6163744469613497
[2019-03-24 08:56:23,599] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01064709], dtype=float32), 0.009641926]
[2019-03-24 08:56:23,599] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 47.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397992.5368210167, 397992.5368210172, 150911.2037518391]
[2019-03-24 08:56:23,600] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:56:23,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3060169e-07 2.4258938e-07 1.3547152e-06 9.9999785e-01 4.0191691e-07], sampled 0.7719435346702459
[2019-03-24 08:56:28,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01064709], dtype=float32), 0.009641926]
[2019-03-24 08:56:28,855] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.33333333333334, 1.0, 2.0, 0.1793376745837517, 1.0, 2.0, 0.1793376745837517, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 447055.524504241, 447055.5245042414, 155679.7886097851]
[2019-03-24 08:56:28,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:56:28,860] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.518974e-07 2.666310e-07 1.478615e-06 9.999975e-01 4.489944e-07], sampled 0.971565732990315
[2019-03-24 08:56:43,317] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01064709], dtype=float32), 0.009641926]
[2019-03-24 08:56:43,320] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.76666666666667, 93.66666666666667, 1.0, 2.0, 0.2357326486274361, 1.0, 2.0, 0.2357326486274361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 562814.4737017686, 562814.473701769, 166962.7770667814]
[2019-03-24 08:56:43,321] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:56:43,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4040071e-07 2.5278254e-07 1.4094331e-06 9.9999762e-01 4.2355921e-07], sampled 0.7807900541421516
[2019-03-24 08:57:37,102] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01064709], dtype=float32), 0.009641926]
[2019-03-24 08:57:37,103] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.88978928333334, 87.54215451666667, 1.0, 2.0, 0.1924931374593264, 1.0, 2.0, 0.1924931374593264, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479832.1336044487, 479832.1336044492, 158417.9545844448]
[2019-03-24 08:57:37,105] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:57:37,107] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3138903e-07 3.4967360e-07 1.8879522e-06 9.9999678e-01 5.7440582e-07], sampled 0.5599077967910921
[2019-03-24 08:57:49,413] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 08:57:49,466] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7362 2495418209.4679 47.0000
[2019-03-24 08:57:49,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.6057 2410682814.8906 22.0000
[2019-03-24 08:57:49,721] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 08:57:49,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 08:57:50,788] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1850000, evaluation results [1850000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.60570358432, 2410682814.8906136, 22.0, 6906.736180006656, 2495418209.4679227, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 08:58:00,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0665547e-08 2.7754647e-08 1.9275284e-07 9.9999976e-01 2.8301235e-09], sum to 1.0000
[2019-03-24 08:58:00,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5273
[2019-03-24 08:58:00,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.93333333333334, 83.33333333333334, 1.0, 2.0, 0.2632155178653592, 1.0, 2.0, 0.2632155178653592, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618765.0352844829, 618765.0352844833, 172774.1551901232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6070800.0000, 
sim time next is 6071400.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2591391691007161, 1.0, 2.0, 0.2591391691007161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 609231.5549521815, 609231.554952182, 171842.685288068], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.83, 1.0, 1.0, 0.11802282035799537, 1.0, 1.0, 0.11802282035799537, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21758269819720769, 0.21758269819720785, 0.33046670247705384], 
reward next is 0.6695, 
noisyNet noise sample is [array([2.0688202], dtype=float32), -1.0807829]. 
=============================================
[2019-03-24 08:58:01,269] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0285049e-06 1.3139104e-05 3.6857241e-06 9.9996758e-01 1.3593727e-05], sum to 1.0000
[2019-03-24 08:58:01,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0443
[2019-03-24 08:58:01,288] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333334, 47.0, 1.0, 2.0, 0.5458505990642707, 1.0, 2.0, 0.5458505990642707, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1326570.200403965, 1326570.200403965, 253303.1169778333], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5836800.0000, 
sim time next is 5837400.0000, 
raw observation next is [27.5, 47.0, 1.0, 2.0, 0.574218565749089, 1.0, 2.0, 0.574218565749089, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1390695.594913224, 1390695.594913224, 262708.6925592719], 
processed observation next is [1.0, 0.5652173913043478, 0.5740740740740741, 0.47, 1.0, 1.0, 0.49311734017748693, 1.0, 1.0, 0.49311734017748693, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4966769981832943, 0.4966769981832943, 0.505209024152446], 
reward next is 0.4948, 
noisyNet noise sample is [array([-1.0191728], dtype=float32), -0.6952943]. 
=============================================
[2019-03-24 08:58:03,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0253519e-07 2.9892246e-06 9.1268717e-08 9.9999583e-01 6.8677656e-07], sum to 1.0000
[2019-03-24 08:58:03,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3397
[2019-03-24 08:58:03,020] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.25, 81.66666666666667, 1.0, 2.0, 0.2984689314179855, 1.0, 2.0, 0.2984689314179855, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700134.0591730973, 700134.0591730976, 181026.6689482066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6073800.0000, 
sim time next is 6074400.0000, 
raw observation next is [24.3, 81.33333333333334, 1.0, 2.0, 0.2738388778140593, 1.0, 2.0, 0.2738388778140593, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642405.3573889177, 642405.3573889182, 175176.3298976502], 
processed observation next is [1.0, 0.30434782608695654, 0.4555555555555556, 0.8133333333333335, 1.0, 1.0, 0.13552247358816583, 1.0, 1.0, 0.13552247358816583, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22943048478175632, 0.22943048478175648, 0.33687755749548115], 
reward next is 0.6631, 
noisyNet noise sample is [array([-0.04145042], dtype=float32), 0.45275354]. 
=============================================
[2019-03-24 08:58:03,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9381183e-06 8.9037549e-08 1.2075940e-05 9.9997854e-01 4.0868156e-07], sum to 1.0000
[2019-03-24 08:58:03,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-24 08:58:03,446] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 82.0, 1.0, 2.0, 0.1973158076286103, 1.0, 2.0, 0.1973158076286103, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 486259.0534430754, 486259.0534430759, 159277.9387562918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5875200.0000, 
sim time next is 5875800.0000, 
raw observation next is [21.18333333333333, 82.16666666666667, 1.0, 2.0, 0.1955571962610823, 1.0, 2.0, 0.1955571962610823, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482511.3769824877, 482511.3769824877, 158927.3505095409], 
processed observation next is [1.0, 0.0, 0.34012345679012335, 0.8216666666666668, 1.0, 1.0, 0.04232999554890751, 1.0, 1.0, 0.04232999554890751, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17232549177945988, 0.17232549177945988, 0.3056295202106556], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.20254694], dtype=float32), -0.41120768]. 
=============================================
[2019-03-24 08:58:10,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0831453e-07 1.1914212e-06 3.0083541e-07 9.9999249e-01 5.7681241e-06], sum to 1.0000
[2019-03-24 08:58:10,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8154
[2019-03-24 08:58:10,595] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.71666666666667, 66.66666666666666, 1.0, 2.0, 0.7172566973075247, 1.0, 2.0, 0.7172566973075247, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1635825.010888154, 1635825.010888154, 310748.3357436709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6004200.0000, 
sim time next is 6004800.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.6766952565298396, 1.0, 2.0, 0.6766952565298396, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1543232.359340846, 1543232.359340847, 295435.8746883796], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.66, 1.0, 1.0, 0.6151134006307615, 1.0, 1.0, 0.6151134006307615, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5511544140503022, 0.5511544140503025, 0.5681459128622685], 
reward next is 0.4319, 
noisyNet noise sample is [array([0.12561196], dtype=float32), 0.6493034]. 
=============================================
[2019-03-24 08:58:10,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9855807e-06 6.9924022e-07 5.3073170e-05 9.9994242e-01 8.2912669e-07], sum to 1.0000
[2019-03-24 08:58:10,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4508
[2019-03-24 08:58:10,804] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 62.5, 1.0, 2.0, 0.3259208440084458, 1.0, 2.0, 0.3259208440084458, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 742888.5275919669, 742888.5275919674, 186797.5463355098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6276600.0000, 
sim time next is 6277200.0000, 
raw observation next is [29.9, 62.33333333333333, 1.0, 2.0, 0.326506476387023, 1.0, 2.0, 0.326506476387023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744224.0382892381, 744224.0382892386, 186943.4038839143], 
processed observation next is [0.0, 0.6521739130434783, 0.6629629629629629, 0.6233333333333333, 1.0, 1.0, 0.19822199569883692, 1.0, 1.0, 0.19822199569883692, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2657942993890136, 0.2657942993890138, 0.3595065459306044], 
reward next is 0.6405, 
noisyNet noise sample is [array([0.32993427], dtype=float32), 0.29930824]. 
=============================================
[2019-03-24 08:58:13,197] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7139886e-07 2.0046743e-07 1.0119796e-06 9.9999714e-01 1.0983781e-06], sum to 1.0000
[2019-03-24 08:58:13,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9026
[2019-03-24 08:58:13,210] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.15, 53.83333333333333, 1.0, 2.0, 0.8102117287627647, 1.0, 2.0, 0.8102117287627647, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1848043.950403603, 1848043.950403603, 347990.6418834458], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6105000.0000, 
sim time next is 6105600.0000, 
raw observation next is [30.1, 54.0, 1.0, 2.0, 0.7725257590112857, 1.0, 2.0, 0.7725257590112857, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1761999.749482667, 1761999.749482667, 332530.9109729691], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.54, 1.0, 1.0, 0.7291973321562926, 1.0, 1.0, 0.7291973321562926, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6292856248152382, 0.6292856248152382, 0.6394825211018637], 
reward next is 0.3605, 
noisyNet noise sample is [array([-0.96348965], dtype=float32), -2.1713352]. 
=============================================
[2019-03-24 08:58:19,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9443423e-09 3.5581468e-08 3.0694098e-06 9.9999690e-01 8.6109786e-09], sum to 1.0000
[2019-03-24 08:58:19,548] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6451
[2019-03-24 08:58:19,553] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 76.33333333333334, 1.0, 2.0, 0.2474059844075816, 1.0, 2.0, 0.2474059844075816, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 588295.8213506888, 588295.8213506893, 169472.6512760309], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6225000.0000, 
sim time next is 6225600.0000, 
raw observation next is [24.26666666666667, 76.66666666666667, 1.0, 2.0, 0.2481617834899956, 1.0, 2.0, 0.2481617834899956, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590249.093202896, 590249.0932028964, 169649.2515234387], 
processed observation next is [0.0, 0.043478260869565216, 0.4543209876543211, 0.7666666666666667, 1.0, 1.0, 0.10495450415475666, 1.0, 1.0, 0.10495450415475666, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21080324757246283, 0.210803247572463, 0.3262485606219975], 
reward next is 0.6738, 
noisyNet noise sample is [array([-2.1009548], dtype=float32), -0.24647318]. 
=============================================
[2019-03-24 08:58:21,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1734323e-06 6.3187269e-07 6.9897851e-07 9.9999726e-01 2.5542235e-07], sum to 1.0000
[2019-03-24 08:58:21,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7530
[2019-03-24 08:58:21,219] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 91.66666666666666, 1.0, 2.0, 0.448963564838904, 1.0, 2.0, 0.448963564838904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1023533.552759092, 1023533.552759092, 220050.1954952291], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6410400.0000, 
sim time next is 6411000.0000, 
raw observation next is [24.75, 91.83333333333333, 1.0, 2.0, 0.4321745332444075, 1.0, 2.0, 0.4321745332444075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 985233.820413781, 985233.8204137814, 215203.7643531194], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9183333333333333, 1.0, 1.0, 0.3240173014814376, 1.0, 1.0, 0.3240173014814376, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35186922157635037, 0.35186922157635053, 0.41385339298676804], 
reward next is 0.5861, 
noisyNet noise sample is [array([1.1666658], dtype=float32), -0.8013103]. 
=============================================
[2019-03-24 08:58:21,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.1041  ]
 [56.93096 ]
 [57.03116 ]
 [56.94171 ]
 [56.615818]], R is [[57.17450333]
 [57.17958832]
 [57.16222382]
 [57.14278793]
 [57.12172699]].
[2019-03-24 08:58:25,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0420003e-08 1.4864924e-08 2.8235370e-08 1.0000000e+00 2.6134675e-08], sum to 1.0000
[2019-03-24 08:58:25,994] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9490
[2019-03-24 08:58:26,002] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.06666666666666, 86.33333333333333, 1.0, 2.0, 0.3051505828668528, 1.0, 2.0, 0.3051505828668528, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695524.3007758554, 695524.3007758559, 181701.1383055767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6334800.0000, 
sim time next is 6335400.0000, 
raw observation next is [25.13333333333333, 86.16666666666667, 1.0, 2.0, 0.306437231596576, 1.0, 2.0, 0.306437231596576, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698458.2723716521, 698458.2723716525, 182012.4936161842], 
processed observation next is [0.0, 0.30434782608695654, 0.4864197530864196, 0.8616666666666667, 1.0, 1.0, 0.17433003761497143, 1.0, 1.0, 0.17433003761497143, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24944938298987573, 0.2494493829898759, 0.3500240261849696], 
reward next is 0.6500, 
noisyNet noise sample is [array([-0.75977856], dtype=float32), 1.4566967]. 
=============================================
[2019-03-24 08:58:29,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9253519e-07 2.4054066e-07 8.0507698e-07 9.9999690e-01 1.8155724e-06], sum to 1.0000
[2019-03-24 08:58:29,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-24 08:58:29,538] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 89.0, 1.0, 2.0, 0.5277959434475512, 1.0, 2.0, 0.5277959434475512, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1203394.364912637, 1203394.364912638, 244112.5751588286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6404400.0000, 
sim time next is 6405000.0000, 
raw observation next is [25.33333333333334, 89.33333333333334, 1.0, 2.0, 0.5762115524392825, 1.0, 2.0, 0.5762115524392825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1313878.422593263, 1313878.422593264, 259957.9816410173], 
processed observation next is [1.0, 0.13043478260869565, 0.49382716049382736, 0.8933333333333334, 1.0, 1.0, 0.49548994338009816, 1.0, 1.0, 0.49548994338009816, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46924229378330823, 0.46924229378330856, 0.49991919546349484], 
reward next is 0.5001, 
noisyNet noise sample is [array([-0.02716183], dtype=float32), -1.0621325]. 
=============================================
[2019-03-24 08:58:29,556] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[53.115936]
 [53.580494]
 [53.268345]
 [53.25476 ]
 [53.1727  ]], R is [[52.64133072]
 [52.64546967]
 [52.63606644]
 [52.60684967]
 [52.55197525]].
[2019-03-24 08:58:32,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4492296e-07 1.6941854e-07 1.6370666e-07 9.9999917e-01 3.2594576e-07], sum to 1.0000
[2019-03-24 08:58:32,103] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9272
[2019-03-24 08:58:32,107] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.26666666666667, 63.5, 1.0, 2.0, 0.3412758203323151, 1.0, 2.0, 0.3412758203323151, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777905.6926789904, 777905.6926789904, 190661.292882631], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6465000.0000, 
sim time next is 6465600.0000, 
raw observation next is [30.2, 64.0, 1.0, 2.0, 0.3445228726257969, 1.0, 2.0, 0.3445228726257969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 785310.8302891499, 785310.8302891504, 191488.7334168435], 
processed observation next is [1.0, 0.8695652173913043, 0.674074074074074, 0.64, 1.0, 1.0, 0.21967008645928202, 1.0, 1.0, 0.21967008645928202, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2804681536746964, 0.2804681536746966, 0.3682475642631606], 
reward next is 0.6318, 
noisyNet noise sample is [array([-0.15522219], dtype=float32), 1.0707476]. 
=============================================
[2019-03-24 08:58:36,765] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3586263e-05 3.5955563e-05 1.0197897e-05 9.9993706e-01 3.1283348e-06], sum to 1.0000
[2019-03-24 08:58:36,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6877
[2019-03-24 08:58:36,775] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 32.0, 1.0, 2.0, 0.172575590150069, 1.0, 2.0, 0.172575590150069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 433188.6801738158, 433188.6801738162, 154355.0939917543], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6628800.0000, 
sim time next is 6629400.0000, 
raw observation next is [28.9, 34.5, 1.0, 2.0, 0.1684650227068412, 1.0, 2.0, 0.1684650227068412, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422047.3704776455, 422047.370477646, 153497.0680889767], 
processed observation next is [1.0, 0.7391304347826086, 0.6259259259259259, 0.345, 1.0, 1.0, 0.010077407984334746, 1.0, 1.0, 0.010077407984334746, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15073120374201623, 0.15073120374201643, 0.29518666940187827], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.940206], dtype=float32), 1.0233548]. 
=============================================
[2019-03-24 08:58:40,445] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 08:58:40,450] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:58:40,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:58:40,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:58:40,451] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:58:40,453] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:58:40,454] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:58:40,455] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:58:40,454] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:58:40,456] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:58:40,456] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:58:40,479] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-24 08:58:40,508] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-24 08:58:40,537] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-24 08:58:40,538] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-24 08:58:40,597] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-24 08:58:56,681] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 08:58:56,682] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.8227711, 57.58834293, 1.0, 2.0, 0.4141646898815005, 1.0, 2.0, 0.4141646898815005, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944151.2570844594, 944151.2570844599, 210113.7176403559]
[2019-03-24 08:58:56,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:58:56,685] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7915811e-07 2.3923050e-07 1.0568409e-06 9.9999797e-01 6.2248336e-07], sampled 0.484888505564922
[2019-03-24 08:59:27,752] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 08:59:27,753] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.59150187, 89.05359173, 1.0, 2.0, 0.3338557885495536, 1.0, 2.0, 0.3338557885495536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760984.0420439184, 760984.0420439189, 188783.8132859164]
[2019-03-24 08:59:27,754] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:59:27,759] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5972584e-07 2.1122574e-07 9.7369218e-07 9.9999809e-01 5.1019595e-07], sampled 0.04716571837339534
[2019-03-24 08:59:33,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 08:59:33,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.76666666666667, 69.66666666666666, 1.0, 2.0, 0.3059439258737848, 1.0, 2.0, 0.3059439258737848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697333.375845435, 697333.3758454354, 181893.1091821365]
[2019-03-24 08:59:33,073] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:59:33,077] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6454074e-07 3.4006666e-07 1.5125819e-06 9.9999702e-01 8.1065275e-07], sampled 0.8642532575132317
[2019-03-24 08:59:42,042] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 08:59:42,044] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.6085368603939617, 1.0, 2.0, 0.6085368603939617, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1387653.406568433, 1387653.406568433, 270988.6696636527]
[2019-03-24 08:59:42,044] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:59:42,047] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9963268e-07 5.0650004e-07 2.1880792e-06 9.9999559e-01 1.2574251e-06], sampled 0.3836601375561792
[2019-03-24 09:00:08,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 09:00:08,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.05, 66.5, 1.0, 2.0, 0.2089175992828109, 1.0, 2.0, 0.2089175992828109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 511235.6260102158, 511235.6260102162, 161621.1248404038]
[2019-03-24 09:00:08,629] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:00:08,632] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1721871e-07 2.8893814e-07 1.2733482e-06 9.9999750e-01 6.9338967e-07], sampled 0.14315774907905154
[2019-03-24 09:00:16,039] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01063477], dtype=float32), 0.009746289]
[2019-03-24 09:00:16,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 23.66666666666666, 1.0, 2.0, 0.4608710850329946, 1.0, 2.0, 0.4608710850329946, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1145191.618498506, 1145191.618498506, 227033.3589166593]
[2019-03-24 09:00:16,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:00:16,046] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.8119262e-07 4.8882754e-07 2.1028391e-06 9.9999583e-01 1.1626134e-06], sampled 0.020476212787155945
[2019-03-24 09:00:22,758] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:00:22,940] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:00:23,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.4017 2465922019.1262 46.0000
[2019-03-24 09:00:23,179] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:00:23,241] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:00:24,256] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1875000, evaluation results [1875000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.401676310929, 2465922019.1261635, 46.0]
[2019-03-24 09:00:38,259] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5371170e-06 5.6732773e-08 4.0754858e-06 9.9999225e-01 6.5317458e-08], sum to 1.0000
[2019-03-24 09:00:38,268] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-24 09:00:38,276] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.46666666666667, 78.33333333333334, 1.0, 2.0, 0.2320401783673727, 1.0, 2.0, 0.2320401783673727, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557193.3175647946, 557193.3175647946, 166274.6422084776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7086000.0000, 
sim time next is 7086600.0000, 
raw observation next is [23.45, 78.0, 1.0, 2.0, 0.2307335902236453, 1.0, 2.0, 0.2307335902236453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554658.3192336519, 554658.3192336523, 166010.2403485668], 
processed observation next is [1.0, 0.0, 0.42407407407407405, 0.78, 1.0, 1.0, 0.08420665502814918, 1.0, 1.0, 0.08420665502814918, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19809225686916138, 0.19809225686916154, 0.3192504622087823], 
reward next is 0.6807, 
noisyNet noise sample is [array([0.6916506], dtype=float32), -0.48817152]. 
=============================================
[2019-03-24 09:00:43,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0004315e-08 1.6127085e-08 4.0197625e-07 9.9999869e-01 9.4398911e-07], sum to 1.0000
[2019-03-24 09:00:43,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1022
[2019-03-24 09:00:43,692] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 61.66666666666667, 1.0, 2.0, 0.3852398803132875, 1.0, 2.0, 0.3852398803132875, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 949488.1165410358, 949488.1165410358, 204910.427057765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7138200.0000, 
sim time next is 7138800.0000, 
raw observation next is [23.7, 62.0, 1.0, 2.0, 0.3837864463385824, 1.0, 2.0, 0.3837864463385824, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945905.5276380169, 945905.5276380169, 204509.3971887787], 
processed observation next is [1.0, 0.6521739130434783, 0.4333333333333333, 0.62, 1.0, 1.0, 0.26641243611736, 1.0, 1.0, 0.26641243611736, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33782340272786315, 0.33782340272786315, 0.3932873022861129], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.41875026], dtype=float32), 0.15712938]. 
=============================================
[2019-03-24 09:00:46,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3108669e-06 1.1994288e-07 5.1812680e-07 9.9999285e-01 2.7688745e-07], sum to 1.0000
[2019-03-24 09:00:46,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4675
[2019-03-24 09:00:46,373] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.98333333333333, 80.66666666666666, 1.0, 2.0, 0.1855025025052136, 1.0, 2.0, 0.1855025025052136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460427.2170760695, 460427.21707607, 156912.3484569654], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7253400.0000, 
sim time next is 7254000.0000, 
raw observation next is [20.9, 81.0, 1.0, 2.0, 0.1849030867727845, 1.0, 2.0, 0.1849030867727845, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459180.6708072195, 459180.6708072199, 156793.5611428545], 
processed observation next is [1.0, 1.0, 0.32962962962962955, 0.81, 1.0, 1.0, 0.029646531872362495, 1.0, 1.0, 0.029646531872362495, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1639930967168641, 0.16399309671686427, 0.30152607912087404], 
reward next is 0.6985, 
noisyNet noise sample is [array([-1.2427131], dtype=float32), -1.5485723]. 
=============================================
[2019-03-24 09:00:46,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.1562  ]
 [67.187935]
 [67.22682 ]
 [67.19877 ]
 [67.259094]], R is [[67.20008087]
 [67.22632599]
 [67.2520752 ]
 [67.27729797]
 [67.30197906]].
[2019-03-24 09:00:47,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1990405e-06 2.7063615e-07 1.8923879e-06 9.9999654e-01 1.5791819e-07], sum to 1.0000
[2019-03-24 09:00:47,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2595
[2019-03-24 09:00:47,499] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.63333333333334, 71.0, 1.0, 2.0, 0.2148634566331559, 1.0, 2.0, 0.2148634566331559, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523659.1316748956, 523659.1316748961, 162825.3931573574], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6996000.0000, 
sim time next is 6996600.0000, 
raw observation next is [23.55, 71.5, 1.0, 2.0, 0.21470337442898, 1.0, 2.0, 0.21470337442898, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523319.7025098914, 523319.7025098918, 162792.6698741374], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.715, 1.0, 1.0, 0.06512306479640476, 1.0, 1.0, 0.06512306479640476, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18689989375353264, 0.1868998937535328, 0.31306282668103347], 
reward next is 0.6869, 
noisyNet noise sample is [array([-0.3539525], dtype=float32), -0.5367384]. 
=============================================
[2019-03-24 09:00:50,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7267899e-06 1.3113931e-06 1.9791798e-06 9.9999404e-01 1.0053324e-06], sum to 1.0000
[2019-03-24 09:00:50,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9764
[2019-03-24 09:00:50,103] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 80.0, 1.0, 2.0, 0.3436771629305539, 1.0, 2.0, 0.3436771629305539, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 845541.5576440481, 845541.5576440486, 193699.1818361337], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7117200.0000, 
sim time next is 7117800.0000, 
raw observation next is [21.41666666666667, 79.66666666666667, 1.0, 2.0, 0.3765891560219221, 1.0, 2.0, 0.3765891560219221, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924963.270764238, 924963.270764238, 202450.3632991518], 
processed observation next is [1.0, 0.391304347826087, 0.3487654320987656, 0.7966666666666667, 1.0, 1.0, 0.2578442333594311, 1.0, 1.0, 0.2578442333594311, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33034402527294215, 0.33034402527294215, 0.38932762172913804], 
reward next is 0.6107, 
noisyNet noise sample is [array([-1.5513897], dtype=float32), 0.61732787]. 
=============================================
[2019-03-24 09:00:53,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3526477e-08 2.0796243e-08 1.2833117e-06 9.9999833e-01 3.9942651e-07], sum to 1.0000
[2019-03-24 09:00:53,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8259
[2019-03-24 09:00:53,747] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 65.33333333333334, 1.0, 2.0, 0.35853076477273, 1.0, 2.0, 0.35853076477273, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 884779.5121096083, 884779.5121096087, 197689.2021094122], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7144800.0000, 
sim time next is 7145400.0000, 
raw observation next is [23.05, 65.66666666666666, 1.0, 2.0, 0.3517873322211231, 1.0, 2.0, 0.3517873322211231, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868530.9089439398, 868530.9089439398, 195908.2241541182], 
processed observation next is [1.0, 0.6956521739130435, 0.40925925925925927, 0.6566666666666666, 1.0, 1.0, 0.22831825264419414, 1.0, 1.0, 0.22831825264419414, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3101896103371214, 0.3101896103371214, 0.37674658491176577], 
reward next is 0.6233, 
noisyNet noise sample is [array([0.8294947], dtype=float32), -1.3685585]. 
=============================================
[2019-03-24 09:00:56,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8976115e-08 7.1112567e-08 1.8488864e-06 9.9999785e-01 1.4234435e-07], sum to 1.0000
[2019-03-24 09:00:56,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-24 09:00:56,126] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.86666666666667, 90.33333333333334, 1.0, 2.0, 0.2318626687310493, 1.0, 2.0, 0.2318626687310493, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 566058.798012144, 566058.7980121445, 166564.9756101956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7284000.0000, 
sim time next is 7284600.0000, 
raw observation next is [20.9, 90.5, 1.0, 2.0, 0.2453402505118481, 1.0, 2.0, 0.2453402505118481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598134.3113719842, 598134.3113719847, 169552.3856158518], 
processed observation next is [1.0, 0.30434782608695654, 0.32962962962962955, 0.905, 1.0, 1.0, 0.1015955363236287, 1.0, 1.0, 0.1015955363236287, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2136193969185658, 0.21361939691856596, 0.3260622800304842], 
reward next is 0.6739, 
noisyNet noise sample is [array([1.5086076], dtype=float32), 0.046628892]. 
=============================================
[2019-03-24 09:01:07,593] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.06790566e-07 5.46158097e-09 5.93987181e-07 9.99998569e-01
 6.91181413e-07], sum to 1.0000
[2019-03-24 09:01:07,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-24 09:01:07,603] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 84.66666666666667, 1.0, 2.0, 0.2597329109561755, 1.0, 2.0, 0.2597329109561755, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610349.8076975867, 610349.8076975867, 171966.0837353315], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7593600.0000, 
sim time next is 7594200.0000, 
raw observation next is [23.75, 85.0, 1.0, 2.0, 0.2602523228404421, 1.0, 2.0, 0.2602523228404421, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611611.6334842996, 611611.6334843, 172086.6377925098], 
processed observation next is [0.0, 0.9130434782608695, 0.4351851851851852, 0.85, 1.0, 1.0, 0.11934800338147868, 1.0, 1.0, 0.11934800338147868, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21843272624439272, 0.21843272624439286, 0.3309358419086727], 
reward next is 0.6691, 
noisyNet noise sample is [array([-2.7099507], dtype=float32), -0.22517605]. 
=============================================
[2019-03-24 09:01:12,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5435006e-07 3.5911739e-07 2.4566990e-07 9.9999928e-01 3.4091933e-08], sum to 1.0000
[2019-03-24 09:01:12,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6660
[2019-03-24 09:01:12,349] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.61666666666667, 85.33333333333334, 1.0, 2.0, 0.170412091637291, 1.0, 2.0, 0.170412091637291, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427448.1318835791, 427448.1318835796, 153905.4791698796], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7685400.0000, 
sim time next is 7686000.0000, 
raw observation next is [19.6, 86.0, 1.0, 2.0, 0.1711593989526257, 1.0, 2.0, 0.1711593989526257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428982.3128328909, 428982.3128328909, 154050.9996510482], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.86, 1.0, 1.0, 0.01328499875312582, 1.0, 1.0, 0.01328499875312582, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1532079688688896, 0.1532079688688896, 0.2962519224058619], 
reward next is 0.7037, 
noisyNet noise sample is [array([1.3500222], dtype=float32), 0.34246385]. 
=============================================
[2019-03-24 09:01:12,366] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.07938 ]
 [67.04928 ]
 [67.04218 ]
 [66.98257 ]
 [66.974434]], R is [[67.1676178 ]
 [67.19996643]
 [67.23207855]
 [67.26389313]
 [67.29579926]].
[2019-03-24 09:01:14,080] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 09:01:14,081] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:01:14,082] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,082] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:01:14,082] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:01:14,083] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,083] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,084] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:01:14,083] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:01:14,085] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,086] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-24 09:01:14,138] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-24 09:01:14,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-24 09:01:14,140] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-24 09:01:14,231] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-24 09:01:14,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:01:14,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:14,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-24 09:01:36,880] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01059336], dtype=float32), 0.009896237]
[2019-03-24 09:01:36,882] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 87.16666666666667, 1.0, 2.0, 0.2164718695787315, 1.0, 2.0, 0.2164718695787315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530254.5716419275, 530254.5716419279, 163258.8701047915]
[2019-03-24 09:01:36,883] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:01:36,885] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9662877e-08 1.5184445e-07 5.9800459e-07 9.9999881e-01 3.1228208e-07], sampled 0.8583093172098343
[2019-03-24 09:02:28,093] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01059336], dtype=float32), 0.009896237]
[2019-03-24 09:02:28,094] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.5, 35.5, 1.0, 2.0, 0.4809545835893675, 1.0, 2.0, 0.4809545835893675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1096517.89524024, 1096517.895240241, 229554.8190204766]
[2019-03-24 09:02:28,095] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:02:28,098] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0326954e-07 1.5324045e-07 6.2230464e-07 9.9999893e-01 2.9611908e-07], sampled 0.2296151966616503
[2019-03-24 09:02:30,801] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01059336], dtype=float32), 0.009896237]
[2019-03-24 09:02:30,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.90297305, 75.44993969, 1.0, 2.0, 0.2436585007255482, 1.0, 2.0, 0.2436585007255482, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576516.3431302616, 576516.3431302616, 168511.1588027175]
[2019-03-24 09:02:30,806] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:02:30,809] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0487879e-07 1.5659178e-07 6.3003057e-07 9.9999881e-01 3.0425289e-07], sampled 0.6306117804720854
[2019-03-24 09:02:38,472] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01059336], dtype=float32), 0.009896237]
[2019-03-24 09:02:38,473] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.7, 80.0, 1.0, 2.0, 0.3289883604217151, 1.0, 2.0, 0.3289883604217151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749883.8991907397, 749883.8991907402, 187562.6827187925]
[2019-03-24 09:02:38,475] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:02:38,478] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0072349e-07 1.5169493e-07 6.0262238e-07 9.9999881e-01 3.0842645e-07], sampled 0.3822671082919298
[2019-03-24 09:02:56,451] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0693 2668508174.5232 68.0000
[2019-03-24 09:02:56,732] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:02:56,835] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:02:56,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 09:02:56,865] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3270 2465960889.4649 46.0000
[2019-03-24 09:02:57,882] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1900000, evaluation results [1900000.0, 7523.069316394719, 2668508174.523248, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.326961235299, 2465960889.4649444, 46.0]
[2019-03-24 09:02:59,161] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1556635e-08 7.7360403e-09 1.7622864e-06 9.9999809e-01 1.3213203e-07], sum to 1.0000
[2019-03-24 09:02:59,169] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5382
[2019-03-24 09:02:59,173] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333333, 84.66666666666667, 1.0, 2.0, 0.4520087506415698, 1.0, 2.0, 0.4520087506415698, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1071341.14974334, 1071341.14974334, 222743.5260938604], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7636800.0000, 
sim time next is 7637400.0000, 
raw observation next is [23.2, 84.0, 1.0, 2.0, 0.4646373799840904, 1.0, 2.0, 0.4646373799840904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1097622.05133188, 1097622.05133188, 226373.4520013736], 
processed observation next is [1.0, 0.391304347826087, 0.4148148148148148, 0.84, 1.0, 1.0, 0.36266354760010755, 1.0, 1.0, 0.36266354760010755, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.39200787547567145, 0.39200787547567145, 0.4353335615411031], 
reward next is 0.5647, 
noisyNet noise sample is [array([0.19165081], dtype=float32), -0.94265354]. 
=============================================
[2019-03-24 09:03:00,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8435212e-07 1.0182492e-07 3.3507824e-06 9.9999511e-01 1.0785325e-06], sum to 1.0000
[2019-03-24 09:03:00,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0784
[2019-03-24 09:03:00,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 66.0, 1.0, 2.0, 0.2042624602316249, 1.0, 2.0, 0.2042624602316249, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970243, 500729.4896970248, 160660.7870382279], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7761600.0000, 
sim time next is 7762200.0000, 
raw observation next is [23.86666666666667, 66.5, 1.0, 2.0, 0.2031568529403653, 1.0, 2.0, 0.2031568529403653, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498545.5111330266, 498545.5111330266, 160443.5860868361], 
processed observation next is [1.0, 0.8695652173913043, 0.4395061728395063, 0.665, 1.0, 1.0, 0.05137720588138728, 1.0, 1.0, 0.05137720588138728, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17805196826179523, 0.17805196826179523, 0.30854535785930015], 
reward next is 0.6915, 
noisyNet noise sample is [array([-2.0217843], dtype=float32), 0.58894503]. 
=============================================
[2019-03-24 09:03:03,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:03,199] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:03,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-24 09:03:03,741] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5118391e-09 2.0119911e-08 2.1870533e-06 9.9999785e-01 1.8134161e-08], sum to 1.0000
[2019-03-24 09:03:03,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5545
[2019-03-24 09:03:03,751] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.13333333333333, 50.66666666666667, 1.0, 2.0, 0.663261462811178, 1.0, 2.0, 0.663261462811178, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1549349.866443273, 1549349.866443273, 292268.0615857979], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7748400.0000, 
sim time next is 7749000.0000, 
raw observation next is [29.1, 51.0, 1.0, 2.0, 0.6603100179067697, 1.0, 2.0, 0.6603100179067697, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1541651.907852864, 1541651.907852865, 291144.0901639015], 
processed observation next is [1.0, 0.6956521739130435, 0.6333333333333334, 0.51, 1.0, 1.0, 0.5956071641747258, 1.0, 1.0, 0.5956071641747258, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5505899670903085, 0.5505899670903089, 0.559892481084426], 
reward next is 0.4401, 
noisyNet noise sample is [array([-0.80953836], dtype=float32), -1.7249048]. 
=============================================
[2019-03-24 09:03:03,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.14266 ]
 [66.99282 ]
 [66.751686]
 [66.68063 ]
 [66.41811 ]], R is [[67.31797791]
 [67.08274078]
 [66.85058594]
 [66.61477661]
 [66.40465546]].
[2019-03-24 09:03:04,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6733786e-06 4.7367934e-07 4.4302960e-06 9.9998701e-01 3.0357197e-07], sum to 1.0000
[2019-03-24 09:03:04,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2200
[2019-03-24 09:03:04,724] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.6, 86.0, 1.0, 2.0, 0.1711593989526257, 1.0, 2.0, 0.1711593989526257, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428982.3128328909, 428982.3128328909, 154050.9996510482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7686000.0000, 
sim time next is 7686600.0000, 
raw observation next is [19.6, 84.66666666666667, 1.0, 2.0, 0.170151161546075, 1.0, 2.0, 0.170151161546075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426976.9321704746, 426976.932170475, 153856.0023197041], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.8466666666666667, 1.0, 1.0, 0.012084716126279775, 1.0, 1.0, 0.012084716126279775, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15249176148945523, 0.15249176148945537, 0.2958769275378925], 
reward next is 0.7041, 
noisyNet noise sample is [array([1.7116221], dtype=float32), 1.3004005]. 
=============================================
[2019-03-24 09:03:07,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9368000e-06 8.4755055e-07 2.8500951e-06 9.9998641e-01 5.0411695e-06], sum to 1.0000
[2019-03-24 09:03:07,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-24 09:03:07,033] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.46666666666667, 37.33333333333334, 1.0, 2.0, 0.5214891586510791, 1.0, 2.0, 0.5214891586510791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1272870.507862324, 1272870.507862325, 245487.2737803614], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 48000.0000, 
sim time next is 48600.0000, 
raw observation next is [29.65, 37.0, 1.0, 2.0, 0.553409191460886, 1.0, 2.0, 0.553409191460886, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1346631.054246419, 1346631.05424642, 255876.1194820662], 
processed observation next is [1.0, 0.5652173913043478, 0.6537037037037037, 0.37, 1.0, 1.0, 0.46834427554867375, 1.0, 1.0, 0.46834427554867375, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.480939662230864, 0.4809396622308643, 0.492069460542435], 
reward next is 0.5079, 
noisyNet noise sample is [array([-1.0717756], dtype=float32), 0.17226867]. 
=============================================
[2019-03-24 09:03:07,483] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:07,483] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:07,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-24 09:03:08,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:08,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:08,454] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-24 09:03:09,421] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4685269e-07 7.8392816e-07 6.1879637e-06 9.9999249e-01 1.0476157e-07], sum to 1.0000
[2019-03-24 09:03:09,426] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4100
[2019-03-24 09:03:09,429] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.61666666666667, 42.66666666666667, 1.0, 2.0, 0.2091431138387509, 1.0, 2.0, 0.2091431138387509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506587.7141664604, 506587.7141664604, 161490.1109314103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7840200.0000, 
sim time next is 7840800.0000, 
raw observation next is [29.3, 44.0, 1.0, 2.0, 0.2120766555088316, 1.0, 2.0, 0.2120766555088316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513543.278049476, 513543.2780494764, 162110.2755627233], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.44, 1.0, 1.0, 0.06199601846289475, 1.0, 1.0, 0.06199601846289475, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18340831358909856, 0.1834083135890987, 0.3117505299283141], 
reward next is 0.6882, 
noisyNet noise sample is [array([1.1352326], dtype=float32), 0.2275795]. 
=============================================
[2019-03-24 09:03:09,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3523636e-07 9.7930268e-08 2.0937085e-07 9.9999928e-01 1.3664972e-07], sum to 1.0000
[2019-03-24 09:03:09,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5899
[2019-03-24 09:03:09,914] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 64.66666666666667, 1.0, 2.0, 0.2201592516688269, 1.0, 2.0, 0.2201592516688269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533768.132950283, 533768.132950283, 163873.0225572588], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7851000.0000, 
sim time next is 7851600.0000, 
raw observation next is [24.9, 65.0, 1.0, 2.0, 0.220549754081285, 1.0, 2.0, 0.220549754081285, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535041.046541061, 535041.0465410615, 163969.2265730095], 
processed observation next is [1.0, 0.9130434782608695, 0.47777777777777775, 0.65, 1.0, 1.0, 0.07208304057295832, 1.0, 1.0, 0.07208304057295832, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19108608805037894, 0.1910860880503791, 0.31532543571732596], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.37579158], dtype=float32), 0.51034415]. 
=============================================
[2019-03-24 09:03:10,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:10,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:10,571] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-24 09:03:11,359] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8393669e-08 8.9204065e-07 1.9547704e-06 9.9998772e-01 9.3585286e-06], sum to 1.0000
[2019-03-24 09:03:11,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1053
[2019-03-24 09:03:11,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 34.5, 1.0, 2.0, 0.5732312631092218, 1.0, 2.0, 0.5732312631092218, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1381717.115848426, 1381717.115848426, 262148.2366292805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7835400.0000, 
sim time next is 7836000.0000, 
raw observation next is [31.13333333333333, 35.0, 1.0, 2.0, 0.5783206079786475, 1.0, 2.0, 0.5783206079786475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1390622.805338802, 1390622.805338803, 263769.9170341092], 
processed observation next is [1.0, 0.6956521739130435, 0.7086419753086418, 0.35, 1.0, 1.0, 0.49800072378410415, 1.0, 1.0, 0.49800072378410415, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.496651001906715, 0.49665100190671535, 0.5072498404502099], 
reward next is 0.4928, 
noisyNet noise sample is [array([-1.9484438], dtype=float32), -0.48426968]. 
=============================================
[2019-03-24 09:03:11,387] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.07977 ]
 [60.959522]
 [60.94182 ]
 [60.8214  ]
 [60.62264 ]], R is [[60.88950348]
 [60.77647781]
 [60.67434692]
 [60.58612061]
 [60.50223923]].
[2019-03-24 09:03:11,836] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:11,836] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:11,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-24 09:03:13,869] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:13,871] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:13,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-24 09:03:14,339] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:14,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:14,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-24 09:03:15,521] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:15,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:15,554] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-24 09:03:16,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:16,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:16,992] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-24 09:03:17,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:17,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:17,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-24 09:03:17,454] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:17,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:17,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-24 09:03:17,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:17,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:17,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-24 09:03:18,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:18,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:18,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-24 09:03:18,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3355450e-08 3.4882356e-07 6.1234402e-07 9.9999857e-01 3.3054499e-07], sum to 1.0000
[2019-03-24 09:03:18,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7773
[2019-03-24 09:03:18,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.96666666666667, 58.0, 1.0, 2.0, 0.2126096058920066, 1.0, 2.0, 0.2126096058920066, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517427.2314256969, 517427.2314256969, 162316.2295067767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 78600.0000, 
sim time next is 79200.0000, 
raw observation next is [25.8, 59.0, 1.0, 2.0, 0.2123665498781407, 1.0, 2.0, 0.2123665498781407, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 516704.5935446543, 516704.5935446547, 162259.6431219684], 
processed observation next is [1.0, 0.9565217391304348, 0.5111111111111112, 0.59, 1.0, 1.0, 0.06234113080731034, 1.0, 1.0, 0.06234113080731034, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18453735483737654, 0.18453735483737668, 0.3120377752345546], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.8569081], dtype=float32), -0.59895366]. 
=============================================
[2019-03-24 09:03:18,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:18,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:18,808] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-24 09:03:19,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3961700e-05 1.1777429e-05 3.5370333e-05 9.9990034e-01 2.8533241e-05], sum to 1.0000
[2019-03-24 09:03:19,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4840
[2019-03-24 09:03:19,524] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 45.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367179.4847521657, 367179.4847521661, 145374.5267388872], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 258000.0000, 
sim time next is 258600.0000, 
raw observation next is [22.95, 45.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 365085.1953634035, 365085.195363404, 145033.2935495767], 
processed observation next is [0.0, 1.0, 0.4055555555555555, 0.4566666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1303875697726441, 0.1303875697726443, 0.2789101799030321], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8202647], dtype=float32), 0.532306]. 
=============================================
[2019-03-24 09:03:19,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:03:19,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:19,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-24 09:03:21,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8044619e-07 3.0770238e-06 2.5646084e-05 9.9991381e-01 5.7062760e-05], sum to 1.0000
[2019-03-24 09:03:21,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-24 09:03:21,389] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.73333333333333, 46.66666666666666, 1.0, 2.0, 0.3044938785942561, 1.0, 2.0, 0.3044938785942561, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774765.7108139023, 774765.7108139028, 184192.8736771639], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 31200.0000, 
sim time next is 31800.0000, 
raw observation next is [23.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3182682167467322, 1.0, 2.0, 0.3182682167467322, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807996.6316552315, 807996.6316552315, 187638.2855493085], 
processed observation next is [1.0, 0.34782608695652173, 0.4432098765432099, 0.46333333333333343, 1.0, 1.0, 0.1884145437461098, 1.0, 1.0, 0.1884145437461098, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2885702255911541, 0.2885702255911541, 0.36084285682559325], 
reward next is 0.6392, 
noisyNet noise sample is [array([-1.6740346], dtype=float32), -0.32459775]. 
=============================================
[2019-03-24 09:03:26,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1224821e-09 2.5175524e-07 2.7291376e-06 9.9999666e-01 3.0296204e-07], sum to 1.0000
[2019-03-24 09:03:26,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-24 09:03:26,641] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 46.0, 1.0, 2.0, 0.6090137888630807, 1.0, 2.0, 0.6090137888630807, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419178.773913367, 1419178.773913368, 272609.5695898793], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 126000.0000, 
sim time next is 126600.0000, 
raw observation next is [30.88333333333333, 44.0, 1.0, 2.0, 0.6736515759708157, 1.0, 2.0, 0.6736515759708157, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1569653.208699377, 1569653.208699378, 295939.3894676986], 
processed observation next is [1.0, 0.4782608695652174, 0.6993827160493825, 0.44, 1.0, 1.0, 0.6114899713938282, 1.0, 1.0, 0.6114899713938282, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.560590431678349, 0.5605904316783493, 0.5691142105148049], 
reward next is 0.4309, 
noisyNet noise sample is [array([0.02630814], dtype=float32), 0.2569315]. 
=============================================
[2019-03-24 09:03:30,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4557271e-08 1.7388244e-06 8.2800079e-06 9.9998963e-01 1.8665851e-07], sum to 1.0000
[2019-03-24 09:03:30,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2323
[2019-03-24 09:03:30,841] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.56666666666667, 14.83333333333333, 1.0, 2.0, 0.1918837759343549, 1.0, 2.0, 0.1918837759343549, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488900.2328060353, 488900.2328060353, 158455.2480189882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 229800.0000, 
sim time next is 230400.0000, 
raw observation next is [33.6, 15.0, 1.0, 2.0, 0.1921091233846166, 1.0, 2.0, 0.1921091233846166, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489139.6940978993, 489139.6940978997, 158500.1087420948], 
processed observation next is [0.0, 0.6956521739130435, 0.8, 0.15, 1.0, 1.0, 0.03822514688644834, 1.0, 1.0, 0.03822514688644834, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1746927478921069, 0.17469274789210704, 0.3048079014271054], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.38883573], dtype=float32), 0.22770971]. 
=============================================
[2019-03-24 09:03:33,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4808806e-05 2.7038663e-05 1.7353332e-05 9.9986374e-01 3.7115355e-05], sum to 1.0000
[2019-03-24 09:03:33,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4626
[2019-03-24 09:03:33,023] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 54.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 333460.3334405978, 333460.3334405982, 134959.0997129177], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 352800.0000, 
sim time next is 353400.0000, 
raw observation next is [20.71666666666667, 54.66666666666666, 1.0, 2.0, 0.244175472888831, 1.0, 2.0, 0.244175472888831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629818.5624798597, 629818.5624798597, 169836.622976828], 
processed observation next is [1.0, 0.08695652173913043, 0.3228395061728396, 0.5466666666666665, 1.0, 1.0, 0.1002088962962274, 1.0, 1.0, 0.1002088962962274, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22493520088566418, 0.22493520088566418, 0.3266088903400538], 
reward next is 0.6734, 
noisyNet noise sample is [array([-1.2272377], dtype=float32), 0.5043217]. 
=============================================
[2019-03-24 09:03:35,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.21803493e-05 1.18783555e-05 1.73219218e-04 9.99569952e-01
 2.22678922e-04], sum to 1.0000
[2019-03-24 09:03:35,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2289
[2019-03-24 09:03:35,556] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.96666666666667, 50.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 322646.6630840523, 322646.6630840523, 120811.3279396519], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 278400.0000, 
sim time next is 279000.0000, 
raw observation next is [20.2, 49.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 325548.9168890946, 325548.9168890951, 121526.5321211981], 
processed observation next is [0.0, 0.21739130434782608, 0.3037037037037037, 0.495, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11626747031753377, 0.11626747031753397, 0.2337048694638425], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43401706], dtype=float32), -0.22090285]. 
=============================================
[2019-03-24 09:03:35,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[38.49537 ]
 [38.558853]
 [38.594505]
 [38.572258]
 [38.590637]], R is [[38.07151031]
 [37.6907959 ]
 [37.31388855]
 [36.94075012]
 [36.57134247]].
[2019-03-24 09:03:43,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5469306e-06 2.9362902e-05 6.2700085e-05 9.9985230e-01 4.8164224e-05], sum to 1.0000
[2019-03-24 09:03:43,904] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5088
[2019-03-24 09:03:43,908] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.76666666666667, 52.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 354633.513297532, 354633.5132975325, 143928.0122039705], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 434400.0000, 
sim time next is 435000.0000, 
raw observation next is [22.48333333333333, 53.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 358012.8319941103, 358012.8319941098, 144407.6958119767], 
processed observation next is [1.0, 0.0, 0.3882716049382715, 0.5366666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12786172571218227, 0.12786172571218207, 0.27770710733072446], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5203294], dtype=float32), -0.7943477]. 
=============================================
[2019-03-24 09:03:43,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.470215]
 [38.431763]
 [38.660854]
 [38.209087]
 [38.56504 ]], R is [[37.71311569]
 [37.33598328]
 [36.9626236 ]
 [36.5929985 ]
 [36.22706985]].
[2019-03-24 09:03:48,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0062312e-06 1.3351694e-04 4.8318227e-05 9.9977833e-01 3.3850665e-05], sum to 1.0000
[2019-03-24 09:03:48,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6550
[2019-03-24 09:03:48,278] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.85, 50.5, 1.0, 2.0, 0.1700364772589324, 1.0, 2.0, 0.1700364772589324, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426939.3126653464, 426939.3126653464, 153837.7606951285], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 606600.0000, 
sim time next is 607200.0000, 
raw observation next is [24.7, 51.0, 1.0, 2.0, 0.1691462015948202, 1.0, 2.0, 0.1691462015948202, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 424937.7522788605, 424937.752278861, 153660.7721264609], 
processed observation next is [1.0, 0.0, 0.4703703703703703, 0.51, 1.0, 1.0, 0.010888335231928793, 1.0, 1.0, 0.010888335231928793, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1517634829567359, 0.15176348295673608, 0.2955014848585787], 
reward next is 0.7045, 
noisyNet noise sample is [array([-0.7045965], dtype=float32), 1.5857035]. 
=============================================
[2019-03-24 09:03:50,030] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 09:03:50,035] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:03:50,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:50,038] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:03:50,040] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:03:50,045] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:50,045] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:03:50,047] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:50,048] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:50,047] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:03:50,050] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:03:50,077] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-24 09:03:50,111] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-24 09:03:50,141] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-24 09:03:50,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-24 09:03:50,174] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-24 09:04:38,799] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01057606], dtype=float32), 0.009915396]
[2019-03-24 09:04:38,803] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.06290669, 89.20968335500001, 1.0, 2.0, 0.5887702420568335, 1.0, 2.0, 0.5887702420568335, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1342539.861526185, 1342539.861526185, 264201.4922981447]
[2019-03-24 09:04:38,804] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:04:38,809] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3102228e-06 1.4053663e-06 5.5785595e-06 9.9998808e-01 3.6343918e-06], sampled 0.4471358460582542
[2019-03-24 09:05:10,464] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01057606], dtype=float32), 0.009915396]
[2019-03-24 09:05:10,465] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.85, 56.5, 1.0, 2.0, 0.5224062769177547, 1.0, 2.0, 0.5224062769177547, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1191096.171807528, 1191096.171807528, 242398.1501195802]
[2019-03-24 09:05:10,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:05:10,469] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3108075e-06 1.4358109e-06 5.5120258e-06 9.9998796e-01 3.7793709e-06], sampled 0.46709937693296144
[2019-03-24 09:05:27,160] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01057606], dtype=float32), 0.009915396]
[2019-03-24 09:05:27,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.15, 47.83333333333334, 1.0, 2.0, 0.7477374067374127, 1.0, 2.0, 0.7477374067374127, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1705407.768615715, 1705407.768615715, 322631.474239396]
[2019-03-24 09:05:27,163] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:05:27,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0501387e-06 1.1080341e-06 4.6423725e-06 9.9999034e-01 2.9146770e-06], sampled 0.6399576262511288
[2019-03-24 09:05:55,638] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01057606], dtype=float32), 0.009915396]
[2019-03-24 09:05:55,639] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.655008605, 73.21483134166667, 1.0, 2.0, 0.2632315423360616, 1.0, 2.0, 0.2632315423360616, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616751.1156998744, 616751.1156998748, 172686.869726485]
[2019-03-24 09:05:55,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:05:55,646] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8622072e-06 2.0651457e-06 7.6447177e-06 9.9998319e-01 5.2354803e-06], sampled 0.814240961721102
[2019-03-24 09:05:58,650] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.6057 2410682814.8906 22.0000
[2019-03-24 09:05:58,718] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 09:05:58,803] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:05:58,979] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:05:58,981] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454269.9342 47.0000
[2019-03-24 09:05:59,993] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1925000, evaluation results [1925000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438873699.591536, 34.0, 7797.60570358432, 2410682814.8906136, 22.0, 6905.908355438081, 2495454269.934179, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:06:02,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5724213e-05 4.2751626e-06 2.4546038e-05 9.9987376e-01 4.1729658e-05], sum to 1.0000
[2019-03-24 09:06:02,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7517
[2019-03-24 09:06:02,354] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.28333333333333, 45.5, 1.0, 2.0, 0.1764357464740011, 1.0, 2.0, 0.1764357464740011, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441085.5432829827, 441085.5432829831, 155110.4568210421], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 600600.0000, 
sim time next is 601200.0000, 
raw observation next is [26.1, 46.0, 1.0, 2.0, 0.1749260754637825, 1.0, 2.0, 0.1749260754637825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437666.8967051255, 437666.8967051259, 154807.4615316112], 
processed observation next is [1.0, 1.0, 0.5222222222222223, 0.46, 1.0, 1.0, 0.017769137456883924, 1.0, 1.0, 0.017769137456883924, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15630960596611626, 0.1563096059661164, 0.29770665679156], 
reward next is 0.7023, 
noisyNet noise sample is [array([0.73037004], dtype=float32), -0.32544133]. 
=============================================
[2019-03-24 09:06:12,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3495749e-08 1.6322392e-06 5.2175318e-07 9.9999428e-01 3.4760783e-06], sum to 1.0000
[2019-03-24 09:06:12,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6318
[2019-03-24 09:06:12,721] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 41.0, 1.0, 2.0, 0.5669596637194162, 1.0, 2.0, 0.5669596637194162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1375519.608632105, 1375519.608632105, 260315.6947403534], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 734400.0000, 
sim time next is 735000.0000, 
raw observation next is [28.98333333333333, 39.33333333333334, 1.0, 2.0, 0.6098522352465885, 1.0, 2.0, 0.6098522352465885, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1480710.813211406, 1480710.813211406, 275233.8205083929], 
processed observation next is [1.0, 0.5217391304347826, 0.6290123456790122, 0.3933333333333334, 1.0, 1.0, 0.5355383752935577, 1.0, 1.0, 0.5355383752935577, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.528825290432645, 0.528825290432645, 0.5292958086699863], 
reward next is 0.4707, 
noisyNet noise sample is [array([0.6319802], dtype=float32), 0.4136788]. 
=============================================
[2019-03-24 09:06:12,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.26894 ]
 [56.26212 ]
 [56.258923]
 [56.428654]
 [56.345764]], R is [[55.93907166]
 [55.8790741 ]
 [55.81758881]
 [55.75993347]
 [55.71653748]].
[2019-03-24 09:06:19,610] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.79551975e-07 2.14791484e-07 1.02065115e-07 9.99999523e-01
 3.20457865e-08], sum to 1.0000
[2019-03-24 09:06:19,623] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3468
[2019-03-24 09:06:19,627] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 43.33333333333334, 1.0, 2.0, 0.2026444970311491, 1.0, 2.0, 0.2026444970311491, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497276.6360656024, 497276.6360656024, 160334.9937661976], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 922800.0000, 
sim time next is 923400.0000, 
raw observation next is [28.35, 43.0, 1.0, 2.0, 0.2009905401438283, 1.0, 2.0, 0.2009905401438283, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493803.4745354085, 493803.474535409, 160004.4834703228], 
processed observation next is [0.0, 0.6956521739130435, 0.6055555555555556, 0.43, 1.0, 1.0, 0.048798262075986074, 1.0, 1.0, 0.048798262075986074, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1763583837626459, 0.17635838376264606, 0.30770092975062074], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.5301175], dtype=float32), -0.61187917]. 
=============================================
[2019-03-24 09:06:24,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8308182e-04 7.5061354e-05 1.7329211e-04 9.9953294e-01 3.5573699e-05], sum to 1.0000
[2019-03-24 09:06:24,927] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3744
[2019-03-24 09:06:24,934] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.85, 45.0, 1.0, 2.0, 0.4647099840119999, 1.0, 2.0, 0.4647099840119999, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1143335.795164846, 1143335.795164847, 227926.2126392689], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1009800.0000, 
sim time next is 1010400.0000, 
raw observation next is [26.93333333333334, 44.66666666666667, 1.0, 2.0, 0.4605030835266058, 1.0, 2.0, 0.4605030835266058, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1132987.972494644, 1132987.972494644, 226649.4243483006], 
processed observation next is [1.0, 0.6956521739130435, 0.5530864197530867, 0.4466666666666667, 1.0, 1.0, 0.35774176610310215, 1.0, 1.0, 0.35774176610310215, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.40463856160523004, 0.40463856160523004, 0.4358642775928858], 
reward next is 0.5641, 
noisyNet noise sample is [array([-0.29451293], dtype=float32), -1.416917]. 
=============================================
[2019-03-24 09:06:42,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2206446e-10 4.8166906e-09 2.7676870e-07 9.9999964e-01 6.6500355e-08], sum to 1.0000
[2019-03-24 09:06:42,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2763
[2019-03-24 09:06:42,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 28.0, 1.0, 2.0, 0.1849688838034701, 1.0, 2.0, 0.1849688838034701, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462610.1806959374, 462610.1806959378, 156890.4155876475], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1454400.0000, 
sim time next is 1455000.0000, 
raw observation next is [30.73333333333333, 28.66666666666667, 1.0, 2.0, 0.1842903041129233, 1.0, 2.0, 0.1842903041129233, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460876.1757982428, 460876.1757982432, 156747.3584517017], 
processed observation next is [0.0, 0.8695652173913043, 0.6938271604938271, 0.28666666666666674, 1.0, 1.0, 0.028917028705861065, 1.0, 1.0, 0.028917028705861065, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16459863421365814, 0.16459863421365828, 0.30143722779173404], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.0377109], dtype=float32), 1.4520309]. 
=============================================
[2019-03-24 09:06:42,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.447105]
 [66.55428 ]
 [66.6336  ]
 [66.76898 ]
 [66.86021 ]], R is [[66.30364227]
 [66.33889771]
 [66.37351227]
 [66.40749359]
 [66.44083405]].
[2019-03-24 09:06:46,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0805727e-08 6.3053984e-10 7.5219466e-09 9.9999964e-01 3.8561723e-07], sum to 1.0000
[2019-03-24 09:06:46,643] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4602
[2019-03-24 09:06:46,648] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 49.0, 1.0, 2.0, 0.2732008776924552, 1.0, 2.0, 0.2732008776924552, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 635079.6659639776, 635079.665963978, 174763.3199660279], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1532400.0000, 
sim time next is 1533000.0000, 
raw observation next is [30.2, 50.5, 1.0, 2.0, 0.2710579566936084, 1.0, 2.0, 0.2710579566936084, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631707.4436801635, 631707.4436801639, 174340.7552156615], 
processed observation next is [0.0, 0.7391304347826086, 0.674074074074074, 0.505, 1.0, 1.0, 0.13221185320667664, 1.0, 1.0, 0.13221185320667664, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2256098013143441, 0.22560980131434427, 0.3352706831070414], 
reward next is 0.6647, 
noisyNet noise sample is [array([-0.05989823], dtype=float32), 0.98990613]. 
=============================================
[2019-03-24 09:06:46,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.20145 ]
 [68.26608 ]
 [68.26087 ]
 [68.259384]
 [68.329926]], R is [[68.1390686 ]
 [68.12159729]
 [68.10354614]
 [68.08429718]
 [68.06104279]].
[2019-03-24 09:06:48,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5144811e-07 9.3529826e-07 9.7476395e-06 9.9998486e-01 4.2734446e-06], sum to 1.0000
[2019-03-24 09:06:48,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-24 09:06:48,460] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333334, 58.00000000000001, 1.0, 2.0, 0.1611160889604742, 1.0, 2.0, 0.1611160889604742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406919.5165485146, 406919.5165485151, 152073.4675773502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1639200.0000, 
sim time next is 1639800.0000, 
raw observation next is [22.85, 58.5, 1.0, 2.0, 0.1606820065696592, 1.0, 2.0, 0.1606820065696592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 405825.7030934722, 405825.7030934722, 151986.1978738876], 
processed observation next is [1.0, 1.0, 0.4018518518518519, 0.585, 1.0, 1.0, 0.0008119125829276116, 1.0, 1.0, 0.0008119125829276116, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1449377511048115, 0.1449377511048115, 0.29228114975747616], 
reward next is 0.7077, 
noisyNet noise sample is [array([-0.8805507], dtype=float32), -1.7232318]. 
=============================================
[2019-03-24 09:06:50,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9260433e-07 1.1569316e-06 4.6488458e-07 9.9999762e-01 4.2247888e-07], sum to 1.0000
[2019-03-24 09:06:50,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4211
[2019-03-24 09:06:50,420] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.38333333333333, 85.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 382421.7175127523, 382421.7175127527, 148271.5347243115], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1803000.0000, 
sim time next is 1803600.0000, 
raw observation next is [18.4, 86.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 383114.305733515, 383114.3057335154, 148394.2736888312], 
processed observation next is [1.0, 0.9130434782608695, 0.237037037037037, 0.86, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13682653776196965, 0.1368265377619698, 0.2853736032477523], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8068589], dtype=float32), 1.7118598]. 
=============================================
[2019-03-24 09:06:58,063] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 09:06:58,065] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:06:58,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:06:58,066] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:06:58,068] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:06:58,069] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:06:58,068] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:06:58,071] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:06:58,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:06:58,078] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:06:58,079] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:06:58,100] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-24 09:06:58,134] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-24 09:06:58,168] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-24 09:06:58,168] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-24 09:06:58,233] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-24 09:07:03,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:03,644] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.66666666666667, 62.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 234204.3394303988, 234204.3394303993, 97825.19265495407]
[2019-03-24 09:07:03,647] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:07:03,652] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.4212287e-07 6.7652769e-07 2.9450400e-06 9.9999392e-01 1.7999047e-06], sampled 0.9323463915747293
[2019-03-24 09:07:08,269] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:08,269] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.85, 22.5, 1.0, 2.0, 0.2210273853480718, 1.0, 2.0, 0.2210273853480718, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560600.6167421899, 560600.6167421899, 164663.506901269]
[2019-03-24 09:07:08,269] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:07:08,273] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2587121e-07 1.3224178e-07 6.8965915e-07 9.9999869e-01 3.7221781e-07], sampled 0.7215665751863354
[2019-03-24 09:07:28,883] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:28,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.791151235, 90.49328664999999, 1.0, 2.0, 0.2001643807842601, 1.0, 2.0, 0.2001643807842601, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489059.8399077244, 489059.8399077249, 159743.2370568891]
[2019-03-24 09:07:28,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:07:28,891] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5521472e-08 1.0098743e-07 5.3605868e-07 9.9999893e-01 3.1022626e-07], sampled 0.6518329747735269
[2019-03-24 09:07:30,596] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:30,598] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.83333333333334, 81.66666666666666, 1.0, 2.0, 0.2821636521590044, 1.0, 2.0, 0.2821636521590044, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 654040.1875427385, 654040.187542739, 176772.3534358189]
[2019-03-24 09:07:30,598] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:07:30,602] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.9164446e-08 6.2006528e-08 3.5404409e-07 9.9999928e-01 1.8326831e-07], sampled 0.865104784648593
[2019-03-24 09:07:47,751] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:47,752] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.58318772, 75.41709138, 1.0, 2.0, 0.499819587894812, 1.0, 2.0, 0.499819587894812, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1139559.793965237, 1139559.793965237, 235327.8095491048]
[2019-03-24 09:07:47,754] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:07:47,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.6006601e-08 8.9653895e-08 5.0257836e-07 9.9999905e-01 2.5803593e-07], sampled 0.5876915969980211
[2019-03-24 09:07:52,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:07:52,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.77487249333333, 91.46843000000001, 1.0, 2.0, 0.2299412280727583, 1.0, 2.0, 0.2299412280727583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553142.4463768151, 553142.4463768156, 165851.0089851115]
[2019-03-24 09:07:52,656] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:07:52,662] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3125191e-08 5.7201710e-08 3.2183257e-07 9.9999952e-01 1.7097059e-07], sampled 0.6853770819875261
[2019-03-24 09:08:15,501] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:08:15,501] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.12841194333334, 84.82790906666666, 1.0, 2.0, 0.2946171827851375, 1.0, 2.0, 0.2946171827851375, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674678.8928241815, 674678.8928241819, 179333.1542686008]
[2019-03-24 09:08:15,502] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:08:15,508] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.7188649e-08 5.0084054e-08 2.9207044e-07 9.9999952e-01 1.5068949e-07], sampled 0.4861506452668618
[2019-03-24 09:08:32,547] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.010815], dtype=float32), 0.010033924]
[2019-03-24 09:08:32,550] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 87.0, 1.0, 2.0, 0.3234403000855695, 1.0, 2.0, 0.3234403000855695, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 775884.5248766058, 775884.5248766063, 187855.4061105395]
[2019-03-24 09:08:32,552] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:08:32,555] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2652426e-08 7.7139667e-08 4.2339755e-07 9.9999917e-01 2.3741255e-07], sampled 0.5284580070040558
[2019-03-24 09:09:07,036] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:09:07,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:09:07,429] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:09:07,500] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454110.0746 47.0000
[2019-03-24 09:09:07,665] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:09:08,682] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1950000, evaluation results [1950000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495454110.074621, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:09:09,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2437486e-07 2.1391818e-07 1.3697078e-06 9.9999762e-01 6.0671482e-07], sum to 1.0000
[2019-03-24 09:09:09,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5309
[2019-03-24 09:09:09,819] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 56.33333333333333, 1.0, 2.0, 0.489666470556385, 1.0, 2.0, 0.489666470556385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1201461.952692747, 1201461.952692747, 235541.6282010723], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1590000.0000, 
sim time next is 1590600.0000, 
raw observation next is [24.88333333333333, 56.16666666666667, 1.0, 2.0, 0.4948679385433611, 1.0, 2.0, 0.4948679385433611, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1212780.705522441, 1212780.705522442, 237133.9244089056], 
processed observation next is [1.0, 0.391304347826087, 0.47716049382716036, 0.5616666666666668, 1.0, 1.0, 0.39865230778971555, 1.0, 1.0, 0.39865230778971555, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43313596625801465, 0.433135966258015, 0.45602677770943384], 
reward next is 0.5440, 
noisyNet noise sample is [array([0.8239484], dtype=float32), 1.3080993]. 
=============================================
[2019-03-24 09:09:10,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5269860e-06 8.8150998e-08 1.3136252e-05 9.9997938e-01 8.0053820e-07], sum to 1.0000
[2019-03-24 09:09:10,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9853
[2019-03-24 09:09:10,069] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.85, 24.66666666666667, 1.0, 2.0, 0.1938490497328944, 1.0, 2.0, 0.1938490497328944, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481414.0848991207, 481414.0848991212, 158656.4881789632], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1446600.0000, 
sim time next is 1447200.0000, 
raw observation next is [32.7, 25.0, 1.0, 2.0, 0.192991627780052, 1.0, 2.0, 0.192991627780052, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479411.8104910198, 479411.8104910203, 158481.0555756741], 
processed observation next is [0.0, 0.782608695652174, 0.7666666666666667, 0.25, 1.0, 1.0, 0.03927574735720475, 1.0, 1.0, 0.03927574735720475, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1712185037467928, 0.17121850374679298, 0.3047712607224502], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.9594984], dtype=float32), 2.6782403]. 
=============================================
[2019-03-24 09:09:14,796] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3308163e-07 8.3620871e-06 3.9208871e-06 9.9998045e-01 6.3965999e-06], sum to 1.0000
[2019-03-24 09:09:14,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6993
[2019-03-24 09:09:14,814] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.65, 56.5, 1.0, 2.0, 0.4857274279584676, 1.0, 2.0, 0.4857274279584676, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1193224.129061286, 1193224.129061286, 234350.7028143463], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1589400.0000, 
sim time next is 1590000.0000, 
raw observation next is [24.76666666666667, 56.33333333333333, 1.0, 2.0, 0.489666470556385, 1.0, 2.0, 0.489666470556385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1201461.952692747, 1201461.952692747, 235541.6282010723], 
processed observation next is [1.0, 0.391304347826087, 0.4728395061728396, 0.5633333333333332, 1.0, 1.0, 0.39246008399569643, 1.0, 1.0, 0.39246008399569643, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.429093554533124, 0.429093554533124, 0.45296466961744675], 
reward next is 0.5470, 
noisyNet noise sample is [array([1.8179187], dtype=float32), 0.54707646]. 
=============================================
[2019-03-24 09:09:14,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.01653 ]
 [63.32241 ]
 [63.706295]
 [64.097496]
 [64.61722 ]], R is [[62.8274498 ]
 [62.74850082]
 [62.67354584]
 [62.60564804]
 [62.55570221]].
[2019-03-24 09:09:15,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3716573e-05 8.4117272e-07 3.9215655e-07 9.9998415e-01 9.2575613e-07], sum to 1.0000
[2019-03-24 09:09:15,480] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-24 09:09:15,491] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.66666666666667, 85.66666666666667, 1.0, 2.0, 0.1803254499876587, 1.0, 2.0, 0.1803254499876587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456805.9024787197, 456805.9024787197, 156028.6621938496], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1671000.0000, 
sim time next is 1671600.0000, 
raw observation next is [18.73333333333333, 85.33333333333334, 1.0, 2.0, 0.2540153667024049, 1.0, 2.0, 0.2540153667024049, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642261.8743123666, 642261.874312367, 172055.2041733689], 
processed observation next is [1.0, 0.34782608695652173, 0.2493827160493826, 0.8533333333333334, 1.0, 1.0, 0.11192305559810105, 1.0, 1.0, 0.11192305559810105, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2293792408258452, 0.22937924082584538, 0.33087539264109406], 
reward next is 0.6691, 
noisyNet noise sample is [array([1.7272675], dtype=float32), 0.47102752]. 
=============================================
[2019-03-24 09:09:18,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0184236e-06 2.5637908e-06 1.4676714e-06 9.9999118e-01 6.5860985e-07], sum to 1.0000
[2019-03-24 09:09:18,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5059
[2019-03-24 09:09:18,201] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.63333333333333, 86.66666666666667, 1.0, 2.0, 0.4898804876412807, 1.0, 2.0, 0.4898804876412807, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1178190.136321158, 1178190.136321158, 234864.005081578], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1870800.0000, 
sim time next is 1871400.0000, 
raw observation next is [21.61666666666667, 86.83333333333333, 1.0, 2.0, 0.4877306312101323, 1.0, 2.0, 0.4877306312101323, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1172817.71096732, 1172817.710967321, 234188.4167329883], 
processed observation next is [1.0, 0.6521739130434783, 0.356172839506173, 0.8683333333333333, 1.0, 1.0, 0.39015551334539567, 1.0, 1.0, 0.39015551334539567, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4188634682026143, 0.4188634682026146, 0.45036233987113133], 
reward next is 0.5496, 
noisyNet noise sample is [array([-0.18456581], dtype=float32), 0.33671844]. 
=============================================
[2019-03-24 09:09:22,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4463772e-09 5.0588790e-07 5.1408365e-06 9.9999368e-01 7.3374270e-07], sum to 1.0000
[2019-03-24 09:09:22,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3378
[2019-03-24 09:09:22,879] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.61666666666667, 71.83333333333333, 1.0, 2.0, 0.1745228642243394, 1.0, 2.0, 0.1745228642243394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441187.6842340814, 441187.6842340819, 154811.4147590881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1651800.0000, 
sim time next is 1652400.0000, 
raw observation next is [20.4, 73.0, 1.0, 2.0, 0.173439852513517, 1.0, 2.0, 0.173439852513517, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438739.3250672899, 438739.3250672899, 154592.466559848], 
processed observation next is [1.0, 0.13043478260869565, 0.31111111111111106, 0.73, 1.0, 1.0, 0.015999824420853584, 1.0, 1.0, 0.015999824420853584, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15669261609546067, 0.15669261609546067, 0.2972932049227846], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.9404687], dtype=float32), -0.955937]. 
=============================================
[2019-03-24 09:09:25,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0439090e-06 1.4203420e-06 1.0592769e-06 9.9999428e-01 2.1809303e-06], sum to 1.0000
[2019-03-24 09:09:25,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2834
[2019-03-24 09:09:25,489] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 66.33333333333334, 1.0, 2.0, 0.4685678344223592, 1.0, 2.0, 0.4685678344223592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1115342.965401036, 1115342.965401036, 227887.3213255785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [25.25, 66.0, 1.0, 2.0, 0.4336651969018376, 1.0, 2.0, 0.4336651969018376, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1034861.060321599, 1034861.060321599, 217626.9274961613], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.66, 1.0, 1.0, 0.32579190107361616, 1.0, 1.0, 0.32579190107361616, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3695932358291425, 0.3695932358291425, 0.4185133221080025], 
reward next is 0.5815, 
noisyNet noise sample is [array([1.5454546], dtype=float32), -0.3254766]. 
=============================================
[2019-03-24 09:09:25,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.158527]
 [60.79754 ]
 [60.99188 ]
 [60.81135 ]
 [60.845562]], R is [[61.14809418]
 [61.0983696 ]
 [60.97421646]
 [60.8898735 ]
 [60.80257797]].
[2019-03-24 09:09:42,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3503710e-07 2.8167472e-06 2.2401343e-06 9.9998224e-01 1.2497494e-05], sum to 1.0000
[2019-03-24 09:09:42,073] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1461
[2019-03-24 09:09:42,079] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 73.0, 1.0, 2.0, 0.3212020340445326, 1.0, 2.0, 0.3212020340445326, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732127.5592935807, 732127.5592935807, 185626.5195365085], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2149200.0000, 
sim time next is 2149800.0000, 
raw observation next is [27.53333333333333, 73.5, 1.0, 2.0, 0.3185238210599304, 1.0, 2.0, 0.3185238210599304, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 726020.1194642232, 726020.1194642236, 184965.3724465832], 
processed observation next is [0.0, 0.9130434782608695, 0.5753086419753086, 0.735, 1.0, 1.0, 0.1887188345951552, 1.0, 1.0, 0.1887188345951552, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2592928998086511, 0.2592928998086513, 0.35570263932035234], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.8362357], dtype=float32), 0.85965407]. 
=============================================
[2019-03-24 09:09:44,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5966247e-07 1.6101982e-06 5.2364771e-06 9.9999046e-01 2.3900491e-06], sum to 1.0000
[2019-03-24 09:09:44,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-24 09:09:44,374] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 47.5, 1.0, 2.0, 0.1909760591943194, 1.0, 2.0, 0.1909760591943194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472583.4009422936, 472583.400942294, 158013.4281449517], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2503800.0000, 
sim time next is 2504400.0000, 
raw observation next is [26.7, 48.0, 1.0, 2.0, 0.1910759882550039, 1.0, 2.0, 0.1910759882550039, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472784.8963685802, 472784.8963685806, 158032.8811905321], 
processed observation next is [1.0, 1.0, 0.5444444444444444, 0.48, 1.0, 1.0, 0.03699522411309989, 1.0, 1.0, 0.03699522411309989, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16885174870306435, 0.1688517487030645, 0.3039093869048694], 
reward next is 0.6961, 
noisyNet noise sample is [array([-0.98403883], dtype=float32), -0.11640819]. 
=============================================
[2019-03-24 09:09:58,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6979392e-08 7.1420473e-08 3.7037742e-07 9.9999821e-01 1.2158206e-06], sum to 1.0000
[2019-03-24 09:09:58,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3750
[2019-03-24 09:09:58,486] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.2132546239171693, 1.0, 2.0, 0.2132546239171693, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 519134.5993493839, 519134.5993493844, 162459.2170293876], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [20.4, 96.0, 1.0, 2.0, 0.2130281948055845, 1.0, 2.0, 0.2130281948055845, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518580.7199765248, 518580.7199765248, 162410.5681554593], 
processed observation next is [1.0, 0.2608695652173913, 0.31111111111111106, 0.96, 1.0, 1.0, 0.06312880333998154, 1.0, 1.0, 0.06312880333998154, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.185207399991616, 0.185207399991616, 0.3123280156835756], 
reward next is 0.6877, 
noisyNet noise sample is [array([-1.0128747], dtype=float32), -1.1402893]. 
=============================================
[2019-03-24 09:09:58,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.061005]
 [65.067566]
 [65.20552 ]
 [65.24427 ]
 [65.14905 ]], R is [[65.05708313]
 [65.09408569]
 [65.13101959]
 [65.16847992]
 [65.1991806 ]].
[2019-03-24 09:09:59,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1199100e-07 8.5244970e-08 5.5791197e-06 9.9999225e-01 1.5003344e-06], sum to 1.0000
[2019-03-24 09:09:59,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8044
[2019-03-24 09:09:59,310] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.73333333333333, 47.33333333333334, 1.0, 2.0, 0.2402500416190613, 1.0, 2.0, 0.2402500416190613, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587171.5205889989, 587171.5205889989, 168453.10373889], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2532000.0000, 
sim time next is 2532600.0000, 
raw observation next is [28.0, 46.5, 1.0, 2.0, 0.2460781164614788, 1.0, 2.0, 0.2460781164614788, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 600732.2174902856, 600732.2174902861, 169744.6908957191], 
processed observation next is [1.0, 0.30434782608695654, 0.5925925925925926, 0.465, 1.0, 1.0, 0.10247394816842716, 1.0, 1.0, 0.10247394816842716, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21454722053224487, 0.21454722053224504, 0.3264320978763829], 
reward next is 0.6736, 
noisyNet noise sample is [array([1.2974906], dtype=float32), 0.66454816]. 
=============================================
[2019-03-24 09:10:00,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6666849e-07 1.3377837e-06 2.1040925e-05 9.9995124e-01 2.5337493e-05], sum to 1.0000
[2019-03-24 09:10:00,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9004
[2019-03-24 09:10:00,699] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.15, 69.0, 1.0, 2.0, 0.509799940108547, 1.0, 2.0, 0.509799940108547, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1187273.855221443, 1187273.855221443, 239594.8139274591], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2305800.0000, 
sim time next is 2306400.0000, 
raw observation next is [26.2, 68.33333333333333, 1.0, 2.0, 0.4823123436503474, 1.0, 2.0, 0.4823123436503474, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1124953.245241911, 1124953.245241911, 231140.3304676148], 
processed observation next is [1.0, 0.6956521739130435, 0.5259259259259259, 0.6833333333333332, 1.0, 1.0, 0.3837051710123184, 1.0, 1.0, 0.3837051710123184, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.40176901615782534, 0.40176901615782534, 0.44450063551464386], 
reward next is 0.5555, 
noisyNet noise sample is [array([-2.3980148], dtype=float32), 0.4667411]. 
=============================================
[2019-03-24 09:10:06,875] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 09:10:06,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:10:06,878] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:10:06,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:10:06,879] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:10:06,880] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:10:06,880] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:10:06,881] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:10:06,881] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:10:06,881] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:10:06,883] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:10:06,913] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-24 09:10:06,949] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-24 09:10:06,950] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-24 09:10:06,950] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-24 09:10:07,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-24 09:10:12,133] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:10:12,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 34.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 366992.4861159309, 366992.4861159314, 145455.7160458969]
[2019-03-24 09:10:12,138] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:10:12,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.8641191e-07 6.9038776e-07 2.5054085e-06 9.9999404e-01 1.9855568e-06], sampled 0.33382596887597926
[2019-03-24 09:10:24,136] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:10:24,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.7, 35.0, 1.0, 2.0, 0.2702233978725528, 1.0, 2.0, 0.2702233978725528, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686523.0830298641, 686523.0830298641, 175872.0820085805]
[2019-03-24 09:10:24,138] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:10:24,142] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.6135645e-07 8.5654960e-07 3.1234085e-06 9.9999285e-01 2.3335140e-06], sampled 0.6680424665051118
[2019-03-24 09:10:53,920] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:10:53,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.57596239, 73.93193440833335, 1.0, 2.0, 0.2157243304173079, 1.0, 2.0, 0.2157243304173079, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541761.830773871, 541761.8307738715, 163431.8919167912]
[2019-03-24 09:10:53,925] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:10:53,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.0255176e-07 4.9511630e-07 1.9243332e-06 9.9999571e-01 1.4447295e-06], sampled 0.2877682774804189
[2019-03-24 09:11:08,673] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:11:08,673] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.2, 59.0, 1.0, 2.0, 0.3697693463531971, 1.0, 2.0, 0.3697693463531971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842889.6804479638, 842889.6804479638, 198048.4022711239]
[2019-03-24 09:11:08,674] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:11:08,676] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8836650e-07 1.7498448e-07 8.0343614e-07 9.9999845e-01 5.0821137e-07], sampled 0.4489539235339207
[2019-03-24 09:11:12,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:11:12,281] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.85, 84.0, 1.0, 2.0, 0.3460461926884836, 1.0, 2.0, 0.3460461926884836, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788784.8965261816, 788784.8965261816, 191878.1933932434]
[2019-03-24 09:11:12,281] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:11:12,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6976676e-07 2.6735466e-07 1.0795343e-06 9.9999762e-01 7.9147662e-07], sampled 0.9636429521603622
[2019-03-24 09:11:15,992] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:11:15,993] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 70.0, 1.0, 2.0, 0.3742374649418069, 1.0, 2.0, 0.3742374649418069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853080.4305562609, 853080.4305562613, 199232.0103076364]
[2019-03-24 09:11:15,995] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:11:15,998] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8851061e-07 1.8101800e-07 8.0780916e-07 9.9999833e-01 5.2841784e-07], sampled 0.4331852006055217
[2019-03-24 09:11:23,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01072037], dtype=float32), 0.010041441]
[2019-03-24 09:11:23,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.10596630833334, 101.506527555, 1.0, 2.0, 0.3510070859800929, 1.0, 2.0, 0.3510070859800929, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 803173.4030156917, 803173.4030156921, 193301.2345804017]
[2019-03-24 09:11:23,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:11:23,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1966513e-07 2.1937790e-07 8.8702683e-07 9.9999797e-01 6.9024424e-07], sampled 0.13427535907233656
[2019-03-24 09:12:15,714] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:12:15,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:12:15,985] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:12:15,988] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3270 2465960889.4649 46.0000
[2019-03-24 09:12:16,081] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:12:17,098] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1975000, evaluation results [1975000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.326961235299, 2465960889.4649444, 46.0]
[2019-03-24 09:12:17,492] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1574343e-06 7.0518252e-07 5.9263880e-06 9.9999142e-01 8.8062865e-07], sum to 1.0000
[2019-03-24 09:12:17,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0395
[2019-03-24 09:12:17,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.53333333333333, 31.33333333333334, 1.0, 2.0, 0.1821735937187868, 1.0, 2.0, 0.1821735937187868, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452777.9898722207, 452777.9898722207, 156234.0983199528], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2490000.0000, 
sim time next is 2490600.0000, 
raw observation next is [30.31666666666667, 31.66666666666667, 1.0, 2.0, 0.1807569872049909, 1.0, 2.0, 0.1807569872049909, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449772.2523939685, 449772.252393969, 155953.2361896685], 
processed observation next is [1.0, 0.8260869565217391, 0.6783950617283951, 0.3166666666666667, 1.0, 1.0, 0.024710699053560586, 1.0, 1.0, 0.024710699053560586, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16063294728356017, 0.16063294728356034, 0.29991006959551636], 
reward next is 0.7001, 
noisyNet noise sample is [array([-0.8917753], dtype=float32), -0.45238143]. 
=============================================
[2019-03-24 09:12:23,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2012155e-08 3.3864977e-09 2.4422706e-09 9.9999988e-01 1.6473541e-07], sum to 1.0000
[2019-03-24 09:12:23,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-24 09:12:23,103] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.8, 96.33333333333333, 1.0, 2.0, 0.2267839179386781, 1.0, 2.0, 0.2267839179386781, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547808.0231523379, 547808.0231523383, 165243.6875185014], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2607600.0000, 
sim time next is 2608200.0000, 
raw observation next is [20.75, 96.5, 1.0, 2.0, 0.2262146692321224, 1.0, 2.0, 0.2262146692321224, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546717.1905975307, 546717.1905975307, 165129.5769896391], 
processed observation next is [0.0, 0.17391304347826086, 0.32407407407407407, 0.965, 1.0, 1.0, 0.07882698718109811, 1.0, 1.0, 0.07882698718109811, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1952561394991181, 0.1952561394991181, 0.31755687882622907], 
reward next is 0.6824, 
noisyNet noise sample is [array([1.3519082], dtype=float32), -2.3805342]. 
=============================================
[2019-03-24 09:12:26,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0645435e-09 1.3197853e-08 8.3496365e-09 9.9999964e-01 3.2788421e-07], sum to 1.0000
[2019-03-24 09:12:26,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4442
[2019-03-24 09:12:26,997] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.2548254224827416, 1.0, 2.0, 0.2548254224827416, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602380.2010683736, 602380.2010683736, 171003.7892060187], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2581200.0000, 
sim time next is 2581800.0000, 
raw observation next is [27.76666666666667, 58.16666666666666, 1.0, 2.0, 0.2534754173062714, 1.0, 2.0, 0.2534754173062714, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599317.7075024749, 599317.7075024754, 170702.8330954248], 
processed observation next is [1.0, 0.9130434782608695, 0.5839506172839507, 0.5816666666666666, 1.0, 1.0, 0.11128025869794211, 1.0, 1.0, 0.11128025869794211, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21404203839374103, 0.2140420383937412, 0.3282746790296631], 
reward next is 0.6717, 
noisyNet noise sample is [array([0.9652511], dtype=float32), -0.35853577]. 
=============================================
[2019-03-24 09:12:29,742] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6256242e-07 5.7680558e-07 5.9272008e-07 9.9999833e-01 3.6799560e-07], sum to 1.0000
[2019-03-24 09:12:29,751] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-24 09:12:29,758] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 87.0, 1.0, 2.0, 0.2714210498446553, 1.0, 2.0, 0.2714210498446553, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 633760.4096457134, 633760.4096457139, 174480.0813724375], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2629800.0000, 
sim time next is 2630400.0000, 
raw observation next is [23.66666666666666, 86.33333333333334, 1.0, 2.0, 0.2673246335732971, 1.0, 2.0, 0.2673246335732971, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626340.9963300417, 626340.9963300421, 173629.1145888363], 
processed observation next is [0.0, 0.43478260869565216, 0.4320987654320985, 0.8633333333333334, 1.0, 1.0, 0.1277674209205918, 1.0, 1.0, 0.1277674209205918, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22369321297501488, 0.22369321297501504, 0.3339021434400698], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.7382112], dtype=float32), 0.83676344]. 
=============================================
[2019-03-24 09:12:37,689] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5486881e-07 3.1019812e-05 2.1271258e-06 9.9996150e-01 4.7806088e-06], sum to 1.0000
[2019-03-24 09:12:37,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3912
[2019-03-24 09:12:37,707] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.06666666666667, 74.33333333333334, 1.0, 2.0, 0.339581764318749, 1.0, 2.0, 0.339581764318749, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774042.3038097547, 774042.3038097551, 190230.8433140083], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2751600.0000, 
sim time next is 2752200.0000, 
raw observation next is [27.8, 75.5, 1.0, 2.0, 0.3383982351478064, 1.0, 2.0, 0.3383982351478064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771343.2113268252, 771343.2113268252, 189930.7997517955], 
processed observation next is [0.0, 0.8695652173913043, 0.5851851851851853, 0.755, 1.0, 1.0, 0.21237885136643622, 1.0, 1.0, 0.21237885136643622, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.275479718331009, 0.275479718331009, 0.3652515379842221], 
reward next is 0.6347, 
noisyNet noise sample is [array([-0.7018936], dtype=float32), 1.2789847]. 
=============================================
[2019-03-24 09:12:42,247] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1617300e-06 3.9474493e-05 1.1965247e-05 9.9986124e-01 7.9085723e-05], sum to 1.0000
[2019-03-24 09:12:42,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-24 09:12:42,264] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3440980672296253, 1.0, 2.0, 0.3440980672296253, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 784342.0267900275, 784342.026790028, 191380.3585662234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2917200.0000, 
sim time next is 2917800.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.337953570496338, 1.0, 2.0, 0.337953570496338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770329.1356786303, 770329.1356786308, 189818.565639033], 
processed observation next is [1.0, 0.782608695652174, 0.5370370370370371, 0.865, 1.0, 1.0, 0.21184948868611667, 1.0, 1.0, 0.21184948868611667, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2751175484566537, 0.27511754845665387, 0.3650357031519866], 
reward next is 0.6350, 
noisyNet noise sample is [array([-0.39235014], dtype=float32), -1.4102458]. 
=============================================
[2019-03-24 09:12:43,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7343035e-07 3.0238994e-06 1.0433403e-05 9.9998188e-01 4.1009180e-06], sum to 1.0000
[2019-03-24 09:12:43,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1926
[2019-03-24 09:12:43,269] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 52.5, 1.0, 2.0, 0.4622571163131358, 1.0, 2.0, 0.4622571163131358, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1053860.63032497, 1053860.630324971, 223957.8140696882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [32.5, 53.0, 1.0, 2.0, 0.3219999970500136, 1.0, 2.0, 0.3219999970500136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733947.2563339, 733947.2563339004, 185824.6983002449], 
processed observation next is [1.0, 0.7391304347826086, 0.7592592592592593, 0.53, 1.0, 1.0, 0.19285713934525428, 1.0, 1.0, 0.19285713934525428, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26212402011925, 0.2621240201192501, 0.3573551890389325], 
reward next is 0.6426, 
noisyNet noise sample is [array([0.47360688], dtype=float32), 1.8304448]. 
=============================================
[2019-03-24 09:12:45,316] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4272866e-06 4.7330508e-07 8.8268871e-06 9.9998903e-01 1.7886202e-07], sum to 1.0000
[2019-03-24 09:12:45,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1261
[2019-03-24 09:12:45,328] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.96666666666667, 93.33333333333334, 1.0, 2.0, 0.5017875218146501, 1.0, 2.0, 0.5017875218146501, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1162542.703416996, 1162542.703416996, 236809.9446607986], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2883000.0000, 
sim time next is 2883600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5183416272318754, 1.0, 2.0, 0.5183416272318754, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1197464.068741303, 1197464.068741303, 241859.9029670148], 
processed observation next is [1.0, 0.391304347826087, 0.4074074074074074, 0.94, 1.0, 1.0, 0.4265971752760421, 1.0, 1.0, 0.4265971752760421, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.42766573883617964, 0.42766573883617964, 0.46511519801349], 
reward next is 0.5349, 
noisyNet noise sample is [array([-0.05208505], dtype=float32), 0.0062403725]. 
=============================================
[2019-03-24 09:12:45,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2072662e-06 4.7273104e-05 3.6293502e-06 9.9993026e-01 1.1531973e-05], sum to 1.0000
[2019-03-24 09:12:45,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3594
[2019-03-24 09:12:45,614] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 55.0, 1.0, 2.0, 1.018403808868152, 1.0, 2.0, 1.018403808868152, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259711437881, 2323535.332822936, 2323535.332822935, 442267.4203796576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2815200.0000, 
sim time next is 2815800.0000, 
raw observation next is [32.63333333333333, 55.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.024458400837615, 6.9112, 121.9254529182238, 2385255.620635751, 2327257.476996287, 443048.3199045296], 
processed observation next is [1.0, 0.6086956521739131, 0.7641975308641975, 0.5533333333333335, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.011325840083761474, 0.0, 0.8094582138423897, 0.8518770073699111, 0.831163384641531, 0.8520159998164031], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8062897], dtype=float32), -0.23458515]. 
=============================================
[2019-03-24 09:12:46,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3509506e-07 4.2947453e-05 7.3966708e-06 9.9994683e-01 2.1000167e-06], sum to 1.0000
[2019-03-24 09:12:46,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-24 09:12:46,084] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3831566389889574, 1.0, 2.0, 0.3831566389889574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 873423.4189212293, 873423.4189212298, 201613.3395769873], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2950200.0000, 
sim time next is 2950800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3781539789394116, 1.0, 2.0, 0.3781539789394116, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 862013.2089937237, 862013.2089937242, 200273.1111391793], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2597071177850138, 1.0, 1.0, 0.2597071177850138, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3078618603549013, 0.3078618603549015, 0.3851405983445756], 
reward next is 0.6149, 
noisyNet noise sample is [array([-0.3194948], dtype=float32), -0.9447439]. 
=============================================
[2019-03-24 09:12:47,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0902444e-07 1.0107491e-07 1.4424543e-06 9.9998939e-01 8.8386068e-06], sum to 1.0000
[2019-03-24 09:12:47,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8937
[2019-03-24 09:12:47,607] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 71.66666666666667, 1.0, 2.0, 0.2405563012889879, 1.0, 2.0, 0.2405563012889879, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574678.7252459239, 574678.7252459243, 168047.9200322855], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3223200.0000, 
sim time next is 3223800.0000, 
raw observation next is [25.15, 68.5, 1.0, 2.0, 0.2384566832087524, 1.0, 2.0, 0.2384566832087524, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570792.5515275891, 570792.5515275891, 167625.354793513], 
processed observation next is [0.0, 0.30434782608695654, 0.487037037037037, 0.685, 1.0, 1.0, 0.09340081334375286, 1.0, 1.0, 0.09340081334375286, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20385448268842468, 0.20385448268842468, 0.3223564515259865], 
reward next is 0.6776, 
noisyNet noise sample is [array([-0.06849283], dtype=float32), 1.567494]. 
=============================================
[2019-03-24 09:12:48,637] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4477626e-05 2.7613462e-06 4.9471605e-06 9.9996662e-01 1.1750940e-06], sum to 1.0000
[2019-03-24 09:12:48,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1961
[2019-03-24 09:12:48,661] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 0.3149097694096636, 1.0, 2.0, 0.3149097694096636, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717778.65527278, 717778.6552727805, 184076.9338314734], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.310179006296065, 1.0, 2.0, 0.310179006296065, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706990.7820918385, 706990.782091839, 182921.0720234614], 
processed observation next is [1.0, 0.043478260869565216, 0.45123456790123445, 0.9266666666666667, 1.0, 1.0, 0.17878453130483926, 1.0, 1.0, 0.17878453130483926, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25249670788994233, 0.2524967078899425, 0.3517712923528104], 
reward next is 0.6482, 
noisyNet noise sample is [array([-0.50683844], dtype=float32), 1.2825763]. 
=============================================
[2019-03-24 09:12:50,505] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.8839272e-07 7.2537237e-06 8.2851266e-06 9.9998021e-01 3.3428553e-06], sum to 1.0000
[2019-03-24 09:12:50,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-24 09:12:50,517] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.7590399975825591, 1.0, 2.0, 0.7590399975825591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1731211.217551272, 1731211.217551272, 327120.8997483377], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3084600.0000, 
sim time next is 3085200.0000, 
raw observation next is [28.2, 86.0, 1.0, 2.0, 0.7702475381119633, 1.0, 2.0, 0.7702475381119633, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1756798.405688888, 1756798.405688889, 331615.1005470609], 
processed observation next is [1.0, 0.7391304347826086, 0.6, 0.86, 1.0, 1.0, 0.726485164419004, 1.0, 1.0, 0.726485164419004, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.6274280020317456, 0.6274280020317461, 0.6377213472058864], 
reward next is 0.3623, 
noisyNet noise sample is [array([0.54964453], dtype=float32), -1.5562009]. 
=============================================
[2019-03-24 09:12:51,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4307957e-06 3.9443094e-06 1.3168453e-05 9.9995863e-01 1.8848354e-05], sum to 1.0000
[2019-03-24 09:12:51,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5861
[2019-03-24 09:12:51,442] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.11666666666667, 53.5, 1.0, 2.0, 0.2451936464472915, 1.0, 2.0, 0.2451936464472915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593913.2467645991, 593913.2467645996, 169389.7618209228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3131400.0000, 
sim time next is 3132000.0000, 
raw observation next is [27.1, 54.0, 1.0, 2.0, 0.24428219141131, 1.0, 2.0, 0.24428219141131, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591028.3266509617, 591028.3266509621, 169160.6559530078], 
processed observation next is [1.0, 0.2608695652173913, 0.5592592592592593, 0.54, 1.0, 1.0, 0.10033594215632143, 1.0, 1.0, 0.10033594215632143, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21108154523248632, 0.21108154523248648, 0.3253089537557842], 
reward next is 0.6747, 
noisyNet noise sample is [array([-0.12447416], dtype=float32), 1.445559]. 
=============================================
[2019-03-24 09:12:51,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.090908]
 [57.09003 ]
 [57.099186]
 [57.175835]
 [57.120083]], R is [[57.28136063]
 [57.38279724]
 [57.48367691]
 [57.58364868]
 [57.67895508]].
[2019-03-24 09:12:52,048] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.5123221e-06 7.2268176e-06 1.2615957e-06 9.9998331e-01 5.9910161e-07], sum to 1.0000
[2019-03-24 09:12:52,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9339
[2019-03-24 09:12:52,055] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.635918490052719, 1.0, 2.0, 0.635918490052719, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1450151.156404927, 1450151.156404927, 280617.6602799129], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2991600.0000, 
sim time next is 2992200.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.6727915399428177, 1.0, 2.0, 0.6727915399428177, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1534320.848263955, 1534320.848263955, 293993.2532657662], 
processed observation next is [1.0, 0.6521739130434783, 0.4876543209876545, 0.9316666666666668, 1.0, 1.0, 0.6104661189795448, 1.0, 1.0, 0.6104661189795448, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5479717315228411, 0.5479717315228411, 0.5653716408957042], 
reward next is 0.4346, 
noisyNet noise sample is [array([-0.52212757], dtype=float32), -0.0488271]. 
=============================================
[2019-03-24 09:12:52,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7170542e-07 1.3855928e-05 9.2668615e-06 9.9997115e-01 4.9408745e-06], sum to 1.0000
[2019-03-24 09:12:52,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5497
[2019-03-24 09:12:52,454] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 93.33333333333334, 1.0, 2.0, 0.2448314299073186, 1.0, 2.0, 0.2448314299073186, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584532.0905157162, 584532.0905157167, 168990.0429820675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3300000.0000, 
sim time next is 3300600.0000, 
raw observation next is [21.75, 93.16666666666666, 1.0, 2.0, 0.2429458071687979, 1.0, 2.0, 0.2429458071687979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580779.0849603487, 580779.0849603491, 168597.2620350882], 
processed observation next is [0.0, 0.17391304347826086, 0.3611111111111111, 0.9316666666666665, 1.0, 1.0, 0.09874500853428322, 1.0, 1.0, 0.09874500853428322, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2074211017715531, 0.20742110177155326, 0.32422550391363114], 
reward next is 0.6758, 
noisyNet noise sample is [array([-0.03823419], dtype=float32), 0.7666624]. 
=============================================
[2019-03-24 09:12:55,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1633238e-06 1.9039032e-06 4.6108620e-05 9.9991965e-01 2.9217805e-05], sum to 1.0000
[2019-03-24 09:12:55,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6632
[2019-03-24 09:12:55,614] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 93.16666666666667, 1.0, 2.0, 0.5346388118308578, 1.0, 2.0, 0.5346388118308578, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.6606223216235, 1219002.964172002, 1219002.964172001, 246410.2897314533], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3031800.0000, 
sim time next is 3032400.0000, 
raw observation next is [24.86666666666667, 93.33333333333334, 1.0, 2.0, 0.4636474421060826, 1.0, 2.0, 0.4636474421060826, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1057032.502036848, 1057032.502036848, 224369.2089882554], 
processed observation next is [1.0, 0.08695652173913043, 0.47654320987654336, 0.9333333333333335, 1.0, 1.0, 0.36148505012628884, 1.0, 1.0, 0.36148505012628884, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3775116078703029, 0.3775116078703029, 0.43147924805433735], 
reward next is 0.5685, 
noisyNet noise sample is [array([0.92152643], dtype=float32), -1.4059546]. 
=============================================
[2019-03-24 09:12:56,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1029650e-08 2.7971303e-09 1.2042045e-08 9.9999976e-01 2.5894133e-07], sum to 1.0000
[2019-03-24 09:12:56,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8798
[2019-03-24 09:12:56,514] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.63333333333333, 88.0, 1.0, 2.0, 0.2487571395361314, 1.0, 2.0, 0.2487571395361314, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 592180.4627395136, 592180.4627395141, 169804.4945090959], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3212400.0000, 
sim time next is 3213000.0000, 
raw observation next is [22.95, 85.0, 1.0, 2.0, 0.2465477726531298, 1.0, 2.0, 0.2465477726531298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 587745.9467729421, 587745.9467729426, 169340.3438518001], 
processed observation next is [0.0, 0.17391304347826086, 0.4055555555555555, 0.85, 1.0, 1.0, 0.10303306268229738, 1.0, 1.0, 0.10303306268229738, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20990926670462218, 0.20990926670462234, 0.3256545074073079], 
reward next is 0.6743, 
noisyNet noise sample is [array([-0.5880812], dtype=float32), -0.26911646]. 
=============================================
[2019-03-24 09:12:56,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.29295]
 [64.38939]
 [64.28265]
 [64.4635 ]
 [64.10123]], R is [[64.17629242]
 [64.20798492]
 [64.23844147]
 [64.26786041]
 [64.29628754]].
[2019-03-24 09:12:57,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1513603e-06 2.1796072e-06 1.7342669e-05 9.9997485e-01 2.5535662e-06], sum to 1.0000
[2019-03-24 09:12:57,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0848
[2019-03-24 09:12:57,311] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.3176703125610577, 1.0, 2.0, 0.3176703125610577, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724073.7752239255, 724073.7752239255, 184755.0362847617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [26.5, 76.5, 1.0, 2.0, 0.311568824536775, 1.0, 2.0, 0.311568824536775, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710160.061140504, 710160.061140504, 183259.8171699897], 
processed observation next is [1.0, 1.0, 0.5370370370370371, 0.765, 1.0, 1.0, 0.18043907682949403, 1.0, 1.0, 0.18043907682949403, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2536285932644657, 0.2536285932644657, 0.3524227253269033], 
reward next is 0.6476, 
noisyNet noise sample is [array([-1.193824], dtype=float32), -0.7745296]. 
=============================================
[2019-03-24 09:12:57,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.465813]
 [56.458035]
 [56.448963]
 [56.358257]
 [56.39338 ]], R is [[56.70453644]
 [56.78219604]
 [56.85730362]
 [56.93153   ]
 [57.00910568]].
[2019-03-24 09:13:05,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9146663e-07 1.8558497e-08 1.3867458e-06 9.9999762e-01 3.1452126e-07], sum to 1.0000
[2019-03-24 09:13:05,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2784
[2019-03-24 09:13:05,027] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.2786209381235858, 1.0, 2.0, 0.2786209381235858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 648990.7163362758, 648990.7163362763, 176088.2049696935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3284400.0000, 
sim time next is 3285000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.2785665577200376, 1.0, 2.0, 0.2785665577200376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 648856.3776503887, 648856.3776503892, 176075.1068848372], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.94, 1.0, 1.0, 0.14115066395242568, 1.0, 1.0, 0.14115066395242568, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23173442058942456, 0.23173442058942473, 0.3386059747785331], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.81998324], dtype=float32), -1.3398662]. 
=============================================
[2019-03-24 09:13:05,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.64397 ]
 [64.25376 ]
 [63.718845]
 [64.69858 ]
 [64.731346]], R is [[64.8356781 ]
 [64.84869385]
 [64.86174774]
 [64.87512207]
 [64.88962555]].
[2019-03-24 09:13:15,234] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 09:13:15,235] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:13:15,235] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:13:15,237] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:13:15,238] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:13:15,238] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:13:15,238] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:13:15,239] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:13:15,241] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:13:15,241] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:13:15,242] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:13:15,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-24 09:13:15,295] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-24 09:13:15,324] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-24 09:13:15,356] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-24 09:13:15,437] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-24 09:13:21,168] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:13:21,170] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 237077.0129642289, 237077.0129642293, 103664.6219306212]
[2019-03-24 09:13:21,171] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:13:21,174] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.9349084e-07 1.1173696e-06 3.3804029e-06 9.9999177e-01 2.8065469e-06], sampled 0.5985765178379487
[2019-03-24 09:13:23,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:13:23,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.8, 32.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393517.2915219301, 393517.2915219305, 149577.8177984919]
[2019-03-24 09:13:23,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:13:23,358] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2753095e-06 1.5687068e-06 4.7550584e-06 9.9998879e-01 3.5914702e-06], sampled 0.2759200145266365
[2019-03-24 09:13:35,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:13:35,511] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.5246158, 55.636963085, 1.0, 2.0, 0.1682828676186571, 1.0, 2.0, 0.1682828676186571, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434172.4494655349, 434172.4494655349, 150505.2386136722]
[2019-03-24 09:13:35,512] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:13:35,517] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5402436e-07 1.1956313e-06 3.6268209e-06 9.9999130e-01 2.9661101e-06], sampled 0.8234484726102171
[2019-03-24 09:14:10,392] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:14:10,394] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.50942346, 72.10432085, 1.0, 2.0, 0.2837489693663326, 1.0, 2.0, 0.2837489693663326, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655377.8376076053, 655377.8376076053, 177034.9767555071]
[2019-03-24 09:14:10,395] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:14:10,403] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9141034e-07 3.7444244e-07 1.2292479e-06 9.9999714e-01 9.6014992e-07], sampled 0.8723743258841887
[2019-03-24 09:14:55,476] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:14:55,477] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.61543822333334, 65.91185524000001, 1.0, 2.0, 0.682902694661074, 1.0, 2.0, 0.682902694661074, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1557403.082594987, 1557403.082594988, 297744.3848509055]
[2019-03-24 09:14:55,479] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:14:55,482] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0006501e-06 1.2296603e-06 3.7989323e-06 9.9999106e-01 2.9339221e-06], sampled 0.5041865306618049
[2019-03-24 09:15:18,805] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0107176], dtype=float32), 0.010034876]
[2019-03-24 09:15:18,807] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.11553416, 66.1324245, 1.0, 2.0, 0.1983778956112281, 1.0, 2.0, 0.1983778956112281, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489793.6984357364, 489793.6984357364, 159527.107620068]
[2019-03-24 09:15:18,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:15:18,812] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0271900e-07 3.8755365e-07 1.2997557e-06 9.9999714e-01 9.7829286e-07], sampled 0.4199310057864748
[2019-03-24 09:15:24,485] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:15:24,721] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.8574 2410747791.0600 22.0000
[2019-03-24 09:15:24,923] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:15:24,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668535969.8193 68.0000
[2019-03-24 09:15:25,001] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:15:26,019] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2000000, evaluation results [2000000.0, 7523.015860012835, 2668535969.8192725, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7796.857446334102, 2410747791.0600004, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:15:31,435] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1280800e-07 2.0964144e-06 2.1913193e-06 9.9997807e-01 1.6926399e-05], sum to 1.0000
[2019-03-24 09:15:31,446] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-24 09:15:31,454] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 80.66666666666667, 1.0, 2.0, 0.2908205383396563, 1.0, 2.0, 0.2908205383396563, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668813.3793637874, 668813.3793637878, 178569.3522259674], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3529200.0000, 
sim time next is 3529800.0000, 
raw observation next is [25.85, 79.0, 1.0, 2.0, 0.2937949322823112, 1.0, 2.0, 0.2937949322823112, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673755.4397561047, 673755.4397561047, 179184.5783926531], 
processed observation next is [1.0, 0.8695652173913043, 0.5129629629629631, 0.79, 1.0, 1.0, 0.1592796812884657, 1.0, 1.0, 0.1592796812884657, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2406269427700374, 0.2406269427700374, 0.344585727678179], 
reward next is 0.6554, 
noisyNet noise sample is [array([-0.8732515], dtype=float32), -0.2999222]. 
=============================================
[2019-03-24 09:15:36,454] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6523534e-07 2.3336125e-07 8.9492396e-06 9.9998605e-01 4.4663807e-06], sum to 1.0000
[2019-03-24 09:15:36,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9655
[2019-03-24 09:15:36,481] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7192349027023082, 1.0, 2.0, 0.7192349027023082, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1640340.784198347, 1640340.784198347, 311512.020842235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3683400.0000, 
sim time next is 3684000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7875316965399088, 1.0, 2.0, 0.7875316965399088, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1796260.151588602, 1796260.151588602, 338630.0698863224], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7470615434998915, 1.0, 1.0, 0.7470615434998915, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.641521482710215, 0.641521482710215, 0.6512116728583124], 
reward next is 0.3488, 
noisyNet noise sample is [array([-0.47615027], dtype=float32), -0.70229405]. 
=============================================
[2019-03-24 09:15:36,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.939835]
 [57.192715]
 [56.583504]
 [56.481136]
 [56.34911 ]], R is [[57.86112595]
 [57.68345642]
 [57.46743393]
 [57.19339752]
 [56.94210434]].
[2019-03-24 09:15:45,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.24075346e-08 1.34392293e-08 4.53742288e-08 9.99999881e-01
 1.62443030e-07], sum to 1.0000
[2019-03-24 09:15:45,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-24 09:15:45,193] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 98.0, 1.0, 2.0, 0.2928564566218659, 1.0, 2.0, 0.2928564566218659, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674440.0325265297, 674440.0325265302, 179099.389900885], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [23.0, 97.0, 1.0, 2.0, 0.2878472598145748, 1.0, 2.0, 0.2878472598145748, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664842.4853346068, 664842.4853346073, 178002.8504929005], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.97, 1.0, 1.0, 0.15219911882687479, 1.0, 1.0, 0.15219911882687479, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23744374476235958, 0.23744374476235974, 0.34231317402480865], 
reward next is 0.6577, 
noisyNet noise sample is [array([1.2094539], dtype=float32), -1.2037553]. 
=============================================
[2019-03-24 09:15:45,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0953157e-06 6.1866608e-06 4.0517007e-06 9.9997270e-01 1.4899412e-05], sum to 1.0000
[2019-03-24 09:15:45,291] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7018
[2019-03-24 09:15:45,301] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 99.16666666666666, 1.0, 2.0, 0.3042460256179407, 1.0, 2.0, 0.3042460256179407, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713060.6185037738, 713060.6185037743, 182403.0559999473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3653400.0000, 
sim time next is 3654000.0000, 
raw observation next is [22.0, 99.0, 1.0, 2.0, 0.2885142407086078, 1.0, 2.0, 0.2885142407086078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676689.7601664616, 676689.760166462, 178631.6717057329], 
processed observation next is [1.0, 0.30434782608695654, 0.37037037037037035, 0.99, 1.0, 1.0, 0.1529931437007236, 1.0, 1.0, 0.1529931437007236, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24167491434516486, 0.24167491434516503, 0.3435224455879479], 
reward next is 0.6565, 
noisyNet noise sample is [array([-0.05149643], dtype=float32), 0.5009199]. 
=============================================
[2019-03-24 09:15:45,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[58.154316]
 [58.235043]
 [58.287956]
 [58.360405]
 [58.3425  ]], R is [[58.14750671]
 [58.21525574]
 [58.28324509]
 [58.35622025]
 [58.42681885]].
[2019-03-24 09:15:52,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.49573125e-05 2.05725646e-05 8.33776357e-05 9.99871612e-01
 9.38596986e-06], sum to 1.0000
[2019-03-24 09:15:52,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-24 09:15:52,093] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.792302684070268, 1.0, 2.0, 0.792302684070268, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1807153.178588855, 1807153.178588856, 340586.6914028776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3762000.0000, 
sim time next is 3762600.0000, 
raw observation next is [32.13333333333333, 69.83333333333334, 1.0, 2.0, 0.8362155172739189, 1.0, 2.0, 0.8362155172739189, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1907420.35410313, 1907420.35410313, 358949.068781587], 
processed observation next is [1.0, 0.5652173913043478, 0.745679012345679, 0.6983333333333335, 1.0, 1.0, 0.8050184729451415, 1.0, 1.0, 0.8050184729451415, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6812215550368321, 0.6812215550368321, 0.6902866707338212], 
reward next is 0.3097, 
noisyNet noise sample is [array([0.5207746], dtype=float32), 1.2254976]. 
=============================================
[2019-03-24 09:15:52,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5771847e-07 2.6386533e-06 6.3109309e-07 9.9999583e-01 3.6243529e-07], sum to 1.0000
[2019-03-24 09:15:52,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9274
[2019-03-24 09:15:52,357] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 56.0, 1.0, 2.0, 0.3605364832568475, 1.0, 2.0, 0.3605364832568475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 821832.0740545136, 821832.074054514, 195623.7040109908], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3783600.0000, 
sim time next is 3784200.0000, 
raw observation next is [32.58333333333334, 59.66666666666667, 1.0, 2.0, 0.3611764478309185, 1.0, 2.0, 0.3611764478309185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823291.6375372442, 823291.6375372447, 195791.0883647208], 
processed observation next is [1.0, 0.8260869565217391, 0.7623456790123461, 0.5966666666666667, 1.0, 1.0, 0.23949577122728394, 1.0, 1.0, 0.23949577122728394, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29403272769187294, 0.2940327276918731, 0.37652132377830927], 
reward next is 0.6235, 
noisyNet noise sample is [array([0.21166612], dtype=float32), 0.22327103]. 
=============================================
[2019-03-24 09:15:54,227] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9012758e-08 8.2613496e-08 4.5483122e-07 9.9999881e-01 5.7088835e-07], sum to 1.0000
[2019-03-24 09:15:54,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6287
[2019-03-24 09:15:54,243] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.6, 68.33333333333334, 1.0, 2.0, 0.3885937657505354, 1.0, 2.0, 0.3885937657505354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885824.7655829461, 885824.7655829461, 203081.2734114358], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3872400.0000, 
sim time next is 3873000.0000, 
raw observation next is [30.25, 68.66666666666666, 1.0, 2.0, 0.3813725184775284, 1.0, 2.0, 0.3813725184775284, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 869354.1264120702, 869354.1264120707, 201135.5929982952], 
processed observation next is [0.0, 0.8260869565217391, 0.6759259259259259, 0.6866666666666665, 1.0, 1.0, 0.2635387124732481, 1.0, 1.0, 0.2635387124732481, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31048361657573936, 0.31048361657573953, 0.38679921730441386], 
reward next is 0.6132, 
noisyNet noise sample is [array([-0.3724902], dtype=float32), -0.403126]. 
=============================================
[2019-03-24 09:15:54,261] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.711796]
 [62.73201 ]
 [62.767883]
 [62.762093]
 [62.734806]], R is [[62.6823616 ]
 [62.6649971 ]
 [62.64590073]
 [62.62929535]
 [62.60707855]].
[2019-03-24 09:15:57,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9214816e-09 1.6239717e-06 2.9792810e-07 9.9999738e-01 5.7972454e-07], sum to 1.0000
[2019-03-24 09:15:57,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2356
[2019-03-24 09:15:57,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.76666666666667, 69.66666666666666, 1.0, 2.0, 0.3059439258737848, 1.0, 2.0, 0.3059439258737848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697333.375845435, 697333.3758454354, 181893.1091821365], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4308000.0000, 
sim time next is 4308600.0000, 
raw observation next is [27.38333333333333, 71.83333333333334, 1.0, 2.0, 0.3067404404846029, 1.0, 2.0, 0.3067404404846029, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699149.6874782931, 699149.6874782935, 182085.9773721225], 
processed observation next is [1.0, 0.8695652173913043, 0.569753086419753, 0.7183333333333334, 1.0, 1.0, 0.17469100057690823, 1.0, 1.0, 0.17469100057690823, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24969631695653324, 0.2496963169565334, 0.35016534110023556], 
reward next is 0.6498, 
noisyNet noise sample is [array([-0.24502437], dtype=float32), -1.3117791]. 
=============================================
[2019-03-24 09:16:00,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9876103e-07 1.2895964e-07 3.2215675e-07 9.9999928e-01 1.6023179e-07], sum to 1.0000
[2019-03-24 09:16:00,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5207
[2019-03-24 09:16:00,622] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.3321814406750336, 1.0, 2.0, 0.3321814406750336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757165.6828644498, 757165.6828644503, 188362.6344148548], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3974400.0000, 
sim time next is 3975000.0000, 
raw observation next is [25.96666666666667, 84.33333333333333, 1.0, 2.0, 0.3313795665949026, 1.0, 2.0, 0.3313795665949026, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755337.0115215193, 755337.0115215197, 188161.4001381274], 
processed observation next is [1.0, 0.0, 0.517283950617284, 0.8433333333333333, 1.0, 1.0, 0.20402329356536023, 1.0, 1.0, 0.20402329356536023, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2697632184005426, 0.2697632184005428, 0.3618488464194758], 
reward next is 0.6382, 
noisyNet noise sample is [array([-0.55755985], dtype=float32), 0.9908132]. 
=============================================
[2019-03-24 09:16:00,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[58.50519 ]
 [60.79666 ]
 [60.818687]
 [60.849873]
 [60.87716 ]], R is [[57.44438171]
 [57.50770187]
 [57.56949615]
 [57.62998962]
 [57.68958664]].
[2019-03-24 09:16:00,667] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4787411e-06 9.5004935e-07 2.2997621e-05 9.9995494e-01 1.9625601e-05], sum to 1.0000
[2019-03-24 09:16:00,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7085
[2019-03-24 09:16:00,685] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.83333333333334, 89.00000000000001, 1.0, 2.0, 0.2294902300080784, 1.0, 2.0, 0.2294902300080784, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553008.0292841573, 553008.0292841578, 165787.7510300792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4147800.0000, 
sim time next is 4148400.0000, 
raw observation next is [21.66666666666667, 90.0, 1.0, 2.0, 0.2281984110538373, 1.0, 2.0, 0.2281984110538373, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550300.089487275, 550300.0894872755, 165519.4468692088], 
processed observation next is [1.0, 0.0, 0.3580246913580249, 0.9, 1.0, 1.0, 0.08118858458790157, 1.0, 1.0, 0.08118858458790157, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19653574624545536, 0.19653574624545553, 0.3183066285946323], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.11007323], dtype=float32), -0.35350946]. 
=============================================
[2019-03-24 09:16:01,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3508298e-07 7.9604592e-07 5.9419376e-06 9.9999297e-01 1.2739807e-07], sum to 1.0000
[2019-03-24 09:16:01,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-24 09:16:01,374] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 70.0, 1.0, 2.0, 0.3831798111031647, 1.0, 2.0, 0.3831798111031647, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873476.2709364063, 873476.2709364063, 201621.2021070607], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3930000.0000, 
sim time next is 3930600.0000, 
raw observation next is [30.75, 70.0, 1.0, 2.0, 0.390980485469329, 1.0, 2.0, 0.390980485469329, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 891268.6120320054, 891268.6120320059, 203728.6205941667], 
processed observation next is [0.0, 0.4782608695652174, 0.6944444444444444, 0.7, 1.0, 1.0, 0.2749767684158679, 1.0, 1.0, 0.2749767684158679, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3183102185828591, 0.31831021858285924, 0.39178580883493597], 
reward next is 0.6082, 
noisyNet noise sample is [array([-0.8147077], dtype=float32), -0.15656707]. 
=============================================
[2019-03-24 09:16:02,503] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6057571e-07 6.4947994e-07 7.3787578e-07 9.9999738e-01 8.7296615e-07], sum to 1.0000
[2019-03-24 09:16:02,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8636
[2019-03-24 09:16:02,512] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 76.33333333333333, 1.0, 2.0, 0.3861558889666677, 1.0, 2.0, 0.3861558889666677, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880264.2753882443, 880264.2753882443, 202422.5631638777], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3955200.0000, 
sim time next is 3955800.0000, 
raw observation next is [29.15, 77.66666666666667, 1.0, 2.0, 0.3895984481728445, 1.0, 2.0, 0.3895984481728445, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 888116.3315116843, 888116.3315116848, 203353.5174868513], 
processed observation next is [0.0, 0.782608695652174, 0.6351851851851852, 0.7766666666666667, 1.0, 1.0, 0.27333148592005296, 1.0, 1.0, 0.27333148592005296, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3171844041113158, 0.317184404111316, 0.3910644567054833], 
reward next is 0.6089, 
noisyNet noise sample is [array([0.4890757], dtype=float32), -0.34721956]. 
=============================================
[2019-03-24 09:16:06,471] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8266064e-05 6.1761816e-06 5.8781479e-06 9.9992442e-01 3.5236008e-05], sum to 1.0000
[2019-03-24 09:16:06,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7378
[2019-03-24 09:16:06,483] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.85, 69.66666666666667, 1.0, 2.0, 0.6070593094855432, 1.0, 2.0, 0.6070593094855432, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1384281.085883972, 1384281.085883972, 270477.0817022741], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4103400.0000, 
sim time next is 4104000.0000, 
raw observation next is [28.0, 70.0, 1.0, 2.0, 0.6865654118336795, 1.0, 2.0, 0.6865654118336795, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1565764.682659113, 1565764.682659114, 299109.9764375976], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.7, 1.0, 1.0, 0.6268635855162851, 1.0, 1.0, 0.6268635855162851, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5592016723782547, 0.559201672378255, 0.5752114931492261], 
reward next is 0.4248, 
noisyNet noise sample is [array([-0.97415537], dtype=float32), 0.4917755]. 
=============================================
[2019-03-24 09:16:06,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.170063]
 [53.079166]
 [52.63877 ]
 [52.56033 ]
 [52.20418 ]], R is [[52.78227997]
 [52.73431015]
 [52.68032837]
 [52.57201385]
 [52.4750824 ]].
[2019-03-24 09:16:14,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2992571e-08 2.1215948e-05 4.3247214e-06 9.9997437e-01 2.7475055e-08], sum to 1.0000
[2019-03-24 09:16:14,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0695
[2019-03-24 09:16:14,072] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.13333333333333, 93.33333333333333, 1.0, 2.0, 0.2266553825151128, 1.0, 2.0, 0.2266553825151128, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547949.9132574586, 547949.9132574586, 165232.0882495497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4134000.0000, 
sim time next is 4134600.0000, 
raw observation next is [21.35, 92.0, 1.0, 2.0, 0.2277227033092495, 1.0, 2.0, 0.2277227033092495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550027.6961038889, 550027.6961038894, 165447.5254576444], 
processed observation next is [1.0, 0.8695652173913043, 0.3462962962962963, 0.92, 1.0, 1.0, 0.08062226584434466, 1.0, 1.0, 0.08062226584434466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19643846289424605, 0.1964384628942462, 0.3181683181877777], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.68903524], dtype=float32), -0.22481062]. 
=============================================
[2019-03-24 09:16:24,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7214974e-05 1.2014505e-05 1.1776664e-05 9.9986017e-01 9.8824807e-05], sum to 1.0000
[2019-03-24 09:16:24,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-24 09:16:24,146] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 79.0, 1.0, 2.0, 0.8447625853733975, 1.0, 2.0, 0.8447625853733975, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1926937.378732705, 1926937.378732705, 362598.4242492188], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.8541916411098828, 1.0, 2.0, 0.8541916411098828, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1948468.895747226, 1948468.895747226, 366656.469995575], 
processed observation next is [1.0, 0.43478260869565216, 0.5925925925925926, 0.79, 1.0, 1.0, 0.826418620368908, 1.0, 1.0, 0.826418620368908, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6958817484811521, 0.6958817484811521, 0.7051085961453366], 
reward next is 0.2949, 
noisyNet noise sample is [array([-0.1639747], dtype=float32), -0.38395262]. 
=============================================
[2019-03-24 09:16:24,152] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 09:16:24,156] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:16:24,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:16:24,157] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:16:24,158] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:16:24,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:16:24,161] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:16:24,161] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:16:24,161] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:16:24,162] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:16:24,164] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:16:24,192] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-24 09:16:24,222] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-24 09:16:24,256] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-24 09:16:24,289] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-24 09:16:24,315] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-24 09:17:55,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01071429], dtype=float32), 0.010095498]
[2019-03-24 09:17:55,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.71666666666667, 79.33333333333334, 1.0, 2.0, 0.6073478945005766, 1.0, 2.0, 0.6073478945005766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1384939.743048194, 1384939.743048195, 270577.3879877405]
[2019-03-24 09:17:55,422] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:17:55,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.4331106e-07 1.0934957e-06 3.6519411e-06 9.9999189e-01 2.4694014e-06], sampled 0.1101381111337636
[2019-03-24 09:18:32,633] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 09:18:32,648] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495473084.7055 47.0000
[2019-03-24 09:18:33,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:18:33,269] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668535969.8193 68.0000
[2019-03-24 09:18:33,452] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:18:34,470] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2025000, evaluation results [2025000.0, 7523.015860012835, 2668535969.8192725, 68.0, 7121.435945869477, 2438873699.591536, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495473084.7055235, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:18:34,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.393227]
 [51.17146 ]
 [51.35691 ]
 [51.143448]
 [51.06859 ]], R is [[51.42686844]
 [51.2152977 ]
 [51.03709412]
 [50.91850662]
 [50.782444  ]].
[2019-03-24 09:18:38,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7366772e-05 5.3110212e-05 1.6976055e-04 9.9733728e-01 2.4024276e-03], sum to 1.0000
[2019-03-24 09:18:38,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6568
[2019-03-24 09:18:38,837] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8044758816994408, 1.0, 2.0, 0.8044758816994408, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1834947.391278051, 1834947.391278051, 345606.9057546808], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4352400.0000, 
sim time next is 4353000.0000, 
raw observation next is [27.16666666666666, 79.00000000000001, 1.0, 2.0, 0.7710667694219615, 1.0, 2.0, 0.7710667694219615, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1758668.766787942, 1758668.766787942, 331943.4564692674], 
processed observation next is [1.0, 0.391304347826087, 0.5617283950617282, 0.7900000000000001, 1.0, 1.0, 0.7274604397880494, 1.0, 1.0, 0.7274604397880494, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6280959881385507, 0.6280959881385507, 0.6383528009024373], 
reward next is 0.3616, 
noisyNet noise sample is [array([-1.2152249], dtype=float32), 2.0167625]. 
=============================================
[2019-03-24 09:18:38,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[47.80584 ]
 [47.930664]
 [47.801914]
 [47.693092]
 [48.03122 ]], R is [[48.00150681]
 [47.85686493]
 [47.76109695]
 [47.67152786]
 [47.57292175]].
[2019-03-24 09:18:42,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6267318e-06 9.5954067e-07 8.1612698e-06 9.9997270e-01 1.2568970e-05], sum to 1.0000
[2019-03-24 09:18:42,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2170
[2019-03-24 09:18:42,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 74.0, 1.0, 2.0, 0.3160790792862805, 1.0, 2.0, 0.3160790792862805, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720445.1336096607, 720445.1336096607, 184364.1191620828], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4450200.0000, 
sim time next is 4450800.0000, 
raw observation next is [27.6, 74.0, 1.0, 2.0, 0.3208312097553843, 1.0, 2.0, 0.3208312097553843, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731281.922736915, 731281.9227369153, 185534.8805326145], 
processed observation next is [0.0, 0.5217391304347826, 0.5777777777777778, 0.74, 1.0, 1.0, 0.19146572589926705, 1.0, 1.0, 0.19146572589926705, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2611721152631839, 0.261172115263184, 0.3567978471781048], 
reward next is 0.6432, 
noisyNet noise sample is [array([-1.9197731], dtype=float32), 0.1473607]. 
=============================================
[2019-03-24 09:18:44,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5316614e-05 1.4199654e-05 2.8863882e-05 9.9990034e-01 3.1272637e-05], sum to 1.0000
[2019-03-24 09:18:44,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7703
[2019-03-24 09:18:44,344] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.46666666666667, 86.33333333333334, 1.0, 2.0, 0.5142862967701551, 1.0, 2.0, 0.5142862967701551, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1182968.073192579, 1182968.073192579, 240337.3097173183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4609200.0000, 
sim time next is 4609800.0000, 
raw observation next is [24.85, 87.0, 1.0, 2.0, 0.6117569017810373, 1.0, 2.0, 0.6117569017810373, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1395002.790011365, 1395002.790011365, 272107.6701738643], 
processed observation next is [1.0, 0.34782608695652173, 0.475925925925926, 0.87, 1.0, 1.0, 0.5378058354536157, 1.0, 1.0, 0.5378058354536157, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49821528214691607, 0.49821528214691607, 0.5232839811035852], 
reward next is 0.4767, 
noisyNet noise sample is [array([0.7796116], dtype=float32), -0.17712317]. 
=============================================
[2019-03-24 09:18:58,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8346213e-05 5.5725537e-05 1.9759102e-05 9.9948847e-01 4.1766639e-04], sum to 1.0000
[2019-03-24 09:18:58,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0742
[2019-03-24 09:18:58,425] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3410984146381097, 1.0, 2.0, 0.3410984146381097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777501.1082229668, 777501.1082229668, 190616.1161672849], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4993200.0000, 
sim time next is 4993800.0000, 
raw observation next is [25.8, 89.33333333333334, 1.0, 2.0, 0.3381515177945086, 1.0, 2.0, 0.3381515177945086, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770780.5622994883, 770780.5622994888, 189868.3912230673], 
processed observation next is [1.0, 0.8260869565217391, 0.5111111111111112, 0.8933333333333334, 1.0, 1.0, 0.21208514023155783, 1.0, 1.0, 0.21208514023155783, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2752787722498173, 0.27527877224981745, 0.36513152158282175], 
reward next is 0.6349, 
noisyNet noise sample is [array([0.12165253], dtype=float32), -0.24086738]. 
=============================================
[2019-03-24 09:19:16,403] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9843044e-06 9.2234332e-06 6.5273639e-06 9.9991047e-01 7.1861949e-05], sum to 1.0000
[2019-03-24 09:19:16,412] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6373
[2019-03-24 09:19:16,417] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6162990643231065, 1.0, 2.0, 0.6162990643231065, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1405369.886663242, 1405369.886663242, 273691.5737308633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4957800.0000, 
sim time next is 4958400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5881618249988446, 1.0, 2.0, 0.5881618249988446, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1341151.307517322, 1341151.307517323, 263993.1295547725], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5097164583319579, 1.0, 1.0, 0.5097164583319579, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.478982609827615, 0.4789826098276153, 0.5076790952976394], 
reward next is 0.4923, 
noisyNet noise sample is [array([-0.280755], dtype=float32), -0.690479]. 
=============================================
[2019-03-24 09:19:17,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3739674e-05 1.3963237e-05 6.9302873e-04 9.9911183e-01 1.5743617e-04], sum to 1.0000
[2019-03-24 09:19:17,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9543
[2019-03-24 09:19:17,595] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 73.0, 1.0, 2.0, 0.8296982028494392, 1.0, 2.0, 0.8296982028494392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1892538.509811252, 1892538.509811252, 356178.496235485], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5223600.0000, 
sim time next is 5224200.0000, 
raw observation next is [27.91666666666666, 74.0, 1.0, 2.0, 0.829959767100832, 1.0, 2.0, 0.829959767100832, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1893135.76921592, 1893135.769215919, 356289.4224539523], 
processed observation next is [1.0, 0.4782608695652174, 0.5895061728395059, 0.74, 1.0, 1.0, 0.7975711513105143, 1.0, 1.0, 0.7975711513105143, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6761199175771143, 0.676119917577114, 0.6851719662576006], 
reward next is 0.3148, 
noisyNet noise sample is [array([0.52233726], dtype=float32), 1.22129]. 
=============================================
[2019-03-24 09:19:20,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4795839e-07 5.6972471e-08 5.2640320e-07 9.9999881e-01 4.3088312e-07], sum to 1.0000
[2019-03-24 09:19:20,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5498
[2019-03-24 09:19:20,882] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.75, 95.0, 1.0, 2.0, 0.3600063595773819, 1.0, 2.0, 0.3600063595773819, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 820623.026166194, 820623.0261661945, 195484.9231375954], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5105400.0000, 
sim time next is 5106000.0000, 
raw observation next is [25.6, 96.0, 1.0, 2.0, 0.3590272304974046, 1.0, 2.0, 0.3590272304974046, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 818389.941068947, 818389.9410689474, 195229.7648908403], 
processed observation next is [0.0, 0.08695652173913043, 0.5037037037037038, 0.96, 1.0, 1.0, 0.2369371791635769, 1.0, 1.0, 0.2369371791635769, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2922821218103382, 0.29228212181033836, 0.37544185555930826], 
reward next is 0.6246, 
noisyNet noise sample is [array([0.97488856], dtype=float32), 0.43142158]. 
=============================================
[2019-03-24 09:19:20,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.9709  ]
 [61.608463]
 [61.81115 ]
 [61.747192]
 [62.283855]], R is [[61.55040359]
 [61.55896759]
 [61.5666008 ]
 [61.57305145]
 [61.57957458]].
[2019-03-24 09:19:22,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4122665e-06 1.0109492e-06 5.0810286e-06 9.9997890e-01 9.7029797e-06], sum to 1.0000
[2019-03-24 09:19:22,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-24 09:19:22,393] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4532235997497385, 1.0, 2.0, 0.4532235997497385, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1033251.99948536, 1033251.99948536, 221295.0467451048], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5197800.0000, 
sim time next is 5198400.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4343772819124808, 1.0, 2.0, 0.4343772819124808, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 990258.6994392334, 990258.6994392334, 215833.6751880792], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.3266396213243819, 1.0, 1.0, 0.3266396213243819, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35366382122829765, 0.35366382122829765, 0.4150647599770754], 
reward next is 0.5849, 
noisyNet noise sample is [array([0.483588], dtype=float32), -0.62828106]. 
=============================================
[2019-03-24 09:19:32,648] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 09:19:32,650] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:19:32,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:19:32,651] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:19:32,652] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:19:32,653] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:19:32,654] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:19:32,654] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:19:32,656] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:19:32,657] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:19:32,661] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:19:32,675] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-24 09:19:32,706] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-24 09:19:32,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-24 09:19:32,773] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-24 09:19:32,809] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-24 09:19:53,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01069856], dtype=float32), 0.010020807]
[2019-03-24 09:19:53,427] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [15.62136328, 89.98982110666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 319368.2553606791, 319368.2553606795, 126568.4708517275]
[2019-03-24 09:19:53,428] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:19:53,430] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9304600e-07 1.3124745e-06 4.9600999e-06 9.9998665e-01 6.0605557e-06], sampled 0.6241269191303485
[2019-03-24 09:21:30,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01069856], dtype=float32), 0.010020807]
[2019-03-24 09:21:30,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.60241365, 79.93633166333333, 1.0, 2.0, 0.1745924965639395, 1.0, 2.0, 0.1745924965639395, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436210.8209835797, 436210.8209835797, 154724.2132423385]
[2019-03-24 09:21:30,875] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:21:30,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5227649e-06 2.0280631e-06 7.3825358e-06 9.9998045e-01 8.6072787e-06], sampled 0.4863357878752824
[2019-03-24 09:21:41,511] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:21:41,573] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.8043 2438871231.1887 34.0000
[2019-03-24 09:21:41,784] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5695 2410701693.3535 22.0000
[2019-03-24 09:21:41,820] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.4338 2465963299.6497 46.0000
[2019-03-24 09:21:41,861] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:21:42,877] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2050000, evaluation results [2050000.0, 7523.727130323888, 2668527814.010175, 68.0, 7120.804329409758, 2438871231.1887355, 34.0, 7797.569468667964, 2410701693.353519, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.4337720958965, 2465963299.6497455, 46.0]
[2019-03-24 09:21:52,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9761682e-05 1.1186200e-05 1.1751143e-05 9.9990237e-01 3.4910652e-05], sum to 1.0000
[2019-03-24 09:21:52,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8538
[2019-03-24 09:21:52,122] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 80.16666666666667, 1.0, 2.0, 0.8132858043534812, 1.0, 2.0, 0.8132858043534812, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1855063.012390577, 1855063.012390577, 349274.7186285979], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5393400.0000, 
sim time next is 5394000.0000, 
raw observation next is [27.33333333333334, 79.33333333333334, 1.0, 2.0, 0.7709831927892987, 1.0, 2.0, 0.7709831927892987, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1758477.955441291, 1758477.955441291, 331909.9640816842], 
processed observation next is [1.0, 0.43478260869565216, 0.5679012345679014, 0.7933333333333334, 1.0, 1.0, 0.7273609437967842, 1.0, 1.0, 0.7273609437967842, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6280278412290325, 0.6280278412290325, 0.6382883924647773], 
reward next is 0.3617, 
noisyNet noise sample is [array([-0.7782948], dtype=float32), 0.1582224]. 
=============================================
[2019-03-24 09:21:52,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[47.01924 ]
 [47.741695]
 [48.041775]
 [48.130215]
 [48.02843 ]], R is [[47.003479  ]
 [46.861763  ]
 [46.80619049]
 [46.79884338]
 [46.79348373]].
[2019-03-24 09:21:54,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8316865e-07 5.6994674e-07 2.2150074e-07 9.9999893e-01 1.6132822e-07], sum to 1.0000
[2019-03-24 09:21:54,947] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6670
[2019-03-24 09:21:54,958] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 81.0, 1.0, 2.0, 0.3265930544401405, 1.0, 2.0, 0.3265930544401405, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744421.4761972738, 744421.4761972743, 186965.1027907452], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5508600.0000, 
sim time next is 5509200.0000, 
raw observation next is [26.83333333333333, 81.0, 1.0, 2.0, 0.3232798985901602, 1.0, 2.0, 0.3232798985901602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736865.9884393079, 736865.9884393084, 186141.4428356021], 
processed observation next is [1.0, 0.782608695652174, 0.5493827160493825, 0.81, 1.0, 1.0, 0.19438083165495262, 1.0, 1.0, 0.19438083165495262, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26316642444260996, 0.2631664244426101, 0.3579643131453886], 
reward next is 0.6420, 
noisyNet noise sample is [array([-0.31616688], dtype=float32), 0.2295119]. 
=============================================
[2019-03-24 09:21:56,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2866930e-06 1.8933140e-06 2.2922901e-05 9.9994504e-01 2.7949378e-05], sum to 1.0000
[2019-03-24 09:21:57,007] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9834
[2019-03-24 09:21:57,018] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.43333333333334, 94.16666666666667, 1.0, 2.0, 0.4536006951017007, 1.0, 2.0, 0.4536006951017007, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1034112.275624715, 1034112.275624716, 221407.7631467796], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5464200.0000, 
sim time next is 5464800.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.4876290285802897, 1.0, 2.0, 0.4876290285802897, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1111745.857355249, 1111745.857355249, 231584.8697828028], 
processed observation next is [1.0, 0.2608695652173913, 0.5370370370370371, 0.94, 1.0, 1.0, 0.3900345578336783, 1.0, 1.0, 0.3900345578336783, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.39705209191258894, 0.39705209191258894, 0.4453555188130823], 
reward next is 0.5546, 
noisyNet noise sample is [array([-0.10594399], dtype=float32), -2.0587099]. 
=============================================
[2019-03-24 09:22:05,579] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4706702e-06 1.7803459e-05 6.8400368e-05 9.9986017e-01 4.4177508e-05], sum to 1.0000
[2019-03-24 09:22:05,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7041
[2019-03-24 09:22:05,597] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333334, 83.0, 1.0, 2.0, 0.8968199228959979, 1.0, 2.0, 0.8968199228959979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2045818.269090997, 2045818.269090997, 385386.5695341372], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5586000.0000, 
sim time next is 5586600.0000, 
raw observation next is [27.11666666666667, 84.0, 1.0, 2.0, 0.8826360308422673, 1.0, 2.0, 0.8826360308422673, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2013425.614152477, 2013425.614152476, 379084.3986163717], 
processed observation next is [1.0, 0.6521739130434783, 0.5598765432098767, 0.84, 1.0, 1.0, 0.8602809890979373, 1.0, 1.0, 0.8602809890979373, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7190805764830275, 0.7190805764830271, 0.7290084588776379], 
reward next is 0.2710, 
noisyNet noise sample is [array([0.21418536], dtype=float32), 0.2591528]. 
=============================================
[2019-03-24 09:22:28,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4013652e-09 4.3007162e-08 2.3989529e-07 9.9999964e-01 1.4210045e-07], sum to 1.0000
[2019-03-24 09:22:28,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-24 09:22:28,318] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 61.0, 1.0, 2.0, 0.2771368897233602, 1.0, 2.0, 0.2771368897233602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 640243.2767373045, 640243.276737305, 175492.2909442825], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6115200.0000, 
sim time next is 6115800.0000, 
raw observation next is [28.35, 61.5, 1.0, 2.0, 0.2766924448677187, 1.0, 2.0, 0.2766924448677187, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639820.8303352107, 639820.8303352107, 175417.6466886097], 
processed observation next is [1.0, 0.782608695652174, 0.6055555555555556, 0.615, 1.0, 1.0, 0.13891957722347467, 1.0, 1.0, 0.13891957722347467, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2285074394054324, 0.2285074394054324, 0.33734162824732633], 
reward next is 0.6627, 
noisyNet noise sample is [array([0.31475288], dtype=float32), -0.7824825]. 
=============================================
[2019-03-24 09:22:31,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2617918e-05 1.8774315e-07 8.0189930e-05 9.9989092e-01 5.9072236e-06], sum to 1.0000
[2019-03-24 09:22:31,517] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5164
[2019-03-24 09:22:31,526] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.2204845438953651, 1.0, 2.0, 0.2204845438953651, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538973.3208254572, 538973.3208254577, 164093.1219435298], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5990400.0000, 
sim time next is 5991000.0000, 
raw observation next is [23.28333333333334, 72.83333333333334, 1.0, 2.0, 0.2509361285193052, 1.0, 2.0, 0.2509361285193052, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611965.2054617658, 611965.2054617661, 170828.2383142925], 
processed observation next is [1.0, 0.34782608695652173, 0.4179012345679014, 0.7283333333333334, 1.0, 1.0, 0.1082572958563157, 1.0, 1.0, 0.1082572958563157, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21855900195063063, 0.21855900195063074, 0.328515842912101], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.87317204], dtype=float32), -0.05415717]. 
=============================================
[2019-03-24 09:22:31,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[58.11726 ]
 [58.029327]
 [57.97382 ]
 [57.854763]
 [57.77983 ]], R is [[58.26499939]
 [58.36678696]
 [58.46722794]
 [58.56388474]
 [58.64840317]].
[2019-03-24 09:22:34,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0909606e-07 7.8737185e-07 1.2602402e-06 9.9999738e-01 5.3574865e-07], sum to 1.0000
[2019-03-24 09:22:34,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7791
[2019-03-24 09:22:34,547] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 66.0, 1.0, 2.0, 0.3023749448209896, 1.0, 2.0, 0.3023749448209896, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 691027.4235407024, 691027.4235407029, 181123.3168331979], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6292800.0000, 
sim time next is 6293400.0000, 
raw observation next is [27.91666666666667, 66.83333333333333, 1.0, 2.0, 0.3009843129685644, 1.0, 2.0, 0.3009843129685644, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688405.3955770556, 688405.3955770556, 180816.2181433369], 
processed observation next is [0.0, 0.8695652173913043, 0.5895061728395063, 0.6683333333333333, 1.0, 1.0, 0.16783846781971956, 1.0, 1.0, 0.16783846781971956, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24585906984894845, 0.24585906984894845, 0.34772349642949407], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.50885534], dtype=float32), -0.42399058]. 
=============================================
[2019-03-24 09:22:40,952] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 09:22:40,955] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:22:40,956] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:22:40,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:22:40,960] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:22:40,961] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:22:40,961] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:22:40,963] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:22:40,964] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:22:40,964] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:22:40,965] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:22:40,989] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-24 09:22:41,023] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-24 09:22:41,052] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-24 09:22:41,085] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-24 09:22:41,086] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-24 09:23:26,089] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01073807], dtype=float32), 0.010169835]
[2019-03-24 09:23:26,090] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.08600063, 42.99215554, 1.0, 2.0, 0.233265812387814, 1.0, 2.0, 0.233265812387814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 555135.4301189111, 555135.4301189114, 166344.8909532171]
[2019-03-24 09:23:26,093] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:23:26,096] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1402762e-07 2.4146556e-07 1.0980909e-06 9.9999797e-01 4.6688857e-07], sampled 0.1639586698185762
[2019-03-24 09:24:14,085] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01073807], dtype=float32), 0.010169835]
[2019-03-24 09:24:14,086] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.56666666666667, 74.0, 1.0, 2.0, 0.3656250037166868, 1.0, 2.0, 0.3656250037166868, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 833437.5098906177, 833437.5098906177, 196956.0634177587]
[2019-03-24 09:24:14,090] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:24:14,092] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8792147e-07 2.1002258e-07 9.8404121e-07 9.9999821e-01 4.0981209e-07], sampled 0.18737559519499503
[2019-03-24 09:24:32,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01073807], dtype=float32), 0.010169835]
[2019-03-24 09:24:32,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.21734042333333, 81.07738061333333, 1.0, 2.0, 0.2029863397385657, 1.0, 2.0, 0.2029863397385657, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495772.5447219263, 495772.5447219268, 160331.40497128]
[2019-03-24 09:24:32,709] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:24:32,712] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3091194e-07 1.4777419e-07 6.9748791e-07 9.9999869e-01 3.1584412e-07], sampled 0.4224942200846278
[2019-03-24 09:24:32,925] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01073807], dtype=float32), 0.010169835]
[2019-03-24 09:24:32,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.72843615, 46.43091883, 1.0, 2.0, 0.2595484517626148, 1.0, 2.0, 0.2595484517626148, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 609031.2947159089, 609031.2947159094, 171884.6763293954]
[2019-03-24 09:24:32,928] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:24:32,930] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8747431e-07 2.1120378e-07 9.7136319e-07 9.9999809e-01 4.1765102e-07], sampled 0.6063529355896795
[2019-03-24 09:24:49,126] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:24:49,187] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:24:49,388] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01073807], dtype=float32), 0.010169835]
[2019-03-24 09:24:49,389] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.01666666666667, 56.0, 1.0, 2.0, 0.5097055170495033, 1.0, 2.0, 0.5097055170495033, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1215250.059734265, 1215250.059734266, 240720.4813027705]
[2019-03-24 09:24:49,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:24:49,392] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.3679568e-07 6.9325802e-07 2.9492967e-06 9.9999440e-01 1.3447324e-06], sampled 0.8820780415895129
[2019-03-24 09:24:49,666] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:24:49,719] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.2751 2668554704.7676 68.0000
[2019-03-24 09:24:49,793] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.6057 2410682814.8906 22.0000
[2019-03-24 09:24:50,810] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2075000, evaluation results [2075000.0, 7523.2750670534115, 2668554704.7676306, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.60570358432, 2410682814.8906136, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:24:57,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0632679e-06 4.0997661e-06 4.2656766e-06 9.9981922e-01 1.7041380e-04], sum to 1.0000
[2019-03-24 09:24:57,967] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-24 09:24:57,971] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.43333333333333, 80.0, 1.0, 2.0, 0.9465707180470624, 1.0, 2.0, 0.9465707180470624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2159446.609207193, 2159446.609207193, 408042.8450297462], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6518400.0000, 
sim time next is 6519000.0000, 
raw observation next is [28.56666666666667, 79.5, 1.0, 2.0, 0.9580145457805611, 1.0, 2.0, 0.9580145457805611, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2185585.787966154, 2185585.787966155, 413375.5863444642], 
processed observation next is [1.0, 0.43478260869565216, 0.6135802469135804, 0.795, 1.0, 1.0, 0.9500173164054299, 1.0, 1.0, 0.9500173164054299, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.780566352845055, 0.7805663528450554, 0.7949530506624312], 
reward next is 0.2050, 
noisyNet noise sample is [array([-1.2109396], dtype=float32), -0.81640923]. 
=============================================
[2019-03-24 09:24:57,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[49.93927 ]
 [49.843422]
 [49.862236]
 [49.813198]
 [49.31898 ]], R is [[49.78810501]
 [49.5055275 ]
 [49.23387909]
 [49.0151062 ]
 [48.8102684 ]].
[2019-03-24 09:25:09,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1382965e-06 8.0764124e-07 1.2986669e-06 9.9999642e-01 3.6109552e-07], sum to 1.0000
[2019-03-24 09:25:09,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-24 09:25:09,745] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 28.0, 1.0, 2.0, 0.497632165375775, 1.0, 2.0, 0.497632165375775, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1240033.062404974, 1240033.062404974, 238505.5471571803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6707400.0000, 
sim time next is 6708000.0000, 
raw observation next is [30.06666666666667, 28.0, 1.0, 2.0, 0.4999844101057944, 1.0, 2.0, 0.4999844101057944, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1244094.785313046, 1244094.785313046, 239213.9890886352], 
processed observation next is [1.0, 0.6521739130434783, 0.669135802469136, 0.28, 1.0, 1.0, 0.40474334536404094, 1.0, 1.0, 0.40474334536404094, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.44431956618323076, 0.44431956618323076, 0.4600269020935292], 
reward next is 0.5400, 
noisyNet noise sample is [array([-0.9560623], dtype=float32), 0.99535793]. 
=============================================
[2019-03-24 09:25:09,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.90715 ]
 [58.285114]
 [58.43552 ]
 [58.412086]
 [58.114517]], R is [[57.86024857]
 [57.82298279]
 [57.8252182 ]
 [57.8494072 ]
 [57.87201691]].
[2019-03-24 09:25:10,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.31566943e-07 1.24071784e-08 2.08966693e-08 9.99999762e-01
 1.26386235e-08], sum to 1.0000
[2019-03-24 09:25:10,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0139
[2019-03-24 09:25:10,300] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.3, 79.33333333333334, 1.0, 2.0, 0.2108022123910465, 1.0, 2.0, 0.2108022123910465, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514719.3723218971, 514719.3723218975, 161986.7895341069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6922200.0000, 
sim time next is 6922800.0000, 
raw observation next is [22.2, 80.0, 1.0, 2.0, 0.2104875587781755, 1.0, 2.0, 0.2104875587781755, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514015.9767045443, 514015.9767045448, 161921.6892760701], 
processed observation next is [0.0, 0.13043478260869565, 0.37777777777777777, 0.8, 1.0, 1.0, 0.0601042366406851, 1.0, 1.0, 0.0601042366406851, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18357713453733723, 0.18357713453733743, 0.3113878639924425], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.31737006], dtype=float32), -2.0138848]. 
=============================================
[2019-03-24 09:25:12,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7810868e-07 4.2772572e-06 6.9878629e-06 9.9998689e-01 1.2025123e-06], sum to 1.0000
[2019-03-24 09:25:12,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4008
[2019-03-24 09:25:12,403] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 81.33333333333333, 1.0, 2.0, 0.6277591503975307, 1.0, 2.0, 0.6277591503975307, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 123.2854536021489, 1431512.422288452, 1431512.422288451, 277925.6647328827], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6487800.0000, 
sim time next is 6488400.0000, 
raw observation next is [26.83333333333333, 81.66666666666667, 1.0, 2.0, 0.6325301342962425, 1.0, 2.0, 0.6325301342962425, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9306092419456, 1442417.008452989, 1442417.008452989, 279412.8900521583], 
processed observation next is [1.0, 0.08695652173913043, 0.5493827160493825, 0.8166666666666668, 1.0, 1.0, 0.5625358741621934, 1.0, 1.0, 0.5625358741621934, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094924464697038, 0.5151489315903532, 0.5151489315903532, 0.5373324808695352], 
reward next is 0.4627, 
noisyNet noise sample is [array([-0.15047252], dtype=float32), 0.46232048]. 
=============================================
[2019-03-24 09:25:13,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6822021e-07 1.3787746e-06 1.1748573e-04 9.9987674e-01 3.3236345e-06], sum to 1.0000
[2019-03-24 09:25:13,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6740
[2019-03-24 09:25:13,191] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.96666666666667, 54.33333333333334, 1.0, 2.0, 0.9036171618711448, 1.0, 2.0, 0.9036171618711448, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2061341.971837416, 2061341.971837416, 388430.7706766648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6448800.0000, 
sim time next is 6449400.0000, 
raw observation next is [31.9, 54.5, 1.0, 2.0, 0.9130755429968318, 1.0, 2.0, 0.9130755429968318, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2082943.705993498, 2082943.705993498, 392694.2090510018], 
processed observation next is [1.0, 0.6521739130434783, 0.7370370370370369, 0.545, 1.0, 1.0, 0.8965185035676569, 1.0, 1.0, 0.8965185035676569, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7439084664262493, 0.7439084664262493, 0.7551811712519265], 
reward next is 0.2448, 
noisyNet noise sample is [array([-1.1017809], dtype=float32), 1.3782787]. 
=============================================
[2019-03-24 09:25:15,518] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8815629e-07 1.1811809e-06 4.6014843e-06 9.9999380e-01 1.9900138e-07], sum to 1.0000
[2019-03-24 09:25:15,528] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3107
[2019-03-24 09:25:15,536] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 42.0, 1.0, 2.0, 0.1773739706501192, 1.0, 2.0, 0.1773739706501192, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439796.3140195701, 439796.3140195706, 155209.4907344814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6631200.0000, 
sim time next is 6631800.0000, 
raw observation next is [27.71666666666667, 43.0, 1.0, 2.0, 0.1806927606812779, 1.0, 2.0, 0.1806927606812779, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 447703.3370479856, 447703.337047986, 155887.0317263588], 
processed observation next is [1.0, 0.782608695652174, 0.5820987654320988, 0.43, 1.0, 1.0, 0.024634238906283214, 1.0, 1.0, 0.024634238906283214, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15989404894570913, 0.15989404894570927, 0.29978275331992077], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.29755637], dtype=float32), 0.19868891]. 
=============================================
[2019-03-24 09:25:18,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6233948e-08 2.7241299e-08 1.6860339e-07 9.9999976e-01 1.4341937e-08], sum to 1.0000
[2019-03-24 09:25:18,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-24 09:25:18,425] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.75, 78.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403067.0174476473, 403067.0174476473, 151591.680182148], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6744600.0000, 
sim time next is 6745200.0000, 
raw observation next is [19.66666666666667, 78.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401057.4183778493, 401057.4183778493, 151268.1534963652], 
processed observation next is [1.0, 0.043478260869565216, 0.28395061728395077, 0.7833333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1432347922778033, 0.1432347922778033, 0.2909002951853177], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74465], dtype=float32), 0.9731833]. 
=============================================
[2019-03-24 09:25:19,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4623881e-07 4.0504480e-09 2.4211774e-08 9.9999976e-01 2.6760864e-08], sum to 1.0000
[2019-03-24 09:25:19,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3190
[2019-03-24 09:25:19,117] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.56666666666667, 80.5, 1.0, 2.0, 0.3281995521979469, 1.0, 2.0, 0.3281995521979469, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748085.0415462992, 748085.0415462992, 187366.3975377589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6544200.0000, 
sim time next is 6544800.0000, 
raw observation next is [27.5, 81.0, 1.0, 2.0, 0.3313118317129013, 1.0, 2.0, 0.3313118317129013, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755182.5425338431, 755182.5425338435, 188145.3039700213], 
processed observation next is [1.0, 0.782608695652174, 0.5740740740740741, 0.81, 1.0, 1.0, 0.20394265680107299, 1.0, 1.0, 0.20394265680107299, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26970805090494393, 0.2697080509049441, 0.36181789225004096], 
reward next is 0.6382, 
noisyNet noise sample is [array([-0.9253658], dtype=float32), 0.67951715]. 
=============================================
[2019-03-24 09:25:27,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.92034815e-07 2.18452627e-07 6.01204420e-08 9.99999046e-01
 1.04199685e-07], sum to 1.0000
[2019-03-24 09:25:27,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-24 09:25:27,375] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.83333333333334, 76.0, 1.0, 2.0, 0.1903000447335529, 1.0, 2.0, 0.1903000447335529, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470924.6257695954, 470924.6257695958, 157873.7041589759], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6841200.0000, 
sim time next is 6841800.0000, 
raw observation next is [21.8, 76.0, 1.0, 2.0, 0.1895393119438745, 1.0, 2.0, 0.1895393119438745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469256.3173579842, 469256.3173579842, 157722.1621157174], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.76, 1.0, 1.0, 0.03516584755223154, 1.0, 1.0, 0.03516584755223154, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1675915419135658, 0.1675915419135658, 0.30331185022253343], 
reward next is 0.6967, 
noisyNet noise sample is [array([0.6659275], dtype=float32), -2.0500832]. 
=============================================
[2019-03-24 09:25:34,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2928158e-06 2.5685888e-06 2.3268612e-05 9.9996984e-01 9.0611610e-07], sum to 1.0000
[2019-03-24 09:25:34,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1330
[2019-03-24 09:25:34,113] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.23333333333333, 76.0, 1.0, 2.0, 0.1996385414215663, 1.0, 2.0, 0.1996385414215663, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491248.1382039285, 491248.1382039289, 159743.4864197269], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6835800.0000, 
sim time next is 6836400.0000, 
raw observation next is [22.2, 76.0, 1.0, 2.0, 0.1992277792273941, 1.0, 2.0, 0.1992277792273941, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 490464.6124409721, 490464.6124409726, 159664.0093865196], 
processed observation next is [0.0, 0.13043478260869565, 0.37777777777777777, 0.76, 1.0, 1.0, 0.04669973717546916, 1.0, 1.0, 0.04669973717546916, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1751659330146329, 0.17516593301463307, 0.3070461718971531], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.4820778], dtype=float32), -1.1130978]. 
=============================================
[2019-03-24 09:25:36,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8751148e-09 4.3816951e-07 1.5845017e-06 9.9999738e-01 6.0109136e-07], sum to 1.0000
[2019-03-24 09:25:36,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2597
[2019-03-24 09:25:36,782] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.204010205497159, 1.0, 2.0, 0.204010205497159, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500548.7658228264, 500548.7658228268, 160621.2213133244], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6909600.0000, 
sim time next is 6910200.0000, 
raw observation next is [23.45, 69.5, 1.0, 2.0, 0.2044239682071305, 1.0, 2.0, 0.2044239682071305, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 501373.0894758395, 501373.0894758399, 160702.8232106985], 
processed observation next is [0.0, 1.0, 0.42407407407407405, 0.695, 1.0, 1.0, 0.0528856764370601, 1.0, 1.0, 0.0528856764370601, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1790618176699427, 0.17906181766994284, 0.3090438907898048], 
reward next is 0.6910, 
noisyNet noise sample is [array([0.75990313], dtype=float32), -0.99488175]. 
=============================================
[2019-03-24 09:25:36,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5512773e-08 5.0126658e-09 3.2286118e-07 9.9999964e-01 1.0810179e-08], sum to 1.0000
[2019-03-24 09:25:36,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3230
[2019-03-24 09:25:36,959] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.36666666666667, 76.0, 1.0, 2.0, 0.2018663851711263, 1.0, 2.0, 0.2018663851711263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495756.899390744, 495756.8993907445, 160182.9616826702], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6833400.0000, 
sim time next is 6834000.0000, 
raw observation next is [22.33333333333333, 76.0, 1.0, 2.0, 0.2009603779826546, 1.0, 2.0, 0.2009603779826546, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493796.233813374, 493796.2338133745, 160000.1982422185], 
processed observation next is [0.0, 0.08695652173913043, 0.38271604938271586, 0.76, 1.0, 1.0, 0.04876235474125547, 1.0, 1.0, 0.04876235474125547, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1763557977904907, 0.17635579779049088, 0.30769268892734325], 
reward next is 0.6923, 
noisyNet noise sample is [array([-0.17994736], dtype=float32), -1.6175561]. 
=============================================
[2019-03-24 09:25:36,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.709206]
 [69.261284]
 [69.64126 ]
 [69.41856 ]
 [69.24905 ]], R is [[68.93161774]
 [68.93425751]
 [68.93641663]
 [68.93772888]
 [68.93810272]].
[2019-03-24 09:25:42,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5082017e-08 1.9419412e-08 1.7790481e-07 9.9999976e-01 9.7394715e-09], sum to 1.0000
[2019-03-24 09:25:42,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4220
[2019-03-24 09:25:42,534] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.4, 72.0, 1.0, 2.0, 0.2103981168122991, 1.0, 2.0, 0.2103981168122991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513485.3730679285, 513485.3730679289, 161892.2062187637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7236000.0000, 
sim time next is 7236600.0000, 
raw observation next is [23.31666666666667, 72.33333333333333, 1.0, 2.0, 0.2109884775760158, 1.0, 2.0, 0.2109884775760158, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515120.5782043816, 515120.5782043821, 162024.8366659265], 
processed observation next is [1.0, 0.782608695652174, 0.4191358024691359, 0.7233333333333333, 1.0, 1.0, 0.06070056854287595, 1.0, 1.0, 0.06070056854287595, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18397163507299344, 0.1839716350729936, 0.31158622435755096], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.24532765], dtype=float32), -0.24216177]. 
=============================================
[2019-03-24 09:25:44,233] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7763224e-08 3.4082634e-09 1.5129142e-07 9.9999976e-01 5.7546630e-09], sum to 1.0000
[2019-03-24 09:25:44,242] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-24 09:25:44,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.85, 69.5, 1.0, 2.0, 0.6000804875665868, 1.0, 2.0, 0.6000804875665868, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1397779.927777225, 1397779.927777225, 269472.7719592234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7039800.0000, 
sim time next is 7040400.0000, 
raw observation next is [26.03333333333333, 68.66666666666667, 1.0, 2.0, 0.6188557680209995, 1.0, 2.0, 0.6188557680209995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1439887.643367727, 1439887.643367728, 275967.6605237674], 
processed observation next is [1.0, 0.4782608695652174, 0.519753086419753, 0.6866666666666668, 1.0, 1.0, 0.5462568666916661, 1.0, 1.0, 0.5462568666916661, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5142455869170454, 0.5142455869170457, 0.5307070394687835], 
reward next is 0.4693, 
noisyNet noise sample is [array([0.3649048], dtype=float32), 1.2923974]. 
=============================================
[2019-03-24 09:25:48,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9123828e-07 6.4908917e-08 2.7022026e-07 9.9999881e-01 1.6104618e-08], sum to 1.0000
[2019-03-24 09:25:48,284] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4743
[2019-03-24 09:25:48,295] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.61666666666667, 79.83333333333334, 1.0, 2.0, 0.242732677101595, 1.0, 2.0, 0.242732677101595, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579368.7097897033, 579368.7097897033, 168513.6909849323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7066200.0000, 
sim time next is 7066800.0000, 
raw observation next is [23.6, 80.0, 1.0, 2.0, 0.2429079729320346, 1.0, 2.0, 0.2429079729320346, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579720.0812891101, 579720.0812891105, 168550.2179644856], 
processed observation next is [1.0, 0.8260869565217391, 0.4296296296296297, 0.8, 1.0, 1.0, 0.09869996777623165, 1.0, 1.0, 0.09869996777623165, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2070428861746822, 0.2070428861746823, 0.3241350345470877], 
reward next is 0.6759, 
noisyNet noise sample is [array([0.8986924], dtype=float32), 0.43904454]. 
=============================================
[2019-03-24 09:25:48,992] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 09:25:48,993] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:25:48,994] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:25:48,994] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:25:49,000] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:25:49,002] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:25:49,005] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:25:49,005] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:25:49,006] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:25:49,007] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:25:49,008] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:25:49,031] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-24 09:25:49,064] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-24 09:25:49,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-24 09:25:49,125] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-24 09:25:49,126] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-24 09:26:04,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:26:04,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 65.0, 1.0, 2.0, 0.181575146821493, 1.0, 2.0, 0.181575146821493, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 452377.4879362345, 452377.4879362349, 156138.2452197802]
[2019-03-24 09:26:04,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:26:04,138] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5467266e-08 4.8436597e-08 1.6704786e-07 9.9999976e-01 4.2814339e-08], sampled 0.2311082845682274
[2019-03-24 09:26:08,308] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:26:08,309] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.4, 67.0, 1.0, 2.0, 0.2478983197343411, 1.0, 2.0, 0.2478983197343411, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 630711.6436112695, 630711.6436112691, 170689.5133798204]
[2019-03-24 09:26:08,310] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:26:08,313] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.8176244e-08 7.7964764e-08 2.6260062e-07 9.9999940e-01 7.0013911e-08], sampled 0.07837226450782098
[2019-03-24 09:26:19,740] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:26:19,744] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.95, 93.5, 1.0, 2.0, 0.2600105324767089, 1.0, 2.0, 0.2600105324767089, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 629129.5711450999, 629129.5711451004, 172746.5027831187]
[2019-03-24 09:26:19,746] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:26:19,749] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0646394e-08 4.1489884e-08 1.4811356e-07 9.9999988e-01 3.6403073e-08], sampled 0.5923529947071403
[2019-03-24 09:27:03,501] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:27:03,502] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.4, 86.33333333333334, 1.0, 2.0, 0.3044764936912833, 1.0, 2.0, 0.3044764936912833, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693987.1658292125, 693987.1658292125, 181538.528760609]
[2019-03-24 09:27:03,503] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:27:03,506] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5047804e-08 3.3943696e-08 1.2283003e-07 9.9999988e-01 2.9519606e-08], sampled 0.1688895801682717
[2019-03-24 09:27:20,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:27:20,099] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.33325064333334, 80.08258262333334, 1.0, 2.0, 0.3399088758999683, 1.0, 2.0, 0.3399088758999683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774788.2984297017, 774788.2984297022, 190314.0291545091]
[2019-03-24 09:27:20,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:27:20,104] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0221423e-08 5.3347371e-08 1.8897366e-07 9.9999976e-01 4.6298638e-08], sampled 0.35906464920441994
[2019-03-24 09:27:30,531] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:27:30,533] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.4, 93.0, 1.0, 2.0, 0.2516483976920437, 1.0, 2.0, 0.2516483976920437, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 594493.6864306072, 594493.6864306076, 170267.4978138155]
[2019-03-24 09:27:30,535] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:27:30,539] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7158115e-08 2.3738270e-08 8.8333401e-08 9.9999988e-01 2.0336396e-08], sampled 0.10278746986782716
[2019-03-24 09:27:39,945] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01081621], dtype=float32), 0.010330895]
[2019-03-24 09:27:39,947] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.76666666666667, 56.66666666666667, 1.0, 2.0, 0.2215471852758275, 1.0, 2.0, 0.2215471852758275, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534728.0280825003, 534728.0280825008, 164086.6611475502]
[2019-03-24 09:27:39,948] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:27:39,951] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1896029e-08 4.3537035e-08 1.5231232e-07 9.9999976e-01 3.8130736e-08], sampled 0.7054835320642093
[2019-03-24 09:27:57,221] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438873699.5915 34.0000
[2019-03-24 09:27:57,439] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:27:57,702] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:27:57,729] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:27:57,962] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:27:58,979] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2100000, evaluation results [2100000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438873699.591536, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:28:00,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0294514e-09 4.6012776e-09 7.1238935e-09 1.0000000e+00 1.4971963e-09], sum to 1.0000
[2019-03-24 09:28:00,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8088
[2019-03-24 09:28:00,777] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 71.0, 1.0, 2.0, 0.207938054457008, 1.0, 2.0, 0.207938054457008, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507119.8777894293, 507119.8777894298, 161355.6062171143], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7234200.0000, 
sim time next is 7234800.0000, 
raw observation next is [23.53333333333333, 71.33333333333334, 1.0, 2.0, 0.2091241699916979, 1.0, 2.0, 0.2091241699916979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510172.9771919238, 510172.9771919243, 161613.5501847756], 
processed observation next is [1.0, 0.7391304347826086, 0.4271604938271604, 0.7133333333333334, 1.0, 1.0, 0.05848115475202129, 1.0, 1.0, 0.05848115475202129, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18220463471140136, 0.18220463471140153, 0.3107952888168762], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.28026453], dtype=float32), 1.7227185]. 
=============================================
[2019-03-24 09:28:06,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1259432e-08 2.5705473e-08 3.1751440e-06 9.9999678e-01 1.0973851e-08], sum to 1.0000
[2019-03-24 09:28:06,709] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-24 09:28:06,714] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.88333333333333, 93.66666666666667, 1.0, 2.0, 0.1901387371939021, 1.0, 2.0, 0.1901387371939021, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468789.9574950189, 468789.9574950189, 157790.3572363315], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7456200.0000, 
sim time next is 7456800.0000, 
raw observation next is [19.96666666666667, 93.33333333333334, 1.0, 2.0, 0.1909965912614077, 1.0, 2.0, 0.1909965912614077, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470591.9665960499, 470591.9665960503, 157958.6469344202], 
processed observation next is [0.0, 0.30434782608695654, 0.2950617283950618, 0.9333333333333335, 1.0, 1.0, 0.03690070388262821, 1.0, 1.0, 0.03690070388262821, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16806855949858926, 0.1680685594985894, 0.30376662872003884], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.9058792], dtype=float32), -0.084911056]. 
=============================================
[2019-03-24 09:28:16,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1087702e-06 8.1507515e-08 5.3356632e-07 9.9999642e-01 1.7300547e-06], sum to 1.0000
[2019-03-24 09:28:16,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3280
[2019-03-24 09:28:16,813] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.73333333333333, 91.0, 1.0, 2.0, 0.2100263160963375, 1.0, 2.0, 0.2100263160963375, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513448.938491167, 513448.9384911675, 161841.567296974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7631400.0000, 
sim time next is 7632000.0000, 
raw observation next is [20.8, 91.0, 1.0, 2.0, 0.2269124496500098, 1.0, 2.0, 0.2269124496500098, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554000.2346855935, 554000.234685594, 165475.0295832101], 
processed observation next is [1.0, 0.34782608695652173, 0.32592592592592595, 0.91, 1.0, 1.0, 0.07965767815477358, 1.0, 1.0, 0.07965767815477358, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19785722667342626, 0.19785722667342642, 0.3182212107369425], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.5787805], dtype=float32), -1.7235671]. 
=============================================
[2019-03-24 09:28:16,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.02452]
 [64.05986]
 [64.06007]
 [64.10811]
 [64.16981]], R is [[63.94813156]
 [63.99741745]
 [64.04557037]
 [64.09009552]
 [64.13508606]].
[2019-03-24 09:28:17,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6178950e-08 5.1988398e-08 1.5508596e-06 9.9999821e-01 8.1091159e-08], sum to 1.0000
[2019-03-24 09:28:17,520] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-24 09:28:17,527] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 91.66666666666667, 1.0, 2.0, 0.4044118804138216, 1.0, 2.0, 0.4044118804138216, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 971100.8667847188, 971100.8667847193, 209487.5413933992], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7395600.0000, 
sim time next is 7396200.0000, 
raw observation next is [21.3, 91.5, 1.0, 2.0, 0.4140919637369578, 1.0, 2.0, 0.4140919637369578, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 994379.5867355037, 994379.5867355042, 212226.1730466869], 
processed observation next is [1.0, 0.6086956521739131, 0.3444444444444445, 0.915, 1.0, 1.0, 0.3024904330201878, 1.0, 1.0, 0.3024904330201878, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35513556669125135, 0.3551355666912515, 0.40812725585901327], 
reward next is 0.5919, 
noisyNet noise sample is [array([0.19091778], dtype=float32), 0.34302467]. 
=============================================
[2019-03-24 09:28:20,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1378482e-07 6.6605253e-07 2.8097752e-06 9.9999595e-01 3.6003692e-07], sum to 1.0000
[2019-03-24 09:28:20,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7771
[2019-03-24 09:28:20,896] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.03333333333333, 82.66666666666667, 1.0, 2.0, 0.2283532598850712, 1.0, 2.0, 0.2283532598850712, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547275.8294687935, 547275.8294687939, 165423.2115376844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7469400.0000, 
sim time next is 7470000.0000, 
raw observation next is [23.2, 82.0, 1.0, 2.0, 0.2298972991964499, 1.0, 2.0, 0.2298972991964499, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550260.2323111797, 550260.2323111802, 165733.2617711231], 
processed observation next is [0.0, 0.4782608695652174, 0.4148148148148148, 0.82, 1.0, 1.0, 0.08321107047196417, 1.0, 1.0, 0.08321107047196417, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19652151153970704, 0.1965215115397072, 0.31871781109831365], 
reward next is 0.6813, 
noisyNet noise sample is [array([-0.5380329], dtype=float32), 0.06188234]. 
=============================================
[2019-03-24 09:28:20,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.306244]
 [67.33804 ]
 [67.36589 ]
 [67.35924 ]
 [67.37263 ]], R is [[67.28346252]
 [67.29250336]
 [67.30200958]
 [67.31197357]
 [67.32244873]].
[2019-03-24 09:28:24,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3619494e-07 2.4041142e-08 6.9128960e-09 9.9999976e-01 1.3934017e-07], sum to 1.0000
[2019-03-24 09:28:24,589] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3325
[2019-03-24 09:28:24,594] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.95, 94.0, 1.0, 2.0, 0.2411304556541509, 1.0, 2.0, 0.2411304556541509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573627.2464989118, 573627.2464989118, 168077.7166028548], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7511400.0000, 
sim time next is 7512000.0000, 
raw observation next is [21.9, 94.33333333333333, 1.0, 2.0, 0.2408165742675758, 1.0, 2.0, 0.2408165742675758, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572982.4012826711, 572982.4012826716, 168011.9761236272], 
processed observation next is [0.0, 0.9565217391304348, 0.36666666666666664, 0.9433333333333332, 1.0, 1.0, 0.09621020746139976, 1.0, 1.0, 0.09621020746139976, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20463657188666826, 0.20463657188666842, 0.3230999540838984], 
reward next is 0.6769, 
noisyNet noise sample is [array([0.28104568], dtype=float32), -1.024227]. 
=============================================
[2019-03-24 09:28:24,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.63462 ]
 [67.59652 ]
 [67.59895 ]
 [67.6454  ]
 [67.627045]], R is [[67.63122559]
 [67.63168335]
 [67.63198853]
 [67.63211823]
 [67.63208008]].
[2019-03-24 09:28:24,839] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:24,843] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:24,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-24 09:28:26,709] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2112019: loss 6.0241
[2019-03-24 09:28:26,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2112019: learning rate 0.0000
[2019-03-24 09:28:26,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6257507e-08 2.7142997e-07 7.6998691e-07 9.9999857e-01 3.3892721e-07], sum to 1.0000
[2019-03-24 09:28:26,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9212
[2019-03-24 09:28:26,870] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 85.0, 1.0, 2.0, 0.2602523228404421, 1.0, 2.0, 0.2602523228404421, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 611611.6334842996, 611611.6334843, 172086.6377925098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7594200.0000, 
sim time next is 7594800.0000, 
raw observation next is [23.7, 85.33333333333333, 1.0, 2.0, 0.2606988354597174, 1.0, 2.0, 0.2606988354597174, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 612699.841394145, 612699.8413941455, 172190.4985811823], 
processed observation next is [0.0, 0.9130434782608695, 0.4333333333333333, 0.8533333333333333, 1.0, 1.0, 0.11987956602347309, 1.0, 1.0, 0.11987956602347309, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21882137192648038, 0.21882137192648055, 0.33113557419458134], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.1923602], dtype=float32), -0.38666925]. 
=============================================
[2019-03-24 09:28:30,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2010310e-09 3.5496772e-08 2.4387910e-07 9.9999976e-01 3.0479669e-08], sum to 1.0000
[2019-03-24 09:28:30,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8672
[2019-03-24 09:28:30,256] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 71.0, 1.0, 2.0, 0.4623535863879606, 1.0, 2.0, 0.4623535863879606, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 1067538.145648278, 1067538.145648276, 224623.6769570417], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7648200.0000, 
sim time next is 7648800.0000, 
raw observation next is [26.43333333333334, 70.33333333333334, 1.0, 2.0, 0.490740375195494, 1.0, 2.0, 0.490740375195494, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1133644.582398527, 1133644.582398528, 233237.054862195], 
processed observation next is [1.0, 0.5217391304347826, 0.5345679012345682, 0.7033333333333335, 1.0, 1.0, 0.39373854189939766, 1.0, 1.0, 0.39373854189939766, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4048730651423311, 0.40487306514233146, 0.4485327978119134], 
reward next is 0.5515, 
noisyNet noise sample is [array([1.374631], dtype=float32), 1.304291]. 
=============================================
[2019-03-24 09:28:31,703] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8360947e-07 5.4921337e-08 2.2266552e-07 9.9999940e-01 2.3427728e-07], sum to 1.0000
[2019-03-24 09:28:31,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5618
[2019-03-24 09:28:31,715] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.51666666666667, 69.66666666666666, 1.0, 2.0, 0.5007669642994207, 1.0, 2.0, 0.5007669642994207, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1156750.555436822, 1156750.555436823, 236335.2030417031], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7649400.0000, 
sim time next is 7650000.0000, 
raw observation next is [26.6, 69.0, 1.0, 2.0, 0.4298751682879515, 1.0, 2.0, 0.4298751682879515, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994831.6734427651, 994831.6734427651, 215246.5451491553], 
processed observation next is [1.0, 0.5652173913043478, 0.5407407407407407, 0.69, 1.0, 1.0, 0.3212799622475614, 1.0, 1.0, 0.3212799622475614, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.355297026229559, 0.355297026229559, 0.4139356637483756], 
reward next is 0.5861, 
noisyNet noise sample is [array([-2.007965], dtype=float32), 1.1199586]. 
=============================================
[2019-03-24 09:28:31,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.26856 ]
 [60.260353]
 [60.200027]
 [60.066006]
 [59.404053]], R is [[60.60927582]
 [60.54869461]
 [60.49467468]
 [60.45775986]
 [60.40068436]].
[2019-03-24 09:28:31,903] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:31,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:31,977] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-24 09:28:33,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2115129: loss 6.5892
[2019-03-24 09:28:33,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2115129: learning rate 0.0000
[2019-03-24 09:28:36,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:36,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:36,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-24 09:28:37,483] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:37,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:37,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-24 09:28:38,540] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2117266: loss 5.9206
[2019-03-24 09:28:38,544] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2117266: learning rate 0.0000
[2019-03-24 09:28:39,364] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2117646: loss 4.7228
[2019-03-24 09:28:39,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2117646: learning rate 0.0000
[2019-03-24 09:28:40,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6352610e-07 1.5581313e-06 2.3351885e-07 9.9999547e-01 2.1759263e-06], sum to 1.0000
[2019-03-24 09:28:40,822] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3317
[2019-03-24 09:28:40,831] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 33.0, 1.0, 2.0, 0.5317480583704784, 1.0, 2.0, 0.5317480583704784, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1289639.578974903, 1289639.578974904, 248570.8339153248], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7833600.0000, 
sim time next is 7834200.0000, 
raw observation next is [31.03333333333333, 33.5, 1.0, 2.0, 0.5373824871082897, 1.0, 2.0, 0.5373824871082897, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1301874.323207599, 1301874.3232076, 250371.8690283592], 
processed observation next is [1.0, 0.6956521739130435, 0.7049382716049382, 0.335, 1.0, 1.0, 0.4492648656051068, 1.0, 1.0, 0.4492648656051068, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46495511543128537, 0.4649551154312857, 0.4814843635160754], 
reward next is 0.5185, 
noisyNet noise sample is [array([-0.17380518], dtype=float32), -0.13381529]. 
=============================================
[2019-03-24 09:28:41,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:41,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:41,770] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-24 09:28:42,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:42,955] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:43,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-24 09:28:43,500] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2119490: loss 8.9666
[2019-03-24 09:28:43,505] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2119491: learning rate 0.0000
[2019-03-24 09:28:43,874] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2119686: loss 0.2666
[2019-03-24 09:28:43,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2119686: learning rate 0.0000
[2019-03-24 09:28:44,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:44,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:44,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-24 09:28:44,760] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2120100: loss 4.4906
[2019-03-24 09:28:44,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2120100: learning rate 0.0000
[2019-03-24 09:28:44,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:44,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:44,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-24 09:28:45,926] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2120694: loss 4.7169
[2019-03-24 09:28:45,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2120694: learning rate 0.0000
[2019-03-24 09:28:46,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:46,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:46,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-24 09:28:46,684] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121056: loss 5.5553
[2019-03-24 09:28:46,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121057: learning rate 0.0000
[2019-03-24 09:28:47,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:47,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:47,597] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6520413e-08 4.1663455e-08 4.0270791e-07 9.9999952e-01 1.5159431e-08], sum to 1.0000
[2019-03-24 09:28:47,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5640
[2019-03-24 09:28:47,607] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.63333333333333, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347346.67184833, 347346.67184833, 142552.7809171776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 345282.8161442532, 345282.8161442537, 142241.0088207649], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12331529148009042, 0.12331529148009061, 0.27354040157839404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.825022], dtype=float32), 1.2090071]. 
=============================================
[2019-03-24 09:28:47,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-24 09:28:47,933] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121653: loss 6.1497
[2019-03-24 09:28:47,937] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121654: learning rate 0.0000
[2019-03-24 09:28:48,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:48,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:48,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-24 09:28:49,135] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2122257: loss 0.2056
[2019-03-24 09:28:49,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2122257: learning rate 0.0000
[2019-03-24 09:28:49,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:49,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:49,203] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2122293: loss 3.3539
[2019-03-24 09:28:49,207] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2122294: learning rate 0.0000
[2019-03-24 09:28:49,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-24 09:28:49,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:49,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:49,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-24 09:28:49,472] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:49,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:49,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-24 09:28:50,129] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2122737: loss 3.9419
[2019-03-24 09:28:50,130] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2122737: learning rate 0.0000
[2019-03-24 09:28:50,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:50,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:50,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-24 09:28:50,863] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2123137: loss 4.5161
[2019-03-24 09:28:50,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2123137: learning rate 0.0000
[2019-03-24 09:28:50,974] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2123195: loss 4.3475
[2019-03-24 09:28:50,978] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2123196: learning rate 0.0000
[2019-03-24 09:28:51,208] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2123317: loss 3.7568
[2019-03-24 09:28:51,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2123317: learning rate 0.0000
[2019-03-24 09:28:52,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2123711: loss 10.5039
[2019-03-24 09:28:52,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2123711: learning rate 0.0000
[2019-03-24 09:28:52,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:28:52,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:52,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-24 09:28:53,518] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2124371: loss 0.3131
[2019-03-24 09:28:53,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2124371: learning rate 0.0000
[2019-03-24 09:28:54,171] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2124692: loss 0.2545
[2019-03-24 09:28:54,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2124693: learning rate 0.0000
[2019-03-24 09:28:54,524] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2124843: loss 3.2959
[2019-03-24 09:28:54,527] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2124843: learning rate 0.0000
[2019-03-24 09:28:54,892] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 09:28:54,893] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:28:54,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:54,897] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:28:54,898] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:54,900] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:28:54,902] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:28:54,903] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:54,902] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:28:54,904] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:54,906] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:28:54,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-24 09:28:54,928] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-24 09:28:54,959] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-24 09:28:54,959] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-24 09:28:54,990] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-24 09:29:38,366] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:38,368] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.64693358166667, 77.91339645666666, 1.0, 2.0, 0.2780413485790122, 1.0, 2.0, 0.2780413485790122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643067.789392367, 643067.7893923675, 175738.5444479821]
[2019-03-24 09:29:38,371] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:29:38,375] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9045116e-08 4.0082046e-08 1.1694910e-07 9.9999988e-01 4.1355495e-08], sampled 0.9685676226780164
[2019-03-24 09:29:45,065] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:45,066] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.33333333333334, 96.66666666666667, 1.0, 2.0, 0.4305981204680597, 1.0, 2.0, 0.4305981204680597, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 984045.9029866371, 984045.9029866375, 214870.1788890188]
[2019-03-24 09:29:45,068] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:29:45,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7990227e-08 4.7530563e-08 1.4418332e-07 9.9999976e-01 4.9064045e-08], sampled 0.12701073057006296
[2019-03-24 09:29:46,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:46,966] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.1, 59.5, 1.0, 2.0, 0.3425184676825596, 1.0, 2.0, 0.3425184676825596, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 780739.6313897631, 780739.6313897636, 190977.5264319881]
[2019-03-24 09:29:46,966] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:29:46,971] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.2202898e-08 3.1937429e-08 9.8887774e-08 9.9999988e-01 3.1944005e-08], sampled 0.926107928716828
[2019-03-24 09:29:48,040] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:48,041] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.75, 63.0, 1.0, 2.0, 0.3729810987793089, 1.0, 2.0, 0.3729810987793089, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850214.9348140351, 850214.9348140351, 198897.9551874986]
[2019-03-24 09:29:48,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:29:48,046] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5298338e-08 2.5748292e-08 7.8604621e-08 9.9999988e-01 2.5745493e-08], sampled 0.33762349942404646
[2019-03-24 09:29:49,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:49,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.16666666666666, 35.0, 1.0, 2.0, 0.3153704947473604, 1.0, 2.0, 0.3153704947473604, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 718829.2859584376, 718829.2859584381, 184190.0514306841]
[2019-03-24 09:29:49,320] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:29:49,324] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1956073e-08 3.2117146e-08 9.7531228e-08 9.9999988e-01 3.2204248e-08], sampled 0.6465152692249863
[2019-03-24 09:29:59,358] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:29:59,358] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.378221373326377, 1.0, 2.0, 0.378221373326377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 862166.9229076203, 862166.9229076208, 200292.6749307255]
[2019-03-24 09:29:59,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:29:59,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0359488e-08 2.0570621e-08 6.4591838e-08 9.9999988e-01 2.0282357e-08], sampled 0.28346576155020364
[2019-03-24 09:30:27,820] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01077896], dtype=float32), 0.010574128]
[2019-03-24 09:30:27,823] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.05357045333334, 89.14993766333333, 1.0, 2.0, 0.228493622617012, 1.0, 2.0, 0.228493622617012, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 549637.7220163518, 549637.7220163522, 165532.5049902737]
[2019-03-24 09:30:27,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:30:27,826] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4282490e-08 3.5322795e-08 1.0595904e-07 9.9999988e-01 3.5285357e-08], sampled 0.14104931480496197
[2019-03-24 09:31:03,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:31:03,453] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:31:03,474] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7333 2495420968.3102 47.0000
[2019-03-24 09:31:03,549] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:31:03,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:31:04,945] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2125000, evaluation results [2125000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6906.733277770052, 2495420968.3101773, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:31:05,292] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5183764e-07 2.3727917e-07 4.7971997e-07 9.9999797e-01 6.7192912e-07], sum to 1.0000
[2019-03-24 09:31:05,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0283
[2019-03-24 09:31:05,310] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.45, 35.0, 1.0, 2.0, 0.1602063787425305, 1.0, 2.0, 0.1602063787425305, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408891.797763789, 408891.7977637894, 151935.3878151602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 329400.0000, 
sim time next is 330000.0000, 
raw observation next is [26.33333333333334, 35.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407263.9652991855, 407263.9652991855, 151715.7355111109], 
processed observation next is [0.0, 0.8260869565217391, 0.5308641975308644, 0.35333333333333344, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14545141617828053, 0.14545141617828053, 0.2917610298290594], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2168332], dtype=float32), -0.20287739]. 
=============================================
[2019-03-24 09:31:05,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.729782]
 [58.726906]
 [58.825966]
 [58.943207]
 [58.99463 ]], R is [[58.08830643]
 [58.21524048]
 [58.34064102]
 [58.46445847]
 [58.58686447]].
[2019-03-24 09:31:08,784] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2126643: loss 0.2938
[2019-03-24 09:31:08,786] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2126643: learning rate 0.0000
[2019-03-24 09:31:09,266] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2126849: loss 1.0565
[2019-03-24 09:31:09,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2126850: learning rate 0.0000
[2019-03-24 09:31:10,650] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2127443: loss 0.4857
[2019-03-24 09:31:10,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2127444: learning rate 0.0000
[2019-03-24 09:31:12,090] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2128068: loss 1.0268
[2019-03-24 09:31:12,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2128068: learning rate 0.0000
[2019-03-24 09:31:12,850] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2128396: loss 1.0091
[2019-03-24 09:31:12,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2128396: learning rate 0.0000
[2019-03-24 09:31:12,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2229436e-06 1.8861699e-06 1.1749380e-05 9.9997449e-01 4.6079908e-06], sum to 1.0000
[2019-03-24 09:31:12,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5056
[2019-03-24 09:31:12,872] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.51666666666667, 31.66666666666667, 1.0, 2.0, 0.1659836626152491, 1.0, 2.0, 0.1659836626152491, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422999.3676247819, 422999.3676247824, 153100.8974817544], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 323400.0000, 
sim time next is 324000.0000, 
raw observation next is [27.4, 32.0, 1.0, 2.0, 0.1656052054284723, 1.0, 2.0, 0.1656052054284723, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422117.0136226637, 422117.0136226642, 153024.4835688299], 
processed observation next is [0.0, 0.782608695652174, 0.5703703703703703, 0.32, 1.0, 1.0, 0.006672863605324152, 1.0, 1.0, 0.006672863605324152, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15075607629380847, 0.15075607629380863, 0.29427785301698056], 
reward next is 0.7057, 
noisyNet noise sample is [array([0.89193445], dtype=float32), 0.8121816]. 
=============================================
[2019-03-24 09:31:12,909] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[45.295242]
 [45.335182]
 [45.385742]
 [45.394287]
 [45.461273]], R is [[45.50754929]
 [45.75804901]
 [46.00590134]
 [46.25109482]
 [46.49364853]].
[2019-03-24 09:31:14,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7207771e-07 6.1436003e-07 7.2409848e-06 9.9999058e-01 6.0455216e-07], sum to 1.0000
[2019-03-24 09:31:14,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4289
[2019-03-24 09:31:14,088] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.46666666666667, 12.66666666666667, 1.0, 2.0, 0.1789536762133091, 1.0, 2.0, 0.1789536762133091, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461711.591951347, 461711.591951347, 149391.1534391553], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 164400.0000, 
sim time next is 165000.0000, 
raw observation next is [31.38333333333333, 12.33333333333333, 1.0, 2.0, 0.1783870759528293, 1.0, 2.0, 0.1783870759528293, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460249.2894012477, 460249.2894012482, 147839.3240565051], 
processed observation next is [1.0, 0.9130434782608695, 0.7179012345679011, 0.12333333333333331, 1.0, 1.0, 0.021889376134320584, 1.0, 1.0, 0.021889376134320584, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1643747462147313, 0.1643747462147315, 0.28430639241635597], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.5209955], dtype=float32), -1.8176361]. 
=============================================
[2019-03-24 09:31:14,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.655293]
 [55.796494]
 [55.92488 ]
 [56.306564]
 [56.36425 ]], R is [[55.6659317 ]
 [55.82197952]
 [55.97310638]
 [56.1187973 ]
 [56.25809479]].
[2019-03-24 09:31:14,519] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2129097: loss 0.4794
[2019-03-24 09:31:14,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2129098: learning rate 0.0000
[2019-03-24 09:31:16,393] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2129909: loss 1.0688
[2019-03-24 09:31:16,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2129909: learning rate 0.0000
[2019-03-24 09:31:16,467] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2129940: loss 3.7438
[2019-03-24 09:31:16,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2129942: learning rate 0.0000
[2019-03-24 09:31:18,054] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2130620: loss 1.8393
[2019-03-24 09:31:18,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2130620: learning rate 0.0000
[2019-03-24 09:31:19,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2131040: loss 1.7902
[2019-03-24 09:31:19,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2131040: learning rate 0.0000
[2019-03-24 09:31:19,068] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2131062: loss 1.7424
[2019-03-24 09:31:19,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2131063: learning rate 0.0000
[2019-03-24 09:31:19,417] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2131209: loss 1.6958
[2019-03-24 09:31:19,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2131209: learning rate 0.0000
[2019-03-24 09:31:20,441] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2131648: loss 2.0510
[2019-03-24 09:31:20,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2131648: learning rate 0.0000
[2019-03-24 09:31:22,125] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2132371: loss 6.9931
[2019-03-24 09:31:22,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2132372: learning rate 0.0000
[2019-03-24 09:31:22,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2585248e-06 2.7880869e-06 5.6839231e-06 9.9998903e-01 1.9196379e-07], sum to 1.0000
[2019-03-24 09:31:22,524] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4848
[2019-03-24 09:31:22,529] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.05, 28.66666666666667, 1.0, 2.0, 0.1776558881364173, 1.0, 2.0, 0.1776558881364173, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446720.1924427559, 446720.1924427559, 155418.2667526343], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 409800.0000, 
sim time next is 410400.0000, 
raw observation next is [29.9, 29.0, 1.0, 2.0, 0.1776647582615634, 1.0, 2.0, 0.1776647582615634, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446919.7624988327, 446919.7624988327, 155423.525125072], 
processed observation next is [1.0, 0.782608695652174, 0.6629629629629629, 0.29, 1.0, 1.0, 0.021029474120908793, 1.0, 1.0, 0.021029474120908793, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15961420089244024, 0.15961420089244024, 0.29889139447129226], 
reward next is 0.7011, 
noisyNet noise sample is [array([0.6444018], dtype=float32), 0.6428142]. 
=============================================
[2019-03-24 09:31:22,905] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2132700: loss 6.8669
[2019-03-24 09:31:22,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2132700: learning rate 0.0000
[2019-03-24 09:31:23,285] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2132862: loss 1.7538
[2019-03-24 09:31:23,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2132862: learning rate 0.0000
[2019-03-24 09:31:23,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6409306e-08 6.2939300e-08 5.8637575e-08 9.9999964e-01 1.1961517e-07], sum to 1.0000
[2019-03-24 09:31:23,786] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8449
[2019-03-24 09:31:23,794] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.96666666666667, 27.66666666666667, 1.0, 2.0, 0.4524951693288841, 1.0, 2.0, 0.4524951693288841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1138688.547361855, 1138688.547361855, 224767.168169692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 387600.0000, 
sim time next is 388200.0000, 
raw observation next is [29.08333333333333, 27.33333333333333, 1.0, 2.0, 0.456342157477508, 1.0, 2.0, 0.456342157477508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1148044.800460787, 1148044.800460787, 225923.5137491517], 
processed observation next is [1.0, 0.4782608695652174, 0.6327160493827159, 0.27333333333333326, 1.0, 1.0, 0.35278828271131907, 1.0, 1.0, 0.35278828271131907, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4100160001645668, 0.4100160001645668, 0.43446829567144557], 
reward next is 0.5655, 
noisyNet noise sample is [array([0.45462438], dtype=float32), 0.1076697]. 
=============================================
[2019-03-24 09:31:27,471] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2134657: loss 7.4561
[2019-03-24 09:31:27,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2134659: learning rate 0.0000
[2019-03-24 09:31:27,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2134859: loss 0.6831
[2019-03-24 09:31:27,950] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2134859: learning rate 0.0000
[2019-03-24 09:31:29,348] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2135460: loss 4.9098
[2019-03-24 09:31:29,352] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2135460: learning rate 0.0000
[2019-03-24 09:31:30,904] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2136131: loss 3.3670
[2019-03-24 09:31:30,907] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2136132: learning rate 0.0000
[2019-03-24 09:31:31,398] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2136349: loss 3.6766
[2019-03-24 09:31:31,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2136350: learning rate 0.0000
[2019-03-24 09:31:33,152] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2137109: loss 4.9524
[2019-03-24 09:31:33,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2137109: learning rate 0.0000
[2019-03-24 09:31:34,890] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2137853: loss 0.2647
[2019-03-24 09:31:34,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2137854: learning rate 0.0000
[2019-03-24 09:31:35,052] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2137919: loss 4.5297
[2019-03-24 09:31:35,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2137920: learning rate 0.0000
[2019-03-24 09:31:36,657] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2138619: loss 4.9050
[2019-03-24 09:31:36,658] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2138619: learning rate 0.0000
[2019-03-24 09:31:37,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8736116e-06 3.6840922e-06 3.5096907e-06 9.9998820e-01 7.1538403e-07], sum to 1.0000
[2019-03-24 09:31:37,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5173
[2019-03-24 09:31:37,399] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.23333333333333, 32.5, 1.0, 2.0, 0.1936392109526508, 1.0, 2.0, 0.1936392109526508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475847.5386116747, 475847.5386116752, 158469.0818733382], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 583800.0000, 
sim time next is 584400.0000, 
raw observation next is [31.06666666666667, 33.0, 1.0, 2.0, 0.1960410884419404, 1.0, 2.0, 0.1960410884419404, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481774.3649157921, 481774.3649157925, 158970.4907463735], 
processed observation next is [1.0, 0.782608695652174, 0.7061728395061729, 0.33, 1.0, 1.0, 0.04290605766897667, 1.0, 1.0, 0.04290605766897667, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17206227318421147, 0.1720622731842116, 0.30571248220456443], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.11121605], dtype=float32), 1.3706251]. 
=============================================
[2019-03-24 09:31:37,650] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2139044: loss 4.5159
[2019-03-24 09:31:37,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2139044: learning rate 0.0000
[2019-03-24 09:31:37,804] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2139110: loss 4.4413
[2019-03-24 09:31:37,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2139110: learning rate 0.0000
[2019-03-24 09:31:37,870] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2139135: loss 3.7895
[2019-03-24 09:31:37,876] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2139136: learning rate 0.0000
[2019-03-24 09:31:39,155] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2139691: loss 3.7801
[2019-03-24 09:31:39,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2139691: learning rate 0.0000
[2019-03-24 09:31:40,785] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2140385: loss 0.0577
[2019-03-24 09:31:40,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2140386: learning rate 0.0000
[2019-03-24 09:31:41,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2140636: loss 0.0707
[2019-03-24 09:31:41,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2140636: learning rate 0.0000
[2019-03-24 09:31:41,910] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2140873: loss 6.2144
[2019-03-24 09:31:41,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2140874: learning rate 0.0000
[2019-03-24 09:31:46,104] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2142667: loss 0.0068
[2019-03-24 09:31:46,111] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2142668: learning rate 0.0000
[2019-03-24 09:31:46,526] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2142849: loss 2.7753
[2019-03-24 09:31:46,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2142849: learning rate 0.0000
[2019-03-24 09:31:48,029] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2143492: loss 0.0110
[2019-03-24 09:31:48,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2143492: learning rate 0.0000
[2019-03-24 09:31:49,433] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2144099: loss 0.0311
[2019-03-24 09:31:49,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2144100: learning rate 0.0000
[2019-03-24 09:31:50,095] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2144384: loss 0.0265
[2019-03-24 09:31:50,096] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2144384: learning rate 0.0000
[2019-03-24 09:31:51,666] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2145051: loss 0.0006
[2019-03-24 09:31:51,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2145051: learning rate 0.0000
[2019-03-24 09:31:52,066] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8270222e-06 5.0740658e-07 6.3615011e-07 9.9999475e-01 1.3330698e-06], sum to 1.0000
[2019-03-24 09:31:52,078] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6952
[2019-03-24 09:31:52,085] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 75.5, 1.0, 2.0, 0.17474293705061, 1.0, 2.0, 0.17474293705061, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437500.8025758811, 437500.8025758815, 154776.4034556611], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1186200.0000, 
sim time next is 1186800.0000, 
raw observation next is [20.93333333333333, 76.0, 1.0, 2.0, 0.1746902767337535, 1.0, 2.0, 0.1746902767337535, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437419.5783877167, 437419.5783877172, 154766.7026438478], 
processed observation next is [1.0, 0.7391304347826086, 0.3308641975308641, 0.76, 1.0, 1.0, 0.017488424683039887, 1.0, 1.0, 0.017488424683039887, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1562212779956131, 0.15622127799561328, 0.2976282743150919], 
reward next is 0.7024, 
noisyNet noise sample is [array([-1.0968102], dtype=float32), 0.49757722]. 
=============================================
[2019-03-24 09:31:52,375] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0497113e-05 2.3098972e-05 5.1286738e-06 9.9993765e-01 1.3577436e-05], sum to 1.0000
[2019-03-24 09:31:52,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-24 09:31:52,393] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 59.5, 1.0, 2.0, 0.2000178334250552, 1.0, 2.0, 0.2000178334250552, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 492753.283360282, 492753.2833602825, 159840.3226983523], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 863400.0000, 
sim time next is 864000.0000, 
raw observation next is [24.6, 60.0, 1.0, 2.0, 0.1998126491809134, 1.0, 2.0, 0.1998126491809134, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 492629.6902845691, 492629.6902845696, 159808.3888055848], 
processed observation next is [0.0, 0.0, 0.46666666666666673, 0.6, 1.0, 1.0, 0.04739601092965881, 1.0, 1.0, 0.04739601092965881, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17593917510163182, 0.17593917510163198, 0.3073238246261246], 
reward next is 0.6927, 
noisyNet noise sample is [array([-0.87365717], dtype=float32), -0.14688413]. 
=============================================
[2019-03-24 09:31:52,417] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[48.17215 ]
 [48.2555  ]
 [48.378407]
 [48.436516]
 [48.5215  ]], R is [[47.46175766]
 [47.67975616]
 [47.89543152]
 [48.10851669]
 [48.3189888 ]].
[2019-03-24 09:31:53,604] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2145891: loss 0.0030
[2019-03-24 09:31:53,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2145891: learning rate 0.0000
[2019-03-24 09:31:53,609] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2145892: loss 4.2049
[2019-03-24 09:31:53,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2145892: learning rate 0.0000
[2019-03-24 09:31:55,396] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2146667: loss 0.0014
[2019-03-24 09:31:55,397] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2146667: learning rate 0.0000
[2019-03-24 09:31:56,357] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2147083: loss 0.0149
[2019-03-24 09:31:56,359] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2147083: learning rate 0.0000
[2019-03-24 09:31:56,428] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2147113: loss 0.0168
[2019-03-24 09:31:56,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2147114: learning rate 0.0000
[2019-03-24 09:31:56,516] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2147148: loss 0.0143
[2019-03-24 09:31:56,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2147151: learning rate 0.0000
[2019-03-24 09:31:56,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3855106e-07 2.1898061e-06 2.3664637e-05 9.9995863e-01 1.4869720e-05], sum to 1.0000
[2019-03-24 09:31:56,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0105
[2019-03-24 09:31:56,799] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.33333333333333, 71.33333333333334, 1.0, 2.0, 0.1600658751127298, 1.0, 2.0, 0.1600658751127298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406278.9636301027, 406278.9636301032, 151889.182075673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [20.26666666666667, 71.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398497.7701074292, 398497.7701074292, 150723.3621346177], 
processed observation next is [1.0, 0.17391304347826086, 0.3061728395061729, 0.7166666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1423206321812247, 0.1423206321812247, 0.2898526194896494], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36902744], dtype=float32), -0.07466782]. 
=============================================
[2019-03-24 09:31:57,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8417684e-06 3.4359744e-04 2.3814498e-05 9.9961674e-01 1.1979868e-05], sum to 1.0000
[2019-03-24 09:31:57,746] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9802
[2019-03-24 09:31:57,752] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.85, 45.0, 1.0, 2.0, 0.4647099840119999, 1.0, 2.0, 0.4647099840119999, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1143335.795164846, 1143335.795164847, 227926.2126392689], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1009800.0000, 
sim time next is 1010400.0000, 
raw observation next is [26.93333333333334, 44.66666666666667, 1.0, 2.0, 0.4605030835266058, 1.0, 2.0, 0.4605030835266058, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1132987.972494644, 1132987.972494644, 226649.4243483006], 
processed observation next is [1.0, 0.6956521739130435, 0.5530864197530867, 0.4466666666666667, 1.0, 1.0, 0.35774176610310215, 1.0, 1.0, 0.35774176610310215, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.40463856160523004, 0.40463856160523004, 0.4358642775928858], 
reward next is 0.5641, 
noisyNet noise sample is [array([0.09889997], dtype=float32), 0.115945645]. 
=============================================
[2019-03-24 09:31:57,757] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2147676: loss 0.0014
[2019-03-24 09:31:57,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2147677: learning rate 0.0000
[2019-03-24 09:31:58,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7872838e-07 3.4992567e-07 1.9316346e-07 9.9999630e-01 2.4567348e-06], sum to 1.0000
[2019-03-24 09:31:58,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8186
[2019-03-24 09:31:58,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 44.0, 1.0, 2.0, 0.206061149523037, 1.0, 2.0, 0.206061149523037, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 504475.8307294773, 504475.8307294777, 161020.9360136871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 921600.0000, 
sim time next is 922200.0000, 
raw observation next is [28.38333333333333, 43.66666666666667, 1.0, 2.0, 0.2043551679210565, 1.0, 2.0, 0.2043551679210565, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500877.8844684478, 500877.8844684478, 160677.9163377419], 
processed observation next is [0.0, 0.6956521739130435, 0.60679012345679, 0.4366666666666667, 1.0, 1.0, 0.05280377133459108, 1.0, 1.0, 0.05280377133459108, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17888495873873136, 0.17888495873873136, 0.30899599295719593], 
reward next is 0.6910, 
noisyNet noise sample is [array([-1.3657244], dtype=float32), 0.3053524]. 
=============================================
[2019-03-24 09:31:58,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7161925e-06 1.1134219e-05 3.5967569e-06 9.9998057e-01 2.9432654e-06], sum to 1.0000
[2019-03-24 09:31:58,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7331
[2019-03-24 09:31:58,577] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.9, 58.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400173.4109208734, 400173.4109208738, 150317.1204439061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 962400.0000, 
sim time next is 963000.0000, 
raw observation next is [20.85, 59.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 392564.2902910949, 392564.2902910953, 149186.3495551196], 
processed observation next is [1.0, 0.13043478260869565, 0.32777777777777783, 0.59, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1402015322468196, 0.14020153224681975, 0.2868968260675377], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19159368], dtype=float32), -0.9034257]. 
=============================================
[2019-03-24 09:31:58,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[47.92788 ]
 [48.596954]
 [48.63758 ]
 [48.69957 ]
 [48.047356]], R is [[47.68817902]
 [47.21129608]
 [47.44284058]
 [46.96841431]
 [46.49872971]].
[2019-03-24 09:31:59,407] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2148395: loss 7.4446
[2019-03-24 09:31:59,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2148395: learning rate 0.0000
[2019-03-24 09:31:59,929] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2148620: loss 6.0035
[2019-03-24 09:31:59,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2148621: learning rate 0.0000
[2019-03-24 09:32:00,517] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2148869: loss 0.0122
[2019-03-24 09:32:00,520] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2148870: learning rate 0.0000
[2019-03-24 09:32:00,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0757530e-07 1.4971338e-06 5.9424251e-06 9.9999106e-01 5.6143000e-07], sum to 1.0000
[2019-03-24 09:32:00,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4621
[2019-03-24 09:32:00,923] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.76666666666667, 70.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 373825.8434021458, 373825.8434021463, 146690.1236388425], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1149600.0000, 
sim time next is 1150200.0000, 
raw observation next is [19.85, 69.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 369427.2340138152, 369427.2340138152, 146031.2434054324], 
processed observation next is [1.0, 0.30434782608695654, 0.2907407407407408, 0.695, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13193829786207684, 0.13193829786207684, 0.28082931424121615], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29918554], dtype=float32), 0.8960678]. 
=============================================
[2019-03-24 09:32:03,128] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 09:32:03,131] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:32:03,132] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:32:03,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:32:03,133] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:32:03,134] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:32:03,133] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:32:03,136] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:32:03,136] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:32:03,138] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:32:03,140] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:32:03,162] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-24 09:32:03,193] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-24 09:32:03,226] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-24 09:32:03,258] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-24 09:32:03,258] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-24 09:32:28,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01078709], dtype=float32), 0.010268618]
[2019-03-24 09:32:29,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 65.5, 1.0, 2.0, 0.1987324420971259, 1.0, 2.0, 0.1987324420971259, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491699.6195757833, 491699.6195757837, 159630.5059797738]
[2019-03-24 09:32:29,004] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:32:29,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4265317e-06 6.8715640e-06 1.2706043e-05 9.9996650e-01 6.4921373e-06], sampled 0.049735610924365625
[2019-03-24 09:33:40,204] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01078709], dtype=float32), 0.010268618]
[2019-03-24 09:33:40,207] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.5249645973193193, 1.0, 2.0, 0.5249645973193193, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1254817.802999081, 1254817.802999082, 245725.5310427121]
[2019-03-24 09:33:40,210] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:33:40,212] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6509979e-06 1.4411429e-06 2.8050479e-06 9.9999249e-01 1.6209156e-06], sampled 0.7952741412433193
[2019-03-24 09:34:00,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01078709], dtype=float32), 0.010268618]
[2019-03-24 09:34:00,721] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.11666666666667, 94.16666666666667, 1.0, 2.0, 0.3033119284187773, 1.0, 2.0, 0.3033119284187773, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 691331.5986615467, 691331.5986615471, 181257.3365760998]
[2019-03-24 09:34:00,722] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:34:00,725] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1334471e-06 2.8689783e-06 5.4956695e-06 9.9998581e-01 2.7650092e-06], sampled 0.6691110687625658
[2019-03-24 09:34:08,743] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01078709], dtype=float32), 0.010268618]
[2019-03-24 09:34:08,744] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.16666666666666, 50.33333333333334, 1.0, 2.0, 0.6621541416137023, 1.0, 2.0, 0.6621541416137023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1547391.04477921, 1547391.044779211, 291888.0338214025]
[2019-03-24 09:34:08,746] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:34:08,749] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.1473444e-06 4.4545918e-06 8.7866856e-06 9.9997711e-01 4.4900303e-06], sampled 0.44621313830380094
[2019-03-24 09:34:11,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:34:11,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.1085 2668501588.0370 68.0000
[2019-03-24 09:34:12,092] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:34:12,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:34:12,366] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:34:13,380] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2150000, evaluation results [2150000.0, 7523.1084984347735, 2668501588.037048, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:34:15,014] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2150704: loss 11.8242
[2019-03-24 09:34:15,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2150704: learning rate 0.0000
[2019-03-24 09:34:15,287] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2150823: loss 0.0116
[2019-03-24 09:34:15,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2150823: learning rate 0.0000
[2019-03-24 09:34:16,768] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2151462: loss 9.0386
[2019-03-24 09:34:16,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2151462: learning rate 0.0000
[2019-03-24 09:34:18,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2152112: loss 7.5111
[2019-03-24 09:34:18,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2152114: learning rate 0.0000
[2019-03-24 09:34:18,790] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2152325: loss 7.8748
[2019-03-24 09:34:18,793] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2152325: learning rate 0.0000
[2019-03-24 09:34:20,468] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2153057: loss 5.8039
[2019-03-24 09:34:20,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2153060: learning rate 0.0000
[2019-03-24 09:34:22,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7252676e-06 1.4427823e-07 5.8051633e-06 9.9999225e-01 1.5640030e-07], sum to 1.0000
[2019-03-24 09:34:22,270] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-24 09:34:22,279] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666667, 65.0, 1.0, 2.0, 0.2751049879270918, 1.0, 2.0, 0.2751049879270918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695799.2911000772, 695799.2911000777, 176999.2814484289], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1163400.0000, 
sim time next is 1164000.0000, 
raw observation next is [21.23333333333333, 65.0, 1.0, 2.0, 0.2398414763789962, 1.0, 2.0, 0.2398414763789962, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 606912.2697046704, 606912.2697046709, 168828.9906946521], 
processed observation next is [1.0, 0.4782608695652174, 0.34197530864197523, 0.65, 1.0, 1.0, 0.09504937664166213, 1.0, 1.0, 0.09504937664166213, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2167543820373823, 0.21675438203738245, 0.3246711359512541], 
reward next is 0.6753, 
noisyNet noise sample is [array([0.1298145], dtype=float32), -0.859389]. 
=============================================
[2019-03-24 09:34:22,304] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.713203]
 [60.56357 ]
 [60.56081 ]
 [60.550625]
 [60.612812]], R is [[60.94087219]
 [60.99108124]
 [61.02743149]
 [61.06198883]
 [61.09658813]].
[2019-03-24 09:34:22,316] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2153849: loss 3.4764
[2019-03-24 09:34:22,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2153849: learning rate 0.0000
[2019-03-24 09:34:22,425] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2153900: loss 0.0440
[2019-03-24 09:34:22,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2153900: learning rate 0.0000
[2019-03-24 09:34:23,616] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2478897e-07 1.5453995e-06 5.4664067e-08 9.9999809e-01 1.2252306e-07], sum to 1.0000
[2019-03-24 09:34:23,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7191
[2019-03-24 09:34:23,632] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.98333333333333, 86.0, 1.0, 2.0, 0.1820128961664638, 1.0, 2.0, 0.1820128961664638, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453589.4943546311, 453589.4943546316, 156232.5038588604], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1299000.0000, 
sim time next is 1299600.0000, 
raw observation next is [19.9, 86.0, 1.0, 2.0, 0.1806518163487215, 1.0, 2.0, 0.1806518163487215, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 450686.5870899596, 450686.5870899601, 155961.5534251596], 
processed observation next is [1.0, 0.043478260869565216, 0.2925925925925925, 0.86, 1.0, 1.0, 0.024585495653239864, 1.0, 1.0, 0.024585495653239864, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1609594953892713, 0.16095949538927146, 0.2999260642791531], 
reward next is 0.7001, 
noisyNet noise sample is [array([-0.7321699], dtype=float32), 0.81535023]. 
=============================================
[2019-03-24 09:34:24,278] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2154711: loss 3.3630
[2019-03-24 09:34:24,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2154711: learning rate 0.0000
[2019-03-24 09:34:24,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7490832e-07 6.5718166e-07 9.9070257e-07 9.9999666e-01 7.5411958e-07], sum to 1.0000
[2019-03-24 09:34:24,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7247
[2019-03-24 09:34:24,931] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.63333333333333, 90.33333333333333, 1.0, 2.0, 0.2012948042385905, 1.0, 2.0, 0.2012948042385905, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506793.0241513081, 506793.0241513086, 160363.8204246202], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1311000.0000, 
sim time next is 1311600.0000, 
raw observation next is [18.56666666666667, 90.66666666666667, 1.0, 2.0, 0.1657510577315326, 1.0, 2.0, 0.1657510577315326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417441.7446590083, 417441.7446590087, 152990.0941123231], 
processed observation next is [1.0, 0.17391304347826086, 0.24320987654321, 0.9066666666666667, 1.0, 1.0, 0.006846497299443558, 1.0, 1.0, 0.006846497299443558, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14908633737821725, 0.1490863373782174, 0.2942117194467752], 
reward next is 0.7058, 
noisyNet noise sample is [array([-0.5862671], dtype=float32), 1.1266502]. 
=============================================
[2019-03-24 09:34:25,079] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2155056: loss 1.4813
[2019-03-24 09:34:25,082] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2155057: learning rate 0.0000
[2019-03-24 09:34:25,135] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2155080: loss 1.2686
[2019-03-24 09:34:25,138] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2155080: learning rate 0.0000
[2019-03-24 09:34:25,210] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2155112: loss 1.1272
[2019-03-24 09:34:25,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2155112: learning rate 0.0000
[2019-03-24 09:34:26,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3379564e-07 1.2048736e-07 1.8504755e-06 9.9999774e-01 1.2624196e-07], sum to 1.0000
[2019-03-24 09:34:26,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1760
[2019-03-24 09:34:26,057] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 76.0, 1.0, 2.0, 0.3855125717021282, 1.0, 2.0, 0.3855125717021282, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957157.3111227534, 957157.3111227534, 205152.946443902], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1684800.0000, 
sim time next is 1685400.0000, 
raw observation next is [21.16666666666667, 75.5, 1.0, 2.0, 0.3840570069548671, 1.0, 2.0, 0.3840570069548671, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 952374.5999458665, 952374.599945867, 204724.31667906], 
processed observation next is [1.0, 0.5217391304347826, 0.33950617283950635, 0.755, 1.0, 1.0, 0.2667345320891275, 1.0, 1.0, 0.2667345320891275, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34013378569495234, 0.3401337856949525, 0.3937006089981923], 
reward next is 0.6063, 
noisyNet noise sample is [array([-0.73108006], dtype=float32), 0.015293336]. 
=============================================
[2019-03-24 09:34:26,632] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2155723: loss 0.3557
[2019-03-24 09:34:26,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2155723: learning rate 0.0000
[2019-03-24 09:34:28,098] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2156352: loss 0.0841
[2019-03-24 09:34:28,103] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2156354: learning rate 0.0000
[2019-03-24 09:34:28,776] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2156642: loss 0.0303
[2019-03-24 09:34:28,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2156642: learning rate 0.0000
[2019-03-24 09:34:29,418] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2156922: loss 0.1079
[2019-03-24 09:34:29,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2156922: learning rate 0.0000
[2019-03-24 09:34:29,514] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0019121e-08 5.0885540e-09 5.4476499e-07 9.9999940e-01 2.0109736e-08], sum to 1.0000
[2019-03-24 09:34:29,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2668
[2019-03-24 09:34:29,528] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.61666666666667, 28.33333333333333, 1.0, 2.0, 0.223181049158076, 1.0, 2.0, 0.223181049158076, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536415.7118013015, 536415.7118013015, 164356.0481824105], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1523400.0000, 
sim time next is 1524000.0000, 
raw observation next is [34.43333333333334, 29.66666666666667, 1.0, 2.0, 0.2248028608493875, 1.0, 2.0, 0.2248028608493875, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538243.5767519161, 538243.5767519166, 164627.5096067189], 
processed observation next is [0.0, 0.6521739130434783, 0.8308641975308644, 0.2966666666666667, 1.0, 1.0, 0.0771462629159375, 1.0, 1.0, 0.0771462629159375, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19222984883997002, 0.19222984883997019, 0.31659136462830556], 
reward next is 0.6834, 
noisyNet noise sample is [array([0.16259855], dtype=float32), -0.9325919]. 
=============================================
[2019-03-24 09:34:29,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.4411 ]
 [70.5325 ]
 [70.54994]
 [70.56138]
 [70.59624]], R is [[70.45245361]
 [70.43186188]
 [70.4154129 ]
 [70.40053558]
 [70.38574219]].
[2019-03-24 09:34:33,572] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2158714: loss 0.1029
[2019-03-24 09:34:33,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2158714: learning rate 0.0000
[2019-03-24 09:34:33,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.05570126e-07 1.03051526e-07 5.82794712e-07 9.99998808e-01
 2.43139908e-07], sum to 1.0000
[2019-03-24 09:34:33,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4564
[2019-03-24 09:34:33,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.86666666666667, 30.66666666666667, 1.0, 2.0, 0.4956042696994848, 1.0, 2.0, 0.4956042696994848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1215025.886357903, 1215025.886357903, 237378.0276557717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1352400.0000, 
sim time next is 1353000.0000, 
raw observation next is [30.88333333333333, 30.33333333333333, 1.0, 2.0, 0.4912013977528444, 1.0, 2.0, 0.4912013977528444, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1205553.643861787, 1205553.643861787, 236031.2808695564], 
processed observation next is [1.0, 0.6521739130434783, 0.6993827160493825, 0.3033333333333333, 1.0, 1.0, 0.39428737827719573, 1.0, 1.0, 0.39428737827719573, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.43055487280778104, 0.43055487280778104, 0.4539063093645315], 
reward next is 0.5461, 
noisyNet noise sample is [array([0.32906613], dtype=float32), 1.2492473]. 
=============================================
[2019-03-24 09:34:33,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.104057]
 [59.0111  ]
 [58.902893]
 [58.677956]
 [58.740017]], R is [[59.15430069]
 [59.10626221]
 [59.05374146]
 [58.99694824]
 [58.93494034]].
[2019-03-24 09:34:33,985] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2158891: loss 4.8828
[2019-03-24 09:34:33,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2158892: learning rate 0.0000
[2019-03-24 09:34:35,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2159480: loss 0.0635
[2019-03-24 09:34:35,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2159480: learning rate 0.0000
[2019-03-24 09:34:36,908] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2160137: loss 0.1007
[2019-03-24 09:34:36,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2160137: learning rate 0.0000
[2019-03-24 09:34:37,325] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2160316: loss 0.0716
[2019-03-24 09:34:37,327] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2160316: learning rate 0.0000
[2019-03-24 09:34:38,869] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160991: loss 0.0805
[2019-03-24 09:34:38,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160992: learning rate 0.0000
[2019-03-24 09:34:40,754] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2161805: loss 0.0989
[2019-03-24 09:34:40,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2161806: learning rate 0.0000
[2019-03-24 09:34:40,920] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2161879: loss 6.2687
[2019-03-24 09:34:40,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2161880: learning rate 0.0000
[2019-03-24 09:34:42,894] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2162719: loss 0.2848
[2019-03-24 09:34:42,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2162719: learning rate 0.0000
[2019-03-24 09:34:43,643] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2163037: loss 0.0523
[2019-03-24 09:34:43,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2163038: learning rate 0.0000
[2019-03-24 09:34:43,814] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2163115: loss 0.0370
[2019-03-24 09:34:43,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2163115: learning rate 0.0000
[2019-03-24 09:34:43,845] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2163124: loss 0.0402
[2019-03-24 09:34:43,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2163125: learning rate 0.0000
[2019-03-24 09:34:45,059] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2163652: loss 0.1001
[2019-03-24 09:34:45,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2163653: learning rate 0.0000
[2019-03-24 09:34:46,613] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2164316: loss 5.6478
[2019-03-24 09:34:46,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2164316: learning rate 0.0000
[2019-03-24 09:34:47,542] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2164717: loss 5.6067
[2019-03-24 09:34:47,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2164717: learning rate 0.0000
[2019-03-24 09:34:48,015] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2164919: loss 0.1395
[2019-03-24 09:34:48,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2164919: learning rate 0.0000
[2019-03-24 09:34:52,222] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2166727: loss 5.5399
[2019-03-24 09:34:52,224] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2166727: learning rate 0.0000
[2019-03-24 09:34:52,510] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2166851: loss 0.0350
[2019-03-24 09:34:52,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2166851: learning rate 0.0000
[2019-03-24 09:34:53,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8351383e-08 1.0430947e-08 1.7962455e-08 9.9999976e-01 8.8003439e-08], sum to 1.0000
[2019-03-24 09:34:53,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4473
[2019-03-24 09:34:53,049] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.06666666666667, 89.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400163.3611603021, 400163.3611603025, 150962.5198639531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1662600.0000, 
sim time next is 1663200.0000, 
raw observation next is [18.1, 89.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399820.4350039166, 399820.435003917, 150918.9223968887], 
processed observation next is [1.0, 0.2608695652173913, 0.22592592592592597, 0.89, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14279301250139878, 0.14279301250139895, 0.29022869691709363], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16797467], dtype=float32), 1.4326211]. 
=============================================
[2019-03-24 09:34:54,111] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2167536: loss 5.5593
[2019-03-24 09:34:54,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2167536: learning rate 0.0000
[2019-03-24 09:34:54,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9101463e-07 9.9093505e-08 9.8902788e-08 9.9999917e-01 3.3550631e-07], sum to 1.0000
[2019-03-24 09:34:54,281] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7471
[2019-03-24 09:34:54,289] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.43333333333333, 76.16666666666667, 1.0, 2.0, 0.1864970397440431, 1.0, 2.0, 0.1864970397440431, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 464065.9227155579, 464065.9227155583, 157152.5672240732], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1843800.0000, 
sim time next is 1844400.0000, 
raw observation next is [21.46666666666667, 76.33333333333334, 1.0, 2.0, 0.2626476646650108, 1.0, 2.0, 0.2626476646650108, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651977.4337303058, 651977.4337303058, 173838.8939430045], 
processed observation next is [1.0, 0.34782608695652173, 0.35061728395061736, 0.7633333333333334, 1.0, 1.0, 0.12219960079167956, 1.0, 1.0, 0.12219960079167956, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2328490834751092, 0.2328490834751092, 0.33430556527500865], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.49387553], dtype=float32), -0.25647584]. 
=============================================
[2019-03-24 09:34:55,522] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2168140: loss 4.7344
[2019-03-24 09:34:55,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2168140: learning rate 0.0000
[2019-03-24 09:34:56,005] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2168349: loss 5.2185
[2019-03-24 09:34:56,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2168349: learning rate 0.0000
[2019-03-24 09:34:57,309] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168906: loss 5.3694
[2019-03-24 09:34:57,311] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168906: learning rate 0.0000
[2019-03-24 09:34:59,412] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2169804: loss 4.8327
[2019-03-24 09:34:59,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2169804: learning rate 0.0000
[2019-03-24 09:34:59,472] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2169829: loss 0.0241
[2019-03-24 09:34:59,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2169832: learning rate 0.0000
[2019-03-24 09:35:01,759] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2170803: loss 4.7805
[2019-03-24 09:35:01,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2170805: learning rate 0.0000
[2019-03-24 09:35:02,269] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2171027: loss 4.7947
[2019-03-24 09:35:02,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2171027: learning rate 0.0000
[2019-03-24 09:35:02,463] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2171109: loss 5.0229
[2019-03-24 09:35:02,466] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2171109: learning rate 0.0000
[2019-03-24 09:35:02,492] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2171122: loss 4.9632
[2019-03-24 09:35:02,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2171123: learning rate 0.0000
[2019-03-24 09:35:03,772] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2171670: loss 4.9724
[2019-03-24 09:35:03,774] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2171670: learning rate 0.0000
[2019-03-24 09:35:04,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6365662e-07 9.5163175e-09 2.1041045e-07 9.9999893e-01 3.4058516e-08], sum to 1.0000
[2019-03-24 09:35:04,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0155
[2019-03-24 09:35:04,129] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.76666666666667, 77.0, 1.0, 2.0, 0.3585632474022764, 1.0, 2.0, 0.3585632474022764, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880918.4775023491, 880918.4775023495, 197595.1142458981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1849800.0000, 
sim time next is 1850400.0000, 
raw observation next is [21.8, 77.0, 1.0, 2.0, 0.360205315328469, 1.0, 2.0, 0.360205315328469, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 884506.307847731, 884506.3078477315, 198021.1202633563], 
processed observation next is [1.0, 0.43478260869565216, 0.362962962962963, 0.77, 1.0, 1.0, 0.23833966110532023, 1.0, 1.0, 0.23833966110532023, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31589510994561826, 0.3158951099456184, 0.3808098466603006], 
reward next is 0.6192, 
noisyNet noise sample is [array([-0.36622456], dtype=float32), 3.1795306]. 
=============================================
[2019-03-24 09:35:05,250] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2172302: loss 0.0030
[2019-03-24 09:35:05,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2172302: learning rate 0.0000
[2019-03-24 09:35:06,128] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2172682: loss 0.0070
[2019-03-24 09:35:06,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2172682: learning rate 0.0000
[2019-03-24 09:35:06,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2172894: loss 4.5832
[2019-03-24 09:35:06,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2172894: learning rate 0.0000
[2019-03-24 09:35:06,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5030635e-06 4.0095310e-06 3.0409015e-07 9.9997687e-01 1.5313773e-05], sum to 1.0000
[2019-03-24 09:35:06,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2471
[2019-03-24 09:35:06,681] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.96666666666667, 95.33333333333334, 1.0, 2.0, 0.2917661852738327, 1.0, 2.0, 0.2917661852738327, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690029.2884244624, 690029.2884244629, 179650.7853798916], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2341200.0000, 
sim time next is 2341800.0000, 
raw observation next is [21.95, 95.5, 1.0, 2.0, 0.2731508503822532, 1.0, 2.0, 0.2731508503822532, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646724.6690205587, 646724.6690205587, 175269.5471285651], 
processed observation next is [1.0, 0.08695652173913043, 0.36851851851851847, 0.955, 1.0, 1.0, 0.13470339331220615, 1.0, 1.0, 0.13470339331220615, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23097309607877098, 0.23097309607877098, 0.3370568214010867], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.3995737], dtype=float32), -0.6173151]. 
=============================================
[2019-03-24 09:35:08,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4269007e-07 2.6916337e-07 1.2706942e-06 9.9999380e-01 4.5493111e-06], sum to 1.0000
[2019-03-24 09:35:08,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3727
[2019-03-24 09:35:08,479] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 98.0, 1.0, 2.0, 0.3188473260745485, 1.0, 2.0, 0.3188473260745485, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735974.9690555361, 735974.9690555366, 185491.7038190578], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2254800.0000, 
sim time next is 2255400.0000, 
raw observation next is [22.65, 98.0, 1.0, 2.0, 0.279015322353368, 1.0, 2.0, 0.279015322353368, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647226.1627540549, 647226.1627540549, 176056.2575182536], 
processed observation next is [1.0, 0.08695652173913043, 0.3944444444444444, 0.98, 1.0, 1.0, 0.14168490756353336, 1.0, 1.0, 0.14168490756353336, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23115220098359102, 0.23115220098359102, 0.33856972599664154], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.46653706], dtype=float32), 0.16823943]. 
=============================================
[2019-03-24 09:35:08,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5562310e-08 3.5964576e-06 9.9610907e-07 9.9999273e-01 2.6507894e-06], sum to 1.0000
[2019-03-24 09:35:08,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0529
[2019-03-24 09:35:08,811] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.36666666666667, 77.0, 1.0, 2.0, 0.3005625132451514, 1.0, 2.0, 0.3005625132451514, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685455.8372761403, 685455.8372761408, 180615.4878684719], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2154000.0000, 
sim time next is 2154600.0000, 
raw observation next is [26.2, 77.5, 1.0, 2.0, 0.2979302671088505, 1.0, 2.0, 0.2979302671088505, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 680754.5430958718, 680754.5430958723, 180049.9214082311], 
processed observation next is [0.0, 0.9565217391304348, 0.5259259259259259, 0.775, 1.0, 1.0, 0.16420269893910774, 1.0, 1.0, 0.16420269893910774, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24312662253423994, 0.24312662253424008, 0.3462498488619829], 
reward next is 0.6538, 
noisyNet noise sample is [array([-1.441024], dtype=float32), 1.8071395]. 
=============================================
[2019-03-24 09:35:10,984] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2174747: loss 0.0040
[2019-03-24 09:35:10,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2174747: learning rate 0.0000
[2019-03-24 09:35:11,138] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2174818: loss 0.0040
[2019-03-24 09:35:11,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2174818: learning rate 0.0000
[2019-03-24 09:35:11,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2641289e-06 9.1251820e-07 5.0704716e-06 9.9999142e-01 1.8645619e-07], sum to 1.0000
[2019-03-24 09:35:11,376] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7537
[2019-03-24 09:35:11,381] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.08333333333334, 89.16666666666667, 1.0, 2.0, 0.3715860062873345, 1.0, 2.0, 0.3715860062873345, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 901178.3515145727, 901178.3515145723, 200749.904191439], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1932600.0000, 
sim time next is 1933200.0000, 
raw observation next is [21.2, 89.0, 1.0, 2.0, 0.3776909952129062, 1.0, 2.0, 0.3776909952129062, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 914409.6628033664, 914409.6628033669, 202355.7560733185], 
processed observation next is [1.0, 0.391304347826087, 0.34074074074074073, 0.89, 1.0, 1.0, 0.25915594668203124, 1.0, 1.0, 0.25915594668203124, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32657487957263087, 0.32657487957263104, 0.3891456847563817], 
reward next is 0.6109, 
noisyNet noise sample is [array([0.9175993], dtype=float32), -1.2378081]. 
=============================================
[2019-03-24 09:35:11,564] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 09:35:11,565] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:35:11,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:35:11,567] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:35:11,570] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:35:11,570] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:35:11,572] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:35:11,575] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:35:11,573] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:35:11,576] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:35:11,577] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:35:11,603] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-24 09:35:11,654] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-24 09:35:11,656] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-24 09:35:11,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-24 09:35:11,656] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-24 09:35:39,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:35:39,253] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.03612417, 79.30531522000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 387839.975207478, 387839.9752074785, 149103.6404795292]
[2019-03-24 09:35:39,253] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:35:39,255] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.08959235e-07 9.80700960e-08 2.56873221e-07 9.99999404e-01
 1.23242529e-07], sampled 0.6705359757902208
[2019-03-24 09:36:02,531] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:02,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.66666666666667, 100.0, 1.0, 2.0, 0.2687877616614845, 1.0, 2.0, 0.2687877616614845, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634801.2911706021, 634801.2911706021, 174186.1195692146]
[2019-03-24 09:36:02,535] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:36:02,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8501664e-08 6.9369761e-08 1.9230076e-07 9.9999952e-01 8.7080572e-08], sampled 0.8100546062038718
[2019-03-24 09:36:08,436] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:08,438] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.01784990666667, 89.25622291333335, 1.0, 2.0, 0.5868625959117156, 1.0, 2.0, 0.5868625959117156, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1338186.162792256, 1338186.162792255, 263554.4137755042]
[2019-03-24 09:36:08,441] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:36:08,444] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.16233430e-07 1.02653345e-07 2.77572440e-07 9.99999404e-01
 1.28765976e-07], sampled 0.8714967660250469
[2019-03-24 09:36:34,690] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:34,692] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.39241774, 68.44718774333333, 1.0, 2.0, 0.3334429355943554, 1.0, 2.0, 0.3334429355943554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760042.5269301846, 760042.526930185, 188680.3635601597]
[2019-03-24 09:36:34,694] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:36:34,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.4667880e-08 5.7095658e-08 1.5748329e-07 9.9999964e-01 6.7694103e-08], sampled 0.8812082869544102
[2019-03-24 09:36:43,681] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:43,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.6996532334861107, 1.0, 2.0, 0.6996532334861107, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1595641.487128913, 1595641.487128914, 304033.3081497356]
[2019-03-24 09:36:43,683] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:36:43,686] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8279002e-07 1.6054470e-07 4.2623708e-07 9.9999905e-01 1.9902843e-07], sampled 0.7603477929784335
[2019-03-24 09:36:51,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:51,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.66666666666666, 53.0, 1.0, 2.0, 0.4358621224037038, 1.0, 2.0, 0.4358621224037038, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 993645.9151038518, 993645.9151038523, 216259.3374759376]
[2019-03-24 09:36:51,865] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:36:51,869] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1625394e-07 1.0297986e-07 2.7786538e-07 9.9999940e-01 1.2363266e-07], sampled 0.19266233103720642
[2019-03-24 09:36:58,743] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01094962], dtype=float32), 0.010530371]
[2019-03-24 09:36:58,745] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.80420710666667, 64.10263140333333, 1.0, 2.0, 0.7134453102792947, 1.0, 2.0, 0.7134453102792947, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 124.0921755517934, 1655325.817932583, 1655325.817932584, 311035.2172892797]
[2019-03-24 09:36:58,747] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:36:58,751] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3318451e-07 1.1749491e-07 3.1687586e-07 9.9999928e-01 1.4380039e-07], sampled 0.17583614487435928
[2019-03-24 09:37:20,120] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:37:20,248] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:37:20,645] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:37:20,700] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:37:20,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0159 2668535969.8193 68.0000
[2019-03-24 09:37:21,978] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2175000, evaluation results [2175000.0, 7523.015860012835, 2668535969.8192725, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:37:22,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9540425e-07 1.2384605e-06 3.7571540e-06 9.9999154e-01 3.3298795e-06], sum to 1.0000
[2019-03-24 09:37:22,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-24 09:37:22,709] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.71666666666667, 78.33333333333334, 1.0, 2.0, 0.189131397932453, 1.0, 2.0, 0.189131397932453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467104.2902095045, 467104.290209505, 157605.536752416], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2016600.0000, 
sim time next is 2017200.0000, 
raw observation next is [21.93333333333334, 77.66666666666667, 1.0, 2.0, 0.1915886343613484, 1.0, 2.0, 0.1915886343613484, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472375.1296032291, 472375.1296032295, 158091.066428711], 
processed observation next is [0.0, 0.34782608695652173, 0.3679012345679015, 0.7766666666666667, 1.0, 1.0, 0.03760551709684334, 1.0, 1.0, 0.03760551709684334, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16870540342972468, 0.16870540342972484, 0.304021281593675], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.12331672], dtype=float32), -0.51311874]. 
=============================================
[2019-03-24 09:37:23,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4890035e-06 8.6510312e-08 7.9278936e-07 9.9999642e-01 8.7897469e-08], sum to 1.0000
[2019-03-24 09:37:23,173] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2879
[2019-03-24 09:37:23,183] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.36666666666667, 80.83333333333334, 1.0, 2.0, 0.2380210414028507, 1.0, 2.0, 0.2380210414028507, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569355.4609603204, 569355.4609603204, 167512.969768212], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2322600.0000, 
sim time next is 2323200.0000, 
raw observation next is [23.23333333333333, 81.66666666666667, 1.0, 2.0, 0.2376553735869778, 1.0, 2.0, 0.2376553735869778, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 568649.8671169098, 568649.8671169102, 167438.4441664925], 
processed observation next is [1.0, 0.9130434782608695, 0.4160493827160493, 0.8166666666666668, 1.0, 1.0, 0.09244687331783072, 1.0, 1.0, 0.09244687331783072, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20308923825603922, 0.20308923825603933, 0.3219970080124856], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.84931856], dtype=float32), -0.68910277]. 
=============================================
[2019-03-24 09:37:23,269] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2175543: loss 0.0037
[2019-03-24 09:37:23,271] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2175543: learning rate 0.0000
[2019-03-24 09:37:23,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6568677e-08 1.5181003e-08 1.3498930e-06 9.9999857e-01 4.9933466e-09], sum to 1.0000
[2019-03-24 09:37:23,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4981
[2019-03-24 09:37:23,879] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.38333333333333, 92.16666666666667, 1.0, 2.0, 0.1821292419557353, 1.0, 2.0, 0.1821292419557353, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453233.5909820474, 453233.5909820479, 156240.0050736885], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1998600.0000, 
sim time next is 1999200.0000, 
raw observation next is [19.36666666666667, 92.33333333333334, 1.0, 2.0, 0.1819633469552025, 1.0, 2.0, 0.1819633469552025, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 452796.0550951576, 452796.0550951581, 156204.7965406257], 
processed observation next is [0.0, 0.13043478260869565, 0.27283950617283964, 0.9233333333333335, 1.0, 1.0, 0.026146841613336306, 1.0, 1.0, 0.026146841613336306, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16171287681969915, 0.1617128768196993, 0.3003938395012033], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.0802022], dtype=float32), 0.5098706]. 
=============================================
[2019-03-24 09:37:24,296] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4284542e-06 1.7297690e-07 7.1993264e-07 9.9999487e-01 8.1940220e-07], sum to 1.0000
[2019-03-24 09:37:24,308] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2156
[2019-03-24 09:37:24,316] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.08333333333334, 50.5, 1.0, 2.0, 0.2869729788498229, 1.0, 2.0, 0.2869729788498229, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 658730.7007236711, 658730.7007236716, 177597.4363235528], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2128200.0000, 
sim time next is 2128800.0000, 
raw observation next is [31.16666666666667, 50.00000000000001, 1.0, 2.0, 0.2860393161527445, 1.0, 2.0, 0.2860393161527445, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657008.7065250205, 657008.7065250205, 177397.9357891864], 
processed observation next is [0.0, 0.6521739130434783, 0.7098765432098767, 0.5000000000000001, 1.0, 1.0, 0.15004680494374348, 1.0, 1.0, 0.15004680494374348, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23464596661607875, 0.23464596661607875, 0.34114987651766615], 
reward next is 0.6589, 
noisyNet noise sample is [array([-1.0433694], dtype=float32), -0.67995554]. 
=============================================
[2019-03-24 09:37:24,685] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2176152: loss 0.0196
[2019-03-24 09:37:24,688] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2176153: learning rate 0.0000
[2019-03-24 09:37:25,016] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2176294: loss 0.0013
[2019-03-24 09:37:25,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2176295: learning rate 0.0000
[2019-03-24 09:37:26,378] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176888: loss 0.0119
[2019-03-24 09:37:26,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176888: learning rate 0.0000
[2019-03-24 09:37:27,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5205766e-06 6.6559103e-08 8.6345204e-07 9.9999380e-01 6.7510899e-07], sum to 1.0000
[2019-03-24 09:37:27,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5656
[2019-03-24 09:37:27,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.86666666666667, 72.0, 1.0, 2.0, 0.6206085960573478, 1.0, 2.0, 0.6206085960573478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1434942.400458439, 1434942.400458439, 276167.5440872184], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2302800.0000, 
sim time next is 2303400.0000, 
raw observation next is [25.93333333333333, 71.5, 1.0, 2.0, 0.6217240860883881, 1.0, 2.0, 0.6217240860883881, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1437664.928605382, 1437664.928605382, 276568.0849195498], 
processed observation next is [1.0, 0.6521739130434783, 0.5160493827160493, 0.715, 1.0, 1.0, 0.5496715310576049, 1.0, 1.0, 0.5496715310576049, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5134517602162079, 0.5134517602162079, 0.531861701768365], 
reward next is 0.4681, 
noisyNet noise sample is [array([0.8564493], dtype=float32), 0.20605181]. 
=============================================
[2019-03-24 09:37:28,539] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2177815: loss 0.0011
[2019-03-24 09:37:28,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2177816: learning rate 0.0000
[2019-03-24 09:37:28,679] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2177875: loss 0.0035
[2019-03-24 09:37:28,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2177875: learning rate 0.0000
[2019-03-24 09:37:30,817] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2178789: loss 0.0073
[2019-03-24 09:37:30,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2178790: learning rate 0.0000
[2019-03-24 09:37:31,368] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2179028: loss 0.0041
[2019-03-24 09:37:31,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2179029: learning rate 0.0000
[2019-03-24 09:37:31,470] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2179072: loss 0.0002
[2019-03-24 09:37:31,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2179073: learning rate 0.0000
[2019-03-24 09:37:31,521] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2179092: loss 0.0003
[2019-03-24 09:37:31,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2179092: learning rate 0.0000
[2019-03-24 09:37:32,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2179667: loss 0.0028
[2019-03-24 09:37:32,879] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2179667: learning rate 0.0000
[2019-03-24 09:37:34,523] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2180366: loss 0.0015
[2019-03-24 09:37:34,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2180367: learning rate 0.0000
[2019-03-24 09:37:35,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2180671: loss 0.0052
[2019-03-24 09:37:35,222] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2180671: learning rate 0.0000
[2019-03-24 09:37:35,741] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2180890: loss 0.0005
[2019-03-24 09:37:35,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2180890: learning rate 0.0000
[2019-03-24 09:37:38,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5582955e-06 1.2245079e-06 3.3238455e-05 9.9996352e-01 4.6394220e-07], sum to 1.0000
[2019-03-24 09:37:38,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5404
[2019-03-24 09:37:38,912] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.06666666666667, 95.0, 1.0, 2.0, 0.3824876350973828, 1.0, 2.0, 0.3824876350973828, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 917244.2582434964, 917244.2582434964, 203366.8692703444], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2277600.0000, 
sim time next is 2278200.0000, 
raw observation next is [21.23333333333333, 94.5, 1.0, 2.0, 0.3862519689165902, 1.0, 2.0, 0.3862519689165902, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 924575.9316139044, 924575.9316139049, 204337.0968771682], 
processed observation next is [1.0, 0.34782608695652173, 0.34197530864197523, 0.945, 1.0, 1.0, 0.26934758204355974, 1.0, 1.0, 0.26934758204355974, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33020568986210874, 0.3302056898621089, 0.39295595553301577], 
reward next is 0.6070, 
noisyNet noise sample is [array([-0.23106487], dtype=float32), 0.18896674]. 
=============================================
[2019-03-24 09:37:40,173] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2182798: loss 0.0004
[2019-03-24 09:37:40,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2182798: learning rate 0.0000
[2019-03-24 09:37:40,188] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2182804: loss 0.0024
[2019-03-24 09:37:40,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2182805: learning rate 0.0000
[2019-03-24 09:37:41,843] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2183517: loss 0.0029
[2019-03-24 09:37:41,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2183517: learning rate 0.0000
[2019-03-24 09:37:42,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8406844e-07 1.4968026e-07 3.5740939e-07 9.9999928e-01 1.6008860e-08], sum to 1.0000
[2019-03-24 09:37:42,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6590
[2019-03-24 09:37:42,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.48333333333333, 91.83333333333334, 1.0, 2.0, 0.6430791815452889, 1.0, 2.0, 0.6430791815452889, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1466496.061657463, 1466496.061657463, 283177.6217277443], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2218200.0000, 
sim time next is 2218800.0000, 
raw observation next is [24.26666666666667, 92.66666666666667, 1.0, 2.0, 0.5828767394825025, 1.0, 2.0, 0.5828767394825025, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1329089.57757417, 1329089.57757417, 262202.5052894734], 
processed observation next is [1.0, 0.6956521739130435, 0.4543209876543211, 0.9266666666666667, 1.0, 1.0, 0.503424689860122, 1.0, 1.0, 0.503424689860122, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4746748491336321, 0.4746748491336321, 0.5042355870951412], 
reward next is 0.4958, 
noisyNet noise sample is [array([0.49586913], dtype=float32), -0.80847675]. 
=============================================
[2019-03-24 09:37:43,095] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2184056: loss 0.0050
[2019-03-24 09:37:43,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2184056: learning rate 0.0000
[2019-03-24 09:37:43,663] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2184298: loss 0.0072
[2019-03-24 09:37:43,667] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2184300: learning rate 0.0000
[2019-03-24 09:37:44,971] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184858: loss 0.0035
[2019-03-24 09:37:44,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184858: learning rate 0.0000
[2019-03-24 09:37:45,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5409431e-07 3.3493754e-06 1.7154893e-07 9.9998713e-01 8.9920077e-06], sum to 1.0000
[2019-03-24 09:37:45,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3573
[2019-03-24 09:37:45,836] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 47.0, 1.0, 2.0, 0.1908761165771432, 1.0, 2.0, 0.1908761165771432, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472393.7393056062, 472393.7393056062, 157994.3030371584], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2503200.0000, 
sim time next is 2503800.0000, 
raw observation next is [26.8, 47.5, 1.0, 2.0, 0.1909760591943194, 1.0, 2.0, 0.1909760591943194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472583.4009422936, 472583.400942294, 158013.4281449517], 
processed observation next is [1.0, 1.0, 0.5481481481481482, 0.475, 1.0, 1.0, 0.03687626094561833, 1.0, 1.0, 0.03687626094561833, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16877978605081914, 0.16877978605081928, 0.3038719772018302], 
reward next is 0.6961, 
noisyNet noise sample is [array([-1.2618887], dtype=float32), -0.85862374]. 
=============================================
[2019-03-24 09:37:47,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2185843: loss 0.0151
[2019-03-24 09:37:47,274] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2185844: learning rate 0.0000
[2019-03-24 09:37:47,453] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2185924: loss 0.0147
[2019-03-24 09:37:47,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2185924: learning rate 0.0000
[2019-03-24 09:37:49,716] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2186898: loss 0.0145
[2019-03-24 09:37:49,718] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2186898: learning rate 0.0000
[2019-03-24 09:37:50,069] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2187051: loss 0.0026
[2019-03-24 09:37:50,074] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2187052: learning rate 0.0000
[2019-03-24 09:37:50,147] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2187088: loss 0.0076
[2019-03-24 09:37:50,149] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2187088: learning rate 0.0000
[2019-03-24 09:37:50,311] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2187156: loss 0.0270
[2019-03-24 09:37:50,312] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2187156: learning rate 0.0000
[2019-03-24 09:37:51,517] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2187674: loss 0.0424
[2019-03-24 09:37:51,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2187675: learning rate 0.0000
[2019-03-24 09:37:53,047] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2188326: loss 0.0031
[2019-03-24 09:37:53,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2188326: learning rate 0.0000
[2019-03-24 09:37:53,823] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2188655: loss 0.0030
[2019-03-24 09:37:53,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2188657: learning rate 0.0000
[2019-03-24 09:37:54,298] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2188860: loss 0.0065
[2019-03-24 09:37:54,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2188860: learning rate 0.0000
[2019-03-24 09:37:54,419] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7241514e-08 2.4139108e-08 9.9492770e-09 1.0000000e+00 1.1732927e-09], sum to 1.0000
[2019-03-24 09:37:54,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3676
[2019-03-24 09:37:54,434] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.96666666666667, 84.0, 1.0, 2.0, 0.2413583805927546, 1.0, 2.0, 0.2413583805927546, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 576708.3994582029, 576708.3994582033, 168231.4007624252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2594400.0000, 
sim time next is 2595000.0000, 
raw observation next is [22.78333333333333, 85.0, 1.0, 2.0, 0.240331233713602, 1.0, 2.0, 0.240331233713602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574744.1121849389, 574744.1121849393, 168021.7136566857], 
processed observation next is [0.0, 0.0, 0.39938271604938264, 0.85, 1.0, 1.0, 0.09563242108762142, 1.0, 1.0, 0.09563242108762142, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2052657543517639, 0.20526575435176406, 0.32311868010901096], 
reward next is 0.6769, 
noisyNet noise sample is [array([0.44429207], dtype=float32), 0.87763715]. 
=============================================
[2019-03-24 09:37:54,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.428185]
 [65.89077 ]
 [66.11276 ]
 [66.37266 ]
 [65.43688 ]], R is [[65.70820618]
 [65.7276001 ]
 [65.74634552]
 [65.76449585]
 [65.78214264]].
[2019-03-24 09:37:56,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.11397794e-10 3.54360310e-08 2.45009035e-09 9.99999881e-01
 9.38141866e-08], sum to 1.0000
[2019-03-24 09:37:56,581] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2810
[2019-03-24 09:37:56,586] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.3069790102141683, 1.0, 2.0, 0.3069790102141683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699693.704670536, 699693.7046705364, 182143.7820613558], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2649000.0000, 
sim time next is 2649600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.3068462431540547, 1.0, 2.0, 0.3068462431540547, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699390.9522016334, 699390.9522016338, 182111.6060647403], 
processed observation next is [0.0, 0.6956521739130435, 0.5555555555555556, 0.74, 1.0, 1.0, 0.17481695613577938, 1.0, 1.0, 0.17481695613577938, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24978248292915478, 0.24978248292915495, 0.3502146270475775], 
reward next is 0.6498, 
noisyNet noise sample is [array([0.37185684], dtype=float32), -0.38580772]. 
=============================================
[2019-03-24 09:37:58,875] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2190804: loss 0.0010
[2019-03-24 09:37:58,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2190805: learning rate 0.0000
[2019-03-24 09:37:58,902] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2190814: loss 0.3392
[2019-03-24 09:37:58,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2190815: learning rate 0.0000
[2019-03-24 09:37:59,751] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8384389e-07 1.1751363e-07 4.4887875e-07 9.9999928e-01 1.4037304e-08], sum to 1.0000
[2019-03-24 09:37:59,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0771
[2019-03-24 09:37:59,768] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.4, 33.0, 1.0, 2.0, 0.756444689020661, 1.0, 2.0, 0.756444689020661, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1771728.139228824, 1771728.139228825, 328389.7193886484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2563200.0000, 
sim time next is 2563800.0000, 
raw observation next is [33.36666666666667, 33.16666666666666, 1.0, 2.0, 0.7524014971904508, 1.0, 2.0, 0.7524014971904508, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1761302.111410461, 1761302.11141046, 326723.3568263255], 
processed observation next is [1.0, 0.6956521739130435, 0.7913580246913581, 0.33166666666666655, 1.0, 1.0, 0.7052398776076795, 1.0, 1.0, 0.7052398776076795, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6290364683608789, 0.6290364683608786, 0.6283141477429336], 
reward next is 0.3717, 
noisyNet noise sample is [array([-0.06347439], dtype=float32), 0.49345598]. 
=============================================
[2019-03-24 09:38:00,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.21354065e-08 5.41911516e-10 4.53065852e-09 1.00000000e+00
 7.87445553e-10], sum to 1.0000
[2019-03-24 09:38:00,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6896
[2019-03-24 09:38:00,265] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 73.16666666666667, 1.0, 2.0, 0.3001904995108358, 1.0, 2.0, 0.3001904995108358, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685083.5232688921, 685083.5232688925, 180550.1447743029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2656200.0000, 
sim time next is 2656800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.3042439846223322, 1.0, 2.0, 0.3042439846223322, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693456.9728720584, 693456.9728720584, 181482.1719950509], 
processed observation next is [0.0, 0.782608695652174, 0.5555555555555556, 0.74, 1.0, 1.0, 0.17171902931230026, 1.0, 1.0, 0.17171902931230026, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2476632045971637, 0.2476632045971637, 0.34900417691355945], 
reward next is 0.6510, 
noisyNet noise sample is [array([1.8058347], dtype=float32), -0.496777]. 
=============================================
[2019-03-24 09:38:00,467] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2191490: loss 0.0094
[2019-03-24 09:38:00,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2191490: learning rate 0.0000
[2019-03-24 09:38:00,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6554823e-09 5.7718563e-09 1.8358463e-08 1.0000000e+00 4.0535038e-08], sum to 1.0000
[2019-03-24 09:38:00,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-24 09:38:00,965] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.76666666666667, 56.66666666666667, 1.0, 2.0, 0.2563888108711176, 1.0, 2.0, 0.2563888108711176, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 634123.4924190779, 634123.4924190784, 172330.5866178214], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2517600.0000, 
sim time next is 2518200.0000, 
raw observation next is [24.7, 57.0, 1.0, 2.0, 0.25574978608054, 1.0, 2.0, 0.25574978608054, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 632689.6461171451, 632689.6461171455, 172187.0372264693], 
processed observation next is [1.0, 0.13043478260869565, 0.4703703703703703, 0.57, 1.0, 1.0, 0.11398784057207142, 1.0, 1.0, 0.11398784057207142, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22596058789898038, 0.22596058789898055, 0.33112891774321024], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.8538746], dtype=float32), -0.190201]. 
=============================================
[2019-03-24 09:38:01,786] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2192045: loss 0.0102
[2019-03-24 09:38:01,787] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2192046: learning rate 0.0000
[2019-03-24 09:38:02,114] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2192189: loss 0.0107
[2019-03-24 09:38:02,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2192193: learning rate 0.0000
[2019-03-24 09:38:03,690] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192860: loss 0.0142
[2019-03-24 09:38:03,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192860: learning rate 0.0000
[2019-03-24 09:38:04,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0435495e-07 8.5687469e-07 3.8042972e-06 9.9999464e-01 5.4110893e-07], sum to 1.0000
[2019-03-24 09:38:04,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6131
[2019-03-24 09:38:04,683] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.96666666666667, 93.33333333333334, 1.0, 2.0, 0.5017875218146501, 1.0, 2.0, 0.5017875218146501, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1162542.703416996, 1162542.703416996, 236809.9446607986], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2883000.0000, 
sim time next is 2883600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5183416272318754, 1.0, 2.0, 0.5183416272318754, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1197464.068741303, 1197464.068741303, 241859.9029670148], 
processed observation next is [1.0, 0.391304347826087, 0.4074074074074074, 0.94, 1.0, 1.0, 0.4265971752760421, 1.0, 1.0, 0.4265971752760421, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.42766573883617964, 0.42766573883617964, 0.46511519801349], 
reward next is 0.5349, 
noisyNet noise sample is [array([-0.1399315], dtype=float32), 0.2980508]. 
=============================================
[2019-03-24 09:38:05,993] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2193843: loss 0.0273
[2019-03-24 09:38:05,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2193843: learning rate 0.0000
[2019-03-24 09:38:06,212] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2193938: loss 0.1400
[2019-03-24 09:38:06,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2193938: learning rate 0.0000
[2019-03-24 09:38:07,912] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.20847430e-05 1.00198285e-07 1.97694089e-06 9.99958873e-01
 6.85606983e-06], sum to 1.0000
[2019-03-24 09:38:07,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-24 09:38:07,927] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.58333333333333, 91.5, 1.0, 2.0, 0.2610655814844557, 1.0, 2.0, 0.2610655814844557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 616533.4396606985, 616533.439660699, 172403.1895593779], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2857800.0000, 
sim time next is 2858400.0000, 
raw observation next is [22.5, 91.0, 1.0, 2.0, 0.2582395340138144, 1.0, 2.0, 0.2582395340138144, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611542.9561815572, 611542.9561815572, 171827.6816110364], 
processed observation next is [1.0, 0.08695652173913043, 0.3888888888888889, 0.91, 1.0, 1.0, 0.11695182620692189, 1.0, 1.0, 0.11695182620692189, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21840819863627042, 0.21840819863627042, 0.33043784925199304], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.11986815], dtype=float32), 0.729112]. 
=============================================
[2019-03-24 09:38:08,340] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2194857: loss 0.0107
[2019-03-24 09:38:08,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2194858: learning rate 0.0000
[2019-03-24 09:38:08,850] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2195079: loss 0.0010
[2019-03-24 09:38:08,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2195079: learning rate 0.0000
[2019-03-24 09:38:08,958] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2195120: loss 0.0052
[2019-03-24 09:38:08,961] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2195121: learning rate 0.0000
[2019-03-24 09:38:08,998] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2195136: loss 0.0118
[2019-03-24 09:38:09,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2195136: learning rate 0.0000
[2019-03-24 09:38:09,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9656493e-07 2.1269213e-06 8.7419721e-07 9.9999511e-01 9.5016179e-07], sum to 1.0000
[2019-03-24 09:38:10,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3818
[2019-03-24 09:38:10,015] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.8204951080489734, 1.0, 2.0, 0.8204951080489734, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1871524.290967628, 1871524.290967628, 352297.2268853657], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2981400.0000, 
sim time next is 2982000.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.7627980305964744, 1.0, 2.0, 0.7627980305964744, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1739790.850354846, 1739790.850354847, 328622.9235232439], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 0.717616703091041, 1.0, 1.0, 0.717616703091041, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6213538751267308, 0.6213538751267311, 0.631967160621623], 
reward next is 0.3680, 
noisyNet noise sample is [array([-0.17625669], dtype=float32), -0.34462553]. 
=============================================
[2019-03-24 09:38:10,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.77374 ]
 [50.124317]
 [49.705254]
 [49.411106]
 [49.77538 ]], R is [[51.06389618]
 [50.87576294]
 [50.6178093 ]
 [50.34005356]
 [50.07372284]].
[2019-03-24 09:38:10,257] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2195687: loss 0.0058
[2019-03-24 09:38:10,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2195688: learning rate 0.0000
[2019-03-24 09:38:11,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2594060e-08 1.7355793e-09 1.3966508e-09 1.0000000e+00 1.0873284e-10], sum to 1.0000
[2019-03-24 09:38:11,600] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0201
[2019-03-24 09:38:11,607] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.3407066661097109, 1.0, 2.0, 0.3407066661097109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 776607.7026771486, 776607.7026771491, 190516.586645815], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2840400.0000, 
sim time next is 2841000.0000, 
raw observation next is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.3397907868639919, 1.0, 2.0, 0.3397907868639919, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774518.9902854369, 774518.9902854369, 190284.0021823462], 
processed observation next is [1.0, 0.9130434782608695, 0.623456790123457, 0.7066666666666667, 1.0, 1.0, 0.2140366510285618, 1.0, 1.0, 0.2140366510285618, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2766139251019417, 0.2766139251019417, 0.36593077342758884], 
reward next is 0.6341, 
noisyNet noise sample is [array([-1.5729498], dtype=float32), 0.89049286]. 
=============================================
[2019-03-24 09:38:11,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.18931]
 [65.31853]
 [65.2036 ]
 [65.24866]
 [65.31406]], R is [[65.2363739 ]
 [65.21762848]
 [65.19895935]
 [65.18063354]
 [65.16300964]].
[2019-03-24 09:38:11,672] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1322005e-07 1.4466547e-06 3.6979440e-08 9.9999797e-01 1.3988141e-07], sum to 1.0000
[2019-03-24 09:38:11,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0047
[2019-03-24 09:38:11,685] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.2, 94.0, 1.0, 2.0, 0.2682293576853378, 1.0, 2.0, 0.2682293576853378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 634281.1623141796, 634281.16231418, 174090.1838699047], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2871000.0000, 
sim time next is 2871600.0000, 
raw observation next is [22.13333333333333, 94.0, 1.0, 2.0, 0.2639345367036559, 1.0, 2.0, 0.2639345367036559, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625007.2064691088, 625007.2064691093, 173134.1366020647], 
processed observation next is [1.0, 0.21739130434782608, 0.3753086419753085, 0.94, 1.0, 1.0, 0.12373159131387608, 1.0, 1.0, 0.12373159131387608, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22321685945325315, 0.2232168594532533, 0.3329502626962783], 
reward next is 0.6670, 
noisyNet noise sample is [array([-0.16078205], dtype=float32), 0.79569155]. 
=============================================
[2019-03-24 09:38:11,862] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2196376: loss 0.0776
[2019-03-24 09:38:11,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2196378: learning rate 0.0000
[2019-03-24 09:38:12,612] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2196701: loss 0.0330
[2019-03-24 09:38:12,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2196701: learning rate 0.0000
[2019-03-24 09:38:12,845] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2196804: loss 0.0017
[2019-03-24 09:38:12,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2196804: learning rate 0.0000
[2019-03-24 09:38:15,139] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2388066e-08 1.5462085e-07 5.0622953e-07 9.9999928e-01 7.6246785e-08], sum to 1.0000
[2019-03-24 09:38:15,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5234
[2019-03-24 09:38:15,158] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.41666666666667, 92.5, 1.0, 2.0, 0.5291491791338151, 1.0, 2.0, 0.5291491791338151, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.6813512779132, 1244651.734014201, 1244651.734014201, 246397.3130567562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.33333333333334, 94.0, 1.0, 2.0, 0.453776026100527, 1.0, 2.0, 0.453776026100527, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1062816.57669594, 1062816.57669594, 222750.3323035408], 
processed observation next is [1.0, 0.08695652173913043, 0.38271604938271625, 0.94, 1.0, 1.0, 0.3497333644053893, 1.0, 1.0, 0.3497333644053893, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37957734881997857, 0.37957734881997857, 0.4283660236606554], 
reward next is 0.5716, 
noisyNet noise sample is [array([0.7118536], dtype=float32), -1.3315251]. 
=============================================
[2019-03-24 09:38:17,409] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2198774: loss 0.0280
[2019-03-24 09:38:17,412] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2198775: learning rate 0.0000
[2019-03-24 09:38:17,524] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2198820: loss 0.0314
[2019-03-24 09:38:17,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2198820: learning rate 0.0000
[2019-03-24 09:38:18,461] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5003190e-05 2.7929304e-06 4.3731866e-06 9.9997771e-01 1.0350596e-07], sum to 1.0000
[2019-03-24 09:38:18,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9163
[2019-03-24 09:38:18,477] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3732657031399502, 1.0, 2.0, 0.3732657031399502, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 850864.0540189222, 850864.0540189226, 198971.902728333], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2951400.0000, 
sim time next is 2952000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3759546161286887, 1.0, 2.0, 0.3759546161286887, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856996.8932340547, 856996.8932340551, 199686.6369169074], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2570888287246294, 1.0, 1.0, 0.2570888287246294, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30607031901216236, 0.30607031901216253, 0.384012763301745], 
reward next is 0.6160, 
noisyNet noise sample is [array([-0.64714074], dtype=float32), 1.4117628]. 
=============================================
[2019-03-24 09:38:18,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[52.91043 ]
 [52.991142]
 [53.17215 ]
 [53.02063 ]
 [52.79764 ]], R is [[52.82284164]
 [52.91197586]
 [52.99771881]
 [53.08002472]
 [53.16205978]].
[2019-03-24 09:38:19,167] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2199519: loss 0.0310
[2019-03-24 09:38:19,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2199520: learning rate 0.0000
[2019-03-24 09:38:20,302] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 09:38:20,305] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:38:20,306] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:38:20,308] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:38:20,308] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:38:20,310] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:38:20,310] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:38:20,312] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:38:20,311] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:38:20,313] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:38:20,312] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:38:20,339] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-24 09:38:20,369] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-24 09:38:20,405] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-24 09:38:20,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-24 09:38:20,439] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-24 09:38:23,999] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01086491], dtype=float32), 0.01046224]
[2019-03-24 09:38:24,001] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [13.75, 70.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 216631.8622584448, 216631.8622584452, 93463.99772248439]
[2019-03-24 09:38:24,001] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:38:24,004] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.2675205e-07 4.1427168e-07 7.3138676e-07 9.9999821e-01 1.8174708e-07], sampled 0.7509380225663019
[2019-03-24 09:39:09,894] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01086491], dtype=float32), 0.01046224]
[2019-03-24 09:39:09,900] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.58568307, 105.098323965, 1.0, 2.0, 0.3257271822114315, 1.0, 2.0, 0.3257271822114315, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 123.0537652762392, 782370.7981726712, 782370.7981726708, 188637.5088960455]
[2019-03-24 09:39:09,902] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:39:09,905] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.9577808e-08 6.6087892e-08 1.2602905e-07 9.9999964e-01 2.5736847e-08], sampled 0.5856650582773143
[2019-03-24 09:39:23,885] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01086491], dtype=float32), 0.01046224]
[2019-03-24 09:39:23,885] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.83333333333334, 89.16666666666666, 1.0, 2.0, 0.3307426648162439, 1.0, 2.0, 0.3307426648162439, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753884.5621070437, 753884.5621070442, 188002.1606449362]
[2019-03-24 09:39:23,886] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:39:23,888] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.0966464e-08 5.7196495e-08 1.1021612e-07 9.9999988e-01 2.2458188e-08], sampled 0.19281924076742762
[2019-03-24 09:39:53,644] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01086491], dtype=float32), 0.01046224]
[2019-03-24 09:39:53,645] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.33333333333334, 47.33333333333334, 1.0, 2.0, 0.2951473829510863, 1.0, 2.0, 0.2951473829510863, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672714.1810164286, 672714.1810164291, 179300.359893567]
[2019-03-24 09:39:53,650] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:39:53,653] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8771278e-08 5.6040811e-08 1.0652664e-07 9.9999988e-01 2.1148765e-08], sampled 0.026211752475490346
[2019-03-24 09:40:09,301] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01086491], dtype=float32), 0.01046224]
[2019-03-24 09:40:09,302] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.9, 38.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 375562.2578579413, 375562.2578579417, 146739.9672982612]
[2019-03-24 09:40:09,302] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:40:09,304] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.3303903e-07 3.3074176e-07 5.8193427e-07 9.9999857e-01 1.3347179e-07], sampled 0.26497053707770357
[2019-03-24 09:40:29,174] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:40:29,204] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:40:29,682] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:40:29,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:40:29,802] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:40:30,821] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2200000, evaluation results [2200000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:40:30,913] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2200044: loss 0.0287
[2019-03-24 09:40:30,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2200044: learning rate 0.0000
[2019-03-24 09:40:31,230] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2200178: loss 0.0248
[2019-03-24 09:40:31,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2200178: learning rate 0.0000
[2019-03-24 09:40:32,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200830: loss 0.0122
[2019-03-24 09:40:32,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200830: learning rate 0.0000
[2019-03-24 09:40:33,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8641488e-08 4.7007451e-09 3.2564788e-08 9.9999988e-01 2.5003688e-09], sum to 1.0000
[2019-03-24 09:40:33,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6211
[2019-03-24 09:40:33,174] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.23333333333334, 89.66666666666667, 1.0, 2.0, 0.322993213379237, 1.0, 2.0, 0.322993213379237, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736212.2205210441, 736212.2205210441, 186070.0696967583], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2935200.0000, 
sim time next is 2935800.0000, 
raw observation next is [25.2, 90.0, 1.0, 2.0, 0.3230419034863424, 1.0, 2.0, 0.3230419034863424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736323.2552639624, 736323.2552639629, 186082.1508975377], 
processed observation next is [1.0, 1.0, 0.4888888888888889, 0.9, 1.0, 1.0, 0.19409750415040758, 1.0, 1.0, 0.19409750415040758, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2629725911657009, 0.26297259116570104, 0.35785029018757253], 
reward next is 0.6421, 
noisyNet noise sample is [array([1.1584318], dtype=float32), -0.5823547]. 
=============================================
[2019-03-24 09:40:35,052] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2201821: loss 0.0208
[2019-03-24 09:40:35,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2201821: learning rate 0.0000
[2019-03-24 09:40:35,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2201853: loss 0.0585
[2019-03-24 09:40:35,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2201853: learning rate 0.0000
[2019-03-24 09:40:37,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1354644e-06 4.9543846e-06 1.9969684e-06 9.9998665e-01 2.3358004e-07], sum to 1.0000
[2019-03-24 09:40:37,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-24 09:40:37,018] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.55, 79.5, 1.0, 2.0, 0.8575900615843598, 1.0, 2.0, 0.8575900615843598, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1956229.412846716, 1956229.412846716, 368126.2639690932], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3079800.0000, 
sim time next is 3080400.0000, 
raw observation next is [27.03333333333333, 81.0, 1.0, 2.0, 0.8659925507445765, 1.0, 2.0, 0.8659925507445765, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1975417.340040634, 1975417.340040634, 371777.9781610054], 
processed observation next is [1.0, 0.6521739130434783, 0.55679012345679, 0.81, 1.0, 1.0, 0.840467322314972, 1.0, 1.0, 0.840467322314972, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.705506192871655, 0.705506192871655, 0.7149576503096258], 
reward next is 0.2850, 
noisyNet noise sample is [array([1.0374608], dtype=float32), -0.68355095]. 
=============================================
[2019-03-24 09:40:37,478] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2202871: loss 0.0135
[2019-03-24 09:40:37,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2202871: learning rate 0.0000
[2019-03-24 09:40:37,937] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2203071: loss 0.0058
[2019-03-24 09:40:37,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2203071: learning rate 0.0000
[2019-03-24 09:40:38,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2203106: loss 0.0059
[2019-03-24 09:40:38,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2203106: learning rate 0.0000
[2019-03-24 09:40:38,231] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2203195: loss 0.0021
[2019-03-24 09:40:38,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2203195: learning rate 0.0000
[2019-03-24 09:40:39,520] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2203749: loss 0.0695
[2019-03-24 09:40:39,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2203749: learning rate 0.0000
[2019-03-24 09:40:41,100] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2204417: loss 0.0029
[2019-03-24 09:40:41,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2204418: learning rate 0.0000
[2019-03-24 09:40:41,785] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2204712: loss 0.0589
[2019-03-24 09:40:41,787] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2204712: learning rate 0.0000
[2019-03-24 09:40:42,075] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2204839: loss 0.0064
[2019-03-24 09:40:42,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2204839: learning rate 0.0000
[2019-03-24 09:40:46,651] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2206791: loss 0.0004
[2019-03-24 09:40:46,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2206792: learning rate 0.0000
[2019-03-24 09:40:46,680] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2206803: loss 0.0193
[2019-03-24 09:40:46,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2206803: learning rate 0.0000
[2019-03-24 09:40:48,386] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2207544: loss 0.0107
[2019-03-24 09:40:48,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2207545: learning rate 0.0000
[2019-03-24 09:40:49,609] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2208077: loss 0.0057
[2019-03-24 09:40:49,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2208078: learning rate 0.0000
[2019-03-24 09:40:49,955] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2208227: loss 0.0188
[2019-03-24 09:40:49,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2208229: learning rate 0.0000
[2019-03-24 09:40:51,427] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208851: loss 0.0035
[2019-03-24 09:40:51,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208856: learning rate 0.0000
[2019-03-24 09:40:53,633] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2209801: loss 0.0419
[2019-03-24 09:40:53,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2209802: learning rate 0.0000
[2019-03-24 09:40:53,686] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2209827: loss 0.0283
[2019-03-24 09:40:53,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2209829: learning rate 0.0000
[2019-03-24 09:40:56,083] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2210862: loss 0.0101
[2019-03-24 09:40:56,085] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2210863: learning rate 0.0000
[2019-03-24 09:40:56,537] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2211055: loss 0.0049
[2019-03-24 09:40:56,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2211058: learning rate 0.0000
[2019-03-24 09:40:56,582] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2211075: loss 0.0010
[2019-03-24 09:40:56,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2211077: learning rate 0.0000
[2019-03-24 09:40:57,006] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2211266: loss 0.0100
[2019-03-24 09:40:57,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2211266: learning rate 0.0000
[2019-03-24 09:40:58,022] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2211709: loss 0.0001
[2019-03-24 09:40:58,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2211710: learning rate 0.0000
[2019-03-24 09:40:59,657] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2212421: loss 0.0110
[2019-03-24 09:40:59,660] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2212421: learning rate 0.0000
[2019-03-24 09:41:00,449] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2212756: loss 0.0081
[2019-03-24 09:41:00,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2212756: learning rate 0.0000
[2019-03-24 09:41:00,530] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2212791: loss 0.0013
[2019-03-24 09:41:00,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2212792: learning rate 0.0000
[2019-03-24 09:41:02,645] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5213507e-06 1.6307831e-06 2.5149743e-07 9.9999630e-01 2.1539469e-07], sum to 1.0000
[2019-03-24 09:41:02,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2932
[2019-03-24 09:41:02,655] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.08333333333333, 93.16666666666666, 1.0, 2.0, 0.2508174326947469, 1.0, 2.0, 0.2508174326947469, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595416.5041642471, 595416.5041642475, 170201.5858039538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3570600.0000, 
sim time next is 3571200.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.2812180171390383, 1.0, 2.0, 0.2812180171390383, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669688.0421263465, 669688.0421263465, 177322.4743453274], 
processed observation next is [1.0, 0.34782608695652173, 0.36666666666666664, 0.93, 1.0, 1.0, 0.1443071632607599, 1.0, 1.0, 0.1443071632607599, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23917430075940946, 0.23917430075940946, 0.3410047583563989], 
reward next is 0.6590, 
noisyNet noise sample is [array([-0.5068966], dtype=float32), 0.5192484]. 
=============================================
[2019-03-24 09:41:05,158] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2214787: loss 0.0501
[2019-03-24 09:41:05,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2214788: learning rate 0.0000
[2019-03-24 09:41:05,180] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2214797: loss 0.0029
[2019-03-24 09:41:05,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2214797: learning rate 0.0000
[2019-03-24 09:41:06,816] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2215498: loss 0.0229
[2019-03-24 09:41:06,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2215498: learning rate 0.0000
[2019-03-24 09:41:08,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2216127: loss 0.0052
[2019-03-24 09:41:08,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2216128: learning rate 0.0000
[2019-03-24 09:41:08,618] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2216275: loss 0.0216
[2019-03-24 09:41:08,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2216275: learning rate 0.0000
[2019-03-24 09:41:09,983] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216852: loss 0.0613
[2019-03-24 09:41:09,985] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216852: learning rate 0.0000
[2019-03-24 09:41:12,119] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2217773: loss 0.0082
[2019-03-24 09:41:12,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2217773: learning rate 0.0000
[2019-03-24 09:41:12,226] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2217824: loss 0.0293
[2019-03-24 09:41:12,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2217825: learning rate 0.0000
[2019-03-24 09:41:14,672] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2218862: loss 0.0088
[2019-03-24 09:41:14,677] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2218863: learning rate 0.0000
[2019-03-24 09:41:15,047] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2219023: loss 0.0040
[2019-03-24 09:41:15,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2219025: learning rate 0.0000
[2019-03-24 09:41:15,140] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2219062: loss 0.0012
[2019-03-24 09:41:15,143] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2219062: learning rate 0.0000
[2019-03-24 09:41:15,592] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2219253: loss 0.0074
[2019-03-24 09:41:15,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2219253: learning rate 0.0000
[2019-03-24 09:41:15,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7317630e-07 4.4488420e-06 5.1746492e-06 9.9998820e-01 1.2656365e-06], sum to 1.0000
[2019-03-24 09:41:15,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7997
[2019-03-24 09:41:15,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 96.66666666666666, 1.0, 2.0, 0.3296408487156366, 1.0, 2.0, 0.3296408487156366, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751371.88579702, 751371.88579702, 187726.0549775617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3732000.0000, 
sim time next is 3732600.0000, 
raw observation next is [24.5, 97.33333333333333, 1.0, 2.0, 0.327057164289324, 1.0, 2.0, 0.327057164289324, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745479.8616596822, 745479.8616596827, 187080.6951210387], 
processed observation next is [1.0, 0.17391304347826086, 0.46296296296296297, 0.9733333333333333, 1.0, 1.0, 0.19887757653490956, 1.0, 1.0, 0.19887757653490956, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2662428077356008, 0.26624280773560094, 0.35977056754045905], 
reward next is 0.6402, 
noisyNet noise sample is [array([0.4858084], dtype=float32), 0.69793]. 
=============================================
[2019-03-24 09:41:15,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0704259e-06 3.8564726e-06 5.2511109e-07 9.9999404e-01 6.1044972e-07], sum to 1.0000
[2019-03-24 09:41:15,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4521
[2019-03-24 09:41:15,911] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.23333333333333, 85.33333333333333, 1.0, 2.0, 0.2699497560867972, 1.0, 2.0, 0.2699497560867972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628254.8205768404, 628254.8205768404, 174043.9350358698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3616800.0000, 
sim time next is 3617400.0000, 
raw observation next is [24.11666666666667, 87.16666666666667, 1.0, 2.0, 0.2733146827250506, 1.0, 2.0, 0.2733146827250506, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634376.8596708323, 634376.8596708323, 174744.5643225479], 
processed observation next is [1.0, 0.8695652173913043, 0.44876543209876557, 0.8716666666666667, 1.0, 1.0, 0.13489843181553643, 1.0, 1.0, 0.13489843181553643, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2265631641681544, 0.2265631641681544, 0.3360472390818229], 
reward next is 0.6640, 
noisyNet noise sample is [array([0.07916962], dtype=float32), 0.6164706]. 
=============================================
[2019-03-24 09:41:16,597] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2219689: loss 0.0476
[2019-03-24 09:41:16,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2219691: learning rate 0.0000
[2019-03-24 09:41:16,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4981907e-07 1.7434835e-06 8.5946300e-07 9.9999714e-01 4.2156646e-08], sum to 1.0000
[2019-03-24 09:41:16,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4607
[2019-03-24 09:41:16,987] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 91.0, 1.0, 2.0, 0.4433023143519004, 1.0, 2.0, 0.4433023143519004, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1045760.656697896, 1045760.656697896, 219977.4192511186], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3574800.0000, 
sim time next is 3575400.0000, 
raw observation next is [22.5, 90.66666666666667, 1.0, 2.0, 0.5092203593118477, 1.0, 2.0, 0.5092203593118477, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1197690.828688636, 1197690.828688636, 239916.5749629773], 
processed observation next is [1.0, 0.391304347826087, 0.3888888888888889, 0.9066666666666667, 1.0, 1.0, 0.4157385229902949, 1.0, 1.0, 0.4157385229902949, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4277467245316557, 0.4277467245316557, 0.4613780287749563], 
reward next is 0.5386, 
noisyNet noise sample is [array([-0.61016506], dtype=float32), -0.79642165]. 
=============================================
[2019-03-24 09:41:18,358] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2220440: loss 0.0035
[2019-03-24 09:41:18,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2220441: learning rate 0.0000
[2019-03-24 09:41:19,123] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2220769: loss 0.0272
[2019-03-24 09:41:19,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2220770: learning rate 0.0000
[2019-03-24 09:41:19,275] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2220835: loss 0.0544
[2019-03-24 09:41:19,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2220835: learning rate 0.0000
[2019-03-24 09:41:19,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5419726e-08 4.8291218e-07 1.5622251e-07 9.9999928e-01 7.5349142e-08], sum to 1.0000
[2019-03-24 09:41:20,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-24 09:41:20,014] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 65.0, 1.0, 2.0, 0.3250802508422595, 1.0, 2.0, 0.3250802508422595, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 740971.5933087897, 740971.5933087901, 186588.4787456784], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3795600.0000, 
sim time next is 3796200.0000, 
raw observation next is [29.25, 68.0, 1.0, 2.0, 0.3280232763983892, 1.0, 2.0, 0.3280232763983892, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747683.049522394, 747683.0495223944, 187321.9866481381], 
processed observation next is [1.0, 0.9565217391304348, 0.6388888888888888, 0.68, 1.0, 1.0, 0.20002770999808236, 1.0, 1.0, 0.20002770999808236, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26702966054371213, 0.2670296605437123, 0.36023458970795785], 
reward next is 0.6398, 
noisyNet noise sample is [array([3.317581], dtype=float32), 1.2554127]. 
=============================================
[2019-03-24 09:41:23,801] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2222794: loss 0.0531
[2019-03-24 09:41:23,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2222796: learning rate 0.0000
[2019-03-24 09:41:23,826] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2222802: loss 0.0023
[2019-03-24 09:41:23,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2222802: learning rate 0.0000
[2019-03-24 09:41:25,391] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2223479: loss 0.0101
[2019-03-24 09:41:25,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2223479: learning rate 0.0000
[2019-03-24 09:41:26,880] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2224121: loss 0.0897
[2019-03-24 09:41:26,883] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2224121: learning rate 0.0000
[2019-03-24 09:41:27,125] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2224226: loss 0.0353
[2019-03-24 09:41:27,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2224226: learning rate 0.0000
[2019-03-24 09:41:27,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1444328e-07 5.8389346e-06 7.3419830e-07 9.9999261e-01 6.6612898e-07], sum to 1.0000
[2019-03-24 09:41:27,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0273
[2019-03-24 09:41:27,387] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 85.0, 1.0, 2.0, 0.3549775285536361, 1.0, 2.0, 0.3549775285536361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809153.9153157745, 809153.915315775, 194177.4849590299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3969600.0000, 
sim time next is 3970200.0000, 
raw observation next is [26.41666666666667, 84.0, 1.0, 2.0, 0.3492474701869404, 1.0, 2.0, 0.3492474701869404, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796085.7445326438, 796085.7445326443, 192698.8251728974], 
processed observation next is [0.0, 0.9565217391304348, 0.5339506172839508, 0.84, 1.0, 1.0, 0.22529460736540527, 1.0, 1.0, 0.22529460736540527, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2843163373330871, 0.28431633733308725, 0.3705746637940335], 
reward next is 0.6294, 
noisyNet noise sample is [array([-0.02374493], dtype=float32), 1.3156865]. 
=============================================
[2019-03-24 09:41:27,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0354570e-08 7.9213516e-09 4.1870113e-08 9.9999964e-01 3.3951864e-07], sum to 1.0000
[2019-03-24 09:41:27,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7913
[2019-03-24 09:41:27,709] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 95.0, 1.0, 2.0, 0.3335228224994136, 1.0, 2.0, 0.3335228224994136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760224.7096911407, 760224.7096911411, 188700.0513617336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [24.66666666666667, 96.0, 1.0, 2.0, 0.3336694878286509, 1.0, 2.0, 0.3336694878286509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760559.1813245396, 760559.1813245396, 188736.9220163771], 
processed observation next is [1.0, 0.9130434782608695, 0.469135802469136, 0.96, 1.0, 1.0, 0.20674939027220346, 1.0, 1.0, 0.20674939027220346, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27162827904447845, 0.27162827904447845, 0.36295561926226366], 
reward next is 0.6370, 
noisyNet noise sample is [array([-0.6074209], dtype=float32), -1.5788152]. 
=============================================
[2019-03-24 09:41:28,598] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224860: loss 0.0086
[2019-03-24 09:41:28,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224860: learning rate 0.0000
[2019-03-24 09:41:28,921] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 09:41:28,926] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:41:28,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:41:28,927] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:41:28,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:41:28,929] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:41:28,929] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:41:28,930] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:41:28,931] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:41:28,931] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:41:28,934] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:41:28,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-24 09:41:28,955] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-24 09:41:28,985] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-24 09:41:29,048] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-24 09:41:29,081] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-24 09:41:37,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:41:37,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.68333333333333, 38.83333333333334, 1.0, 2.0, 0.475505347205458, 1.0, 2.0, 0.475505347205458, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1165262.206497812, 1165262.206497812, 231105.5805476327]
[2019-03-24 09:41:37,242] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:41:37,246] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7302360e-07 3.9133565e-07 7.2283416e-07 9.9999821e-01 4.1708748e-07], sampled 0.044050464634403874
[2019-03-24 09:41:39,445] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:41:39,447] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.58333333333334, 37.33333333333334, 1.0, 2.0, 0.1636713883187231, 1.0, 2.0, 0.1636713883187231, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 412205.2856309885, 412205.2856309889, 152569.1458343861]
[2019-03-24 09:41:39,447] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:41:39,454] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4459057e-07 3.7433216e-07 6.7208697e-07 9.9999821e-01 3.7862984e-07], sampled 0.21121893453414298
[2019-03-24 09:41:43,670] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:41:43,671] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.73333333333333, 26.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 362300.3852801427, 362300.3852801427, 123633.0607332308]
[2019-03-24 09:41:43,671] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:41:43,675] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.6308710e-07 6.1220709e-07 1.0779393e-06 9.9999714e-01 6.2065942e-07], sampled 0.2865738316676266
[2019-03-24 09:42:15,229] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:42:15,231] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.45800548, 80.01079754, 1.0, 2.0, 0.8246707018333177, 1.0, 2.0, 0.8246707018333177, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1881058.722545013, 1881058.722545013, 354056.8891493857]
[2019-03-24 09:42:15,231] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:42:15,234] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.2536626e-07 5.5000595e-07 9.8874455e-07 9.9999726e-01 5.6890701e-07], sampled 0.4183509199307237
[2019-03-24 09:42:28,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:42:28,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.2915147309325513, 1.0, 2.0, 0.2915147309325513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668579.4998041617, 668579.4998041622, 178644.671563305]
[2019-03-24 09:42:28,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:42:28,227] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2488891e-07 1.3741843e-07 2.5559618e-07 9.9999940e-01 1.4497635e-07], sampled 0.9686597125641052
[2019-03-24 09:43:25,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01089597], dtype=float32), 0.010611478]
[2019-03-24 09:43:25,062] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.36666666666667, 66.66666666666666, 1.0, 2.0, 0.2233272172749913, 1.0, 2.0, 0.2233272172749913, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550392.9098621198, 550392.9098621203, 164847.0529912585]
[2019-03-24 09:43:25,065] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:43:25,067] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9467094e-07 3.1605319e-07 5.8156638e-07 9.9999845e-01 3.3309234e-07], sampled 0.157443437012746
[2019-03-24 09:43:38,222] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:43:38,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:43:38,344] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:43:38,475] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:43:38,500] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:43:39,521] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2225000, evaluation results [2225000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:43:41,362] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2225796: loss 0.0100
[2019-03-24 09:43:41,366] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2225800: learning rate 0.0000
[2019-03-24 09:43:41,450] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2225834: loss 0.0424
[2019-03-24 09:43:41,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2225834: learning rate 0.0000
[2019-03-24 09:43:44,000] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2226926: loss 0.0021
[2019-03-24 09:43:44,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2226926: learning rate 0.0000
[2019-03-24 09:43:44,162] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2226996: loss 0.0038
[2019-03-24 09:43:44,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2226997: learning rate 0.0000
[2019-03-24 09:43:44,288] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2227051: loss 0.0059
[2019-03-24 09:43:44,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2227052: learning rate 0.0000
[2019-03-24 09:43:44,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2227292: loss 0.0054
[2019-03-24 09:43:44,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2227292: learning rate 0.0000
[2019-03-24 09:43:45,916] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2227745: loss 0.0007
[2019-03-24 09:43:45,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2227745: learning rate 0.0000
[2019-03-24 09:43:46,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2984102e-08 2.0871376e-08 9.9134020e-08 9.9999976e-01 9.2076185e-08], sum to 1.0000
[2019-03-24 09:43:46,741] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1541
[2019-03-24 09:43:46,748] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.1, 31.0, 1.0, 2.0, 0.7040069355931338, 1.0, 2.0, 0.7040069355931338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1652534.098438321, 1652534.098438321, 307956.0418007592], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [34.08333333333334, 31.5, 1.0, 2.0, 0.6718156349332539, 1.0, 2.0, 0.6718156349332539, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1574976.715409086, 1574976.715409087, 295690.8541548433], 
processed observation next is [1.0, 0.6521739130434783, 0.8179012345679015, 0.315, 1.0, 1.0, 0.6093043273014928, 1.0, 1.0, 0.6093043273014928, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5624916840746736, 0.562491684074674, 0.5686362579900833], 
reward next is 0.4314, 
noisyNet noise sample is [array([-1.1392394], dtype=float32), 1.0872468]. 
=============================================
[2019-03-24 09:43:47,413] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2228386: loss 0.0155
[2019-03-24 09:43:47,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2228386: learning rate 0.0000
[2019-03-24 09:43:48,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2228752: loss 0.0246
[2019-03-24 09:43:48,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2228752: learning rate 0.0000
[2019-03-24 09:43:48,357] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2228795: loss 0.0011
[2019-03-24 09:43:48,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2228795: learning rate 0.0000
[2019-03-24 09:43:52,861] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2230752: loss 0.0017
[2019-03-24 09:43:52,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2230753: learning rate 0.0000
[2019-03-24 09:43:52,947] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2230787: loss 0.1346
[2019-03-24 09:43:52,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2230787: learning rate 0.0000
[2019-03-24 09:43:54,611] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2231506: loss 0.1513
[2019-03-24 09:43:54,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2231507: learning rate 0.0000
[2019-03-24 09:43:55,948] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2232086: loss 0.1808
[2019-03-24 09:43:55,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2232086: learning rate 0.0000
[2019-03-24 09:43:56,244] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2232217: loss 0.1182
[2019-03-24 09:43:56,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2232217: learning rate 0.0000
[2019-03-24 09:43:57,874] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232906: loss 0.2878
[2019-03-24 09:43:57,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232906: learning rate 0.0000
[2019-03-24 09:43:59,883] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2233766: loss 0.8100
[2019-03-24 09:43:59,886] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2233766: learning rate 0.0000
[2019-03-24 09:44:00,059] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2233842: loss 0.0176
[2019-03-24 09:44:00,061] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2233842: learning rate 0.0000
[2019-03-24 09:44:02,559] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2234924: loss 0.5818
[2019-03-24 09:44:02,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2234925: learning rate 0.0000
[2019-03-24 09:44:02,600] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234943: loss 0.5070
[2019-03-24 09:44:02,604] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234943: learning rate 0.0000
[2019-03-24 09:44:02,919] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2235075: loss 0.4835
[2019-03-24 09:44:02,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2235075: learning rate 0.0000
[2019-03-24 09:44:03,399] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2235279: loss 0.6352
[2019-03-24 09:44:03,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2235279: learning rate 0.0000
[2019-03-24 09:44:04,391] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2235710: loss 0.2584
[2019-03-24 09:44:04,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2235710: learning rate 0.0000
[2019-03-24 09:44:05,834] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2588997e-07 8.0915788e-07 1.2446012e-06 9.9999475e-01 2.8327979e-06], sum to 1.0000
[2019-03-24 09:44:05,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3127
[2019-03-24 09:44:05,851] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 94.0, 1.0, 2.0, 0.3253570060146802, 1.0, 2.0, 0.3253570060146802, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 741602.720296786, 741602.7202967865, 186656.953761844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4494600.0000, 
sim time next is 4495200.0000, 
raw observation next is [24.33333333333334, 94.0, 1.0, 2.0, 0.3211434153705349, 1.0, 2.0, 0.3211434153705349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731993.8838087041, 731993.8838087041, 185611.7994426637], 
processed observation next is [0.0, 0.0, 0.4567901234567903, 0.94, 1.0, 1.0, 0.1918373992506368, 1.0, 1.0, 0.1918373992506368, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2614263870745372, 0.2614263870745372, 0.35694576815896867], 
reward next is 0.6431, 
noisyNet noise sample is [array([-0.02958316], dtype=float32), -0.52986306]. 
=============================================
[2019-03-24 09:44:06,076] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2236422: loss 0.0092
[2019-03-24 09:44:06,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2236424: learning rate 0.0000
[2019-03-24 09:44:06,881] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2236768: loss 0.0045
[2019-03-24 09:44:06,887] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2236769: learning rate 0.0000
[2019-03-24 09:44:06,892] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6423925e-08 1.9369034e-08 3.9612129e-08 9.9999988e-01 2.9195510e-08], sum to 1.0000
[2019-03-24 09:44:06,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-24 09:44:06,909] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 91.16666666666667, 1.0, 2.0, 0.292879340341004, 1.0, 2.0, 0.292879340341004, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672625.5278761594, 672625.5278761599, 179014.144801444], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [24.2, 91.0, 1.0, 2.0, 0.2962576798347521, 1.0, 2.0, 0.2962576798347521, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678714.2085457573, 678714.2085457578, 179738.581869666], 
processed observation next is [0.0, 0.391304347826087, 0.45185185185185184, 0.91, 1.0, 1.0, 0.1622115236128001, 1.0, 1.0, 0.1622115236128001, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24239793162348477, 0.24239793162348494, 0.3456511189801269], 
reward next is 0.6543, 
noisyNet noise sample is [array([-1.0503887], dtype=float32), 0.15514311]. 
=============================================
[2019-03-24 09:44:06,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2236813: loss 0.0669
[2019-03-24 09:44:06,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2236814: learning rate 0.0000
[2019-03-24 09:44:08,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4804813e-07 1.3655233e-05 7.6051392e-06 9.9997199e-01 5.7448829e-06], sum to 1.0000
[2019-03-24 09:44:08,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9088
[2019-03-24 09:44:08,098] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 60.66666666666666, 1.0, 2.0, 0.2338371785181445, 1.0, 2.0, 0.2338371785181445, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563379.5116851325, 563379.5116851325, 166741.898905046], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4229400.0000, 
sim time next is 4230000.0000, 
raw observation next is [26.0, 58.0, 1.0, 2.0, 0.2244791425301361, 1.0, 2.0, 0.2244791425301361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 544772.4093939221, 544772.4093939225, 164831.0435966705], 
processed observation next is [1.0, 1.0, 0.5185185185185185, 0.58, 1.0, 1.0, 0.07676088396444773, 1.0, 1.0, 0.07676088396444773, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1945615747835436, 0.19456157478354377, 0.31698277614744325], 
reward next is 0.6830, 
noisyNet noise sample is [array([-1.7525235], dtype=float32), -0.6594422]. 
=============================================
[2019-03-24 09:44:08,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.28389 ]
 [55.596394]
 [55.859   ]
 [56.055977]
 [56.27433 ]], R is [[55.13078308]
 [55.25881958]
 [55.38173676]
 [55.49930573]
 [55.61172867]].
[2019-03-24 09:44:08,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6373581e-07 2.4232029e-06 3.7434336e-07 9.9999571e-01 1.2425945e-06], sum to 1.0000
[2019-03-24 09:44:08,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3599
[2019-03-24 09:44:08,838] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 79.0, 1.0, 2.0, 0.7315269907760309, 1.0, 2.0, 0.7315269907760309, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1668401.214844994, 1668401.214844994, 316272.5762133207], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4354200.0000, 
sim time next is 4354800.0000, 
raw observation next is [27.66666666666666, 79.0, 1.0, 2.0, 0.806254548203071, 1.0, 2.0, 0.806254548203071, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1839008.568807857, 1839008.568807856, 346345.7547166844], 
processed observation next is [1.0, 0.391304347826087, 0.5802469135802467, 0.79, 1.0, 1.0, 0.7693506526227035, 1.0, 1.0, 0.7693506526227035, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6567887745742347, 0.6567887745742342, 0.6660495283013161], 
reward next is 0.3340, 
noisyNet noise sample is [array([-1.5490788], dtype=float32), 1.239547]. 
=============================================
[2019-03-24 09:44:11,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0015476e-07 2.6061190e-07 3.5836824e-06 9.9999142e-01 3.8663834e-06], sum to 1.0000
[2019-03-24 09:44:11,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7718
[2019-03-24 09:44:11,228] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 0.540985977020991, 1.0, 2.0, 0.540985977020991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1274719.548681673, 1274719.548681674, 250225.8104525516], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4279200.0000, 
sim time next is 4279800.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.5408805204218048, 1.0, 2.0, 0.5408805204218048, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1274743.878779802, 1274743.878779802, 250202.56803786], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 0.453429190978339, 1.0, 1.0, 0.453429190978339, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4552656709927864, 0.4552656709927864, 0.48115878468819234], 
reward next is 0.5188, 
noisyNet noise sample is [array([0.6807302], dtype=float32), -0.23220101]. 
=============================================
[2019-03-24 09:44:11,527] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2238758: loss 0.0020
[2019-03-24 09:44:11,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2238761: learning rate 0.0000
[2019-03-24 09:44:11,636] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2238808: loss 0.1221
[2019-03-24 09:44:11,641] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2238808: learning rate 0.0000
[2019-03-24 09:44:12,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0135137e-07 1.3322215e-06 2.0806376e-06 9.9999523e-01 5.3628372e-07], sum to 1.0000
[2019-03-24 09:44:12,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3631
[2019-03-24 09:44:12,785] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.23333333333333, 87.33333333333334, 1.0, 2.0, 0.3152680155840901, 1.0, 2.0, 0.3152680155840901, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742722.3224749697, 742722.3224749697, 185274.7431933999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4606800.0000, 
sim time next is 4607400.0000, 
raw observation next is [23.46666666666667, 86.16666666666667, 1.0, 2.0, 0.3311044158513922, 1.0, 2.0, 0.3311044158513922, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778251.5298633697, 778251.5298633697, 189174.4225377775], 
processed observation next is [1.0, 0.30434782608695654, 0.42469135802469143, 0.8616666666666667, 1.0, 1.0, 0.2036957331564193, 1.0, 1.0, 0.2036957331564193, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27794697495120346, 0.27794697495120346, 0.3637969664188029], 
reward next is 0.6362, 
noisyNet noise sample is [array([-1.1053545], dtype=float32), 0.09233633]. 
=============================================
[2019-03-24 09:44:13,313] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2239539: loss 0.0005
[2019-03-24 09:44:13,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2239539: learning rate 0.0000
[2019-03-24 09:44:14,527] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2240063: loss 0.0006
[2019-03-24 09:44:14,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2240065: learning rate 0.0000
[2019-03-24 09:44:14,908] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2240230: loss 0.0048
[2019-03-24 09:44:14,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2240230: learning rate 0.0000
[2019-03-24 09:44:16,438] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240902: loss 0.0013
[2019-03-24 09:44:16,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240902: learning rate 0.0000
[2019-03-24 09:44:18,092] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2241746: loss 0.0092
[2019-03-24 09:44:18,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2241748: learning rate 0.0000
[2019-03-24 09:44:18,238] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2241814: loss 0.1549
[2019-03-24 09:44:18,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2241816: learning rate 0.0000
[2019-03-24 09:44:20,722] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2242884: loss 0.0176
[2019-03-24 09:44:20,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2242885: learning rate 0.0000
[2019-03-24 09:44:20,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2242910: loss 0.0166
[2019-03-24 09:44:20,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2242911: learning rate 0.0000
[2019-03-24 09:44:21,129] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2243060: loss 0.0008
[2019-03-24 09:44:21,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2243060: learning rate 0.0000
[2019-03-24 09:44:21,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6566750e-05 1.1214766e-05 1.1745472e-04 9.9982256e-01 3.2272001e-05], sum to 1.0000
[2019-03-24 09:44:21,770] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2243339: loss 0.0122
[2019-03-24 09:44:21,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2243339: learning rate 0.0000
[2019-03-24 09:44:21,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5418
[2019-03-24 09:44:21,780] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.23333333333333, 65.66666666666667, 1.0, 2.0, 0.7851181510672534, 1.0, 2.0, 0.7851181510672534, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1790749.64156788, 1790749.641567881, 337642.8821908215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4628400.0000, 
sim time next is 4629000.0000, 
raw observation next is [29.36666666666667, 64.83333333333333, 1.0, 2.0, 0.7875111674117934, 1.0, 2.0, 0.7875111674117934, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1796213.280165023, 1796213.280165023, 338620.3500916399], 
processed observation next is [1.0, 0.5652173913043478, 0.64320987654321, 0.6483333333333333, 1.0, 1.0, 0.7470371040616588, 1.0, 1.0, 0.7470371040616588, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6415047429160796, 0.6415047429160796, 0.6511929809454614], 
reward next is 0.3488, 
noisyNet noise sample is [array([0.5668417], dtype=float32), 0.3932112]. 
=============================================
[2019-03-24 09:44:21,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[49.26753 ]
 [49.2689  ]
 [49.672794]
 [50.4357  ]
 [50.15412 ]], R is [[49.25347137]
 [49.11162186]
 [48.97554016]
 [48.88787842]
 [48.92971802]].
[2019-03-24 09:44:22,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2243710: loss 0.0041
[2019-03-24 09:44:22,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2243711: learning rate 0.0000
[2019-03-24 09:44:24,274] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2244408: loss 0.1435
[2019-03-24 09:44:24,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2244410: learning rate 0.0000
[2019-03-24 09:44:25,086] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2244754: loss 0.1096
[2019-03-24 09:44:25,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2244754: learning rate 0.0000
[2019-03-24 09:44:25,267] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2244833: loss 0.0025
[2019-03-24 09:44:25,273] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2244833: learning rate 0.0000
[2019-03-24 09:44:28,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4010657e-06 6.0473127e-08 2.3582841e-06 9.9999273e-01 1.4282342e-06], sum to 1.0000
[2019-03-24 09:44:28,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0628
[2019-03-24 09:44:28,311] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.86666666666667, 94.66666666666666, 1.0, 2.0, 0.261225829053487, 1.0, 2.0, 0.261225829053487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620958.3121919418, 620958.3121919422, 172608.3824161985], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4603200.0000, 
sim time next is 4603800.0000, 
raw observation next is [22.08333333333334, 93.33333333333334, 1.0, 2.0, 0.2569327461709524, 1.0, 2.0, 0.2569327461709524, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 610399.4835257354, 610399.4835257359, 171610.2249910257], 
processed observation next is [1.0, 0.2608695652173913, 0.373456790123457, 0.9333333333333335, 1.0, 1.0, 0.11539612639399097, 1.0, 1.0, 0.11539612639399097, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21799981554490552, 0.2179998155449057, 0.3300196634442802], 
reward next is 0.6700, 
noisyNet noise sample is [array([-0.51153356], dtype=float32), 0.38210306]. 
=============================================
[2019-03-24 09:44:28,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9302217e-06 1.5132700e-05 2.9870536e-05 9.9993634e-01 1.6684240e-05], sum to 1.0000
[2019-03-24 09:44:28,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7447
[2019-03-24 09:44:28,895] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.8829417659522513, 1.0, 2.0, 0.8829417659522513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2014123.828446277, 2014123.828446277, 379219.5844712092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4982400.0000, 
sim time next is 4983000.0000, 
raw observation next is [27.78333333333333, 79.83333333333334, 1.0, 2.0, 0.8565108665894688, 1.0, 2.0, 0.8565108665894688, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1953764.99265284, 1953764.99265284, 367659.2422277278], 
processed observation next is [1.0, 0.6956521739130435, 0.5845679012345678, 0.7983333333333335, 1.0, 1.0, 0.829179603082701, 1.0, 1.0, 0.829179603082701, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6977732116617286, 0.6977732116617286, 0.7070370042840919], 
reward next is 0.2930, 
noisyNet noise sample is [array([-0.75125617], dtype=float32), 0.13325468]. 
=============================================
[2019-03-24 09:44:28,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.172646]
 [50.034195]
 [49.872116]
 [49.978577]
 [49.752098]], R is [[50.25793457]
 [50.02608871]
 [49.82503891]
 [49.65653229]
 [49.56460953]].
[2019-03-24 09:44:29,789] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2246776: loss 0.1206
[2019-03-24 09:44:29,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2246778: learning rate 0.0000
[2019-03-24 09:44:29,867] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2246809: loss 0.2641
[2019-03-24 09:44:29,870] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2246809: learning rate 0.0000
[2019-03-24 09:44:31,738] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2247604: loss 0.1651
[2019-03-24 09:44:31,742] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2247604: learning rate 0.0000
[2019-03-24 09:44:32,679] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2248005: loss 0.1381
[2019-03-24 09:44:32,682] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2248005: learning rate 0.0000
[2019-03-24 09:44:33,216] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2248234: loss 0.1424
[2019-03-24 09:44:33,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2248235: learning rate 0.0000
[2019-03-24 09:44:33,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1108882e-06 2.2647359e-07 1.0960644e-06 9.9996066e-01 3.4929704e-05], sum to 1.0000
[2019-03-24 09:44:33,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4371
[2019-03-24 09:44:33,562] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5741933325649128, 1.0, 2.0, 0.5741933325649128, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1309272.541622662, 1309272.541622662, 259280.3096927844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4960200.0000, 
sim time next is 4960800.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6085368603939617, 1.0, 2.0, 0.6085368603939617, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1387653.406568433, 1387653.406568433, 270988.6696636527], 
processed observation next is [1.0, 0.43478260869565216, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5339724528499544, 1.0, 1.0, 0.5339724528499544, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4955905023458689, 0.4955905023458689, 0.521132057045486], 
reward next is 0.4789, 
noisyNet noise sample is [array([0.12692179], dtype=float32), -0.57026446]. 
=============================================
[2019-03-24 09:44:34,757] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248891: loss 0.1571
[2019-03-24 09:44:34,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248891: learning rate 0.0000
[2019-03-24 09:44:36,681] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2249709: loss 0.1392
[2019-03-24 09:44:36,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2249710: learning rate 0.0000
[2019-03-24 09:44:36,920] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2249812: loss 0.0639
[2019-03-24 09:44:36,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2249812: learning rate 0.0000
[2019-03-24 09:44:37,360] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 09:44:37,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:44:37,362] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:44:37,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:44:37,365] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:44:37,365] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:44:37,365] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:44:37,363] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:44:37,368] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:44:37,368] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:44:37,370] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:44:37,389] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-24 09:44:37,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-24 09:44:37,457] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-24 09:44:37,458] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-24 09:44:37,516] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-24 09:44:54,208] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:44:54,210] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 28.0, 1.0, 2.0, 0.1693143804664407, 1.0, 2.0, 0.1693143804664407, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 436834.5268765944, 436834.5268765948, 147402.9455355379]
[2019-03-24 09:44:54,211] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:44:54,214] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2999648e-06 1.5033920e-06 2.5793806e-06 9.9999106e-01 3.4538152e-06], sampled 0.3263034837524894
[2019-03-24 09:45:24,707] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:45:24,708] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.43333333333334, 71.66666666666666, 1.0, 2.0, 0.3024284890574483, 1.0, 2.0, 0.3024284890574483, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689317.0912123594, 689317.0912123598, 181044.4846236189]
[2019-03-24 09:45:24,709] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:45:24,712] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.8839673e-07 9.2542763e-07 1.6346978e-06 9.9999452e-01 2.1179674e-06], sampled 0.7475725089031645
[2019-03-24 09:45:28,335] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:45:28,337] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666667, 96.0, 1.0, 2.0, 0.3278986838378773, 1.0, 2.0, 0.3278986838378773, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747398.9198047939, 747398.9198047944, 187290.6341562224]
[2019-03-24 09:45:28,337] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:45:28,339] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9400546e-07 5.8155018e-07 1.0173891e-06 9.9999642e-01 1.4009380e-06], sampled 0.7678095062969035
[2019-03-24 09:45:31,795] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:45:31,796] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.91666666666667, 80.66666666666667, 1.0, 2.0, 0.3852377673972458, 1.0, 2.0, 0.3852377673972458, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878170.1660701, 878170.1660701, 202175.2982090423]
[2019-03-24 09:45:31,797] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:45:31,800] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8192032e-07 5.6553813e-07 1.0161888e-06 9.9999654e-01 1.3318130e-06], sampled 0.9228707756580646
[2019-03-24 09:45:35,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:45:35,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.23333333333333, 77.33333333333333, 1.0, 2.0, 0.2972124636352809, 1.0, 2.0, 0.2972124636352809, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679718.8854588553, 679718.8854588557, 179908.3539930644]
[2019-03-24 09:45:35,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:45:35,526] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.7889962e-07 9.1625685e-07 1.6100142e-06 9.9999452e-01 2.0898058e-06], sampled 0.7564150117155957
[2019-03-24 09:45:55,259] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:45:55,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.33333333333333, 94.0, 1.0, 2.0, 0.2818146617704418, 1.0, 2.0, 0.2818146617704418, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686748.2689133442, 686748.2689133447, 178018.8382961514]
[2019-03-24 09:45:55,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:45:55,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9694936e-07 4.7240698e-07 8.2245191e-07 9.9999714e-01 1.1899767e-06], sampled 0.18662137683337743
[2019-03-24 09:46:17,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01084829], dtype=float32), 0.010642614]
[2019-03-24 09:46:17,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.3375060557459441, 1.0, 2.0, 0.3375060557459441, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769308.5616195636, 769308.5616195641, 189704.7165530606]
[2019-03-24 09:46:17,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:46:17,225] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2482047e-07 7.2493992e-07 1.2640850e-06 9.9999559e-01 1.7350084e-06], sampled 0.6536916874411891
[2019-03-24 09:46:46,192] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:46:46,248] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:46:46,498] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:46:46,688] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:46:46,802] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:46:47,822] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2250000, evaluation results [2250000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:46:48,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0260942e-06 5.5925631e-07 4.8864383e-08 9.9999809e-01 2.5440130e-07], sum to 1.0000
[2019-03-24 09:46:48,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-24 09:46:48,779] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.3, 77.5, 1.0, 2.0, 0.3692444515856415, 1.0, 2.0, 0.3692444515856415, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 841692.5251880216, 841692.5251880221, 197910.3557182581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4901400.0000, 
sim time next is 4902000.0000, 
raw observation next is [29.86666666666667, 81.33333333333333, 1.0, 2.0, 0.3782439788599923, 1.0, 2.0, 0.3782439788599923, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 862218.4818826258, 862218.4818826258, 200299.9905181215], 
processed observation next is [1.0, 0.7391304347826086, 0.6617283950617285, 0.8133333333333332, 1.0, 1.0, 0.25981426054760987, 1.0, 1.0, 0.25981426054760987, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3079351721009378, 0.3079351721009378, 0.385192289457926], 
reward next is 0.6148, 
noisyNet noise sample is [array([0.37609193], dtype=float32), 0.028581025]. 
=============================================
[2019-03-24 09:46:48,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.701553]
 [59.429863]
 [59.255955]
 [58.861866]
 [58.23739 ]], R is [[59.60639954]
 [59.62974167]
 [59.65389633]
 [59.61359024]
 [59.20717621]].
[2019-03-24 09:46:48,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5848930e-08 5.2867392e-07 3.2573826e-07 9.9998879e-01 1.0381763e-05], sum to 1.0000
[2019-03-24 09:46:48,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5919
[2019-03-24 09:46:48,889] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 83.0, 1.0, 2.0, 0.4310566729137969, 1.0, 2.0, 0.4310566729137969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 982683.7858832043, 982683.7858832048, 214887.5466270191], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5135400.0000, 
sim time next is 5136000.0000, 
raw observation next is [29.4, 81.0, 1.0, 2.0, 0.4238337676660713, 1.0, 2.0, 0.4238337676660713, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 966207.2828439244, 966207.2828439248, 212835.1944609298], 
processed observation next is [0.0, 0.43478260869565216, 0.6444444444444444, 0.81, 1.0, 1.0, 0.31408781865008484, 1.0, 1.0, 0.31408781865008484, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34507402958711586, 0.345074029587116, 0.4092984508864035], 
reward next is 0.5907, 
noisyNet noise sample is [array([1.2794893], dtype=float32), -0.29842973]. 
=============================================
[2019-03-24 09:46:48,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.16335 ]
 [60.252045]
 [60.381596]
 [60.27793 ]
 [60.37428 ]], R is [[60.17841721]
 [60.1633873 ]
 [60.14749908]
 [60.13569641]
 [60.1132164 ]].
[2019-03-24 09:46:49,865] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2250881: loss 0.1943
[2019-03-24 09:46:49,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2250882: learning rate 0.0000
[2019-03-24 09:46:49,957] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2250920: loss 0.1911
[2019-03-24 09:46:49,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2250920: learning rate 0.0000
[2019-03-24 09:46:50,282] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2251061: loss 0.1822
[2019-03-24 09:46:50,286] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2251061: learning rate 0.0000
[2019-03-24 09:46:50,897] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2251321: loss 0.1735
[2019-03-24 09:46:50,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2251321: learning rate 0.0000
[2019-03-24 09:46:51,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0180057e-06 1.1349426e-05 2.6201637e-05 9.9983561e-01 1.2483874e-04], sum to 1.0000
[2019-03-24 09:46:51,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5987
[2019-03-24 09:46:51,216] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 85.66666666666667, 1.0, 2.0, 0.8809039460019946, 1.0, 2.0, 0.8809039460019946, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2009470.022521511, 2009470.022521512, 378320.7270470314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4876800.0000, 
sim time next is 4877400.0000, 
raw observation next is [28.38333333333333, 84.83333333333333, 1.0, 2.0, 0.8940860073121686, 1.0, 2.0, 0.8940860073121686, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2039574.561057929, 2039574.561057929, 384167.5099680886], 
processed observation next is [1.0, 0.43478260869565216, 0.60679012345679, 0.8483333333333333, 1.0, 1.0, 0.8739119134668674, 1.0, 1.0, 0.8739119134668674, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7284194860921175, 0.7284194860921175, 0.738783673015555], 
reward next is 0.2612, 
noisyNet noise sample is [array([0.15945946], dtype=float32), -0.19839154]. 
=============================================
[2019-03-24 09:46:51,678] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2251652: loss 0.1679
[2019-03-24 09:46:51,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2251652: learning rate 0.0000
[2019-03-24 09:46:53,405] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2252400: loss 0.1113
[2019-03-24 09:46:53,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2252400: learning rate 0.0000
[2019-03-24 09:46:54,358] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2252805: loss 0.0317
[2019-03-24 09:46:54,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2252805: learning rate 0.0000
[2019-03-24 09:46:54,465] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2252855: loss 0.2256
[2019-03-24 09:46:54,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2252856: learning rate 0.0000
[2019-03-24 09:46:55,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2780514e-07 1.0558251e-05 9.2631526e-06 9.9984360e-01 1.3561518e-04], sum to 1.0000
[2019-03-24 09:46:55,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9237
[2019-03-24 09:46:55,153] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.3412179080733336, 1.0, 2.0, 0.3412179080733336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 786929.7742990463, 786929.7742990467, 191086.385944484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4939200.0000, 
sim time next is 4939800.0000, 
raw observation next is [24.08333333333333, 87.33333333333334, 1.0, 2.0, 0.3280537612750141, 1.0, 2.0, 0.3280537612750141, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758828.0958117247, 758828.0958117251, 187860.7605778918], 
processed observation next is [1.0, 0.17391304347826086, 0.4475308641975307, 0.8733333333333334, 1.0, 1.0, 0.20006400151787396, 1.0, 1.0, 0.20006400151787396, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2710100342184731, 0.27101003421847325, 0.3612706934190227], 
reward next is 0.6387, 
noisyNet noise sample is [array([-1.5787776], dtype=float32), -1.2933835]. 
=============================================
[2019-03-24 09:46:57,513] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.05460895e-05 1.69804139e-06 5.07562436e-05 9.99348342e-01
 5.88684459e-04], sum to 1.0000
[2019-03-24 09:46:57,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7617
[2019-03-24 09:46:57,530] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 87.16666666666667, 1.0, 2.0, 0.3248562147096749, 1.0, 2.0, 0.3248562147096749, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 740460.6899605535, 740460.689960554, 186532.46621407], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5177400.0000, 
sim time next is 5178000.0000, 
raw observation next is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.3240725839237364, 1.0, 2.0, 0.3240725839237364, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738673.6612897813, 738673.6612897818, 186337.6969299988], 
processed observation next is [0.0, 0.9565217391304348, 0.49382716049382736, 0.8733333333333334, 1.0, 1.0, 0.19532450467111476, 1.0, 1.0, 0.19532450467111476, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2638120218892076, 0.26381202188920777, 0.35834172486538235], 
reward next is 0.6417, 
noisyNet noise sample is [array([-0.1405971], dtype=float32), -0.5657414]. 
=============================================
[2019-03-24 09:46:57,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.775234]
 [60.83093 ]
 [60.870975]
 [60.84695 ]
 [60.848843]], R is [[60.75465393]
 [60.78839111]
 [60.81793213]
 [60.84546661]
 [60.8710022 ]].
[2019-03-24 09:46:58,972] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2254789: loss 0.3336
[2019-03-24 09:46:58,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2254789: learning rate 0.0000
[2019-03-24 09:46:58,977] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2254790: loss 0.0463
[2019-03-24 09:46:58,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2254791: learning rate 0.0000
[2019-03-24 09:46:59,900] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5031550e-04 2.3223969e-04 1.9323854e-03 9.7641969e-01 2.1165447e-02], sum to 1.0000
[2019-03-24 09:46:59,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1224
[2019-03-24 09:46:59,920] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 88.16666666666667, 1.0, 2.0, 0.5458004660525898, 1.0, 2.0, 0.5458004660525898, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1244478.689790351, 1244478.689790352, 249910.6422814773], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4971000.0000, 
sim time next is 4971600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5885572413083814, 1.0, 2.0, 0.5885572413083814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1342053.742319786, 1342053.742319786, 264128.9932274712], 
processed observation next is [1.0, 0.5652173913043478, 0.5185185185185185, 0.89, 1.0, 1.0, 0.5101871920337874, 1.0, 1.0, 0.5101871920337874, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4793049079713521, 0.4793049079713521, 0.5079403715912908], 
reward next is 0.4921, 
noisyNet noise sample is [array([0.03065196], dtype=float32), 0.07449693]. 
=============================================
[2019-03-24 09:47:00,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9960838e-06 6.2129613e-05 2.5306512e-05 9.9963582e-01 2.6983756e-04], sum to 1.0000
[2019-03-24 09:47:00,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-24 09:47:00,628] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.05, 87.5, 1.0, 2.0, 0.4430352225000587, 1.0, 2.0, 0.4430352225000587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1010009.390021018, 1010009.390021018, 218331.1157772975], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4908600.0000, 
sim time next is 4909200.0000, 
raw observation next is [29.06666666666667, 87.0, 1.0, 2.0, 0.4407332380101694, 1.0, 2.0, 0.4407332380101694, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1004758.001070827, 1004758.001070827, 217665.509329475], 
processed observation next is [1.0, 0.8260869565217391, 0.6320987654320989, 0.87, 1.0, 1.0, 0.33420623572639213, 1.0, 1.0, 0.33420623572639213, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3588421432395811, 0.3588421432395811, 0.41858751794129806], 
reward next is 0.5814, 
noisyNet noise sample is [array([-0.06122611], dtype=float32), 1.5113018]. 
=============================================
[2019-03-24 09:47:00,887] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2255608: loss 0.1560
[2019-03-24 09:47:00,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2255609: learning rate 0.0000
[2019-03-24 09:47:01,858] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2256026: loss 0.3542
[2019-03-24 09:47:01,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2256027: learning rate 0.0000
[2019-03-24 09:47:02,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2256168: loss 0.2076
[2019-03-24 09:47:02,181] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2256169: learning rate 0.0000
[2019-03-24 09:47:03,792] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256865: loss 0.2772
[2019-03-24 09:47:03,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256865: learning rate 0.0000
[2019-03-24 09:47:05,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2257735: loss 0.3494
[2019-03-24 09:47:05,822] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2257736: learning rate 0.0000
[2019-03-24 09:47:05,963] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2257794: loss 0.0570
[2019-03-24 09:47:05,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2257794: learning rate 0.0000
[2019-03-24 09:47:08,489] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2258895: loss 0.2812
[2019-03-24 09:47:08,491] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2258895: learning rate 0.0000
[2019-03-24 09:47:08,685] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2258976: loss 0.1718
[2019-03-24 09:47:08,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2258976: learning rate 0.0000
[2019-03-24 09:47:08,831] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2259040: loss 0.2207
[2019-03-24 09:47:08,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2259041: learning rate 0.0000
[2019-03-24 09:47:09,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2259344: loss 0.1425
[2019-03-24 09:47:09,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2259344: learning rate 0.0000
[2019-03-24 09:47:10,299] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2259673: loss 0.0584
[2019-03-24 09:47:10,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2259674: learning rate 0.0000
[2019-03-24 09:47:11,896] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2260360: loss 0.0954
[2019-03-24 09:47:11,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2260360: learning rate 0.0000
[2019-03-24 09:47:12,835] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2260768: loss 0.0924
[2019-03-24 09:47:12,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2260769: learning rate 0.0000
[2019-03-24 09:47:13,178] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2260914: loss 0.1391
[2019-03-24 09:47:13,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2260914: learning rate 0.0000
[2019-03-24 09:47:17,417] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2262746: loss 0.1074
[2019-03-24 09:47:17,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2262746: learning rate 0.0000
[2019-03-24 09:47:17,652] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2262848: loss 0.7486
[2019-03-24 09:47:17,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2262848: learning rate 0.0000
[2019-03-24 09:47:19,325] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2263568: loss 0.1036
[2019-03-24 09:47:19,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2263569: learning rate 0.0000
[2019-03-24 09:47:20,409] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2264039: loss 0.1080
[2019-03-24 09:47:20,413] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2264039: learning rate 0.0000
[2019-03-24 09:47:20,631] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2264134: loss 0.1235
[2019-03-24 09:47:20,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2264134: learning rate 0.0000
[2019-03-24 09:47:22,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264829: loss 0.0977
[2019-03-24 09:47:22,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264830: learning rate 0.0000
[2019-03-24 09:47:24,235] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2265658: loss 0.1225
[2019-03-24 09:47:24,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2265661: learning rate 0.0000
[2019-03-24 09:47:24,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2265844: loss 4.1620
[2019-03-24 09:47:24,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2265844: learning rate 0.0000
[2019-03-24 09:47:26,940] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2266816: loss 0.1081
[2019-03-24 09:47:26,946] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2266816: learning rate 0.0000
[2019-03-24 09:47:27,232] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2266946: loss 0.1407
[2019-03-24 09:47:27,235] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2266946: learning rate 0.0000
[2019-03-24 09:47:27,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2266988: loss 0.1387
[2019-03-24 09:47:27,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2266989: learning rate 0.0000
[2019-03-24 09:47:28,212] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2267371: loss 0.0882
[2019-03-24 09:47:28,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2267371: learning rate 0.0000
[2019-03-24 09:47:29,003] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2267706: loss 0.0625
[2019-03-24 09:47:29,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2267706: learning rate 0.0000
[2019-03-24 09:47:30,569] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2268386: loss 0.8417
[2019-03-24 09:47:30,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2268386: learning rate 0.0000
[2019-03-24 09:47:31,557] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2268809: loss 0.5575
[2019-03-24 09:47:31,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2268809: learning rate 0.0000
[2019-03-24 09:47:31,895] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2268952: loss 0.0939
[2019-03-24 09:47:31,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2268952: learning rate 0.0000
[2019-03-24 09:47:36,022] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2270727: loss 0.3476
[2019-03-24 09:47:36,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2270727: learning rate 0.0000
[2019-03-24 09:47:36,226] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2270815: loss 2.5986
[2019-03-24 09:47:36,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2270816: learning rate 0.0000
[2019-03-24 09:47:38,191] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2271660: loss 0.4460
[2019-03-24 09:47:38,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2271660: learning rate 0.0000
[2019-03-24 09:47:39,021] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2272011: loss 0.2729
[2019-03-24 09:47:39,026] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2272013: learning rate 0.0000
[2019-03-24 09:47:39,435] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2272192: loss 0.4757
[2019-03-24 09:47:39,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2272192: learning rate 0.0000
[2019-03-24 09:47:40,839] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272800: loss 0.5740
[2019-03-24 09:47:40,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272800: learning rate 0.0000
[2019-03-24 09:47:42,832] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2273664: loss 0.4027
[2019-03-24 09:47:42,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2273664: learning rate 0.0000
[2019-03-24 09:47:43,149] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2273790: loss 2.6402
[2019-03-24 09:47:43,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2273791: learning rate 0.0000
[2019-03-24 09:47:44,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0563935e-07 9.1783697e-08 5.3143816e-07 9.9999571e-01 3.5007984e-06], sum to 1.0000
[2019-03-24 09:47:44,792] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7363
[2019-03-24 09:47:44,797] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 71.0, 1.0, 2.0, 0.2659094406176798, 1.0, 2.0, 0.2659094406176798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 622749.4202857926, 622749.420285793, 173290.3294927399], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6037200.0000, 
sim time next is 6037800.0000, 
raw observation next is [25.9, 71.5, 1.0, 2.0, 0.2649023805472639, 1.0, 2.0, 0.2649023805472639, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620659.5825893538, 620659.5825893541, 173070.5213923415], 
processed observation next is [1.0, 0.9130434782608695, 0.5148148148148147, 0.715, 1.0, 1.0, 0.12488378636579035, 1.0, 1.0, 0.12488378636579035, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22166413663905493, 0.22166413663905504, 0.3328279257545029], 
reward next is 0.6672, 
noisyNet noise sample is [array([0.03613301], dtype=float32), -0.05482962]. 
=============================================
[2019-03-24 09:47:45,660] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2274870: loss 0.4144
[2019-03-24 09:47:45,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2274870: learning rate 0.0000
[2019-03-24 09:47:45,847] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2274952: loss 0.1894
[2019-03-24 09:47:45,849] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2274952: learning rate 0.0000
[2019-03-24 09:47:45,960] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 09:47:45,965] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:47:45,967] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:47:45,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:47:45,968] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:47:45,968] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:47:45,969] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:47:45,970] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:47:45,971] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:47:45,974] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:47:45,974] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:47:45,990] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-24 09:47:46,023] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-24 09:47:46,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-24 09:47:46,084] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-24 09:47:46,085] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-24 09:47:48,769] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:47:48,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.20513772, 31.56197159, 1.0, 2.0, 0.2442846051237608, 1.0, 2.0, 0.2442846051237608, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595174.6871698294, 595174.6871698298, 169301.5794865413]
[2019-03-24 09:47:48,772] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:47:48,775] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2323790e-07 9.1377325e-07 2.1543137e-06 9.9999058e-01 5.7480588e-06], sampled 0.9987748407796188
[2019-03-24 09:47:56,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:47:56,027] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.46666666666667, 35.66666666666666, 1.0, 2.0, 0.6228535438166725, 1.0, 2.0, 0.6228535438166725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1502161.228906181, 1502161.228906181, 279531.4755678473]
[2019-03-24 09:47:56,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:47:56,032] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7490008e-06 2.4108167e-06 5.6369663e-06 9.9997711e-01 1.3069669e-05], sampled 0.5397031048489962
[2019-03-24 09:48:22,019] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:48:22,020] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.03333333333333, 89.33333333333334, 1.0, 2.0, 0.3115629009201915, 1.0, 2.0, 0.3115629009201915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 718068.8975034801, 718068.8975034805, 183645.4790423037]
[2019-03-24 09:48:22,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:48:22,023] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.4140781e-07 7.9198833e-07 1.8681570e-06 9.9999166e-01 5.1099146e-06], sampled 0.44306821201652424
[2019-03-24 09:49:39,658] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:49:39,659] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.53598181666667, 54.73744379999999, 1.0, 2.0, 0.3083677044460565, 1.0, 2.0, 0.3083677044460565, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702860.390430577, 702860.390430577, 182481.3330798188]
[2019-03-24 09:49:39,661] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:49:39,664] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9064505e-07 7.3149903e-07 1.7352511e-06 9.9999249e-01 4.5622614e-06], sampled 0.611995104869048
[2019-03-24 09:49:40,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:49:40,296] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.43067618, 63.97273275, 1.0, 2.0, 0.2216161190228955, 1.0, 2.0, 0.2216161190228955, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535615.6689451919, 535615.6689451924, 164128.3190511625]
[2019-03-24 09:49:40,297] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:49:40,301] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.5477141e-07 1.1107348e-06 2.5957509e-06 9.9998903e-01 6.5880854e-06], sampled 0.7392324689325842
[2019-03-24 09:49:41,389] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:49:41,392] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.89704579333333, 78.97826649000001, 1.0, 2.0, 0.3979204870811377, 1.0, 2.0, 0.3979204870811377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 921237.9014520711, 921237.9014520716, 206284.7301736993]
[2019-03-24 09:49:41,396] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:49:41,399] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.2130958e-07 1.1844151e-06 2.8011357e-06 9.9998820e-01 7.0047126e-06], sampled 0.6516465212275054
[2019-03-24 09:49:54,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01099433], dtype=float32), 0.010710902]
[2019-03-24 09:49:54,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.8, 73.66666666666667, 1.0, 2.0, 0.2065638845742456, 1.0, 2.0, 0.2065638845742456, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506345.8225616437, 506345.8225616441, 161148.0571298894]
[2019-03-24 09:49:54,818] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:49:54,825] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.8353941e-07 1.1518744e-06 2.6978964e-06 9.9998844e-01 6.9354055e-06], sampled 0.6414199776713003
[2019-03-24 09:49:55,045] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:49:55,077] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:49:55,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3655 2465964287.0515 46.0000
[2019-03-24 09:49:55,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:49:55,552] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:49:56,571] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2275000, evaluation results [2275000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7478.3655125783835, 2465964287.0514793, 46.0]
[2019-03-24 09:49:56,593] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2275012: loss 0.2243
[2019-03-24 09:49:56,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2275012: learning rate 0.0000
[2019-03-24 09:49:57,568] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2275428: loss 0.2766
[2019-03-24 09:49:57,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2275429: learning rate 0.0000
[2019-03-24 09:49:58,425] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2275793: loss 0.2053
[2019-03-24 09:49:58,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2275794: learning rate 0.0000
[2019-03-24 09:49:58,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8209182e-07 1.8183753e-06 2.1382828e-06 9.9999261e-01 3.2948699e-06], sum to 1.0000
[2019-03-24 09:49:58,816] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7485
[2019-03-24 09:49:58,824] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.03333333333333, 48.33333333333334, 1.0, 2.0, 0.1906950498112292, 1.0, 2.0, 0.1906950498112292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469619.2891606051, 469619.2891606055, 157889.2562157579], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5854200.0000, 
sim time next is 5854800.0000, 
raw observation next is [26.86666666666667, 49.66666666666667, 1.0, 2.0, 0.1934301795580584, 1.0, 2.0, 0.1934301795580584, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475641.8363223908, 475641.8363223913, 158435.1803811759], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.4966666666666667, 1.0, 1.0, 0.03979783280721239, 1.0, 1.0, 0.03979783280721239, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16987208440085386, 0.16987208440085402, 0.304683039194569], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.4703343], dtype=float32), 0.60283476]. 
=============================================
[2019-03-24 09:49:59,701] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2276339: loss 1.6516
[2019-03-24 09:49:59,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2276340: learning rate 0.0000
[2019-03-24 09:50:00,691] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2276762: loss 1.5516
[2019-03-24 09:50:00,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2276762: learning rate 0.0000
[2019-03-24 09:50:00,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2143327e-07 1.5361225e-06 2.8674731e-07 9.9999654e-01 1.4470197e-06], sum to 1.0000
[2019-03-24 09:50:00,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3795
[2019-03-24 09:50:00,921] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.96666666666667, 68.0, 1.0, 2.0, 0.3027120121678162, 1.0, 2.0, 0.3027120121678162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689963.6086002332, 689963.6086002332, 181112.7062851473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5764800.0000, 
sim time next is 5765400.0000, 
raw observation next is [27.8, 68.5, 1.0, 2.0, 0.3013494480627449, 1.0, 2.0, 0.3013494480627449, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686856.5603912566, 686856.560391257, 180784.734747611], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.685, 1.0, 1.0, 0.16827315245564867, 1.0, 1.0, 0.16827315245564867, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24530591442544877, 0.24530591442544894, 0.3476629514377134], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.9121837], dtype=float32), 0.91626734]. 
=============================================
[2019-03-24 09:50:01,490] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2277105: loss 0.1792
[2019-03-24 09:50:01,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2277105: learning rate 0.0000
[2019-03-24 09:50:04,395] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1126874e-08 3.4065764e-08 4.0946398e-07 9.9999809e-01 1.4777023e-06], sum to 1.0000
[2019-03-24 09:50:04,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4340
[2019-03-24 09:50:04,412] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 82.0, 1.0, 2.0, 0.2259012218181717, 1.0, 2.0, 0.2259012218181717, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545593.1030755366, 545593.103075537, 165047.6274228446], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5964000.0000, 
sim time next is 5964600.0000, 
raw observation next is [22.6, 81.5, 1.0, 2.0, 0.2241018111097982, 1.0, 2.0, 0.2241018111097982, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541860.0935732723, 541860.0935732728, 164677.4760838663], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.815, 1.0, 1.0, 0.07631167989261692, 1.0, 1.0, 0.07631167989261692, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19352146199045442, 0.19352146199045459, 0.3166874540074352], 
reward next is 0.6833, 
noisyNet noise sample is [array([-0.9921344], dtype=float32), 0.0656793]. 
=============================================
[2019-03-24 09:50:05,161] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2278682: loss 0.9282
[2019-03-24 09:50:05,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2278683: learning rate 0.0000
[2019-03-24 09:50:05,591] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2278854: loss 1.7275
[2019-03-24 09:50:05,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2278854: learning rate 0.0000
[2019-03-24 09:50:07,375] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2279609: loss 0.8336
[2019-03-24 09:50:07,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2279610: learning rate 0.0000
[2019-03-24 09:50:08,326] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2280012: loss 0.8299
[2019-03-24 09:50:08,327] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2280012: learning rate 0.0000
[2019-03-24 09:50:08,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2280127: loss 0.7525
[2019-03-24 09:50:08,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2280129: learning rate 0.0000
[2019-03-24 09:50:10,018] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280742: loss 0.4750
[2019-03-24 09:50:10,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280742: learning rate 0.0000
[2019-03-24 09:50:12,205] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2281671: loss 0.7024
[2019-03-24 09:50:12,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2281671: learning rate 0.0000
[2019-03-24 09:50:12,488] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2281792: loss 0.8011
[2019-03-24 09:50:12,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2281792: learning rate 0.0000
[2019-03-24 09:50:13,981] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8591888e-06 2.2846275e-07 4.8012553e-06 9.9997938e-01 1.3720328e-05], sum to 1.0000
[2019-03-24 09:50:13,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8213
[2019-03-24 09:50:13,991] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.6, 51.0, 1.0, 2.0, 0.816363318853865, 1.0, 2.0, 0.816363318853865, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1862089.981721058, 1862089.981721058, 350560.7963301814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6098400.0000, 
sim time next is 6099000.0000, 
raw observation next is [30.56666666666667, 51.33333333333333, 1.0, 2.0, 0.8399721418917468, 1.0, 2.0, 0.8399721418917468, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1915998.463617994, 1915998.463617993, 360546.7947406624], 
processed observation next is [1.0, 0.6086956521739131, 0.6876543209876544, 0.5133333333333333, 1.0, 1.0, 0.8094906451092224, 1.0, 1.0, 0.8094906451092224, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.684285165577855, 0.6842851655778547, 0.69335922065512], 
reward next is 0.3066, 
noisyNet noise sample is [array([-0.10679328], dtype=float32), 0.65336233]. 
=============================================
[2019-03-24 09:50:14,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[59.426586]
 [59.079685]
 [59.07164 ]
 [59.24143 ]
 [59.717274]], R is [[58.9301033 ]
 [58.66664505]
 [58.38469315]
 [58.1057663 ]
 [57.83623123]].
[2019-03-24 09:50:15,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2282868: loss 0.6716
[2019-03-24 09:50:15,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2282869: learning rate 0.0000
[2019-03-24 09:50:15,157] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2282935: loss 0.6575
[2019-03-24 09:50:15,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2282935: learning rate 0.0000
[2019-03-24 09:50:15,280] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2282984: loss 0.5298
[2019-03-24 09:50:15,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2282986: learning rate 0.0000
[2019-03-24 09:50:16,260] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2283412: loss 0.5468
[2019-03-24 09:50:16,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2283413: learning rate 0.0000
[2019-03-24 09:50:17,108] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2283778: loss 0.4608
[2019-03-24 09:50:17,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2283780: learning rate 0.0000
[2019-03-24 09:50:17,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3731575e-06 1.2009913e-06 1.7813849e-05 9.9989712e-01 8.2442311e-05], sum to 1.0000
[2019-03-24 09:50:17,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-24 09:50:17,816] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 88.83333333333334, 1.0, 2.0, 0.4137529670171948, 1.0, 2.0, 0.4137529670171948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 943212.0947301729, 943212.0947301734, 209999.4748959977], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6508200.0000, 
sim time next is 6508800.0000, 
raw observation next is [26.3, 89.0, 1.0, 2.0, 0.4519187154000786, 1.0, 2.0, 0.4519187154000786, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1030275.144814337, 1030275.144814337, 220914.3253088363], 
processed observation next is [1.0, 0.34782608695652173, 0.5296296296296297, 0.89, 1.0, 1.0, 0.3475222802381889, 1.0, 1.0, 0.3475222802381889, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36795540886226324, 0.36795540886226324, 0.42483524097853137], 
reward next is 0.5752, 
noisyNet noise sample is [array([0.18920472], dtype=float32), -0.74600613]. 
=============================================
[2019-03-24 09:50:18,505] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2284378: loss 0.6962
[2019-03-24 09:50:18,508] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2284379: learning rate 0.0000
[2019-03-24 09:50:19,353] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2284736: loss 0.3312
[2019-03-24 09:50:19,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2284736: learning rate 0.0000
[2019-03-24 09:50:20,181] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2285099: loss 0.5997
[2019-03-24 09:50:20,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2285100: learning rate 0.0000
[2019-03-24 09:50:23,964] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2286733: loss 0.5311
[2019-03-24 09:50:23,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2286733: learning rate 0.0000
[2019-03-24 09:50:24,169] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2286825: loss 0.7421
[2019-03-24 09:50:24,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2286826: learning rate 0.0000
[2019-03-24 09:50:25,376] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2840011e-06 3.4767352e-06 1.0304174e-05 9.9997628e-01 5.6820295e-06], sum to 1.0000
[2019-03-24 09:50:25,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2620
[2019-03-24 09:50:25,397] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.18333333333333, 60.33333333333333, 1.0, 2.0, 0.3260582990861993, 1.0, 2.0, 0.3260582990861993, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 743201.9880683119, 743201.9880683124, 186831.698295468], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6282600.0000, 
sim time next is 6283200.0000, 
raw observation next is [30.06666666666667, 60.66666666666667, 1.0, 2.0, 0.3206571809579463, 1.0, 2.0, 0.3206571809579463, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730885.0636366272, 730885.0636366272, 185491.9242120026], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6066666666666667, 1.0, 1.0, 0.1912585487594599, 1.0, 1.0, 0.1912585487594599, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.261030379870224, 0.261030379870224, 0.3567152388692358], 
reward next is 0.6433, 
noisyNet noise sample is [array([-3.14211], dtype=float32), 1.5495031]. 
=============================================
[2019-03-24 09:50:26,134] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2287669: loss 0.3531
[2019-03-24 09:50:26,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2287670: learning rate 0.0000
[2019-03-24 09:50:26,940] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2288016: loss 0.1166
[2019-03-24 09:50:26,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2288017: learning rate 0.0000
[2019-03-24 09:50:27,186] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2288123: loss 0.0234
[2019-03-24 09:50:27,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2288123: learning rate 0.0000
[2019-03-24 09:50:28,699] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288776: loss 0.0221
[2019-03-24 09:50:28,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288776: learning rate 0.0000
[2019-03-24 09:50:30,720] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2289662: loss 0.0271
[2019-03-24 09:50:30,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2289662: learning rate 0.0000
[2019-03-24 09:50:31,000] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2289782: loss 1.0031
[2019-03-24 09:50:31,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2289782: learning rate 0.0000
[2019-03-24 09:50:33,583] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2290899: loss 0.0185
[2019-03-24 09:50:33,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2290899: learning rate 0.0000
[2019-03-24 09:50:33,604] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2290906: loss 0.0306
[2019-03-24 09:50:33,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2290906: learning rate 0.0000
[2019-03-24 09:50:33,864] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2291020: loss 0.0173
[2019-03-24 09:50:33,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2291020: learning rate 0.0000
[2019-03-24 09:50:34,861] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2291453: loss 0.1026
[2019-03-24 09:50:34,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2291455: learning rate 0.0000
[2019-03-24 09:50:34,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5011322e-05 5.7285383e-06 2.0370555e-05 9.9876773e-01 1.1412482e-03], sum to 1.0000
[2019-03-24 09:50:34,997] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-24 09:50:35,001] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 48.66666666666667, 1.0, 2.0, 0.225689587687978, 1.0, 2.0, 0.225689587687978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 562999.0103894894, 562999.0103894897, 165534.772662353], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6579600.0000, 
sim time next is 6580200.0000, 
raw observation next is [25.6, 48.33333333333333, 1.0, 2.0, 0.2164225683023552, 1.0, 2.0, 0.2164225683023552, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540539.7301076343, 540539.7301076348, 163525.1585326335], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.4833333333333333, 1.0, 1.0, 0.06716972416947048, 1.0, 1.0, 0.06716972416947048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1930499036098694, 0.19304990360986957, 0.31447145871660287], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.61978036], dtype=float32), 1.2371421]. 
=============================================
[2019-03-24 09:50:35,660] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2291798: loss 0.1686
[2019-03-24 09:50:35,666] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2291799: learning rate 0.0000
[2019-03-24 09:50:36,948] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2292346: loss 0.9740
[2019-03-24 09:50:36,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2292348: learning rate 0.0000
[2019-03-24 09:50:37,830] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2292724: loss 1.0904
[2019-03-24 09:50:37,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2292725: learning rate 0.0000
[2019-03-24 09:50:38,673] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2293088: loss 0.0677
[2019-03-24 09:50:38,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2293089: learning rate 0.0000
[2019-03-24 09:50:41,115] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7905218e-07 3.5717085e-07 4.9264786e-06 9.9997246e-01 2.1757571e-05], sum to 1.0000
[2019-03-24 09:50:41,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3212
[2019-03-24 09:50:41,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 45.83333333333334, 1.0, 2.0, 0.1827930342035654, 1.0, 2.0, 0.1827930342035654, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469993.040083699, 469993.0400836995, 156577.0257956686], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [23.0, 45.66666666666667, 1.0, 2.0, 0.1733601745824372, 1.0, 2.0, 0.1733601745824372, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445649.2062959917, 445649.2062959917, 154619.1847904078], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.4566666666666667, 1.0, 1.0, 0.015904969740996647, 1.0, 1.0, 0.015904969740996647, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15916043081999703, 0.15916043081999703, 0.2973445861353996], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.8532303], dtype=float32), 0.24883687]. 
=============================================
[2019-03-24 09:50:42,459] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2294715: loss 1.0551
[2019-03-24 09:50:42,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2294715: learning rate 0.0000
[2019-03-24 09:50:42,576] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2294763: loss 0.2630
[2019-03-24 09:50:42,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2294763: learning rate 0.0000
[2019-03-24 09:50:44,758] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2295707: loss 0.8053
[2019-03-24 09:50:44,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2295708: learning rate 0.0000
[2019-03-24 09:50:45,464] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2296003: loss 0.7637
[2019-03-24 09:50:45,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2296004: learning rate 0.0000
[2019-03-24 09:50:45,768] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2296139: loss 0.7622
[2019-03-24 09:50:45,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2296141: learning rate 0.0000
[2019-03-24 09:50:47,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296785: loss 0.9959
[2019-03-24 09:50:47,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296786: learning rate 0.0000
[2019-03-24 09:50:49,382] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2297693: loss 0.6500
[2019-03-24 09:50:49,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2297695: learning rate 0.0000
[2019-03-24 09:50:49,673] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2297820: loss 0.2086
[2019-03-24 09:50:49,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2297821: learning rate 0.0000
[2019-03-24 09:50:52,238] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2298922: loss 0.5136
[2019-03-24 09:50:52,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2298922: learning rate 0.0000
[2019-03-24 09:50:52,263] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2298933: loss 0.5249
[2019-03-24 09:50:52,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2298935: learning rate 0.0000
[2019-03-24 09:50:52,310] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2298953: loss 0.5537
[2019-03-24 09:50:52,311] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2298953: learning rate 0.0000
[2019-03-24 09:50:53,442] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2299438: loss 0.4713
[2019-03-24 09:50:53,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2299438: learning rate 0.0000
[2019-03-24 09:50:54,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2299768: loss 0.4325
[2019-03-24 09:50:54,225] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2299768: learning rate 0.0000
[2019-03-24 09:50:54,764] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 09:50:54,766] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:50:54,766] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:50:54,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:50:54,767] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:50:54,768] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:50:54,769] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:50:54,769] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:50:54,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:50:54,771] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:50:54,772] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:50:54,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-24 09:50:54,826] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-24 09:50:54,827] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-24 09:50:54,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-24 09:50:54,941] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-24 09:51:12,020] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:51:12,022] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.53333333333333, 41.66666666666666, 1.0, 2.0, 0.2874045245993655, 1.0, 2.0, 0.2874045245993655, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 726518.5301335879, 726518.5301335884, 179949.9633205994]
[2019-03-24 09:51:12,025] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:51:12,030] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2162550e-07 7.6073098e-07 2.1248443e-06 9.9999368e-01 2.7139929e-06], sampled 0.22488722761534063
[2019-03-24 09:51:12,061] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:51:12,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.3724037, 51.67052558, 1.0, 2.0, 0.3391908115968384, 1.0, 2.0, 0.3391908115968384, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838266.6515405808, 838266.6515405808, 192626.6579621216]
[2019-03-24 09:51:12,065] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:51:12,068] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.8603819e-07 3.0490190e-07 8.7415572e-07 9.9999726e-01 1.2102331e-06], sampled 0.4227798502733896
[2019-03-24 09:51:12,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:51:12,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 55.66666666666667, 1.0, 2.0, 0.3165759386082966, 1.0, 2.0, 0.3165759386082966, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795355.1803590676, 795355.1803590672, 187105.7937345425]
[2019-03-24 09:51:12,972] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:51:12,977] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9120147e-07 3.1134638e-07 8.8798686e-07 9.9999726e-01 1.2362797e-06], sampled 0.07498595894138294
[2019-03-24 09:51:42,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:51:42,725] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.10436400333333, 82.06697199, 1.0, 2.0, 0.3099198739637425, 1.0, 2.0, 0.3099198739637425, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706399.8698175744, 706399.8698175749, 182858.3627039493]
[2019-03-24 09:51:42,726] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:51:42,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0477968e-07 4.3010814e-07 1.2360027e-06 9.9999630e-01 1.5940516e-06], sampled 0.74585674186041
[2019-03-24 09:52:32,619] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:52:32,622] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.11477235, 87.08038030833333, 1.0, 2.0, 0.2250308976101772, 1.0, 2.0, 0.2250308976101772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541886.3352404287, 541886.3352404292, 164797.6525379457]
[2019-03-24 09:52:32,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:52:32,625] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.4277439e-07 5.9315289e-07 1.6694872e-06 9.9999499e-01 2.1561239e-06], sampled 0.17916045019583215
[2019-03-24 09:52:37,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01095336], dtype=float32), 0.0108044585]
[2019-03-24 09:52:37,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.26666666666667, 92.83333333333334, 1.0, 2.0, 0.2417775636987224, 1.0, 2.0, 0.2417775636987224, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 573771.8737157412, 573771.8737157417, 168164.0030584675]
[2019-03-24 09:52:37,598] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:52:37,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4337827e-07 1.5730721e-07 4.6161981e-07 9.9999869e-01 6.5028712e-07], sampled 0.5213964173355996
[2019-03-24 09:53:03,949] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:53:04,001] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0917 2668496507.7118 68.0000
[2019-03-24 09:53:04,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:53:04,273] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454269.9342 47.0000
[2019-03-24 09:53:04,322] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:53:05,338] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2300000, evaluation results [2300000.0, 7523.091712791175, 2668496507.711827, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495454269.934179, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:53:06,320] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2300420: loss 0.2269
[2019-03-24 09:53:06,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2300421: learning rate 0.0000
[2019-03-24 09:53:07,013] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2300713: loss 0.3054
[2019-03-24 09:53:07,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2300713: learning rate 0.0000
[2019-03-24 09:53:07,787] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2301047: loss 0.0441
[2019-03-24 09:53:07,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2301047: learning rate 0.0000
[2019-03-24 09:53:11,605] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2302693: loss 0.1958
[2019-03-24 09:53:11,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2302693: learning rate 0.0000
[2019-03-24 09:53:11,748] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2302757: loss 0.0308
[2019-03-24 09:53:11,752] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2302757: learning rate 0.0000
[2019-03-24 09:53:13,937] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2303691: loss 0.2255
[2019-03-24 09:53:13,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2303691: learning rate 0.0000
[2019-03-24 09:53:14,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0365187e-08 7.6494433e-07 9.3805392e-07 9.9995327e-01 4.5107154e-05], sum to 1.0000
[2019-03-24 09:53:14,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3318
[2019-03-24 09:53:14,200] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.13333333333334, 72.66666666666667, 1.0, 2.0, 0.2077776500464718, 1.0, 2.0, 0.2077776500464718, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508346.5577404366, 508346.5577404366, 161375.0788261303], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6915000.0000, 
sim time next is 6915600.0000, 
raw observation next is [23.1, 73.0, 1.0, 2.0, 0.2082065461645814, 1.0, 2.0, 0.2082065461645814, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 509269.108537293, 509269.1085372926, 161462.2728861342], 
processed observation next is [0.0, 0.043478260869565216, 0.41111111111111115, 0.73, 1.0, 1.0, 0.05738874543402547, 1.0, 1.0, 0.05738874543402547, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18188182447760465, 0.18188182447760448, 0.31050437093487343], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.00437459], dtype=float32), 1.531705]. 
=============================================
[2019-03-24 09:53:14,852] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2304075: loss 0.2922
[2019-03-24 09:53:14,854] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2304077: learning rate 0.0000
[2019-03-24 09:53:15,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2304181: loss 0.1549
[2019-03-24 09:53:15,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2304182: learning rate 0.0000
[2019-03-24 09:53:15,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1990009e-07 1.6129782e-08 3.5134287e-06 9.9999607e-01 2.1890578e-07], sum to 1.0000
[2019-03-24 09:53:15,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-24 09:53:15,286] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.91666666666667, 70.5, 1.0, 2.0, 0.2392305104500371, 1.0, 2.0, 0.2392305104500371, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571994.1332377992, 571994.1332377996, 167771.851658918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6811800.0000, 
sim time next is 6812400.0000, 
raw observation next is [24.83333333333334, 71.0, 1.0, 2.0, 0.2378393088494915, 1.0, 2.0, 0.2378393088494915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 568734.9801102605, 568734.980110261, 167465.2368623293], 
processed observation next is [1.0, 0.8695652173913043, 0.47530864197530887, 0.71, 1.0, 1.0, 0.09266584386844226, 1.0, 1.0, 0.09266584386844226, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20311963575366448, 0.20311963575366465, 0.3220485324275563], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.9283824], dtype=float32), 1.5743061]. 
=============================================
[2019-03-24 09:53:16,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304803: loss 0.2424
[2019-03-24 09:53:16,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304804: learning rate 0.0000
[2019-03-24 09:53:18,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3887897e-08 2.0358345e-07 7.8664624e-07 9.9999857e-01 3.8773388e-07], sum to 1.0000
[2019-03-24 09:53:18,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-24 09:53:18,408] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 51.5, 1.0, 2.0, 0.2970641890363456, 1.0, 2.0, 0.2970641890363456, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679426.2303757407, 679426.2303757407, 179875.1690553889], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6966600.0000, 
sim time next is 6967200.0000, 
raw observation next is [31.0, 51.0, 1.0, 2.0, 0.293211659022843, 1.0, 2.0, 0.293211659022843, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671967.4252264828, 671967.4252264833, 179023.3716185258], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.51, 1.0, 1.0, 0.1585853083605274, 1.0, 1.0, 0.1585853083605274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23998836615231528, 0.23998836615231545, 0.34427571465101114], 
reward next is 0.6557, 
noisyNet noise sample is [array([-0.98129827], dtype=float32), -0.4661589]. 
=============================================
[2019-03-24 09:53:18,659] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2305696: loss 0.2089
[2019-03-24 09:53:18,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2305697: learning rate 0.0000
[2019-03-24 09:53:18,887] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2305797: loss 0.0667
[2019-03-24 09:53:18,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2305799: learning rate 0.0000
[2019-03-24 09:53:21,440] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2306902: loss 0.2958
[2019-03-24 09:53:21,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2306902: learning rate 0.0000
[2019-03-24 09:53:21,617] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2306977: loss 0.1903
[2019-03-24 09:53:21,620] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2306977: loss 0.1776
[2019-03-24 09:53:21,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2306977: learning rate 0.0000
[2019-03-24 09:53:21,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2306978: learning rate 0.0000
[2019-03-24 09:53:22,637] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2307414: loss 0.2154
[2019-03-24 09:53:22,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2307414: learning rate 0.0000
[2019-03-24 09:53:23,447] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2307760: loss 0.1779
[2019-03-24 09:53:23,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2307761: learning rate 0.0000
[2019-03-24 09:53:24,872] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2308380: loss 0.1783
[2019-03-24 09:53:24,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2308380: learning rate 0.0000
[2019-03-24 09:53:25,592] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2308693: loss 0.1491
[2019-03-24 09:53:25,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2308693: learning rate 0.0000
[2019-03-24 09:53:26,311] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2308999: loss 0.2958
[2019-03-24 09:53:26,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2308999: learning rate 0.0000
[2019-03-24 09:53:28,433] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8093567e-07 2.6084703e-07 3.2433354e-07 9.9999869e-01 1.5685212e-07], sum to 1.0000
[2019-03-24 09:53:28,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3011
[2019-03-24 09:53:28,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.26666666666667, 88.0, 1.0, 2.0, 0.218572142383288, 1.0, 2.0, 0.218572142383288, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532591.7098035064, 532591.7098035068, 163622.0723878642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7021200.0000, 
sim time next is 7021800.0000, 
raw observation next is [21.35, 87.5, 1.0, 2.0, 0.2172873190319146, 1.0, 2.0, 0.2172873190319146, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529442.604689321, 529442.604689321, 163343.6880129972], 
processed observation next is [1.0, 0.2608695652173913, 0.3462962962962963, 0.875, 1.0, 1.0, 0.06819918932370785, 1.0, 1.0, 0.06819918932370785, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18908664453190036, 0.18908664453190036, 0.31412247694807155], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.56054795], dtype=float32), 1.1063454]. 
=============================================
[2019-03-24 09:53:30,315] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2310720: loss 0.0037
[2019-03-24 09:53:30,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2310720: learning rate 0.0000
[2019-03-24 09:53:30,342] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2310728: loss 0.1440
[2019-03-24 09:53:30,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2310728: learning rate 0.0000
[2019-03-24 09:53:32,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1378526e-09 3.2721488e-09 8.9610119e-10 1.0000000e+00 8.7816082e-10], sum to 1.0000
[2019-03-24 09:53:32,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-24 09:53:32,440] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 65.0, 1.0, 2.0, 0.2389329439130924, 1.0, 2.0, 0.2389329439130924, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590268.7102833192, 590268.7102833197, 168341.5201945409], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7131600.0000, 
sim time next is 7132200.0000, 
raw observation next is [23.58333333333334, 64.16666666666667, 1.0, 2.0, 0.3034067883171418, 1.0, 2.0, 0.3034067883171418, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748743.8644700632, 748743.8644700637, 183523.6891997803], 
processed observation next is [1.0, 0.5652173913043478, 0.4290123456790126, 0.6416666666666667, 1.0, 1.0, 0.17072236704421642, 1.0, 1.0, 0.17072236704421642, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2674085230250226, 0.26740852302502277, 0.352930171538039], 
reward next is 0.6471, 
noisyNet noise sample is [array([-0.57117635], dtype=float32), 0.61339146]. 
=============================================
[2019-03-24 09:53:32,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2311667: loss 0.1222
[2019-03-24 09:53:32,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2311667: learning rate 0.0000
[2019-03-24 09:53:33,418] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2312055: loss 0.0924
[2019-03-24 09:53:33,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2312055: learning rate 0.0000
[2019-03-24 09:53:33,751] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2312195: loss 0.1434
[2019-03-24 09:53:33,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2312196: learning rate 0.0000
[2019-03-24 09:53:33,860] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.62520325e-07 1.11433216e-07 5.00456281e-06 9.99993920e-01
 6.50587310e-07], sum to 1.0000
[2019-03-24 09:53:33,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9146
[2019-03-24 09:53:33,881] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.58333333333334, 70.66666666666667, 1.0, 2.0, 0.2990321694270995, 1.0, 2.0, 0.2990321694270995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 728228.5679224565, 728228.5679224569, 182168.3818363025], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7218600.0000, 
sim time next is 7219200.0000, 
raw observation next is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.3768485242815199, 1.0, 2.0, 0.3768485242815199, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 914986.0720293334, 914986.0720293338, 202210.1834090888], 
processed observation next is [1.0, 0.5652173913043478, 0.43209876543209896, 0.7033333333333335, 1.0, 1.0, 0.25815300509704747, 1.0, 1.0, 0.25815300509704747, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32678074001047624, 0.32678074001047636, 0.38886573732517077], 
reward next is 0.6111, 
noisyNet noise sample is [array([-0.45385], dtype=float32), 0.20523925]. 
=============================================
[2019-03-24 09:53:35,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312771: loss 0.0624
[2019-03-24 09:53:35,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312772: learning rate 0.0000
[2019-03-24 09:53:35,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1604741e-09 5.3366257e-08 2.4585296e-08 9.9999893e-01 1.0329028e-06], sum to 1.0000
[2019-03-24 09:53:35,764] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6919
[2019-03-24 09:53:35,770] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.41666666666667, 75.33333333333333, 1.0, 2.0, 0.2010622951831004, 1.0, 2.0, 0.2010622951831004, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 494164.5122600454, 494164.5122600454, 160025.2847878392], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7243800.0000, 
sim time next is 7244400.0000, 
raw observation next is [22.33333333333334, 75.66666666666667, 1.0, 2.0, 0.1991702349897798, 1.0, 2.0, 0.1991702349897798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489786.027984399, 489786.0279843995, 159635.6770985875], 
processed observation next is [1.0, 0.8695652173913043, 0.38271604938271625, 0.7566666666666667, 1.0, 1.0, 0.046631232130690224, 1.0, 1.0, 0.046631232130690224, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17492358142299963, 0.17492358142299982, 0.3069916867280529], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.6805367], dtype=float32), -0.10124865]. 
=============================================
[2019-03-24 09:53:37,463] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2313797: loss 0.0255
[2019-03-24 09:53:37,467] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2313797: learning rate 0.0000
[2019-03-24 09:53:37,491] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2313808: loss 0.0005
[2019-03-24 09:53:37,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2313808: learning rate 0.0000
[2019-03-24 09:53:39,865] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2314837: loss 0.0207
[2019-03-24 09:53:39,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2314837: learning rate 0.0000
[2019-03-24 09:53:40,215] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2314990: loss 0.0233
[2019-03-24 09:53:40,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2314991: learning rate 0.0000
[2019-03-24 09:53:40,283] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2315017: loss 0.0127
[2019-03-24 09:53:40,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2315019: learning rate 0.0000
[2019-03-24 09:53:41,199] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2315415: loss 0.0047
[2019-03-24 09:53:41,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2315415: learning rate 0.0000
[2019-03-24 09:53:42,015] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2315760: loss 0.0046
[2019-03-24 09:53:42,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2315761: learning rate 0.0000
[2019-03-24 09:53:43,327] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2316318: loss 0.0020
[2019-03-24 09:53:43,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2316319: learning rate 0.0000
[2019-03-24 09:53:44,181] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2316682: loss 0.0015
[2019-03-24 09:53:44,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2316682: learning rate 0.0000
[2019-03-24 09:53:44,798] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2316944: loss 0.0265
[2019-03-24 09:53:44,805] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2316945: learning rate 0.0000
[2019-03-24 09:53:48,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.36358825e-08 7.85762779e-08 1.16058246e-07 9.99999762e-01
 2.55956660e-08], sum to 1.0000
[2019-03-24 09:53:48,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2254
[2019-03-24 09:53:48,543] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.06666666666667, 96.33333333333334, 1.0, 2.0, 0.1809884646590831, 1.0, 2.0, 0.1809884646590831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449545.1044042325, 449545.1044042325, 155979.7003748561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7449600.0000, 
sim time next is 7450200.0000, 
raw observation next is [19.15, 96.0, 1.0, 2.0, 0.1816974382325646, 1.0, 2.0, 0.1816974382325646, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451019.3984528507, 451019.3984528507, 156119.1775493938], 
processed observation next is [0.0, 0.21739130434782608, 0.2648148148148148, 0.96, 1.0, 1.0, 0.025830283610195945, 1.0, 1.0, 0.025830283610195945, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1610783565903038, 0.1610783565903038, 0.30022918759498807], 
reward next is 0.6998, 
noisyNet noise sample is [array([0.7519946], dtype=float32), -0.82371646]. 
=============================================
[2019-03-24 09:53:48,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4146686e-07 4.1551419e-07 2.8342108e-06 9.9999559e-01 8.8697567e-07], sum to 1.0000
[2019-03-24 09:53:48,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2771
[2019-03-24 09:53:48,595] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 72.33333333333333, 1.0, 2.0, 0.2264891404633596, 1.0, 2.0, 0.2264891404633596, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545686.5581658657, 545686.5581658662, 165126.8370935974], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7329000.0000, 
sim time next is 7329600.0000, 
raw observation next is [24.0, 73.0, 1.0, 2.0, 0.2249321305618015, 1.0, 2.0, 0.2249321305618015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 542498.7842246701, 542498.7842246706, 164808.1074127959], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.73, 1.0, 1.0, 0.07730015543071607, 1.0, 1.0, 0.07730015543071607, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19374956579452504, 0.1937495657945252, 0.31693866810153054], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.7278792], dtype=float32), 0.5877657]. 
=============================================
[2019-03-24 09:53:48,966] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2318710: loss 0.2973
[2019-03-24 09:53:48,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2318710: learning rate 0.0000
[2019-03-24 09:53:49,019] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2318730: loss 0.0006
[2019-03-24 09:53:49,021] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2318730: learning rate 0.0000
[2019-03-24 09:53:51,284] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2319711: loss 0.0026
[2019-03-24 09:53:51,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2319712: learning rate 0.0000
[2019-03-24 09:53:52,157] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2320082: loss 0.0008
[2019-03-24 09:53:52,161] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2320083: learning rate 0.0000
[2019-03-24 09:53:52,443] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2320197: loss 0.0130
[2019-03-24 09:53:52,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2320198: learning rate 0.0000
[2019-03-24 09:53:53,665] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320731: loss 0.0007
[2019-03-24 09:53:53,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320732: learning rate 0.0000
[2019-03-24 09:53:56,190] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2321817: loss 0.0010
[2019-03-24 09:53:56,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2321817: learning rate 0.0000
[2019-03-24 09:53:56,226] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2321833: loss 0.1289
[2019-03-24 09:53:56,229] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2321834: learning rate 0.0000
[2019-03-24 09:53:58,537] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2322832: loss 0.0036
[2019-03-24 09:53:58,539] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2322832: learning rate 0.0000
[2019-03-24 09:53:58,587] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:53:58,588] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:53:58,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 09:53:58,906] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322975: loss 0.0008
[2019-03-24 09:53:58,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322975: learning rate 0.0000
[2019-03-24 09:53:59,019] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2323031: loss 0.0004
[2019-03-24 09:53:59,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2323033: learning rate 0.0000
[2019-03-24 09:53:59,672] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2323377: loss 0.0043
[2019-03-24 09:53:59,675] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2323378: learning rate 0.0000
[2019-03-24 09:53:59,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8537197e-07 5.2297839e-08 2.3013104e-06 9.9999511e-01 2.4335766e-06], sum to 1.0000
[2019-03-24 09:53:59,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9901
[2019-03-24 09:53:59,699] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.6, 80.66666666666667, 1.0, 2.0, 0.1624471260190968, 1.0, 2.0, 0.1624471260190968, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409998.3419212194, 409998.3419212194, 152337.0904214156], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7688400.0000, 
sim time next is 7689000.0000, 
raw observation next is [19.6, 79.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 402204.2777677049, 402204.2777677054, 151498.5939826485], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.7933333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14364438491703746, 0.14364438491703763, 0.29134344996663175], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57354087], dtype=float32), -0.9831039]. 
=============================================
[2019-03-24 09:53:59,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.409386]
 [65.518135]
 [65.5422  ]
 [65.57256 ]
 [65.58211 ]], R is [[64.67790985]
 [64.73817444]
 [64.7966156 ]
 [64.85344696]
 [64.90903473]].
[2019-03-24 09:54:00,389] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2323703: loss 0.0021
[2019-03-24 09:54:00,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2323703: learning rate 0.0000
[2019-03-24 09:54:01,624] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2324234: loss 0.0290
[2019-03-24 09:54:01,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2324234: learning rate 0.0000
[2019-03-24 09:54:02,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2324618: loss 0.0724
[2019-03-24 09:54:02,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2324618: learning rate 0.0000
[2019-03-24 09:54:02,962] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2324807: loss 0.0006
[2019-03-24 09:54:02,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2324807: learning rate 0.0000
[2019-03-24 09:54:03,407] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 09:54:03,409] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:54:03,410] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:54:03,411] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:54:03,411] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:54:03,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:54:03,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:54:03,414] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:54:03,414] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:54:03,413] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:54:03,418] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:54:03,439] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 09:54:03,471] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 09:54:03,506] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 09:54:03,536] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 09:54:03,567] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 09:54:10,482] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:10,485] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.41666666666666, 47.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 335071.9759949953, 335071.9759949958, 140897.6655612819]
[2019-03-24 09:54:10,487] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:54:10,491] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0149690e-07 3.3970829e-07 7.5597501e-07 9.9999738e-01 1.1426242e-06], sampled 0.684704569777383
[2019-03-24 09:54:12,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:12,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.03333333333333, 27.66666666666667, 1.0, 2.0, 0.5710801953794103, 1.0, 2.0, 0.5710801953794103, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1391282.724013809, 1391282.724013809, 261899.4920843145]
[2019-03-24 09:54:12,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:54:12,248] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1392727e-07 3.4242726e-07 8.0186004e-07 9.9999750e-01 1.0988920e-06], sampled 0.8313610272043098
[2019-03-24 09:54:21,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:21,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.90766962, 81.298317295, 1.0, 2.0, 0.1721732094499656, 1.0, 2.0, 0.1721732094499656, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 430002.5171666407, 430002.5171666411, 154223.7915539925]
[2019-03-24 09:54:21,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:54:21,942] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0133765e-07 3.5020446e-07 7.8675265e-07 9.9999738e-01 1.1337473e-06], sampled 0.923089193823541
[2019-03-24 09:54:22,515] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:22,515] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.91857863833334, 65.04880078833334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 301239.5341956245, 301239.5341956249, 135709.1545513466]
[2019-03-24 09:54:22,515] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:54:22,517] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6014137e-07 4.0656542e-07 8.9426356e-07 9.9999702e-01 1.3396248e-06], sampled 0.8943157334075814
[2019-03-24 09:54:29,366] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:29,367] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 65.0, 1.0, 2.0, 0.2380290889125107, 1.0, 2.0, 0.2380290889125107, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571508.3464429645, 571508.3464429645, 167597.8164937109]
[2019-03-24 09:54:29,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:54:29,372] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2154842e-08 1.0754652e-07 2.5277907e-07 9.9999917e-01 3.7716413e-07], sampled 0.6150970685673494
[2019-03-24 09:54:37,752] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:37,753] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.06666666666667, 63.66666666666667, 1.0, 2.0, 0.192444769291607, 1.0, 2.0, 0.192444769291607, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 474148.2968106155, 474148.296810616, 158258.7166004773]
[2019-03-24 09:54:37,754] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:54:37,756] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1835340e-07 1.3844637e-07 3.1940945e-07 9.9999893e-01 4.7708568e-07], sampled 0.6330888577406647
[2019-03-24 09:54:41,257] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:41,259] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 78.0, 1.0, 2.0, 0.2163767248636825, 1.0, 2.0, 0.2163767248636825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520636.7744529066, 520636.7744529066, 162908.3852227002]
[2019-03-24 09:54:41,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:54:41,267] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1695423e-07 1.3198365e-07 3.0481809e-07 9.9999893e-01 4.7419348e-07], sampled 0.18724871094408946
[2019-03-24 09:54:46,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:46,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.75, 46.16666666666666, 1.0, 2.0, 0.3014522897233018, 1.0, 2.0, 0.3014522897233018, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 687091.0692832645, 687091.0692832649, 180809.6216915328]
[2019-03-24 09:54:46,290] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:54:46,293] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.11418274e-07 1.23874088e-07 2.94576409e-07 9.99999046e-01
 4.20712809e-07], sampled 0.45116926955550285
[2019-03-24 09:54:47,919] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:54:47,920] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 76.5, 1.0, 2.0, 0.289923897060491, 1.0, 2.0, 0.289923897060491, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667253.0365359046, 667253.0365359046, 178380.8530846097]
[2019-03-24 09:54:47,920] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:54:47,923] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00681078e-07 1.12699084e-07 2.65665875e-07 9.99999166e-01
 4.06669045e-07], sampled 0.4917256160529325
[2019-03-24 09:55:06,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:55:06,531] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.6781758, 83.8302942, 1.0, 2.0, 0.4087817837007569, 1.0, 2.0, 0.4087817837007569, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 931872.6447515994, 931872.6447515999, 208617.4027866994]
[2019-03-24 09:55:06,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:55:06,536] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.1773633e-08 7.1386509e-08 1.7202221e-07 9.9999940e-01 2.5311854e-07], sampled 0.6567947051342723
[2019-03-24 09:55:11,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:55:11,722] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [37.677848045, 42.251297495, 1.0, 2.0, 0.8068546133698898, 1.0, 2.0, 0.8068546133698898, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1840378.684327713, 1840378.684327712, 346596.7475370963]
[2019-03-24 09:55:11,722] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:55:11,724] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.13031774e-07 1.25975376e-07 2.99975056e-07 9.99999046e-01
 4.28244590e-07], sampled 0.6617033172381871
[2019-03-24 09:55:22,298] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:55:22,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.66666666666667, 96.0, 1.0, 2.0, 0.3482560290790349, 1.0, 2.0, 0.3482560290790349, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 794286.2977033508, 794286.2977033512, 192466.0559609049]
[2019-03-24 09:55:22,302] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:55:22,308] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6121987e-07 1.8087171e-07 4.1639805e-07 9.9999857e-01 6.2257573e-07], sampled 0.9522171073159539
[2019-03-24 09:55:30,650] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:55:30,651] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.08333333333334, 65.16666666666667, 1.0, 2.0, 0.7427409097279608, 1.0, 2.0, 0.7427409097279608, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1694001.16528997, 1694001.16528997, 320663.0682973281]
[2019-03-24 09:55:30,651] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:55:30,655] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6595910e-07 2.8851309e-07 6.9001578e-07 9.9999785e-01 9.3238663e-07], sampled 0.3840371704708009
[2019-03-24 09:56:02,803] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01089489], dtype=float32), 0.010962616]
[2019-03-24 09:56:02,805] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.24820075333333, 95.77153716000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 370013.8989572081, 370013.8989572081, 146352.209929597]
[2019-03-24 09:56:02,808] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:56:02,812] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1875760e-07 1.3703557e-07 3.1098637e-07 9.9999893e-01 4.8992536e-07], sampled 0.8245683085526647
[2019-03-24 09:56:11,924] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5567 2410719396.8229 22.0000
[2019-03-24 09:56:11,936] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:56:12,439] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495454269.9342 47.0000
[2019-03-24 09:56:12,456] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:56:12,651] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:56:13,669] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2325000, evaluation results [2325000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7797.556686597635, 2410719396.8229294, 22.0, 6905.908355438081, 2495454269.934179, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:56:14,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6285912e-09 4.7939519e-08 6.1200285e-07 9.9999928e-01 1.2280303e-07], sum to 1.0000
[2019-03-24 09:56:14,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4223
[2019-03-24 09:56:14,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.73333333333333, 65.66666666666667, 1.0, 2.0, 0.2182604952599161, 1.0, 2.0, 0.2182604952599161, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529958.9181142321, 529958.9181142321, 163490.2954311721], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7852800.0000, 
sim time next is 7853400.0000, 
raw observation next is [24.65, 66.0, 1.0, 2.0, 0.2169887973359179, 1.0, 2.0, 0.2169887973359179, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 527106.520932781, 527106.5209327815, 163224.0004819987], 
processed observation next is [1.0, 0.9130434782608695, 0.46851851851851845, 0.66, 1.0, 1.0, 0.0678438063522832, 1.0, 1.0, 0.0678438063522832, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18825232890456467, 0.18825232890456484, 0.31389230861922823], 
reward next is 0.6861, 
noisyNet noise sample is [array([-0.15169275], dtype=float32), -1.1189295]. 
=============================================
[2019-03-24 09:56:15,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:15,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:15,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 09:56:17,181] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2326604: loss 0.0328
[2019-03-24 09:56:17,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2326605: learning rate 0.0000
[2019-03-24 09:56:19,478] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2327585: loss 0.0806
[2019-03-24 09:56:19,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2327585: learning rate 0.0000
[2019-03-24 09:56:20,253] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2327915: loss 0.0907
[2019-03-24 09:56:20,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2327915: learning rate 0.0000
[2019-03-24 09:56:20,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2328022: loss 0.0647
[2019-03-24 09:56:20,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2328022: learning rate 0.0000
[2019-03-24 09:56:21,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:21,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:21,220] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 09:56:21,694] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328541: loss 0.0353
[2019-03-24 09:56:21,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328541: learning rate 0.0000
[2019-03-24 09:56:21,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:21,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:21,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 09:56:23,734] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2329538: loss 0.0943
[2019-03-24 09:56:23,736] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2329539: learning rate 0.0000
[2019-03-24 09:56:26,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:26,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:26,124] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 09:56:26,196] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2330572: loss 0.1461
[2019-03-24 09:56:26,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2330572: learning rate 0.0000
[2019-03-24 09:56:26,536] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330730: loss 0.0766
[2019-03-24 09:56:26,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330730: learning rate 0.0000
[2019-03-24 09:56:26,569] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2330744: loss 0.0684
[2019-03-24 09:56:26,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2330746: learning rate 0.0000
[2019-03-24 09:56:27,156] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2331056: loss 0.1095
[2019-03-24 09:56:27,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2331056: learning rate 0.0000
[2019-03-24 09:56:28,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:28,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:28,106] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2331487: loss 0.0591
[2019-03-24 09:56:28,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2331488: learning rate 0.0000
[2019-03-24 09:56:28,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 09:56:28,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:28,834] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:28,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 09:56:29,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:29,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:29,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 09:56:29,750] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2332277: loss 0.0906
[2019-03-24 09:56:29,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2332278: learning rate 0.0000
[2019-03-24 09:56:30,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:30,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:30,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 09:56:31,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1620378e-08 5.9355824e-07 5.7668615e-07 9.9999726e-01 1.3923335e-06], sum to 1.0000
[2019-03-24 09:56:31,139] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-24 09:56:31,144] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.61666666666667, 12.5, 1.0, 2.0, 0.1910948918489953, 1.0, 2.0, 0.1910948918489953, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489897.1683008009, 489897.1683008014, 158298.4290307036], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 155400.0000, 
sim time next is 156000.0000, 
raw observation next is [33.33333333333334, 13.0, 1.0, 2.0, 0.1883730782931911, 1.0, 2.0, 0.1883730782931911, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482985.0130672455, 482985.0130672455, 157732.782973859], 
processed observation next is [1.0, 0.8260869565217391, 0.7901234567901239, 0.13, 1.0, 1.0, 0.03377747415856084, 1.0, 1.0, 0.03377747415856084, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17249464752401625, 0.17249464752401625, 0.3033322749497288], 
reward next is 0.6967, 
noisyNet noise sample is [array([-1.4826959], dtype=float32), 0.35341486]. 
=============================================
[2019-03-24 09:56:31,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.12755 ]
 [64.83194 ]
 [65.103615]
 [65.144936]
 [65.13095 ]], R is [[65.10012817]
 [65.14470673]
 [65.18930054]
 [65.23301697]
 [65.27586365]].
[2019-03-24 09:56:31,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:31,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:31,876] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 09:56:33,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:33,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:33,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 09:56:34,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:34,143] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:34,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 09:56:34,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:34,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:34,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 09:56:34,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:34,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:34,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 09:56:35,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:35,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:35,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 09:56:37,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 09:56:37,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:56:37,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 09:56:44,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1705474e-05 1.5994101e-07 7.8370385e-06 9.9996710e-01 1.3239523e-05], sum to 1.0000
[2019-03-24 09:56:44,567] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1529
[2019-03-24 09:56:44,573] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.26666666666667, 51.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326731.4727316831, 326731.4727316831, 123853.8555420208], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 271200.0000, 
sim time next is 271800.0000, 
raw observation next is [20.2, 51.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 325431.7053372575, 325431.7053372579, 123376.7153053271], 
processed observation next is [0.0, 0.13043478260869565, 0.3037037037037037, 0.515, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11622560904902053, 0.11622560904902067, 0.23726291404870598], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07097011], dtype=float32), -0.014077163]. 
=============================================
[2019-03-24 09:56:47,729] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4015029e-05 5.3735341e-05 8.6316913e-06 9.9991453e-01 9.0391823e-06], sum to 1.0000
[2019-03-24 09:56:47,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8835
[2019-03-24 09:56:47,744] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 32.33333333333334, 1.0, 2.0, 0.1652829951018208, 1.0, 2.0, 0.1652829951018208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421341.1647495348, 421341.1647495353, 152959.2946781706], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 324600.0000, 
sim time next is 325200.0000, 
raw observation next is [27.2, 32.66666666666667, 1.0, 2.0, 0.1644639560743461, 1.0, 2.0, 0.1644639560743461, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 419291.4868759005, 419291.4868759009, 152793.2469325625], 
processed observation next is [0.0, 0.782608695652174, 0.5629629629629629, 0.3266666666666667, 1.0, 1.0, 0.0053142334218406, 1.0, 1.0, 0.0053142334218406, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14974695959853587, 0.14974695959853604, 0.2938331671780048], 
reward next is 0.7062, 
noisyNet noise sample is [array([-0.42750368], dtype=float32), -0.66995484]. 
=============================================
[2019-03-24 09:56:51,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5896899e-06 5.4011667e-05 1.1456575e-05 9.9989760e-01 3.1336593e-05], sum to 1.0000
[2019-03-24 09:56:51,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2527
[2019-03-24 09:56:51,927] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.36666666666667, 60.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 303578.2692670079, 303578.2692670079, 123039.0339438249], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [19.78333333333333, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 309834.0827249566, 309834.0827249566, 125219.0153323555], 
processed observation next is [1.0, 0.21739130434782608, 0.28827160493827153, 0.58, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11065502954462736, 0.11065502954462736, 0.24080579871606828], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7838266], dtype=float32), -0.21361]. 
=============================================
[2019-03-24 09:56:52,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8825151e-06 3.9935344e-06 5.8130577e-06 9.9993408e-01 5.2179596e-05], sum to 1.0000
[2019-03-24 09:56:52,125] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2008
[2019-03-24 09:56:52,136] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 29.66666666666667, 1.0, 2.0, 0.1757990295364364, 1.0, 2.0, 0.1757990295364364, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442594.2863759515, 442594.2863759515, 155044.394671614], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [29.45, 30.0, 1.0, 2.0, 0.1745956960400786, 1.0, 2.0, 0.1745956960400786, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439761.6224802001, 439761.6224802005, 154799.6540260125], 
processed observation next is [1.0, 0.782608695652174, 0.6462962962962963, 0.3, 1.0, 1.0, 0.01737582861914119, 1.0, 1.0, 0.01737582861914119, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15705772231435716, 0.15705772231435733, 0.29769164235771634], 
reward next is 0.7023, 
noisyNet noise sample is [array([-0.52439624], dtype=float32), 1.3997089]. 
=============================================
[2019-03-24 09:56:53,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3702411e-08 1.0926926e-08 2.1480372e-07 9.9999928e-01 5.2137830e-07], sum to 1.0000
[2019-03-24 09:56:53,096] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0894
[2019-03-24 09:56:53,101] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.65, 27.33333333333333, 1.0, 2.0, 0.2558703903869275, 1.0, 2.0, 0.2558703903869275, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637208.2293114346, 637208.2293114346, 172314.711354997], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 407400.0000, 
sim time next is 408000.0000, 
raw observation next is [30.5, 27.66666666666667, 1.0, 2.0, 0.1836857289148948, 1.0, 2.0, 0.1836857289148948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460352.3629078966, 460352.362907897, 156643.0574155526], 
processed observation next is [1.0, 0.7391304347826086, 0.6851851851851852, 0.2766666666666667, 1.0, 1.0, 0.028197296327255702, 1.0, 1.0, 0.028197296327255702, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16441155818139164, 0.16441155818139178, 0.3012366488760627], 
reward next is 0.6988, 
noisyNet noise sample is [array([1.1473806], dtype=float32), 1.9249518]. 
=============================================
[2019-03-24 09:56:53,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[46.736034]
 [47.268463]
 [47.16145 ]
 [47.290882]
 [47.245213]], R is [[46.07092667]
 [46.27884293]
 [46.33456802]
 [46.40101242]
 [46.46428299]].
[2019-03-24 09:56:59,970] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.14001534e-06 3.02381704e-06 1.20754165e-04 9.99837399e-01
 3.67576577e-05], sum to 1.0000
[2019-03-24 09:56:59,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-24 09:56:59,985] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.76666666666667, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400044.3823367535, 400044.3823367539, 151154.5410860489], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 517800.0000, 
sim time next is 518400.0000, 
raw observation next is [22.6, 59.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402241.7789574796, 402241.7789574796, 151484.9889508597], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.59, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14365777819909986, 0.14365777819909986, 0.29131728644396093], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83007824], dtype=float32), 1.0964613]. 
=============================================
[2019-03-24 09:57:02,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3157573e-06 2.1960507e-06 2.6564360e-06 9.9995673e-01 3.5149278e-05], sum to 1.0000
[2019-03-24 09:57:02,427] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1618
[2019-03-24 09:57:02,434] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 48.66666666666667, 1.0, 2.0, 0.5368557550668216, 1.0, 2.0, 0.5368557550668216, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1298359.869550147, 1298359.869550147, 250124.9857770986], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 557400.0000, 
sim time next is 558000.0000, 
raw observation next is [27.0, 50.0, 1.0, 2.0, 0.5184625647740864, 1.0, 2.0, 0.5184625647740864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1254630.259562648, 1254630.259562648, 244168.584522871], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.5, 1.0, 1.0, 0.426741148540579, 1.0, 1.0, 0.426741148540579, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4480822355580885, 0.4480822355580885, 0.4695549702362904], 
reward next is 0.5304, 
noisyNet noise sample is [array([-0.8076819], dtype=float32), 0.83968586]. 
=============================================
[2019-03-24 09:57:02,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[51.688988]
 [51.59785 ]
 [51.610863]
 [51.62638 ]
 [51.569565]], R is [[51.67316437]
 [51.67542267]
 [51.67570877]
 [51.67580032]
 [51.67961121]].
[2019-03-24 09:57:05,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3897898e-06 2.4876968e-07 2.3498467e-06 9.9998963e-01 4.4464136e-06], sum to 1.0000
[2019-03-24 09:57:05,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6014
[2019-03-24 09:57:05,230] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 39.33333333333333, 1.0, 2.0, 0.5513855093179644, 1.0, 2.0, 0.5513855093179644, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1337949.377841512, 1337949.377841512, 255080.2685178639], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 550200.0000, 
sim time next is 550800.0000, 
raw observation next is [30.6, 35.0, 1.0, 2.0, 0.5808560600828255, 1.0, 2.0, 0.5808560600828255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1405349.069225238, 1405349.069225239, 264937.5997095545], 
processed observation next is [1.0, 0.391304347826087, 0.688888888888889, 0.35, 1.0, 1.0, 0.5010191191462209, 1.0, 1.0, 0.5010191191462209, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5019103818661564, 0.5019103818661568, 0.5094953840568356], 
reward next is 0.4905, 
noisyNet noise sample is [array([0.5596735], dtype=float32), -1.6483659]. 
=============================================
[2019-03-24 09:57:10,021] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5497297e-05 2.6688222e-06 1.1332595e-05 9.9993086e-01 2.9689038e-05], sum to 1.0000
[2019-03-24 09:57:10,034] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0653
[2019-03-24 09:57:10,041] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.45, 32.5, 1.0, 2.0, 0.65757121162277, 1.0, 2.0, 0.65757121162277, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1583602.997132326, 1583602.997132326, 292109.875174602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 574200.0000, 
sim time next is 574800.0000, 
raw observation next is [31.53333333333333, 32.33333333333334, 1.0, 2.0, 0.6706645437898223, 1.0, 2.0, 0.6706645437898223, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1614096.222424085, 1614096.222424085, 296955.4382102996], 
processed observation next is [1.0, 0.6521739130434783, 0.7234567901234568, 0.3233333333333334, 1.0, 1.0, 0.6079339807021694, 1.0, 1.0, 0.6079339807021694, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5764629365800303, 0.5764629365800303, 0.5710681504044223], 
reward next is 0.4289, 
noisyNet noise sample is [array([-1.2888352], dtype=float32), 2.6839175]. 
=============================================
[2019-03-24 09:57:10,048] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 09:57:10,050] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:57:10,051] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:57:10,051] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:57:10,052] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:57:10,053] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:57:10,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:57:10,053] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:57:10,057] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:57:10,061] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:57:10,058] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:57:10,088] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 09:57:10,122] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 09:57:10,154] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 09:57:10,184] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 09:57:10,185] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 09:57:18,830] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:57:18,830] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.75, 71.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332328.0095742426, 332328.0095742426, 140199.2553178671]
[2019-03-24 09:57:18,830] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:57:18,832] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6003202e-06 2.5256124e-06 7.2782982e-06 9.9997962e-01 8.0080381e-06], sampled 0.5455600188023658
[2019-03-24 09:57:42,609] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:57:42,610] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.99892781, 70.442850125, 1.0, 2.0, 0.3222477739736071, 1.0, 2.0, 0.3222477739736071, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742674.1519736317, 742674.1519736317, 186281.6758032166]
[2019-03-24 09:57:42,610] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:57:42,612] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2185717e-07 6.0061132e-07 1.9330864e-06 9.9999475e-01 2.1421308e-06], sampled 0.16568792369464702
[2019-03-24 09:57:43,230] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:57:43,230] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.1719935648506199, 1.0, 2.0, 0.1719935648506199, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 429123.4455293345, 429123.4455293349, 154176.2861759821]
[2019-03-24 09:57:43,230] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:57:43,233] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4449251e-07 9.3764839e-07 2.8901441e-06 9.9999201e-01 3.2361781e-06], sampled 0.8999089846404279
[2019-03-24 09:57:45,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:57:45,243] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.08333333333334, 43.33333333333333, 1.0, 2.0, 0.2242235692973927, 1.0, 2.0, 0.2242235692973927, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538560.9327830077, 538560.9327830081, 164568.7261278832]
[2019-03-24 09:57:45,246] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:57:45,249] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.4184398e-07 8.1226153e-07 2.5535444e-06 9.9999309e-01 2.7686760e-06], sampled 0.45144175995489755
[2019-03-24 09:58:09,564] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:58:09,567] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.90941919, 99.78420047333333, 1.0, 2.0, 0.2932579464980528, 1.0, 2.0, 0.2932579464980528, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673193.617214482, 673193.6172144825, 179089.5114881338]
[2019-03-24 09:58:09,568] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:58:09,572] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9810358e-07 6.7737926e-07 2.1839771e-06 9.9999404e-01 2.3436419e-06], sampled 0.31932843259172006
[2019-03-24 09:58:10,048] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:58:10,048] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.25, 74.0, 1.0, 2.0, 0.6608701490897957, 1.0, 2.0, 0.6608701490897957, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1507107.012847836, 1507107.012847836, 289619.246450657]
[2019-03-24 09:58:10,050] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:58:10,052] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2639448e-07 8.7118957e-07 2.7833516e-06 9.9999249e-01 2.9803109e-06], sampled 0.863859938984943
[2019-03-24 09:58:26,033] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:58:26,035] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.13333333333333, 85.33333333333334, 1.0, 2.0, 0.2983720049400511, 1.0, 2.0, 0.2983720049400511, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 680697.9605870048, 680697.9605870051, 180102.2554338936]
[2019-03-24 09:58:26,035] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:58:26,038] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.3304035e-07 5.1230228e-07 1.6804346e-06 9.9999535e-01 1.8708274e-06], sampled 0.9697529278543152
[2019-03-24 09:58:43,413] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01096228], dtype=float32), 0.010942339]
[2019-03-24 09:58:43,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.5, 27.0, 1.0, 2.0, 0.2300671334485734, 1.0, 2.0, 0.2300671334485734, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548974.823471239, 548974.8234712394, 165702.271858667]
[2019-03-24 09:58:43,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:58:43,420] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2735265e-07 5.0799093e-07 1.6539279e-06 9.9999559e-01 1.8046773e-06], sampled 0.1108170898577493
[2019-03-24 09:59:18,775] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 09:59:19,359] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 09:59:19,551] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 09:59:19,609] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 09:59:19,734] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 09:59:20,752] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2350000, evaluation results [2350000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 09:59:32,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1775045e-07 4.8824006e-07 8.1976314e-06 9.9998641e-01 4.0630512e-06], sum to 1.0000
[2019-03-24 09:59:32,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0678
[2019-03-24 09:59:32,607] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.26666666666667, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 384629.0279740387, 384629.0279740392, 148617.9456978613], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1020000.0000, 
sim time next is 1020600.0000, 
raw observation next is [22.75, 54.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 381626.654854789, 381626.6548547894, 148117.5915505308], 
processed observation next is [1.0, 0.8260869565217391, 0.39814814814814814, 0.545, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13629523387671036, 0.1362952338767105, 0.28484152221255926], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36215246], dtype=float32), -0.067838505]. 
=============================================
[2019-03-24 09:59:36,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8384727e-07 1.9932564e-07 1.7031634e-06 9.9999678e-01 8.0426116e-07], sum to 1.0000
[2019-03-24 09:59:36,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5444
[2019-03-24 09:59:36,963] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333333, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396570.7243281645, 396570.7243281645, 150700.1990765363], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 398914.7459901508, 398914.7459901513, 151086.6459664646], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.58, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14246955213933957, 0.14246955213933976, 0.29055124224320117], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11963654], dtype=float32), -1.2882807]. 
=============================================
[2019-03-24 09:59:44,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7323913e-05 7.6865899e-06 2.9109692e-06 9.9996185e-01 1.0248214e-05], sum to 1.0000
[2019-03-24 09:59:44,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5794
[2019-03-24 09:59:44,589] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.15, 42.5, 1.0, 2.0, 0.2487217442687873, 1.0, 2.0, 0.2487217442687873, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 624677.0602824417, 624677.0602824417, 170778.019826912], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1084200.0000, 
sim time next is 1084800.0000, 
raw observation next is [26.3, 42.0, 1.0, 2.0, 0.3619077409566255, 1.0, 2.0, 0.3619077409566255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 906994.3503135585, 906994.3503135589, 198888.4943840916], 
processed observation next is [1.0, 0.5652173913043478, 0.5296296296296297, 0.42, 1.0, 1.0, 0.240366358281697, 1.0, 1.0, 0.240366358281697, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3239265536834137, 0.3239265536834139, 0.3824778738155608], 
reward next is 0.6175, 
noisyNet noise sample is [array([-0.16039118], dtype=float32), 0.5861483]. 
=============================================
[2019-03-24 09:59:48,895] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2018285e-04 5.3830423e-05 3.3364503e-04 9.9835926e-01 9.3311421e-04], sum to 1.0000
[2019-03-24 09:59:48,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4501
[2019-03-24 09:59:48,917] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 44.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367218.2193331146, 367218.219333115, 145745.0973013996], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1022400.0000, 
sim time next is 1023000.0000, 
raw observation next is [24.13333333333333, 44.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 365487.961753857, 365487.9617538574, 145461.3361524212], 
processed observation next is [1.0, 0.8695652173913043, 0.44938271604938257, 0.4433333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13053141491209178, 0.13053141491209191, 0.27973333875465617], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7431649], dtype=float32), 0.38000324]. 
=============================================
[2019-03-24 09:59:48,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[40.32524 ]
 [40.54696 ]
 [40.30228 ]
 [40.517353]
 [40.62577 ]], R is [[39.82688522]
 [39.42861557]
 [39.03432846]
 [38.64398575]
 [38.25754547]].
[2019-03-24 09:59:49,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6650334e-05 2.0093714e-04 2.4655613e-04 9.9929881e-01 2.1699896e-04], sum to 1.0000
[2019-03-24 09:59:49,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5214
[2019-03-24 09:59:49,558] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.23333333333333, 48.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 351198.6627203489, 351198.6627203493, 143300.699094095], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1032000.0000, 
sim time next is 1032600.0000, 
raw observation next is [23.16666666666667, 48.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 351297.3781220517, 351297.3781220521, 143313.7894873781], 
processed observation next is [1.0, 0.9565217391304348, 0.4135802469135804, 0.4866666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12546334932930417, 0.12546334932930434, 0.2756034413218809], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.591594], dtype=float32), 0.58113176]. 
=============================================
[2019-03-24 09:59:53,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1973441e-05 6.6203684e-05 1.4032352e-05 9.9975175e-01 8.6030086e-05], sum to 1.0000
[2019-03-24 09:59:53,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4205
[2019-03-24 09:59:53,035] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.33333333333333, 71.33333333333334, 1.0, 2.0, 0.1600658751127298, 1.0, 2.0, 0.1600658751127298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 406278.9636301027, 406278.9636301032, 151889.182075673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [20.26666666666667, 71.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398497.7701074292, 398497.7701074292, 150723.3621346177], 
processed observation next is [1.0, 0.17391304347826086, 0.3061728395061729, 0.7166666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1423206321812247, 0.1423206321812247, 0.2898526194896494], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.72073746], dtype=float32), 0.0770109]. 
=============================================
[2019-03-24 10:00:02,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6676009e-07 1.3719604e-06 2.7886881e-06 9.9997675e-01 1.8510800e-05], sum to 1.0000
[2019-03-24 10:00:02,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1208
[2019-03-24 10:00:02,532] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 54.0, 1.0, 2.0, 0.5074318945571125, 1.0, 2.0, 0.5074318945571125, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1235359.681938119, 1235359.681938119, 240874.0164994181], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1594800.0000, 
sim time next is 1595400.0000, 
raw observation next is [25.88333333333333, 53.5, 1.0, 2.0, 0.4645519486443137, 1.0, 2.0, 0.4645519486443137, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1131778.205573138, 1131778.205573139, 227562.0968374026], 
processed observation next is [1.0, 0.4782608695652174, 0.5141975308641974, 0.535, 1.0, 1.0, 0.362561843624183, 1.0, 1.0, 0.362561843624183, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4042065019904065, 0.4042065019904068, 0.437619416995005], 
reward next is 0.5624, 
noisyNet noise sample is [array([-0.21001777], dtype=float32), 0.39271218]. 
=============================================
[2019-03-24 10:00:03,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5500990e-06 1.2758600e-06 1.1041163e-06 9.9999595e-01 9.4733373e-08], sum to 1.0000
[2019-03-24 10:00:03,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0575
[2019-03-24 10:00:03,115] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.26666666666667, 60.0, 1.0, 2.0, 0.3699282637884719, 1.0, 2.0, 0.3699282637884719, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 899476.3311386802, 899476.3311386807, 200375.309392881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1257600.0000, 
sim time next is 1258200.0000, 
raw observation next is [25.45, 59.5, 1.0, 2.0, 0.3919346705955953, 1.0, 2.0, 0.3919346705955953, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 950788.594820052, 950788.594820052, 206330.8234842954], 
processed observation next is [1.0, 0.5652173913043478, 0.4981481481481481, 0.595, 1.0, 1.0, 0.27611270308999436, 1.0, 1.0, 0.27611270308999436, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33956735529287574, 0.33956735529287574, 0.39679004516210653], 
reward next is 0.6032, 
noisyNet noise sample is [array([1.5575696], dtype=float32), 0.24631302]. 
=============================================
[2019-03-24 10:00:04,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3160890e-07 9.9544593e-07 3.5673474e-05 9.9996090e-01 2.1889571e-06], sum to 1.0000
[2019-03-24 10:00:04,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3202
[2019-03-24 10:00:04,665] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.66666666666667, 67.0, 1.0, 2.0, 0.1640716041147872, 1.0, 2.0, 0.1640716041147872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413508.0652494197, 413508.0652494201, 152655.2597167264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1385400.0000, 
sim time next is 1386000.0000, 
raw observation next is [21.6, 67.0, 1.0, 2.0, 0.162603387295236, 1.0, 2.0, 0.162603387295236, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410118.4835385369, 410118.4835385374, 152364.0803612978], 
processed observation next is [0.0, 0.043478260869565216, 0.3555555555555556, 0.67, 1.0, 1.0, 0.0030992705895666515, 1.0, 1.0, 0.0030992705895666515, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1464708869780489, 0.14647088697804908, 0.2930078468486496], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.6938143], dtype=float32), -0.26957297]. 
=============================================
[2019-03-24 10:00:04,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.250595]
 [64.633766]
 [64.91103 ]
 [64.58804 ]
 [64.54703 ]], R is [[63.61206055]
 [63.68237305]
 [63.75128174]
 [63.8187294 ]
 [63.88493347]].
[2019-03-24 10:00:05,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5227448e-06 6.3093051e-09 7.4010939e-07 9.9999678e-01 8.9883855e-07], sum to 1.0000
[2019-03-24 10:00:05,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3081
[2019-03-24 10:00:05,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.2, 91.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392521.0456674654, 392521.0456674654, 150011.9058914795], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1231200.0000, 
sim time next is 1231800.0000, 
raw observation next is [18.28333333333333, 90.66666666666667, 1.0, 2.0, 0.1658964486331262, 1.0, 2.0, 0.1658964486331262, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 419582.1487580682, 419582.1487580687, 153048.5971255037], 
processed observation next is [1.0, 0.2608695652173913, 0.23271604938271598, 0.9066666666666667, 1.0, 1.0, 0.0070195817061026065, 1.0, 1.0, 0.0070195817061026065, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1498507674135958, 0.14985076741359596, 0.29432422524135327], 
reward next is 0.7057, 
noisyNet noise sample is [array([-2.48477], dtype=float32), 0.8021197]. 
=============================================
[2019-03-24 10:00:13,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5292184e-07 2.0158996e-07 1.7642207e-06 9.9999642e-01 1.3366888e-06], sum to 1.0000
[2019-03-24 10:00:13,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7820
[2019-03-24 10:00:13,069] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 60.0, 1.0, 2.0, 0.1808993207300556, 1.0, 2.0, 0.1808993207300556, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 450700.817990954, 450700.8179909545, 155997.7925830179], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1375200.0000, 
sim time next is 1375800.0000, 
raw observation next is [23.58333333333334, 61.16666666666666, 1.0, 2.0, 0.1801381006582452, 1.0, 2.0, 0.1801381006582452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 448964.9882860892, 448964.9882860896, 155843.7260532411], 
processed observation next is [1.0, 0.9565217391304348, 0.4290123456790126, 0.6116666666666666, 1.0, 1.0, 0.02397392935505381, 1.0, 1.0, 0.02397392935505381, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1603446386736033, 0.16034463867360343, 0.2996994731793098], 
reward next is 0.7003, 
noisyNet noise sample is [array([-1.2809038], dtype=float32), 0.0074718865]. 
=============================================
[2019-03-24 10:00:18,665] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2117185e-07 2.1052259e-07 3.9851143e-06 9.9997485e-01 2.0709182e-05], sum to 1.0000
[2019-03-24 10:00:18,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9105
[2019-03-24 10:00:18,675] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.96666666666667, 78.66666666666667, 1.0, 2.0, 0.3748726475748448, 1.0, 2.0, 0.3748726475748448, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 915555.3616088255, 915555.361608826, 201836.1612074145], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1855200.0000, 
sim time next is 1855800.0000, 
raw observation next is [21.95, 79.0, 1.0, 2.0, 0.403764986536837, 1.0, 2.0, 0.403764986536837, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 984642.6617475048, 984642.6617475052, 209796.6659672716], 
processed observation next is [1.0, 0.4782608695652174, 0.36851851851851847, 0.79, 1.0, 1.0, 0.2901964125438536, 1.0, 1.0, 0.2901964125438536, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3516580934812517, 0.3516580934812519, 0.4034551268601377], 
reward next is 0.5965, 
noisyNet noise sample is [array([0.4211343], dtype=float32), -1.1793684]. 
=============================================
[2019-03-24 10:00:19,145] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 10:00:19,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:00:19,152] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:00:19,152] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:00:19,158] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:00:19,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:00:19,163] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:00:19,161] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:00:19,164] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:00:19,166] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:00:19,166] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:00:19,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 10:00:19,213] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 10:00:19,214] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 10:00:19,271] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 10:00:19,304] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 10:00:25,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:00:25,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.71666666666667, 54.66666666666666, 1.0, 2.0, 0.244175472888831, 1.0, 2.0, 0.244175472888831, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629818.5624798597, 629818.5624798597, 169836.622976828]
[2019-03-24 10:00:25,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:00:25,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6076414e-07 3.6499054e-07 1.8509305e-06 9.9999559e-01 1.6780136e-06], sampled 0.7370801591013437
[2019-03-24 10:00:50,009] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:00:50,010] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.2245523998442038, 1.0, 2.0, 0.2245523998442038, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 546562.7461693834, 546562.7461693838, 164902.5172512816]
[2019-03-24 10:00:50,011] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:00:50,015] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0262766e-07 6.4565917e-08 3.8871670e-07 9.9999905e-01 3.5920772e-07], sampled 0.4848005253630435
[2019-03-24 10:00:50,608] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:00:50,611] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.75065464666667, 83.579680975, 1.0, 2.0, 0.1753458514851281, 1.0, 2.0, 0.1753458514851281, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439518.7374171448, 439518.7374171453, 154911.8372907325]
[2019-03-24 10:00:50,611] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:00:50,615] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2201849e-07 7.8423938e-08 4.6149535e-07 9.9999893e-01 4.1640536e-07], sampled 0.13033779026334147
[2019-03-24 10:00:52,502] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:00:52,503] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.06666666666667, 80.66666666666666, 1.0, 2.0, 0.177324082868252, 1.0, 2.0, 0.177324082868252, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439931.7041909717, 439931.7041909722, 155206.5283881477]
[2019-03-24 10:00:52,506] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:00:52,509] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.7867277e-08 4.8871065e-08 2.9833956e-07 9.9999940e-01 2.7979431e-07], sampled 0.980004770740021
[2019-03-24 10:00:58,584] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:00:58,584] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.492145895, 45.92236489, 1.0, 2.0, 0.4194212207575549, 1.0, 2.0, 0.4194212207575549, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 971320.8151157026, 971320.815115704, 212301.2354948372]
[2019-03-24 10:00:58,587] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:00:58,590] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8043632e-07 1.7736727e-07 9.9155613e-07 9.9999774e-01 8.4260688e-07], sampled 0.25836030278693467
[2019-03-24 10:01:10,862] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:01:10,863] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.63333333333333, 39.33333333333334, 1.0, 2.0, 0.7414810175385271, 1.0, 2.0, 0.7414810175385271, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1733207.781035084, 1733207.781035084, 322254.1517842354]
[2019-03-24 10:01:10,864] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:01:10,867] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0796094e-07 3.8180070e-07 2.0586599e-06 9.9999523e-01 1.7456298e-06], sampled 0.9457171832522694
[2019-03-24 10:01:16,441] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:01:16,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.06666666666667, 59.33333333333334, 1.0, 2.0, 0.2609098126938716, 1.0, 2.0, 0.2609098126938716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 601948.6013131347, 601948.6013131351, 171714.8633553661]
[2019-03-24 10:01:16,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:01:16,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2987662e-07 2.6256961e-07 1.5226357e-06 9.9999666e-01 1.2458314e-06], sampled 0.3955337394610363
[2019-03-24 10:01:24,793] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:01:24,796] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.4, 78.66666666666667, 1.0, 2.0, 0.3045057570709911, 1.0, 2.0, 0.3045057570709911, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694053.8954580149, 694053.8954580149, 181546.3043466454]
[2019-03-24 10:01:24,797] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:01:24,800] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9411185e-07 2.4230150e-07 1.3964113e-06 9.9999678e-01 1.1492943e-06], sampled 0.4053642229576083
[2019-03-24 10:01:53,973] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:01:53,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 78.0, 1.0, 2.0, 0.3136519153241338, 1.0, 2.0, 0.3136519153241338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756840.4349063257, 756840.4349063261, 185557.7387017915]
[2019-03-24 10:01:53,976] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:01:53,978] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3197546e-07 1.4514399e-07 8.1875265e-07 9.9999809e-01 7.4262312e-07], sampled 0.38645801714996086
[2019-03-24 10:02:08,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:02:08,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.02937585, 14.91531423, 1.0, 2.0, 0.2519836549694925, 1.0, 2.0, 0.2519836549694925, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647600.2449181754, 647600.2449181754, 171637.1664635352]
[2019-03-24 10:02:08,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:02:08,240] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1793260e-07 2.0418986e-07 1.1008186e-06 9.9999738e-01 9.6750261e-07], sampled 0.4193032818894512
[2019-03-24 10:02:15,765] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:02:15,765] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7140390850821772, 1.0, 2.0, 0.7140390850821772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1628480.014763176, 1628480.014763176, 309515.3295365925]
[2019-03-24 10:02:15,768] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:02:15,772] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4172999e-07 2.0637582e-07 1.2219209e-06 9.9999726e-01 9.8125497e-07], sampled 0.9350006289408729
[2019-03-24 10:02:25,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117118], dtype=float32), 0.0111092385]
[2019-03-24 10:02:25,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.10421982, 78.66829199, 1.0, 2.0, 0.2061315787300027, 1.0, 2.0, 0.2061315787300027, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 499966.3445896921, 499966.3445896926, 160875.6810914666]
[2019-03-24 10:02:25,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:02:25,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5284269e-07 9.5787819e-08 5.5851154e-07 9.9999869e-01 5.2373366e-07], sampled 0.129423287207321
[2019-03-24 10:02:28,276] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.1599 2410750670.2005 22.0000
[2019-03-24 10:02:28,615] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 10:02:28,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 10:02:28,706] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 10:02:28,711] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 10:02:29,731] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2375000, evaluation results [2375000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.159933053251, 2410750670.2004886, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 10:02:30,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5455092e-07 2.2102523e-07 4.2595036e-07 9.9999654e-01 2.2082854e-06], sum to 1.0000
[2019-03-24 10:02:30,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-24 10:02:30,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 48.5, 1.0, 2.0, 0.1773103009674692, 1.0, 2.0, 0.1773103009674692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 442474.4928361179, 442474.4928361183, 155271.9438176735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1626600.0000, 
sim time next is 1627200.0000, 
raw observation next is [25.7, 49.0, 1.0, 2.0, 0.1759950883510266, 1.0, 2.0, 0.1759950883510266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439350.7593225829, 439350.7593225829, 155004.3226546576], 
processed observation next is [1.0, 0.8695652173913043, 0.5074074074074074, 0.49, 1.0, 1.0, 0.019041771846460224, 1.0, 1.0, 0.019041771846460224, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15691098547235105, 0.15691098547235105, 0.2980852358743415], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.9296082], dtype=float32), 1.051987]. 
=============================================
[2019-03-24 10:02:36,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9914283e-07 2.0555648e-08 1.9134772e-08 9.9999654e-01 2.9232999e-06], sum to 1.0000
[2019-03-24 10:02:36,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0204
[2019-03-24 10:02:36,395] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.51666666666667, 87.83333333333334, 1.0, 2.0, 0.4106993916949043, 1.0, 2.0, 0.4106993916949043, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 990173.7003168135, 990173.7003168135, 211398.8224655669], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [21.5, 88.0, 1.0, 2.0, 0.4058008070198413, 1.0, 2.0, 0.4058008070198413, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 978267.6245918104, 978267.6245918104, 210010.4324322667], 
processed observation next is [1.0, 0.7391304347826086, 0.35185185185185186, 0.88, 1.0, 1.0, 0.2926200083569539, 1.0, 1.0, 0.2926200083569539, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34938129449707517, 0.34938129449707517, 0.4038662162158975], 
reward next is 0.5961, 
noisyNet noise sample is [array([-1.6989397], dtype=float32), 1.5449752]. 
=============================================
[2019-03-24 10:02:37,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0336527e-06 1.5495626e-08 2.1354892e-07 9.9999607e-01 2.7160136e-06], sum to 1.0000
[2019-03-24 10:02:37,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7069
[2019-03-24 10:02:37,372] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.28333333333333, 86.5, 1.0, 2.0, 0.1853040701412869, 1.0, 2.0, 0.1853040701412869, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459694.2830426893, 459694.2830426897, 156864.0676595354], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [20.2, 87.0, 1.0, 2.0, 0.1846892901003732, 1.0, 2.0, 0.1846892901003732, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458310.6505138573, 458310.6505138573, 156739.4194136935], 
processed observation next is [1.0, 0.17391304347826086, 0.3037037037037037, 0.87, 1.0, 1.0, 0.029392012024253792, 1.0, 1.0, 0.029392012024253792, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16368237518352047, 0.16368237518352047, 0.30142196041094904], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.8097603], dtype=float32), 0.023507243]. 
=============================================
[2019-03-24 10:02:40,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2582982e-07 1.4119834e-07 1.9124460e-07 9.9999583e-01 3.4528075e-06], sum to 1.0000
[2019-03-24 10:02:40,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6207
[2019-03-24 10:02:40,885] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.0, 88.0, 1.0, 2.0, 0.1849671269699495, 1.0, 2.0, 0.1849671269699495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459425.1432761955, 459425.143276196, 156809.3118197004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1744200.0000, 
sim time next is 1744800.0000, 
raw observation next is [19.93333333333333, 88.33333333333333, 1.0, 2.0, 0.1833607923607266, 1.0, 2.0, 0.1833607923607266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455632.0867023756, 455632.0867023756, 156479.0053399997], 
processed observation next is [1.0, 0.17391304347826086, 0.293827160493827, 0.8833333333333333, 1.0, 1.0, 0.027810467096103103, 1.0, 1.0, 0.027810467096103103, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16272574525084843, 0.16272574525084843, 0.30092116411538405], 
reward next is 0.6991, 
noisyNet noise sample is [array([1.065742], dtype=float32), -1.4327446]. 
=============================================
[2019-03-24 10:02:42,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.009915e-08 9.541261e-08 5.737306e-07 9.999993e-01 9.267020e-09], sum to 1.0000
[2019-03-24 10:02:42,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9934
[2019-03-24 10:02:42,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 77.66666666666667, 1.0, 2.0, 0.2769965576731805, 1.0, 2.0, 0.2769965576731805, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642952.9921805831, 642952.9921805831, 175603.4281717442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2065200.0000, 
sim time next is 2065800.0000, 
raw observation next is [25.25, 77.83333333333333, 1.0, 2.0, 0.2735217634708418, 1.0, 2.0, 0.2735217634708418, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636474.2175994278, 636474.2175994278, 174867.99821762], 
processed observation next is [0.0, 0.9130434782608695, 0.49074074074074076, 0.7783333333333333, 1.0, 1.0, 0.1351449565129069, 1.0, 1.0, 0.1351449565129069, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22731222057122422, 0.22731222057122422, 0.3362846119569616], 
reward next is 0.6637, 
noisyNet noise sample is [array([0.14411159], dtype=float32), 1.2714627]. 
=============================================
[2019-03-24 10:02:44,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9213143e-09 1.8966505e-08 1.0249897e-06 9.9999881e-01 6.7477480e-08], sum to 1.0000
[2019-03-24 10:02:44,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9725
[2019-03-24 10:02:44,702] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.1, 88.33333333333334, 1.0, 2.0, 0.1699432658482057, 1.0, 2.0, 0.1699432658482057, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426956.3076411827, 426956.3076411827, 153823.8124709578], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1833600.0000, 
sim time next is 1834200.0000, 
raw observation next is [19.25, 87.5, 1.0, 2.0, 0.1699483740734089, 1.0, 2.0, 0.1699483740734089, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426772.624075297, 426772.6240752974, 153820.8880624835], 
processed observation next is [1.0, 0.21739130434782608, 0.26851851851851855, 0.875, 1.0, 1.0, 0.01184330246834393, 1.0, 1.0, 0.01184330246834393, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15241879431260608, 0.15241879431260622, 0.29580940012016055], 
reward next is 0.7042, 
noisyNet noise sample is [array([0.617401], dtype=float32), 0.1461469]. 
=============================================
[2019-03-24 10:02:45,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2042850e-05 3.7665870e-06 8.1536655e-07 9.9997187e-01 1.4014381e-06], sum to 1.0000
[2019-03-24 10:02:45,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3681
[2019-03-24 10:02:45,617] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 65.0, 1.0, 2.0, 0.4463347676401531, 1.0, 2.0, 0.4463347676401531, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1065743.863576788, 1065743.863576788, 221364.1438125536], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1774800.0000, 
sim time next is 1775400.0000, 
raw observation next is [25.46666666666667, 64.66666666666667, 1.0, 2.0, 0.4057787747254277, 1.0, 2.0, 0.4057787747254277, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 969577.7461778058, 969577.7461778063, 209699.5266054978], 
processed observation next is [1.0, 0.5652173913043478, 0.4987654320987655, 0.6466666666666667, 1.0, 1.0, 0.292593779435033, 1.0, 1.0, 0.292593779435033, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3462777664920735, 0.34627776649207365, 0.4032683203951881], 
reward next is 0.5967, 
noisyNet noise sample is [array([0.8199873], dtype=float32), 1.1738454]. 
=============================================
[2019-03-24 10:02:51,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4253001e-07 4.5731639e-07 9.6777978e-07 9.9999666e-01 1.1769844e-06], sum to 1.0000
[2019-03-24 10:02:51,558] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-24 10:02:51,564] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.35, 88.0, 1.0, 2.0, 0.6835109812198584, 1.0, 2.0, 0.6835109812198584, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1558791.730839055, 1558791.730839055, 297969.6431817746], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2215800.0000, 
sim time next is 2216400.0000, 
raw observation next is [25.13333333333333, 89.0, 1.0, 2.0, 0.583119769310622, 1.0, 2.0, 0.583119769310622, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1329644.221037649, 1329644.22103765, 262284.9556014955], 
processed observation next is [1.0, 0.6521739130434783, 0.4864197530864196, 0.89, 1.0, 1.0, 0.5037140110840739, 1.0, 1.0, 0.5037140110840739, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4748729360848747, 0.474872936084875, 0.5043941453874914], 
reward next is 0.4956, 
noisyNet noise sample is [array([-1.4249933], dtype=float32), 1.3389968]. 
=============================================
[2019-03-24 10:02:52,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9688972e-06 1.7501540e-07 7.2494566e-07 9.9999595e-01 2.1712249e-07], sum to 1.0000
[2019-03-24 10:02:52,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7601
[2019-03-24 10:02:52,023] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.93333333333333, 92.33333333333334, 1.0, 2.0, 0.237883314838881, 1.0, 2.0, 0.237883314838881, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568371.08323437, 568371.08323437, 167456.3257840292], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [21.95, 92.5, 1.0, 2.0, 0.2386820744464233, 1.0, 2.0, 0.2386820744464233, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569893.5320236484, 569893.5320236488, 167618.3301936385], 
processed observation next is [1.0, 0.0, 0.36851851851851847, 0.925, 1.0, 1.0, 0.09366913624574204, 1.0, 1.0, 0.09366913624574204, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20353340429416014, 0.2035334042941603, 0.3223429426800741], 
reward next is 0.6777, 
noisyNet noise sample is [array([0.18799259], dtype=float32), -0.27292603]. 
=============================================
[2019-03-24 10:02:54,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8846387e-08 4.9523781e-08 4.8273865e-05 9.9994981e-01 1.8507117e-06], sum to 1.0000
[2019-03-24 10:02:54,791] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9932
[2019-03-24 10:02:54,796] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.03333333333333, 91.83333333333334, 1.0, 2.0, 0.1945398975478917, 1.0, 2.0, 0.1945398975478917, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479997.5126775109, 479997.5126775109, 158714.9436754004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1923000.0000, 
sim time next is 1923600.0000, 
raw observation next is [20.06666666666667, 91.66666666666667, 1.0, 2.0, 0.1896144429574871, 1.0, 2.0, 0.1896144429574871, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467742.8858127749, 467742.8858127749, 157689.1929160179], 
processed observation next is [1.0, 0.2608695652173913, 0.29876543209876555, 0.9166666666666667, 1.0, 1.0, 0.0352552892351037, 1.0, 1.0, 0.0352552892351037, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1670510306474196, 0.1670510306474196, 0.30324844791541905], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.0027313], dtype=float32), -0.8804899]. 
=============================================
[2019-03-24 10:02:55,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3755722e-08 1.9142703e-05 6.8286357e-07 9.9997830e-01 1.7933947e-06], sum to 1.0000
[2019-03-24 10:02:55,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3805
[2019-03-24 10:02:55,093] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.2, 90.0, 1.0, 2.0, 0.2149444166442594, 1.0, 2.0, 0.2149444166442594, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522515.5840173315, 522515.5840173315, 162796.8975189199], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1882800.0000, 
sim time next is 1883400.0000, 
raw observation next is [21.16666666666667, 90.16666666666667, 1.0, 2.0, 0.2144420814079893, 1.0, 2.0, 0.2144420814079893, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521371.1963222623, 521371.1963222628, 162691.6034605065], 
processed observation next is [1.0, 0.8260869565217391, 0.33950617283950635, 0.9016666666666667, 1.0, 1.0, 0.06481200167617772, 1.0, 1.0, 0.06481200167617772, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18620399868652224, 0.18620399868652243, 0.31286846819328173], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.35097703], dtype=float32), 1.0256739]. 
=============================================
[2019-03-24 10:02:58,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4046396e-07 2.8600439e-06 3.0116798e-05 9.9996340e-01 2.6263115e-06], sum to 1.0000
[2019-03-24 10:02:58,606] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7112
[2019-03-24 10:02:58,610] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.58333333333334, 92.0, 1.0, 2.0, 0.1841551010352922, 1.0, 2.0, 0.1841551010352922, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457160.9042486206, 457160.9042486206, 156632.6717714123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1911000.0000, 
sim time next is 1911600.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.1875221409136924, 1.0, 2.0, 0.1875221409136924, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 465392.3996552366, 465392.399655237, 157334.7756880381], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.92, 1.0, 1.0, 0.03276445346868143, 1.0, 1.0, 0.03276445346868143, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16621157130544162, 0.16621157130544179, 0.30256687632315016], 
reward next is 0.6974, 
noisyNet noise sample is [array([-0.7291431], dtype=float32), -1.137988]. 
=============================================
[2019-03-24 10:03:02,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8853246e-06 3.9225841e-07 8.0237197e-07 9.9999106e-01 9.7926704e-07], sum to 1.0000
[2019-03-24 10:03:02,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9587
[2019-03-24 10:03:02,143] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.38333333333333, 79.83333333333334, 1.0, 2.0, 0.187522365076496, 1.0, 2.0, 0.187522365076496, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463746.024771635, 463746.024771635, 157287.2945196601], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [21.5, 79.0, 1.0, 2.0, 0.1873478056084526, 1.0, 2.0, 0.1873478056084526, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463292.9871949694, 463292.9871949694, 157250.0134602101], 
processed observation next is [0.0, 0.34782608695652173, 0.35185185185185186, 0.79, 1.0, 1.0, 0.03255691143863405, 1.0, 1.0, 0.03255691143863405, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1654617811410605, 0.1654617811410605, 0.30240387203886554], 
reward next is 0.6976, 
noisyNet noise sample is [array([0.59795076], dtype=float32), -0.07209212]. 
=============================================
[2019-03-24 10:03:02,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.49218]
 [66.55424]
 [66.58847]
 [66.6649 ]
 [66.69839]], R is [[66.46852875]
 [66.50136566]
 [66.53372192]
 [66.56556702]
 [66.59703827]].
[2019-03-24 10:03:06,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7599585e-06 4.2544794e-09 5.5984754e-07 9.9999619e-01 4.7259041e-07], sum to 1.0000
[2019-03-24 10:03:06,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9165
[2019-03-24 10:03:06,175] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 76.33333333333333, 1.0, 2.0, 0.2947781690169048, 1.0, 2.0, 0.2947781690169048, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674694.3588301983, 674694.3588301986, 179353.9587289645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2061600.0000, 
sim time next is 2062200.0000, 
raw observation next is [26.15, 76.66666666666667, 1.0, 2.0, 0.291886976603159, 1.0, 2.0, 0.291886976603159, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669456.7452250019, 669456.7452250024, 178734.2628155236], 
processed observation next is [0.0, 0.8695652173913043, 0.524074074074074, 0.7666666666666667, 1.0, 1.0, 0.15700830547995118, 1.0, 1.0, 0.15700830547995118, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23909169472321498, 0.23909169472321515, 0.3437197361836992], 
reward next is 0.6563, 
noisyNet noise sample is [array([0.40761945], dtype=float32), -1.5426441]. 
=============================================
[2019-03-24 10:03:12,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4675031e-05 2.3451798e-06 2.4897831e-06 9.9991953e-01 5.0842144e-05], sum to 1.0000
[2019-03-24 10:03:12,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1885
[2019-03-24 10:03:12,587] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.1, 89.0, 1.0, 2.0, 0.2962385736815409, 1.0, 2.0, 0.2962385736815409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683388.009593508, 683388.0095935084, 179963.176817713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2183400.0000, 
sim time next is 2184000.0000, 
raw observation next is [24.13333333333333, 89.0, 1.0, 2.0, 0.292860695061118, 1.0, 2.0, 0.292860695061118, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675303.1139343505, 675303.1139343505, 179141.4694555156], 
processed observation next is [1.0, 0.2608695652173913, 0.44938271604938257, 0.89, 1.0, 1.0, 0.1581674941203786, 1.0, 1.0, 0.1581674941203786, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24117968354798233, 0.24117968354798233, 0.3445028258759915], 
reward next is 0.6555, 
noisyNet noise sample is [array([0.0418577], dtype=float32), -0.8136739]. 
=============================================
[2019-03-24 10:03:12,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.824368]
 [56.631397]
 [56.620804]
 [56.591007]
 [56.90486 ]], R is [[57.08307266]
 [57.16615677]
 [57.24464035]
 [57.30603409]
 [57.3611145 ]].
[2019-03-24 10:03:14,702] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3658867e-05 4.1878778e-07 1.1428714e-06 9.9992383e-01 1.0854457e-05], sum to 1.0000
[2019-03-24 10:03:14,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-24 10:03:14,716] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.63333333333334, 91.66666666666667, 1.0, 2.0, 0.5917613615474588, 1.0, 2.0, 0.5917613615474588, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1349366.351971377, 1349366.351971377, 265219.1534882248], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2200800.0000, 
sim time next is 2201400.0000, 
raw observation next is [24.8, 91.0, 1.0, 2.0, 0.5799601335991894, 1.0, 2.0, 0.5799601335991894, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1322433.321481623, 1322433.321481623, 261218.4588918001], 
processed observation next is [1.0, 0.4782608695652174, 0.4740740740740741, 0.91, 1.0, 1.0, 0.499952539999035, 1.0, 1.0, 0.499952539999035, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4722976148148654, 0.4722976148148654, 0.5023431901765387], 
reward next is 0.4977, 
noisyNet noise sample is [array([-1.7774547], dtype=float32), -0.661722]. 
=============================================
[2019-03-24 10:03:14,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3106850e-06 2.2397752e-07 1.0452277e-06 9.9999404e-01 2.3912978e-06], sum to 1.0000
[2019-03-24 10:03:14,819] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1087
[2019-03-24 10:03:14,825] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.76666666666667, 96.0, 1.0, 2.0, 0.2557204383971459, 1.0, 2.0, 0.2557204383971459, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 607339.7255249544, 607339.7255249548, 171326.2779141605], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2346000.0000, 
sim time next is 2346600.0000, 
raw observation next is [21.73333333333333, 96.0, 1.0, 2.0, 0.2543213665906739, 1.0, 2.0, 0.2543213665906739, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 604401.6493859722, 604401.6493859726, 171023.584463495], 
processed observation next is [1.0, 0.13043478260869565, 0.3604938271604937, 0.96, 1.0, 1.0, 0.11228734117937368, 1.0, 1.0, 0.11228734117937368, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2158577319235615, 0.21585773192356167, 0.32889150858364424], 
reward next is 0.6711, 
noisyNet noise sample is [array([1.6100909], dtype=float32), 0.6009975]. 
=============================================
[2019-03-24 10:03:18,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0006126e-07 6.1758931e-07 2.2655061e-07 9.9999547e-01 2.9356761e-06], sum to 1.0000
[2019-03-24 10:03:18,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9308
[2019-03-24 10:03:18,181] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 96.5, 1.0, 2.0, 0.2184281192077518, 1.0, 2.0, 0.2184281192077518, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531142.2359017992, 531142.2359017992, 163553.5203932185], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2273400.0000, 
sim time next is 2274000.0000, 
raw observation next is [20.4, 96.66666666666666, 1.0, 2.0, 0.2300748885347742, 1.0, 2.0, 0.2300748885347742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 559182.8290031264, 559182.8290031267, 166086.68188713], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.9666666666666666, 1.0, 1.0, 0.08342248635092167, 1.0, 1.0, 0.08342248635092167, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19970815321540228, 0.1997081532154024, 0.3193974651675577], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.36790624], dtype=float32), 0.22875655]. 
=============================================
[2019-03-24 10:03:18,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[61.98353 ]
 [62.02724 ]
 [62.150284]
 [62.24726 ]
 [62.27772 ]], R is [[62.00492477]
 [62.07035065]
 [62.13423538]
 [62.19075775]
 [62.25675964]].
[2019-03-24 10:03:18,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0148700e-06 2.1381064e-08 2.8065237e-08 9.9999881e-01 7.3761754e-08], sum to 1.0000
[2019-03-24 10:03:18,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5434
[2019-03-24 10:03:18,622] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 51.0, 1.0, 2.0, 0.1943644584114829, 1.0, 2.0, 0.1943644584114829, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479083.2010563746, 479083.2010563751, 158664.2175907759], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2408400.0000, 
sim time next is 2409000.0000, 
raw observation next is [26.16666666666666, 52.0, 1.0, 2.0, 0.194153771731525, 1.0, 2.0, 0.194153771731525, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478702.532537809, 478702.532537809, 158624.4141629369], 
processed observation next is [1.0, 0.9130434782608695, 0.5246913580246911, 0.52, 1.0, 1.0, 0.040659252061339295, 1.0, 1.0, 0.040659252061339295, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17096519019207465, 0.17096519019207465, 0.3050469503133402], 
reward next is 0.6950, 
noisyNet noise sample is [array([2.4048827], dtype=float32), -0.8852624]. 
=============================================
[2019-03-24 10:03:18,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.72676 ]
 [64.700195]
 [64.5804  ]
 [64.411705]
 [64.21575 ]], R is [[64.86956024]
 [64.91574097]
 [64.9614563 ]
 [65.00675964]
 [65.05168915]].
[2019-03-24 10:03:27,852] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 10:03:27,853] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:03:27,853] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:03:27,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:03:27,854] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:03:27,854] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:03:27,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:03:27,859] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:03:27,860] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:03:27,854] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:03:27,865] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:03:27,886] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 10:03:27,920] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 10:03:27,951] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 10:03:27,979] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 10:03:28,008] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 10:03:49,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:03:49,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.53333333333333, 62.33333333333333, 1.0, 2.0, 0.2739244506100475, 1.0, 2.0, 0.2739244506100475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670464.4516857876, 670464.4516857876, 176235.752078593]
[2019-03-24 10:03:49,003] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:03:49,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1678352e-06 7.3878010e-07 3.0444255e-06 9.9999201e-01 3.1241655e-06], sampled 0.29203432717250144
[2019-03-24 10:03:53,163] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:03:53,166] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.46666666666667, 33.0, 1.0, 2.0, 0.2096374313583088, 1.0, 2.0, 0.2096374313583088, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507152.9580948238, 507152.9580948243, 161572.0749818801]
[2019-03-24 10:03:53,169] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:03:53,172] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8230004e-07 3.0043060e-07 1.2913765e-06 9.9999642e-01 1.3788556e-06], sampled 0.37749558298805475
[2019-03-24 10:03:57,350] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:03:57,352] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.33333333333334, 45.66666666666667, 1.0, 2.0, 0.2796858273873908, 1.0, 2.0, 0.2796858273873908, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662616.7450777079, 662616.7450777079, 176822.0861367097]
[2019-03-24 10:03:57,354] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:03:57,359] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4386171e-07 4.0119636e-07 1.7108466e-06 9.9999547e-01 1.7840466e-06], sampled 0.7567081169416792
[2019-03-24 10:04:20,210] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:04:20,211] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.33495145333333, 63.75921645666667, 1.0, 2.0, 0.3020888597894693, 1.0, 2.0, 0.3020888597894693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690528.4148864484, 690528.4148864484, 181062.0135215952]
[2019-03-24 10:04:20,212] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:04:20,213] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.6807784e-07 2.8937885e-07 1.2806516e-06 9.9999666e-01 1.2988803e-06], sampled 0.7361532919281234
[2019-03-24 10:04:45,131] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:04:45,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.94402120666667, 83.49739345333333, 1.0, 2.0, 0.2862106890421572, 1.0, 2.0, 0.2862106890421572, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 660596.9166161197, 660596.9166161192, 177593.4237367983]
[2019-03-24 10:04:45,134] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:04:45,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.9720427e-07 3.0887782e-07 1.3616973e-06 9.9999630e-01 1.3933618e-06], sampled 0.8283335557402784
[2019-03-24 10:04:58,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:04:58,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.24101012666667, 102.5664349766667, 1.0, 2.0, 0.4425921214981948, 1.0, 2.0, 0.4425921214981948, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1008998.565598094, 1008998.565598094, 218201.866364034]
[2019-03-24 10:04:58,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:04:58,138] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.0358232e-07 4.2833560e-07 1.8323443e-06 9.9999511e-01 1.9223364e-06], sampled 0.3450489556000427
[2019-03-24 10:05:06,021] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:05:06,022] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.49893085833333, 63.16383099833333, 1.0, 2.0, 0.1994070118224704, 1.0, 2.0, 0.1994070118224704, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489668.1574428905, 489668.1574428909, 159663.8774900074]
[2019-03-24 10:05:06,022] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:05:06,025] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.7476236e-07 4.2088413e-07 1.7986732e-06 9.9999523e-01 1.8353807e-06], sampled 0.17646125917652478
[2019-03-24 10:05:23,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01101427], dtype=float32), 0.011086254]
[2019-03-24 10:05:23,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.24334057833333, 71.32244015666667, 1.0, 2.0, 0.173538166090372, 1.0, 2.0, 0.173538166090372, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 431815.6202406628, 431815.6202406633, 154463.0688023121]
[2019-03-24 10:05:23,055] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:05:23,057] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.8730728e-07 3.6132403e-07 1.5381561e-06 9.9999583e-01 1.6897610e-06], sampled 0.37677071772741255
[2019-03-24 10:05:36,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 10:05:36,742] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 10:05:36,945] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0917 2668496507.7118 68.0000
[2019-03-24 10:05:37,009] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 10:05:37,019] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 10:05:38,037] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2400000, evaluation results [2400000.0, 7523.091712791175, 2668496507.711827, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 10:05:40,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.06888145e-07 3.31897837e-07 3.77863362e-05 9.99958277e-01
 3.43561442e-06], sum to 1.0000
[2019-03-24 10:05:40,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-24 10:05:40,215] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.96666666666667, 30.66666666666667, 1.0, 2.0, 0.1852636010985432, 1.0, 2.0, 0.1852636010985432, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459376.6091422516, 459376.6091422516, 156849.4435876873], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2488800.0000, 
sim time next is 2489400.0000, 
raw observation next is [30.75, 31.0, 1.0, 2.0, 0.1834393840007091, 1.0, 2.0, 0.1834393840007091, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455399.809717533, 455399.8097175334, 156483.6484448136], 
processed observation next is [1.0, 0.8260869565217391, 0.6944444444444444, 0.31, 1.0, 1.0, 0.027904028572272747, 1.0, 1.0, 0.027904028572272747, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16264278918483321, 0.16264278918483335, 0.30093009316310304], 
reward next is 0.6991, 
noisyNet noise sample is [array([-0.89910555], dtype=float32), -0.8405388]. 
=============================================
[2019-03-24 10:05:41,820] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.65291874e-06 1.27493695e-05 5.40578221e-05 9.99843955e-01
 8.75790574e-05], sum to 1.0000
[2019-03-24 10:05:41,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4353
[2019-03-24 10:05:41,837] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 46.5, 1.0, 2.0, 0.1900181903521907, 1.0, 2.0, 0.1900181903521907, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470344.0077944551, 470344.0077944551, 157818.580623086], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2502600.0000, 
sim time next is 2503200.0000, 
raw observation next is [26.9, 47.0, 1.0, 2.0, 0.1908761165771432, 1.0, 2.0, 0.1908761165771432, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472393.7393056062, 472393.7393056062, 157994.3030371584], 
processed observation next is [1.0, 1.0, 0.5518518518518518, 0.47, 1.0, 1.0, 0.0367572816394562, 1.0, 1.0, 0.0367572816394562, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1687120497520022, 0.1687120497520022, 0.3038351981483815], 
reward next is 0.6962, 
noisyNet noise sample is [array([0.8337839], dtype=float32), 1.292003]. 
=============================================
[2019-03-24 10:06:07,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9368235e-08 2.0621006e-07 1.7204211e-07 9.9999869e-01 8.4076157e-07], sum to 1.0000
[2019-03-24 10:06:07,820] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6395
[2019-03-24 10:06:07,823] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 93.5, 1.0, 2.0, 0.4045201290498001, 1.0, 2.0, 0.4045201290498001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922151.7890415391, 922151.7890415395, 207434.1552049026], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [24.93333333333333, 93.66666666666667, 1.0, 2.0, 0.3946332111978919, 1.0, 2.0, 0.3946332111978919, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 899600.1545005179, 899600.1545005183, 204720.6244639728], 
processed observation next is [1.0, 0.08695652173913043, 0.47901234567901224, 0.9366666666666668, 1.0, 1.0, 0.2793252514260618, 1.0, 1.0, 0.2793252514260618, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3212857694644707, 0.32128576946447085, 0.3936935085845631], 
reward next is 0.6063, 
noisyNet noise sample is [array([-0.5326087], dtype=float32), -1.9422041]. 
=============================================
[2019-03-24 10:06:09,684] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8485920e-07 1.5853223e-07 5.8858882e-06 9.9999297e-01 2.3438527e-07], sum to 1.0000
[2019-03-24 10:06:09,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0915
[2019-03-24 10:06:09,699] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.58333333333333, 86.5, 1.0, 2.0, 0.3942739127843165, 1.0, 2.0, 0.3942739127843165, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 898780.6227630893, 898780.6227630897, 204622.3871367814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2967000.0000, 
sim time next is 2967600.0000, 
raw observation next is [25.66666666666667, 87.0, 1.0, 2.0, 0.593185148598717, 1.0, 2.0, 0.593185148598717, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1352615.815144866, 1352615.815144866, 265705.3601908397], 
processed observation next is [1.0, 0.34782608695652173, 0.506172839506173, 0.87, 1.0, 1.0, 0.515696605474663, 1.0, 1.0, 0.515696605474663, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.48307707683745216, 0.48307707683745216, 0.5109718465208456], 
reward next is 0.4890, 
noisyNet noise sample is [array([0.51571614], dtype=float32), -0.23154745]. 
=============================================
[2019-03-24 10:06:10,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6674681e-06 5.3996773e-06 1.2915142e-06 9.9998569e-01 2.9367420e-06], sum to 1.0000
[2019-03-24 10:06:10,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8997
[2019-03-24 10:06:10,567] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.3822399253198356, 1.0, 2.0, 0.3822399253198356, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 871332.539489191, 871332.5394891915, 201369.0445587477], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3089400.0000, 
sim time next is 3090000.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.3934494612193414, 1.0, 2.0, 0.3934494612193414, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896900.1161765736, 896900.1161765736, 204399.9919527459], 
processed observation next is [1.0, 0.782608695652174, 0.6543209876543211, 0.7633333333333334, 1.0, 1.0, 0.2779160252611207, 1.0, 1.0, 0.2779160252611207, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.320321470063062, 0.320321470063062, 0.39307690760143443], 
reward next is 0.6069, 
noisyNet noise sample is [array([-0.04856696], dtype=float32), 0.97164536]. 
=============================================
[2019-03-24 10:06:10,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.36009 ]
 [60.825447]
 [60.66937 ]
 [61.793167]
 [61.58909 ]], R is [[61.51041412]
 [61.50806046]
 [61.50796127]
 [61.51011658]
 [61.51600266]].
[2019-03-24 10:06:14,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1253037e-07 2.9726735e-07 2.6477659e-07 9.9997818e-01 2.0944573e-05], sum to 1.0000
[2019-03-24 10:06:14,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2575
[2019-03-24 10:06:14,122] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.96666666666667, 93.83333333333334, 1.0, 2.0, 0.3873176406646501, 1.0, 2.0, 0.3873176406646501, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 882914.0798004589, 882914.0798004592, 202734.6403551589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3034200.0000, 
sim time next is 3034800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3811380022705572, 1.0, 2.0, 0.3811380022705572, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 868819.2341939263, 868819.2341939267, 201071.4889584866], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2632595265125681, 1.0, 1.0, 0.2632595265125681, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31029258364068796, 0.3102925836406881, 0.3866759403047819], 
reward next is 0.6133, 
noisyNet noise sample is [array([0.07297029], dtype=float32), -0.98156554]. 
=============================================
[2019-03-24 10:06:29,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6650175e-07 2.4486519e-07 1.0600206e-06 9.9994373e-01 5.4540113e-05], sum to 1.0000
[2019-03-24 10:06:29,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-24 10:06:29,793] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.05, 76.0, 1.0, 2.0, 0.3416951631891526, 1.0, 2.0, 0.3416951631891526, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778862.0303715111, 778862.0303715111, 190767.9380504884], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3335400.0000, 
sim time next is 3336000.0000, 
raw observation next is [28.36666666666667, 75.33333333333333, 1.0, 2.0, 0.3467236854779041, 1.0, 2.0, 0.3467236854779041, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 790329.9838583546, 790329.9838583551, 192051.778665797], 
processed observation next is [0.0, 0.6086956521739131, 0.606172839506173, 0.7533333333333333, 1.0, 1.0, 0.22229010175940966, 1.0, 1.0, 0.22229010175940966, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28226070852084095, 0.2822607085208411, 0.36933034358807115], 
reward next is 0.6307, 
noisyNet noise sample is [array([0.06435966], dtype=float32), -0.0092581855]. 
=============================================
[2019-03-24 10:06:29,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.333694]
 [62.39916 ]
 [62.461784]
 [62.49287 ]
 [62.535137]], R is [[62.29829788]
 [62.30845261]
 [62.32115936]
 [62.33601761]
 [62.3523407 ]].
[2019-03-24 10:06:36,348] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 10:06:36,355] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:06:36,358] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:06:36,358] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:06:36,359] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:06:36,362] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:06:36,363] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:06:36,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:06:36,365] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:06:36,365] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:06:36,366] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:06:36,388] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 10:06:36,425] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 10:06:36,426] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 10:06:36,482] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 10:06:36,512] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 10:06:38,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01111014], dtype=float32), 0.011169784]
[2019-03-24 10:06:38,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.6, 39.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 329449.3242215103, 329449.3242215108, 120310.1692593973]
[2019-03-24 10:06:38,276] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:06:38,279] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3115440e-05 8.4508856e-06 3.8044131e-05 9.9980336e-01 1.3705484e-04], sampled 0.6533591413892144
[2019-03-24 10:07:37,028] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01111014], dtype=float32), 0.011169784]
[2019-03-24 10:07:37,031] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.79264435, 71.02335306, 1.0, 2.0, 0.4456843598694309, 1.0, 2.0, 0.4456843598694309, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1021843.878901304, 1021843.878901304, 219374.6695497559]
[2019-03-24 10:07:37,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:07:37,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6166973e-06 2.1603332e-06 1.1531114e-05 9.9993312e-01 4.9550526e-05], sampled 0.38802788671171895
[2019-03-24 10:07:39,933] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01111014], dtype=float32), 0.011169784]
[2019-03-24 10:07:39,934] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.58333333333333, 76.66666666666667, 1.0, 2.0, 0.3280248257141691, 1.0, 2.0, 0.3280248257141691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747686.5826927198, 747686.5826927202, 187322.2440259213]
[2019-03-24 10:07:39,934] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:07:39,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8130721e-06 1.0639429e-06 6.0399152e-06 9.9996161e-01 2.9416819e-05], sampled 0.549643986083792
[2019-03-24 10:08:23,170] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01111014], dtype=float32), 0.011169784]
[2019-03-24 10:08:23,171] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.46666666666667, 79.66666666666667, 1.0, 2.0, 0.7200306394746657, 1.0, 2.0, 0.7200306394746657, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1642157.268787257, 1642157.268787257, 311817.8476820512]
[2019-03-24 10:08:23,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:08:23,179] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7186057e-06 3.2896235e-06 1.7963022e-05 9.9990404e-01 6.8877627e-05], sampled 0.48428357055082627
[2019-03-24 10:08:35,620] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01111014], dtype=float32), 0.011169784]
[2019-03-24 10:08:35,621] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.39748819666666, 85.61053053333333, 1.0, 2.0, 0.1882858925772416, 1.0, 2.0, 0.1882858925772416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466642.1456380722, 466642.1456380726, 157476.4782310738]
[2019-03-24 10:08:35,623] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:08:35,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6364449e-06 9.4520863e-07 5.3600197e-06 9.9996412e-01 2.7843149e-05], sampled 0.0770809931259624
[2019-03-24 10:08:45,057] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 10:08:45,654] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3459 2668541672.7745 68.0000
[2019-03-24 10:08:45,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 10:08:45,884] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438854835.5905 34.0000
[2019-03-24 10:08:45,963] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.1128 2410788069.1770 22.0000
[2019-03-24 10:08:46,985] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2425000, evaluation results [2425000.0, 7522.3458632473075, 2668541672.7745423, 68.0, 7121.435945869477, 2438854835.590539, 34.0, 7796.112818523811, 2410788069.1770186, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 10:08:49,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9148915e-04 3.6939280e-05 5.3253472e-05 9.9631125e-01 3.3069840e-03], sum to 1.0000
[2019-03-24 10:08:49,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2649
[2019-03-24 10:08:49,846] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3322145073904937, 1.0, 2.0, 0.3322145073904937, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757241.0914997556, 757241.0914997556, 188371.2343045915], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3369600.0000, 
sim time next is 3370200.0000, 
raw observation next is [24.88333333333334, 93.83333333333334, 1.0, 2.0, 0.3313089646804921, 1.0, 2.0, 0.3313089646804921, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755176.0042845055, 755176.004284506, 188143.8815306267], 
processed observation next is [1.0, 0.0, 0.47716049382716075, 0.9383333333333335, 1.0, 1.0, 0.2039392436672525, 1.0, 1.0, 0.2039392436672525, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2697057158158948, 0.269705715815895, 0.36181515678966675], 
reward next is 0.6382, 
noisyNet noise sample is [array([-0.5448747], dtype=float32), 0.26577818]. 
=============================================
[2019-03-24 10:08:51,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6974637e-04 1.6253884e-06 4.6416945e-04 9.9907982e-01 2.8456358e-04], sum to 1.0000
[2019-03-24 10:08:51,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-24 10:08:51,068] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.2887832654325788, 1.0, 2.0, 0.2887832654325788, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672755.4882775279, 672755.4882775279, 178492.5452640842], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3567600.0000, 
sim time next is 3568200.0000, 
raw observation next is [22.81666666666667, 93.83333333333334, 1.0, 2.0, 0.3089639826514253, 1.0, 2.0, 0.3089639826514253, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721317.0281027565, 721317.028102757, 183434.8166537475], 
processed observation next is [1.0, 0.30434782608695654, 0.4006172839506174, 0.9383333333333335, 1.0, 1.0, 0.1773380745850301, 1.0, 1.0, 0.1773380745850301, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.257613224322413, 0.2576132243224132, 0.35275926279566827], 
reward next is 0.6472, 
noisyNet noise sample is [array([-1.4693938], dtype=float32), 1.0820292]. 
=============================================
[2019-03-24 10:08:54,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1159294e-07 1.0616537e-06 6.8622080e-06 9.9992967e-01 6.1574268e-05], sum to 1.0000
[2019-03-24 10:08:54,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4803
[2019-03-24 10:08:54,242] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 94.5, 1.0, 2.0, 0.2863310628053812, 1.0, 2.0, 0.2863310628053812, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 659498.7813577587, 659498.7813577591, 177555.5308125737], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [23.33333333333333, 96.33333333333333, 1.0, 2.0, 0.2899055637100602, 1.0, 2.0, 0.2899055637100602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 666760.5378339073, 666760.5378339078, 178354.646370663], 
processed observation next is [1.0, 0.9130434782608695, 0.4197530864197529, 0.9633333333333333, 1.0, 1.0, 0.15464948060721453, 1.0, 1.0, 0.15464948060721453, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23812876351210974, 0.2381287635121099, 0.34298970455896727], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.5986054], dtype=float32), -0.256383]. 
=============================================
[2019-03-24 10:08:55,454] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6894701e-08 6.1932388e-09 4.6726868e-07 9.9999928e-01 2.2879894e-07], sum to 1.0000
[2019-03-24 10:08:55,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9823
[2019-03-24 10:08:55,473] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.55, 80.5, 1.0, 2.0, 0.2784482330397165, 1.0, 2.0, 0.2784482330397165, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 649469.9957949023, 649469.9957949028, 176087.8676028729], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3537000.0000, 
sim time next is 3537600.0000, 
raw observation next is [23.73333333333333, 81.0, 1.0, 2.0, 0.2601199227878724, 1.0, 2.0, 0.2601199227878724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 615309.7597092709, 615309.7597092714, 172229.1947664591], 
processed observation next is [1.0, 0.9565217391304348, 0.4345679012345678, 0.81, 1.0, 1.0, 0.11919038427127665, 1.0, 1.0, 0.11919038427127665, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2197534856104539, 0.21975348561045405, 0.3312099899354983], 
reward next is 0.6688, 
noisyNet noise sample is [array([0.671672], dtype=float32), -1.7505]. 
=============================================
[2019-03-24 10:08:57,816] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0111556e-06 1.9607592e-07 1.6265578e-05 9.9989057e-01 9.0939880e-05], sum to 1.0000
[2019-03-24 10:08:57,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2442
[2019-03-24 10:08:57,828] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.03333333333333, 86.83333333333334, 1.0, 2.0, 0.2450329268760037, 1.0, 2.0, 0.2450329268760037, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 581787.1476675952, 581787.1476675957, 168903.7249774375], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3563400.0000, 
sim time next is 3564000.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2498001451354815, 1.0, 2.0, 0.2498001451354815, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590328.7910598944, 590328.7910598948, 169858.96575243], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.89, 1.0, 1.0, 0.10690493468509701, 1.0, 1.0, 0.10690493468509701, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21083171109281942, 0.2108317110928196, 0.32665185721621154], 
reward next is 0.6733, 
noisyNet noise sample is [array([-2.1029675], dtype=float32), 0.3916942]. 
=============================================
[2019-03-24 10:08:57,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.236496]
 [57.20433 ]
 [57.14512 ]
 [57.18712 ]
 [57.389065]], R is [[57.18458557]
 [57.28792572]
 [57.39227295]
 [57.49698257]
 [57.60112381]].
[2019-03-24 10:08:59,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1762730e-06 3.8216076e-05 6.2956009e-05 9.9987829e-01 1.8333896e-05], sum to 1.0000
[2019-03-24 10:08:59,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0328
[2019-03-24 10:08:59,058] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.7, 82.0, 1.0, 2.0, 0.5252358094607454, 1.0, 2.0, 0.5252358094607454, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1232686.10157116, 1232686.101571161, 244909.3534079141], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3582000.0000, 
sim time next is 3582600.0000, 
raw observation next is [23.75, 82.16666666666667, 1.0, 2.0, 0.5913363534050208, 1.0, 2.0, 0.5913363534050208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1383804.394235534, 1383804.394235535, 266739.1181172994], 
processed observation next is [1.0, 0.4782608695652174, 0.4351851851851852, 0.8216666666666668, 1.0, 1.0, 0.5134956588155009, 1.0, 1.0, 0.5134956588155009, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49421585508411925, 0.49421585508411964, 0.5129598425332681], 
reward next is 0.4870, 
noisyNet noise sample is [array([-1.8302263], dtype=float32), 1.2937632]. 
=============================================
[2019-03-24 10:09:05,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8546125e-06 2.2618007e-05 2.7684652e-04 9.9967754e-01 1.3058292e-05], sum to 1.0000
[2019-03-24 10:09:05,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4282
[2019-03-24 10:09:05,257] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7192349027023082, 1.0, 2.0, 0.7192349027023082, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1640340.784198347, 1640340.784198347, 311512.020842235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3683400.0000, 
sim time next is 3684000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7875316965399088, 1.0, 2.0, 0.7875316965399088, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1796260.151588602, 1796260.151588602, 338630.0698863224], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7470615434998915, 1.0, 1.0, 0.7470615434998915, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.641521482710215, 0.641521482710215, 0.6512116728583124], 
reward next is 0.3488, 
noisyNet noise sample is [array([0.3410258], dtype=float32), 1.3647305]. 
=============================================
[2019-03-24 10:09:05,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.181572]
 [57.508186]
 [56.93547 ]
 [56.74277 ]
 [56.60859 ]], R is [[58.02630234]
 [57.84698105]
 [57.62932587]
 [57.35366821]
 [57.10077286]].
[2019-03-24 10:09:08,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4129300e-05 2.9970977e-07 1.6265120e-06 9.9997354e-01 4.1332225e-07], sum to 1.0000
[2019-03-24 10:09:08,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2967
[2019-03-24 10:09:08,043] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.3691037430419354, 1.0, 2.0, 0.3691037430419354, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 841371.6040876319, 841371.6040876324, 197871.4980791949], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3891000.0000, 
sim time next is 3891600.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.3693180672629428, 1.0, 2.0, 0.3693180672629428, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 841860.4242443049, 841860.4242443054, 197928.0662453359], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.94, 1.0, 1.0, 0.24918817531302714, 1.0, 1.0, 0.24918817531302714, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3006644372301089, 0.30066443723010905, 0.380630896625646], 
reward next is 0.6194, 
noisyNet noise sample is [array([0.81685597], dtype=float32), 0.6379903]. 
=============================================
[2019-03-24 10:09:13,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0551454e-05 2.0500434e-05 7.3144707e-05 9.9976593e-01 6.9861759e-05], sum to 1.0000
[2019-03-24 10:09:13,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-24 10:09:13,845] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4059484431835755, 1.0, 2.0, 0.4059484431835755, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925409.7670324064, 925409.7670324064, 207831.1930885671], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3934800.0000, 
sim time next is 3935400.0000, 
raw observation next is [30.93333333333334, 69.5, 1.0, 2.0, 0.3899962278663525, 1.0, 2.0, 0.3899962278663525, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 889023.6234826528, 889023.6234826533, 203461.6842369004], 
processed observation next is [0.0, 0.5652173913043478, 0.7012345679012348, 0.695, 1.0, 1.0, 0.2738050331742292, 1.0, 1.0, 0.2738050331742292, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3175084369580903, 0.31750843695809045, 0.3912724696863469], 
reward next is 0.6087, 
noisyNet noise sample is [array([-0.33312565], dtype=float32), 0.98196197]. 
=============================================
[2019-03-24 10:09:31,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0943306e-08 3.0731323e-07 8.2063245e-08 9.9999928e-01 1.8067598e-07], sum to 1.0000
[2019-03-24 10:09:31,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2874
[2019-03-24 10:09:31,283] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.75, 96.5, 1.0, 2.0, 0.224336966837113, 1.0, 2.0, 0.224336966837113, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 542351.2715263808, 542351.2715263813, 164725.9257744343], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4153800.0000, 
sim time next is 4154400.0000, 
raw observation next is [20.7, 97.0, 1.0, 2.0, 0.224002714086155, 1.0, 2.0, 0.224002714086155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541472.8789749192, 541472.8789749192, 164650.5087882211], 
processed observation next is [1.0, 0.08695652173913043, 0.3222222222222222, 0.97, 1.0, 1.0, 0.07619370724542261, 1.0, 1.0, 0.07619370724542261, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19338317106247113, 0.19338317106247113, 0.31663559382350215], 
reward next is 0.6834, 
noisyNet noise sample is [array([-1.0948828], dtype=float32), -0.050693497]. 
=============================================
[2019-03-24 10:09:37,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4793698e-06 1.0657954e-05 4.6911504e-05 9.9991548e-01 2.3453145e-05], sum to 1.0000
[2019-03-24 10:09:37,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3653
[2019-03-24 10:09:37,896] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.73333333333333, 82.66666666666667, 1.0, 2.0, 0.2838549630283366, 1.0, 2.0, 0.2838549630283366, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657836.8227726655, 657836.822772666, 177164.8901016339], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4324800.0000, 
sim time next is 4325400.0000, 
raw observation next is [24.6, 82.5, 1.0, 2.0, 0.2794879863299413, 1.0, 2.0, 0.2794879863299413, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 649775.0505550455, 649775.050555046, 176234.6706427149], 
processed observation next is [1.0, 0.043478260869565216, 0.46666666666666673, 0.825, 1.0, 1.0, 0.14224760277373966, 1.0, 1.0, 0.14224760277373966, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2320625180553734, 0.23206251805537356, 0.3389128281590671], 
reward next is 0.6611, 
noisyNet noise sample is [array([1.6858708], dtype=float32), 1.1711899]. 
=============================================
[2019-03-24 10:09:45,104] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 10:09:45,105] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:09:45,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:09:45,106] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:09:45,108] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:09:45,108] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:09:45,109] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:09:45,110] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:09:45,112] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:09:45,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:09:45,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:09:45,136] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 10:09:45,170] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 10:09:45,207] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 10:09:45,246] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 10:09:45,278] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 10:10:15,804] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:15,807] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.00786868, 82.07189282, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 366234.4888408709, 366234.4888408713, 145842.6057053651]
[2019-03-24 10:10:15,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:10:15,811] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4131965e-06 2.1298724e-06 9.5383093e-06 9.9992728e-01 5.7522164e-05], sampled 0.9197231053313639
[2019-03-24 10:10:24,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:24,068] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.6, 96.0, 1.0, 2.0, 0.2410458993504463, 1.0, 2.0, 0.2410458993504463, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574555.7368010028, 574555.7368010032, 168105.1151612748]
[2019-03-24 10:10:24,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:10:24,072] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.3940082e-06 2.0964630e-06 9.4385696e-06 9.9992871e-01 5.6274526e-05], sampled 0.5159889356980124
[2019-03-24 10:10:26,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:26,022] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.55, 23.16666666666667, 1.0, 2.0, 0.6191607312459921, 1.0, 2.0, 0.6191607312459921, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1497624.810475033, 1497624.810475033, 278360.5840976774]
[2019-03-24 10:10:26,022] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:10:26,026] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.7390739e-06 6.0817711e-06 2.6094747e-05 9.9983525e-01 1.2278963e-04], sampled 0.7008595639955637
[2019-03-24 10:10:37,027] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:37,028] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.61366369333333, 46.16992489666666, 1.0, 2.0, 0.3769197758411015, 1.0, 2.0, 0.3769197758411015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 859198.2294397667, 859198.2294397672, 199943.6752907596]
[2019-03-24 10:10:37,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:10:37,032] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.4605486e-06 2.7657613e-06 1.2317742e-05 9.9991250e-01 6.7983688e-05], sampled 0.015052899366402861
[2019-03-24 10:10:39,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:39,700] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.3, 87.0, 1.0, 2.0, 0.2873547225929036, 1.0, 2.0, 0.2873547225929036, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664117.8870354333, 664117.8870354338, 177905.9078806553]
[2019-03-24 10:10:39,700] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:10:39,702] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3485704e-06 1.4576434e-06 6.7652281e-06 9.9994719e-01 4.2364332e-05], sampled 0.48188908749515136
[2019-03-24 10:10:44,586] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:10:44,587] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.12219746, 87.167966275, 1.0, 2.0, 0.278632522903568, 1.0, 2.0, 0.278632522903568, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645616.7603174953, 645616.7603174953, 175932.7029085983]
[2019-03-24 10:10:44,587] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:10:44,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.1415664e-06 3.3015410e-06 1.4403180e-05 9.9990010e-01 7.6976939e-05], sampled 0.4877269263530727
[2019-03-24 10:11:05,146] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01104121], dtype=float32), 0.011175193]
[2019-03-24 10:11:05,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.1, 77.0, 1.0, 2.0, 0.2152382589697783, 1.0, 2.0, 0.2152382589697783, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521905.4560395191, 521905.4560395196, 162813.3716325612]
[2019-03-24 10:11:05,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:11:05,151] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4329069e-06 2.1534663e-06 9.6448830e-06 9.9992716e-01 5.7575009e-05], sampled 0.6189338368036015
[2019-03-24 10:11:54,411] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 10:11:54,540] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.4677 2668590850.8620 68.0000
[2019-03-24 10:11:54,638] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 10:11:54,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6904.6357 2495480493.1846 47.0000
[2019-03-24 10:11:54,735] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 10:11:55,751] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2450000, evaluation results [2450000.0, 7522.46772784887, 2668590850.8619647, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6904.635745735533, 2495480493.1845503, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 10:11:58,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0315204e-05 7.2026662e-05 4.5059355e-06 9.9607557e-01 3.7875185e-03], sum to 1.0000
[2019-03-24 10:11:58,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-24 10:11:58,938] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333333, 61.5, 1.0, 2.0, 0.8732977361546002, 1.0, 2.0, 0.8732977361546002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1992099.799036626, 1992099.799036626, 374972.8112851943], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4363800.0000, 
sim time next is 4364400.0000, 
raw observation next is [30.66666666666667, 61.0, 1.0, 2.0, 0.7128106850887571, 1.0, 2.0, 0.7128106850887571, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1625675.903729609, 1625675.90372961, 309043.4819980991], 
processed observation next is [1.0, 0.5217391304347826, 0.6913580246913582, 0.61, 1.0, 1.0, 0.6581079584389965, 1.0, 1.0, 0.6581079584389965, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5805985370462889, 0.5805985370462893, 0.5943143884578829], 
reward next is 0.4057, 
noisyNet noise sample is [array([-1.1611435], dtype=float32), 1.8455697]. 
=============================================
[2019-03-24 10:12:01,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9944122e-05 5.0063513e-06 7.2339491e-05 9.9930620e-01 5.8648858e-04], sum to 1.0000
[2019-03-24 10:12:01,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1457
[2019-03-24 10:12:01,854] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.16666666666666, 98.66666666666666, 1.0, 2.0, 0.2875311737954206, 1.0, 2.0, 0.2875311737954206, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659419.973529387, 659419.973529387, 177700.0343940369], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4772400.0000, 
sim time next is 4773000.0000, 
raw observation next is [23.08333333333333, 99.33333333333334, 1.0, 2.0, 0.2872429769376371, 1.0, 2.0, 0.2872429769376371, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658822.6492160854, 658822.6492160854, 177635.13819377], 
processed observation next is [1.0, 0.21739130434782608, 0.41049382716049365, 0.9933333333333334, 1.0, 1.0, 0.151479734449568, 1.0, 1.0, 0.151479734449568, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23529380329145907, 0.23529380329145907, 0.3416060349880192], 
reward next is 0.6584, 
noisyNet noise sample is [array([-0.05210831], dtype=float32), -0.087215796]. 
=============================================
[2019-03-24 10:12:01,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.141994]
 [52.951546]
 [52.87589 ]
 [52.90096 ]
 [52.57233 ]], R is [[53.14456558]
 [53.27138901]
 [53.39606094]
 [53.51861191]
 [53.63389969]].
[2019-03-24 10:12:05,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5634476e-08 2.0678235e-07 7.4219415e-08 9.9998915e-01 1.0527540e-05], sum to 1.0000
[2019-03-24 10:12:05,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0985
[2019-03-24 10:12:05,280] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 95.83333333333334, 1.0, 2.0, 0.3056219104444179, 1.0, 2.0, 0.3056219104444179, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697144.6725511794, 697144.6725511798, 181842.5090971123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4553400.0000, 
sim time next is 4554000.0000, 
raw observation next is [23.9, 95.0, 1.0, 2.0, 0.30647939782118, 1.0, 2.0, 0.30647939782118, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698554.4250720282, 698554.4250720287, 182022.6550756916], 
processed observation next is [0.0, 0.7391304347826086, 0.4407407407407407, 0.95, 1.0, 1.0, 0.17438023550140477, 1.0, 1.0, 0.17438023550140477, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24948372324001006, 0.24948372324001022, 0.3500435674532531], 
reward next is 0.6500, 
noisyNet noise sample is [array([-0.5114178], dtype=float32), -0.29256073]. 
=============================================
[2019-03-24 10:12:05,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.8603  ]
 [62.89724 ]
 [62.886894]
 [62.898006]
 [63.008415]], R is [[62.85721207]
 [62.8789444 ]
 [62.90122604]
 [62.924366  ]
 [62.9480896 ]].
[2019-03-24 10:12:08,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2326847e-05 1.2400567e-05 7.0210604e-05 9.9942255e-01 4.5255068e-04], sum to 1.0000
[2019-03-24 10:12:08,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9749
[2019-03-24 10:12:08,717] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 83.0, 1.0, 2.0, 0.3418214164151849, 1.0, 2.0, 0.3418214164151849, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 779149.9590076812, 779149.9590076817, 190799.9332721664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4649400.0000, 
sim time next is 4650000.0000, 
raw observation next is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.3386358100655258, 1.0, 2.0, 0.3386358100655258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771885.0110457757, 771885.0110457757, 189991.0173602237], 
processed observation next is [1.0, 0.8260869565217391, 0.545679012345679, 0.8266666666666667, 1.0, 1.0, 0.21266167864943547, 1.0, 1.0, 0.21266167864943547, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2756732182306342, 0.2756732182306342, 0.36536734107735325], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.4597403], dtype=float32), -0.23217826]. 
=============================================
[2019-03-24 10:12:08,738] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[56.317303]
 [56.42803 ]
 [56.452923]
 [56.2513  ]
 [56.362972]], R is [[56.44554901]
 [56.5141716 ]
 [56.58084106]
 [56.64573669]
 [56.70928574]].
[2019-03-24 10:12:11,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2183172e-05 5.3773482e-07 7.3755225e-05 9.9974960e-01 1.5382658e-04], sum to 1.0000
[2019-03-24 10:12:11,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2825
[2019-03-24 10:12:11,869] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 90.66666666666667, 1.0, 2.0, 0.3800754796808357, 1.0, 2.0, 0.3800754796808357, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866395.8026737487, 866395.8026737487, 200788.3319945066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4824600.0000, 
sim time next is 4825200.0000, 
raw observation next is [26.8, 91.33333333333334, 1.0, 2.0, 0.3762761303733329, 1.0, 2.0, 0.3762761303733329, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 857730.2021988316, 857730.2021988321, 199773.6357980096], 
processed observation next is [1.0, 0.8695652173913043, 0.5481481481481482, 0.9133333333333334, 1.0, 1.0, 0.2574715837777773, 1.0, 1.0, 0.2574715837777773, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30633221507101127, 0.30633221507101144, 0.3841800688423262], 
reward next is 0.6158, 
noisyNet noise sample is [array([1.5241343], dtype=float32), -1.0655414]. 
=============================================
[2019-03-24 10:12:23,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0933840e-04 4.7663216e-05 6.8162599e-06 9.9939036e-01 4.5902096e-05], sum to 1.0000
[2019-03-24 10:12:23,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-24 10:12:23,907] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3392633817154841, 1.0, 2.0, 0.3392633817154841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773316.2167658072, 773316.2167658072, 190150.2369690767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4741200.0000, 
sim time next is 4741800.0000, 
raw observation next is [25.83333333333334, 89.83333333333334, 1.0, 2.0, 0.3389636311912446, 1.0, 2.0, 0.3389636311912446, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 772632.6217147607, 772632.6217147611, 190074.2046475765], 
processed observation next is [1.0, 0.9130434782608695, 0.5123456790123458, 0.8983333333333334, 1.0, 1.0, 0.21305194189433885, 1.0, 1.0, 0.21305194189433885, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27594022204098595, 0.2759402220409861, 0.3655273166299548], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.08859482], dtype=float32), 1.0999027]. 
=============================================
[2019-03-24 10:12:25,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00850116e-07 7.88480463e-08 3.05010235e-06 9.99946713e-01
 5.00627684e-05], sum to 1.0000
[2019-03-24 10:12:25,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7774
[2019-03-24 10:12:25,336] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.75, 87.0, 1.0, 2.0, 0.3183499228477781, 1.0, 2.0, 0.3183499228477781, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725623.5608755087, 725623.5608755087, 184922.7371625954], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5041800.0000, 
sim time next is 5042400.0000, 
raw observation next is [25.83333333333334, 87.66666666666666, 1.0, 2.0, 0.3232689592127602, 1.0, 2.0, 0.3232689592127602, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736841.0418545146, 736841.0418545146, 186138.6959068465], 
processed observation next is [0.0, 0.34782608695652173, 0.5123456790123458, 0.8766666666666666, 1.0, 1.0, 0.1943678085866193, 1.0, 1.0, 0.1943678085866193, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26315751494804096, 0.26315751494804096, 0.35795903059008943], 
reward next is 0.6420, 
noisyNet noise sample is [array([0.21191582], dtype=float32), 2.310441]. 
=============================================
[2019-03-24 10:12:26,728] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7268305e-04 6.4151223e-05 1.1324439e-04 9.9846470e-01 8.8524300e-04], sum to 1.0000
[2019-03-24 10:12:26,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3778
[2019-03-24 10:12:26,750] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 77.66666666666667, 1.0, 2.0, 0.3244600800094575, 1.0, 2.0, 0.3244600800094575, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 739557.3251521339, 739557.3251521344, 186434.1010241814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4929600.0000, 
sim time next is 4930200.0000, 
raw observation next is [26.95, 77.0, 1.0, 2.0, 0.3202225151799992, 1.0, 2.0, 0.3202225151799992, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 729893.8431264723, 729893.8431264728, 185384.3773107829], 
processed observation next is [1.0, 0.043478260869565216, 0.5537037037037037, 0.77, 1.0, 1.0, 0.19074108949999907, 1.0, 1.0, 0.19074108949999907, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2606763725451687, 0.26067637254516884, 0.35650841790535176], 
reward next is 0.6435, 
noisyNet noise sample is [array([0.8849543], dtype=float32), -0.21699375]. 
=============================================
[2019-03-24 10:12:27,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8012421e-05 2.5346322e-05 2.2180926e-05 9.9957782e-01 3.0655556e-04], sum to 1.0000
[2019-03-24 10:12:27,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1633
[2019-03-24 10:12:27,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 92.66666666666666, 1.0, 2.0, 0.3239420805728452, 1.0, 2.0, 0.3239420805728452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738376.0556868068, 738376.0556868073, 186305.2886292103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [24.5, 92.33333333333333, 1.0, 2.0, 0.3199166434511415, 1.0, 2.0, 0.3199166434511415, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 729196.3279031969, 729196.3279031973, 185308.660253064], 
processed observation next is [1.0, 0.043478260869565216, 0.46296296296296297, 0.9233333333333333, 1.0, 1.0, 0.19037695648945419, 1.0, 1.0, 0.19037695648945419, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2604272599654275, 0.2604272599654276, 0.35636280817896926], 
reward next is 0.6436, 
noisyNet noise sample is [array([-0.533081], dtype=float32), -1.282047]. 
=============================================
[2019-03-24 10:12:30,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8997671e-05 4.9507648e-06 3.0110091e-06 9.9971646e-01 2.5646048e-04], sum to 1.0000
[2019-03-24 10:12:30,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-24 10:12:30,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3125206.820137525 W.
[2019-03-24 10:12:30,099] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 85.66666666666666, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9515344554570703, 1.0, 1.0, 0.9977734948820727, 7.223294659383785, 6.9112, 121.94756008, 3125206.820137525, 2965358.25478895, 552651.8413457456], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4894800.0000, 
sim time next is 4895400.0000, 
raw observation next is [30.16666666666666, 87.33333333333334, 1.0, 2.0, 0.8454559393549071, 1.0, 2.0, 0.7360926316538883, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2519419.439796573, 2519419.439796573, 470613.5746960005], 
processed observation next is [1.0, 0.6521739130434783, 0.6728395061728393, 0.8733333333333334, 1.0, 1.0, 0.8160189754225085, 1.0, 1.0, 0.6858245614927241, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8997926570702046, 0.8997926570702046, 0.9050261051846163], 
reward next is 0.0950, 
noisyNet noise sample is [array([-1.6849477], dtype=float32), 0.21192124]. 
=============================================
[2019-03-24 10:12:36,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2751884e-06 7.1067620e-06 3.1032253e-06 9.9992156e-01 6.6843495e-05], sum to 1.0000
[2019-03-24 10:12:36,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1670
[2019-03-24 10:12:36,121] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.93333333333334, 83.33333333333334, 1.0, 2.0, 0.4110010271119452, 1.0, 2.0, 0.4110010271119452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 936934.7989679263, 936934.7989679268, 209233.6841585346], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5080800.0000, 
sim time next is 5081400.0000, 
raw observation next is [28.9, 83.0, 1.0, 2.0, 0.4124493216291961, 1.0, 2.0, 0.4124493216291961, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 940238.4159471225, 940238.415947123, 209637.2010467389], 
processed observation next is [0.0, 0.8260869565217391, 0.6259259259259259, 0.83, 1.0, 1.0, 0.3005349067014239, 1.0, 1.0, 0.3005349067014239, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33579943426682946, 0.3357994342668296, 0.4031484635514209], 
reward next is 0.5969, 
noisyNet noise sample is [array([1.5153092], dtype=float32), -0.30394295]. 
=============================================
[2019-03-24 10:12:37,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.71868191e-05 3.18369042e-04 1.18962416e-04 9.98789728e-01
 7.35841750e-04], sum to 1.0000
[2019-03-24 10:12:37,330] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9953
[2019-03-24 10:12:37,338] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 78.16666666666667, 1.0, 2.0, 0.8489831445941459, 1.0, 2.0, 0.8489831445941459, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1936575.081605278, 1936575.081605279, 364411.0169969274], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4981800.0000, 
sim time next is 4982400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.8829417659522513, 1.0, 2.0, 0.8829417659522513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2014123.828446277, 2014123.828446277, 379219.5844712092], 
processed observation next is [1.0, 0.6956521739130435, 0.5925925925925926, 0.79, 1.0, 1.0, 0.8606449594669658, 1.0, 1.0, 0.8606449594669658, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7193299387308132, 0.7193299387308132, 0.7292684316754023], 
reward next is 0.2707, 
noisyNet noise sample is [array([-0.00917935], dtype=float32), -0.93727595]. 
=============================================
[2019-03-24 10:12:37,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3043437e-05 4.7549815e-06 4.0745745e-06 9.9864990e-01 1.3282032e-03], sum to 1.0000
[2019-03-24 10:12:37,984] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9514
[2019-03-24 10:12:37,995] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.6, 69.0, 1.0, 2.0, 0.3870178137726626, 1.0, 2.0, 0.3870178137726626, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 882230.2128074856, 882230.2128074861, 202655.2739852465], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5060400.0000, 
sim time next is 5061000.0000, 
raw observation next is [30.75, 67.5, 1.0, 2.0, 0.3829509905613515, 1.0, 2.0, 0.3829509905613515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 872954.3667657389, 872954.3667657394, 201559.5432675509], 
processed observation next is [0.0, 0.5652173913043478, 0.6944444444444444, 0.675, 1.0, 1.0, 0.26541784590637085, 1.0, 1.0, 0.26541784590637085, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3117694167020496, 0.3117694167020498, 0.38761450628375177], 
reward next is 0.6124, 
noisyNet noise sample is [array([0.45374486], dtype=float32), -0.851998]. 
=============================================
[2019-03-24 10:12:38,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.222538]
 [63.19945 ]
 [63.208775]
 [63.150723]
 [63.181408]], R is [[63.23077011]
 [63.20874023]
 [63.18640518]
 [63.16559219]
 [63.13805008]].
[2019-03-24 10:12:42,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2706088e-08 1.4271106e-07 5.1470247e-06 9.9998927e-01 5.3633603e-06], sum to 1.0000
[2019-03-24 10:12:42,913] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9186
[2019-03-24 10:12:42,919] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.41666666666666, 75.83333333333334, 1.0, 2.0, 0.4011647863121802, 1.0, 2.0, 0.4011647863121802, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 914498.3221254242, 914498.3221254242, 206512.0930391365], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5141400.0000, 
sim time next is 5142000.0000, 
raw observation next is [30.53333333333333, 75.66666666666667, 1.0, 2.0, 0.3961483748254829, 1.0, 2.0, 0.3961483748254829, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 903056.1345354834, 903056.1345354839, 205136.9677792364], 
processed observation next is [0.0, 0.5217391304347826, 0.6864197530864197, 0.7566666666666667, 1.0, 1.0, 0.28112901764938436, 1.0, 1.0, 0.28112901764938436, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32252004804838696, 0.32252004804838713, 0.39449416880622384], 
reward next is 0.6055, 
noisyNet noise sample is [array([-0.45502758], dtype=float32), 0.34247294]. 
=============================================
[2019-03-24 10:12:42,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8890043e-08 5.2973610e-07 2.9511486e-07 9.9999893e-01 2.8285589e-07], sum to 1.0000
[2019-03-24 10:12:42,949] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.39455 ]
 [61.336147]
 [61.269943]
 [61.177853]
 [61.076653]], R is [[61.41615677]
 [61.40485382]
 [61.38507843]
 [61.36716843]
 [61.35107422]].
[2019-03-24 10:12:42,950] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1070
[2019-03-24 10:12:42,957] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.4174312507202846, 1.0, 2.0, 0.4174312507202846, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 951602.5016673493, 951602.5016673497, 211031.2971725271], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5079600.0000, 
sim time next is 5080200.0000, 
raw observation next is [28.96666666666667, 83.66666666666667, 1.0, 2.0, 0.4025812178222681, 1.0, 2.0, 0.4025812178222681, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 917729.1635830363, 917729.1635830367, 206901.8187305314], 
processed observation next is [0.0, 0.8260869565217391, 0.6283950617283951, 0.8366666666666667, 1.0, 1.0, 0.2887871640741287, 1.0, 1.0, 0.2887871640741287, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3277604155653701, 0.3277604155653703, 0.39788811294332965], 
reward next is 0.6021, 
noisyNet noise sample is [array([-0.5124278], dtype=float32), 0.3368803]. 
=============================================
[2019-03-24 10:12:49,594] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2282479e-04 2.8378148e-05 2.6555872e-04 9.9949801e-01 8.5206782e-05], sum to 1.0000
[2019-03-24 10:12:49,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6408
[2019-03-24 10:12:49,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.46666666666667, 86.33333333333334, 1.0, 2.0, 0.4965703717576076, 1.0, 2.0, 0.4965703717576076, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1159975.297945646, 1159975.297945646, 235610.4799811261], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5305200.0000, 
sim time next is 5305800.0000, 
raw observation next is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.5206052069175324, 1.0, 2.0, 0.5206052069175324, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1212841.122198404, 1212841.122198404, 243037.4201341642], 
processed observation next is [1.0, 0.391304347826087, 0.43086419753086447, 0.8566666666666667, 1.0, 1.0, 0.4292919129970624, 1.0, 1.0, 0.4292919129970624, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43315754364228715, 0.43315754364228715, 0.4673796541041619], 
reward next is 0.5326, 
noisyNet noise sample is [array([1.4001635], dtype=float32), -0.56547725]. 
=============================================
[2019-03-24 10:12:52,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8574544e-05 8.9833607e-05 4.3464627e-04 9.9924707e-01 1.8993087e-04], sum to 1.0000
[2019-03-24 10:12:52,136] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9620
[2019-03-24 10:12:52,141] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 79.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.29168048167733, 6.9112, 121.9243663570227, 2522273.230610647, 2327435.895723809, 443048.7996947719], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5583600.0000, 
sim time next is 5584200.0000, 
raw observation next is [28.38333333333333, 80.00000000000001, 1.0, 2.0, 0.9554566776139346, 1.0, 2.0, 0.9554566776139346, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.925813496907, 2179743.225709671, 2179743.225709671, 412179.6079859902], 
processed observation next is [1.0, 0.6521739130434783, 0.60679012345679, 0.8000000000000002, 1.0, 1.0, 0.9469722352546841, 1.0, 1.0, 0.9469722352546841, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094606077098707, 0.7784797234677397, 0.7784797234677397, 0.7926530922807503], 
reward next is 0.2073, 
noisyNet noise sample is [array([0.843526], dtype=float32), -0.42912415]. 
=============================================
[2019-03-24 10:12:52,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4798652e-04 5.0925788e-05 8.9246634e-05 9.9885178e-01 7.6001638e-04], sum to 1.0000
[2019-03-24 10:12:52,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-24 10:12:52,246] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 78.5, 1.0, 2.0, 0.6190965097875649, 1.0, 2.0, 0.6190965097875649, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1419728.303375789, 1419728.303375788, 275068.9096259772], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5311800.0000, 
sim time next is 5312400.0000, 
raw observation next is [25.5, 77.33333333333334, 1.0, 2.0, 0.5726286160999519, 1.0, 2.0, 0.5726286160999519, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1313498.316465993, 1313498.316465994, 259140.5221505067], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.7733333333333334, 1.0, 1.0, 0.49122454297613316, 1.0, 1.0, 0.49122454297613316, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4691065415949975, 0.4691065415949979, 0.49834715798174367], 
reward next is 0.5017, 
noisyNet noise sample is [array([-0.3452643], dtype=float32), -0.8273788]. 
=============================================
[2019-03-24 10:12:53,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8157220e-05 5.0584782e-05 8.7382832e-05 9.9878699e-01 1.0069810e-03], sum to 1.0000
[2019-03-24 10:12:53,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-24 10:12:53,136] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 67.0, 1.0, 2.0, 0.9423000184553904, 1.0, 2.0, 0.9423000184553904, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2149691.976507721, 2149691.976507722, 406063.4239689953], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5234400.0000, 
sim time next is 5235000.0000, 
raw observation next is [29.41666666666667, 68.16666666666667, 1.0, 2.0, 0.9214931451794184, 1.0, 2.0, 0.9214931451794184, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2102168.873504177, 2102168.873504177, 396514.8073600378], 
processed observation next is [1.0, 0.6086956521739131, 0.6450617283950619, 0.6816666666666668, 1.0, 1.0, 0.9065394585469266, 1.0, 1.0, 0.9065394585469266, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7507745976800633, 0.7507745976800633, 0.7625284756923804], 
reward next is 0.2375, 
noisyNet noise sample is [array([0.02890599], dtype=float32), -0.3608673]. 
=============================================
[2019-03-24 10:12:53,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[45.888885]
 [45.72169 ]
 [45.468723]
 [45.478348]
 [45.163433]], R is [[45.86066818]
 [45.62117004]
 [45.3737793 ]
 [45.12535858]
 [44.89947891]].
[2019-03-24 10:12:53,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7037581e-05 1.7146640e-04 1.0908139e-05 9.9906129e-01 7.3919358e-04], sum to 1.0000
[2019-03-24 10:12:53,312] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4392
[2019-03-24 10:12:53,319] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 82.66666666666666, 1.0, 2.0, 0.832566470944105, 1.0, 2.0, 0.832566470944105, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1899087.974403373, 1899087.974403374, 357396.1649375038], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5410200.0000, 
sim time next is 5410800.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.817001497526424, 1.0, 2.0, 0.817001497526424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1863547.158692209, 1863547.158692209, 350830.860929626], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.84, 1.0, 1.0, 0.7821446399124096, 1.0, 1.0, 0.7821446399124096, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6655525566757889, 0.6655525566757889, 0.6746747325569731], 
reward next is 0.3253, 
noisyNet noise sample is [array([0.5733531], dtype=float32), -0.48861748]. 
=============================================
[2019-03-24 10:12:53,925] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 10:12:53,926] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:12:53,926] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:12:53,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:12:53,929] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:12:53,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:12:53,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:12:53,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:12:53,934] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:12:53,935] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:12:53,937] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:12:53,963] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 10:12:53,996] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 10:12:54,031] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 10:12:54,032] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 10:12:54,104] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 10:13:16,321] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:13:16,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.75, 27.0, 1.0, 2.0, 0.2694259857836704, 1.0, 2.0, 0.2694259857836704, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 655178.1235360365, 655178.1235360369, 175043.1405972147]
[2019-03-24 10:13:16,328] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:13:16,330] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4082251e-06 1.3379895e-06 6.6177545e-06 9.9994767e-01 4.1908424e-05], sampled 0.38411714874612557
[2019-03-24 10:13:24,260] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:13:24,261] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.5, 91.0, 1.0, 2.0, 0.2018771352521541, 1.0, 2.0, 0.2018771352521541, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 495162.1750542413, 495162.1750542409, 160165.800127908]
[2019-03-24 10:13:24,261] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:13:24,263] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0013916e-06 5.3906263e-07 2.9140365e-06 9.9997365e-01 2.1846252e-05], sampled 0.5231449098637628
[2019-03-24 10:13:28,612] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:13:28,613] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.85, 93.0, 1.0, 2.0, 0.2144216302702095, 1.0, 2.0, 0.2144216302702095, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521047.2783759233, 521047.2783759237, 162677.649975192]
[2019-03-24 10:13:28,613] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:13:28,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4797549e-07 4.0176153e-07 2.2041281e-06 9.9997938e-01 1.7229280e-05], sampled 0.029842822043269046
[2019-03-24 10:14:30,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:14:30,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.5, 82.33333333333334, 1.0, 2.0, 0.5198838578215015, 1.0, 2.0, 0.5198838578215015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1185340.559388613, 1185340.559388613, 241600.4412721959]
[2019-03-24 10:14:30,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:14:30,277] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.9546147e-06 5.2189330e-06 2.2625411e-05 9.9985027e-01 1.1284776e-04], sampled 0.36403671193865306
[2019-03-24 10:14:32,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:14:32,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.23333333333333, 70.0, 1.0, 2.0, 0.267668324258318, 1.0, 2.0, 0.267668324258318, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626073.4126661815, 626073.4126661819, 173660.3816687487]
[2019-03-24 10:14:32,714] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:14:32,718] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0305059e-06 1.7518778e-06 8.3990508e-06 9.9993742e-01 4.9293445e-05], sampled 0.35389428290218217
[2019-03-24 10:14:45,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:14:45,478] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.18533925666667, 60.81002672000001, 1.0, 2.0, 0.2783359657116765, 1.0, 2.0, 0.2783359657116765, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 645561.1487572578, 645561.1487572583, 175893.0289233761]
[2019-03-24 10:14:45,481] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:14:45,484] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6066862e-06 1.4772510e-06 7.2580510e-06 9.9994433e-01 4.4370561e-05], sampled 0.5406679280134777
[2019-03-24 10:14:51,954] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:14:51,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.25, 85.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.432993916703701, 6.9112, 128.7666774432977, 2609565.616940181, 2327369.007291127, 444329.3836215184]
[2019-03-24 10:14:51,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:14:51,957] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.1217039e-06 2.8974023e-06 1.3233906e-05 9.9990523e-01 7.3553085e-05], sampled 0.5712162027172101
[2019-03-24 10:14:51,958] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2609565.616940181 W.
[2019-03-24 10:15:00,247] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01112578], dtype=float32), 0.01128003]
[2019-03-24 10:15:00,250] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.33333333333333, 90.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 299564.0057440161, 299564.0057440166, 132596.1069557433]
[2019-03-24 10:15:00,251] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:15:00,253] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0930324e-06 1.1894437e-06 5.8091628e-06 9.9995244e-01 3.8542697e-05], sampled 0.4379157268941838
[2019-03-24 10:15:02,612] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.3551 2495506955.2922 47.0000
[2019-03-24 10:15:02,812] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.7070 2438888990.1645 34.0000
[2019-03-24 10:15:03,008] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.5319 2668602203.2928 68.0000
[2019-03-24 10:15:03,148] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.9558 2465989904.6867 46.0000
[2019-03-24 10:15:03,324] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 10:15:04,346] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2475000, evaluation results [2475000.0, 7522.531879779782, 2668602203.2928214, 68.0, 7120.707004060854, 2438888990.1645417, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.355113076557, 2495506955.2921543, 47.0, 7478.955848051994, 2465989904.6866508, 46.0]
[2019-03-24 10:15:11,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0832098e-07 6.8521764e-08 2.4014906e-07 9.9999082e-01 7.9547008e-06], sum to 1.0000
[2019-03-24 10:15:11,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-24 10:15:11,469] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.51666666666667, 97.0, 1.0, 2.0, 0.2981673762652353, 1.0, 2.0, 0.2981673762652353, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681377.8228941287, 681377.8228941287, 180110.7812355197], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5622600.0000, 
sim time next is 5623200.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.297441198812347, 1.0, 2.0, 0.297441198812347, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679981.3399780886, 679981.3399780891, 179950.0770764914], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 1.0, 1.0, 0.16362047477660355, 1.0, 1.0, 0.16362047477660355, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2428504785636031, 0.24285047856360326, 0.34605784053171423], 
reward next is 0.6539, 
noisyNet noise sample is [array([0.07768404], dtype=float32), 0.42353508]. 
=============================================
[2019-03-24 10:15:18,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3913264e-05 1.7533291e-06 3.2472853e-05 9.9991012e-01 3.1687843e-05], sum to 1.0000
[2019-03-24 10:15:18,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6347
[2019-03-24 10:15:18,536] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 93.0, 1.0, 2.0, 0.370457638414843, 1.0, 2.0, 0.370457638414843, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 844459.5073928968, 844459.5073928968, 198228.3473364766], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5546400.0000, 
sim time next is 5547000.0000, 
raw observation next is [25.31666666666667, 93.0, 1.0, 2.0, 0.3651073866174274, 1.0, 2.0, 0.3651073866174274, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832256.9677400822, 832256.9677400826, 196818.8455033211], 
processed observation next is [1.0, 0.17391304347826086, 0.49320987654321, 0.93, 1.0, 1.0, 0.24417546025884218, 1.0, 1.0, 0.24417546025884218, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2972346313357436, 0.2972346313357438, 0.378497779814079], 
reward next is 0.6215, 
noisyNet noise sample is [array([1.039983], dtype=float32), 0.38121969]. 
=============================================
[2019-03-24 10:15:18,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[53.985962]
 [54.010124]
 [54.16539 ]
 [54.373264]
 [54.50576 ]], R is [[53.8636322 ]
 [53.94379044]
 [54.0195961 ]
 [54.09104156]
 [54.14399719]].
[2019-03-24 10:15:19,362] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1086739e-07 3.5203931e-07 6.5379527e-06 9.9998164e-01 1.1119407e-05], sum to 1.0000
[2019-03-24 10:15:19,373] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4832
[2019-03-24 10:15:19,383] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.28333333333333, 96.33333333333333, 1.0, 2.0, 0.3227668079140173, 1.0, 2.0, 0.3227668079140173, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735695.9172341208, 735695.9172341212, 186013.8885081918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5609400.0000, 
sim time next is 5610000.0000, 
raw observation next is [24.16666666666667, 96.66666666666666, 1.0, 2.0, 0.3203699722524447, 1.0, 2.0, 0.3203699722524447, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730230.1070320953, 730230.1070320953, 185420.7815514936], 
processed observation next is [1.0, 0.9565217391304348, 0.45061728395061745, 0.9666666666666666, 1.0, 1.0, 0.19091663363386271, 1.0, 1.0, 0.19091663363386271, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2607964667971769, 0.2607964667971769, 0.3565784260605646], 
reward next is 0.6434, 
noisyNet noise sample is [array([1.0604565], dtype=float32), -0.7649924]. 
=============================================
[2019-03-24 10:15:19,399] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.38617 ]
 [61.41442 ]
 [61.368713]
 [61.38759 ]
 [61.365788]], R is [[61.35279083]
 [61.38154221]
 [61.40887451]
 [61.43490982]
 [61.45990753]].
[2019-03-24 10:15:19,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6152165e-07 1.1937738e-07 2.3701030e-07 9.9999523e-01 4.1621543e-06], sum to 1.0000
[2019-03-24 10:15:19,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-24 10:15:19,506] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 77.66666666666667, 1.0, 2.0, 0.3545828964141424, 1.0, 2.0, 0.3545828964141424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808253.8963628258, 808253.8963628262, 194075.883963181], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5660400.0000, 
sim time next is 5661000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.3545664522469563, 1.0, 2.0, 0.3545664522469563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808216.3929473655, 808216.3929473655, 194071.6199658607], 
processed observation next is [0.0, 0.5217391304347826, 0.6074074074074074, 0.77, 1.0, 1.0, 0.2316267288654242, 1.0, 1.0, 0.2316267288654242, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28864871176691625, 0.28864871176691625, 0.37321465378050134], 
reward next is 0.6268, 
noisyNet noise sample is [array([-0.5910205], dtype=float32), 1.3747526]. 
=============================================
[2019-03-24 10:15:19,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.18447]
 [64.21299]
 [64.23134]
 [64.2595 ]
 [64.24961]], R is [[64.14221954]
 [64.12757111]
 [64.11338806]
 [64.09975433]
 [64.08679199]].
[2019-03-24 10:15:27,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4913980e-06 1.9823527e-07 2.0015488e-05 9.9997318e-01 1.0900819e-06], sum to 1.0000
[2019-03-24 10:15:27,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6880
[2019-03-24 10:15:27,474] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 62.0, 1.0, 2.0, 0.2611962446529023, 1.0, 2.0, 0.2611962446529023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 612011.1982120979, 612011.1982120983, 172221.8052338327], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5751600.0000, 
sim time next is 5752200.0000, 
raw observation next is [27.75, 62.0, 1.0, 2.0, 0.2647897452105724, 1.0, 2.0, 0.2647897452105724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618746.1974985617, 618746.1974985622, 172970.1976948891], 
processed observation next is [0.0, 0.5652173913043478, 0.5833333333333334, 0.62, 1.0, 1.0, 0.12474969667925287, 1.0, 1.0, 0.12474969667925287, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2209807848209149, 0.22098078482091507, 0.3326349955670944], 
reward next is 0.6674, 
noisyNet noise sample is [array([-1.9426597], dtype=float32), -0.8723565]. 
=============================================
[2019-03-24 10:15:27,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.7992860e-07 3.0888164e-06 4.7239202e-05 9.9991858e-01 3.0252699e-05], sum to 1.0000
[2019-03-24 10:15:27,883] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5425
[2019-03-24 10:15:27,887] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 80.5, 1.0, 2.0, 0.3499399991755855, 1.0, 2.0, 0.3499399991755855, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797665.1384394737, 797665.1384394737, 192877.6224662231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5657400.0000, 
sim time next is 5658000.0000, 
raw observation next is [27.86666666666667, 80.0, 1.0, 2.0, 0.3509776816152795, 1.0, 2.0, 0.3509776816152795, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 800031.7015264021, 800031.7015264026, 193144.7987452825], 
processed observation next is [0.0, 0.4782608695652174, 0.5876543209876545, 0.8, 1.0, 1.0, 0.22735438287533272, 1.0, 1.0, 0.22735438287533272, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28572560768800076, 0.2857256076880009, 0.3714323052793894], 
reward next is 0.6286, 
noisyNet noise sample is [array([-1.7048844], dtype=float32), -0.54876775]. 
=============================================
[2019-03-24 10:15:27,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.790462]
 [59.779716]
 [59.743553]
 [59.708424]
 [59.704052]], R is [[59.86535263]
 [59.89578247]
 [59.92639923]
 [59.95715714]
 [59.98807144]].
[2019-03-24 10:15:29,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3502017e-06 2.3191356e-07 8.7082577e-07 9.9998677e-01 8.8612787e-06], sum to 1.0000
[2019-03-24 10:15:29,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3368
[2019-03-24 10:15:29,738] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.2966586837228353, 1.0, 2.0, 0.2966586837228353, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678270.8401494512, 678270.8401494515, 179766.8457867386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5631600.0000, 
sim time next is 5632200.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.2961773289416477, 1.0, 2.0, 0.2961773289416477, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677183.3846719516, 677183.3846719521, 179652.4790094169], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.16211586778767587, 1.0, 1.0, 0.16211586778767587, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2418512088114113, 0.24185120881141148, 0.34548553655657094], 
reward next is 0.6545, 
noisyNet noise sample is [array([-0.39684895], dtype=float32), -0.077602126]. 
=============================================
[2019-03-24 10:15:30,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4064778e-08 1.4371008e-07 1.0274258e-07 9.9998522e-01 1.4574604e-05], sum to 1.0000
[2019-03-24 10:15:30,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3593
[2019-03-24 10:15:30,289] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.2749981274060581, 1.0, 2.0, 0.2749981274060581, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639104.0622599053, 639104.0622599057, 175174.3329265105], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [28.01666666666667, 62.5, 1.0, 2.0, 0.2778247595652124, 1.0, 2.0, 0.2778247595652124, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 644600.8296743055, 644600.829674306, 175784.1359257539], 
processed observation next is [0.0, 0.6521739130434783, 0.59320987654321, 0.625, 1.0, 1.0, 0.14026757091096714, 1.0, 1.0, 0.14026757091096714, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2302145820265377, 0.23021458202653786, 0.3380464152418344], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.3224913], dtype=float32), -0.57564884]. 
=============================================
[2019-03-24 10:15:30,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.746685]
 [62.804718]
 [62.817795]
 [62.84724 ]
 [62.868404]], R is [[62.72464752]
 [62.76052856]
 [62.79668808]
 [62.83300018]
 [62.86919785]].
[2019-03-24 10:15:30,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1271197e-07 8.1796434e-06 3.3945330e-06 9.9995172e-01 3.5954512e-05], sum to 1.0000
[2019-03-24 10:15:30,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0983
[2019-03-24 10:15:30,502] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.76666666666667, 46.16666666666667, 1.0, 2.0, 0.5111220216420378, 1.0, 2.0, 0.5111220216420378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1225022.439869392, 1225022.439869392, 241406.3023030717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5922600.0000, 
sim time next is 5923200.0000, 
raw observation next is [28.93333333333334, 45.33333333333334, 1.0, 2.0, 0.5508261747200317, 1.0, 2.0, 0.5508261747200317, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1317562.830428468, 1317562.830428468, 254234.5460989506], 
processed observation next is [1.0, 0.5652173913043478, 0.6271604938271608, 0.4533333333333334, 1.0, 1.0, 0.46526925561908533, 1.0, 1.0, 0.46526925561908533, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47055815372445287, 0.47055815372445287, 0.4889125886518281], 
reward next is 0.5111, 
noisyNet noise sample is [array([-0.9653003], dtype=float32), -0.86473453]. 
=============================================
[2019-03-24 10:15:31,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0484775e-06 1.3345013e-07 2.7085176e-07 9.9998701e-01 9.4945344e-06], sum to 1.0000
[2019-03-24 10:15:31,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-24 10:15:31,539] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 77.66666666666667, 1.0, 2.0, 0.3545828964141424, 1.0, 2.0, 0.3545828964141424, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808253.8963628258, 808253.8963628262, 194075.883963181], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5660400.0000, 
sim time next is 5661000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.3545664522469563, 1.0, 2.0, 0.3545664522469563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808216.3929473655, 808216.3929473655, 194071.6199658607], 
processed observation next is [0.0, 0.5217391304347826, 0.6074074074074074, 0.77, 1.0, 1.0, 0.2316267288654242, 1.0, 1.0, 0.2316267288654242, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28864871176691625, 0.28864871176691625, 0.37321465378050134], 
reward next is 0.6268, 
noisyNet noise sample is [array([0.04351651], dtype=float32), -0.5911728]. 
=============================================
[2019-03-24 10:15:31,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.860603]
 [62.841484]
 [62.819942]
 [62.854702]
 [62.859554]], R is [[62.86248016]
 [62.86063385]
 [62.8591156 ]
 [62.85802841]
 [62.85748291]].
[2019-03-24 10:15:31,999] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.5579268e-06 4.1872922e-06 1.4001709e-04 9.9977010e-01 7.7124321e-05], sum to 1.0000
[2019-03-24 10:15:32,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3635
[2019-03-24 10:15:32,013] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333334, 74.0, 1.0, 2.0, 0.4202541402172195, 1.0, 2.0, 0.4202541402172195, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1007858.93713376, 1007858.93713376, 213939.4984412596], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5818800.0000, 
sim time next is 5819400.0000, 
raw observation next is [24.0, 72.0, 1.0, 2.0, 0.4689566611575803, 1.0, 2.0, 0.4689566611575803, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1123486.102828088, 1123486.102828088, 228271.7136868063], 
processed observation next is [1.0, 0.34782608695652173, 0.4444444444444444, 0.72, 1.0, 1.0, 0.36780554899711937, 1.0, 1.0, 0.36780554899711937, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40124503672431716, 0.40124503672431716, 0.43898406478231977], 
reward next is 0.5610, 
noisyNet noise sample is [array([1.834967], dtype=float32), -0.54771364]. 
=============================================
[2019-03-24 10:15:34,776] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2251333e-06 3.3650522e-06 1.3481579e-06 9.9998081e-01 8.1728476e-06], sum to 1.0000
[2019-03-24 10:15:34,787] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9024
[2019-03-24 10:15:34,791] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 97.0, 1.0, 2.0, 0.2535307426278913, 1.0, 2.0, 0.2535307426278913, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 600404.4032058707, 600404.4032058711, 170755.8466908205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5712000.0000, 
sim time next is 5712600.0000, 
raw observation next is [21.75, 97.0, 1.0, 2.0, 0.2519560369403111, 1.0, 2.0, 0.2519560369403111, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597255.6836664496, 597255.6836664496, 170423.3495498358], 
processed observation next is [0.0, 0.08695652173913043, 0.3611111111111111, 0.97, 1.0, 1.0, 0.1094714725479894, 1.0, 1.0, 0.1094714725479894, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21330560130944629, 0.21330560130944629, 0.3277372106727612], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.9172396], dtype=float32), -1.2553015]. 
=============================================
[2019-03-24 10:15:34,922] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4359508e-06 6.8590218e-08 4.7759255e-07 9.9999368e-01 3.3415774e-06], sum to 1.0000
[2019-03-24 10:15:34,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5436
[2019-03-24 10:15:34,936] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.2486790594589857, 1.0, 2.0, 0.2486790594589857, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 588625.3392841821, 588625.3392841825, 169646.81512697], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5749200.0000, 
sim time next is 5749800.0000, 
raw observation next is [27.15, 62.0, 1.0, 2.0, 0.2514170635113744, 1.0, 2.0, 0.2514170635113744, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593759.5009906864, 593759.5009906868, 170207.1801199311], 
processed observation next is [0.0, 0.5652173913043478, 0.561111111111111, 0.62, 1.0, 1.0, 0.10882983751354093, 1.0, 1.0, 0.10882983751354093, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21205696463953083, 0.212056964639531, 0.3273215002306367], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.17816393], dtype=float32), 0.58317983]. 
=============================================
[2019-03-24 10:15:36,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6647647e-06 2.6556606e-07 1.1706624e-06 9.9997807e-01 1.7833701e-05], sum to 1.0000
[2019-03-24 10:15:36,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7522
[2019-03-24 10:15:36,929] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.73333333333333, 74.33333333333333, 1.0, 2.0, 0.1976489898575148, 1.0, 2.0, 0.1976489898575148, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491342.7730998464, 491342.7730998468, 159463.889466969], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5902800.0000, 
sim time next is 5903400.0000, 
raw observation next is [21.91666666666667, 73.66666666666667, 1.0, 2.0, 0.2035949032120841, 1.0, 2.0, 0.2035949032120841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505409.3781613049, 505409.3781613049, 160700.5991791402], 
processed observation next is [1.0, 0.30434782608695654, 0.36728395061728414, 0.7366666666666667, 1.0, 1.0, 0.05189869430010011, 1.0, 1.0, 0.05189869430010011, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18050334934332318, 0.18050334934332318, 0.30903961380603884], 
reward next is 0.6910, 
noisyNet noise sample is [array([-0.5183109], dtype=float32), -2.314143]. 
=============================================
[2019-03-24 10:15:37,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4665696e-06 1.1822657e-06 3.3735873e-06 9.9992287e-01 6.6049273e-05], sum to 1.0000
[2019-03-24 10:15:37,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2103
[2019-03-24 10:15:37,653] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333333, 89.5, 1.0, 2.0, 0.2185734616770357, 1.0, 2.0, 0.2185734616770357, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530571.3370742657, 530571.3370742662, 163552.7703499002], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [21.36666666666667, 89.0, 1.0, 2.0, 0.2177004880735066, 1.0, 2.0, 0.2177004880735066, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528712.0161820293, 528712.0161820297, 163373.2816457519], 
processed observation next is [0.0, 0.30434782608695654, 0.3469135802469137, 0.89, 1.0, 1.0, 0.06869105723036498, 1.0, 1.0, 0.06869105723036498, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18882572006501044, 0.1888257200650106, 0.31417938778029214], 
reward next is 0.6858, 
noisyNet noise sample is [array([-0.86627215], dtype=float32), 1.3875221]. 
=============================================
[2019-03-24 10:15:45,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7910036e-07 6.5070608e-08 9.5448365e-07 9.9998808e-01 1.0639676e-05], sum to 1.0000
[2019-03-24 10:15:45,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1591
[2019-03-24 10:15:45,262] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 59.0, 1.0, 2.0, 0.2623780092239112, 1.0, 2.0, 0.2623780092239112, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614043.0751578473, 614043.0751578477, 172459.2304758645], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6026400.0000, 
sim time next is 6027000.0000, 
raw observation next is [28.08333333333333, 59.66666666666667, 1.0, 2.0, 0.2624640395033923, 1.0, 2.0, 0.2624640395033923, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614117.1614733805, 614117.161473381, 172473.1908419816], 
processed observation next is [1.0, 0.782608695652174, 0.5956790123456789, 0.5966666666666667, 1.0, 1.0, 0.12198099940880038, 1.0, 1.0, 0.12198099940880038, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21932755766906448, 0.21932755766906464, 0.3316792131576569], 
reward next is 0.6683, 
noisyNet noise sample is [array([-1.7602472], dtype=float32), -0.38076267]. 
=============================================
[2019-03-24 10:15:45,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.509094]
 [63.570633]
 [63.40995 ]
 [63.419327]
 [63.320827]], R is [[63.63080215]
 [63.6628418 ]
 [63.69566345]
 [63.72990417]
 [63.76659393]].
[2019-03-24 10:15:46,775] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8641519e-07 5.4067019e-08 1.3860040e-06 9.9999654e-01 1.9061791e-06], sum to 1.0000
[2019-03-24 10:15:46,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3631
[2019-03-24 10:15:46,799] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.65, 85.5, 1.0, 2.0, 0.2380218971382863, 1.0, 2.0, 0.2380218971382863, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569760.3210193092, 569760.3210193092, 167529.0477645786], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [22.63333333333333, 85.0, 1.0, 2.0, 0.236355803172019, 1.0, 2.0, 0.236355803172019, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 566588.464542882, 566588.4645428825, 167191.2968345678], 
processed observation next is [1.0, 1.0, 0.393827160493827, 0.85, 1.0, 1.0, 0.09089976568097502, 1.0, 1.0, 0.09089976568097502, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2023530230510293, 0.20235302305102948, 0.32152172468186113], 
reward next is 0.6785, 
noisyNet noise sample is [array([-0.43389723], dtype=float32), -2.5910075]. 
=============================================
[2019-03-24 10:15:53,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2089448e-06 1.7894473e-07 4.3429864e-06 9.9998021e-01 1.3951669e-05], sum to 1.0000
[2019-03-24 10:15:53,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0045
[2019-03-24 10:15:53,405] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 59.0, 1.0, 2.0, 0.7817021929069015, 1.0, 2.0, 0.7817021929069015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1782950.521291846, 1782950.521291847, 336249.9259570763], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6012000.0000, 
sim time next is 6012600.0000, 
raw observation next is [29.0, 58.83333333333334, 1.0, 2.0, 0.733004479730833, 1.0, 2.0, 0.733004479730833, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1671774.092217699, 1671774.092217698, 316846.9047076182], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.5883333333333334, 1.0, 1.0, 0.6821481901557536, 1.0, 1.0, 0.6821481901557536, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5970621757920354, 0.597062175792035, 0.6093209705915734], 
reward next is 0.3907, 
noisyNet noise sample is [array([-0.48064074], dtype=float32), -1.8504906]. 
=============================================
[2019-03-24 10:15:59,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4228691e-05 6.9213451e-07 1.0546753e-05 9.9995947e-01 1.4986257e-05], sum to 1.0000
[2019-03-24 10:15:59,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3460
[2019-03-24 10:15:59,530] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.41666666666666, 37.5, 1.0, 2.0, 0.4324703840384405, 1.0, 2.0, 0.4324703840384405, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1079391.884099541, 1079391.88409954, 218655.0423346497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6606600.0000, 
sim time next is 6607200.0000, 
raw observation next is [27.53333333333333, 38.0, 1.0, 2.0, 0.4472043966633893, 1.0, 2.0, 0.4472043966633893, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1112916.399112345, 1112916.399112346, 222954.4885925779], 
processed observation next is [1.0, 0.4782608695652174, 0.5753086419753086, 0.38, 1.0, 1.0, 0.3419099960278444, 1.0, 1.0, 0.3419099960278444, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3974701425401232, 0.3974701425401235, 0.42875863190880364], 
reward next is 0.5712, 
noisyNet noise sample is [array([-0.04042385], dtype=float32), 0.26463607]. 
=============================================
[2019-03-24 10:16:02,642] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 10:16:02,645] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 10:16:02,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:16:02,648] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 10:16:02,649] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:16:02,651] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 10:16:02,652] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:16:02,652] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 10:16:02,654] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 10:16:02,655] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:16:02,656] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 10:16:02,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 10:16:02,710] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 10:16:02,740] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 10:16:02,774] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 10:16:02,824] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/42/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 10:16:07,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:07,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.19652226, 25.39401020666666, 1.0, 2.0, 0.1925060783777344, 1.0, 2.0, 0.1925060783777344, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 476473.3631610219, 476473.3631610223, 158334.0719505258]
[2019-03-24 10:16:07,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:16:07,792] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.1981352e-07 2.9477067e-07 9.1106801e-07 9.9999547e-01 2.9344023e-06], sampled 0.5369103062658183
[2019-03-24 10:16:14,888] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:14,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.9, 17.0, 1.0, 2.0, 0.4312766513767574, 1.0, 2.0, 0.4312766513767574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1079950.262424081, 1079950.262424082, 218370.5576661669]
[2019-03-24 10:16:14,893] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:16:14,895] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2396426e-07 4.9766822e-07 1.5378989e-06 9.9999261e-01 4.6931791e-06], sampled 0.5027014292135856
[2019-03-24 10:16:18,376] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:18,377] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.54235728833333, 59.42986358833333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 306126.2804994882, 306126.2804994886, 124374.4901433934]
[2019-03-24 10:16:18,380] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:16:18,383] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7730138e-07 2.5913891e-07 8.0537643e-07 9.9999583e-01 2.7644253e-06], sampled 0.8792702137018408
[2019-03-24 10:16:31,109] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:31,110] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.97778771, 80.340955845, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 309968.619335464, 309968.619335464, 127616.8881952645]
[2019-03-24 10:16:31,111] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:16:31,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5267146e-07 3.0706673e-07 9.5781400e-07 9.9999499e-01 3.2570128e-06], sampled 0.48033156892975415
[2019-03-24 10:16:40,940] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:40,941] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.3, 54.0, 1.0, 2.0, 0.3623704704736256, 1.0, 2.0, 0.3623704704736256, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 828762.4780143795, 828762.47801438, 196234.8131698117]
[2019-03-24 10:16:40,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:16:40,945] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2878945e-07 4.2916045e-07 1.3286652e-06 9.9999344e-01 4.2186452e-06], sampled 0.3017756721304954
[2019-03-24 10:16:56,853] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:56,854] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.3042321995911882, 1.0, 2.0, 0.3042321995911882, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694454.6736476478, 694454.6736476483, 181530.6990638586]
[2019-03-24 10:16:56,855] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:16:56,859] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6730825e-07 2.5534143e-07 8.0389782e-07 9.9999595e-01 2.6196378e-06], sampled 0.39143985488075506
[2019-03-24 10:16:59,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:16:59,658] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.417858365, 97.498305665, 1.0, 2.0, 0.332618805348934, 1.0, 2.0, 0.332618805348934, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758163.0934801196, 758163.0934801201, 188472.693696337]
[2019-03-24 10:16:59,659] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:16:59,662] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.9132576e-07 2.7084221e-07 8.6381857e-07 9.9999571e-01 2.7733715e-06], sampled 0.4305560686084138
[2019-03-24 10:17:04,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:04,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 64.0, 1.0, 2.0, 0.4646902424540299, 1.0, 2.0, 0.4646902424540299, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1059411.542203322, 1059411.542203322, 224682.633991913]
[2019-03-24 10:17:04,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:17:04,484] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8621060e-07 3.8919174e-07 1.2639528e-06 9.9999404e-01 3.7312541e-06], sampled 0.33883268170167535
[2019-03-24 10:17:07,247] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:07,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.18528079, 69.96094328, 1.0, 2.0, 0.3948603522645281, 1.0, 2.0, 0.3948603522645281, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900118.2460600663, 900118.2460600663, 204784.9340039707]
[2019-03-24 10:17:07,250] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:17:07,252] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.4946975e-07 3.0613077e-07 9.5924281e-07 9.9999511e-01 3.1396200e-06], sampled 0.3846429762794211
[2019-03-24 10:17:09,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:09,693] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.66666666666666, 70.0, 1.0, 2.0, 0.7848551220811706, 1.0, 2.0, 0.7848551220811706, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1790149.106412491, 1790149.106412491, 337537.4240504863]
[2019-03-24 10:17:09,695] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 10:17:09,697] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3560606e-06 1.6097181e-06 4.7992271e-06 9.9997842e-01 1.2781973e-05], sampled 0.5620061298155858
[2019-03-24 10:17:25,829] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:25,830] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 55.0, 1.0, 2.0, 0.2776664942128587, 1.0, 2.0, 0.2776664942128587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643549.1787296603, 643549.1787296603, 175714.9169523429]
[2019-03-24 10:17:25,830] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 10:17:25,835] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9344863e-07 2.7214978e-07 8.5273439e-07 9.9999571e-01 2.8046397e-06], sampled 0.15122007049356423
[2019-03-24 10:17:42,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:42,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.82301890166666, 81.92267873166668, 1.0, 2.0, 0.2019163837288181, 1.0, 2.0, 0.2019163837288181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 498354.1591988868, 498354.1591988872, 160267.084171378]
[2019-03-24 10:17:42,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 10:17:42,769] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1726096e-07 2.8520583e-07 8.8614865e-07 9.9999547e-01 2.9603971e-06], sampled 0.784766680237742
[2019-03-24 10:17:57,332] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:17:57,335] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.6, 83.66666666666667, 1.0, 2.0, 0.3152636547572605, 1.0, 2.0, 0.3152636547572605, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768185.8993674755, 768185.899367476, 186202.8655384502]
[2019-03-24 10:17:57,336] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 10:17:57,339] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6412802e-07 3.8377112e-07 1.1851291e-06 9.9999392e-01 3.8999297e-06], sampled 0.4481799894644801
[2019-03-24 10:18:00,694] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01117208], dtype=float32), 0.011416161]
[2019-03-24 10:18:00,697] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.97109707, 85.94208718333333, 1.0, 2.0, 0.2043516222827527, 1.0, 2.0, 0.2043516222827527, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 501376.9869726761, 501376.9869726765, 160693.1247287864]
[2019-03-24 10:18:00,701] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 10:18:00,705] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.6890019e-07 4.0535971e-07 1.2307337e-06 9.9999392e-01 3.8790868e-06], sampled 0.23951477403905552
[2019-03-24 10:18:11,898] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 10:18:12,298] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 10:18:12,397] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0359 2668562720.4983 68.0000
[2019-03-24 10:18:12,663] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 10:18:12,701] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 10:18:13,716] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2500000, evaluation results [2500000.0, 7523.035865829873, 2668562720.4982953, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
