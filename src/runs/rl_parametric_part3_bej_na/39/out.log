Using TensorFlow backend.
[2019-03-24 00:22:07,059] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.0001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-24 00:22:07,059] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-24 00:22:07.159552: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-24 00:22:39,845] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-24 00:22:39,846] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-24 00:22:39,858] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-24 00:22:39,861] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-24 00:22:39,864] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-24 00:22:39,868] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-24 00:22:39,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-24 00:22:39,875] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:39,876] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-24 00:22:39,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:39,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-24 00:22:40,877] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:40,880] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-24 00:22:40,977] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:40,978] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-24 00:22:41,434] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 00:22:41,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:22:41,435] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:22:41,435] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,436] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:22:41,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:22:41,436] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:22:41,437] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,437] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,437] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,438] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,442] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-24 00:22:41,442] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-24 00:22:41,443] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-24 00:22:41,443] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-24 00:22:41,504] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-24 00:22:41,881] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:41,882] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-24 00:22:41,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:41,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-24 00:22:42,884] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:42,885] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-24 00:22:43,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:43,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-24 00:22:43,886] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:43,893] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-24 00:22:44,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:44,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-24 00:22:44,890] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:44,895] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-24 00:22:45,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:45,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-24 00:22:45,894] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:45,901] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-24 00:22:46,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:46,048] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-24 00:22:46,899] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:46,903] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-24 00:22:47,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:47,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-24 00:22:47,904] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:47,907] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-24 00:22:48,023] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:48,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-24 00:22:48,909] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:48,915] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-24 00:22:49,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:49,048] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-24 00:22:49,915] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:49,922] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-24 00:22:50,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:50,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-24 00:22:50,922] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:50,926] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-24 00:22:51,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:51,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-24 00:22:51,925] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:51,932] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-24 00:22:52,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:52,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-24 00:22:52,930] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:52,936] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-24 00:22:53,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:53,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-24 00:22:53,935] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:53,939] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-24 00:22:54,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:54,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-24 00:22:54,939] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 00:22:54,943] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-24 00:22:55,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:55,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-24 00:23:24,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 00:23:24,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.1, 66.66666666666667, 1.0, 1.0, 0.2511688804050881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4036063831606379, 6.911199999999999, 6.9112, 121.9260426156618, 596896.7345255641, 596896.7345255646, 181725.3065368242]
[2019-03-24 00:23:24,409] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:23:24,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.17396411 0.1926549  0.23330936 0.18611935 0.21395236], sampled 0.2140717311675282
[2019-03-24 00:23:54,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 00:23:54,289] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.93333333333333, 67.33333333333334, 1.0, 2.0, 0.200864574658927, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3298883984541185, 6.911199999999999, 6.9112, 121.9260426156618, 493021.3627947556, 493021.362794756, 168298.1654035616]
[2019-03-24 00:23:54,290] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:23:54,292] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.17466383 0.19370484 0.2299893  0.1861358  0.2155062 ], sampled 0.2596148797785838
[2019-03-24 00:24:27,824] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 00:24:27,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.05, 92.5, 1.0, 2.0, 0.2895079236291666, 1.0, 1.0, 0.2895079236291666, 1.0, 1.0, 0.4667150953092601, 6.9112, 6.9112, 121.94756008, 1039287.512855469, 1039287.512855469, 251583.9588277476]
[2019-03-24 00:24:27,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:24:27,828] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.17286856 0.1951201  0.23104164 0.18673253 0.21423715], sampled 0.219131774305247
[2019-03-24 00:24:29,107] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 00:24:29,108] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.06666666666667, 93.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 356720.0985625238, 356720.0985625234, 168606.5418441361]
[2019-03-24 00:24:29,109] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:24:29,111] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.17314762 0.19570708 0.2331242  0.18476138 0.2132597 ], sampled 0.6440975332483747
[2019-03-24 00:24:33,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3771.7064 2554495376.7174 295.0000
[2019-03-24 00:24:33,437] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 3953.8540 2454482852.3922 209.0000
[2019-03-24 00:24:33,464] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3872.5500 2518067739.1104 300.0000
[2019-03-24 00:24:33,515] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 3874.0065 2486565901.7272 244.0000
[2019-03-24 00:24:33,706] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3880.1945 2734391865.9673 399.0000
[2019-03-24 00:24:34,723] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3880.1944828569, 2734391865.967252, 399.0, 3874.006510760401, 2486565901.727238, 244.0, 3953.854007543868, 2454482852.3922334, 209.0, 3771.7063649786883, 2554495376.7174215, 295.0, 3872.5500123081, 2518067739.1103873, 300.0]
[2019-03-24 00:24:49,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2730097e-08 9.9999475e-01 7.6866984e-09 5.1625079e-06 6.2447171e-08], sum to 1.0000
[2019-03-24 00:24:49,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1917
[2019-03-24 00:24:49,997] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.53333333333333, 14.66666666666667, 1.0, 2.0, 0.3807181570900547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488589.2962024809, 488589.2962024809, 126130.5512033037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 229200.0000, 
sim time next is 229800.0000, 
raw observation next is [33.56666666666667, 14.83333333333333, 1.0, 2.0, 0.3811992487931162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488900.2328060357, 488900.2328060357, 126197.7976174728], 
processed observation next is [0.0, 0.6521739130434783, 0.7987654320987656, 0.14833333333333332, 1.0, 1.0, 0.26333243903942405, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1746072260021556, 0.1746072260021556, 0.24268807234129383], 
reward next is 0.7573, 
noisyNet noise sample is [array([1.2590537], dtype=float32), -0.086364046]. 
=============================================
[2019-03-24 00:24:52,181] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7968957e-13 1.0000000e+00 4.5976382e-16 3.1616879e-11 2.6371616e-16], sum to 1.0000
[2019-03-24 00:24:52,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1760
[2019-03-24 00:24:52,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 51.16666666666666, 1.0, 2.0, 0.2545756168311171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328381.9062604767, 328381.9062604767, 93008.35270226706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 270600.0000, 
sim time next is 271200.0000, 
raw observation next is [20.26666666666667, 51.33333333333334, 1.0, 2.0, 0.2532964030626842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326731.4727316831, 326731.4727316831, 92626.55987684756], 
processed observation next is [0.0, 0.13043478260869565, 0.3061728395061729, 0.5133333333333334, 1.0, 1.0, 0.11106714650319546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11668981168988683, 0.11668981168988683, 0.1781279997631684], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.3430804], dtype=float32), -0.4568629]. 
=============================================
[2019-03-24 00:24:53,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7872: loss 0.0826
[2019-03-24 00:24:53,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7873: learning rate 0.0001
[2019-03-24 00:24:53,835] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7920: loss 0.9851
[2019-03-24 00:24:53,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7921: learning rate 0.0001
[2019-03-24 00:24:53,840] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7921: loss 1.2746
[2019-03-24 00:24:53,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7921: learning rate 0.0001
[2019-03-24 00:24:53,920] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7965: loss 1.3380
[2019-03-24 00:24:53,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7966: learning rate 0.0001
[2019-03-24 00:24:53,930] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7968: loss 1.4903
[2019-03-24 00:24:53,933] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7969: learning rate 0.0001
[2019-03-24 00:24:53,940] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7973: loss 1.5858
[2019-03-24 00:24:53,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7974: learning rate 0.0001
[2019-03-24 00:24:53,953] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7983: loss 0.9329
[2019-03-24 00:24:53,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7983: learning rate 0.0001
[2019-03-24 00:24:53,965] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7988: loss 1.2456
[2019-03-24 00:24:53,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8081754e-09 9.9999630e-01 2.4700112e-11 3.6382537e-06 1.1886027e-09], sum to 1.0000
[2019-03-24 00:24:53,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7988: learning rate 0.0001
[2019-03-24 00:24:53,976] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7992: loss 1.0184
[2019-03-24 00:24:53,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2047
[2019-03-24 00:24:53,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7992: learning rate 0.0001
[2019-03-24 00:24:54,148] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 29.33333333333333, 1.0, 2.0, 0.3066636552112818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395588.581481632, 395588.581481632, 106371.3755917808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 298200.0000, 
sim time next is 298800.0000, 
raw observation next is [26.1, 29.0, 1.0, 2.0, 0.3077439914011608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 396982.5493317747, 396982.5493317743, 106792.2689551882], 
processed observation next is [0.0, 0.4782608695652174, 0.5222222222222223, 0.29, 1.0, 1.0, 0.17588570404900097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14177948190420525, 0.1417794819042051, 0.20536974799074656], 
reward next is 0.7946, 
noisyNet noise sample is [array([-0.32664305], dtype=float32), 1.5870872]. 
=============================================
[2019-03-24 00:24:54,161] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8008: loss 0.3597
[2019-03-24 00:24:54,161] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8008: loss 0.3117
[2019-03-24 00:24:54,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8009: learning rate 0.0001
[2019-03-24 00:24:54,166] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8009: learning rate 0.0001
[2019-03-24 00:24:54,187] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8022: loss 0.0267
[2019-03-24 00:24:54,188] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8022: learning rate 0.0001
[2019-03-24 00:24:54,206] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8033: loss 0.0117
[2019-03-24 00:24:54,209] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8034: loss 0.1739
[2019-03-24 00:24:54,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8034: learning rate 0.0001
[2019-03-24 00:24:54,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8034: learning rate 0.0001
[2019-03-24 00:24:54,264] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8063: loss 0.3269
[2019-03-24 00:24:54,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8064: learning rate 0.0001
[2019-03-24 00:24:54,323] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8092: loss 3.8470
[2019-03-24 00:24:54,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8093: learning rate 0.0001
[2019-03-24 00:24:56,790] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2524614e-07 9.9999261e-01 6.8078410e-09 6.7057645e-06 4.5019853e-08], sum to 1.0000
[2019-03-24 00:24:56,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5978
[2019-03-24 00:24:56,969] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 53.0, 1.0, 2.0, 0.2615382937437919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337365.170336205, 337365.170336205, 101830.890899253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [21.05, 53.5, 1.0, 2.0, 0.2599338504763279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 335295.104080551, 335295.1040805514, 101023.4111809151], 
processed observation next is [1.0, 0.043478260869565216, 0.3351851851851852, 0.535, 1.0, 1.0, 0.11896886961467605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11974825145733965, 0.11974825145733979, 0.19427579073252904], 
reward next is 0.8057, 
noisyNet noise sample is [array([-0.6799197], dtype=float32), 0.70968884]. 
=============================================
[2019-03-24 00:25:06,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7853391e-09 9.9999821e-01 1.7609677e-06 2.5144442e-09 5.1108690e-10], sum to 1.0000
[2019-03-24 00:25:06,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6939
[2019-03-24 00:25:06,372] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 75.0, 1.0, 2.0, 0.3293455430465352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420313.636904403, 420313.636904403, 119278.4122688979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531600.0000, 
sim time next is 532200.0000, 
raw observation next is [19.78333333333333, 75.5, 1.0, 2.0, 0.3246235054713112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414361.1856674658, 414361.1856674658, 118672.409002684], 
processed observation next is [1.0, 0.13043478260869565, 0.28827160493827153, 0.755, 1.0, 1.0, 0.19598036365632285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14798613773838065, 0.14798613773838065, 0.2282161711590077], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.2338061], dtype=float32), 0.5691234]. 
=============================================
[2019-03-24 00:25:09,057] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15789: loss 4.0474
[2019-03-24 00:25:09,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15790: learning rate 0.0001
[2019-03-24 00:25:09,137] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15831: loss 3.6880
[2019-03-24 00:25:09,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15832: learning rate 0.0001
[2019-03-24 00:25:09,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2570246e-05 7.2644287e-01 2.7320796e-01 1.0855200e-05 2.9573037e-04], sum to 1.0000
[2019-03-24 00:25:09,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9721
[2019-03-24 00:25:09,218] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15870: loss 3.7311
[2019-03-24 00:25:09,220] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15871: learning rate 0.0001
[2019-03-24 00:25:09,220] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.01666666666667, 43.5, 1.0, 2.0, 0.181634320529079, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3048143961210278, 6.911199999999999, 6.9112, 121.9260426156618, 453936.9561147278, 453936.9561147283, 162764.9117163545], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [26.83333333333334, 44.0, 1.0, 2.0, 0.1802845848705844, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3024956883650867, 6.911199999999999, 6.9112, 121.9260426156618, 450508.1208305986, 450508.1208305991, 162479.921869233], 
processed observation next is [1.0, 0.9565217391304348, 0.5493827160493829, 0.44, 1.0, 1.0, 0.024148315322124293, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1281196104563584, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1608957574394995, 0.1608957574394997, 0.3124613882100634], 
reward next is 0.6875, 
noisyNet noise sample is [array([-0.17703752], dtype=float32), 1.3155473]. 
=============================================
[2019-03-24 00:25:09,271] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15896: loss 1.6916
[2019-03-24 00:25:09,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15897: learning rate 0.0001
[2019-03-24 00:25:09,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15907: loss 2.7818
[2019-03-24 00:25:09,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15907: learning rate 0.0001
[2019-03-24 00:25:09,300] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15908: loss 1.6671
[2019-03-24 00:25:09,302] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15908: learning rate 0.0001
[2019-03-24 00:25:09,441] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15981: loss 1.5422
[2019-03-24 00:25:09,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15981: learning rate 0.0001
[2019-03-24 00:25:09,495] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16000: loss 0.6437
[2019-03-24 00:25:09,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16000: learning rate 0.0001
[2019-03-24 00:25:09,648] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16017: loss 0.4135
[2019-03-24 00:25:09,649] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16017: loss 0.4814
[2019-03-24 00:25:09,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16018: learning rate 0.0001
[2019-03-24 00:25:09,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16018: learning rate 0.0001
[2019-03-24 00:25:09,721] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16056: loss 0.2172
[2019-03-24 00:25:09,723] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16056: learning rate 0.0001
[2019-03-24 00:25:09,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16071: loss 0.0790
[2019-03-24 00:25:09,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16071: learning rate 0.0001
[2019-03-24 00:25:09,753] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16071: loss 0.4605
[2019-03-24 00:25:09,753] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16071: loss 0.1506
[2019-03-24 00:25:09,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16071: learning rate 0.0001
[2019-03-24 00:25:09,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16071: learning rate 0.0001
[2019-03-24 00:25:09,862] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16125: loss 1.4654
[2019-03-24 00:25:09,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16125: learning rate 0.0001
[2019-03-24 00:25:10,015] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16199: loss 0.2400
[2019-03-24 00:25:10,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16199: learning rate 0.0001
[2019-03-24 00:25:11,180] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2471804e-10 9.9997938e-01 2.0622951e-05 1.2556090e-09 1.5027910e-08], sum to 1.0000
[2019-03-24 00:25:11,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4464
[2019-03-24 00:25:11,192] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 48.33333333333333, 1.0, 2.0, 0.8988199990374579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.0274306788741, 6.9112, 121.9255194177117, 1177828.243501202, 1118308.00274641, 221121.8696705908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 636000.0000, 
sim time next is 636600.0000, 
raw observation next is [27.05, 47.16666666666667, 1.0, 2.0, 0.9181087942105045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.149771877560671, 6.9112, 121.9249213678866, 1263177.781555993, 1141008.780424863, 225552.7879262768], 
processed observation next is [1.0, 0.34782608695652173, 0.5574074074074075, 0.47166666666666673, 1.0, 1.0, 0.9025104692982197, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.023857187756067065, 0.0, 0.8094546849009241, 0.45113492198428323, 0.40750313586602255, 0.43375536139668613], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46221608], dtype=float32), -0.3628014]. 
=============================================
[2019-03-24 00:25:12,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3574592e-05 5.5041026e-02 6.2405460e-02 5.9335050e-04 8.8194656e-01], sum to 1.0000
[2019-03-24 00:25:12,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4713
[2019-03-24 00:25:12,507] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.13333333333334, 34.0, 1.0, 2.0, 0.4001628389647223, 1.0, 1.0, 0.4001628389647223, 1.0, 2.0, 0.6406669200775991, 6.9112, 6.9112, 121.94756008, 1413459.934788033, 1413459.934788033, 297122.2713090429], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [32.35, 33.0, 1.0, 2.0, 0.3857750993651538, 1.0, 2.0, 0.3857750993651538, 1.0, 2.0, 0.6176619392600574, 6.911200000000001, 6.9112, 121.94756008, 1362797.358036588, 1362797.358036588, 290858.9213889697], 
processed observation next is [1.0, 0.4782608695652174, 0.7537037037037038, 0.33, 1.0, 1.0, 0.2687798801966117, 1.0, 1.0, 0.2687798801966117, 1.0, 1.0, 0.5220774240750717, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.48671334215592427, 0.48671334215592427, 0.5593440795941725], 
reward next is 0.4407, 
noisyNet noise sample is [array([0.48600456], dtype=float32), 0.45672587]. 
=============================================
[2019-03-24 00:25:13,805] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.05564648 0.21120822 0.41885802 0.10724716 0.2070401 ], sum to 1.0000
[2019-03-24 00:25:13,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7786
[2019-03-24 00:25:13,819] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.93333333333333, 32.33333333333334, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 436725.4852393306, 436725.485239331, 183759.3016698587], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 685200.0000, 
sim time next is 685800.0000, 
raw observation next is [28.75, 33.0, 1.0, 2.0, 0.1727257978690108, 1.0, 2.0, 0.1727257978690108, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 434276.7597284873, 434276.7597284878, 154400.1974389436], 
processed observation next is [1.0, 0.9565217391304348, 0.6203703703703703, 0.33, 1.0, 1.0, 0.01514975936786999, 1.0, 1.0, 0.01514975936786999, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15509884276017402, 0.15509884276017422, 0.29692345661335307], 
reward next is 0.7031, 
noisyNet noise sample is [array([-0.7226814], dtype=float32), 0.19525422]. 
=============================================
[2019-03-24 00:25:13,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.05024732 0.21668532 0.5676238  0.13246386 0.03297978], sum to 1.0000
[2019-03-24 00:25:13,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7128
[2019-03-24 00:25:14,135] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.13333333333334, 25.0, 1.0, 1.0, 0.1830900047043729, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3122534396047157, 6.911199999999999, 6.9112, 121.9260426156618, 462060.6947410977, 462060.6947410982, 162216.2995633363], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 678000.0000, 
sim time next is 678600.0000, 
raw observation next is [30.95, 25.5, 1.0, 2.0, 0.1819773830265279, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3100302318602686, 6.911199999999999, 6.9112, 121.9260426156618, 458991.5483983819, 458991.5483983823, 162028.3206169552], 
processed observation next is [1.0, 0.8695652173913043, 0.7018518518518518, 0.255, 1.0, 1.0, 0.026163551222057033, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13753778982533577, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1639255529994221, 0.16392555299942227, 0.31159292426337537], 
reward next is 0.6884, 
noisyNet noise sample is [array([0.37414983], dtype=float32), 0.51615417]. 
=============================================
[2019-03-24 00:25:24,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0210995e-08 9.9999988e-01 2.2635840e-08 7.6028090e-09 4.0617475e-11], sum to 1.0000
[2019-03-24 00:25:24,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-24 00:25:24,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 64.0, 1.0, 2.0, 0.3840885448886922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479198.7986880673, 479198.7986880673, 126468.4495059791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867600.0000, 
sim time next is 868200.0000, 
raw observation next is [23.45, 64.66666666666667, 1.0, 2.0, 0.3826147677718219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477617.58263286, 477617.58263286, 126269.7850799687], 
processed observation next is [0.0, 0.043478260869565216, 0.42407407407407405, 0.6466666666666667, 1.0, 1.0, 0.2650175806807404, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17057770808316428, 0.17057770808316428, 0.24282650976917058], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.59789693], dtype=float32), -1.207045]. 
=============================================
[2019-03-24 00:25:25,641] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23803: loss 1.0651
[2019-03-24 00:25:25,646] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23804: learning rate 0.0001
[2019-03-24 00:25:25,696] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23829: loss 0.5061
[2019-03-24 00:25:25,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23830: learning rate 0.0001
[2019-03-24 00:25:25,715] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23840: loss 0.5790
[2019-03-24 00:25:25,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23841: learning rate 0.0001
[2019-03-24 00:25:25,726] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23844: loss 0.1758
[2019-03-24 00:25:25,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23844: learning rate 0.0001
[2019-03-24 00:25:25,744] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23851: loss 0.0507
[2019-03-24 00:25:25,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23851: learning rate 0.0001
[2019-03-24 00:25:25,891] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23927: loss 1.5041
[2019-03-24 00:25:25,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23927: learning rate 0.0001
[2019-03-24 00:25:25,933] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23941: loss 3.1705
[2019-03-24 00:25:25,935] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23941: learning rate 0.0001
[2019-03-24 00:25:26,067] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24008: loss 0.0447
[2019-03-24 00:25:26,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24010: learning rate 0.0001
[2019-03-24 00:25:26,113] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24029: loss 0.0693
[2019-03-24 00:25:26,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24029: learning rate 0.0001
[2019-03-24 00:25:26,124] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24035: loss 0.0987
[2019-03-24 00:25:26,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24035: learning rate 0.0001
[2019-03-24 00:25:26,127] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24035: loss 0.1357
[2019-03-24 00:25:26,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24036: learning rate 0.0001
[2019-03-24 00:25:26,150] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24048: loss 0.1208
[2019-03-24 00:25:26,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24048: learning rate 0.0001
[2019-03-24 00:25:26,229] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24086: loss 0.7425
[2019-03-24 00:25:26,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24086: learning rate 0.0001
[2019-03-24 00:25:26,372] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24159: loss 0.2789
[2019-03-24 00:25:26,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24159: learning rate 0.0001
[2019-03-24 00:25:26,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24178: loss 0.0002
[2019-03-24 00:25:26,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24178: learning rate 0.0001
[2019-03-24 00:25:26,469] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24201: loss 0.5362
[2019-03-24 00:25:26,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24201: learning rate 0.0001
[2019-03-24 00:25:28,047] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 00:25:28,050] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:25:28,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:28,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:25:28,055] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:25:28,056] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:28,057] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:28,058] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:25:28,059] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:25:28,060] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:28,062] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:28,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-24 00:25:28,097] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-24 00:25:28,120] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-24 00:25:28,145] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-24 00:25:28,165] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-24 00:25:43,399] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:25:43,399] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.58331788333334, 60.09370146666667, 1.0, 2.0, 0.392458858577495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487070.2668757747, 487070.2668757747, 127579.0914314692]
[2019-03-24 00:25:43,400] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:25:43,403] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.1105830e-11 1.0000000e+00 2.5884111e-11 1.4588960e-11 1.2027887e-15], sampled 0.4352317975576656
[2019-03-24 00:25:49,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:25:49,581] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.59999999999999, 33.0, 1.0, 2.0, 0.4404901353823285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536615.5587882494, 536615.5587882494, 134229.8582571843]
[2019-03-24 00:25:49,582] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:25:49,586] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0908036e-10 1.0000000e+00 4.0565142e-11 2.3013156e-11 2.2615439e-15], sampled 0.3346609926381008
[2019-03-24 00:26:17,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:26:17,538] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.82254309, 67.2703481, 1.0, 2.0, 0.5297004404116217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 625016.3695854554, 625016.3695854549, 147376.714583407]
[2019-03-24 00:26:17,543] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:26:17,545] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4969264e-11 1.0000000e+00 5.0304943e-12 2.7624886e-12 1.2047581e-16], sampled 0.8096418483512736
[2019-03-24 00:26:18,566] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:26:18,568] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.5722450828270497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664169.2329286152, 664169.2329286152, 153942.990958857]
[2019-03-24 00:26:18,569] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:26:18,571] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0854546e-11 1.0000000e+00 3.5873643e-12 1.9609427e-12 7.4903355e-17], sampled 0.34697047254207936
[2019-03-24 00:26:34,440] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:26:34,441] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.68798113666666, 100.2138032333334, 1.0, 2.0, 0.6109897043462338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700649.2236746192, 700649.2236746192, 160193.1739297248]
[2019-03-24 00:26:34,442] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:26:34,443] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6556020e-11 1.0000000e+00 9.1859038e-12 5.0950173e-12 2.8062802e-16], sampled 0.07365261518608435
[2019-03-24 00:27:06,576] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.055686805]
[2019-03-24 00:27:06,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.61264402333333, 94.05614228666667, 1.0, 2.0, 0.385549562248157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474829.7830173765, 474829.7830173765, 126533.8346273573]
[2019-03-24 00:27:06,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:27:06,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.8629151e-11 1.0000000e+00 2.4932230e-11 1.4063931e-11 1.1416046e-15], sampled 0.222735780955017
[2019-03-24 00:27:12,885] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4455 2170606717.8096 493.0000
[2019-03-24 00:27:13,165] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.6848 2195097664.3176 572.0000
[2019-03-24 00:27:13,223] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-24 00:27:13,269] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.0871 2120505356.6476 430.0000
[2019-03-24 00:27:13,309] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.8771 2445351666.9398 746.0000
[2019-03-24 00:27:14,322] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 25000, evaluation results [25000.0, 8099.877128650518, 2445351666.939811, 746.0, 8769.445485181082, 2170606717.8095584, 493.0, 8924.087098226395, 2120505356.6476104, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8698.684794770457, 2195097664.317608, 572.0]
[2019-03-24 00:27:18,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4881866e-04 9.9970537e-01 6.6936104e-06 3.7353300e-05 1.7886135e-06], sum to 1.0000
[2019-03-24 00:27:18,169] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9946
[2019-03-24 00:27:18,360] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 45.5, 1.0, 2.0, 0.2472006835001853, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4121368021948274, 6.9112, 6.9112, 121.9258651842126, 614948.372196512, 614948.372196512, 178230.2432891676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1012200.0000, 
sim time next is 1012800.0000, 
raw observation next is [26.13333333333334, 47.0, 1.0, 2.0, 0.3403033312810394, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425615581, 426394.9640583561, 426394.9640583561, 120618.5449828705], 
processed observation next is [1.0, 0.7391304347826086, 0.523456790123457, 0.47, 1.0, 1.0, 0.21464682295361834, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621284609437, 0.1522839157351272, 0.1522839157351272, 0.23195874035167405], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29211313], dtype=float32), 0.83271855]. 
=============================================
[2019-03-24 00:27:20,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6675422e-13 1.0000000e+00 1.8069424e-16 5.4558073e-14 2.6941624e-18], sum to 1.0000
[2019-03-24 00:27:20,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4155
[2019-03-24 00:27:20,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 69.0, 1.0, 2.0, 0.3298761562610794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 420819.3717497817, 420819.3717497812, 119346.2853250103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [20.7, 69.33333333333333, 1.0, 2.0, 0.3227383611528948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411730.6132241195, 411730.6132241195, 118430.8867804457], 
processed observation next is [1.0, 0.13043478260869565, 0.3222222222222222, 0.6933333333333332, 1.0, 1.0, 0.19373614422963664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14704664758004266, 0.14704664758004266, 0.22775170534701095], 
reward next is 0.7722, 
noisyNet noise sample is [array([-0.4216895], dtype=float32), 2.009048]. 
=============================================
[2019-03-24 00:27:20,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.81468]
 [67.91818]
 [67.76355]
 [67.82756]
 [67.82209]], R is [[67.97183228]
 [68.06259918]
 [68.15187836]
 [68.233078  ]
 [68.32822418]].
[2019-03-24 00:27:22,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6359123e-10 1.0000000e+00 3.7544339e-14 1.6221220e-13 3.1278386e-16], sum to 1.0000
[2019-03-24 00:27:22,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4240
[2019-03-24 00:27:22,858] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 54.33333333333334, 1.0, 2.0, 0.3382579189717804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426695.84057566, 426695.84057566, 120394.3778116702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1102800.0000, 
sim time next is 1103400.0000, 
raw observation next is [24.05, 55.5, 1.0, 2.0, 0.3372974182459056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425629.8820564277, 425629.8820564277, 120271.1059797551], 
processed observation next is [1.0, 0.782608695652174, 0.4462962962962963, 0.555, 1.0, 1.0, 0.21106835505464952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1520106721630099, 0.1520106721630099, 0.23129058842260597], 
reward next is 0.7687, 
noisyNet noise sample is [array([0.08330598], dtype=float32), 0.7602878]. 
=============================================
[2019-03-24 00:27:22,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7867643e-12 1.0000000e+00 5.1972841e-15 7.1361111e-15 2.1215494e-17], sum to 1.0000
[2019-03-24 00:27:22,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0988
[2019-03-24 00:27:22,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1479808.168430957 W.
[2019-03-24 00:27:23,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 44.0, 1.0, 2.0, 0.9555531666370736, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.460296933488411, 6.9112, 121.9237652128687, 1479808.168430957, 1198626.712920419, 234651.4042780108], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1094400.0000, 
sim time next is 1095000.0000, 
raw observation next is [26.46666666666667, 44.33333333333334, 1.0, 2.0, 0.3140580511334007, 1.0, 1.0, 0.3140580511334007, 1.0, 1.0, 0.5166117334633825, 6.9112, 6.9112, 121.94756008, 1158658.866149542, 1158658.866149542, 259853.9763806805], 
processed observation next is [1.0, 0.6956521739130435, 0.5358024691358025, 0.4433333333333334, 1.0, 1.0, 0.18340244182547702, 1.0, 0.5, 0.18340244182547702, 1.0, 0.5, 0.3957646668292281, 0.0, 0.0, 0.8096049824067558, 0.41380673791055067, 0.41380673791055067, 0.4997191853474625], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24400076], dtype=float32), 1.3561338]. 
=============================================
[2019-03-24 00:27:23,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.57282 ]
 [58.271862]
 [58.45518 ]
 [58.2478  ]
 [57.98004 ]], R is [[57.51231003]
 [56.93718719]
 [56.87714386]
 [56.3083725 ]
 [55.74528885]].
[2019-03-24 00:27:26,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3789577e-21 1.0000000e+00 5.1309861e-26 5.6002296e-25 4.9840109e-31], sum to 1.0000
[2019-03-24 00:27:26,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4503
[2019-03-24 00:27:26,444] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156800.0000, 
sim time next is 1157400.0000, 
raw observation next is [20.6, 66.5, 1.0, 2.0, 0.5397508969684752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691292.0731469521, 691292.0731469516, 150331.4407642356], 
processed observation next is [1.0, 0.391304347826087, 0.3185185185185186, 0.665, 1.0, 1.0, 0.4520844011529467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24689002612391145, 0.24689002612391128, 0.2890989245466069], 
reward next is 0.7109, 
noisyNet noise sample is [array([1.5719987], dtype=float32), 0.48345038]. 
=============================================
[2019-03-24 00:27:27,611] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31712: loss 1.2590
[2019-03-24 00:27:27,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31712: learning rate 0.0001
[2019-03-24 00:27:27,641] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31721: loss 2.0957
[2019-03-24 00:27:27,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31722: learning rate 0.0001
[2019-03-24 00:27:27,918] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31870: loss 0.7644
[2019-03-24 00:27:27,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31871: learning rate 0.0001
[2019-03-24 00:27:27,933] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31875: loss 1.0451
[2019-03-24 00:27:27,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31875: learning rate 0.0001
[2019-03-24 00:27:27,975] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31896: loss 0.0926
[2019-03-24 00:27:27,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31897: learning rate 0.0001
[2019-03-24 00:27:28,030] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31927: loss 0.0130
[2019-03-24 00:27:28,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31927: learning rate 0.0001
[2019-03-24 00:27:28,082] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31954: loss 0.1867
[2019-03-24 00:27:28,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31956: learning rate 0.0001
[2019-03-24 00:27:28,135] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31976: loss 0.9446
[2019-03-24 00:27:28,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31978: learning rate 0.0001
[2019-03-24 00:27:28,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32049: loss 0.5526
[2019-03-24 00:27:28,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32051: learning rate 0.0001
[2019-03-24 00:27:28,306] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32071: loss 0.0643
[2019-03-24 00:27:28,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32072: learning rate 0.0001
[2019-03-24 00:27:28,326] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32081: loss 0.0154
[2019-03-24 00:27:28,326] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32081: loss 0.0112
[2019-03-24 00:27:28,327] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32081: learning rate 0.0001
[2019-03-24 00:27:28,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32081: learning rate 0.0001
[2019-03-24 00:27:28,372] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32106: loss 0.0103
[2019-03-24 00:27:28,373] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32106: learning rate 0.0001
[2019-03-24 00:27:28,387] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32110: loss 0.0744
[2019-03-24 00:27:28,390] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32111: learning rate 0.0001
[2019-03-24 00:27:28,442] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32141: loss 0.5175
[2019-03-24 00:27:28,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32141: learning rate 0.0001
[2019-03-24 00:27:28,669] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32256: loss 0.0085
[2019-03-24 00:27:28,672] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32259: learning rate 0.0001
[2019-03-24 00:27:32,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1134594e-22 1.0000000e+00 2.8225268e-29 3.2411765e-25 1.3513512e-31], sum to 1.0000
[2019-03-24 00:27:32,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5107
[2019-03-24 00:27:32,299] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333334, 62.83333333333334, 1.0, 2.0, 0.4132177659587963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508812.4892308354, 508812.4892308354, 130420.9288949392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1278600.0000, 
sim time next is 1279200.0000, 
raw observation next is [24.76666666666667, 63.66666666666667, 1.0, 2.0, 0.4125606323324168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507821.6534054868, 507821.6534054872, 130322.3577568563], 
processed observation next is [1.0, 0.8260869565217391, 0.4728395061728396, 0.6366666666666667, 1.0, 1.0, 0.3006674194433533, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18136487621624528, 0.18136487621624542, 0.2506199187631852], 
reward next is 0.7494, 
noisyNet noise sample is [array([0.14122415], dtype=float32), 0.18252684]. 
=============================================
[2019-03-24 00:27:42,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3798958e-19 1.0000000e+00 2.0675064e-26 7.4919950e-24 5.4690315e-28], sum to 1.0000
[2019-03-24 00:27:42,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-24 00:27:42,719] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 64.66666666666667, 1.0, 2.0, 0.3369182329251828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426627.154279145, 426627.154279145, 120237.8356696304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1480800.0000, 
sim time next is 1481400.0000, 
raw observation next is [22.1, 65.5, 1.0, 2.0, 0.3382838226446179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428217.2636750843, 428217.2636750843, 120414.2985573978], 
processed observation next is [0.0, 0.13043478260869565, 0.3740740740740741, 0.655, 1.0, 1.0, 0.21224264600549753, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15293473702681581, 0.15293473702681581, 0.23156595876422653], 
reward next is 0.7684, 
noisyNet noise sample is [array([-0.9196662], dtype=float32), -0.16230221]. 
=============================================
[2019-03-24 00:27:42,751] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39575: loss 0.6322
[2019-03-24 00:27:42,753] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39575: learning rate 0.0001
[2019-03-24 00:27:42,820] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39604: loss 1.2527
[2019-03-24 00:27:42,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39604: learning rate 0.0001
[2019-03-24 00:27:43,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3535411e-20 1.0000000e+00 4.3478514e-28 9.3072583e-27 5.0816576e-29], sum to 1.0000
[2019-03-24 00:27:43,307] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5465
[2019-03-24 00:27:43,310] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 68.0, 1.0, 2.0, 0.3640569074943374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456639.400630095, 456639.4006300955, 123777.9236876952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [22.88333333333333, 66.5, 1.0, 2.0, 0.36651613332052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459275.9645618865, 459275.9645618865, 124102.623960142], 
processed observation next is [0.0, 0.21739130434782608, 0.4030864197530863, 0.665, 1.0, 1.0, 0.24585253966728574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16402713020067375, 0.16402713020067375, 0.2386588922310423], 
reward next is 0.7613, 
noisyNet noise sample is [array([-1.4511237], dtype=float32), -0.87509704]. 
=============================================
[2019-03-24 00:27:43,322] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39871: loss 0.1757
[2019-03-24 00:27:43,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39871: learning rate 0.0001
[2019-03-24 00:27:43,390] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39901: loss 1.1051
[2019-03-24 00:27:43,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39901: learning rate 0.0001
[2019-03-24 00:27:43,434] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39919: loss 1.2259
[2019-03-24 00:27:43,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39919: learning rate 0.0001
[2019-03-24 00:27:43,498] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39966: loss 0.5737
[2019-03-24 00:27:43,498] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39966: loss 0.7567
[2019-03-24 00:27:43,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39966: learning rate 0.0001
[2019-03-24 00:27:43,500] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39966: learning rate 0.0001
[2019-03-24 00:27:43,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40011: loss 0.0209
[2019-03-24 00:27:43,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40012: learning rate 0.0001
[2019-03-24 00:27:43,700] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40075: loss 0.4055
[2019-03-24 00:27:43,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40075: learning rate 0.0001
[2019-03-24 00:27:43,707] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40076: loss 0.4442
[2019-03-24 00:27:43,710] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40077: learning rate 0.0001
[2019-03-24 00:27:43,713] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40080: loss 0.4964
[2019-03-24 00:27:43,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40081: learning rate 0.0001
[2019-03-24 00:27:43,758] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40101: loss 0.2218
[2019-03-24 00:27:43,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40101: learning rate 0.0001
[2019-03-24 00:27:43,802] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40122: loss 0.0212
[2019-03-24 00:27:43,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40123: learning rate 0.0001
[2019-03-24 00:27:43,823] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40136: loss 0.0068
[2019-03-24 00:27:43,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40136: learning rate 0.0001
[2019-03-24 00:27:43,930] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8082724e-19 1.0000000e+00 2.1765459e-25 1.1841815e-23 1.1748472e-27], sum to 1.0000
[2019-03-24 00:27:43,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-24 00:27:43,942] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 38.0, 1.0, 2.0, 0.4385223940285022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535892.0774215152, 535892.0774215152, 133988.3035383107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1504200.0000, 
sim time next is 1504800.0000, 
raw observation next is [31.2, 37.0, 1.0, 2.0, 0.4414443186797329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 539102.6298717994, 539102.6298717989, 134409.1585452934], 
processed observation next is [0.0, 0.43478260869565216, 0.7111111111111111, 0.37, 1.0, 1.0, 0.3350527603330153, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19253665352564264, 0.19253665352564248, 0.25847915104864116], 
reward next is 0.7415, 
noisyNet noise sample is [array([-1.183282], dtype=float32), 0.3273093]. 
=============================================
[2019-03-24 00:27:43,965] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40217: loss 1.0367
[2019-03-24 00:27:43,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40218: learning rate 0.0001
[2019-03-24 00:27:44,026] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40253: loss 0.1140
[2019-03-24 00:27:44,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40253: learning rate 0.0001
[2019-03-24 00:27:47,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3292020e-14 1.0000000e+00 9.3740384e-18 3.1718636e-16 5.5609910e-19], sum to 1.0000
[2019-03-24 00:27:47,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0694
[2019-03-24 00:27:47,968] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333333, 56.16666666666667, 1.0, 2.0, 0.5099216858800019, 1.0, 1.0, 0.5099216858800019, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258316391061, 1251504.215165743, 1251504.215165743, 241962.2083112409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1590600.0000, 
sim time next is 1591200.0000, 
raw observation next is [25.0, 56.0, 1.0, 2.0, 0.9169535872697621, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.130970547018245, 6.9112, 121.9250544491591, 1250061.243350715, 1137519.992522327, 225230.3330873832], 
processed observation next is [1.0, 0.43478260869565216, 0.48148148148148145, 0.56, 1.0, 1.0, 0.9011352229401929, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02197705470182454, 0.0, 0.8094555684221788, 0.4464504440538268, 0.40625714018654535, 0.43313525593727537], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7875286], dtype=float32), 1.1144416]. 
=============================================
[2019-03-24 00:27:53,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0214050e-22 1.0000000e+00 6.6689789e-26 6.3803109e-25 4.9444216e-28], sum to 1.0000
[2019-03-24 00:27:53,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-24 00:27:53,174] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333333, 79.33333333333334, 1.0, 2.0, 0.6415639899744716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 811750.7665192467, 811750.7665192463, 168136.4597388207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1681800.0000, 
sim time next is 1682400.0000, 
raw observation next is [20.26666666666667, 78.66666666666667, 1.0, 2.0, 0.6967296914801593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880580.877161484, 880580.877161484, 178568.9790654641], 
processed observation next is [1.0, 0.4782608695652174, 0.3061728395061729, 0.7866666666666667, 1.0, 1.0, 0.638963918428761, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3144931704148157, 0.3144931704148157, 0.3434018828182002], 
reward next is 0.6566, 
noisyNet noise sample is [array([0.57856053], dtype=float32), -0.5306202]. 
=============================================
[2019-03-24 00:27:57,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4184166e-14 1.0000000e+00 7.8283000e-18 1.0757402e-16 5.2026884e-19], sum to 1.0000
[2019-03-24 00:27:57,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5089
[2019-03-24 00:27:57,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 88.16666666666667, 1.0, 2.0, 0.3899656431317965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488138.3618033805, 488138.3618033801, 127313.0346826939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1746600.0000, 
sim time next is 1747200.0000, 
raw observation next is [20.13333333333333, 87.33333333333334, 1.0, 2.0, 0.3710533933073112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464082.0078806899, 464082.0078806899, 124702.8367845206], 
processed observation next is [1.0, 0.21739130434782608, 0.30123456790123443, 0.8733333333333334, 1.0, 1.0, 0.25125403965156096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16574357424310354, 0.16574357424310354, 0.2398131476625396], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.6701338], dtype=float32), 2.1283538]. 
=============================================
[2019-03-24 00:27:58,415] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47520: loss 0.0139
[2019-03-24 00:27:58,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47520: learning rate 0.0001
[2019-03-24 00:27:58,497] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47560: loss 0.3276
[2019-03-24 00:27:58,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47560: learning rate 0.0001
[2019-03-24 00:27:59,137] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47878: loss 0.7369
[2019-03-24 00:27:59,139] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47878: learning rate 0.0001
[2019-03-24 00:27:59,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47918: loss 2.4943
[2019-03-24 00:27:59,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47919: learning rate 0.0001
[2019-03-24 00:27:59,233] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47928: loss 1.2472
[2019-03-24 00:27:59,235] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47928: learning rate 0.0001
[2019-03-24 00:27:59,253] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47935: loss 1.7474
[2019-03-24 00:27:59,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47936: learning rate 0.0001
[2019-03-24 00:27:59,381] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48000: loss 4.6571
[2019-03-24 00:27:59,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48000: learning rate 0.0001
[2019-03-24 00:27:59,404] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48012: loss 4.5938
[2019-03-24 00:27:59,406] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48012: learning rate 0.0001
[2019-03-24 00:27:59,420] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48020: loss 2.3534
[2019-03-24 00:27:59,422] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48020: learning rate 0.0001
[2019-03-24 00:27:59,433] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48020: loss 3.9315
[2019-03-24 00:27:59,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48020: learning rate 0.0001
[2019-03-24 00:27:59,466] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48037: loss 0.3221
[2019-03-24 00:27:59,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48038: learning rate 0.0001
[2019-03-24 00:27:59,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8976939e-14 1.0000000e+00 4.9218436e-19 2.5220657e-17 2.2209018e-21], sum to 1.0000
[2019-03-24 00:27:59,501] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5708
[2019-03-24 00:27:59,506] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48059: loss 2.9504
[2019-03-24 00:27:59,508] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.35, 85.5, 1.0, 2.0, 0.2991671463905153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382627.7960521247, 382627.7960521247, 115474.1115160139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [18.36666666666667, 85.66666666666666, 1.0, 2.0, 0.2989319299462199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 382194.828453599, 382194.8284535985, 115445.0034690849], 
processed observation next is [1.0, 0.8695652173913043, 0.2358024691358026, 0.8566666666666666, 1.0, 1.0, 0.16539515469788085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1364981530191425, 0.1364981530191423, 0.2220096220559325], 
reward next is 0.7780, 
noisyNet noise sample is [array([0.17595099], dtype=float32), -1.482878]. 
=============================================
[2019-03-24 00:27:59,508] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48060: learning rate 0.0001
[2019-03-24 00:27:59,722] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48170: loss 0.0132
[2019-03-24 00:27:59,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48170: learning rate 0.0001
[2019-03-24 00:27:59,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48209: loss 1.5579
[2019-03-24 00:27:59,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48209: learning rate 0.0001
[2019-03-24 00:27:59,898] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48254: loss 2.8622
[2019-03-24 00:27:59,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48254: learning rate 0.0001
[2019-03-24 00:28:00,071] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48335: loss 4.2622
[2019-03-24 00:28:00,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48336: learning rate 0.0001
[2019-03-24 00:28:03,431] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 00:28:03,432] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:28:03,432] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:28:03,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:28:03,433] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:28:03,434] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:28:03,435] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:28:03,438] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:28:03,438] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:28:03,439] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:28:03,439] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:28:03,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-24 00:28:03,451] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-24 00:28:03,474] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-24 00:28:03,498] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-24 00:28:03,540] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-24 00:28:11,511] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:28:11,512] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [15.33333333333333, 92.0, 1.0, 2.0, 0.2370770459902208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 305805.6686135262, 305805.6686135266, 92404.78513934505]
[2019-03-24 00:28:11,512] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:28:11,516] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3987496e-13 1.0000000e+00 1.0117481e-17 1.2696520e-15 6.1558988e-20], sampled 0.8064431588474809
[2019-03-24 00:28:29,070] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:28:29,072] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333334, 65.33333333333333, 1.0, 2.0, 0.4212302052743056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518333.6776650497, 518333.6776650497, 131563.5200044012]
[2019-03-24 00:28:29,074] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:28:29,081] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7941238e-14 1.0000000e+00 1.8356058e-18 2.8629176e-16 8.9613888e-21], sampled 0.19254587071718265
[2019-03-24 00:28:36,674] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:28:36,675] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.53205921333333, 110.8724352666667, 1.0, 2.0, 0.5453936950391611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650364.135879285, 650364.135879285, 150202.8617485741]
[2019-03-24 00:28:36,676] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:28:36,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1120583e-14 1.0000000e+00 9.3036395e-19 1.5828515e-16 4.1604123e-21], sampled 0.5309178914281694
[2019-03-24 00:28:46,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:28:46,403] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.58333333333333, 95.83333333333334, 1.0, 2.0, 0.6062859625711337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 702369.044389763, 702369.0443897626, 159712.2242095032]
[2019-03-24 00:28:46,403] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:28:46,406] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6132600e-14 1.0000000e+00 5.0373697e-19 9.2642316e-17 2.0805741e-21], sampled 0.8769543780430443
[2019-03-24 00:29:19,503] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:29:19,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.3, 91.5, 1.0, 2.0, 0.6849143019420356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780599.7943653632, 780599.7943653632, 173305.5138163908]
[2019-03-24 00:29:19,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:29:19,511] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.3855513e-14 1.0000000e+00 2.0549342e-18 3.1599316e-16 1.0176222e-20], sampled 0.52132102986428
[2019-03-24 00:29:27,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:29:27,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.18333333333333, 65.33333333333333, 1.0, 2.0, 0.6643590277923853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 757161.2888460736, 757161.2888460732, 169508.3580315512]
[2019-03-24 00:29:27,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:29:27,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3787568e-15 1.0000000e+00 9.3960423e-21 2.8644549e-18 2.3209750e-23], sampled 0.1652000957356169
[2019-03-24 00:29:31,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:29:31,730] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.5135135599078078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 605218.8372440727, 605218.8372440732, 144752.9059048585]
[2019-03-24 00:29:31,732] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:29:31,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.8710838e-14 1.0000000e+00 2.6330073e-18 3.9228592e-16 1.3465166e-20], sampled 0.38926594599837294
[2019-03-24 00:29:39,669] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.109919876]
[2019-03-24 00:29:39,670] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6938013438107191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790733.6189064619, 790733.6189064619, 174974.3650007933]
[2019-03-24 00:29:39,671] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:29:39,673] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9977638e-14 1.0000000e+00 6.0665467e-19 1.0896379e-16 2.5669816e-21], sampled 0.2643817194903272
[2019-03-24 00:29:49,249] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:29:49,370] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4311 2445354871.8656 746.0000
[2019-03-24 00:29:49,390] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:29:49,585] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:29:49,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:29:50,613] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 50000, evaluation results [50000.0, 8098.431051942187, 2445354871.865624, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:29:53,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3434271e-18 1.0000000e+00 1.5748881e-25 1.4562578e-22 4.5646812e-30], sum to 1.0000
[2019-03-24 00:29:53,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7008
[2019-03-24 00:29:53,799] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 91.66666666666667, 1.0, 2.0, 0.3763008874103568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467742.8858127754, 467742.8858127754, 125362.7133763666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1923600.0000, 
sim time next is 1924200.0000, 
raw observation next is [20.1, 91.5, 1.0, 2.0, 0.3768110927489469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468295.8093931106, 468295.8093931106, 125430.805986504], 
processed observation next is [1.0, 0.2608695652173913, 0.30000000000000004, 0.915, 1.0, 1.0, 0.25810844374874636, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16724850335468236, 0.16724850335468236, 0.24121308843558462], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.80407727], dtype=float32), 1.763516]. 
=============================================
[2019-03-24 00:29:56,328] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7578153e-15 1.0000000e+00 7.7208147e-20 6.8228908e-17 1.0915239e-21], sum to 1.0000
[2019-03-24 00:29:56,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3422
[2019-03-24 00:29:56,347] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.3629941758597088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455014.7011625302, 455014.7011625302, 123630.0060073544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1989600.0000, 
sim time next is 1990200.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.3621780852118634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453992.975178508, 453992.975178508, 123520.261797074], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 1.0, 1.0, 0.24068819668078978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16214034827803855, 0.16214034827803855, 0.23753896499437308], 
reward next is 0.7625, 
noisyNet noise sample is [array([1.5036224], dtype=float32), 0.5552901]. 
=============================================
[2019-03-24 00:29:57,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6947889e-15 1.0000000e+00 3.9621984e-18 1.7963661e-15 4.4040188e-22], sum to 1.0000
[2019-03-24 00:29:57,217] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7582
[2019-03-24 00:29:57,221] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 93.5, 1.0, 2.0, 0.3639462411847413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455719.4831342913, 455719.4831342913, 123750.0927304869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2003400.0000, 
sim time next is 2004000.0000, 
raw observation next is [19.3, 93.66666666666667, 1.0, 2.0, 0.3637807994185449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455400.4990456486, 455400.4990456486, 123725.9013506426], 
processed observation next is [0.0, 0.17391304347826086, 0.27037037037037037, 0.9366666666666668, 1.0, 1.0, 0.24259618978398204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16264303537344593, 0.16264303537344593, 0.2379344256743127], 
reward next is 0.7621, 
noisyNet noise sample is [array([-0.17463268], dtype=float32), 0.6333064]. 
=============================================
[2019-03-24 00:29:57,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.5781  ]
 [62.55437 ]
 [62.524418]
 [62.611412]
 [62.718052]], R is [[62.74048233]
 [62.87509918]
 [63.00852585]
 [63.14105988]
 [63.27256393]].
[2019-03-24 00:30:00,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5444322e-17 1.0000000e+00 1.1296535e-21 5.3423224e-20 5.7985098e-26], sum to 1.0000
[2019-03-24 00:30:00,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-24 00:30:00,260] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 77.16666666666667, 1.0, 2.0, 0.5655733001881633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659280.6906547546, 659280.6906547546, 152951.3003728054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2063400.0000, 
sim time next is 2064000.0000, 
raw observation next is [25.7, 77.33333333333334, 1.0, 2.0, 0.559975905935405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654338.1253912471, 654338.1253912471, 152086.2231920943], 
processed observation next is [0.0, 0.9130434782608695, 0.5074074074074074, 0.7733333333333334, 1.0, 1.0, 0.47616179278024406, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2336921876397311, 0.2336921876397311, 0.29247350613864287], 
reward next is 0.7075, 
noisyNet noise sample is [array([1.2207929], dtype=float32), 0.10837005]. 
=============================================
[2019-03-24 00:30:00,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[82.03459]
 [81.9572 ]
 [81.86421]
 [81.78754]
 [81.71411]], R is [[81.9839325 ]
 [81.86995697]
 [81.7554245 ]
 [81.64035797]
 [81.52471161]].
[2019-03-24 00:30:01,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55454: loss 0.0549
[2019-03-24 00:30:01,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55454: learning rate 0.0001
[2019-03-24 00:30:01,317] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55516: loss 0.2313
[2019-03-24 00:30:01,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55517: learning rate 0.0001
[2019-03-24 00:30:01,982] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55854: loss 0.2172
[2019-03-24 00:30:01,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55854: learning rate 0.0001
[2019-03-24 00:30:02,096] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55917: loss 0.0033
[2019-03-24 00:30:02,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55918: learning rate 0.0001
[2019-03-24 00:30:02,131] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55934: loss 0.0001
[2019-03-24 00:30:02,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55934: learning rate 0.0001
[2019-03-24 00:30:02,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55962: loss 0.1189
[2019-03-24 00:30:02,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55962: learning rate 0.0001
[2019-03-24 00:30:02,196] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55962: loss 0.2277
[2019-03-24 00:30:02,200] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55962: loss 0.3095
[2019-03-24 00:30:02,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55962: learning rate 0.0001
[2019-03-24 00:30:02,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55963: learning rate 0.0001
[2019-03-24 00:30:02,262] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55997: loss 0.4629
[2019-03-24 00:30:02,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55997: learning rate 0.0001
[2019-03-24 00:30:02,282] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56010: loss 0.3700
[2019-03-24 00:30:02,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56010: learning rate 0.0001
[2019-03-24 00:30:02,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56029: loss 0.3392
[2019-03-24 00:30:02,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56029: learning rate 0.0001
[2019-03-24 00:30:02,499] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56123: loss 0.3630
[2019-03-24 00:30:02,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56123: learning rate 0.0001
[2019-03-24 00:30:02,678] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56213: loss 0.0176
[2019-03-24 00:30:02,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56213: learning rate 0.0001
[2019-03-24 00:30:02,787] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56270: loss 0.3480
[2019-03-24 00:30:02,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56270: learning rate 0.0001
[2019-03-24 00:30:02,884] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56316: loss 0.4131
[2019-03-24 00:30:02,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56316: learning rate 0.0001
[2019-03-24 00:30:02,931] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56345: loss 0.2707
[2019-03-24 00:30:02,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56345: learning rate 0.0001
[2019-03-24 00:30:16,401] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63434: loss 0.6389
[2019-03-24 00:30:16,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63435: learning rate 0.0001
[2019-03-24 00:30:16,652] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63566: loss 1.3382
[2019-03-24 00:30:16,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63566: learning rate 0.0001
[2019-03-24 00:30:16,885] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0857052e-11 1.0000000e+00 1.3054654e-15 7.3579753e-15 8.8044529e-17], sum to 1.0000
[2019-03-24 00:30:16,891] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5286
[2019-03-24 00:30:16,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1370090.964187688 W.
[2019-03-24 00:30:16,902] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.9, 37.0, 1.0, 2.0, 0.5715066370549783, 1.0, 1.0, 0.5715066370549783, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1370090.964187688, 1370090.964187688, 261294.9378160174], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2388600.0000, 
sim time next is 2389200.0000, 
raw observation next is [30.86666666666667, 37.0, 1.0, 2.0, 0.4333421770312159, 1.0, 2.0, 0.4333421770312159, 1.0, 1.0, 0.6952828572734548, 6.9112, 6.9112, 121.94756008, 1540009.270101481, 1540009.270101481, 311909.9732073565], 
processed observation next is [1.0, 0.6521739130434783, 0.6987654320987656, 0.37, 1.0, 1.0, 0.32540735360859036, 1.0, 1.0, 0.32540735360859036, 1.0, 0.5, 0.6191035715918185, 0.0, 0.0, 0.8096049824067558, 0.5500033107505289, 0.5500033107505289, 0.5998268715526087], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.672692], dtype=float32), 0.38219813]. 
=============================================
[2019-03-24 00:30:17,172] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63837: loss 1.3095
[2019-03-24 00:30:17,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63838: learning rate 0.0001
[2019-03-24 00:30:17,255] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63883: loss 0.9211
[2019-03-24 00:30:17,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63884: learning rate 0.0001
[2019-03-24 00:30:17,305] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63908: loss 0.1523
[2019-03-24 00:30:17,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63908: learning rate 0.0001
[2019-03-24 00:30:17,356] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63934: loss 0.5735
[2019-03-24 00:30:17,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63935: learning rate 0.0001
[2019-03-24 00:30:17,373] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63946: loss 0.0528
[2019-03-24 00:30:17,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63946: learning rate 0.0001
[2019-03-24 00:30:17,378] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63946: loss 0.1197
[2019-03-24 00:30:17,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63946: learning rate 0.0001
[2019-03-24 00:30:17,422] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63966: loss 0.2898
[2019-03-24 00:30:17,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63966: learning rate 0.0001
[2019-03-24 00:30:17,588] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64051: loss 0.0629
[2019-03-24 00:30:17,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64052: learning rate 0.0001
[2019-03-24 00:30:17,632] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64074: loss 0.9633
[2019-03-24 00:30:17,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64075: learning rate 0.0001
[2019-03-24 00:30:17,642] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64079: loss 0.0734
[2019-03-24 00:30:17,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64079: learning rate 0.0001
[2019-03-24 00:30:17,990] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64261: loss 0.4277
[2019-03-24 00:30:17,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64261: learning rate 0.0001
[2019-03-24 00:30:18,073] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64302: loss 0.0870
[2019-03-24 00:30:18,075] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64303: learning rate 0.0001
[2019-03-24 00:30:18,097] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64314: loss 0.0617
[2019-03-24 00:30:18,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64314: learning rate 0.0001
[2019-03-24 00:30:18,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64369: loss 1.0641
[2019-03-24 00:30:18,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64369: learning rate 0.0001
[2019-03-24 00:30:18,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0520641e-16 1.0000000e+00 4.1692097e-23 1.9694037e-22 3.5384531e-25], sum to 1.0000
[2019-03-24 00:30:18,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1437
[2019-03-24 00:30:18,856] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 61.66666666666667, 1.0, 2.0, 0.3811058109836294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474904.7333167108, 474904.7333167108, 126045.9315545064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2414400.0000, 
sim time next is 2415000.0000, 
raw observation next is [23.91666666666666, 62.83333333333334, 1.0, 2.0, 0.3815154235522328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475508.6745527202, 475508.6745527197, 126104.1635692375], 
processed observation next is [1.0, 0.9565217391304348, 0.4413580246913578, 0.6283333333333334, 1.0, 1.0, 0.2637088375621819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1698245266259715, 0.1698245266259713, 0.24250800686391827], 
reward next is 0.7575, 
noisyNet noise sample is [array([-0.12214106], dtype=float32), 2.887692]. 
=============================================
[2019-03-24 00:30:18,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.732567]
 [63.671394]
 [63.6121  ]
 [63.54951 ]
 [63.482212]], R is [[63.91923904]
 [64.03765106]
 [64.15491486]
 [64.27100372]
 [64.38576508]].
[2019-03-24 00:30:19,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4771024e-14 1.0000000e+00 2.7179756e-19 9.1379767e-18 1.1945727e-21], sum to 1.0000
[2019-03-24 00:30:19,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6906
[2019-03-24 00:30:19,924] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 75.16666666666667, 1.0, 2.0, 0.3075376143696739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395790.8896638951, 395790.8896638951, 116505.5377313965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434200.0000, 
sim time next is 2434800.0000, 
raw observation next is [18.76666666666667, 76.33333333333334, 1.0, 2.0, 0.2759191550640063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355137.9412800927, 355137.9412800922, 112645.2314566344], 
processed observation next is [1.0, 0.17391304347826086, 0.2506172839506174, 0.7633333333333334, 1.0, 1.0, 0.13799899412381705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12683497902860452, 0.12683497902860436, 0.2166254451089123], 
reward next is 0.7834, 
noisyNet noise sample is [array([0.3440745], dtype=float32), 1.2132583]. 
=============================================
[2019-03-24 00:30:20,102] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6912031e-15 1.0000000e+00 7.3438832e-19 7.5572586e-19 2.5846274e-22], sum to 1.0000
[2019-03-24 00:30:20,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6121
[2019-03-24 00:30:20,299] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 42.0, 1.0, 2.0, 0.4603023977506367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572696.1778646032, 572696.1778646028, 137488.972846486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2448000.0000, 
sim time next is 2448600.0000, 
raw observation next is [28.55, 40.83333333333334, 1.0, 2.0, 0.690414133870927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858567.6507586589, 858567.6507586589, 177101.1202064626], 
processed observation next is [1.0, 0.34782608695652173, 0.612962962962963, 0.40833333333333344, 1.0, 1.0, 0.6314453974653893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3066313038423782, 0.3066313038423782, 0.3405790773201204], 
reward next is 0.6594, 
noisyNet noise sample is [array([0.5433492], dtype=float32), 0.60622394]. 
=============================================
[2019-03-24 00:30:31,923] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71373: loss 0.1436
[2019-03-24 00:30:31,925] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71374: learning rate 0.0001
[2019-03-24 00:30:32,197] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71511: loss 0.1778
[2019-03-24 00:30:32,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71512: learning rate 0.0001
[2019-03-24 00:30:32,851] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71839: loss 0.0027
[2019-03-24 00:30:32,853] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71840: learning rate 0.0001
[2019-03-24 00:30:32,928] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71882: loss 0.0001
[2019-03-24 00:30:32,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71883: learning rate 0.0001
[2019-03-24 00:30:32,961] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71898: loss 0.0557
[2019-03-24 00:30:32,963] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71898: loss 0.0009
[2019-03-24 00:30:32,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71898: learning rate 0.0001
[2019-03-24 00:30:32,964] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71898: learning rate 0.0001
[2019-03-24 00:30:33,106] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71971: loss 0.5101
[2019-03-24 00:30:33,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71971: learning rate 0.0001
[2019-03-24 00:30:33,148] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71988: loss 0.8493
[2019-03-24 00:30:33,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71988: learning rate 0.0001
[2019-03-24 00:30:33,312] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72067: loss 0.4121
[2019-03-24 00:30:33,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72067: learning rate 0.0001
[2019-03-24 00:30:33,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72077: loss 0.2538
[2019-03-24 00:30:33,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72078: learning rate 0.0001
[2019-03-24 00:30:33,343] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72083: loss 0.1537
[2019-03-24 00:30:33,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72083: learning rate 0.0001
[2019-03-24 00:30:33,405] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72114: loss 0.0141
[2019-03-24 00:30:33,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72114: learning rate 0.0001
[2019-03-24 00:30:33,662] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72242: loss 0.0794
[2019-03-24 00:30:33,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72242: learning rate 0.0001
[2019-03-24 00:30:33,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72279: loss 0.3667
[2019-03-24 00:30:33,733] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72280: loss 0.3619
[2019-03-24 00:30:33,734] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72279: learning rate 0.0001
[2019-03-24 00:30:33,735] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72280: learning rate 0.0001
[2019-03-24 00:30:33,850] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72333: loss 0.6403
[2019-03-24 00:30:33,852] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72333: learning rate 0.0001
[2019-03-24 00:30:35,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5329541e-11 1.0000000e+00 1.4774971e-13 6.5996729e-15 5.8018076e-18], sum to 1.0000
[2019-03-24 00:30:35,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1831
[2019-03-24 00:30:35,540] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 48.66666666666667, 1.0, 2.0, 0.580554777741109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 673690.0549798673, 673690.0549798668, 155342.0775936184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743800.0000, 
sim time next is 2744400.0000, 
raw observation next is [31.33333333333334, 51.33333333333334, 1.0, 2.0, 0.5915686204277716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 682794.8133842774, 682794.8133842769, 157051.9921364271], 
processed observation next is [0.0, 0.782608695652174, 0.7160493827160496, 0.5133333333333334, 1.0, 1.0, 0.5137721671759186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24385529049438479, 0.24385529049438462, 0.3020230618008214], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.03963474], dtype=float32), 1.0640374]. 
=============================================
[2019-03-24 00:30:39,299] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 00:30:39,299] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:30:39,301] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:39,303] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:30:39,304] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:30:39,304] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:39,305] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:39,305] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:30:39,306] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:30:39,307] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:39,307] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:39,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-24 00:30:39,350] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-24 00:30:39,380] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-24 00:30:39,380] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-24 00:30:39,382] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-24 00:30:52,364] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:30:52,366] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.2, 47.66666666666666, 1.0, 2.0, 0.2007389610979715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 258925.2632185668, 258925.2632185668, 74436.93257834748]
[2019-03-24 00:30:52,368] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:30:52,371] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.2998014e-08 9.9999988e-01 1.2412114e-10 1.1038531e-10 9.1832878e-13], sampled 0.6974292039022884
[2019-03-24 00:30:55,379] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:30:55,379] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.59247062, 68.86013297, 1.0, 2.0, 0.7070834085250413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871556.0966575338, 871556.0966575338, 180145.5738887746]
[2019-03-24 00:30:55,380] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:30:55,385] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0245544e-07 9.9999988e-01 1.6689557e-10 1.4840007e-10 1.3158242e-12], sampled 0.15376407729870634
[2019-03-24 00:30:55,523] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:30:55,524] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.33333333333333, 68.16666666666666, 1.0, 2.0, 0.3245810427427166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 411999.2800417346, 411999.2800417341, 118654.8623922102]
[2019-03-24 00:30:55,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:30:55,530] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6883960e-08 1.0000000e+00 2.5311673e-11 2.2552120e-11 1.3333849e-13], sampled 0.4211212087056818
[2019-03-24 00:31:01,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:31:01,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.15499637333333, 79.38329173666668, 1.0, 2.0, 0.3854676438322684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477338.6908014772, 477338.6908014772, 126585.2989189719]
[2019-03-24 00:31:01,264] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:31:01,268] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8397864e-08 1.0000000e+00 4.1832704e-11 3.7257909e-11 2.4538130e-13], sampled 0.8474746277849027
[2019-03-24 00:31:21,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:31:21,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.1, 65.0, 1.0, 2.0, 0.9329158422589005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260164438045, 1063444.333656984, 1063444.333656984, 224935.3113954352]
[2019-03-24 00:31:21,311] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:31:21,317] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.87411736e-08 9.99999881e-01 1.15112524e-10 1.02381444e-10
 8.38284412e-13], sampled 0.9882305690066775
[2019-03-24 00:31:27,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:31:27,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.417858365, 97.498305665, 1.0, 2.0, 0.6652376106978679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758163.0934801196, 758163.0934801201, 169665.5526644232]
[2019-03-24 00:31:27,093] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:31:27,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8663004e-08 1.0000000e+00 2.7681812e-11 2.4658733e-11 1.4866077e-13], sampled 0.16911301355476005
[2019-03-24 00:31:55,003] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:31:55,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.19032416333333, 93.97006125666667, 1.0, 2.0, 0.5534866903931189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649842.0831502612, 649842.0831502607, 151140.9091805895]
[2019-03-24 00:31:55,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:31:55,009] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6054830e-08 1.0000000e+00 1.2229330e-11 1.0899379e-11 5.5149092e-14], sampled 0.9054187291949332
[2019-03-24 00:32:25,260] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7937 2120437309.6851 430.0000
[2019-03-24 00:32:25,417] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1399733]
[2019-03-24 00:32:25,417] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.51889437, 83.35072270500001, 1.0, 2.0, 0.3860899447108995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478269.6080785866, 478269.6080785866, 126674.7742187363]
[2019-03-24 00:32:25,418] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:32:25,419] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.2670843e-08 1.0000000e+00 1.9896522e-11 1.7732281e-11 9.9552880e-14], sampled 0.5779483106544392
[2019-03-24 00:32:25,942] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-03-24 00:32:26,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-24 00:32:26,055] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-03-24 00:32:26,070] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1308 2195031930.5214 572.0000
[2019-03-24 00:32:27,085] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 75000, evaluation results [75000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8922.793663302313, 2120437309.6850784, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8700.13078353732, 2195031930.5214496, 572.0]
[2019-03-24 00:32:27,639] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3084537e-05 9.9998689e-01 3.4810220e-08 3.9072916e-08 7.1756205e-09], sum to 1.0000
[2019-03-24 00:32:27,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9098
[2019-03-24 00:32:27,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2414691.013456374 W.
[2019-03-24 00:32:27,654] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.83333333333333, 57.33333333333333, 1.0, 2.0, 0.7843420943569126, 1.0, 2.0, 0.705535709154891, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2414691.013456374, 2414691.013456374, 452673.1715552536], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2819400.0000, 
sim time next is 2820000.0000, 
raw observation next is [32.86666666666667, 57.66666666666667, 1.0, 2.0, 1.011784510123337, 1.0, 2.0, 1.011784510123337, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9258597760883, 2308413.573655521, 2308413.573655522, 439039.4976208291], 
processed observation next is [1.0, 0.6521739130434783, 0.7728395061728395, 0.5766666666666667, 1.0, 1.0, 1.0140291787182583, 1.0, 1.0, 1.0140291787182583, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094609149555076, 0.8244334191626861, 0.8244334191626864, 0.8443067261939021], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29707098], dtype=float32), 0.27589405]. 
=============================================
[2019-03-24 00:32:27,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[16.705822]
 [17.01311 ]
 [16.99377 ]
 [16.818983]
 [16.715258]], R is [[16.58011246]
 [16.543787  ]
 [16.3783493 ]
 [16.39394951]
 [16.39928436]].
[2019-03-24 00:32:28,921] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2641972e-20 1.0000000e+00 2.8627377e-27 3.4993853e-28 8.7271475e-31], sum to 1.0000
[2019-03-24 00:32:28,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4803
[2019-03-24 00:32:28,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.7052093528421278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834916.6055221698, 834916.6055221694, 178590.6699608936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2864400.0000, 
sim time next is 2865000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.6652779014483942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 787748.5570661663, 787748.5570661672, 171037.2949002389], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.6015213112480883, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2813387703807737, 0.28133877038077404, 0.3289178748081517], 
reward next is 0.6711, 
noisyNet noise sample is [array([-1.1411319], dtype=float32), -0.06882733]. 
=============================================
[2019-03-24 00:32:28,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.85246 ]
 [58.959934]
 [59.304806]
 [59.141277]
 [59.550034]], R is [[58.9852829 ]
 [59.05198669]
 [59.07527542]
 [59.10096359]
 [59.13624573]].
[2019-03-24 00:32:30,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8659745e-17 1.0000000e+00 1.0301224e-24 2.8208426e-25 1.4413809e-28], sum to 1.0000
[2019-03-24 00:32:30,824] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3312
[2019-03-24 00:32:30,834] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5572084894482441, 1.0, 2.0, 0.5572084894482441, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1280979.947604002, 1280979.947604002, 254151.5471202263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2887200.0000, 
sim time next is 2887800.0000, 
raw observation next is [23.21666666666667, 92.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.464074153295416, 6.9112, 121.9237477171331, 1477638.086166518, 1194522.43326652, 247314.7741550023], 
processed observation next is [1.0, 0.43478260869565216, 0.4154320987654322, 0.9233333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05528741532954155, 0.0, 0.8094468930804316, 0.5277278879166136, 0.42661515473804285, 0.47560533491346596], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6617003], dtype=float32), 0.32432312]. 
=============================================
[2019-03-24 00:32:31,377] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9030931e-10 1.0000000e+00 2.7766151e-15 4.1637252e-16 2.6989676e-17], sum to 1.0000
[2019-03-24 00:32:31,383] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5435
[2019-03-24 00:32:31,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1347020.536622916 W.
[2019-03-24 00:32:31,398] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3938224035196189, 1.0, 2.0, 0.3938224035196189, 1.0, 2.0, 0.6269780923034933, 6.9112, 6.9112, 121.94756008, 1347020.536622916, 1347020.536622916, 294386.5794668831], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2885400.0000, 
sim time next is 2886000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.6022603714660948, 1.0, 2.0, 0.6022603714660948, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1383717.55330633, 1383717.55330633, 269332.1086218428], 
processed observation next is [1.0, 0.391304347826087, 0.4074074074074074, 0.94, 1.0, 1.0, 0.5265004422215414, 1.0, 1.0, 0.5265004422215414, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4941848404665464, 0.4941848404665464, 0.517946362734313], 
reward next is 0.4821, 
noisyNet noise sample is [array([-0.05028887], dtype=float32), 1.2679038]. 
=============================================
[2019-03-24 00:32:31,414] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[30.787094]
 [31.337439]
 [31.919998]
 [33.15154 ]
 [33.432087]], R is [[30.72145462]
 [30.84811211]
 [30.98610497]
 [31.08953476]
 [30.77863884]].
[2019-03-24 00:32:32,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6574906e-18 1.0000000e+00 6.1733524e-26 9.0418116e-28 4.3995680e-30], sum to 1.0000
[2019-03-24 00:32:32,693] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7070
[2019-03-24 00:32:32,698] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 83.16666666666666, 1.0, 2.0, 0.6733229765523759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767382.4977451237, 767382.4977451237, 171157.1265587537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2915400.0000, 
sim time next is 2916000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6735849532096242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767681.2206168383, 767681.2206168383, 171204.9027769072], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6114106585828859, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27417186450601366, 0.27417186450601366, 0.32924019764789847], 
reward next is 0.6708, 
noisyNet noise sample is [array([0.29262748], dtype=float32), 1.7342732]. 
=============================================
[2019-03-24 00:32:32,712] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.656662]
 [62.500282]
 [61.8004  ]
 [60.999527]
 [59.93273 ]], R is [[64.40779114]
 [64.43456268]
 [64.46107483]
 [64.4881134 ]
 [64.51113129]].
[2019-03-24 00:32:34,843] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5186409e-19 1.0000000e+00 1.8638506e-26 8.1901875e-28 5.1863093e-31], sum to 1.0000
[2019-03-24 00:32:34,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-24 00:32:34,854] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 88.66666666666666, 1.0, 2.0, 0.8386455026268425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 955917.1746342498, 955917.1746342493, 204047.8747664611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2965200.0000, 
sim time next is 2965800.0000, 
raw observation next is [25.41666666666666, 87.33333333333333, 1.0, 2.0, 0.8190852415208293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933608.1308864435, 933608.1308864435, 199908.2563580476], 
processed observation next is [1.0, 0.30434782608695654, 0.49691358024691334, 0.8733333333333333, 1.0, 1.0, 0.7846252875247968, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33343147531658696, 0.33343147531658696, 0.38443895453470694], 
reward next is 0.6156, 
noisyNet noise sample is [array([-0.13730814], dtype=float32), 0.5542573]. 
=============================================
[2019-03-24 00:32:35,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79511: loss 170.5175
[2019-03-24 00:32:35,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79512: learning rate 0.0001
[2019-03-24 00:32:35,951] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79546: loss 170.6872
[2019-03-24 00:32:35,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79546: learning rate 0.0001
[2019-03-24 00:32:36,416] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79715: loss 214.3297
[2019-03-24 00:32:36,418] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79715: learning rate 0.0001
[2019-03-24 00:32:36,674] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79785: loss 127.3875
[2019-03-24 00:32:36,677] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79786: learning rate 0.0001
[2019-03-24 00:32:37,095] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79940: loss 180.4915
[2019-03-24 00:32:37,096] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79940: learning rate 0.0001
[2019-03-24 00:32:37,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79956: loss 141.0996
[2019-03-24 00:32:37,265] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79957: learning rate 0.0001
[2019-03-24 00:32:37,426] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79978: loss -11.0540
[2019-03-24 00:32:37,427] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79978: learning rate 0.0001
[2019-03-24 00:32:37,702] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80054: loss 165.4339
[2019-03-24 00:32:37,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80054: learning rate 0.0001
[2019-03-24 00:32:37,848] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80069: loss 16.8202
[2019-03-24 00:32:37,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80070: learning rate 0.0001
[2019-03-24 00:32:37,859] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80076: loss 240.3577
[2019-03-24 00:32:37,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80076: learning rate 0.0001
[2019-03-24 00:32:38,167] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80096: loss 173.2638
[2019-03-24 00:32:38,168] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80096: learning rate 0.0001
[2019-03-24 00:32:38,404] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80158: loss 178.2486
[2019-03-24 00:32:38,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80158: learning rate 0.0001
[2019-03-24 00:32:38,409] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80160: loss 135.3100
[2019-03-24 00:32:38,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80161: learning rate 0.0001
[2019-03-24 00:32:38,859] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80264: loss 118.2769
[2019-03-24 00:32:38,860] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80264: loss 241.4992
[2019-03-24 00:32:38,861] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80264: learning rate 0.0001
[2019-03-24 00:32:38,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80264: learning rate 0.0001
[2019-03-24 00:32:39,174] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80281: loss 39.4111
[2019-03-24 00:32:39,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80281: learning rate 0.0001
[2019-03-24 00:32:53,045] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87387: loss 0.0478
[2019-03-24 00:32:53,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87387: learning rate 0.0001
[2019-03-24 00:32:53,311] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87533: loss 0.7580
[2019-03-24 00:32:53,312] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87533: learning rate 0.0001
[2019-03-24 00:32:53,778] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87777: loss 0.0841
[2019-03-24 00:32:53,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87777: learning rate 0.0001
[2019-03-24 00:32:53,918] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87853: loss 0.0235
[2019-03-24 00:32:53,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87854: learning rate 0.0001
[2019-03-24 00:32:54,118] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87954: loss 0.2333
[2019-03-24 00:32:54,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87954: learning rate 0.0001
[2019-03-24 00:32:54,168] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87983: loss 0.3008
[2019-03-24 00:32:54,169] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87983: learning rate 0.0001
[2019-03-24 00:32:54,185] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87990: loss 0.3941
[2019-03-24 00:32:54,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87992: learning rate 0.0001
[2019-03-24 00:32:54,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87998: loss 0.0481
[2019-03-24 00:32:54,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87998: learning rate 0.0001
[2019-03-24 00:32:54,215] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88001: loss 0.0905
[2019-03-24 00:32:54,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88001: learning rate 0.0001
[2019-03-24 00:32:54,324] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88062: loss 0.0805
[2019-03-24 00:32:54,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88062: learning rate 0.0001
[2019-03-24 00:32:54,391] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88092: loss 0.2670
[2019-03-24 00:32:54,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88093: learning rate 0.0001
[2019-03-24 00:32:54,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88094: loss 0.2500
[2019-03-24 00:32:54,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88094: learning rate 0.0001
[2019-03-24 00:32:54,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4059267e-18 1.0000000e+00 1.3915619e-27 1.7225582e-25 2.2604322e-29], sum to 1.0000
[2019-03-24 00:32:54,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3402
[2019-03-24 00:32:54,428] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 93.5, 1.0, 2.0, 0.4888348380936035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588794.5200696108, 588794.5200696108, 141355.0226428295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3299400.0000, 
sim time next is 3300000.0000, 
raw observation next is [21.8, 93.33333333333334, 1.0, 2.0, 0.4847058664667073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584532.0905157172, 584532.0905157176, 140737.8677213524], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.9333333333333335, 1.0, 1.0, 0.3865546029365563, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20876146089847042, 0.20876146089847059, 0.2706497456179854], 
reward next is 0.7294, 
noisyNet noise sample is [array([-1.476942], dtype=float32), -0.7727101]. 
=============================================
[2019-03-24 00:32:54,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[56.294636]
 [56.287354]
 [56.274853]
 [56.40031 ]
 [56.439133]], R is [[56.46583176]
 [56.62933731]
 [56.79012299]
 [56.94846344]
 [57.10466766]].
[2019-03-24 00:32:54,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88118: loss 0.2888
[2019-03-24 00:32:54,451] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88120: learning rate 0.0001
[2019-03-24 00:32:54,511] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88157: loss 0.1162
[2019-03-24 00:32:54,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88160: learning rate 0.0001
[2019-03-24 00:32:54,986] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88399: loss 0.1568
[2019-03-24 00:32:54,989] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88401: loss 0.2858
[2019-03-24 00:32:54,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88399: learning rate 0.0001
[2019-03-24 00:32:54,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88401: learning rate 0.0001
[2019-03-24 00:32:55,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3764943e-19 1.0000000e+00 1.1773944e-29 3.2870549e-28 7.6904071e-31], sum to 1.0000
[2019-03-24 00:32:55,693] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4306
[2019-03-24 00:32:55,700] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6577575185660002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 749633.9562521745, 749633.956252174, 168299.5946329774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3329400.0000, 
sim time next is 3330000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6595120227149743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751634.5122163635, 751634.5122163635, 168619.1155783043], 
processed observation next is [0.0, 0.5652173913043478, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5946571698987789, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2684408972201298, 0.2684408972201298, 0.3242675299582775], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.46639562], dtype=float32), -0.25465435]. 
=============================================
[2019-03-24 00:32:55,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.21172 ]
 [64.235435]
 [64.26404 ]
 [64.29376 ]
 [64.327034]], R is [[64.25001526]
 [64.28386688]
 [64.31797028]
 [64.35224152]
 [64.3868866 ]].
[2019-03-24 00:33:00,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2527284e-12 1.0000000e+00 4.1103822e-17 7.1366483e-17 1.5023147e-19], sum to 1.0000
[2019-03-24 00:33:00,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3961
[2019-03-24 00:33:00,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1994345.334559676 W.
[2019-03-24 00:33:00,400] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.85, 70.0, 1.0, 2.0, 0.8742810372077109, 1.0, 2.0, 0.8742810372077109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1994345.334559676, 1994345.334559676, 375404.3675462741], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [29.06666666666666, 69.0, 1.0, 2.0, 0.9153261364507121, 1.0, 2.0, 0.9153261364507121, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2088083.850890046, 2088083.850890046, 393713.2888863414], 
processed observation next is [1.0, 0.43478260869565216, 0.6320987654320985, 0.69, 1.0, 1.0, 0.899197781488943, 1.0, 1.0, 0.899197781488943, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7457442324607307, 0.7457442324607307, 0.7571409401660412], 
reward next is 0.2429, 
noisyNet noise sample is [array([0.27844828], dtype=float32), -0.04291621]. 
=============================================
[2019-03-24 00:33:00,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[37.162582]
 [36.58352 ]
 [36.058365]
 [35.735035]
 [36.127884]], R is [[37.62799454]
 [37.52978516]
 [37.47423935]
 [37.40923309]
 [37.37652969]].
[2019-03-24 00:33:08,606] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95448: loss -17.6605
[2019-03-24 00:33:08,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95448: learning rate 0.0001
[2019-03-24 00:33:08,999] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95640: loss -13.5349
[2019-03-24 00:33:09,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95644: learning rate 0.0001
[2019-03-24 00:33:09,256] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95766: loss 60.5019
[2019-03-24 00:33:09,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95766: learning rate 0.0001
[2019-03-24 00:33:09,478] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95876: loss 84.6764
[2019-03-24 00:33:09,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95876: learning rate 0.0001
[2019-03-24 00:33:09,527] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95900: loss 38.7514
[2019-03-24 00:33:09,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95900: learning rate 0.0001
[2019-03-24 00:33:09,562] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95913: loss 36.3079
[2019-03-24 00:33:09,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95914: learning rate 0.0001
[2019-03-24 00:33:09,659] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95964: loss -18.8648
[2019-03-24 00:33:09,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95964: learning rate 0.0001
[2019-03-24 00:33:09,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95985: loss 69.8798
[2019-03-24 00:33:09,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95987: learning rate 0.0001
[2019-03-24 00:33:09,721] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95989: loss 48.0981
[2019-03-24 00:33:09,723] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95989: learning rate 0.0001
[2019-03-24 00:33:09,826] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96046: loss 10.6150
[2019-03-24 00:33:09,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96046: learning rate 0.0001
[2019-03-24 00:33:09,954] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96106: loss -46.6899
[2019-03-24 00:33:09,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96106: learning rate 0.0001
[2019-03-24 00:33:10,047] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96152: loss 11.7565
[2019-03-24 00:33:10,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96152: learning rate 0.0001
[2019-03-24 00:33:10,103] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96178: loss -57.8226
[2019-03-24 00:33:10,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96179: learning rate 0.0001
[2019-03-24 00:33:10,220] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96234: loss -53.1065
[2019-03-24 00:33:10,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96234: learning rate 0.0001
[2019-03-24 00:33:10,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3336866e-17 1.0000000e+00 6.7256409e-27 1.4523562e-24 9.8047968e-29], sum to 1.0000
[2019-03-24 00:33:10,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3219
[2019-03-24 00:33:10,356] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 81.66666666666666, 1.0, 2.0, 0.5459478418728597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637941.6087005252, 637941.6087005252, 149767.1986904131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3606000.0000, 
sim time next is 3606600.0000, 
raw observation next is [25.05, 82.33333333333334, 1.0, 2.0, 0.5505292224772917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642702.2026959194, 642702.2026959194, 150495.0909366812], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.8233333333333335, 1.0, 1.0, 0.4649157410443949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22953650096282838, 0.22953650096282838, 0.2894136364166946], 
reward next is 0.7106, 
noisyNet noise sample is [array([0.6423593], dtype=float32), 0.99873817]. 
=============================================
[2019-03-24 00:33:10,449] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96350: loss -3.4398
[2019-03-24 00:33:10,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96350: learning rate 0.0001
[2019-03-24 00:33:10,734] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96487: loss 48.1560
[2019-03-24 00:33:10,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96489: learning rate 0.0001
[2019-03-24 00:33:13,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3448635e-19 1.0000000e+00 9.6954530e-28 2.0631833e-24 6.0866768e-31], sum to 1.0000
[2019-03-24 00:33:13,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5997
[2019-03-24 00:33:13,052] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.83333333333334, 1.0, 2.0, 0.6548733389864867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 775864.9462158735, 775864.946215873, 169131.7002309288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3651000.0000, 
sim time next is 3651600.0000, 
raw observation next is [22.0, 99.66666666666667, 1.0, 2.0, 0.5802899139998906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687709.3409518662, 687709.3409518662, 155906.5039325657], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9966666666666667, 1.0, 1.0, 0.5003451357141555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2456104789113808, 0.2456104789113808, 0.29982019987031866], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.03148497], dtype=float32), 0.5029602]. 
=============================================
[2019-03-24 00:33:13,576] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1174357e-13 1.0000000e+00 5.4246567e-18 5.7683989e-17 3.6735421e-20], sum to 1.0000
[2019-03-24 00:33:13,585] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0679
[2019-03-24 00:33:13,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1580384.037442825 W.
[2019-03-24 00:33:13,600] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 86.0, 1.0, 2.0, 0.6929691811935832, 1.0, 2.0, 0.6929691811935832, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1580384.037442825, 1580384.037442826, 301511.9350892366], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3679200.0000, 
sim time next is 3679800.0000, 
raw observation next is [26.16666666666667, 86.5, 1.0, 2.0, 0.4815604924926549, 1.0, 2.0, 0.4815604924926549, 1.0, 1.0, 0.7666599873786368, 6.911199999999999, 6.9112, 121.94756008, 1647430.448607853, 1647430.448607854, 334630.9271845699], 
processed observation next is [1.0, 0.6086956521739131, 0.5246913580246916, 0.865, 1.0, 1.0, 0.3828101101103035, 1.0, 1.0, 0.3828101101103035, 1.0, 0.5, 0.708324984223296, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5883680173599475, 0.5883680173599479, 0.6435210138164805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11757405], dtype=float32), 0.028088346]. 
=============================================
[2019-03-24 00:33:16,166] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6344655e-15 1.0000000e+00 2.2969371e-24 9.5927632e-23 3.1366629e-27], sum to 1.0000
[2019-03-24 00:33:16,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4061
[2019-03-24 00:33:16,179] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6734058294659245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 767476.9720285487, 767476.9720285492, 171168.8741508377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3704400.0000, 
sim time next is 3705000.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.6695821858961557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763117.0169496551, 763117.0169496547, 170464.0102805504], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.6066454594001853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27254179176773397, 0.2725417917677338, 0.32781540438567386], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.1841409], dtype=float32), 0.43186042]. 
=============================================
[2019-03-24 00:33:16,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9723353e-15 1.0000000e+00 1.4609644e-23 1.4907757e-21 1.5318938e-25], sum to 1.0000
[2019-03-24 00:33:16,201] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[53.83376 ]
 [53.57112 ]
 [53.453632]
 [53.21468 ]
 [53.212097]], R is [[54.23084641]
 [54.35936737]
 [54.48376465]
 [54.60461807]
 [54.72264099]].
[2019-03-24 00:33:16,201] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8826
[2019-03-24 00:33:16,208] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.66666666666667, 1.0, 2.0, 0.6614376194165611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753830.1607775163, 753830.1607775163, 168970.9997676988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3720000.0000, 
sim time next is 3720600.0000, 
raw observation next is [24.85, 95.0, 1.0, 2.0, 0.6619080476174652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754366.5642945742, 754366.5642945742, 169056.8864071425], 
processed observation next is [1.0, 0.043478260869565216, 0.475925925925926, 0.95, 1.0, 1.0, 0.5975095804969824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26941663010520506, 0.26941663010520506, 0.3251093969368125], 
reward next is 0.6749, 
noisyNet noise sample is [array([1.0201198], dtype=float32), -0.43478814]. 
=============================================
[2019-03-24 00:33:17,917] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 00:33:17,918] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:33:17,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:17,920] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:33:17,921] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:33:17,922] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:17,922] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:17,922] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:33:17,923] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:33:17,925] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:17,928] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:17,939] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-24 00:33:17,959] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-24 00:33:17,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-24 00:33:17,985] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-24 00:33:18,004] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-24 00:33:33,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:33:33,531] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.77975077833333, 56.07308140333333, 1.0, 2.0, 0.858935946329236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1030485.458405674, 1030485.458405673, 210869.9733862773]
[2019-03-24 00:33:33,532] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:33:33,534] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.9888867e-15 1.0000000e+00 1.9745340e-22 5.3721797e-20 1.2009814e-24], sampled 0.34154201139869134
[2019-03-24 00:33:44,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:33:44,344] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.25, 86.0, 1.0, 2.0, 0.6169602928735533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760755.3932263582, 760755.3932263582, 163277.5397705371]
[2019-03-24 00:33:44,344] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:44,348] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3360566e-15 1.0000000e+00 1.9834185e-23 7.0228821e-21 9.5454401e-26], sampled 0.13544451985489392
[2019-03-24 00:33:52,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:33:52,371] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.592960433128064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686448.0837574254, 686448.0837574254, 157385.7478393544]
[2019-03-24 00:33:52,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:52,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.0130775e-16 1.0000000e+00 1.0852948e-23 4.1177499e-21 4.9120535e-26], sampled 0.908173509092948
[2019-03-24 00:34:18,592] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:34:18,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.6, 92.0, 1.0, 2.0, 0.6770612777911736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 820751.2710197957, 820751.2710197952, 173950.1323129871]
[2019-03-24 00:34:18,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:34:18,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5442513e-16 1.0000000e+00 2.5974543e-24 1.1611015e-21 1.0162963e-26], sampled 0.9141837441497591
[2019-03-24 00:34:20,777] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:34:20,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.43791057666667, 97.90458604833333, 1.0, 2.0, 0.6424926462810857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732228.5572672021, 732228.5572672021, 165542.5029505538]
[2019-03-24 00:34:20,780] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:34:20,786] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1354484e-16 1.0000000e+00 2.1529874e-24 9.8333741e-22 8.2640691e-27], sampled 0.9535181712683614
[2019-03-24 00:34:33,979] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:34:33,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.23253450666667, 83.71413984333333, 1.0, 2.0, 0.7995054171209299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911277.4250291452, 911277.4250291452, 195848.7599796256]
[2019-03-24 00:34:33,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:34:33,986] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6828515e-17 1.0000000e+00 4.9810015e-26 3.5007962e-23 1.3032525e-28], sampled 0.5187141738083914
[2019-03-24 00:34:47,624] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:34:47,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.787088265, 76.42220798666666, 1.0, 2.0, 0.8250092044033933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940364.5133978993, 940364.5133978993, 201158.2673856746]
[2019-03-24 00:34:47,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:34:47,630] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6001976e-15 1.0000000e+00 2.6146042e-23 8.9695976e-21 1.2945438e-25], sampled 0.6324071431501296
[2019-03-24 00:34:51,649] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:34:51,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.76666666666667, 57.66666666666667, 1.0, 2.0, 0.4711473751603312, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562151.6088213867, 562151.6088213867, 138442.1287816905]
[2019-03-24 00:34:51,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:34:51,654] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8073509e-16 1.0000000e+00 1.8176507e-24 8.4569701e-22 6.8599938e-27], sampled 0.575913538203872
[2019-03-24 00:35:00,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.15018028]
[2019-03-24 00:35:00,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.41666666666667, 95.83333333333334, 1.0, 2.0, 0.2976295968663881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 379734.0508021222, 379734.0508021222, 115282.9215061747]
[2019-03-24 00:35:00,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:35:00,278] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8517838e-16 1.0000000e+00 9.6092350e-25 4.8140064e-22 3.3973293e-27], sampled 0.03942436169197827
[2019-03-24 00:35:04,433] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:35:04,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:35:04,486] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:35:04,553] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:35:04,567] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:35:05,579] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:35:12,349] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103449: loss 0.0025
[2019-03-24 00:35:12,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103449: learning rate 0.0001
[2019-03-24 00:35:12,495] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103525: loss 0.1685
[2019-03-24 00:35:12,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103525: learning rate 0.0001
[2019-03-24 00:35:12,964] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103775: loss 0.0237
[2019-03-24 00:35:12,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103776: learning rate 0.0001
[2019-03-24 00:35:13,131] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103862: loss 0.0028
[2019-03-24 00:35:13,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103863: learning rate 0.0001
[2019-03-24 00:35:13,147] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103869: loss 0.0009
[2019-03-24 00:35:13,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103871: learning rate 0.0001
[2019-03-24 00:35:13,160] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103874: loss 0.0383
[2019-03-24 00:35:13,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103878: learning rate 0.0001
[2019-03-24 00:35:13,238] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103916: loss 0.0708
[2019-03-24 00:35:13,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103917: learning rate 0.0001
[2019-03-24 00:35:13,255] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103920: loss 0.0208
[2019-03-24 00:35:13,256] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103921: learning rate 0.0001
[2019-03-24 00:35:13,334] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103968: loss 0.0224
[2019-03-24 00:35:13,338] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103968: learning rate 0.0001
[2019-03-24 00:35:13,451] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104025: loss 0.0032
[2019-03-24 00:35:13,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104027: learning rate 0.0001
[2019-03-24 00:35:13,554] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104078: loss 0.0170
[2019-03-24 00:35:13,556] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104078: learning rate 0.0001
[2019-03-24 00:35:13,642] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104127: loss 0.1069
[2019-03-24 00:35:13,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104130: learning rate 0.0001
[2019-03-24 00:35:13,650] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104130: loss 0.0173
[2019-03-24 00:35:13,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104132: learning rate 0.0001
[2019-03-24 00:35:14,046] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104330: loss 0.0038
[2019-03-24 00:35:14,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104330: learning rate 0.0001
[2019-03-24 00:35:14,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104385: loss 0.0340
[2019-03-24 00:35:14,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104385: learning rate 0.0001
[2019-03-24 00:35:14,432] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104536: loss 1.3880
[2019-03-24 00:35:14,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104536: learning rate 0.0001
[2019-03-24 00:35:14,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3109659e-21 1.0000000e+00 1.2086161e-30 1.0216989e-27 1.3518435e-35], sum to 1.0000
[2019-03-24 00:35:14,922] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7808
[2019-03-24 00:35:15,109] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.73333333333333, 65.16666666666667, 1.0, 2.0, 0.7266218687749892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 828159.7687100349, 828159.7687100335, 181247.5627870167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3949800.0000, 
sim time next is 3950400.0000, 
raw observation next is [30.56666666666667, 66.33333333333334, 1.0, 2.0, 0.7238920889904229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825046.8558553372, 825046.8558553372, 180719.2186203591], 
processed observation next is [0.0, 0.7391304347826086, 0.6876543209876544, 0.6633333333333334, 1.0, 1.0, 0.6713001059409797, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29465959137690617, 0.29465959137690617, 0.347536958885306], 
reward next is 0.6525, 
noisyNet noise sample is [array([-1.088849], dtype=float32), -2.088167]. 
=============================================
[2019-03-24 00:35:20,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8874069e-15 1.0000000e+00 3.0456980e-25 1.7757441e-21 7.5809656e-26], sum to 1.0000
[2019-03-24 00:35:20,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5701
[2019-03-24 00:35:20,773] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.76666666666667, 88.0, 1.0, 2.0, 0.6696268144005512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763167.9049898001, 763167.9049897996, 170471.9979647383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4044000.0000, 
sim time next is 4044600.0000, 
raw observation next is [25.65, 87.5, 1.0, 2.0, 0.6602631718150633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752491.0041280902, 752491.0041280902, 168755.6051544013], 
processed observation next is [1.0, 0.8260869565217391, 0.5055555555555555, 0.875, 1.0, 1.0, 0.5955513950179325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2687467871886037, 0.2687467871886037, 0.3245300099123102], 
reward next is 0.6755, 
noisyNet noise sample is [array([1.8400328], dtype=float32), -0.39891064]. 
=============================================
[2019-03-24 00:35:23,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.38860601e-13 1.00000000e+00 6.22853715e-19 1.06049294e-17
 3.38215896e-21], sum to 1.0000
[2019-03-24 00:35:23,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3745
[2019-03-24 00:35:23,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1553012.798773005 W.
[2019-03-24 00:35:23,935] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 68.66666666666667, 1.0, 2.0, 0.6809795577349628, 1.0, 2.0, 0.6809795577349628, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1553012.798773005, 1553012.798773005, 297026.2143326221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4101600.0000, 
sim time next is 4102200.0000, 
raw observation next is [27.55, 69.0, 1.0, 2.0, 0.4635409943842074, 1.0, 2.0, 0.4635409943842074, 1.0, 1.0, 0.7379723595359055, 6.911199999999999, 6.9112, 121.94756008, 1585730.598519098, 1585730.598519099, 326034.0203484587], 
processed observation next is [1.0, 0.4782608695652174, 0.575925925925926, 0.69, 1.0, 1.0, 0.36135832664786605, 1.0, 1.0, 0.36135832664786605, 1.0, 0.5, 0.6724654494198817, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5663323566139635, 0.5663323566139639, 0.6269885006701129], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.083093], dtype=float32), 0.7052365]. 
=============================================
[2019-03-24 00:35:27,167] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7534167e-18 1.0000000e+00 1.9478499e-28 3.3267458e-25 7.1185436e-31], sum to 1.0000
[2019-03-24 00:35:27,174] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-24 00:35:27,179] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 91.0, 1.0, 2.0, 0.4495754593660087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547601.2038882084, 547601.2038882084, 135574.8591224398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4149000.0000, 
sim time next is 4149600.0000, 
raw observation next is [21.33333333333334, 92.0, 1.0, 2.0, 0.447091540122169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544950.4612085358, 544950.4612085358, 135216.0390475166], 
processed observation next is [1.0, 0.0, 0.3456790123456792, 0.92, 1.0, 1.0, 0.3417756430025821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1946251647173342, 0.1946251647173342, 0.2600308443221473], 
reward next is 0.7400, 
noisyNet noise sample is [array([0.9148649], dtype=float32), 1.1026851]. 
=============================================
[2019-03-24 00:35:28,244] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111525: loss -1.7311
[2019-03-24 00:35:28,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111526: learning rate 0.0001
[2019-03-24 00:35:28,597] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111714: loss 23.5074
[2019-03-24 00:35:28,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111714: learning rate 0.0001
[2019-03-24 00:35:28,602] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111715: loss -12.7009
[2019-03-24 00:35:28,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111715: learning rate 0.0001
[2019-03-24 00:35:28,758] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111791: loss -68.7230
[2019-03-24 00:35:28,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111791: learning rate 0.0001
[2019-03-24 00:35:28,810] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111812: loss -18.1730
[2019-03-24 00:35:28,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111813: learning rate 0.0001
[2019-03-24 00:35:28,870] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111849: loss -72.5697
[2019-03-24 00:35:28,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111850: learning rate 0.0001
[2019-03-24 00:35:28,930] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111880: loss -41.5993
[2019-03-24 00:35:28,932] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111881: learning rate 0.0001
[2019-03-24 00:35:28,940] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111885: loss 37.7126
[2019-03-24 00:35:28,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111885: learning rate 0.0001
[2019-03-24 00:35:29,117] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111974: loss 13.7947
[2019-03-24 00:35:29,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111975: learning rate 0.0001
[2019-03-24 00:35:29,452] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112149: loss -72.7904
[2019-03-24 00:35:29,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112150: learning rate 0.0001
[2019-03-24 00:35:29,473] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112159: loss -114.0253
[2019-03-24 00:35:29,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112159: learning rate 0.0001
[2019-03-24 00:35:29,492] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112168: loss -10.4175
[2019-03-24 00:35:29,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112168: learning rate 0.0001
[2019-03-24 00:35:29,681] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112263: loss -90.5375
[2019-03-24 00:35:29,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112263: learning rate 0.0001
[2019-03-24 00:35:29,705] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112277: loss -83.4851
[2019-03-24 00:35:29,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112277: learning rate 0.0001
[2019-03-24 00:35:29,757] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112306: loss -46.0375
[2019-03-24 00:35:29,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112307: learning rate 0.0001
[2019-03-24 00:35:30,063] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112464: loss 53.3454
[2019-03-24 00:35:30,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112464: learning rate 0.0001
[2019-03-24 00:35:33,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5435046e-10 1.0000000e+00 1.4090008e-14 2.2043255e-13 9.6299377e-16], sum to 1.0000
[2019-03-24 00:35:33,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3755
[2019-03-24 00:35:33,564] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.53333333333333, 59.0, 1.0, 2.0, 0.5817475833562569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672832.1059404433, 672832.1059404433, 155441.6561390013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4304400.0000, 
sim time next is 4305000.0000, 
raw observation next is [29.41666666666667, 60.0, 1.0, 2.0, 0.5875923488700878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678488.7098236223, 678488.7098236223, 156385.2589597128], 
processed observation next is [1.0, 0.8260869565217391, 0.6450617283950619, 0.6, 1.0, 1.0, 0.5090385105596283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24231739636557936, 0.24231739636557936, 0.30074088261483234], 
reward next is 0.6993, 
noisyNet noise sample is [array([1.4174688], dtype=float32), -1.0624398]. 
=============================================
[2019-03-24 00:35:33,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[34.94773 ]
 [34.864235]
 [35.011333]
 [35.116356]
 [34.967842]], R is [[35.0594902 ]
 [35.40996933]
 [35.75820541]
 [36.10403824]
 [36.44739914]].
[2019-03-24 00:35:40,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0340601e-19 1.0000000e+00 1.8779225e-28 7.1481479e-24 8.0179829e-32], sum to 1.0000
[2019-03-24 00:35:40,878] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-24 00:35:40,882] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 91.33333333333334, 1.0, 2.0, 0.4932741868438581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592146.8676648386, 592146.8676648386, 141979.1901790492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4412400.0000, 
sim time next is 4413000.0000, 
raw observation next is [22.41666666666666, 90.66666666666666, 1.0, 2.0, 0.4928812172488545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591684.3271251274, 591684.327125127, 141918.1292381895], 
processed observation next is [0.0, 0.043478260869565216, 0.38580246913580224, 0.9066666666666666, 1.0, 1.0, 0.3962871633914934, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21131583111611693, 0.21131583111611676, 0.27291947930421057], 
reward next is 0.7271, 
noisyNet noise sample is [array([0.6560935], dtype=float32), -0.38157558]. 
=============================================
[2019-03-24 00:35:40,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.9152  ]
 [68.00625 ]
 [68.04754 ]
 [68.232834]
 [68.289024]], R is [[67.93799591]
 [67.98558044]
 [68.03256989]
 [68.07896423]
 [68.12471771]].
[2019-03-24 00:35:43,277] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119401: loss 0.0037
[2019-03-24 00:35:43,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119402: learning rate 0.0001
[2019-03-24 00:35:43,548] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119540: loss 0.5060
[2019-03-24 00:35:43,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119541: learning rate 0.0001
[2019-03-24 00:35:43,865] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119700: loss 0.0296
[2019-03-24 00:35:43,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119701: learning rate 0.0001
[2019-03-24 00:35:43,950] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119738: loss 0.0659
[2019-03-24 00:35:43,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119738: learning rate 0.0001
[2019-03-24 00:35:44,048] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119789: loss 0.5187
[2019-03-24 00:35:44,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119789: learning rate 0.0001
[2019-03-24 00:35:44,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8864576e-15 1.0000000e+00 8.7730786e-23 1.6080076e-20 3.3251834e-26], sum to 1.0000
[2019-03-24 00:35:44,269] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-24 00:35:44,274] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 93.33333333333334, 1.0, 2.0, 0.6099344678199877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705056.2968787298, 705056.2968787298, 160276.8824071318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4497000.0000, 
sim time next is 4497600.0000, 
raw observation next is [23.96666666666667, 92.66666666666667, 1.0, 2.0, 0.6022207172572422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697681.1244212678, 697681.1244212673, 159006.8056688128], 
processed observation next is [0.0, 0.043478260869565216, 0.4432098765432099, 0.9266666666666667, 1.0, 1.0, 0.5264532348300502, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24917183015045277, 0.2491718301504526, 0.3057823185938708], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.17472254], dtype=float32), 1.0399615]. 
=============================================
[2019-03-24 00:35:44,324] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119924: loss 0.0244
[2019-03-24 00:35:44,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119925: learning rate 0.0001
[2019-03-24 00:35:44,339] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119932: loss 0.0169
[2019-03-24 00:35:44,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119933: learning rate 0.0001
[2019-03-24 00:35:44,394] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119956: loss 0.1698
[2019-03-24 00:35:44,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119958: learning rate 0.0001
[2019-03-24 00:35:44,400] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119959: loss 0.2382
[2019-03-24 00:35:44,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119959: learning rate 0.0001
[2019-03-24 00:35:44,557] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120037: loss 0.0038
[2019-03-24 00:35:44,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120037: learning rate 0.0001
[2019-03-24 00:35:44,818] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120170: loss 0.5506
[2019-03-24 00:35:44,819] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120170: learning rate 0.0001
[2019-03-24 00:35:44,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120241: loss 0.0324
[2019-03-24 00:35:44,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120242: learning rate 0.0001
[2019-03-24 00:35:45,060] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120288: loss 0.3566
[2019-03-24 00:35:45,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120291: learning rate 0.0001
[2019-03-24 00:35:45,094] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120304: loss 0.4361
[2019-03-24 00:35:45,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120305: learning rate 0.0001
[2019-03-24 00:35:45,246] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120379: loss 0.0033
[2019-03-24 00:35:45,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120380: learning rate 0.0001
[2019-03-24 00:35:45,379] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120445: loss 0.2377
[2019-03-24 00:35:45,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120445: learning rate 0.0001
[2019-03-24 00:35:48,417] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2898124e-24 1.0000000e+00 1.6997380e-33 1.2737178e-29 6.0640586e-38], sum to 1.0000
[2019-03-24 00:35:48,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-24 00:35:48,425] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 95.66666666666666, 1.0, 2.0, 0.5466246122256794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642579.8966563198, 642579.8966563198, 150041.28261321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4575000.0000, 
sim time next is 4575600.0000, 
raw observation next is [22.9, 96.0, 1.0, 2.0, 0.5481426297615613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644049.208679685, 644049.2086796846, 150278.1444780665], 
processed observation next is [0.0, 1.0, 0.4037037037037037, 0.96, 1.0, 1.0, 0.46207455923995383, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23001757452845895, 0.23001757452845878, 0.2889964316885894], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.05329622], dtype=float32), 1.3948002]. 
=============================================
[2019-03-24 00:35:54,589] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 00:35:54,590] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:35:54,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:54,592] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:35:54,593] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:54,593] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:35:54,595] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:35:54,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:35:54,598] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:54,597] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:54,599] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:54,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-24 00:35:54,630] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-24 00:35:54,653] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-24 00:35:54,653] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-24 00:35:54,708] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-24 00:36:05,821] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:36:05,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 40.0, 1.0, 2.0, 0.5141618355635621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 644822.1926977338, 644822.1926977342, 146013.5655814696]
[2019-03-24 00:36:05,823] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:36:05,826] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4751850e-15 1.0000000e+00 1.7807232e-21 1.2069161e-15 5.1522332e-24], sampled 0.3907347621114641
[2019-03-24 00:36:30,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:36:30,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.86666666666667, 53.16666666666666, 1.0, 2.0, 0.4349292468753029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540936.7562627655, 540936.7562627655, 133692.683212371]
[2019-03-24 00:36:30,386] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:36:30,388] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5167385e-15 1.0000000e+00 4.0775910e-22 4.2027578e-16 9.8642796e-25], sampled 0.6642400706305892
[2019-03-24 00:36:31,185] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:36:31,186] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.5613401888014128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654901.7504703951, 654901.7504703951, 152268.868536825]
[2019-03-24 00:36:31,187] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:36:31,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1499769e-15 1.0000000e+00 1.9614039e-22 2.4891874e-16 4.3410799e-25], sampled 0.506869061876185
[2019-03-24 00:36:43,454] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:36:43,457] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.07159058, 97.13829448, 1.0, 2.0, 0.7971084064289667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 908543.6893073865, 908543.689307386, 195352.9312711926]
[2019-03-24 00:36:43,458] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:36:43,462] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.7514089e-15 1.0000000e+00 6.3774252e-22 5.7878211e-16 1.6286045e-24], sampled 0.2941193227824217
[2019-03-24 00:37:34,094] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:37:34,094] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.41666666666666, 91.00000000000001, 1.0, 2.0, 0.5913404800220938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682225.571169157, 682225.571169157, 156998.2570950043]
[2019-03-24 00:37:34,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:37:34,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4124388e-15 1.0000000e+00 2.3274396e-22 2.8132579e-16 5.2591631e-25], sampled 0.029132608122586112
[2019-03-24 00:37:41,077] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.16712587]
[2019-03-24 00:37:41,078] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.52187236, 63.49305709666666, 1.0, 2.0, 0.4558974547555302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554689.1066028622, 554689.1066028622, 136502.6150346532]
[2019-03-24 00:37:41,079] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:37:41,082] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4583204e-16 1.0000000e+00 7.7971020e-24 2.4757011e-17 1.1663412e-26], sampled 0.08770153601275821
[2019-03-24 00:37:41,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:37:42,061] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:37:42,080] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0838 2170637693.1962 493.0000
[2019-03-24 00:37:42,110] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2011 2445344792.3129 746.0000
[2019-03-24 00:37:42,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:37:43,174] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 125000, evaluation results [125000.0, 8099.201058977578, 2445344792.312898, 746.0, 8771.08379319977, 2170637693.1962304, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:37:44,593] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1182416e-07 9.9999988e-01 9.5981782e-12 6.5091204e-09 2.6247891e-14], sum to 1.0000
[2019-03-24 00:37:44,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9925
[2019-03-24 00:37:44,605] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1456500.427755963 W.
[2019-03-24 00:37:44,613] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.38333333333333, 86.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.484331223901903, 6.9112, 121.923994361985, 1456500.427755963, 1163010.945686851, 245589.4941407849], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4713000.0000, 
sim time next is 4713600.0000, 
raw observation next is [27.76666666666667, 83.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.010695926337766, 6.9112, 121.9253406585391, 1929080.632820679, 1878130.119026629, 383778.6052980314], 
processed observation next is [1.0, 0.5652173913043478, 0.5839506172839507, 0.8366666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.009949592633776571, 0.0, 0.8094574685548251, 0.6889573688645283, 0.6707607567952246, 0.7380357794192912], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3241816], dtype=float32), -1.1023072]. 
=============================================
[2019-03-24 00:37:45,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2514012e-08 1.0000000e+00 2.0059119e-14 5.4543276e-11 7.6420371e-16], sum to 1.0000
[2019-03-24 00:37:45,080] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4337
[2019-03-24 00:37:45,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2036511.792828928 W.
[2019-03-24 00:37:45,088] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666666, 79.83333333333334, 1.0, 2.0, 0.8927449142663154, 1.0, 2.0, 0.8927449142663154, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2036511.792828928, 2036511.792828928, 383569.5050355656], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4726200.0000, 
sim time next is 4726800.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.9257603838325271, 1.0, 2.0, 0.9257603838325271, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2111915.082344797, 2111915.082344797, 398461.936726955], 
processed observation next is [1.0, 0.7391304347826086, 0.6222222222222222, 0.79, 1.0, 1.0, 0.9116195045625323, 1.0, 1.0, 0.9116195045625323, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7542553865517132, 0.7542553865517132, 0.7662729552441442], 
reward next is 0.2337, 
noisyNet noise sample is [array([-0.56667], dtype=float32), 0.52713823]. 
=============================================
[2019-03-24 00:37:47,854] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127438: loss -50.1158
[2019-03-24 00:37:47,857] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127439: learning rate 0.0001
[2019-03-24 00:37:47,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0064349e-12 1.0000000e+00 1.6641063e-16 4.0056751e-12 2.4663220e-17], sum to 1.0000
[2019-03-24 00:37:47,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9980
[2019-03-24 00:37:47,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1429735.813784175 W.
[2019-03-24 00:37:47,944] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 93.83333333333334, 1.0, 2.0, 0.6269743281529219, 1.0, 1.0, 0.6269743281529219, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156224, 1429735.813784175, 1429735.813784175, 277443.2598152643], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4783800.0000, 
sim time next is 4784400.0000, 
raw observation next is [23.9, 94.0, 1.0, 2.0, 0.4204173298867239, 1.0, 2.0, 0.4204173298867239, 1.0, 1.0, 0.669318081216208, 6.9112, 6.9112, 121.94756008, 1438070.558658064, 1438070.558658064, 306141.5256885299], 
processed observation next is [1.0, 0.391304347826087, 0.4407407407407407, 0.94, 1.0, 1.0, 0.3100206308175285, 1.0, 1.0, 0.3100206308175285, 1.0, 0.5, 0.5866476015202599, 0.0, 0.0, 0.8096049824067558, 0.5135966280921658, 0.5135966280921658, 0.5887337032471729], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17615941], dtype=float32), 0.23334728]. 
=============================================
[2019-03-24 00:37:48,208] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127620: loss -58.6154
[2019-03-24 00:37:48,213] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127622: learning rate 0.0001
[2019-03-24 00:37:48,460] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127754: loss -67.7339
[2019-03-24 00:37:48,461] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127755: learning rate 0.0001
[2019-03-24 00:37:48,542] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127794: loss -42.4906
[2019-03-24 00:37:48,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127794: learning rate 0.0001
[2019-03-24 00:37:48,565] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127806: loss -89.7187
[2019-03-24 00:37:48,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127806: learning rate 0.0001
[2019-03-24 00:37:48,791] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127924: loss -83.0935
[2019-03-24 00:37:48,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127924: learning rate 0.0001
[2019-03-24 00:37:48,795] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127925: loss -56.3036
[2019-03-24 00:37:48,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127927: learning rate 0.0001
[2019-03-24 00:37:48,807] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127931: loss 53.3626
[2019-03-24 00:37:48,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127931: learning rate 0.0001
[2019-03-24 00:37:48,812] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127932: loss -22.6647
[2019-03-24 00:37:48,815] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127932: learning rate 0.0001
[2019-03-24 00:37:49,041] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128050: loss -115.1633
[2019-03-24 00:37:49,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128050: learning rate 0.0001
[2019-03-24 00:37:49,199] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128134: loss -54.3883
[2019-03-24 00:37:49,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128134: learning rate 0.0001
[2019-03-24 00:37:49,490] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128283: loss -12.6727
[2019-03-24 00:37:49,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128283: learning rate 0.0001
[2019-03-24 00:37:49,540] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128314: loss -40.7144
[2019-03-24 00:37:49,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128314: learning rate 0.0001
[2019-03-24 00:37:49,561] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128324: loss -8.8509
[2019-03-24 00:37:49,563] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128325: learning rate 0.0001
[2019-03-24 00:37:49,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128333: loss -134.4099
[2019-03-24 00:37:49,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128333: learning rate 0.0001
[2019-03-24 00:37:49,617] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128348: loss -68.8262
[2019-03-24 00:37:49,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128348: learning rate 0.0001
[2019-03-24 00:37:49,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4053234e-10 1.0000000e+00 1.8523227e-14 5.0590770e-10 3.5548128e-16], sum to 1.0000
[2019-03-24 00:37:49,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1610
[2019-03-24 00:37:49,742] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1852679.712181425 W.
[2019-03-24 00:37:49,751] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.06666666666667, 85.66666666666667, 1.0, 2.0, 0.8122420144569064, 1.0, 2.0, 0.8122420144569064, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1852679.712181425, 1852679.712181425, 348840.3315612091], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4812000.0000, 
sim time next is 4812600.0000, 
raw observation next is [28.33333333333334, 84.83333333333333, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.06606844785391, 6.9112, 121.9253713925993, 1957465.983972551, 1878159.933281901, 383582.5679429067], 
processed observation next is [1.0, 0.6956521739130435, 0.6049382716049385, 0.8483333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.015486844785390997, 0.0, 0.8094576725970237, 0.699094994275911, 0.6707714047435361, 0.7376587845055897], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9769876], dtype=float32), -0.22335418]. 
=============================================
[2019-03-24 00:37:52,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1529727e-15 1.0000000e+00 2.9661400e-22 1.0931481e-15 5.9203228e-26], sum to 1.0000
[2019-03-24 00:37:52,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0257
[2019-03-24 00:37:52,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2185736.692101047 W.
[2019-03-24 00:37:52,668] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 88.16666666666667, 1.0, 2.0, 0.9580806111881756, 1.0, 2.0, 0.9580806111881756, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2185736.692101047, 2185736.692101047, 413407.2506204112], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4881000.0000, 
sim time next is 4881600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.9493321923041877, 1.0, 2.0, 0.9493321923041877, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2165754.102581828, 2165754.102581828, 409326.328144622], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.89, 1.0, 1.0, 0.9396811813145092, 1.0, 1.0, 0.9396811813145092, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7734836080649385, 0.7734836080649385, 0.7871660156627346], 
reward next is 0.2128, 
noisyNet noise sample is [array([-0.435035], dtype=float32), 0.37904927]. 
=============================================
[2019-03-24 00:38:02,805] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135233: loss 10.3723
[2019-03-24 00:38:02,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135233: learning rate 0.0001
[2019-03-24 00:38:03,536] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135620: loss 7.9295
[2019-03-24 00:38:03,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135620: learning rate 0.0001
[2019-03-24 00:38:03,678] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135696: loss 3.9280
[2019-03-24 00:38:03,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135696: learning rate 0.0001
[2019-03-24 00:38:03,814] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135765: loss 1.0585
[2019-03-24 00:38:03,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135765: learning rate 0.0001
[2019-03-24 00:38:04,000] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135864: loss 3.8411
[2019-03-24 00:38:04,001] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135864: learning rate 0.0001
[2019-03-24 00:38:04,046] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135885: loss 4.8091
[2019-03-24 00:38:04,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135888: learning rate 0.0001
[2019-03-24 00:38:04,054] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135889: loss 5.1469
[2019-03-24 00:38:04,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135889: learning rate 0.0001
[2019-03-24 00:38:04,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135984: loss 4.3073
[2019-03-24 00:38:04,236] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135984: learning rate 0.0001
[2019-03-24 00:38:04,238] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135985: loss 6.0337
[2019-03-24 00:38:04,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135985: learning rate 0.0001
[2019-03-24 00:38:04,435] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136085: loss 1.1630
[2019-03-24 00:38:04,436] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136086: learning rate 0.0001
[2019-03-24 00:38:04,474] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136106: loss 0.7481
[2019-03-24 00:38:04,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136107: learning rate 0.0001
[2019-03-24 00:38:04,683] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136219: loss 4.3751
[2019-03-24 00:38:04,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136219: learning rate 0.0001
[2019-03-24 00:38:04,823] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136288: loss 6.4147
[2019-03-24 00:38:04,824] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136288: loss 4.4105
[2019-03-24 00:38:04,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136289: learning rate 0.0001
[2019-03-24 00:38:04,828] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136289: learning rate 0.0001
[2019-03-24 00:38:04,912] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136334: loss 2.9239
[2019-03-24 00:38:04,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136334: learning rate 0.0001
[2019-03-24 00:38:05,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136558: loss 8.2066
[2019-03-24 00:38:05,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136558: learning rate 0.0001
[2019-03-24 00:38:08,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5495594e-13 1.0000000e+00 3.2711622e-17 6.0060663e-12 5.1786304e-19], sum to 1.0000
[2019-03-24 00:38:08,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8403
[2019-03-24 00:38:08,472] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 92.33333333333333, 1.0, 2.0, 0.6363270807346239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729196.3279031977, 729196.3279031977, 164638.0538239012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [24.4, 92.0, 1.0, 2.0, 0.6256749520404902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719273.3581701106, 719273.3581701106, 162856.7983406076], 
processed observation next is [1.0, 0.08695652173913043, 0.4592592592592592, 0.92, 1.0, 1.0, 0.5543749429053454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2568833422036109, 0.2568833422036109, 0.31318615065501465], 
reward next is 0.6868, 
noisyNet noise sample is [array([-0.20533144], dtype=float32), 1.2354932]. 
=============================================
[2019-03-24 00:38:18,452] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143347: loss 28.8556
[2019-03-24 00:38:18,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143348: learning rate 0.0001
[2019-03-24 00:38:18,486] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3088925e-13 1.0000000e+00 3.6988410e-19 1.6415398e-10 5.7584339e-19], sum to 1.0000
[2019-03-24 00:38:18,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4124
[2019-03-24 00:38:18,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1484262.183929767 W.
[2019-03-24 00:38:18,510] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.56666666666667, 87.66666666666666, 1.0, 2.0, 0.4339082967066135, 1.0, 2.0, 0.4339082967066135, 1.0, 2.0, 0.6907961397635876, 6.9112, 6.9112, 121.94756008, 1484262.183929767, 1484262.183929767, 312254.242364932], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5388000.0000, 
sim time next is 5388600.0000, 
raw observation next is [25.73333333333333, 86.83333333333333, 1.0, 2.0, 0.4368406365526578, 1.0, 2.0, 0.4368406365526578, 1.0, 2.0, 0.6954645202981317, 6.911199999999999, 6.9112, 121.94756008, 1494302.57001208, 1494302.57001208, 313596.1980775719], 
processed observation next is [1.0, 0.34782608695652173, 0.5086419753086419, 0.8683333333333333, 1.0, 1.0, 0.32957218637221164, 1.0, 1.0, 0.32957218637221164, 1.0, 1.0, 0.6193306503726645, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5336794892900286, 0.5336794892900286, 0.6030696116876383], 
reward next is 0.3969, 
noisyNet noise sample is [array([0.09813883], dtype=float32), -0.023024777]. 
=============================================
[2019-03-24 00:38:18,920] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143588: loss 76.6462
[2019-03-24 00:38:18,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143588: learning rate 0.0001
[2019-03-24 00:38:19,143] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143706: loss 30.5014
[2019-03-24 00:38:19,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143706: learning rate 0.0001
[2019-03-24 00:38:19,220] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143743: loss -5.4259
[2019-03-24 00:38:19,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143743: learning rate 0.0001
[2019-03-24 00:38:19,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143774: loss -48.7786
[2019-03-24 00:38:19,287] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143775: learning rate 0.0001
[2019-03-24 00:38:19,388] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143828: loss 57.6010
[2019-03-24 00:38:19,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143829: learning rate 0.0001
[2019-03-24 00:38:19,654] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143974: loss -2.0014
[2019-03-24 00:38:19,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143974: learning rate 0.0001
[2019-03-24 00:38:19,682] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143984: loss 111.2842
[2019-03-24 00:38:19,685] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143985: learning rate 0.0001
[2019-03-24 00:38:19,815] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144054: loss 88.1318
[2019-03-24 00:38:19,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144054: learning rate 0.0001
[2019-03-24 00:38:19,919] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144113: loss 43.1745
[2019-03-24 00:38:19,921] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144113: loss 216.2452
[2019-03-24 00:38:19,923] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144113: learning rate 0.0001
[2019-03-24 00:38:19,923] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144113: learning rate 0.0001
[2019-03-24 00:38:20,067] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144190: loss 138.0239
[2019-03-24 00:38:20,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144190: learning rate 0.0001
[2019-03-24 00:38:20,289] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144312: loss 150.3288
[2019-03-24 00:38:20,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144314: learning rate 0.0001
[2019-03-24 00:38:20,320] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144326: loss 29.8378
[2019-03-24 00:38:20,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144326: learning rate 0.0001
[2019-03-24 00:38:20,435] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144392: loss 91.5826
[2019-03-24 00:38:20,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144392: learning rate 0.0001
[2019-03-24 00:38:20,576] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144474: loss 55.9322
[2019-03-24 00:38:20,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144474: learning rate 0.0001
[2019-03-24 00:38:24,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1406537e-13 1.0000000e+00 9.4217242e-17 9.2346877e-12 1.9751493e-17], sum to 1.0000
[2019-03-24 00:38:24,869] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4718
[2019-03-24 00:38:24,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2614369.08920645 W.
[2019-03-24 00:38:24,878] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.9008572224409992, 1.0, 2.0, 0.7637932731969341, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2614369.08920645, 2614369.089206451, 487574.7804250882], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5496000.0000, 
sim time next is 5496600.0000, 
raw observation next is [31.65, 68.0, 1.0, 2.0, 0.8626786697811873, 1.0, 2.0, 0.7447039968670285, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2548935.584356511, 2548935.584356511, 475815.2686518307], 
processed observation next is [1.0, 0.6086956521739131, 0.7277777777777777, 0.68, 1.0, 1.0, 0.8365222259299849, 1.0, 1.0, 0.6960761867464624, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9103341372701825, 0.9103341372701825, 0.9150293627919821], 
reward next is 0.0850, 
noisyNet noise sample is [array([1.2207645], dtype=float32), -0.5024932]. 
=============================================
[2019-03-24 00:38:29,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0651538e-12 1.0000000e+00 4.4914743e-17 8.7355877e-13 2.0619485e-16], sum to 1.0000
[2019-03-24 00:38:29,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3106
[2019-03-24 00:38:29,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2431854.467257891 W.
[2019-03-24 00:38:29,965] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 74.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.115338137868601, 6.9112, 121.9252815451769, 2431854.467257891, 2327318.147536194, 443049.6129720938], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5580000.0000, 
sim time next is 5580600.0000, 
raw observation next is [30.2, 74.83333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 8.215103559403177, 6.9112, 122.9301705230149, 3001241.882432976, 2328027.717440382, 443199.0685821834], 
processed observation next is [1.0, 0.6086956521739131, 0.674074074074074, 0.7483333333333334, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.13039035594031773, 0.0, 0.8161284939055335, 1.07187210086892, 0.8314384705144222, 0.8523059011195835], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38462514], dtype=float32), 3.5171862]. 
=============================================
[2019-03-24 00:38:31,529] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7406343e-16 1.0000000e+00 1.5792589e-21 4.9019491e-17 2.3102083e-22], sum to 1.0000
[2019-03-24 00:38:31,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5189
[2019-03-24 00:38:31,541] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 96.5, 1.0, 2.0, 0.5946818095670475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 686313.4323380458, 686313.4323380453, 157582.349480054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635800.0000, 
sim time next is 5636400.0000, 
raw observation next is [23.76666666666667, 96.33333333333334, 1.0, 2.0, 0.596024749508781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687174.3768280424, 687174.3768280424, 157780.8167898527], 
processed observation next is [0.0, 0.21739130434782608, 0.43580246913580256, 0.9633333333333334, 1.0, 1.0, 0.5190770827485488, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24541942029572944, 0.24541942029572944, 0.30342464767279365], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.32082397], dtype=float32), 0.30241367]. 
=============================================
[2019-03-24 00:38:31,694] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 00:38:31,696] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:38:31,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:31,697] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:38:31,698] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:38:31,699] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:31,699] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:38:31,702] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:31,701] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:38:31,703] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:31,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:31,719] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-24 00:38:31,721] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-24 00:38:31,776] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-24 00:38:31,777] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-24 00:38:31,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-24 00:38:38,728] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:38:38,729] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.34338661333334, 67.35439005666666, 1.0, 2.0, 0.6447025001464008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819217.0375845665, 819217.0375845665, 168748.6337799351]
[2019-03-24 00:38:38,729] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:38:38,732] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.3803475e-18 1.0000000e+00 5.5453222e-24 1.2583815e-18 2.7989347e-24], sampled 0.833704681640929
[2019-03-24 00:38:46,503] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:38:46,505] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.48869254, 56.89433419, 1.0, 2.0, 0.2957913154314523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378139.1707783945, 378139.170778394, 115058.4882680281]
[2019-03-24 00:38:46,506] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:38:46,510] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0505559e-19 1.0000000e+00 6.6611230e-26 4.2526144e-20 3.2010441e-26], sampled 0.06286402850088757
[2019-03-24 00:39:02,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:39:02,881] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.8199722, 105.1581959566667, 1.0, 2.0, 0.8146318703234005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156312, 943372.9214793786, 943372.9214793791, 199747.0567145166]
[2019-03-24 00:39:02,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:39:02,886] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.6859975e-19 1.0000000e+00 5.4453491e-25 2.1265466e-19 2.6783822e-25], sampled 0.8168038052342234
[2019-03-24 00:39:18,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:39:18,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.53333333333333, 67.0, 1.0, 2.0, 0.6193105395965095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 717913.9771333841, 717913.9771333836, 162014.3120749824]
[2019-03-24 00:39:18,599] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:39:18,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6218893e-20 1.0000000e+00 4.1175489e-27 5.0408055e-21 1.9178645e-27], sampled 0.820917556061702
[2019-03-24 00:39:36,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:39:36,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.6214271617142851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708209.8003429952, 708209.8003429952, 161802.0037734327]
[2019-03-24 00:39:36,309] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:39:36,311] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9162113e-20 1.0000000e+00 9.6413155e-27 9.6735065e-21 4.5337808e-27], sampled 0.8509042547053816
[2019-03-24 00:39:52,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.1839204]
[2019-03-24 00:39:52,643] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.16208443666667, 66.27586885, 1.0, 2.0, 0.4040942152995568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.7797854237, 498394.7797854237, 129143.5895645975]
[2019-03-24 00:39:52,644] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:39:52,649] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.3597813e-20 1.0000000e+00 1.6644598e-26 1.4698379e-20 7.8760096e-27], sampled 0.7238282399889877
[2019-03-24 00:40:18,665] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:40:18,835] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-03-24 00:40:18,846] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:40:18,908] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:40:19,045] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:40:20,059] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 150000, evaluation results [150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:40:22,506] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151287: loss 0.0758
[2019-03-24 00:40:22,508] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151288: learning rate 0.0001
[2019-03-24 00:40:22,878] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151479: loss 0.5114
[2019-03-24 00:40:22,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151479: learning rate 0.0001
[2019-03-24 00:40:23,110] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151599: loss 0.1590
[2019-03-24 00:40:23,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151599: learning rate 0.0001
[2019-03-24 00:40:23,329] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151715: loss 0.0043
[2019-03-24 00:40:23,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151715: learning rate 0.0001
[2019-03-24 00:40:23,343] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151719: loss 0.0199
[2019-03-24 00:40:23,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151720: learning rate 0.0001
[2019-03-24 00:40:23,359] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151726: loss 0.0358
[2019-03-24 00:40:23,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151728: learning rate 0.0001
[2019-03-24 00:40:23,831] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151979: loss 0.1767
[2019-03-24 00:40:23,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151979: learning rate 0.0001
[2019-03-24 00:40:23,917] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152019: loss 0.0045
[2019-03-24 00:40:23,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152019: learning rate 0.0001
[2019-03-24 00:40:24,000] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152063: loss 0.2827
[2019-03-24 00:40:24,006] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152065: learning rate 0.0001
[2019-03-24 00:40:24,047] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152087: loss 0.4100
[2019-03-24 00:40:24,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152087: learning rate 0.0001
[2019-03-24 00:40:24,116] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152122: loss 0.5626
[2019-03-24 00:40:24,117] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152123: learning rate 0.0001
[2019-03-24 00:40:24,291] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152215: loss 0.0261
[2019-03-24 00:40:24,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152215: learning rate 0.0001
[2019-03-24 00:40:24,587] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152367: loss 0.0009
[2019-03-24 00:40:24,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152367: learning rate 0.0001
[2019-03-24 00:40:24,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152409: loss 0.0720
[2019-03-24 00:40:24,683] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152411: learning rate 0.0001
[2019-03-24 00:40:24,794] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152478: loss 0.5290
[2019-03-24 00:40:24,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152478: learning rate 0.0001
[2019-03-24 00:40:24,930] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152549: loss 0.0098
[2019-03-24 00:40:24,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152550: learning rate 0.0001
[2019-03-24 00:40:25,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5658012e-23 1.0000000e+00 1.7193371e-30 2.4216848e-24 1.1415828e-30], sum to 1.0000
[2019-03-24 00:40:25,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1191
[2019-03-24 00:40:25,365] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 78.0, 1.0, 2.0, 0.4538632959578224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551548.2291505411, 551548.2291505411, 136177.7100275356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5736600.0000, 
sim time next is 5737200.0000, 
raw observation next is [23.6, 77.0, 1.0, 2.0, 0.4579245849440653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555998.5738849208, 555998.5738849208, 136772.6468171256], 
processed observation next is [0.0, 0.391304347826087, 0.4296296296296297, 0.77, 1.0, 1.0, 0.35467212493341105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19857091924461456, 0.19857091924461456, 0.26302432080216465], 
reward next is 0.7370, 
noisyNet noise sample is [array([1.270467], dtype=float32), 0.5143565]. 
=============================================
[2019-03-24 00:40:32,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9100269e-23 1.0000000e+00 1.0004349e-30 2.6991535e-24 2.4418897e-31], sum to 1.0000
[2019-03-24 00:40:32,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3163
[2019-03-24 00:40:32,705] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 74.0, 1.0, 2.0, 0.4160452542671071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512707.8581950254, 512707.8581950254, 130836.4339819702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5868000.0000, 
sim time next is 5868600.0000, 
raw observation next is [22.81666666666667, 75.0, 1.0, 2.0, 0.4141292727100018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510604.2328041508, 510604.2328041508, 130568.0640478782], 
processed observation next is [1.0, 0.9565217391304348, 0.4006172839506174, 0.75, 1.0, 1.0, 0.3025348484642878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.182358654572911, 0.182358654572911, 0.2510924308613042], 
reward next is 0.7489, 
noisyNet noise sample is [array([0.3698649], dtype=float32), -1.0421678]. 
=============================================
[2019-03-24 00:40:37,948] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159393: loss -85.0848
[2019-03-24 00:40:37,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159393: learning rate 0.0001
[2019-03-24 00:40:38,024] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159434: loss -132.9414
[2019-03-24 00:40:38,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159434: learning rate 0.0001
[2019-03-24 00:40:38,191] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159517: loss -103.1425
[2019-03-24 00:40:38,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159517: learning rate 0.0001
[2019-03-24 00:40:38,347] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159595: loss -67.6681
[2019-03-24 00:40:38,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159595: learning rate 0.0001
[2019-03-24 00:40:38,368] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3471613e-15 1.0000000e+00 3.7903555e-20 1.4348949e-15 1.5708293e-21], sum to 1.0000
[2019-03-24 00:40:38,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4450
[2019-03-24 00:40:38,386] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 82.0, 1.0, 2.0, 0.4475716067868561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 545593.1030755375, 545593.103075537, 135289.1011825062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964000.0000, 
sim time next is 5964600.0000, 
raw observation next is [22.6, 81.5, 1.0, 2.0, 0.444042087099989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541860.0935732728, 541860.0935732728, 134781.5853977911], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.815, 1.0, 1.0, 0.3381453417857012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19352146199045459, 0.19352146199045459, 0.2591953565342136], 
reward next is 0.7408, 
noisyNet noise sample is [array([-0.30835602], dtype=float32), -0.27472728]. 
=============================================
[2019-03-24 00:40:38,402] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159622: loss -160.9248
[2019-03-24 00:40:38,403] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159623: learning rate 0.0001
[2019-03-24 00:40:39,088] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159979: loss -89.5264
[2019-03-24 00:40:39,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159979: learning rate 0.0001
[2019-03-24 00:40:39,140] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160005: loss -102.1981
[2019-03-24 00:40:39,141] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160005: learning rate 0.0001
[2019-03-24 00:40:39,191] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160032: loss -62.6977
[2019-03-24 00:40:39,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160032: learning rate 0.0001
[2019-03-24 00:40:39,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160069: loss -113.0309
[2019-03-24 00:40:39,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160070: learning rate 0.0001
[2019-03-24 00:40:39,281] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160074: loss -61.1331
[2019-03-24 00:40:39,284] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160075: learning rate 0.0001
[2019-03-24 00:40:39,379] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160126: loss -79.1026
[2019-03-24 00:40:39,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160126: learning rate 0.0001
[2019-03-24 00:40:39,387] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160129: loss -74.8754
[2019-03-24 00:40:39,389] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160130: learning rate 0.0001
[2019-03-24 00:40:39,713] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160301: loss -144.4853
[2019-03-24 00:40:39,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160302: learning rate 0.0001
[2019-03-24 00:40:39,801] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160341: loss -115.6894
[2019-03-24 00:40:39,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160342: learning rate 0.0001
[2019-03-24 00:40:39,928] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160408: loss -87.0892
[2019-03-24 00:40:39,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160408: learning rate 0.0001
[2019-03-24 00:40:40,049] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160472: loss -63.2488
[2019-03-24 00:40:40,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160472: learning rate 0.0001
[2019-03-24 00:40:45,165] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3504730e-19 1.0000000e+00 1.7571559e-25 7.4962661e-21 1.6920778e-26], sum to 1.0000
[2019-03-24 00:40:45,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0784
[2019-03-24 00:40:45,177] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 67.66666666666667, 1.0, 2.0, 0.5468965712095464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642743.3579362264, 642743.3579362264, 150079.4776272151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6123000.0000, 
sim time next is 6123600.0000, 
raw observation next is [26.9, 68.0, 1.0, 2.0, 0.5455737295272122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641488.626393677, 641488.626393677, 149874.3785666167], 
processed observation next is [1.0, 0.9130434782608695, 0.5518518518518518, 0.68, 1.0, 1.0, 0.45901634467525254, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22910308085488462, 0.22910308085488462, 0.2882199587819552], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.3708465], dtype=float32), 0.038223375]. 
=============================================
[2019-03-24 00:40:47,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8864710e-16 1.0000000e+00 5.0236990e-22 2.2457734e-18 7.3442603e-23], sum to 1.0000
[2019-03-24 00:40:47,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-24 00:40:47,628] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 88.33333333333334, 1.0, 2.0, 0.5411426464148484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644107.1346706923, 644107.1346706923, 149458.5734389185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6157200.0000, 
sim time next is 6157800.0000, 
raw observation next is [23.3, 88.0, 1.0, 2.0, 0.5421565458985889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644655.8571853546, 644655.8571853541, 149600.145390779], 
processed observation next is [1.0, 0.2608695652173913, 0.41851851851851857, 0.88, 1.0, 1.0, 0.4549482689268915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2302342347090552, 0.23023423470905505, 0.28769258728995967], 
reward next is 0.7123, 
noisyNet noise sample is [array([1.2102904], dtype=float32), 0.6869391]. 
=============================================
[2019-03-24 00:40:48,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0208443e-07 9.9999988e-01 2.0583354e-10 3.3058626e-08 7.1330120e-10], sum to 1.0000
[2019-03-24 00:40:48,215] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3015
[2019-03-24 00:40:48,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1732288.10160944 W.
[2019-03-24 00:40:48,226] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.06666666666667, 63.66666666666666, 1.0, 2.0, 0.8905179293119668, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9958854929318345, 6.9112, 6.9112, 121.9260426156618, 1732288.10160944, 1732288.10160944, 354643.4466714703], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6177000.0000, 
sim time next is 6177600.0000, 
raw observation next is [28.2, 63.0, 1.0, 2.0, 0.7777692385688645, 1.0, 1.0, 0.7777692385688645, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1773971.109249726, 1773971.109249727, 334652.3785996493], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.63, 1.0, 1.0, 0.7354395697248387, 1.0, 0.5, 0.7354395697248387, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6335611104463307, 0.6335611104463311, 0.6435622665377871], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9696922], dtype=float32), 1.0176276]. 
=============================================
[2019-03-24 00:40:49,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5128074e-21 1.0000000e+00 3.4314996e-31 2.7366435e-24 2.2718432e-29], sum to 1.0000
[2019-03-24 00:40:49,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4957
[2019-03-24 00:40:49,846] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 74.0, 1.0, 2.0, 0.4972502351633676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595248.4770954245, 595248.4770954245, 142542.7010816298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6220800.0000, 
sim time next is 6221400.0000, 
raw observation next is [24.81666666666667, 74.33333333333334, 1.0, 2.0, 0.4955321210412312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593465.4522269061, 593465.4522269061, 142283.304694051], 
processed observation next is [0.0, 0.0, 0.4746913580246915, 0.7433333333333334, 1.0, 1.0, 0.39944300123956095, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21195194722389504, 0.21195194722389504, 0.27362173979625193], 
reward next is 0.7264, 
noisyNet noise sample is [array([0.65897524], dtype=float32), -1.0965413]. 
=============================================
[2019-03-24 00:40:50,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2130355e-22 1.0000000e+00 1.8989265e-30 6.5583936e-21 6.2975514e-29], sum to 1.0000
[2019-03-24 00:40:50,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6615
[2019-03-24 00:40:50,046] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 83.0, 1.0, 2.0, 0.4751342853538689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573487.5604613783, 573487.5604613783, 139279.6605055186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6233400.0000, 
sim time next is 6234000.0000, 
raw observation next is [23.0, 83.66666666666667, 1.0, 2.0, 0.4749419591376831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573340.6923375642, 573340.6923375637, 139252.9912653492], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.8366666666666667, 1.0, 1.0, 0.374930903735337, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2047645329777015, 0.20476453297770134, 0.2677942139718254], 
reward next is 0.7322, 
noisyNet noise sample is [array([-1.366734], dtype=float32), -1.9879749]. 
=============================================
[2019-03-24 00:40:50,100] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[89.06736]
 [89.37372]
 [89.58375]
 [89.75201]
 [89.92119]], R is [[88.7858429 ]
 [88.63014221]
 [88.47579956]
 [88.32260132]
 [88.17051697]].
[2019-03-24 00:40:51,566] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7067545e-17 1.0000000e+00 8.5464479e-22 1.5763250e-17 3.9834853e-21], sum to 1.0000
[2019-03-24 00:40:51,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0337
[2019-03-24 00:40:51,582] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 77.0, 1.0, 2.0, 0.573201241642133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 667065.3223012909, 667065.3223012906, 154184.2493389617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6256800.0000, 
sim time next is 6257400.0000, 
raw observation next is [26.15, 76.66666666666667, 1.0, 2.0, 0.5782547492514296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671784.247926528, 671784.247926528, 154986.479087014], 
processed observation next is [0.0, 0.43478260869565216, 0.524074074074074, 0.7666666666666667, 1.0, 1.0, 0.4979223205374162, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2399229456880457, 0.2399229456880457, 0.2980509213211808], 
reward next is 0.7019, 
noisyNet noise sample is [array([1.3512874], dtype=float32), 0.52932346]. 
=============================================
[2019-03-24 00:40:53,603] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167491: loss 0.7425
[2019-03-24 00:40:53,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167493: learning rate 0.0001
[2019-03-24 00:40:53,696] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167535: loss 0.0909
[2019-03-24 00:40:53,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167535: learning rate 0.0001
[2019-03-24 00:40:53,800] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167593: loss 0.0255
[2019-03-24 00:40:53,802] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167594: learning rate 0.0001
[2019-03-24 00:40:53,866] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167626: loss 0.2628
[2019-03-24 00:40:53,869] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167627: learning rate 0.0001
[2019-03-24 00:40:54,256] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167834: loss 0.4778
[2019-03-24 00:40:54,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167835: learning rate 0.0001
[2019-03-24 00:40:54,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167878: loss 0.0550
[2019-03-24 00:40:54,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167879: learning rate 0.0001
[2019-03-24 00:40:54,428] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167921: loss 0.1210
[2019-03-24 00:40:54,429] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167921: loss 0.1160
[2019-03-24 00:40:54,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167921: learning rate 0.0001
[2019-03-24 00:40:54,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167921: learning rate 0.0001
[2019-03-24 00:40:54,652] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168036: loss 0.0015
[2019-03-24 00:40:54,655] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168036: learning rate 0.0001
[2019-03-24 00:40:54,769] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168097: loss 0.1957
[2019-03-24 00:40:54,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168097: learning rate 0.0001
[2019-03-24 00:40:54,831] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168129: loss 0.2150
[2019-03-24 00:40:54,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168129: learning rate 0.0001
[2019-03-24 00:40:55,055] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168251: loss 0.3325
[2019-03-24 00:40:55,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168251: learning rate 0.0001
[2019-03-24 00:40:55,176] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168315: loss 0.1908
[2019-03-24 00:40:55,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168315: learning rate 0.0001
[2019-03-24 00:40:55,180] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168316: loss 0.1013
[2019-03-24 00:40:55,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168316: learning rate 0.0001
[2019-03-24 00:40:55,298] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168377: loss 0.0639
[2019-03-24 00:40:55,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168378: learning rate 0.0001
[2019-03-24 00:40:55,457] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168457: loss 0.0388
[2019-03-24 00:40:55,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168458: learning rate 0.0001
[2019-03-24 00:40:55,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3752332e-14 1.0000000e+00 8.4741955e-19 3.5738793e-14 9.3020472e-18], sum to 1.0000
[2019-03-24 00:40:55,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9920
[2019-03-24 00:40:55,812] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 88.0, 1.0, 2.0, 0.5607613566423372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657317.4800206803, 657317.4800206803, 152305.6912069781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324000.0000, 
sim time next is 6324600.0000, 
raw observation next is [24.01666666666667, 88.0, 1.0, 2.0, 0.5589769519272273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655443.3117704917, 655443.3117704917, 152017.4523975722], 
processed observation next is [0.0, 0.17391304347826086, 0.4450617283950618, 0.88, 1.0, 1.0, 0.4749725618181277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23408689706088986, 0.23408689706088986, 0.29234125461071575], 
reward next is 0.7077, 
noisyNet noise sample is [array([-0.15271612], dtype=float32), -0.11006484]. 
=============================================
[2019-03-24 00:40:59,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1813164e-18 1.0000000e+00 1.1515033e-21 3.5314923e-19 3.8047617e-24], sum to 1.0000
[2019-03-24 00:40:59,505] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2249
[2019-03-24 00:40:59,510] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 84.5, 1.0, 2.0, 0.67053997848961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 764209.1490233442, 764209.1490233437, 170639.8178776363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6397800.0000, 
sim time next is 6398400.0000, 
raw observation next is [26.1, 85.0, 1.0, 2.0, 0.6685634448111113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761955.3894890782, 761955.3894890782, 170275.991865834], 
processed observation next is [1.0, 0.043478260869565216, 0.5222222222222223, 0.85, 1.0, 1.0, 0.6054326723941801, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2721269248175279, 0.2721269248175279, 0.32745383051121923], 
reward next is 0.6725, 
noisyNet noise sample is [array([-0.30133417], dtype=float32), 0.62047]. 
=============================================
[2019-03-24 00:41:00,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1780711e-12 1.0000000e+00 2.1241823e-16 3.0612961e-13 1.2856674e-15], sum to 1.0000
[2019-03-24 00:41:00,552] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-24 00:41:00,555] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 92.0, 1.0, 2.0, 0.8521304787463722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 973127.4189587752, 973127.4189587752, 207039.8124688348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6412200.0000, 
sim time next is 6412800.0000, 
raw observation next is [24.76666666666667, 92.0, 1.0, 2.0, 0.8164084812034409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931649.1061599533, 931649.1061599533, 199406.2463729599], 
processed observation next is [1.0, 0.21739130434782608, 0.4728395061728396, 0.92, 1.0, 1.0, 0.7814386680993344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33273182362855475, 0.33273182362855475, 0.38347355071723055], 
reward next is 0.6165, 
noisyNet noise sample is [array([-0.27028257], dtype=float32), 0.87601507]. 
=============================================
[2019-03-24 00:41:08,436] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 00:41:08,437] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:41:08,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:41:08,438] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:41:08,442] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:41:08,442] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:41:08,444] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:41:08,445] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:41:08,446] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:41:08,444] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:41:08,446] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:41:08,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-24 00:41:08,461] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-24 00:41:08,502] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-24 00:41:08,502] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-24 00:41:08,503] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-24 00:41:11,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:41:11,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.9, 56.0, 1.0, 2.0, 0.2032251142908654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 262132.6020682549, 262132.6020682549, 77320.13845000962]
[2019-03-24 00:41:11,768] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:41:11,770] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2274050e-16 1.0000000e+00 2.6599062e-22 1.1016204e-16 3.3834236e-21], sampled 0.05525828856998838
[2019-03-24 00:41:15,143] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:41:15,144] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.23333333333333, 51.0, 1.0, 2.0, 0.2614865357463556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337298.3916435229, 337298.3916435229, 109398.1084248186]
[2019-03-24 00:41:15,145] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:41:15,147] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2124277e-17 1.0000000e+00 8.2792953e-23 4.6623661e-17 1.1196017e-21], sampled 0.2226711543895118
[2019-03-24 00:41:28,086] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:41:28,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.09938136666667, 39.55789873, 1.0, 2.0, 0.6661393345688991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797983.6389341896, 797983.6389341896, 171559.3137367201]
[2019-03-24 00:41:28,088] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:41:28,090] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7125211e-16 1.0000000e+00 7.8372480e-22 2.4422157e-16 9.4198722e-21], sampled 0.40883684426125877
[2019-03-24 00:41:55,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:41:55,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.6298061278446234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 731469.1706142032, 731469.1706142027, 163941.0100291949]
[2019-03-24 00:41:55,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:41:55,832] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.2579231e-16 1.0000000e+00 1.9312613e-21 4.7466239e-16 2.2141441e-20], sampled 0.28926737587267937
[2019-03-24 00:42:26,112] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:26,114] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.91438585666667, 83.74143692000001, 1.0, 2.0, 0.4051518926691096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499436.3047803896, 499436.3047803896, 129287.7252632548]
[2019-03-24 00:42:26,115] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:42:26,118] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5700544e-16 1.0000000e+00 3.7200893e-22 1.4106020e-16 4.6494978e-21], sampled 0.33882805009963557
[2019-03-24 00:42:28,922] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:28,923] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.09190156, 61.26615016666666, 1.0, 2.0, 0.6169607725570838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723805.1578160453, 723805.1578160453, 161985.1943889699]
[2019-03-24 00:42:28,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:42:28,926] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.8046736e-16 1.0000000e+00 2.7445826e-21 6.1491987e-16 3.0891167e-20], sampled 0.09011369068528752
[2019-03-24 00:42:32,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:32,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.65, 91.0, 1.0, 2.0, 0.7063605362905407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 828118.9430766484, 828118.9430766493, 178460.964074454]
[2019-03-24 00:42:32,481] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:42:32,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1791513e-15 1.0000000e+00 5.8053854e-21 1.0679150e-15 6.2823437e-20], sampled 0.23029884366525044
[2019-03-24 00:42:42,159] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:42,160] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.7, 57.0, 1.0, 2.0, 0.740391491215396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934063.258068443, 934063.258068443, 187196.4580762826]
[2019-03-24 00:42:42,162] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:42:42,165] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.2569841e-15 1.0000000e+00 5.6435858e-20 5.7041596e-15 5.4207855e-19], sampled 0.015336643886298962
[2019-03-24 00:42:43,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:43,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.20170514333334, 84.25244604, 1.0, 2.0, 0.3999053057818548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495662.405393858, 495662.405393858, 128609.5953235059]
[2019-03-24 00:42:43,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:42:43,864] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3592877e-16 1.0000000e+00 6.4797827e-22 2.1232264e-16 7.8668754e-21], sampled 0.8815510457410389
[2019-03-24 00:42:47,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.20695549]
[2019-03-24 00:42:47,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.6738344540414617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767965.7178469319, 767965.7178469319, 171251.9114230577]
[2019-03-24 00:42:47,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:42:47,840] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2560098e-16 1.0000000e+00 2.9953410e-21 6.5585856e-16 3.3558278e-20], sampled 0.05034571985109426
[2019-03-24 00:42:56,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:42:56,316] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:42:56,418] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:42:56,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:42:56,473] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:42:57,486] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 175000, evaluation results [175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:42:58,276] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175414: loss 0.2038
[2019-03-24 00:42:58,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175414: learning rate 0.0001
[2019-03-24 00:42:58,586] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175579: loss 0.4958
[2019-03-24 00:42:58,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175579: learning rate 0.0001
[2019-03-24 00:42:58,637] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175606: loss 0.5448
[2019-03-24 00:42:58,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175606: learning rate 0.0001
[2019-03-24 00:42:58,780] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175683: loss 0.2692
[2019-03-24 00:42:58,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175685: learning rate 0.0001
[2019-03-24 00:42:59,073] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175836: loss 0.4405
[2019-03-24 00:42:59,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175836: learning rate 0.0001
[2019-03-24 00:42:59,214] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175910: loss 0.7962
[2019-03-24 00:42:59,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175910: learning rate 0.0001
[2019-03-24 00:42:59,272] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175934: loss 0.5131
[2019-03-24 00:42:59,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175937: learning rate 0.0001
[2019-03-24 00:42:59,286] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175944: loss 0.5776
[2019-03-24 00:42:59,287] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175944: learning rate 0.0001
[2019-03-24 00:42:59,414] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176009: loss 0.5367
[2019-03-24 00:42:59,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176009: learning rate 0.0001
[2019-03-24 00:42:59,609] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176111: loss 0.7378
[2019-03-24 00:42:59,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176111: learning rate 0.0001
[2019-03-24 00:42:59,671] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176142: loss 0.7013
[2019-03-24 00:42:59,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176142: learning rate 0.0001
[2019-03-24 00:42:59,746] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176184: loss 0.4700
[2019-03-24 00:42:59,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176186: learning rate 0.0001
[2019-03-24 00:42:59,870] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176246: loss 0.1685
[2019-03-24 00:42:59,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176246: learning rate 0.0001
[2019-03-24 00:42:59,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176270: loss 0.0939
[2019-03-24 00:42:59,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176270: learning rate 0.0001
[2019-03-24 00:43:00,185] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176406: loss 0.0458
[2019-03-24 00:43:00,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176407: learning rate 0.0001
[2019-03-24 00:43:00,315] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176472: loss 0.0320
[2019-03-24 00:43:00,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176473: learning rate 0.0001
[2019-03-24 00:43:00,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8485392e-15 1.0000000e+00 6.6057765e-20 1.4928573e-15 8.2036981e-20], sum to 1.0000
[2019-03-24 00:43:00,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6919
[2019-03-24 00:43:00,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.61666666666667, 59.66666666666667, 1.0, 2.0, 0.3890897367463709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483599.4292004593, 483599.4292004593, 127125.1470235174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6639000.0000, 
sim time next is 6639600.0000, 
raw observation next is [24.63333333333333, 58.33333333333334, 1.0, 2.0, 0.3853731363589858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 480206.2393641761, 480206.2393641756, 126634.5383058482], 
processed observation next is [1.0, 0.8695652173913043, 0.46790123456790106, 0.5833333333333335, 1.0, 1.0, 0.2683013528083164, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1715022283443486, 0.17150222834434842, 0.2435279582804773], 
reward next is 0.7565, 
noisyNet noise sample is [array([-0.41034102], dtype=float32), -1.0837979]. 
=============================================
[2019-03-24 00:43:03,519] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5489304e-17 1.0000000e+00 3.4498477e-24 3.9455040e-17 7.0194169e-24], sum to 1.0000
[2019-03-24 00:43:03,526] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2993
[2019-03-24 00:43:03,532] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 44.50000000000001, 1.0, 2.0, 0.3192187026086005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411788.6324863221, 411788.6324863221, 111290.2608871726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [22.9, 45.0, 1.0, 2.0, 0.2896552188353633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373642.7715324259, 373642.7715324259, 108164.4186723898], 
processed observation next is [1.0, 0.21739130434782608, 0.4037037037037037, 0.45, 1.0, 1.0, 0.15435145099448014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1334438469758664, 0.1334438469758664, 0.20800849744690347], 
reward next is 0.7920, 
noisyNet noise sample is [array([-0.48000506], dtype=float32), 0.22032602]. 
=============================================
[2019-03-24 00:43:03,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.01952]
 [68.04889]
 [67.99422]
 [68.00763]
 [68.02068]], R is [[68.16603851]
 [68.27035522]
 [68.38356018]
 [68.4942627 ]
 [68.60186768]].
[2019-03-24 00:43:06,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6854887e-17 1.0000000e+00 3.1670748e-24 2.8603275e-18 2.0724764e-23], sum to 1.0000
[2019-03-24 00:43:06,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8445
[2019-03-24 00:43:06,606] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.08333333333333, 84.66666666666667, 1.0, 2.0, 0.3268963072547721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419347.5798206844, 419347.5798206844, 118963.5320092202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6756600.0000, 
sim time next is 6757200.0000, 
raw observation next is [18.0, 85.0, 1.0, 2.0, 0.3225121509125046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413895.4883950911, 413895.4883950907, 118401.9200806776], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.85, 1.0, 1.0, 0.19346684632441027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1478198172839611, 0.14781981728396096, 0.22769600015514924], 
reward next is 0.7723, 
noisyNet noise sample is [array([0.51269805], dtype=float32), 1.6372591]. 
=============================================
[2019-03-24 00:43:10,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6093970e-17 1.0000000e+00 8.9686508e-26 1.1970802e-16 5.5494146e-21], sum to 1.0000
[2019-03-24 00:43:10,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5878
[2019-03-24 00:43:10,415] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1412181.910963888 W.
[2019-03-24 00:43:10,421] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.1, 56.0, 1.0, 2.0, 0.6044382455622719, 1.0, 2.0, 0.6044382455622719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1412181.910963888, 1412181.910963888, 271176.7251562654], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6800400.0000, 
sim time next is 6801000.0000, 
raw observation next is [27.93333333333333, 56.83333333333334, 1.0, 2.0, 0.2111329570553554, 1.0, 2.0, 0.2111329570553554, 1.0, 1.0, 0.3370877766809955, 6.9112, 6.9112, 121.94756008, 737896.2542162361, 737896.2542162361, 224208.4912646679], 
processed observation next is [1.0, 0.7391304347826086, 0.5901234567901233, 0.5683333333333335, 1.0, 1.0, 0.06087256792304214, 1.0, 1.0, 0.06087256792304214, 1.0, 0.5, 0.17135972085124435, 0.0, 0.0, 0.8096049824067558, 0.2635343765057986, 0.2635343765057986, 0.4311701755089767], 
reward next is 0.5688, 
noisyNet noise sample is [array([-0.09341582], dtype=float32), -1.1779046]. 
=============================================
[2019-03-24 00:43:10,445] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.20594]
 [73.46931]
 [73.34609]
 [72.69484]
 [72.016  ]], R is [[75.75787354]
 [75.47880554]
 [75.19696045]
 [74.44499207]
 [73.70054626]].
[2019-03-24 00:43:13,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5106824e-16 1.0000000e+00 9.5096599e-22 3.8031666e-16 5.7288462e-22], sum to 1.0000
[2019-03-24 00:43:13,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3446
[2019-03-24 00:43:13,490] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 54.33333333333333, 1.0, 2.0, 0.4848194033303901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 582799.1423444398, 582799.1423444393, 140692.2570751269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6889200.0000, 
sim time next is 6889800.0000, 
raw observation next is [28.01666666666667, 54.66666666666667, 1.0, 2.0, 0.4828680465283668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580873.9321538435, 580873.9321538435, 140404.9077172731], 
processed observation next is [0.0, 0.7391304347826086, 0.59320987654321, 0.5466666666666667, 1.0, 1.0, 0.3843667220575795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2074549757692298, 0.2074549757692298, 0.2700094379178329], 
reward next is 0.7300, 
noisyNet noise sample is [array([0.7683707], dtype=float32), -1.2655154]. 
=============================================
[2019-03-24 00:43:13,888] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183547: loss 0.1193
[2019-03-24 00:43:13,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183548: learning rate 0.0001
[2019-03-24 00:43:13,989] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183600: loss 0.0485
[2019-03-24 00:43:13,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183600: learning rate 0.0001
[2019-03-24 00:43:14,008] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183606: loss 0.0445
[2019-03-24 00:43:14,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183606: learning rate 0.0001
[2019-03-24 00:43:14,015] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183608: loss 0.0706
[2019-03-24 00:43:14,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183609: learning rate 0.0001
[2019-03-24 00:43:14,399] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183806: loss 0.4879
[2019-03-24 00:43:14,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183809: learning rate 0.0001
[2019-03-24 00:43:14,473] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183846: loss 0.0815
[2019-03-24 00:43:14,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183846: learning rate 0.0001
[2019-03-24 00:43:14,525] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183873: loss 0.0108
[2019-03-24 00:43:14,527] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183873: learning rate 0.0001
[2019-03-24 00:43:14,761] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183997: loss 0.0183
[2019-03-24 00:43:14,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183999: learning rate 0.0001
[2019-03-24 00:43:14,928] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184089: loss 0.0620
[2019-03-24 00:43:14,929] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184089: learning rate 0.0001
[2019-03-24 00:43:14,949] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184097: loss 0.0747
[2019-03-24 00:43:14,953] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184100: learning rate 0.0001
[2019-03-24 00:43:15,022] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184134: loss 0.0839
[2019-03-24 00:43:15,023] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184134: learning rate 0.0001
[2019-03-24 00:43:15,090] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184171: loss 0.0145
[2019-03-24 00:43:15,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184171: learning rate 0.0001
[2019-03-24 00:43:15,325] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184293: loss 0.0722
[2019-03-24 00:43:15,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184293: learning rate 0.0001
[2019-03-24 00:43:15,390] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184328: loss 0.0019
[2019-03-24 00:43:15,393] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184328: learning rate 0.0001
[2019-03-24 00:43:15,512] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184390: loss 0.1796
[2019-03-24 00:43:15,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184391: learning rate 0.0001
[2019-03-24 00:43:15,589] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184427: loss 0.2466
[2019-03-24 00:43:15,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184428: learning rate 0.0001
[2019-03-24 00:43:19,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8372365e-20 1.0000000e+00 1.2585300e-26 8.9799755e-20 2.5480981e-25], sum to 1.0000
[2019-03-24 00:43:19,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-24 00:43:19,204] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 44.0, 1.0, 2.0, 0.5148503194355282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612064.994449293, 612064.994449293, 145172.3183029748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6973200.0000, 
sim time next is 6973800.0000, 
raw observation next is [30.93333333333333, 44.66666666666667, 1.0, 2.0, 0.5200985827805858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619419.9875216929, 619419.9875216929, 146054.4427243699], 
processed observation next is [0.0, 0.7391304347826086, 0.7012345679012344, 0.4466666666666667, 1.0, 1.0, 0.42868878902450697, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22122142411489032, 0.22122142411489032, 0.280873928316096], 
reward next is 0.7191, 
noisyNet noise sample is [array([0.08150973], dtype=float32), 1.4455569]. 
=============================================
[2019-03-24 00:43:25,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6941821e-20 1.0000000e+00 4.6034130e-23 9.1300876e-21 5.8905895e-25], sum to 1.0000
[2019-03-24 00:43:25,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4691
[2019-03-24 00:43:25,595] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 83.33333333333334, 1.0, 2.0, 0.4524526975669524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564469.878713842, 564469.878713842, 136333.768858459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7111200.0000, 
sim time next is 7111800.0000, 
raw observation next is [20.75, 83.0, 1.0, 2.0, 0.4371697345443328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545862.8281153433, 545862.8281153433, 134064.7183201529], 
processed observation next is [1.0, 0.30434782608695654, 0.32407407407407407, 0.83, 1.0, 1.0, 0.3299639696956343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19495101004119406, 0.19495101004119406, 0.257816766000294], 
reward next is 0.7422, 
noisyNet noise sample is [array([-0.05303173], dtype=float32), 0.079354376]. 
=============================================
[2019-03-24 00:43:29,271] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191542: loss 0.2436
[2019-03-24 00:43:29,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191543: learning rate 0.0001
[2019-03-24 00:43:29,317] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191566: loss 0.4450
[2019-03-24 00:43:29,323] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191569: loss 0.4439
[2019-03-24 00:43:29,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191569: learning rate 0.0001
[2019-03-24 00:43:29,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191569: learning rate 0.0001
[2019-03-24 00:43:29,395] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191608: loss 0.0514
[2019-03-24 00:43:29,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191608: learning rate 0.0001
[2019-03-24 00:43:29,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191621: loss 0.0778
[2019-03-24 00:43:29,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191621: learning rate 0.0001
[2019-03-24 00:43:29,812] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191828: loss 0.0515
[2019-03-24 00:43:29,815] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191828: learning rate 0.0001
[2019-03-24 00:43:29,979] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191914: loss 0.1661
[2019-03-24 00:43:29,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191914: learning rate 0.0001
[2019-03-24 00:43:30,041] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191947: loss 0.0004
[2019-03-24 00:43:30,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191948: learning rate 0.0001
[2019-03-24 00:43:30,421] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192144: loss 0.0747
[2019-03-24 00:43:30,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192144: learning rate 0.0001
[2019-03-24 00:43:30,487] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192183: loss 0.0486
[2019-03-24 00:43:30,490] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192183: learning rate 0.0001
[2019-03-24 00:43:30,528] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192203: loss 0.0212
[2019-03-24 00:43:30,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192203: learning rate 0.0001
[2019-03-24 00:43:30,535] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192205: loss 0.0634
[2019-03-24 00:43:30,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192206: learning rate 0.0001
[2019-03-24 00:43:30,558] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192216: loss 0.0572
[2019-03-24 00:43:30,559] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192216: learning rate 0.0001
[2019-03-24 00:43:30,700] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192292: loss 0.1834
[2019-03-24 00:43:30,702] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192292: learning rate 0.0001
[2019-03-24 00:43:31,070] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192490: loss 0.1110
[2019-03-24 00:43:31,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192490: learning rate 0.0001
[2019-03-24 00:43:31,129] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192515: loss 0.0239
[2019-03-24 00:43:31,132] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192516: learning rate 0.0001
[2019-03-24 00:43:35,092] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5686030e-14 1.0000000e+00 2.1131239e-18 4.7210559e-15 3.5633779e-17], sum to 1.0000
[2019-03-24 00:43:35,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2193
[2019-03-24 00:43:35,106] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 86.0, 1.0, 2.0, 0.6449332156307481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790432.9902705422, 790432.9902705422, 168230.1681527025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290000.0000, 
sim time next is 7290600.0000, 
raw observation next is [21.83333333333333, 85.33333333333334, 1.0, 2.0, 0.6904513184330424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845762.5195425039, 845762.5195425039, 176775.0081427108], 
processed observation next is [1.0, 0.391304347826087, 0.36419753086419737, 0.8533333333333334, 1.0, 1.0, 0.6314896648012409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30205804269375136, 0.30205804269375136, 0.33995193873598234], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.30763456], dtype=float32), -0.8799245]. 
=============================================
[2019-03-24 00:43:39,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9033495e-16 1.0000000e+00 6.3476201e-22 2.0145446e-16 3.2366733e-21], sum to 1.0000
[2019-03-24 00:43:39,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1603
[2019-03-24 00:43:39,183] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.21666666666667, 96.0, 1.0, 2.0, 0.3687376245508701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460442.8929499286, 460442.8929499286, 124374.9564370938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7368600.0000, 
sim time next is 7369200.0000, 
raw observation next is [19.2, 96.0, 1.0, 2.0, 0.3754940432708817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468979.2119544517, 468979.2119544517, 125296.4571319123], 
processed observation next is [1.0, 0.30434782608695654, 0.26666666666666666, 0.96, 1.0, 1.0, 0.2565405277034306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16749257569801845, 0.16749257569801845, 0.2409547252536775], 
reward next is 0.7590, 
noisyNet noise sample is [array([-0.23696193], dtype=float32), -0.13801843]. 
=============================================
[2019-03-24 00:43:44,572] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199472: loss 0.4417
[2019-03-24 00:43:44,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199474: learning rate 0.0001
[2019-03-24 00:43:44,600] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199488: loss 0.4290
[2019-03-24 00:43:44,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199488: learning rate 0.0001
[2019-03-24 00:43:44,709] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199539: loss 0.0338
[2019-03-24 00:43:44,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199539: learning rate 0.0001
[2019-03-24 00:43:44,804] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199592: loss 0.0322
[2019-03-24 00:43:44,806] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199593: learning rate 0.0001
[2019-03-24 00:43:45,001] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199690: loss 0.0825
[2019-03-24 00:43:45,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199691: learning rate 0.0001
[2019-03-24 00:43:45,293] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199834: loss 0.0673
[2019-03-24 00:43:45,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199835: learning rate 0.0001
[2019-03-24 00:43:45,377] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199874: loss 0.0003
[2019-03-24 00:43:45,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199874: learning rate 0.0001
[2019-03-24 00:43:45,630] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 00:43:45,631] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:43:45,631] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:43:45,632] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:45,633] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:45,633] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:43:45,633] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:43:45,634] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:45,635] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:45,635] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:43:45,636] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:45,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-24 00:43:45,677] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-24 00:43:45,678] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-24 00:43:45,678] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-24 00:43:45,717] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-24 00:43:48,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:43:48,310] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.40021191333334, 20.420028445, 1.0, 2.0, 0.59589590598678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733529.1425550344, 733529.1425550344, 159508.4712886641]
[2019-03-24 00:43:48,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:43:48,314] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4163694e-19 1.0000000e+00 1.1907719e-24 3.7753640e-19 4.1478890e-23], sampled 0.8486410492423643
[2019-03-24 00:43:48,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:43:48,826] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.65, 10.33333333333333, 1.0, 2.0, 0.351368395989655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453273.6420878447, 453273.6420878447, 105181.1873426666]
[2019-03-24 00:43:48,826] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:43:48,831] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.6919048e-20 1.0000000e+00 8.9866991e-26 5.2000667e-20 3.7104479e-24], sampled 0.5946223844354835
[2019-03-24 00:43:56,821] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:43:56,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [38.0, 15.0, 1.0, 2.0, 0.5573350092121653, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9123403384776113, 6.911199999999999, 6.9112, 121.9260426156618, 1363916.306324064, 1363916.306324065, 274484.4281680345]
[2019-03-24 00:43:56,824] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:43:56,829] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9216437e-19 1.0000000e+00 5.6317648e-25 2.1252085e-19 2.0607931e-23], sampled 0.48312066482069105
[2019-03-24 00:43:56,831] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1363916.306324064 W.
[2019-03-24 00:43:57,196] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:43:57,199] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.3, 48.0, 1.0, 2.0, 0.2999448921115587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382784.5362341509, 382784.5362341509, 115568.7550491971]
[2019-03-24 00:43:57,200] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:43:57,203] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3230095e-19 1.0000000e+00 3.4639030e-25 1.4641252e-19 1.3087759e-23], sampled 0.06080394997616334
[2019-03-24 00:43:58,294] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:43:58,296] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.26666666666667, 61.33333333333334, 1.0, 2.0, 0.3928074039470443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488801.8696444911, 488801.8696444906, 127655.3603023668]
[2019-03-24 00:43:58,296] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:43:58,299] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0724238e-19 1.0000000e+00 2.6357011e-25 1.1870877e-19 1.0138390e-23], sampled 0.830574857435074
[2019-03-24 00:44:13,807] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:44:13,809] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.36666666666667, 92.33333333333334, 1.0, 2.0, 0.3613194956726943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 452796.0550951585, 452796.0550951581, 123402.9313183395]
[2019-03-24 00:44:13,811] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:44:13,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5286237e-19 1.0000000e+00 4.1808637e-25 1.6911868e-19 1.5600964e-23], sampled 0.008089112652106878
[2019-03-24 00:44:25,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:44:25,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.83333333333333, 90.66666666666667, 1.0, 2.0, 0.5763890169914578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687068.739740027, 687068.739740027, 155395.4701197054]
[2019-03-24 00:44:25,446] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:44:25,449] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.7443996e-20 1.0000000e+00 2.3269301e-25 1.0787301e-19 9.0238430e-24], sampled 0.13679336671765974
[2019-03-24 00:45:01,625] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:45:01,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.7, 81.0, 1.0, 2.0, 0.6479996242017092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738507.7091978219, 738507.7091978219, 166532.295370711]
[2019-03-24 00:45:01,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:45:01,631] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.617249e-21 1.000000e+00 7.021200e-27 7.354978e-21 3.428239e-25], sampled 0.25545289204939037
[2019-03-24 00:45:26,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:45:26,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.11666666666667, 53.5, 1.0, 2.0, 0.2865461758020351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366211.7341251632, 366211.7341251632, 113930.4968912117]
[2019-03-24 00:45:26,020] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:45:26,023] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.5475579e-20 1.0000000e+00 6.2456219e-26 3.9333705e-20 2.6411779e-24], sampled 0.3533086754929543
[2019-03-24 00:45:28,278] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.23630488]
[2019-03-24 00:45:28,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.547597235, 101.61511393, 1.0, 2.0, 0.4060387052674931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501707.3962897736, 501707.3962897736, 129441.1515023004]
[2019-03-24 00:45:28,281] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:45:28,286] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0119400e-19 1.0000000e+00 2.4440964e-25 1.1201881e-19 9.4477114e-24], sampled 0.07892529867677167
[2019-03-24 00:45:33,125] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0839 2170604073.8558 493.0000
[2019-03-24 00:45:33,309] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:45:33,320] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:45:33,409] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:45:33,537] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:45:34,552] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 200000, evaluation results [200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.08387552638, 2170604073.8558493, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:45:34,684] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200070: loss 0.0461
[2019-03-24 00:45:34,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200070: learning rate 0.0001
[2019-03-24 00:45:34,690] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200073: loss 0.0446
[2019-03-24 00:45:34,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200073: learning rate 0.0001
[2019-03-24 00:45:34,903] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200183: loss 0.0132
[2019-03-24 00:45:34,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200184: learning rate 0.0001
[2019-03-24 00:45:34,909] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200186: loss 0.0249
[2019-03-24 00:45:34,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200187: learning rate 0.0001
[2019-03-24 00:45:34,980] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200225: loss 0.1463
[2019-03-24 00:45:34,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200226: learning rate 0.0001
[2019-03-24 00:45:35,026] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200250: loss 0.3505
[2019-03-24 00:45:35,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200250: learning rate 0.0001
[2019-03-24 00:45:35,075] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200271: loss 0.2776
[2019-03-24 00:45:35,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200271: learning rate 0.0001
[2019-03-24 00:45:35,345] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200418: loss 0.0077
[2019-03-24 00:45:35,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200418: learning rate 0.0001
[2019-03-24 00:45:35,719] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200607: loss 0.0438
[2019-03-24 00:45:35,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200607: learning rate 0.0001
[2019-03-24 00:45:38,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9825021e-24 1.0000000e+00 6.4576250e-29 2.1647333e-22 4.1009462e-28], sum to 1.0000
[2019-03-24 00:45:38,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9383
[2019-03-24 00:45:38,943] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 87.5, 1.0, 2.0, 0.4886856536334924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585999.4374593544, 585999.4374593544, 141241.6238457599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7601400.0000, 
sim time next is 7602000.0000, 
raw observation next is [22.73333333333333, 87.33333333333334, 1.0, 2.0, 0.4833168640661272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580955.5179806432, 580955.5179806427, 140458.4487482972], 
processed observation next is [0.0, 1.0, 0.39753086419753075, 0.8733333333333334, 1.0, 1.0, 0.3849010286501515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20748411356451543, 0.20748411356451527, 0.2701124014390331], 
reward next is 0.7299, 
noisyNet noise sample is [array([-0.12958089], dtype=float32), 0.850213]. 
=============================================
[2019-03-24 00:45:38,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[95.96552 ]
 [95.950676]
 [95.92312 ]
 [95.90094 ]
 [95.84394 ]], R is [[95.74512482]
 [95.51605225]
 [95.2877121 ]
 [95.0599823 ]
 [94.83318329]].
[2019-03-24 00:45:40,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9249138e-14 1.0000000e+00 6.1322266e-20 1.2716054e-15 1.1302161e-17], sum to 1.0000
[2019-03-24 00:45:40,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9004
[2019-03-24 00:45:40,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 84.0, 1.0, 2.0, 0.915489300444128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932633391255504, 6.9112, 121.925889803163, 1111694.238688794, 1100718.440427423, 223727.4941547404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7637400.0000, 
sim time next is 7638000.0000, 
raw observation next is [23.46666666666667, 83.33333333333334, 1.0, 2.0, 0.9278930443901336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.995163855576904, 6.9112, 121.925601143885, 1155317.904210207, 1112321.061234803, 226467.8239366773], 
processed observation next is [1.0, 0.391304347826087, 0.42469135802469143, 0.8333333333333335, 1.0, 1.0, 0.9141583861787306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008396385557690423, 0.0, 0.8094591979066363, 0.4126135372179311, 0.39725752186957247, 0.43551504603207175], 
reward next is 0.1447, 
noisyNet noise sample is [array([-1.260755], dtype=float32), 0.6096287]. 
=============================================
[2019-03-24 00:45:40,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.19486 ]
 [65.39628 ]
 [65.61521 ]
 [66.150475]
 [66.30746 ]], R is [[64.52944946]
 [64.34674072]
 [64.28466797]
 [64.22104645]
 [64.22408295]].
[2019-03-24 00:45:44,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0277777e-21 1.0000000e+00 3.9318672e-29 6.7260208e-21 2.4925763e-26], sum to 1.0000
[2019-03-24 00:45:44,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8966
[2019-03-24 00:45:44,028] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.91666666666666, 77.33333333333333, 1.0, 2.0, 0.3131419266893594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398424.6568671668, 398424.6568671668, 117209.8700329589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678200.0000, 
sim time next is 7678800.0000, 
raw observation next is [19.9, 78.0, 1.0, 2.0, 0.3163479656018405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402209.4503635289, 402209.4503635289, 117612.6525677301], 
processed observation next is [1.0, 0.9130434782608695, 0.2925925925925925, 0.78, 1.0, 1.0, 0.18612853047838152, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1436462322726889, 0.1436462322726889, 0.22617817801486556], 
reward next is 0.7738, 
noisyNet noise sample is [array([0.15723184], dtype=float32), 0.090963386]. 
=============================================
[2019-03-24 00:45:45,536] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5649530e-18 1.0000000e+00 1.7542166e-24 7.1933868e-18 3.3310812e-22], sum to 1.0000
[2019-03-24 00:45:45,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-24 00:45:45,546] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.18333333333334, 92.16666666666667, 1.0, 2.0, 0.3103585014018716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394639.0130860892, 394639.0130860892, 116858.779770845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7707000.0000, 
sim time next is 7707600.0000, 
raw observation next is [18.1, 94.0, 1.0, 2.0, 0.3147703728346104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399717.8601995404, 399717.8601995404, 117410.1471549808], 
processed observation next is [1.0, 0.21739130434782608, 0.22592592592592597, 0.94, 1.0, 1.0, 0.18425044385072667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.142756378642693, 0.142756378642693, 0.22578874452880923], 
reward next is 0.7742, 
noisyNet noise sample is [array([1.0599029], dtype=float32), 0.6343583]. 
=============================================
[2019-03-24 00:45:48,802] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207436: loss 0.0322
[2019-03-24 00:45:48,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207436: learning rate 0.0001
[2019-03-24 00:45:48,868] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207471: loss 0.0935
[2019-03-24 00:45:48,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207471: learning rate 0.0001
[2019-03-24 00:45:49,007] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207540: loss 0.3005
[2019-03-24 00:45:49,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207540: learning rate 0.0001
[2019-03-24 00:45:49,211] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207647: loss 0.3142
[2019-03-24 00:45:49,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207649: learning rate 0.0001
[2019-03-24 00:45:49,349] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207720: loss 0.0192
[2019-03-24 00:45:49,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207721: learning rate 0.0001
[2019-03-24 00:45:49,566] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207834: loss 0.0131
[2019-03-24 00:45:49,569] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207834: learning rate 0.0001
[2019-03-24 00:45:49,814] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207964: loss 0.5772
[2019-03-24 00:45:49,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207965: learning rate 0.0001
[2019-03-24 00:45:49,874] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207992: loss 0.8109
[2019-03-24 00:45:49,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207993: learning rate 0.0001
[2019-03-24 00:45:50,151] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208137: loss 0.3689
[2019-03-24 00:45:50,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208137: learning rate 0.0001
[2019-03-24 00:45:50,191] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208160: loss 0.2383
[2019-03-24 00:45:50,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208160: learning rate 0.0001
[2019-03-24 00:45:50,214] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208172: loss 0.2045
[2019-03-24 00:45:50,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208172: learning rate 0.0001
[2019-03-24 00:45:50,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208206: loss 0.1810
[2019-03-24 00:45:50,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208206: learning rate 0.0001
[2019-03-24 00:45:50,304] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208214: loss 0.1716
[2019-03-24 00:45:50,304] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208214: learning rate 0.0001
[2019-03-24 00:45:50,318] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208219: loss 0.1412
[2019-03-24 00:45:50,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208219: learning rate 0.0001
[2019-03-24 00:45:50,480] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.396354e-15 1.000000e+00 5.205249e-19 7.966627e-13 1.783479e-18], sum to 1.0000
[2019-03-24 00:45:50,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3219
[2019-03-24 00:45:50,490] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 43.33333333333334, 1.0, 2.0, 0.8272482022870862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032767.555900462, 1032767.555900462, 205215.4460417696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7811400.0000, 
sim time next is 7812000.0000, 
raw observation next is [27.7, 43.0, 1.0, 2.0, 0.888761854276296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.972649842010482, 6.9112, 121.9257811772168, 1139611.043544204, 1108143.299584757, 218875.6204385336], 
processed observation next is [1.0, 0.43478260869565216, 0.5814814814814815, 0.43, 1.0, 1.0, 0.8675736360432095, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.006144984201048231, 0.0, 0.809460393140738, 0.40700394412293, 0.39576546413741326, 0.4209146546894877], 
reward next is 0.2718, 
noisyNet noise sample is [array([-1.1870675], dtype=float32), -1.1696317]. 
=============================================
[2019-03-24 00:45:50,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.43538 ]
 [62.56197 ]
 [62.73984 ]
 [63.064133]
 [63.2767  ]], R is [[61.79077911]
 [61.77822495]
 [61.76773071]
 [61.75129318]
 [61.75704956]].
[2019-03-24 00:45:50,699] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208421: loss 0.8489
[2019-03-24 00:45:50,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208421: learning rate 0.0001
[2019-03-24 00:45:51,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7082284e-09 1.0000000e+00 7.9235891e-13 1.8117009e-09 4.0773240e-12], sum to 1.0000
[2019-03-24 00:45:51,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6521
[2019-03-24 00:45:51,117] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.98333333333333, 45.5, 1.0, 2.0, 0.4271968073332987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521671.87296828, 521671.8729682795, 132320.8266558193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7841400.0000, 
sim time next is 7842000.0000, 
raw observation next is [28.66666666666667, 47.0, 1.0, 2.0, 0.4310269308034933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526107.7406058445, 526107.7406058445, 132871.5221554558], 
processed observation next is [1.0, 0.782608695652174, 0.6172839506172841, 0.47, 1.0, 1.0, 0.3226511080993968, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18789562164494447, 0.18789562164494447, 0.25552215799126116], 
reward next is 0.7445, 
noisyNet noise sample is [array([-1.8649375], dtype=float32), 1.7090421]. 
=============================================
[2019-03-24 00:45:51,119] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208608: loss 2.0763
[2019-03-24 00:45:51,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208608: learning rate 0.0001
[2019-03-24 00:45:51,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[42.188236]
 [41.783512]
 [41.61664 ]
 [41.349823]
 [41.24723 ]], R is [[42.45597076]
 [42.77694702]
 [43.09660721]
 [43.41465759]
 [43.73100662]].
[2019-03-24 00:45:56,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2700204e-08 5.7359897e-03 1.4661365e-06 9.9091727e-01 3.3451926e-03], sum to 1.0000
[2019-03-24 00:45:56,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0403
[2019-03-24 00:45:56,578] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.68333333333333, 74.5, 1.0, 2.0, 0.2236107262910801, 1.0, 2.0, 0.2236107262910801, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540156.0115665072, 540156.0115665076, 164551.5804427218], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7948200.0000, 
sim time next is 7948800.0000, 
raw observation next is [23.6, 75.0, 1.0, 2.0, 0.223512763142335, 1.0, 2.0, 0.223512763142335, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539993.4604142805, 539993.460414281, 164532.9805985082], 
processed observation next is [1.0, 0.0, 0.4296296296296297, 0.75, 1.0, 1.0, 0.07561043231230358, 1.0, 1.0, 0.07561043231230358, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19285480729081447, 0.19285480729081464, 0.31640957807405423], 
reward next is 0.6836, 
noisyNet noise sample is [array([-0.49265334], dtype=float32), -0.37023002]. 
=============================================
[2019-03-24 00:45:57,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:57,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:57,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-24 00:45:57,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:57,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:57,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-24 00:45:57,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:57,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:57,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-24 00:45:57,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:57,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:57,773] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-24 00:45:57,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:57,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:57,990] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-24 00:45:58,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-24 00:45:58,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,322] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-24 00:45:58,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,364] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-24 00:45:58,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-24 00:45:58,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,452] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-24 00:45:58,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-24 00:45:58,544] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-24 00:45:58,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,580] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-24 00:45:58,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-24 00:45:58,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:45:58,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:45:58,725] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-24 00:45:58,655] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-24 00:45:59,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.465183]
 [63.57959 ]
 [63.483265]], R is [[0.68359042]
 [1.36030917]
 [2.03020071]].
[2019-03-24 00:46:05,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6577344e-16 4.9153599e-08 8.8898219e-13 1.0000000e+00 3.2137231e-09], sum to 1.0000
[2019-03-24 00:46:05,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6925
[2019-03-24 00:46:05,291] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 77.0, 1.0, 2.0, 0.2033974739656958, 1.0, 2.0, 0.2033974739656958, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 504100.5302117264, 504100.5302117269, 160637.576740951], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 102000.0000, 
sim time next is 102600.0000, 
raw observation next is [21.4, 77.0, 1.0, 2.0, 0.200948250649445, 1.0, 2.0, 0.200948250649445, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 498832.2206010259, 498832.2206010263, 160140.5628366322], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.77, 1.0, 1.0, 0.048747917439815464, 1.0, 1.0, 0.048747917439815464, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1781543645003664, 0.17815436450036654, 0.3079626208396773], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.6664566], dtype=float32), 0.51556647]. 
=============================================
[2019-03-24 00:46:05,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2120655e-08 4.0941409e-04 4.4526852e-05 9.9269366e-01 6.8523264e-03], sum to 1.0000
[2019-03-24 00:46:05,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8638
[2019-03-24 00:46:05,722] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 53.0, 1.0, 2.0, 0.5824223518376754, 1.0, 2.0, 0.5824223518376754, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1377805.881695347, 1377805.881695347, 264312.1744755626], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 122400.0000, 
sim time next is 123000.0000, 
raw observation next is [28.41666666666667, 51.83333333333334, 1.0, 2.0, 0.5622307244213341, 1.0, 2.0, 0.5622307244213341, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1327222.599008921, 1327222.599008921, 257358.6172143115], 
processed observation next is [1.0, 0.43478260869565216, 0.6080246913580248, 0.5183333333333334, 1.0, 1.0, 0.47884610050158827, 1.0, 1.0, 0.47884610050158827, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4740080710746147, 0.4740080710746147, 0.4949204177198298], 
reward next is 0.5051, 
noisyNet noise sample is [array([0.74897075], dtype=float32), -0.20328653]. 
=============================================
[2019-03-24 00:46:05,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.705963]
 [53.529545]
 [53.403915]
 [53.322857]
 [53.178738]], R is [[53.87483215]
 [53.82778931]
 [53.78922272]
 [53.75794601]
 [53.7334137 ]].
[2019-03-24 00:46:09,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6995244e-08 2.1072992e-03 7.1932764e-06 9.9766386e-01 2.2153840e-04], sum to 1.0000
[2019-03-24 00:46:09,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1675
[2019-03-24 00:46:09,178] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 12.0, 1.0, 2.0, 0.1701824714720476, 1.0, 2.0, 0.1701824714720476, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439074.8604299804, 439074.8604299809, 137254.6656063042], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 172800.0000, 
sim time next is 173400.0000, 
raw observation next is [29.15, 12.33333333333333, 1.0, 2.0, 0.1685606377359563, 1.0, 2.0, 0.1685606377359563, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 434889.3039559638, 434889.3039559643, 136518.6239964193], 
processed observation next is [0.0, 0.0, 0.6351851851851852, 0.12333333333333331, 1.0, 1.0, 0.010191235399947983, 1.0, 1.0, 0.010191235399947983, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15531760855570137, 0.15531760855570154, 0.26253581537772946], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.6090858], dtype=float32), -0.036564443]. 
=============================================
[2019-03-24 00:46:09,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7584610e-07 8.6099806e-04 2.5762718e-05 9.9898344e-01 1.2901842e-04], sum to 1.0000
[2019-03-24 00:46:09,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1809
[2019-03-24 00:46:09,308] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.4, 15.0, 1.0, 2.0, 0.1609439576517246, 1.0, 2.0, 0.1609439576517246, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415232.8198535314, 415232.8198535314, 132745.4472371993], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 177600.0000, 
sim time next is 178200.0000, 
raw observation next is [27.15, 15.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411957.5837821446, 411957.583782145, 132203.2399402621], 
processed observation next is [0.0, 0.043478260869565216, 0.561111111111111, 0.155, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14712770849362306, 0.14712770849362322, 0.25423699988511944], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8303318], dtype=float32), 0.90027654]. 
=============================================
[2019-03-24 00:46:11,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3501511e-10 1.4770968e-04 4.0518383e-08 9.9985230e-01 9.2089208e-10], sum to 1.0000
[2019-03-24 00:46:11,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7565
[2019-03-24 00:46:11,752] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 20.0, 1.0, 2.0, 0.1858206777135588, 1.0, 2.0, 0.1858206777135588, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472295.9795243673, 472295.9795243677, 157188.9914919274], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 239400.0000, 
sim time next is 240000.0000, 
raw observation next is [31.46666666666667, 20.66666666666667, 1.0, 2.0, 0.1851605281237271, 1.0, 2.0, 0.1851605281237271, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470530.5251641595, 470530.52516416, 157052.0975378402], 
processed observation next is [0.0, 0.782608695652174, 0.7209876543209878, 0.20666666666666672, 1.0, 1.0, 0.029953009671103693, 1.0, 1.0, 0.029953009671103693, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16804661613005695, 0.16804661613005714, 0.30202326449584654], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.610762], dtype=float32), -0.7279323]. 
=============================================
[2019-03-24 00:46:11,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.94806 ]
 [67.90175 ]
 [67.87536 ]
 [67.847336]
 [67.76926 ]], R is [[67.99227905]
 [68.0100708 ]
 [68.0273819 ]
 [68.04380798]
 [68.06012726]].
[2019-03-24 00:46:12,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9135959e-07 6.0671108e-04 1.1612071e-05 9.9938118e-01 2.2914017e-07], sum to 1.0000
[2019-03-24 00:46:12,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6571
[2019-03-24 00:46:12,228] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.63333333333334, 15.0, 1.0, 2.0, 0.1930176131829015, 1.0, 2.0, 0.1930176131829015, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491193.9376300322, 491193.9376300327, 158687.9378151915], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 231600.0000, 
sim time next is 232200.0000, 
raw observation next is [33.65000000000001, 15.0, 1.0, 2.0, 0.1924387569020648, 1.0, 2.0, 0.1924387569020648, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489728.188844594, 489728.1888445945, 158567.1235022547], 
processed observation next is [0.0, 0.6956521739130435, 0.8018518518518524, 0.15, 1.0, 1.0, 0.03861756774055333, 1.0, 1.0, 0.03861756774055333, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.174902924587355, 0.17490292458735518, 0.30493677596587443], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.5485502], dtype=float32), -0.45064142]. 
=============================================
[2019-03-24 00:46:24,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1096760e-06 3.1564289e-01 6.1888636e-07 6.8433446e-01 1.9970439e-05], sum to 1.0000
[2019-03-24 00:46:24,968] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9388
[2019-03-24 00:46:24,974] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.76666666666667, 24.66666666666666, 1.0, 2.0, 0.1842187699839746, 1.0, 2.0, 0.1842187699839746, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461764.0699462772, 461764.0699462777, 156756.3986999423], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 495600.0000, 
sim time next is 496200.0000, 
raw observation next is [31.53333333333333, 25.33333333333334, 1.0, 2.0, 0.1843526375581196, 1.0, 2.0, 0.1843526375581196, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462091.6017912854, 462091.6017912859, 156784.2792308817], 
processed observation next is [1.0, 0.7391304347826086, 0.7234567901234568, 0.2533333333333334, 1.0, 1.0, 0.028991235188237607, 1.0, 1.0, 0.028991235188237607, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16503271492545907, 0.16503271492545926, 0.3015082292901571], 
reward next is 0.6985, 
noisyNet noise sample is [array([-1.748836], dtype=float32), -0.0064748013]. 
=============================================
[2019-03-24 00:46:25,041] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 00:46:25,044] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:46:25,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:25,045] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:46:25,047] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:46:25,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:25,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:46:25,048] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:25,049] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:25,049] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:46:25,051] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:25,058] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-24 00:46:25,082] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-24 00:46:25,105] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-24 00:46:25,108] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-24 00:46:25,154] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-24 00:46:55,570] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.25410196]
[2019-03-24 00:46:55,571] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.06666666666667, 89.16666666666667, 1.0, 2.0, 0.3631506973492579, 1.0, 2.0, 0.3631506973492579, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836468.6588087736, 836468.6588087736, 196721.3105029883]
[2019-03-24 00:46:55,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:46:55,576] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6242384e-05 2.6428133e-01 4.9467226e-06 7.3557407e-01 5.3378153e-05], sampled 0.07023538066913781
[2019-03-24 00:47:20,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.25410196]
[2019-03-24 00:47:20,800] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.37106781, 87.00336506, 1.0, 2.0, 0.3315743151132184, 1.0, 1.0, 0.3315743151132184, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755781.1345100437, 755781.1345100441, 188210.1706450769]
[2019-03-24 00:47:20,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:47:20,805] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.1864793e-05 2.5969467e-01 3.8660946e-06 7.4018580e-01 4.3859403e-05], sampled 0.8779555405146218
[2019-03-24 00:47:24,110] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.25410196]
[2019-03-24 00:47:24,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 94.0, 1.0, 2.0, 0.3963185533323191, 1.0, 2.0, 0.3963185533323191, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 903444.3005304541, 903444.3005304541, 205181.8271793817]
[2019-03-24 00:47:24,113] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:47:24,115] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5831511e-05 2.5722399e-01 3.4428335e-06 7.4266666e-01 4.0096042e-05], sampled 0.06962810623393079
[2019-03-24 00:47:42,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.25410196]
[2019-03-24 00:47:42,400] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.348755956268064, 1.0, 2.0, 0.348755956268064, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794964.7911373801, 794964.7911373801, 192573.0349922418]
[2019-03-24 00:47:42,401] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:47:42,403] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.05053245e-04 2.69599885e-01 6.44579404e-06 7.30222881e-01
 6.57452256e-05], sampled 0.4053143817778281
[2019-03-24 00:47:56,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.25410196]
[2019-03-24 00:47:56,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.80420710666667, 64.10263140333333, 1.0, 2.0, 0.7134458259845308, 1.0, 2.0, 0.7134458259845308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 124.0921755517934, 1655325.817932583, 1655325.817932584, 311035.3588615622]
[2019-03-24 00:47:56,240] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:47:56,242] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4140511e-04 2.7723545e-01 9.6487993e-06 7.2252297e-01 9.0522401e-05], sampled 0.38642262162520613
[2019-03-24 00:48:13,098] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5906.0240 2426907997.7636 222.0000
[2019-03-24 00:48:13,134] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6217.9505 2609676735.7874 298.0000
[2019-03-24 00:48:13,294] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6258.1689 2392530340.3437 215.0000
[2019-03-24 00:48:13,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6575.8997 2332779150.3230 156.0000
[2019-03-24 00:48:13,430] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6057.6230 2367490850.8550 177.0000
[2019-03-24 00:48:14,444] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 225000, evaluation results [225000.0, 6217.950517853492, 2609676735.7873535, 298.0, 6057.622954006849, 2367490850.85497, 177.0, 6575.899708784676, 2332779150.323048, 156.0, 5906.024029933746, 2426907997.763625, 222.0, 6258.168873589287, 2392530340.343655, 215.0]
[2019-03-24 00:48:16,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8847946e-07 4.8074555e-03 2.3801017e-10 9.9519074e-01 1.4337031e-06], sum to 1.0000
[2019-03-24 00:48:16,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4672
[2019-03-24 00:48:16,027] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.73333333333333, 46.33333333333334, 1.0, 2.0, 0.1689842805953319, 1.0, 2.0, 0.1689842805953319, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 424082.7407220036, 424082.740722004, 153618.5744581386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 510000.0000, 
sim time next is 510600.0000, 
raw observation next is [25.46666666666667, 47.16666666666666, 1.0, 2.0, 0.167860567525517, 1.0, 2.0, 0.167860567525517, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421654.4595051915, 421654.4595051919, 153397.7538949468], 
processed observation next is [1.0, 0.9130434782608695, 0.4987654320987655, 0.47166666666666657, 1.0, 1.0, 0.009357818482758339, 1.0, 1.0, 0.009357818482758339, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15059087839471125, 0.15059087839471139, 0.2949956805672054], 
reward next is 0.7050, 
noisyNet noise sample is [array([2.1783202], dtype=float32), -0.19075489]. 
=============================================
[2019-03-24 00:48:18,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0491580e-07 1.4010941e-04 1.8767635e-08 9.9985695e-01 2.6392329e-06], sum to 1.0000
[2019-03-24 00:48:18,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-24 00:48:18,516] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 42.0, 1.0, 2.0, 0.437698207615686, 1.0, 2.0, 0.437698207615686, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1054320.029767953, 1054320.029767953, 219152.920930991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 563400.0000, 
sim time next is 564000.0000, 
raw observation next is [29.53333333333333, 41.0, 1.0, 2.0, 0.4651365923088303, 1.0, 2.0, 0.4651365923088303, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1121973.689477573, 1121973.689477573, 227380.452537629], 
processed observation next is [1.0, 0.5217391304347826, 0.6493827160493827, 0.41, 1.0, 1.0, 0.36325784798670274, 1.0, 1.0, 0.36325784798670274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4007048890991332, 0.4007048890991332, 0.4372701010339019], 
reward next is 0.5627, 
noisyNet noise sample is [array([-0.324514], dtype=float32), -1.2941666]. 
=============================================
[2019-03-24 00:48:18,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.855923]
 [54.924603]
 [54.754185]
 [54.78493 ]
 [54.742687]], R is [[54.74088287]
 [54.77202606]
 [54.78852844]
 [54.7388382 ]
 [54.67456055]].
[2019-03-24 00:48:24,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4080246e-10 1.5687236e-07 1.0812629e-13 9.9999988e-01 1.7726481e-09], sum to 1.0000
[2019-03-24 00:48:24,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8833
[2019-03-24 00:48:24,419] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.4, 36.0, 1.0, 2.0, 0.1642870127141219, 1.0, 2.0, 0.1642870127141219, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415281.4473621543, 415281.4473621547, 152718.8226102119], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 691200.0000, 
sim time next is 691800.0000, 
raw observation next is [27.25, 36.33333333333334, 1.0, 2.0, 0.1634274842167777, 1.0, 2.0, 0.1634274842167777, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413371.3020473931, 413371.3020473935, 152548.7961935229], 
processed observation next is [1.0, 0.0, 0.5648148148148148, 0.36333333333333345, 1.0, 1.0, 0.004080338353306771, 1.0, 1.0, 0.004080338353306771, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14763260787406896, 0.14763260787406912, 0.29336306960292863], 
reward next is 0.7066, 
noisyNet noise sample is [array([-1.1911366], dtype=float32), -1.3650432]. 
=============================================
[2019-03-24 00:48:24,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1705559e-10 2.4759192e-05 1.1186468e-11 9.9997520e-01 1.0505338e-09], sum to 1.0000
[2019-03-24 00:48:24,607] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3391
[2019-03-24 00:48:24,613] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.23333333333333, 38.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399560.289607101, 399560.2896071015, 150849.0548202511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 696000.0000, 
sim time next is 696600.0000, 
raw observation next is [26.1, 38.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397705.7050359992, 397705.7050359997, 150530.9775596021], 
processed observation next is [1.0, 0.043478260869565216, 0.5222222222222223, 0.385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14203775179857114, 0.14203775179857134, 0.289482649153081], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.72269696], dtype=float32), 1.651825]. 
=============================================
[2019-03-24 00:48:25,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0884070e-08 1.7895174e-05 1.1939671e-08 9.9998212e-01 2.6810561e-08], sum to 1.0000
[2019-03-24 00:48:25,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6692
[2019-03-24 00:48:25,034] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 29.0, 1.0, 2.0, 0.1785758601601558, 1.0, 2.0, 0.1785758601601558, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449559.9777917755, 449559.9777917759, 155619.0967406581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 682200.0000, 
sim time next is 682800.0000, 
raw observation next is [29.66666666666666, 29.66666666666666, 1.0, 2.0, 0.1784846637252133, 1.0, 2.0, 0.1784846637252133, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449242.5108572005, 449242.5108572005, 155598.5233127667], 
processed observation next is [1.0, 0.9130434782608695, 0.6543209876543208, 0.29666666666666663, 1.0, 1.0, 0.022005552053825348, 1.0, 1.0, 0.022005552053825348, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1604437538775716, 0.1604437538775716, 0.29922792944762827], 
reward next is 0.7008, 
noisyNet noise sample is [array([-1.4413356], dtype=float32), -1.2461538]. 
=============================================
[2019-03-24 00:48:27,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5914736e-11 1.0612307e-07 1.1192614e-11 9.9999988e-01 1.5770079e-09], sum to 1.0000
[2019-03-24 00:48:27,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2671
[2019-03-24 00:48:27,883] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.91666666666666, 24.0, 1.0, 2.0, 0.4841243619076971, 1.0, 2.0, 0.4841243619076971, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1200419.595985467, 1200419.595985468, 234130.1088091963], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 751800.0000, 
sim time next is 752400.0000, 
raw observation next is [31.9, 24.0, 1.0, 2.0, 0.5028998335418263, 1.0, 2.0, 0.5028998335418263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1246896.444237352, 1246896.444237353, 240042.5313794579], 
processed observation next is [1.0, 0.7391304347826086, 0.7370370370370369, 0.24, 1.0, 1.0, 0.4082140875497932, 1.0, 1.0, 0.4082140875497932, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4453201586561972, 0.4453201586561975, 0.46162025265280365], 
reward next is 0.5384, 
noisyNet noise sample is [array([-1.2839106], dtype=float32), 1.1860482]. 
=============================================
[2019-03-24 00:48:28,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3687464e-09 1.2311642e-07 3.7623082e-12 9.9999988e-01 3.9941908e-09], sum to 1.0000
[2019-03-24 00:48:28,793] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-24 00:48:28,798] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 40.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394251.8835190024, 394251.8835190028, 150263.6759785506], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [26.03333333333333, 41.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391954.3853854141, 391954.3853854145, 149896.67797256], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.41, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13998370906621932, 0.13998370906621949, 0.28826284225492305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5097767], dtype=float32), -0.6015238]. 
=============================================
[2019-03-24 00:48:37,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3651817e-07 7.1231052e-06 4.2299924e-11 9.9999273e-01 5.1155902e-10], sum to 1.0000
[2019-03-24 00:48:37,308] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5963
[2019-03-24 00:48:37,312] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 52.33333333333334, 1.0, 2.0, 0.1860018716134437, 1.0, 2.0, 0.1860018716134437, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461885.098139559, 461885.0981395594, 157023.0331441658], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 935400.0000, 
sim time next is 936000.0000, 
raw observation next is [25.3, 53.0, 1.0, 2.0, 0.1853334859875406, 1.0, 2.0, 0.1853334859875406, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460425.8846916239, 460425.8846916244, 156888.4947002099], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.53, 1.0, 1.0, 0.03015891188992928, 1.0, 1.0, 0.03015891188992928, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16443781596129425, 0.16443781596129442, 0.3017086436542498], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.7204608], dtype=float32), -1.487202]. 
=============================================
[2019-03-24 00:48:37,332] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.72745 ]
 [81.72618 ]
 [81.721085]
 [81.70688 ]
 [81.69821 ]], R is [[81.66169739]
 [81.54311371]
 [81.42546082]
 [81.30874634]
 [81.19297791]].
[2019-03-24 00:48:39,696] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8360593e-05 9.9990857e-01 5.3977573e-08 7.0770839e-05 2.2996016e-06], sum to 1.0000
[2019-03-24 00:48:39,704] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-24 00:48:39,707] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 59.66666666666666, 1.0, 2.0, 0.2914878988877665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376007.4295045176, 376007.4295045176, 113172.1821217291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [20.7, 60.0, 1.0, 2.0, 0.2903184508242002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 374498.5211570468, 374498.5211570463, 113034.6751537354], 
processed observation next is [1.0, 0.17391304347826086, 0.3222222222222222, 0.6, 1.0, 1.0, 0.15514101288595264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13374947184180241, 0.13374947184180225, 0.217374375295645], 
reward next is 0.7826, 
noisyNet noise sample is [array([-0.2621369], dtype=float32), 1.0468848]. 
=============================================
[2019-03-24 00:48:39,875] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3993383e-07 9.9999976e-01 1.5107398e-11 8.2034013e-08 1.7318564e-08], sum to 1.0000
[2019-03-24 00:48:39,878] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0767
[2019-03-24 00:48:39,882] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 59.33333333333333, 1.0, 2.0, 0.3151048593531182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 404214.4367449772, 404214.4367449767, 117462.4373036727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 974400.0000, 
sim time next is 975000.0000, 
raw observation next is [21.76666666666667, 59.16666666666667, 1.0, 2.0, 0.3091733446577255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396281.4574865083, 396281.4574865083, 116717.435431299], 
processed observation next is [1.0, 0.2608695652173913, 0.3617283950617285, 0.5916666666666667, 1.0, 1.0, 0.17758731506872083, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14152909195946725, 0.14152909195946725, 0.22445660659865194], 
reward next is 0.7755, 
noisyNet noise sample is [array([0.23617733], dtype=float32), 1.1773204]. 
=============================================
[2019-03-24 00:48:39,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.00183 ]
 [49.823803]
 [50.214306]
 [50.92541 ]
 [50.626198]], R is [[50.82852936]
 [51.09435272]
 [51.35159302]
 [51.60861969]
 [51.85256577]].
[2019-03-24 00:48:42,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3421675e-08 9.9999940e-01 2.7526763e-13 5.5865360e-07 3.6433265e-12], sum to 1.0000
[2019-03-24 00:48:42,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-24 00:48:42,121] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 54.0, 1.0, 2.0, 0.277356403103608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 355915.0330477285, 355915.0330477285, 112822.8486870748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1036800.0000, 
sim time next is 1037400.0000, 
raw observation next is [22.4, 55.0, 1.0, 2.0, 0.2801200936320363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359264.1537263692, 359264.1537263692, 113154.5201900645], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.55, 1.0, 1.0, 0.1430001114667099, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12830862633084614, 0.12830862633084614, 0.21760484651935483], 
reward next is 0.7824, 
noisyNet noise sample is [array([0.5965994], dtype=float32), 0.54428124]. 
=============================================
[2019-03-24 00:48:48,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4724432e-13 1.0000000e+00 4.1986331e-19 3.4669647e-13 6.2918476e-18], sum to 1.0000
[2019-03-24 00:48:48,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1061
[2019-03-24 00:48:48,690] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 65.0, 1.0, 2.0, 0.4652843679836323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 593611.3552084351, 593611.3552084346, 138435.1955293682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1164600.0000, 
sim time next is 1165200.0000, 
raw observation next is [21.36666666666667, 65.0, 1.0, 2.0, 0.4848953239173456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618265.9323143833, 618265.9323143833, 141469.6772503585], 
processed observation next is [1.0, 0.4782608695652174, 0.3469135802469137, 0.65, 1.0, 1.0, 0.3867801475206495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22080926154085118, 0.22080926154085118, 0.27205707163530485], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.27544987], dtype=float32), 0.28615403]. 
=============================================
[2019-03-24 00:48:50,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1857749e-08 1.0000000e+00 2.1461913e-15 1.0842169e-08 2.7194721e-13], sum to 1.0000
[2019-03-24 00:48:50,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8097
[2019-03-24 00:48:50,201] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 77.5, 1.0, 2.0, 0.3523328344427514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 444106.9010177477, 444106.9010177482, 122241.3365797503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1188600.0000, 
sim time next is 1189200.0000, 
raw observation next is [20.66666666666667, 78.0, 1.0, 2.0, 0.3541033725295138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446331.411384368, 446331.411384368, 122476.5992925784], 
processed observation next is [1.0, 0.782608695652174, 0.3209876543209878, 0.78, 1.0, 1.0, 0.23107544348751644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15940407549441715, 0.15940407549441715, 0.23553192171649692], 
reward next is 0.7645, 
noisyNet noise sample is [array([1.2794114], dtype=float32), -0.31050563]. 
=============================================
[2019-03-24 00:48:51,030] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0843037e-13 1.0000000e+00 2.5798723e-20 2.6282324e-13 6.8003816e-19], sum to 1.0000
[2019-03-24 00:48:51,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9061
[2019-03-24 00:48:51,040] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 94.0, 1.0, 2.0, 0.3426972633197489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432274.3021098503, 432274.3021098503, 120974.1916985835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1209000.0000, 
sim time next is 1209600.0000, 
raw observation next is [18.6, 94.0, 1.0, 2.0, 0.3417353373579014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431231.7268789453, 431231.7268789453, 120850.2861362921], 
processed observation next is [1.0, 0.0, 0.2444444444444445, 0.94, 1.0, 1.0, 0.21635159209273977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15401133102819475, 0.15401133102819475, 0.23240439641594635], 
reward next is 0.7676, 
noisyNet noise sample is [array([-0.3656887], dtype=float32), -0.62489617]. 
=============================================
[2019-03-24 00:48:52,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7322744e-14 1.0000000e+00 6.6275087e-20 1.0172462e-08 4.0326446e-19], sum to 1.0000
[2019-03-24 00:48:52,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7191
[2019-03-24 00:48:52,757] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.91666666666666, 93.0, 1.0, 2.0, 0.306540586317284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 390315.9758480964, 390315.975848096, 116384.1580373464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1223400.0000, 
sim time next is 1224000.0000, 
raw observation next is [17.9, 93.0, 1.0, 2.0, 0.3049398688818971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388347.7251468171, 388347.7251468171, 116185.0876231327], 
processed observation next is [1.0, 0.17391304347826086, 0.21851851851851847, 0.93, 1.0, 1.0, 0.17254746295463944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13869561612386325, 0.13869561612386325, 0.22343286081371672], 
reward next is 0.7766, 
noisyNet noise sample is [array([-0.6955975], dtype=float32), -0.64512724]. 
=============================================
[2019-03-24 00:48:52,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[93.02357 ]
 [93.080246]
 [93.02932 ]
 [93.14611 ]
 [93.187965]], R is [[92.71769714]
 [92.5667038 ]
 [92.41690063]
 [92.26810455]
 [92.12059784]].
[2019-03-24 00:48:55,268] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7779385e-12 1.0000000e+00 6.6017814e-17 9.6759765e-14 1.9600946e-15], sum to 1.0000
[2019-03-24 00:48:55,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7077
[2019-03-24 00:48:55,290] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.4095421816569274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505133.4675446501, 505133.4675446501, 129917.3779599373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1285200.0000, 
sim time next is 1285800.0000, 
raw observation next is [22.91666666666667, 74.0, 1.0, 2.0, 0.4073931142348451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502749.453168884, 502749.453168884, 129618.1884573517], 
processed observation next is [1.0, 0.9130434782608695, 0.4043209876543212, 0.74, 1.0, 1.0, 0.2945156121843394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17955337613174427, 0.17955337613174427, 0.24926574703336865], 
reward next is 0.7507, 
noisyNet noise sample is [array([1.2038662], dtype=float32), -0.111920916]. 
=============================================
[2019-03-24 00:48:57,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0884972e-09 1.0000000e+00 2.9399312e-19 4.1464883e-12 5.4633567e-14], sum to 1.0000
[2019-03-24 00:48:57,416] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0300
[2019-03-24 00:48:57,421] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 85.16666666666667, 1.0, 2.0, 0.3600961072494975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 453123.1915112759, 453123.1915112755, 123267.2775036326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1318200.0000, 
sim time next is 1318800.0000, 
raw observation next is [20.16666666666667, 84.33333333333334, 1.0, 2.0, 0.3535126968698111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444144.1307590637, 444144.1307590637, 122378.0707493194], 
processed observation next is [1.0, 0.2608695652173913, 0.3024691358024693, 0.8433333333333334, 1.0, 1.0, 0.23037225817834658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15862290384252276, 0.15862290384252276, 0.23534244374869118], 
reward next is 0.7647, 
noisyNet noise sample is [array([0.52515423], dtype=float32), -0.00072337006]. 
=============================================
[2019-03-24 00:49:02,813] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 00:49:02,815] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:49:02,815] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:49:02,816] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:49:02,818] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:49:02,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:49:02,817] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:49:02,819] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:49:02,824] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:49:02,824] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:49:02,822] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:49:02,840] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-24 00:49:02,863] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-24 00:49:02,864] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-24 00:49:02,910] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-24 00:49:02,933] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-24 00:49:19,077] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:49:19,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.4, 68.0, 1.0, 2.0, 0.3220427310771428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408761.2545186008, 408761.2545186008, 118330.7499411867]
[2019-03-24 00:49:19,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:49:19,084] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0873746e-14 1.0000000e+00 1.5769541e-20 2.8463644e-13 1.6250961e-19], sampled 0.6775497417816775
[2019-03-24 00:49:22,583] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:49:22,584] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.86666666666667, 31.33333333333334, 1.0, 2.0, 0.3512699908491098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442485.3357965641, 442485.3357965641, 122096.6306366458]
[2019-03-24 00:49:22,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:49:22,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.20452956e-14 1.00000000e+00 7.07769336e-21 1.72113354e-13
 7.61472551e-20], sampled 0.21845193718857137
[2019-03-24 00:49:47,355] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:49:47,357] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.48350814, 80.57670583666666, 1.0, 2.0, 0.6797743678650514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774738.8287707545, 774738.8287707545, 172351.2416887005]
[2019-03-24 00:49:47,358] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:49:47,361] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.0732993e-15 1.0000000e+00 1.4585102e-21 6.3901751e-14 1.7086490e-20], sampled 0.2980554816972605
[2019-03-24 00:50:02,020] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:50:02,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.00174558666667, 78.25797390833334, 1.0, 2.0, 0.6571588378715573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259260360835, 786764.2813801582, 786764.2813801582, 169871.7346011084]
[2019-03-24 00:50:02,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:50:02,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3782974e-14 1.0000000e+00 8.6146652e-21 1.9489686e-13 9.1729270e-20], sampled 0.9491539463847135
[2019-03-24 00:50:02,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:50:02,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 52.0, 1.0, 2.0, 0.5620107683623976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650730.7991563297, 650730.7991563297, 152159.2166918582]
[2019-03-24 00:50:02,397] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:50:02,398] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7824548e-15 1.0000000e+00 4.3727481e-22 2.9973406e-14 5.4640877e-21], sampled 0.3037727176627758
[2019-03-24 00:50:05,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:50:05,650] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.34085444333333, 87.51716144333334, 1.0, 2.0, 0.3878690824139062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483110.5542579216, 483110.5542579216, 126976.5014971024]
[2019-03-24 00:50:05,651] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:50:05,654] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1477709e-14 1.0000000e+00 6.5994012e-21 1.6479087e-13 7.1279039e-20], sampled 0.23676412838615246
[2019-03-24 00:50:24,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:50:24,905] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.83333333333334, 87.33333333333333, 1.0, 2.0, 0.795636482847028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 970395.5002967938, 970395.5002967938, 197821.1396687559]
[2019-03-24 00:50:24,905] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:50:24,908] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0848280e-14 1.0000000e+00 6.0785864e-21 1.5649981e-13 6.5964345e-20], sampled 0.37900428675086195
[2019-03-24 00:50:35,831] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.28627586]
[2019-03-24 00:50:35,832] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 67.33333333333334, 1.0, 2.0, 0.8315650520024044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425932161, 947841.6408360241, 947841.6408360241, 202541.8493963109]
[2019-03-24 00:50:35,835] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:50:35,838] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0680133e-14 1.0000000e+00 5.9416509e-21 1.5435499e-13 6.4548962e-20], sampled 0.13210113196202145
[2019-03-24 00:50:50,824] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:50:50,829] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:50:50,889] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:50:50,958] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:50:51,016] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:50:52,030] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 250000, evaluation results [250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:50:53,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9777220e-10 1.0000000e+00 7.4732472e-15 1.1645047e-08 4.3552072e-12], sum to 1.0000
[2019-03-24 00:50:53,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-24 00:50:53,198] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 27.66666666666666, 1.0, 2.0, 0.3701710495783454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465587.7458674669, 465587.7458674669, 124624.4503095508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1453200.0000, 
sim time next is 1453800.0000, 
raw observation next is [31.05, 27.83333333333334, 1.0, 2.0, 0.3686742389690624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464080.1820296385, 464080.1820296385, 124426.4508284465], 
processed observation next is [0.0, 0.8260869565217391, 0.7055555555555556, 0.2783333333333334, 1.0, 1.0, 0.2484217130584076, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16574292215344233, 0.16574292215344233, 0.23928163620855095], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.615976], dtype=float32), 0.05167848]. 
=============================================
[2019-03-24 00:50:58,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0403557e-09 1.0000000e+00 2.0553649e-11 2.6458885e-08 2.8676577e-11], sum to 1.0000
[2019-03-24 00:50:58,014] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1353
[2019-03-24 00:50:58,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 72.5, 1.0, 2.0, 0.4469882229635649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547774.7669585983, 547774.7669585983, 135283.940059117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1546200.0000, 
sim time next is 1546800.0000, 
raw observation next is [23.6, 71.66666666666667, 1.0, 2.0, 0.4422443399858073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542940.5208134411, 542940.5208134411, 134605.9111135261], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.7166666666666667, 1.0, 1.0, 0.33600516664977065, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19390732886194326, 0.19390732886194326, 0.25885752137216556], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.61500853], dtype=float32), -0.6002085]. 
=============================================
[2019-03-24 00:50:58,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6432738e-08 1.0000000e+00 1.2707351e-11 1.1452743e-09 3.8108566e-12], sum to 1.0000
[2019-03-24 00:50:58,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1444
[2019-03-24 00:50:58,038] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.53333333333333, 21.33333333333333, 1.0, 2.0, 0.4143239774341992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512058.5365688694, 512058.5365688694, 130625.2514068128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1518000.0000, 
sim time next is 1518600.0000, 
raw observation next is [35.66666666666666, 20.66666666666667, 1.0, 2.0, 0.4148730577431489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513509.366259232, 513509.366259232, 130721.9792041577], 
processed observation next is [0.0, 0.5652173913043478, 0.8765432098765429, 0.20666666666666672, 1.0, 1.0, 0.3034203068370821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18339620223544, 0.18339620223544, 0.25138842154645713], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.359622], dtype=float32), 1.1204602]. 
=============================================
[2019-03-24 00:51:06,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1270094e-13 1.0000000e+00 7.9108803e-19 3.0654440e-17 2.3191541e-21], sum to 1.0000
[2019-03-24 00:51:06,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7857302e-13 1.0000000e+00 1.5416608e-17 3.0423228e-15 9.1982308e-19], sum to 1.0000
[2019-03-24 00:51:06,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3954
[2019-03-24 00:51:06,933] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 79.33333333333334, 1.0, 2.0, 0.3835537446694909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477326.7218873044, 477326.7218873044, 126370.9300946081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1725600.0000, 
sim time next is 1726200.0000, 
raw observation next is [21.5, 79.5, 1.0, 2.0, 0.382104612412524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475592.7306500347, 475592.7306500343, 126172.4384962286], 
processed observation next is [1.0, 1.0, 0.35185185185185186, 0.795, 1.0, 1.0, 0.26441025287205244, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16985454666072666, 0.16985454666072655, 0.2426393048004396], 
reward next is 0.7574, 
noisyNet noise sample is [array([-0.3472939], dtype=float32), 0.8271261]. 
=============================================
[2019-03-24 00:51:06,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-24 00:51:06,944] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 81.16666666666667, 1.0, 2.0, 0.3784326872961695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471090.2565992745, 471090.256599274, 125668.9490937618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1732200.0000, 
sim time next is 1732800.0000, 
raw observation next is [21.23333333333333, 81.33333333333334, 1.0, 2.0, 0.3780729086734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470710.6046117082, 470710.6046117082, 125620.9818334616], 
processed observation next is [1.0, 0.043478260869565216, 0.34197530864197523, 0.8133333333333335, 1.0, 1.0, 0.25961060556367, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1681109302184672, 0.1681109302184672, 0.24157881121819538], 
reward next is 0.7584, 
noisyNet noise sample is [array([-0.03757158], dtype=float32), 0.32694265]. 
=============================================
[2019-03-24 00:51:11,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4036114e-11 1.0000000e+00 9.9437625e-19 7.2541842e-12 9.6817909e-18], sum to 1.0000
[2019-03-24 00:51:11,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-24 00:51:11,117] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 88.66666666666667, 1.0, 2.0, 0.3171912121435959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 402949.6238740566, 402949.6238740561, 117717.0995436303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812000.0000, 
sim time next is 1812600.0000, 
raw observation next is [18.6, 89.0, 1.0, 2.0, 0.3173338124566747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403106.5379023704, 403106.5379023704, 117734.985335184], 
processed observation next is [1.0, 1.0, 0.2444444444444445, 0.89, 1.0, 1.0, 0.18730215768651748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14396662067941798, 0.14396662067941798, 0.22641343333689232], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.33305913], dtype=float32), -0.096864365]. 
=============================================
[2019-03-24 00:51:12,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7170596e-15 1.0000000e+00 1.9761939e-20 3.5795632e-17 1.3495042e-20], sum to 1.0000
[2019-03-24 00:51:12,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-24 00:51:12,434] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.36666666666666, 92.0, 1.0, 2.0, 0.3254027301890172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 412881.4412708965, 412881.4412708961, 118758.9912135766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1824600.0000, 
sim time next is 1825200.0000, 
raw observation next is [18.4, 92.0, 1.0, 2.0, 0.3252159047070614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 412495.1360751531, 412495.1360751536, 118733.8622447011], 
processed observation next is [1.0, 0.13043478260869565, 0.237037037037037, 0.92, 1.0, 1.0, 0.19668560084173978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14731969145541182, 0.147319691455412, 0.22833435047057904], 
reward next is 0.7717, 
noisyNet noise sample is [array([-1.7798705], dtype=float32), -1.2181927]. 
=============================================
[2019-03-24 00:51:17,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6564545e-14 1.0000000e+00 4.5518244e-18 4.4920207e-14 7.0467426e-20], sum to 1.0000
[2019-03-24 00:51:17,469] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3537
[2019-03-24 00:51:17,478] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4210835306724902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521710.3443778895, 521710.3443778899, 131628.4008476031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929600.0000, 
sim time next is 1930200.0000, 
raw observation next is [20.61666666666667, 89.83333333333333, 1.0, 2.0, 0.4334155368112574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 536385.2346796136, 536385.2346796131, 133411.782846542], 
processed observation next is [1.0, 0.34782608695652173, 0.319135802469136, 0.8983333333333333, 1.0, 1.0, 0.32549468668006837, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19156615524271914, 0.19156615524271897, 0.2565611208587346], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.4427427], dtype=float32), 0.9054305]. 
=============================================
[2019-03-24 00:51:24,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.02372815e-11 1.00000000e+00 2.63167181e-18 9.93811831e-14
 1.05805691e-16], sum to 1.0000
[2019-03-24 00:51:24,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6265
[2019-03-24 00:51:24,555] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 65.0, 1.0, 2.0, 0.6005102148633794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688854.058490721, 688854.058490721, 158386.7279439515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [28.63333333333333, 65.66666666666667, 1.0, 2.0, 0.6013776537253146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 689753.4332320658, 689753.4332320653, 158531.7395171375], 
processed observation next is [0.0, 0.7391304347826086, 0.6160493827160493, 0.6566666666666667, 1.0, 1.0, 0.5254495877682317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2463405118685949, 0.24634051186859474, 0.30486872984064906], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.5547651], dtype=float32), -1.1775609]. 
=============================================
[2019-03-24 00:51:25,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1993237e-16 1.0000000e+00 1.4131567e-21 1.5280356e-18 2.8354914e-19], sum to 1.0000
[2019-03-24 00:51:25,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3418
[2019-03-24 00:51:25,597] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 67.0, 1.0, 2.0, 0.6035192177994184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692066.842424881, 692066.8424248814, 158894.8118514062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2052000.0000, 
sim time next is 2052600.0000, 
raw observation next is [28.26666666666667, 67.66666666666667, 1.0, 2.0, 0.6040488705258578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692799.0241078826, 692799.0241078826, 158992.4924196614], 
processed observation next is [0.0, 0.782608695652174, 0.6024691358024692, 0.6766666666666667, 1.0, 1.0, 0.5286296077688782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24742822289567237, 0.24742822289567237, 0.30575479311473347], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.5116199], dtype=float32), 0.9068013]. 
=============================================
[2019-03-24 00:51:26,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2714185e-19 1.0000000e+00 1.0774169e-29 3.4682601e-21 6.9878606e-25], sum to 1.0000
[2019-03-24 00:51:26,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1304
[2019-03-24 00:51:26,142] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 86.5, 1.0, 2.0, 0.4352894704547075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531438.348879268, 531438.348879268, 133498.6413928096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2083800.0000, 
sim time next is 2084400.0000, 
raw observation next is [21.8, 87.0, 1.0, 2.0, 0.4329682321402208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 529030.5022538377, 529030.5022538372, 133170.7910171292], 
processed observation next is [0.0, 0.13043478260869565, 0.362962962962963, 0.87, 1.0, 1.0, 0.3249621811193105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18893946509065632, 0.18893946509065615, 0.2560976750329408], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.9151025], dtype=float32), 0.59105307]. 
=============================================
[2019-03-24 00:51:32,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7423128e-08 1.0000000e+00 6.2656672e-11 2.0293832e-10 5.4313224e-11], sum to 1.0000
[2019-03-24 00:51:32,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1163
[2019-03-24 00:51:32,593] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 95.0, 1.0, 2.0, 0.5443240035397932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640891.8095727265, 640891.8095727265, 149705.078481022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2228400.0000, 
sim time next is 2229000.0000, 
raw observation next is [22.86666666666667, 94.83333333333334, 1.0, 2.0, 0.5422302700193803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639093.1528455222, 639093.1528455217, 149388.878215037], 
processed observation next is [1.0, 0.8260869565217391, 0.4024691358024693, 0.9483333333333335, 1.0, 1.0, 0.45503603573735746, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22824755458768647, 0.2282475545876863, 0.28728630425968654], 
reward next is 0.7127, 
noisyNet noise sample is [array([-1.4047763], dtype=float32), 0.59372324]. 
=============================================
[2019-03-24 00:51:32,613] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.253143]
 [32.07811 ]
 [31.95555 ]
 [31.58043 ]
 [31.413483]], R is [[32.58687973]
 [32.97311783]
 [33.35482788]
 [33.73164749]
 [34.10330963]].
[2019-03-24 00:51:33,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9826617e-15 1.0000000e+00 6.3143578e-24 4.9194517e-22 3.7136359e-23], sum to 1.0000
[2019-03-24 00:51:33,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5847
[2019-03-24 00:51:33,809] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 98.0, 1.0, 2.0, 0.5682472803818581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662056.2531798366, 662056.2531798366, 153384.593141943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2252400.0000, 
sim time next is 2253000.0000, 
raw observation next is [23.08333333333334, 98.0, 1.0, 2.0, 0.5688693642929773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662549.2272326476, 662549.2272326476, 153478.7623568388], 
processed observation next is [1.0, 0.043478260869565216, 0.41049382716049404, 0.98, 1.0, 1.0, 0.48674924320592533, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23662472401165985, 0.23662472401165985, 0.29515146607084386], 
reward next is 0.7048, 
noisyNet noise sample is [array([1.2946228], dtype=float32), 1.133366]. 
=============================================
[2019-03-24 00:51:33,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.19906]
 [67.33392]
 [67.34699]
 [67.40452]
 [67.36111]], R is [[67.20928955]
 [67.24223328]
 [67.27526093]
 [67.30843353]
 [67.34176636]].
[2019-03-24 00:51:33,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.20235169e-17 1.00000000e+00 2.46028188e-23 1.44285966e-22
 1.16703104e-26], sum to 1.0000
[2019-03-24 00:51:33,993] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4922
[2019-03-24 00:51:33,998] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 98.0, 1.0, 2.0, 0.5247841329304803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619794.6712019248, 619794.6712019248, 146606.6178025482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2256600.0000, 
sim time next is 2257200.0000, 
raw observation next is [22.2, 98.0, 1.0, 2.0, 0.5160748755089949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611295.7919596261, 611295.7919596261, 145281.9931182174], 
processed observation next is [1.0, 0.13043478260869565, 0.37777777777777777, 0.98, 1.0, 1.0, 0.423898661320232, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21831992569986647, 0.21831992569986647, 0.27938844830426424], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.4011471], dtype=float32), -1.0003463]. 
=============================================
[2019-03-24 00:51:37,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1518462e-13 1.0000000e+00 4.7240210e-18 3.1630913e-16 1.9934923e-15], sum to 1.0000
[2019-03-24 00:51:37,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-24 00:51:37,084] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 74.5, 1.0, 2.0, 0.488245188038502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586341.7672865008, 586341.7672865008, 141203.7449013812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2316600.0000, 
sim time next is 2317200.0000, 
raw observation next is [24.53333333333333, 75.0, 1.0, 2.0, 0.4899177302090552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588734.5022334966, 588734.5022334966, 141477.1320349379], 
processed observation next is [1.0, 0.8260869565217391, 0.46419753086419746, 0.75, 1.0, 1.0, 0.39275920262982766, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2102623222262488, 0.2102623222262488, 0.27207140775949595], 
reward next is 0.7279, 
noisyNet noise sample is [array([0.922093], dtype=float32), 0.42801455]. 
=============================================
[2019-03-24 00:51:40,295] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 00:51:40,297] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:51:40,298] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:51:40,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:40,301] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:51:40,299] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:51:40,301] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:40,303] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:40,303] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:40,301] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:51:40,307] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:40,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-24 00:51:40,338] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-24 00:51:40,339] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-24 00:51:40,339] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-24 00:51:40,408] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-24 00:52:01,418] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.3074825]
[2019-03-24 00:52:01,419] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.62916736666666, 28.55043188, 1.0, 2.0, 0.3296598335782227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422610.0020637612, 422610.0020637612, 119320.0815818115]
[2019-03-24 00:52:01,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:52:01,423] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1972578e-13 1.0000000e+00 6.3056123e-19 1.8733538e-17 3.8063555e-18], sampled 0.7171044769405763
[2019-03-24 00:52:33,328] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.3074825]
[2019-03-24 00:52:33,330] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.19944796333333, 72.93103167666668, 1.0, 2.0, 0.6225233879161474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 714406.4299344895, 714406.4299344891, 162239.1214224304]
[2019-03-24 00:52:33,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:52:33,335] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.3396214e-13 1.0000000e+00 5.2520042e-18 1.2961260e-16 2.8764025e-17], sampled 0.4719026568636908
[2019-03-24 00:52:35,861] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.3074825]
[2019-03-24 00:52:35,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.66711572666667, 89.77070715, 1.0, 2.0, 0.5551010926756782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8837390179201507, 6.911199999999999, 6.9112, 121.9260426156618, 1265702.551955216, 1265702.551955217, 276808.4576797332]
[2019-03-24 00:52:35,864] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:52:35,867] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2880919e-12 1.0000000e+00 1.8305790e-17 4.0498244e-16 9.4672992e-17], sampled 0.7314878597830725
[2019-03-24 00:53:22,477] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.3074825]
[2019-03-24 00:53:22,479] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.49052650333334, 78.29465582333334, 1.0, 2.0, 0.3266513591453076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413227.2874741061, 413227.2874741057, 118908.2285498033]
[2019-03-24 00:53:22,481] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:53:22,483] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3100868e-13 1.0000000e+00 1.6011538e-18 4.3841836e-17 9.2595987e-18], sampled 0.9596210623526047
[2019-03-24 00:53:23,529] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.3074825]
[2019-03-24 00:53:23,531] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.50660595, 67.20690117666668, 1.0, 2.0, 0.3901640443213891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484100.5005590981, 484100.5005590977, 127256.8103373528]
[2019-03-24 00:53:23,533] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:53:23,535] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6885007e-13 1.0000000e+00 1.0266693e-18 2.9226468e-17 6.0598656e-18], sampled 0.9686674165479865
[2019-03-24 00:53:28,486] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:53:28,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:53:28,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:53:28,863] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:53:28,964] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:53:29,979] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 275000, evaluation results [275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:53:31,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5203913e-16 1.0000000e+00 1.7658605e-22 5.3529652e-22 8.0081120e-24], sum to 1.0000
[2019-03-24 00:53:31,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0448
[2019-03-24 00:53:31,974] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.53333333333333, 38.33333333333334, 1.0, 2.0, 0.2803464579864958, 0.0, 1.0, 0.0, 1.0, 1.0, 0.454948866210254, 6.911199999999999, 6.9112, 121.9260426156618, 678199.4036640441, 678199.4036640446, 188355.8446756157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2394600.0000, 
sim time next is 2395200.0000, 
raw observation next is [30.36666666666667, 38.66666666666667, 1.0, 2.0, 0.4019129310723999, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491725.301600105, 491725.301600105, 128730.2251771217], 
processed observation next is [1.0, 0.7391304347826086, 0.680246913580247, 0.3866666666666667, 1.0, 1.0, 0.2879915846099999, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17561617914289465, 0.17561617914289465, 0.24755812534061866], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5514488], dtype=float32), 1.148172]. 
=============================================
[2019-03-24 00:53:35,256] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0741787e-10 1.0000000e+00 1.6998759e-16 1.6293895e-14 2.1119828e-15], sum to 1.0000
[2019-03-24 00:53:35,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8360
[2019-03-24 00:53:35,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1449506.199195541 W.
[2019-03-24 00:53:35,276] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.73333333333333, 23.0, 1.0, 2.0, 0.6042109963060428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9569371812900841, 6.9112, 6.9112, 121.9260426156618, 1449506.199195541, 1449506.199195541, 289075.0288210229], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2472000.0000, 
sim time next is 2472600.0000, 
raw observation next is [34.66666666666667, 23.0, 1.0, 2.0, 0.4071148659673439, 1.0, 1.0, 0.4071148659673439, 1.0, 2.0, 0.6567286336649157, 6.9112, 6.9112, 121.94756008, 1463644.589981243, 1463644.589981243, 299818.9969985886], 
processed observation next is [1.0, 0.6086956521739131, 0.8395061728395063, 0.23, 1.0, 1.0, 0.294184364246838, 1.0, 0.5, 0.294184364246838, 1.0, 1.0, 0.5709107920811446, 0.0, 0.0, 0.8096049824067558, 0.5227302107075867, 0.5227302107075867, 0.576574994228055], 
reward next is 0.4234, 
noisyNet noise sample is [array([-0.6284102], dtype=float32), -0.60954434]. 
=============================================
[2019-03-24 00:53:39,546] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2195486e-08 1.0000000e+00 3.5843158e-11 6.6874267e-10 2.4502297e-10], sum to 1.0000
[2019-03-24 00:53:39,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9812
[2019-03-24 00:53:39,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1444981.030567732 W.
[2019-03-24 00:53:39,560] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.45, 32.0, 1.0, 2.0, 0.5976473110266332, 1.0, 2.0, 0.5976473110266332, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1444981.030567732, 1444981.030567732, 270730.2870548108], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2543400.0000, 
sim time next is 2544000.0000, 
raw observation next is [31.63333333333333, 31.33333333333334, 1.0, 2.0, 0.605292635491593, 1.0, 2.0, 0.605292635491593, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1463580.523881316, 1463580.523881316, 273419.4650735649], 
processed observation next is [1.0, 0.43478260869565216, 0.7271604938271603, 0.3133333333333334, 1.0, 1.0, 0.5301102803471345, 1.0, 1.0, 0.5301102803471345, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5227073299576128, 0.5227073299576128, 0.5258066636030094], 
reward next is 0.4742, 
noisyNet noise sample is [array([1.5250283], dtype=float32), -0.8719833]. 
=============================================
[2019-03-24 00:53:39,581] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[33.67739 ]
 [33.615345]
 [33.450016]
 [33.589912]
 [33.219208]], R is [[33.94245148]
 [34.08239365]
 [34.22212219]
 [34.35810852]
 [34.46368408]].
[2019-03-24 00:53:41,798] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9883874e-18 1.0000000e+00 1.6322188e-23 5.0794809e-24 6.7131393e-25], sum to 1.0000
[2019-03-24 00:53:41,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5074
[2019-03-24 00:53:41,814] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 99.0, 1.0, 2.0, 0.4442316230901721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 542487.2112780932, 542487.2112780927, 134821.1406040145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2612400.0000, 
sim time next is 2613000.0000, 
raw observation next is [20.35, 99.5, 1.0, 2.0, 0.444812353968067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543136.8749322682, 543136.8749322685, 134905.5712630375], 
processed observation next is [0.0, 0.21739130434782608, 0.3092592592592593, 0.995, 1.0, 1.0, 0.3390623261524608, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1939774553329529, 0.19397745533295305, 0.25943379089045676], 
reward next is 0.7406, 
noisyNet noise sample is [array([-1.6263725], dtype=float32), -1.9273174]. 
=============================================
[2019-03-24 00:53:41,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[83.10917 ]
 [83.09744 ]
 [83.08316 ]
 [83.081955]
 [83.079384]], R is [[83.04394531]
 [82.95423889]
 [82.86559296]
 [82.7779007 ]
 [82.69097137]].
[2019-03-24 00:53:43,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7010434e-12 1.0000000e+00 2.4924641e-17 2.7691352e-16 2.1138184e-17], sum to 1.0000
[2019-03-24 00:53:43,853] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-24 00:53:43,859] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 98.0, 1.0, 2.0, 0.4434095859876681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541606.7844383608, 541606.7844383608, 134702.8410714332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2611200.0000, 
sim time next is 2611800.0000, 
raw observation next is [20.45, 98.5, 1.0, 2.0, 0.4436361506627885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 541821.1949175092, 541821.1949175088, 134734.629769032], 
processed observation next is [0.0, 0.21739130434782608, 0.31296296296296294, 0.985, 1.0, 1.0, 0.33766208412236726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19350756961339616, 0.193507569613396, 0.2591050572481385], 
reward next is 0.7409, 
noisyNet noise sample is [array([0.6460594], dtype=float32), 1.6091679]. 
=============================================
[2019-03-24 00:53:48,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4046090e-21 1.0000000e+00 2.4201678e-26 3.5708767e-24 2.1826487e-25], sum to 1.0000
[2019-03-24 00:53:48,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-24 00:53:48,862] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.56666666666667, 52.0, 1.0, 2.0, 0.6231361537644097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712427.4637474616, 712427.4637474616, 162215.6200945962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2731200.0000, 
sim time next is 2731800.0000, 
raw observation next is [31.78333333333333, 50.5, 1.0, 2.0, 0.6154126779911341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 705366.0082932471, 705366.0082932466, 160947.3644430407], 
processed observation next is [0.0, 0.6086956521739131, 0.732716049382716, 0.505, 1.0, 1.0, 0.5421579499894453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2519164315333025, 0.25191643153330234, 0.30951416239046287], 
reward next is 0.6905, 
noisyNet noise sample is [array([-0.39375225], dtype=float32), 1.9039656]. 
=============================================
[2019-03-24 00:53:50,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5106773e-20 1.0000000e+00 1.4334408e-21 1.0496933e-19 7.9118560e-24], sum to 1.0000
[2019-03-24 00:53:50,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4584
[2019-03-24 00:53:50,014] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 51.0, 1.0, 2.0, 0.6102377969818399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700584.6546247219, 700584.6546247219, 160100.0161181824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2741400.0000, 
sim time next is 2742000.0000, 
raw observation next is [31.7, 49.33333333333333, 1.0, 2.0, 0.5989409674391513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690706.3820053316, 690706.3820053316, 158290.846865444], 
processed observation next is [0.0, 0.7391304347826086, 0.7296296296296296, 0.4933333333333333, 1.0, 1.0, 0.5225487707608943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24668085071618984, 0.24668085071618984, 0.30440547474123847], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.32854268], dtype=float32), 0.06036885]. 
=============================================
[2019-03-24 00:53:50,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.68611 ]
 [73.63374 ]
 [73.57823 ]
 [73.53513 ]
 [73.468475]], R is [[73.68566895]
 [73.64093018]
 [73.59394836]
 [73.54254913]
 [73.49032593]].
[2019-03-24 00:53:52,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3087053e-07 9.9999964e-01 4.9370890e-09 5.8751704e-10 1.9505078e-09], sum to 1.0000
[2019-03-24 00:53:52,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3548
[2019-03-24 00:53:52,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1893506.449675106 W.
[2019-03-24 00:53:52,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.941299709566412, 6.9112, 121.9257229386158, 1893506.449675106, 1878092.748508772, 384025.5594834978], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2797200.0000, 
sim time next is 2797800.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5740931787185753, 1.0, 1.0, 0.5740931787185753, 1.0, 2.0, 0.9139750374295036, 6.9112, 6.9112, 121.94756008, 1964335.092360826, 1964335.092360826, 381441.0090047018], 
processed observation next is [1.0, 0.391304347826087, 0.5987654320987656, 0.7816666666666667, 1.0, 1.0, 0.49296806990306585, 1.0, 0.5, 0.49296806990306585, 1.0, 1.0, 0.8924687967868794, 0.0, 0.0, 0.8096049824067558, 0.7015482472717236, 0.7015482472717236, 0.7335404019321189], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35203022], dtype=float32), -1.7747601]. 
=============================================
[2019-03-24 00:54:00,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2281974e-16 1.0000000e+00 6.5137137e-21 1.0067718e-21 9.1982264e-20], sum to 1.0000
[2019-03-24 00:54:00,412] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9927
[2019-03-24 00:54:00,417] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.8175232388146594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931826.6496064599, 931826.6496064599, 199582.9160743532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949000.0000, 
sim time next is 2949600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.764176001203987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870986.02369769, 870986.02369769, 188645.5451734953], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7192571442904607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3110664370348893, 0.3110664370348893, 0.36277989456441406], 
reward next is 0.6372, 
noisyNet noise sample is [array([-1.3212392], dtype=float32), -0.23349637]. 
=============================================
[2019-03-24 00:54:00,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.109916e-19 1.000000e+00 3.940090e-24 5.416434e-23 7.301562e-27], sum to 1.0000
[2019-03-24 00:54:00,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7470
[2019-03-24 00:54:00,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1944109.58101442 W.
[2019-03-24 00:54:00,770] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 80.66666666666667, 1.0, 2.0, 0.8522826336587351, 1.0, 2.0, 0.8522826336587351, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1944109.58101442, 1944109.581014421, 365832.9621095834], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2977800.0000, 
sim time next is 2978400.0000, 
raw observation next is [28.26666666666667, 81.33333333333334, 1.0, 2.0, 0.8047311872128238, 1.0, 2.0, 0.8047311872128238, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1835530.321801142, 1835530.321801142, 345714.25890473], 
processed observation next is [1.0, 0.4782608695652174, 0.6024691358024692, 0.8133333333333335, 1.0, 1.0, 0.767537127634314, 1.0, 1.0, 0.767537127634314, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6555465435004079, 0.6555465435004079, 0.664835113278327], 
reward next is 0.3352, 
noisyNet noise sample is [array([-0.8555497], dtype=float32), -1.4096727]. 
=============================================
[2019-03-24 00:54:04,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9064811e-16 1.0000000e+00 3.7215370e-22 1.2010651e-22 7.3742110e-24], sum to 1.0000
[2019-03-24 00:54:04,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0185
[2019-03-24 00:54:04,066] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 89.0, 1.0, 2.0, 0.6709496335375297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764676.2625457158, 764676.2625457158, 170716.1712893358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3011400.0000, 
sim time next is 3012000.0000, 
raw observation next is [25.5, 90.66666666666667, 1.0, 2.0, 0.6705033592556434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764167.3935664694, 764167.3935664694, 170633.8618018663], 
processed observation next is [1.0, 0.8695652173913043, 0.5, 0.9066666666666667, 1.0, 1.0, 0.6077420943519565, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2729169262737391, 0.2729169262737391, 0.32814204192666596], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.3111386], dtype=float32), -0.40316808]. 
=============================================
[2019-03-24 00:54:04,085] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.03403 ]
 [61.111664]
 [61.23281 ]
 [61.197803]
 [61.331127]], R is [[61.16944122]
 [61.22944641]
 [61.28841782]
 [61.34584427]
 [61.40100098]].
[2019-03-24 00:54:04,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.66653076e-17 1.00000000e+00 3.06353246e-21 1.27188154e-23
 3.03340733e-25], sum to 1.0000
[2019-03-24 00:54:04,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0613
[2019-03-24 00:54:04,519] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5914666362410865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684653.6211759099, 684653.6211759099, 157126.2176617032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3025800.0000, 
sim time next is 3026400.0000, 
raw observation next is [23.66666666666667, 96.0, 1.0, 2.0, 0.593603293646465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686502.2740586746, 686502.2740586746, 157464.0472233082], 
processed observation next is [1.0, 0.0, 0.43209876543209896, 0.96, 1.0, 1.0, 0.5161943971981726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24517938359238378, 0.24517938359238378, 0.3028154754294389], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.1094761], dtype=float32), 0.3291775]. 
=============================================
[2019-03-24 00:54:07,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6460175e-12 1.0000000e+00 5.6755713e-16 9.9640160e-16 3.0892559e-14], sum to 1.0000
[2019-03-24 00:54:07,073] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-24 00:54:07,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2401802.215039208 W.
[2019-03-24 00:54:07,085] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.76666666666667, 68.33333333333334, 1.0, 2.0, 0.7768203932713754, 1.0, 2.0, 0.7017748586121223, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2401802.215039208, 2401802.215039207, 450520.9277565416], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3075000.0000, 
sim time next is 3075600.0000, 
raw observation next is [31.23333333333333, 69.66666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.156652251028664, 6.9112, 121.9249464287146, 2453038.096676214, 2327345.735934809, 443049.5469246418], 
processed observation next is [1.0, 0.6086956521739131, 0.7123456790123456, 0.6966666666666668, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.024545225102866386, 0.0, 0.8094548512787606, 0.8760850345272193, 0.8311949056910032, 0.852018359470465], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5469935], dtype=float32), -0.33425027]. 
=============================================
[2019-03-24 00:54:09,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9614978e-12 1.0000000e+00 6.6983847e-16 1.0845383e-14 2.4826358e-15], sum to 1.0000
[2019-03-24 00:54:09,085] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3565
[2019-03-24 00:54:09,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1406416.276341482 W.
[2019-03-24 00:54:09,097] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 50.5, 1.0, 2.0, 0.6096612467019176, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9715718492623495, 6.911199999999999, 6.9112, 121.9260426156618, 1406416.276341482, 1406416.276341482, 297397.0782199636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3143400.0000, 
sim time next is 3144000.0000, 
raw observation next is [30.33333333333334, 49.0, 1.0, 2.0, 0.6078977335582781, 1.0, 1.0, 0.6078977335582781, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1404792.355168994, 1404792.355168995, 271675.3613460758], 
processed observation next is [1.0, 0.391304347826087, 0.6790123456790126, 0.49, 1.0, 1.0, 0.5332115875693787, 1.0, 0.5, 0.5332115875693787, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5017115554174979, 0.5017115554174982, 0.5224526179732226], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.62110865], dtype=float32), -1.3362436]. 
=============================================
[2019-03-24 00:54:09,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[41.30203 ]
 [39.71955 ]
 [40.5428  ]
 [41.375793]
 [42.701145]], R is [[41.29652786]
 [40.883564  ]
 [40.47472763]
 [40.06998062]
 [39.66928101]].
[2019-03-24 00:54:14,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2179371e-23 1.0000000e+00 2.1665727e-32 2.3894866e-30 2.0062237e-31], sum to 1.0000
[2019-03-24 00:54:14,363] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5410
[2019-03-24 00:54:14,370] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 44.5, 1.0, 2.0, 0.530535646588999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626846.2067352091, 626846.2067352091, 147545.7643708859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [31.66666666666666, 43.33333333333333, 1.0, 2.0, 0.5256846980224305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622402.9999361525, 622402.999936152, 146813.0117024865], 
processed observation next is [0.0, 0.6086956521739131, 0.7283950617283949, 0.4333333333333333, 1.0, 1.0, 0.43533892621717907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22228678569148302, 0.22228678569148286, 0.282332714812474], 
reward next is 0.7177, 
noisyNet noise sample is [array([-0.6030099], dtype=float32), 1.0461879]. 
=============================================
[2019-03-24 00:54:16,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8184973e-16 1.0000000e+00 2.0964283e-21 3.6417697e-21 1.3935455e-24], sum to 1.0000
[2019-03-24 00:54:16,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7044
[2019-03-24 00:54:16,982] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 93.33333333333334, 1.0, 2.0, 0.4847058664667073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584532.0905157172, 584532.0905157176, 140737.8677213524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3300000.0000, 
sim time next is 3300600.0000, 
raw observation next is [21.75, 93.16666666666666, 1.0, 2.0, 0.4810126132292717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580779.0849603487, 580779.0849603487, 140190.0692645859], 
processed observation next is [0.0, 0.17391304347826086, 0.3611111111111111, 0.9316666666666665, 1.0, 1.0, 0.3821578728919901, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2074211017715531, 0.2074211017715531, 0.2695962870472806], 
reward next is 0.7304, 
noisyNet noise sample is [array([1.0736712], dtype=float32), 1.0298513]. 
=============================================
[2019-03-24 00:54:18,127] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 00:54:18,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:54:18,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:18,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:54:18,131] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:18,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:54:18,133] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:18,134] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:54:18,135] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:54:18,136] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:18,136] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:18,158] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-24 00:54:18,159] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-24 00:54:18,159] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-24 00:54:18,234] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-24 00:54:18,235] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-24 00:54:53,631] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.31658086]
[2019-03-24 00:54:53,633] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.31504076, 41.78987037, 1.0, 2.0, 0.7360736196310662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156605, 890274.5171474532, 890274.5171474528, 185350.1838922488]
[2019-03-24 00:54:53,633] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:54:53,636] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.6983573e-18 1.0000000e+00 1.3228799e-24 4.8509278e-23 6.5604039e-26], sampled 0.2215875360841063
[2019-03-24 00:55:04,693] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.31658086]
[2019-03-24 00:55:04,695] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.88333333333333, 58.5, 1.0, 2.0, 0.4677545920612026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566245.7321376554, 566245.7321376554, 138207.3632634855]
[2019-03-24 00:55:04,695] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:55:04,697] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7508317e-19 1.0000000e+00 1.3943150e-26 7.0290327e-25 5.4277338e-28], sampled 0.7849797740127967
[2019-03-24 00:55:15,806] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.31658086]
[2019-03-24 00:55:15,808] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.0, 100.0, 1.0, 2.0, 0.4568880238095395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560441.4501926855, 560441.4501926855, 136781.1161515537]
[2019-03-24 00:55:15,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:55:15,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4734559e-18 1.0000000e+00 8.7086832e-25 3.2886687e-23 4.2243551e-26], sampled 0.11027521108481353
[2019-03-24 00:55:43,263] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.31658086]
[2019-03-24 00:55:43,265] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.66666666666667, 65.66666666666667, 1.0, 2.0, 0.985206908375363, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9948317390091795, 6.9112, 6.9112, 121.9260426156618, 1841869.414566828, 1841869.414566828, 375586.6231339477]
[2019-03-24 00:55:43,266] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:55:43,271] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.7222261e-15 1.0000000e+00 4.4181242e-20 7.8094158e-19 3.8114790e-21], sampled 0.24210385356536723
[2019-03-24 00:55:43,273] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1841869.414566828 W.
[2019-03-24 00:56:06,343] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:56:06,665] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:56:06,870] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:56:06,917] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:56:06,922] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:56:07,935] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 300000, evaluation results [300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:56:09,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7537499e-20 1.0000000e+00 3.2828836e-27 5.2922919e-24 4.2981954e-29], sum to 1.0000
[2019-03-24 00:56:09,075] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7958
[2019-03-24 00:56:09,083] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 74.66666666666667, 1.0, 2.0, 0.7026989524696257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 800879.6268972837, 800879.6268972832, 176656.8618590602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.7116793828858077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 811120.213328846, 811120.2133288456, 178368.9789102207], 
processed observation next is [0.0, 0.6521739130434783, 0.6296296296296297, 0.74, 1.0, 1.0, 0.656761170102152, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28968579047458787, 0.2896857904745877, 0.3430172671350398], 
reward next is 0.6570, 
noisyNet noise sample is [array([1.2503388], dtype=float32), -0.037252095]. 
=============================================
[2019-03-24 00:56:10,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9598671e-16 1.0000000e+00 1.5091289e-24 1.1274100e-22 2.0182880e-26], sum to 1.0000
[2019-03-24 00:56:10,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4506
[2019-03-24 00:56:10,509] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 87.33333333333334, 1.0, 2.0, 0.6656915515780928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758680.7003277733, 758680.7003277733, 169748.5853612633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3363600.0000, 
sim time next is 3364200.0000, 
raw observation next is [25.6, 86.5, 1.0, 2.0, 0.6565558623497526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 748263.7826757213, 748263.7826757209, 168079.7011628399], 
processed observation next is [0.0, 0.9565217391304348, 0.5037037037037038, 0.865, 1.0, 1.0, 0.591137931368753, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26723706524132906, 0.2672370652413289, 0.3232301945439229], 
reward next is 0.6768, 
noisyNet noise sample is [array([-0.27550822], dtype=float32), 2.2379708]. 
=============================================
[2019-03-24 00:56:11,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5045498e-13 1.0000000e+00 1.8303206e-17 1.2355602e-16 1.3957843e-18], sum to 1.0000
[2019-03-24 00:56:11,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-24 00:56:11,045] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.7731522572947146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892105.6743019121, 892105.6743019121, 191011.7463399378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3383400.0000, 
sim time next is 3384000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.7505275597470338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866011.312407829, 866011.312407829, 186466.9267891635], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.7030089996988498, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30928975443136747, 0.30928975443136747, 0.3585902438253144], 
reward next is 0.6414, 
noisyNet noise sample is [array([-0.8912554], dtype=float32), 1.3806813]. 
=============================================
[2019-03-24 00:56:11,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[49.24645 ]
 [49.47949 ]
 [49.86245 ]
 [50.30187 ]
 [49.910717]], R is [[49.48589325]
 [49.62370682]
 [49.75821686]
 [49.89346695]
 [50.02197266]].
[2019-03-24 00:56:37,525] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3548119e-18 1.0000000e+00 9.7553884e-24 5.1419918e-21 4.3482398e-25], sum to 1.0000
[2019-03-24 00:56:37,532] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4344
[2019-03-24 00:56:37,539] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.03333333333334, 54.33333333333334, 1.0, 2.0, 0.7205202628059695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 821201.8008476354, 821201.8008476349, 180067.7562480613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [33.05, 53.5, 1.0, 2.0, 0.7168488894001809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817015.1797220919, 817015.1797220919, 179360.0695343838], 
processed observation next is [0.0, 0.5652173913043478, 0.7796296296296296, 0.535, 1.0, 1.0, 0.6629153445240249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29179113561503284, 0.29179113561503284, 0.34492321064304576], 
reward next is 0.6551, 
noisyNet noise sample is [array([-0.9505609], dtype=float32), -0.5983714]. 
=============================================
[2019-03-24 00:56:44,119] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3269672e-13 1.0000000e+00 3.1774067e-18 1.6589859e-15 1.4326292e-17], sum to 1.0000
[2019-03-24 00:56:44,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7410
[2019-03-24 00:56:44,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1798084.303814219 W.
[2019-03-24 00:56:44,139] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 87.33333333333334, 1.0, 2.0, 0.5255538617510481, 1.0, 2.0, 0.5255538617510481, 1.0, 1.0, 0.8366988640020091, 6.9112, 6.9112, 121.94756008, 1798084.303814219, 1798084.303814219, 356308.1835640411], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4012800.0000, 
sim time next is 4013400.0000, 
raw observation next is [26.0, 85.66666666666666, 1.0, 2.0, 0.5253598039522691, 1.0, 2.0, 0.5253598039522691, 1.0, 2.0, 0.8363899176663316, 6.911199999999999, 6.9112, 121.94756008, 1797419.703439987, 1797419.703439987, 356210.2605640023], 
processed observation next is [1.0, 0.43478260869565216, 0.5185185185185185, 0.8566666666666666, 1.0, 1.0, 0.4349521475622251, 1.0, 1.0, 0.4349521475622251, 1.0, 1.0, 0.7954873970829146, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6419356083714239, 0.6419356083714239, 0.6850197318538507], 
reward next is 0.3150, 
noisyNet noise sample is [array([0.7520188], dtype=float32), 0.5770262]. 
=============================================
[2019-03-24 00:56:44,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3129387e-12 1.0000000e+00 2.7247885e-17 1.6786247e-15 3.6972628e-18], sum to 1.0000
[2019-03-24 00:56:44,850] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0909
[2019-03-24 00:56:44,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333333, 92.16666666666667, 1.0, 2.0, 1.00425983474984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.18494469156619, 6.9112, 121.9250583469639, 1287714.780913994, 1147534.163450201, 241901.0369363008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3993000.0000, 
sim time next is 3993600.0000, 
raw observation next is [24.66666666666667, 92.33333333333334, 1.0, 2.0, 1.000306787741448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.159200255145078, 6.9112, 121.9247120150338, 1269755.712727827, 1142758.802037309, 240930.6590932402], 
processed observation next is [1.0, 0.21739130434782608, 0.469135802469136, 0.9233333333333335, 1.0, 1.0, 1.0003652235017237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.024800025514507773, 0.0, 0.8094532950156932, 0.45348418311708105, 0.4081281435847532, 0.46332819056392344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8614476], dtype=float32), 0.2553626]. 
=============================================
[2019-03-24 00:56:46,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9820596e-18 1.0000000e+00 1.8672389e-25 2.6290879e-22 2.0992858e-28], sum to 1.0000
[2019-03-24 00:56:46,927] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7157
[2019-03-24 00:56:46,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1749568.974175941 W.
[2019-03-24 00:56:46,938] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5113874083841027, 1.0, 2.0, 0.5113874083841027, 1.0, 1.0, 0.8141454088726556, 6.9112, 6.9112, 121.94756008, 1749568.974175941, 1749568.974175941, 349213.2827875718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.9160947365589986, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1759457.022053571, 1759457.022053571, 360465.8854660224], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.9001127816178556, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6283775078762753, 0.6283775078762753, 0.693203625896197], 
reward next is 0.3068, 
noisyNet noise sample is [array([-0.7195826], dtype=float32), 0.54610884]. 
=============================================
[2019-03-24 00:56:56,058] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 00:56:56,060] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:56:56,060] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:56:56,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:56,061] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:56,064] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:56:56,065] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:56:56,066] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:56,067] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:56:56,067] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:56,068] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:56,085] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-24 00:56:56,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-24 00:56:56,134] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-24 00:56:56,155] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-24 00:56:56,155] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-24 00:56:58,266] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:56:58,266] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.95543422, 77.82778453666667, 1.0, 2.0, 0.4347383035308665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531965.1170104599, 531965.1170104599, 133451.6921389113]
[2019-03-24 00:56:58,267] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:56:58,270] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.7812421e-17 1.0000000e+00 1.4437846e-22 5.8909836e-21 6.8865082e-25], sampled 0.7446827616311225
[2019-03-24 00:57:03,067] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:57:03,068] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.17588121, 46.09274622, 1.0, 2.0, 0.2586818970704519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 333679.6433386275, 333679.6433386271, 93480.74169942661]
[2019-03-24 00:57:03,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:57:03,072] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.57004285e-17 1.00000000e+00 1.05075736e-22 4.39581347e-21
 4.84692756e-25], sampled 0.07047834000980158
[2019-03-24 00:57:31,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:57:31,737] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.02942783333334, 32.11511072666666, 1.0, 2.0, 0.6774737979635079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857588.129721328, 857588.129721328, 174877.722660943]
[2019-03-24 00:57:31,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:57:31,741] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8852563e-15 1.0000000e+00 1.6012987e-20 4.5159341e-19 1.2537886e-22], sampled 0.5514086005670121
[2019-03-24 00:58:13,938] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:58:13,939] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.2, 78.33333333333334, 1.0, 2.0, 0.707916567177014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806829.3734398125, 806829.3734398125, 177649.9210315976]
[2019-03-24 00:58:13,940] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:58:13,942] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1327890e-16 1.0000000e+00 8.4267955e-22 2.9937434e-20 4.8389489e-24], sampled 0.1955359052614125
[2019-03-24 00:58:16,322] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:58:16,325] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 76.0, 1.0, 2.0, 0.5027374670494971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611953.2096326118, 611953.2096326118, 143740.8685553936]
[2019-03-24 00:58:16,328] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:58:16,331] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3126845e-16 1.0000000e+00 9.4000524e-22 3.3113203e-20 5.4609744e-24], sampled 0.3136608631509551
[2019-03-24 00:58:28,038] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.32936698]
[2019-03-24 00:58:28,039] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.02937585, 14.91531423, 1.0, 2.0, 0.5019563279831366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 647600.2449181763, 647600.2449181759, 138775.8289187301]
[2019-03-24 00:58:28,040] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:58:28,043] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6536524e-16 1.0000000e+00 5.9733507e-22 2.1805571e-20 3.3086369e-24], sampled 0.07559480780091554
[2019-03-24 00:58:44,436] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:58:44,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:58:45,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:58:45,090] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:58:45,142] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:58:46,157] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 325000, evaluation results [325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:58:50,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2972862e-12 1.0000000e+00 2.7184670e-16 6.5997705e-16 4.1227027e-20], sum to 1.0000
[2019-03-24 00:58:50,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7593
[2019-03-24 00:58:50,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2337962.002061313 W.
[2019-03-24 00:58:50,215] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 35.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9850443397899084, 7.775791931000231, 6.9112, 121.9229998578291, 2337962.002061313, 1895224.706163544, 379262.0103283735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4288200.0000, 
sim time next is 4288800.0000, 
raw observation next is [33.66666666666667, 37.33333333333334, 1.0, 2.0, 0.9248363731542181, 1.0, 1.0, 0.9248363731542181, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9255219722487, 2114752.660817293, 2114752.660817292, 398316.2510521077], 
processed observation next is [1.0, 0.6521739130434783, 0.8024691358024693, 0.3733333333333334, 1.0, 1.0, 0.9105194918502596, 1.0, 0.5, 0.9105194918502596, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.809458672289304, 0.7552688074347474, 0.7552688074347471, 0.7659927904848225], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23110096], dtype=float32), -0.29494157]. 
=============================================
[2019-03-24 00:58:51,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2741444e-11 1.0000000e+00 1.7416682e-16 3.7808864e-14 5.7731986e-17], sum to 1.0000
[2019-03-24 00:58:51,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7465
[2019-03-24 00:58:51,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2014212.564278654 W.
[2019-03-24 00:58:51,271] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 74.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.176767266816999, 6.9112, 121.9250033611604, 2014212.564278654, 1878219.546701692, 383181.58475227], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4357200.0000, 
sim time next is 4357800.0000, 
raw observation next is [28.6, 72.5, 1.0, 2.0, 0.842648174305063, 1.0, 1.0, 0.842648174305063, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258826957448, 1922109.134873201, 1922109.134873201, 361692.4418875705], 
processed observation next is [1.0, 0.43478260869565216, 0.6148148148148148, 0.725, 1.0, 1.0, 0.8126763979822178, 1.0, 0.5, 0.8126763979822178, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094610671181921, 0.6864675481690004, 0.6864675481690004, 0.6955623882453279], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02618147], dtype=float32), 2.8662295]. 
=============================================
[2019-03-24 00:58:58,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.03808556e-19 1.00000000e+00 1.38178374e-31 1.91322830e-23
 6.77143750e-35], sum to 1.0000
[2019-03-24 00:58:58,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2619
[2019-03-24 00:58:58,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7096691360059341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808827.8717921328, 808827.8717921328, 177982.6110973363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4484400.0000, 
sim time next is 4485000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7091120791279004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808192.645246627, 808192.645246627, 177876.2650166509], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6537048561046434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28864023044522397, 0.28864023044522397, 0.34206974041663635], 
reward next is 0.6579, 
noisyNet noise sample is [array([1.0811183], dtype=float32), -1.0704937]. 
=============================================
[2019-03-24 00:58:58,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.32109 ]
 [79.402245]
 [79.47592 ]
 [79.55385 ]
 [79.5536  ]], R is [[79.11558533]
 [78.98215485]
 [78.85076904]
 [78.72227478]
 [78.59793091]].
[2019-03-24 00:58:59,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3750794e-16 1.0000000e+00 2.6281611e-25 2.4327291e-18 4.1588149e-26], sum to 1.0000
[2019-03-24 00:58:59,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9571
[2019-03-24 00:58:59,721] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7091120791279004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808192.645246627, 808192.645246627, 177876.2650166509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485000.0000, 
sim time next is 4485600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7072838569960311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806107.879373672, 806107.879373672, 177527.620172185], 
processed observation next is [0.0, 0.9565217391304348, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6515284011857514, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28789567120488285, 0.28789567120488285, 0.34139926956189426], 
reward next is 0.6586, 
noisyNet noise sample is [array([-1.0888281], dtype=float32), 0.8549183]. 
=============================================
[2019-03-24 00:59:01,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3984758e-20 1.0000000e+00 1.3500483e-30 2.4511789e-21 2.4589395e-31], sum to 1.0000
[2019-03-24 00:59:01,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8922
[2019-03-24 00:59:01,610] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 86.0, 1.0, 2.0, 0.5839012848255937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 678668.9812822536, 678668.9812822532, 155960.0744193575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4532400.0000, 
sim time next is 4533000.0000, 
raw observation next is [24.41666666666666, 87.33333333333334, 1.0, 2.0, 0.5773688866529071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672520.0752758441, 672520.0752758441, 154915.1689115063], 
processed observation next is [0.0, 0.4782608695652174, 0.4598765432098763, 0.8733333333333334, 1.0, 1.0, 0.49686772220584174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24018574116994432, 0.24018574116994432, 0.29791378636828136], 
reward next is 0.7021, 
noisyNet noise sample is [array([0.2205627], dtype=float32), -0.18299828]. 
=============================================
[2019-03-24 00:59:01,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.09648]
 [71.95244]
 [71.86912]
 [71.79966]
 [71.74203]], R is [[72.18358612]
 [72.16182709]
 [72.13785553]
 [72.11168671]
 [72.08362579]].
[2019-03-24 00:59:11,588] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0550143e-18 1.0000000e+00 1.8369572e-26 7.3712763e-19 5.6847917e-27], sum to 1.0000
[2019-03-24 00:59:11,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6724
[2019-03-24 00:59:11,599] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 81.5, 1.0, 2.0, 0.6909726795596027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787508.1005834385, 787508.1005834385, 174448.2500929074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4728600.0000, 
sim time next is 4729200.0000, 
raw observation next is [28.26666666666667, 82.33333333333334, 1.0, 2.0, 0.6987804979605703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 796411.3681173549, 796411.3681173559, 175919.170260203], 
processed observation next is [1.0, 0.7391304347826086, 0.6024691358024692, 0.8233333333333335, 1.0, 1.0, 0.6414053547149646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2844326314704839, 0.28443263147048425, 0.33830609665423655], 
reward next is 0.6617, 
noisyNet noise sample is [array([1.392431], dtype=float32), -0.5791578]. 
=============================================
[2019-03-24 00:59:19,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7598754e-09 1.0000000e+00 1.7571850e-15 1.5622260e-11 6.3943470e-17], sum to 1.0000
[2019-03-24 00:59:19,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0390
[2019-03-24 00:59:19,204] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3059634.666544324 W.
[2019-03-24 00:59:19,210] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 77.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8941781196106674, 1.0, 1.0, 0.9977734948820727, 7.223283209374007, 6.9112, 121.94756008, 3059634.666544324, 2899791.965658921, 539937.7915830885], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4889400.0000, 
sim time next is 4890000.0000, 
raw observation next is [31.53333333333333, 77.66666666666667, 1.0, 2.0, 0.9998937832628589, 1.0, 2.0, 0.8133115536078641, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2784128.357037835, 2784128.357037835, 519548.3256502076], 
processed observation next is [1.0, 0.6086956521739131, 0.7234567901234568, 0.7766666666666667, 1.0, 1.0, 0.9998735515034035, 1.0, 1.0, 0.7777518495331716, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9943315560849411, 0.9943315560849411, 0.9991313954811685], 
reward next is 0.0009, 
noisyNet noise sample is [array([1.714309], dtype=float32), 0.9934801]. 
=============================================
[2019-03-24 00:59:19,219] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[42.52221 ]
 [42.30298 ]
 [43.651947]
 [43.45314 ]
 [44.786297]], R is [[42.7272644 ]
 [42.29999161]
 [41.87699127]
 [41.55126572]
 [41.13575363]].
[2019-03-24 00:59:20,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3306747e-12 1.0000000e+00 2.9625063e-17 6.0713667e-10 2.7486837e-18], sum to 1.0000
[2019-03-24 00:59:20,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3284
[2019-03-24 00:59:20,522] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.16666666666667, 1.0, 2.0, 0.7016955598571372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799735.4442706938, 799735.4442706938, 176464.9203663054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4925400.0000, 
sim time next is 4926000.0000, 
raw observation next is [27.0, 82.33333333333334, 1.0, 2.0, 0.6938175809732829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 790752.1341389337, 790752.1341389333, 174976.2308530201], 
processed observation next is [1.0, 0.0, 0.5555555555555556, 0.8233333333333335, 1.0, 1.0, 0.6354971202062892, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2824114764781906, 0.2824114764781904, 0.33649275164042325], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.52876526], dtype=float32), -0.10010775]. 
=============================================
[2019-03-24 00:59:20,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[43.896217]
 [44.236603]
 [45.16549 ]
 [45.09948 ]
 [45.045555]], R is [[43.84255219]
 [44.06476974]
 [44.28131104]
 [44.4901619 ]
 [44.68967056]].
[2019-03-24 00:59:24,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2940694e-06 9.9999857e-01 2.2926487e-09 1.4731026e-07 1.9944690e-09], sum to 1.0000
[2019-03-24 00:59:24,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9316
[2019-03-24 00:59:24,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1616378.053508726 W.
[2019-03-24 00:59:24,409] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.73333333333333, 81.0, 1.0, 2.0, 0.472491767393721, 1.0, 1.0, 0.472491767393721, 1.0, 2.0, 0.7522222816733768, 6.9112, 6.9112, 121.94756008, 1616378.053508726, 1616378.053508726, 330291.6878514297], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4977600.0000, 
sim time next is 4978200.0000, 
raw observation next is [27.36666666666667, 77.5, 1.0, 2.0, 0.8390070744823387, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1671462.984479395, 1671462.984479396, 344113.4449352114], 
processed observation next is [1.0, 0.6086956521739131, 0.569135802469136, 0.775, 1.0, 1.0, 0.8083417553361175, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5969510658854982, 0.5969510658854985, 0.6617566248754065], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31800058], dtype=float32), -1.7062169]. 
=============================================
[2019-03-24 00:59:24,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6181769e-12 1.0000000e+00 6.1461174e-19 2.1908109e-14 5.0007382e-21], sum to 1.0000
[2019-03-24 00:59:24,505] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4621
[2019-03-24 00:59:24,513] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 87.16666666666667, 1.0, 2.0, 0.6438021526785517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 754947.4631619395, 754947.463161939, 166777.6126385206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950600.0000, 
sim time next is 4951200.0000, 
raw observation next is [24.16666666666666, 85.33333333333334, 1.0, 2.0, 0.7511099829596853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883512.1414498221, 883512.1414498221, 187374.5809879153], 
processed observation next is [1.0, 0.30434782608695654, 0.45061728395061706, 0.8533333333333334, 1.0, 1.0, 0.7037023606662921, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3155400505177936, 0.3155400505177936, 0.3603357326690679], 
reward next is 0.6397, 
noisyNet noise sample is [array([-0.05854696], dtype=float32), 0.8540845]. 
=============================================
[2019-03-24 00:59:27,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2665330e-25 1.0000000e+00 1.1632134e-33 4.8577931e-25 5.2948414e-37], sum to 1.0000
[2019-03-24 00:59:27,324] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0216
[2019-03-24 00:59:27,328] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 76.0, 1.0, 2.0, 0.7485074046721707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 853117.4645624782, 853117.4645624782, 185536.6868303977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5052600.0000, 
sim time next is 5053200.0000, 
raw observation next is [29.7, 77.0, 1.0, 2.0, 0.7722532325783421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880197.508339269, 880197.508339269, 190281.4915772637], 
processed observation next is [0.0, 0.4782608695652174, 0.6555555555555556, 0.77, 1.0, 1.0, 0.7288728959265978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3143562529783103, 0.3143562529783103, 0.36592594534089173], 
reward next is 0.6341, 
noisyNet noise sample is [array([-0.21915299], dtype=float32), 1.0450299]. 
=============================================
[2019-03-24 00:59:28,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4100712e-22 1.0000000e+00 2.0713862e-30 1.6744489e-22 1.1723366e-33], sum to 1.0000
[2019-03-24 00:59:28,607] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7062
[2019-03-24 00:59:28,611] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 77.0, 1.0, 2.0, 0.7044939120287528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802926.4486423738, 802926.4486423738, 176998.1210362162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5048400.0000, 
sim time next is 5049000.0000, 
raw observation next is [28.55, 76.0, 1.0, 2.0, 0.7082427428137017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807201.3193343551, 807201.3193343551, 177711.9473004138], 
processed observation next is [0.0, 0.43478260869565216, 0.612962962962963, 0.76, 1.0, 1.0, 0.6526699319210735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2882861854765554, 0.2882861854765554, 0.3417537448084881], 
reward next is 0.6582, 
noisyNet noise sample is [array([1.0673475], dtype=float32), -0.45230818]. 
=============================================
[2019-03-24 00:59:28,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.53918]
 [79.48675]
 [79.35488]
 [79.25524]
 [79.21577]], R is [[79.48168182]
 [79.34648895]
 [79.21647644]
 [79.08424377]
 [78.95466614]].
[2019-03-24 00:59:31,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2960441e-18 1.0000000e+00 8.7921999e-25 3.8641296e-18 1.3861909e-25], sum to 1.0000
[2019-03-24 00:59:31,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2859
[2019-03-24 00:59:31,709] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 95.33333333333334, 1.0, 2.0, 0.7367783672500761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839741.8743177919, 839741.8743177919, 183226.9877760185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5125200.0000, 
sim time next is 5125800.0000, 
raw observation next is [26.41666666666666, 94.16666666666666, 1.0, 2.0, 0.7470121768882841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851412.3198257467, 851412.3198257467, 185239.0775706492], 
processed observation next is [0.0, 0.30434782608695654, 0.5339506172839504, 0.9416666666666665, 1.0, 1.0, 0.6988240201051001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30407582850919523, 0.30407582850919523, 0.35622899532817154], 
reward next is 0.6438, 
noisyNet noise sample is [array([0.2933465], dtype=float32), 2.1538534]. 
=============================================
[2019-03-24 00:59:33,294] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0420785e-19 1.0000000e+00 5.8770748e-26 4.1508257e-19 2.4895817e-27], sum to 1.0000
[2019-03-24 00:59:33,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5922
[2019-03-24 00:59:33,307] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.53333333333333, 75.66666666666667, 1.0, 2.0, 0.7922967496509657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 903056.1345354834, 903056.1345354834, 194364.4033077311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5142000.0000, 
sim time next is 5142600.0000, 
raw observation next is [30.65, 75.5, 1.0, 2.0, 0.8046689791088548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 917166.3821859591, 917166.3821859587, 196917.8264600176], 
processed observation next is [0.0, 0.5217391304347826, 0.6907407407407407, 0.755, 1.0, 1.0, 0.7674630703676844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32755942220927114, 0.327559422209271, 0.37868812780772615], 
reward next is 0.6213, 
noisyNet noise sample is [array([0.06887597], dtype=float32), 1.1933197]. 
=============================================
[2019-03-24 00:59:34,608] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 00:59:34,611] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:59:34,612] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:59:34,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,612] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:59:34,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:59:34,613] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,615] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,615] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:59:34,615] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,617] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-24 00:59:34,625] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-24 00:59:34,675] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-24 00:59:34,704] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-24 00:59:34,733] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-24 00:59:50,746] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 00:59:50,748] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.14453109, 48.31697264, 1.0, 2.0, 0.5339135826519721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 661981.2537195972, 661981.2537195968, 149089.3183873993]
[2019-03-24 00:59:50,748] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:59:50,751] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9291399e-19 1.0000000e+00 2.7759522e-27 1.4125975e-19 1.0391931e-30], sampled 0.4259585640408311
[2019-03-24 01:00:00,024] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:00:00,024] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.73333333333333, 57.0, 1.0, 2.0, 0.3924093550382287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484773.4861827777, 484773.4861827777, 127521.8572024076]
[2019-03-24 01:00:00,026] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:00:00,028] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.3773083e-19 1.0000000e+00 6.6486037e-27 2.6162257e-19 2.7839545e-30], sampled 0.27913093550900947
[2019-03-24 01:00:00,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:00:00,719] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.66666666666666, 87.66666666666667, 1.0, 2.0, 0.3165166648720475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402489.3337260498, 402489.3337260498, 117634.3590190129]
[2019-03-24 01:00:00,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:00:00,722] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.3103747e-19 1.0000000e+00 3.3101971e-27 1.5993460e-19 1.2672568e-30], sampled 0.2145204358637922
[2019-03-24 01:00:19,133] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:00:19,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.8, 32.0, 1.0, 2.0, 0.8700477591613278, 1.0, 1.0, 0.8700477591613278, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9257074875908, 2005678.913522939, 2005678.913522938, 374684.2381423854]
[2019-03-24 01:00:19,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:00:19,137] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9631823e-14 1.0000000e+00 2.4138410e-20 1.1133194e-14 6.9985922e-23], sampled 0.7804467355472055
[2019-03-24 01:00:19,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2005678.913522939 W.
[2019-03-24 01:00:47,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:00:47,689] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.6, 84.0, 1.0, 2.0, 0.7016301389556898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425954594, 805501.058455694, 805501.058455694, 176745.4971722222]
[2019-03-24 01:00:47,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:00:47,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.6245545e-19 1.0000000e+00 8.9745670e-27 3.2328638e-19 3.9049151e-30], sampled 0.0793146770665264
[2019-03-24 01:00:58,518] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:00:58,519] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 80.66666666666667, 1.0, 2.0, 0.5904550679572658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679710.9529951529, 679710.9529951529, 156776.2418226184]
[2019-03-24 01:00:58,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:00:58,522] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.6112504e-19 1.0000000e+00 8.9484491e-27 3.2263342e-19 3.8923037e-30], sampled 0.40304896914459376
[2019-03-24 01:01:00,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:01:00,855] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 55.0, 1.0, 2.0, 0.7353587002240208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857360.312089909, 857360.312089909, 183894.7333951533]
[2019-03-24 01:01:00,857] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:01:00,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8574448e-19 1.0000000e+00 7.5189830e-27 2.8532644e-19 3.1983035e-30], sampled 0.8905699343149948
[2019-03-24 01:01:09,482] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([9.655381e-05], dtype=float32), 0.33864853]
[2019-03-24 01:01:09,484] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.21144229666667, 51.204556045, 1.0, 2.0, 0.5494985016576175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 638077.5771517337, 638077.5771517332, 150175.2843599158]
[2019-03-24 01:01:09,486] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:01:09,489] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7438633e-19 1.0000000e+00 2.5269355e-27 1.3220055e-19 9.3470176e-31], sampled 0.6803349465847768
[2019-03-24 01:01:23,989] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:01:24,174] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:01:24,238] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:01:24,254] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:01:24,439] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:01:25,455] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 350000, evaluation results [350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:01:29,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0790484e-05 9.0134346e-01 6.9138713e-07 9.8615058e-02 7.8473295e-10], sum to 1.0000
[2019-03-24 01:01:29,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8140
[2019-03-24 01:01:29,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2125671.503654612 W.
[2019-03-24 01:01:29,540] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.9317833576013067, 1.0, 2.0, 0.9317833576013067, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2125671.503654612, 2125671.503654612, 401218.5504310046], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5235600.0000, 
sim time next is 5236200.0000, 
raw observation next is [29.25, 70.5, 1.0, 2.0, 0.9538035358732551, 1.0, 2.0, 0.9538035358732551, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2175967.209144721, 2175967.209144721, 411407.3233987388], 
processed observation next is [1.0, 0.6086956521739131, 0.6388888888888888, 0.705, 1.0, 1.0, 0.9450042093729227, 1.0, 1.0, 0.9450042093729227, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7771311461231146, 0.7771311461231146, 0.7911679296129592], 
reward next is 0.2088, 
noisyNet noise sample is [array([-1.0692568], dtype=float32), 0.25490478]. 
=============================================
[2019-03-24 01:01:32,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3402801e-09 9.2935652e-01 3.8055045e-12 7.0643514e-02 3.5243188e-16], sum to 1.0000
[2019-03-24 01:01:32,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3912
[2019-03-24 01:01:32,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1447582.915432873 W.
[2019-03-24 01:01:32,335] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 83.0, 1.0, 2.0, 0.6339505547153662, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9852681622181574, 6.911199999999999, 6.9112, 121.9260426156144, 1447582.915432873, 1447582.915432874, 303339.4361685489], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5308800.0000, 
sim time next is 5309400.0000, 
raw observation next is [24.55, 82.5, 1.0, 2.0, 0.6289986496368709, 0.0, 2.0, 0.0, 1.0, 2.0, 0.983808017755282, 6.9112, 6.9112, 121.9260426156618, 1443138.698327717, 1443138.698327717, 302200.0165790959], 
processed observation next is [1.0, 0.43478260869565216, 0.46481481481481485, 0.825, 1.0, 1.0, 0.5583317257581797, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9797600221941024, 0.0, 0.0, 0.8094621288201359, 0.5154066779741846, 0.5154066779741846, 0.5811538780367229], 
reward next is 0.4188, 
noisyNet noise sample is [array([-0.09432704], dtype=float32), 0.52715397]. 
=============================================
[2019-03-24 01:01:39,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7913493e-08 9.9993968e-01 9.6683973e-11 6.0334645e-05 4.1931885e-14], sum to 1.0000
[2019-03-24 01:01:39,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7310
[2019-03-24 01:01:39,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2023133.72699958 W.
[2019-03-24 01:01:39,883] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 81.5, 1.0, 2.0, 0.5912581262054825, 1.0, 2.0, 0.5912581262054825, 1.0, 2.0, 0.941302192851972, 6.911199999999999, 6.9112, 121.94756008, 2023133.72699958, 2023133.72699958, 390633.1457265987], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5412600.0000, 
sim time next is 5413200.0000, 
raw observation next is [28.66666666666666, 80.66666666666667, 1.0, 2.0, 0.8948053121937598, 1.0, 2.0, 0.8948053121937598, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156587, 2041217.303110419, 2041217.303110419, 384487.9579047929], 
processed observation next is [1.0, 0.6521739130434783, 0.6172839506172837, 0.8066666666666668, 1.0, 1.0, 0.874768228802095, 1.0, 1.0, 0.874768228802095, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201154, 0.7290061796822925, 0.7290061796822925, 0.7393999190476787], 
reward next is 0.2606, 
noisyNet noise sample is [array([0.3695427], dtype=float32), -0.39612252]. 
=============================================
[2019-03-24 01:01:39,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1593393e-17 1.0000000e+00 7.4239473e-23 3.8734923e-15 1.0526879e-28], sum to 1.0000
[2019-03-24 01:01:39,970] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-24 01:01:39,974] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 92.16666666666667, 1.0, 2.0, 0.7427482784158461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846549.8279931385, 846549.8279931385, 184398.5232059633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [26.56666666666667, 92.33333333333334, 1.0, 2.0, 0.7403281385836932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 843789.9471642919, 843789.9471642914, 183922.7675615838], 
processed observation next is [1.0, 0.043478260869565216, 0.5395061728395063, 0.9233333333333335, 1.0, 1.0, 0.6908668316472538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3013535525586757, 0.3013535525586755, 0.3536976299261227], 
reward next is 0.6463, 
noisyNet noise sample is [array([-0.608587], dtype=float32), -0.9620776]. 
=============================================
[2019-03-24 01:01:39,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[49.65811 ]
 [49.809013]
 [49.805717]
 [49.95666 ]
 [50.164886]], R is [[49.69272614]
 [49.84118652]
 [49.98740005]
 [50.13191605]
 [50.27464294]].
[2019-03-24 01:01:47,508] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5021668e-26 1.0000000e+00 9.5761370e-36 7.4066469e-20 3.4026411e-38], sum to 1.0000
[2019-03-24 01:01:47,514] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3638
[2019-03-24 01:01:47,522] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 93.66666666666667, 1.0, 2.0, 0.6868527762491582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782810.210076644, 782810.210076644, 173669.2646985114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5604000.0000, 
sim time next is 5604600.0000, 
raw observation next is [25.21666666666667, 93.83333333333334, 1.0, 2.0, 0.681852075310412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 777107.9922529213, 777107.9922529199, 172735.8173899558], 
processed observation next is [1.0, 0.8695652173913043, 0.48950617283950626, 0.9383333333333335, 1.0, 1.0, 0.6212524706076333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.27753856866175763, 0.27753856866175713, 0.3321842642114535], 
reward next is 0.6678, 
noisyNet noise sample is [array([1.1315157], dtype=float32), -0.68717283]. 
=============================================
[2019-03-24 01:01:48,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5601814e-21 1.0000000e+00 2.4575141e-31 7.2130886e-18 1.7620680e-34], sum to 1.0000
[2019-03-24 01:01:49,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5618
[2019-03-24 01:01:49,013] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 97.0, 1.0, 2.0, 0.5937559133346013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 686041.8585465777, 686041.8585465773, 157460.5433053175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5620800.0000, 
sim time next is 5621400.0000, 
raw observation next is [23.55, 97.0, 1.0, 2.0, 0.5920586512344038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684329.7000618353, 684329.7000618353, 157180.8904051606], 
processed observation next is [0.0, 0.043478260869565216, 0.4277777777777778, 0.97, 1.0, 1.0, 0.5143555371838141, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24440346430779833, 0.24440346430779833, 0.3022709430868473], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.05588891], dtype=float32), 1.1607846]. 
=============================================
[2019-03-24 01:01:54,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4067579e-26 1.0000000e+00 2.9793345e-33 3.6296843e-24 0.0000000e+00], sum to 1.0000
[2019-03-24 01:01:54,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-24 01:01:54,133] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 87.66666666666667, 1.0, 2.0, 0.7248515231006674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 826140.9480815806, 826140.9480815801, 180903.1827102715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5691000.0000, 
sim time next is 5691600.0000, 
raw observation next is [26.5, 88.0, 1.0, 2.0, 0.71418853821322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813981.4839389207, 813981.4839389207, 178847.7917339864], 
processed observation next is [0.0, 0.9130434782608695, 0.5370370370370371, 0.88, 1.0, 1.0, 0.6597482597776428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29070767283532883, 0.29070767283532883, 0.34393806102689695], 
reward next is 0.6561, 
noisyNet noise sample is [array([-0.28786156], dtype=float32), -0.12558663]. 
=============================================
[2019-03-24 01:01:55,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1680037e-23 1.0000000e+00 1.4013320e-34 1.5564617e-19 8.3941984e-37], sum to 1.0000
[2019-03-24 01:01:55,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6604
[2019-03-24 01:01:55,872] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 84.0, 1.0, 2.0, 0.5121093124352167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609122.8329825962, 609122.8329825958, 144747.7659877211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5784000.0000, 
sim time next is 5784600.0000, 
raw observation next is [23.7, 84.5, 1.0, 2.0, 0.5104663398493184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607509.8423786379, 607509.8423786379, 144499.4763170625], 
processed observation next is [0.0, 0.9565217391304348, 0.4333333333333333, 0.845, 1.0, 1.0, 0.4172218331539505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21696780084951353, 0.21696780084951353, 0.2778836083020433], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.8278148], dtype=float32), 0.71546257]. 
=============================================
[2019-03-24 01:02:00,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4537094e-23 1.0000000e+00 2.6237055e-31 7.6549679e-22 2.4963699e-36], sum to 1.0000
[2019-03-24 01:02:00,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3645
[2019-03-24 01:02:00,584] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 85.0, 1.0, 2.0, 0.3982850215165286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503273.1625400921, 503273.1625400921, 128545.4962429288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5887200.0000, 
sim time next is 5887800.0000, 
raw observation next is [19.45, 85.0, 1.0, 2.0, 0.3823483505483523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483465.3454825889, 483465.3454825885, 126324.6352164814], 
processed observation next is [1.0, 0.13043478260869565, 0.2759259259259259, 0.85, 1.0, 1.0, 0.26470041731946703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17266619481521034, 0.17266619481521017, 0.24293199080092578], 
reward next is 0.7571, 
noisyNet noise sample is [array([0.9337713], dtype=float32), -1.2558146]. 
=============================================
[2019-03-24 01:02:13,781] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:02:13,781] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:02:13,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,783] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:02:13,783] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,784] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:02:13,784] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:02:13,785] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:02:13,786] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,788] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,801] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-24 01:02:13,822] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-24 01:02:13,844] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-24 01:02:13,845] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-24 01:02:13,866] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-24 01:03:13,757] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3550592]
[2019-03-24 01:03:13,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5557870505823507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 648120.7124197561, 648120.7124197566, 151332.7295682824]
[2019-03-24 01:03:13,760] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:13,764] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2504955e-21 1.0000000e+00 4.1070479e-30 6.7316012e-18 1.8354027e-33], sampled 0.8790575772894073
[2019-03-24 01:03:20,729] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3550592]
[2019-03-24 01:03:20,731] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.28611126333333, 85.33440524000001, 1.0, 2.0, 0.5572866195414706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667835.1740726766, 667835.1740726766, 152300.4181615914]
[2019-03-24 01:03:20,732] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:03:20,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3577486e-21 1.0000000e+00 1.4161405e-29 1.3822469e-17 7.2822345e-33], sampled 0.051413810267843085
[2019-03-24 01:03:40,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3550592]
[2019-03-24 01:03:40,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.55127390666667, 62.83450857333334, 1.0, 2.0, 0.446631508980419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544296.7210151013, 544296.7210151013, 135144.7973024227]
[2019-03-24 01:03:40,309] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:03:40,313] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8652342e-22 1.0000000e+00 1.1748269e-31 8.5295241e-19 3.5083952e-35], sampled 0.32343998476676106
[2019-03-24 01:03:43,620] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3550592]
[2019-03-24 01:03:43,621] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.2, 88.0, 1.0, 2.0, 0.4179463205330579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514124.0600184708, 514124.0600184708, 131086.1376155133]
[2019-03-24 01:03:43,622] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:43,627] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9917147e-21 1.0000000e+00 9.3035875e-30 1.0827632e-17 4.5619066e-33], sampled 0.8221592298313903
[2019-03-24 01:04:01,166] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:04:01,762] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:04:02,230] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:04:02,570] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:04:02,596] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:04:03,612] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 375000, evaluation results [375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:04:06,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2974067e-13 1.0000000e+00 7.8447674e-19 3.0986672e-11 7.0763977e-21], sum to 1.0000
[2019-03-24 01:04:06,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-24 01:04:06,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1945180.093854655 W.
[2019-03-24 01:04:06,958] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.91666666666667, 52.66666666666667, 1.0, 2.0, 0.5685010609197345, 1.0, 2.0, 0.5685010609197345, 1.0, 1.0, 0.9050722037711869, 6.911199999999999, 6.9112, 121.94756008, 1945180.093854655, 1945180.093854655, 378480.6440810807], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6192600.0000, 
sim time next is 6193200.0000, 
raw observation next is [29.93333333333333, 52.33333333333334, 1.0, 2.0, 0.5518549257004579, 1.0, 2.0, 0.5518549257004579, 1.0, 2.0, 0.8785710143753224, 6.9112, 6.9112, 121.94756008, 1888163.57313386, 1888163.57313386, 369768.3959904894], 
processed observation next is [1.0, 0.6956521739130435, 0.6641975308641974, 0.5233333333333334, 1.0, 1.0, 0.46649395916721176, 1.0, 1.0, 0.46649395916721176, 1.0, 1.0, 0.8482137679691528, 0.0, 0.0, 0.8096049824067558, 0.6743441332620929, 0.6743441332620929, 0.7110930692124796], 
reward next is 0.2889, 
noisyNet noise sample is [array([-0.9155255], dtype=float32), -1.6175011]. 
=============================================
[2019-03-24 01:04:07,316] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2621683e-13 1.0000000e+00 1.1169086e-16 9.8417600e-11 9.5754213e-18], sum to 1.0000
[2019-03-24 01:04:07,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-24 01:04:07,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1485165.159807229 W.
[2019-03-24 01:04:07,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.03333333333333, 68.66666666666667, 1.0, 2.0, 0.6508709888010178, 1.0, 2.0, 0.6508709888010178, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1485165.159807229, 1485165.159807229, 286028.5917998745], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6172800.0000, 
sim time next is 6173400.0000, 
raw observation next is [27.21666666666667, 67.83333333333333, 1.0, 2.0, 0.6666718351816325, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9914095951136862, 6.9112, 6.9112, 121.9260426156618, 1480003.833751085, 1480003.833751085, 310179.6988559988], 
processed observation next is [1.0, 0.43478260869565216, 0.5635802469135803, 0.6783333333333332, 1.0, 1.0, 0.6031807561686101, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9892619938921077, 0.0, 0.0, 0.8094621288201359, 0.5285727977682446, 0.5285727977682446, 0.5964994208769208], 
reward next is 0.4035, 
noisyNet noise sample is [array([0.63021076], dtype=float32), 0.30480018]. 
=============================================
[2019-03-24 01:04:08,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0150817e-22 1.0000000e+00 3.5622110e-31 1.0905469e-19 1.1063360e-33], sum to 1.0000
[2019-03-24 01:04:08,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9845
[2019-03-24 01:04:08,157] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 65.33333333333334, 1.0, 2.0, 0.5606398312659668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654409.3496968211, 654409.3496968211, 152166.2532653918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6207000.0000, 
sim time next is 6207600.0000, 
raw observation next is [27.6, 65.66666666666667, 1.0, 2.0, 0.5568560573125135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651059.150198973, 651059.150198973, 151583.3842757899], 
processed observation next is [1.0, 0.8695652173913043, 0.5777777777777778, 0.6566666666666667, 1.0, 1.0, 0.4724476872768018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2325211250710618, 0.2325211250710618, 0.2915065082226729], 
reward next is 0.7085, 
noisyNet noise sample is [array([0.7721427], dtype=float32), -0.3940766]. 
=============================================
[2019-03-24 01:04:10,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6262500e-26 1.0000000e+00 4.3569555e-33 3.6717889e-21 0.0000000e+00], sum to 1.0000
[2019-03-24 01:04:10,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1066
[2019-03-24 01:04:10,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.45, 67.66666666666667, 1.0, 2.0, 0.6274192490490716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716864.1004598549, 716864.1004598549, 162948.9543607213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6267000.0000, 
sim time next is 6267600.0000, 
raw observation next is [28.6, 67.0, 1.0, 2.0, 0.6292895138624086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718549.775718472, 718549.775718472, 163257.4584157544], 
processed observation next is [0.0, 0.5652173913043478, 0.6148148148148148, 0.67, 1.0, 1.0, 0.5586779926933436, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2566249198994543, 0.2566249198994543, 0.31395665079952767], 
reward next is 0.6860, 
noisyNet noise sample is [array([1.921077], dtype=float32), -0.2754422]. 
=============================================
[2019-03-24 01:04:12,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1028596e-18 1.0000000e+00 6.3540028e-26 2.2348708e-16 2.8089071e-29], sum to 1.0000
[2019-03-24 01:04:12,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0405
[2019-03-24 01:04:12,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 87.33333333333334, 1.0, 2.0, 0.5750433126808678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670894.5574300095, 670894.5574300095, 154569.6681542604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6313200.0000, 
sim time next is 6313800.0000, 
raw observation next is [24.33333333333333, 87.66666666666667, 1.0, 2.0, 0.5754261203286125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671178.2816124414, 671178.2816124414, 154627.2458202479], 
processed observation next is [0.0, 0.043478260869565216, 0.45679012345678993, 0.8766666666666667, 1.0, 1.0, 0.4945549051531101, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2397065291473005, 0.2397065291473005, 0.29736008811586134], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.5892857], dtype=float32), 0.5039028]. 
=============================================
[2019-03-24 01:04:12,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5837558e-23 1.0000000e+00 8.8280866e-34 3.4890294e-20 0.0000000e+00], sum to 1.0000
[2019-03-24 01:04:12,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3039
[2019-03-24 01:04:12,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 65.0, 1.0, 2.0, 0.6383574784904393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727513.6008994087, 727513.6008994087, 164801.0142750754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [29.26666666666667, 64.5, 1.0, 2.0, 0.642414137452463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732139.0405082707, 732139.0405082707, 165527.1390405319], 
processed observation next is [0.0, 0.5652173913043478, 0.6395061728395063, 0.645, 1.0, 1.0, 0.5743025445862655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26147822875295385, 0.26147822875295385, 0.31832142123179213], 
reward next is 0.6817, 
noisyNet noise sample is [array([-0.60263854], dtype=float32), -1.2597351]. 
=============================================
[2019-03-24 01:04:14,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.31688229e-18 1.00000000e+00 1.08126714e-28 4.38403309e-17
 1.09708395e-29], sum to 1.0000
[2019-03-24 01:04:14,064] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4117
[2019-03-24 01:04:14,067] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 86.16666666666667, 1.0, 2.0, 0.6061461847058627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698458.272371653, 698458.272371653, 159512.3623999708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6335400.0000, 
sim time next is 6336000.0000, 
raw observation next is [25.2, 86.0, 1.0, 2.0, 0.6093821954507705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 701535.791149677, 701535.7911496765, 160044.4078794924], 
processed observation next is [0.0, 0.34782608695652173, 0.4888888888888889, 0.86, 1.0, 1.0, 0.5349788041080602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25054849683917035, 0.2505484968391702, 0.3077777074605623], 
reward next is 0.6922, 
noisyNet noise sample is [array([-0.18201199], dtype=float32), 0.9051236]. 
=============================================
[2019-03-24 01:04:14,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.916965]
 [61.922943]
 [61.9305  ]
 [61.94001 ]
 [61.9533  ]], R is [[62.01489639]
 [62.08799362]
 [62.16133499]
 [62.23486328]
 [62.30856323]].
[2019-03-24 01:04:14,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5549524e-25 1.0000000e+00 4.7623071e-33 2.8206116e-21 5.7006128e-38], sum to 1.0000
[2019-03-24 01:04:14,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-24 01:04:14,302] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 62.83333333333333, 1.0, 2.0, 0.646868259363808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737217.7031496238, 737217.7031496238, 166328.225769791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6275400.0000, 
sim time next is 6276000.0000, 
raw observation next is [29.8, 62.66666666666667, 1.0, 2.0, 0.6495004107501783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740218.9410213553, 740218.9410213553, 166802.8882790058], 
processed observation next is [0.0, 0.6521739130434783, 0.6592592592592593, 0.6266666666666667, 1.0, 1.0, 0.5827385842264027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2643639075076269, 0.2643639075076269, 0.32077478515193425], 
reward next is 0.6792, 
noisyNet noise sample is [array([1.363306], dtype=float32), -0.4343208]. 
=============================================
[2019-03-24 01:04:14,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.40585 ]
 [77.33673 ]
 [77.23169 ]
 [77.171585]
 [77.11786 ]], R is [[77.37622833]
 [77.28260803]
 [77.18838501]
 [77.09533691]
 [77.003479  ]].
[2019-03-24 01:04:17,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.31200416e-17 1.00000000e+00 4.26015149e-26 1.86778176e-16
 1.58401370e-28], sum to 1.0000
[2019-03-24 01:04:17,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0112
[2019-03-24 01:04:17,971] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666667, 73.33333333333334, 1.0, 2.0, 0.6905680286531419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787046.6793406818, 787046.6793406818, 174365.4656839865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6385800.0000, 
sim time next is 6386400.0000, 
raw observation next is [28.3, 74.0, 1.0, 2.0, 0.6905327503762037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 787006.4517252224, 787006.4517252219, 174358.8252583063], 
processed observation next is [0.0, 0.9565217391304348, 0.6037037037037037, 0.74, 1.0, 1.0, 0.6315866075907186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.281073732759008, 0.2810737327590078, 0.33530543318905054], 
reward next is 0.6647, 
noisyNet noise sample is [array([1.4194795], dtype=float32), -0.3695054]. 
=============================================
[2019-03-24 01:04:32,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8187762e-22 1.0000000e+00 3.1005377e-32 1.5293718e-17 3.2848840e-37], sum to 1.0000
[2019-03-24 01:04:32,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1936
[2019-03-24 01:04:32,801] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 42.0, 1.0, 2.0, 0.3522111109473756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439796.3140195706, 439796.3140195701, 122159.7489338853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6631200.0000, 
sim time next is 6631800.0000, 
raw observation next is [27.71666666666667, 43.0, 1.0, 2.0, 0.358761785107898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447703.337047986, 447703.337047986, 123026.638743534], 
processed observation next is [1.0, 0.782608695652174, 0.5820987654320988, 0.43, 1.0, 1.0, 0.23662117274749767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15989404894570927, 0.15989404894570927, 0.23658968989141155], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.057972], dtype=float32), 0.7115001]. 
=============================================
[2019-03-24 01:04:33,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9963856e-23 1.0000000e+00 7.6044828e-34 2.8220123e-20 0.0000000e+00], sum to 1.0000
[2019-03-24 01:04:33,217] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2191
[2019-03-24 01:04:33,221] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 50.66666666666667, 1.0, 2.0, 0.3444746176705698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435343.5169563969, 435343.5169563969, 121216.9555828924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6643200.0000, 
sim time next is 6643800.0000, 
raw observation next is [24.8, 49.5, 1.0, 2.0, 0.3387338035895728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428898.1742087316, 428898.1742087316, 120473.8489177882], 
processed observation next is [1.0, 0.9130434782608695, 0.4740740740740741, 0.495, 1.0, 1.0, 0.21277833760663425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1531779193602613, 0.1531779193602613, 0.23168047868805422], 
reward next is 0.7683, 
noisyNet noise sample is [array([-0.33503014], dtype=float32), -0.8130982]. 
=============================================
[2019-03-24 01:04:44,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.11141137e-19 1.00000000e+00 4.61438731e-29 1.04825436e-16
 7.88326361e-32], sum to 1.0000
[2019-03-24 01:04:44,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4910
[2019-03-24 01:04:44,519] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 80.0, 1.0, 2.0, 0.4547440782533805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551914.0090059382, 551914.0090059382, 136288.1093489259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6940800.0000, 
sim time next is 6941400.0000, 
raw observation next is [23.46666666666667, 78.66666666666667, 1.0, 2.0, 0.4579976725212002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555198.2605247416, 555198.2605247416, 136756.0528704827], 
processed observation next is [0.0, 0.34782608695652173, 0.42469135802469143, 0.7866666666666667, 1.0, 1.0, 0.3547591339538098, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19828509304455058, 0.19828509304455058, 0.2629924093663129], 
reward next is 0.7370, 
noisyNet noise sample is [array([-1.3289553], dtype=float32), 0.27072668]. 
=============================================
[2019-03-24 01:04:47,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2007710e-21 1.0000000e+00 1.7391113e-32 8.2859742e-20 2.5879943e-35], sum to 1.0000
[2019-03-24 01:04:47,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-24 01:04:47,901] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 85.66666666666667, 1.0, 2.0, 0.4142452291711953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511264.0078017961, 511264.0078017961, 130597.3503758817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928800.0000, 
sim time next is 6929400.0000, 
raw observation next is [21.2, 86.33333333333333, 1.0, 2.0, 0.4130009339265889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509836.2584876765, 509836.2584876765, 130421.7928790147], 
processed observation next is [0.0, 0.17391304347826086, 0.34074074074074073, 0.8633333333333333, 1.0, 1.0, 0.30119158800784385, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18208437803131303, 0.18208437803131303, 0.25081114015195133], 
reward next is 0.7492, 
noisyNet noise sample is [array([1.2920967], dtype=float32), -0.8841266]. 
=============================================
[2019-03-24 01:04:51,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8464708e-16 1.0000000e+00 7.7972249e-23 1.5045380e-14 8.5103786e-27], sum to 1.0000
[2019-03-24 01:04:51,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-24 01:04:51,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 81.0, 1.0, 2.0, 0.4817753212024241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580887.70809171, 580887.70809171, 140281.0571911783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7072200.0000, 
sim time next is 7072800.0000, 
raw observation next is [23.46666666666667, 81.0, 1.0, 2.0, 0.4865672615523107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586497.8756202535, 586497.8756202535, 141017.3521908943], 
processed observation next is [1.0, 0.8695652173913043, 0.42469135802469143, 0.81, 1.0, 1.0, 0.3887705494670366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2094635270072334, 0.2094635270072334, 0.27118721575171983], 
reward next is 0.7288, 
noisyNet noise sample is [array([0.9667385], dtype=float32), -0.32713932]. 
=============================================
[2019-03-24 01:04:52,076] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:04:52,078] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:04:52,078] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:04:52,080] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:04:52,081] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:52,082] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:52,082] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:52,080] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:04:52,079] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:04:52,086] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:52,086] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:52,104] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-24 01:04:52,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-24 01:04:52,148] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-24 01:04:52,149] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-24 01:04:52,191] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-24 01:04:59,541] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:04:59,542] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.01033518, 53.11546398999999, 1.0, 2.0, 0.243302210267964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 313837.1505442503, 313837.1505442499, 91317.56223429402]
[2019-03-24 01:04:59,544] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:04:59,547] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.8764772e-19 1.0000000e+00 3.0927742e-26 2.1627106e-15 2.7122032e-29], sampled 0.37731879272437563
[2019-03-24 01:04:59,894] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:04:59,896] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.890067895, 66.423293445, 1.0, 2.0, 0.4087809363234816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510925.7683083958, 510925.7683083958, 129952.4777805312]
[2019-03-24 01:04:59,897] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:04:59,902] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0913138e-17 1.0000000e+00 1.0840116e-24 1.6471914e-14 1.4513903e-27], sampled 0.8661553216449455
[2019-03-24 01:05:01,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:05:01,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.43333333333333, 80.66666666666667, 1.0, 2.0, 0.2512413001754549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 324079.9993959299, 324079.9993959299, 93576.78156222831]
[2019-03-24 01:05:01,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:05:01,957] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2113791e-18 1.0000000e+00 4.8061064e-26 2.7815978e-15 4.4414403e-29], sampled 0.928666040689431
[2019-03-24 01:05:23,584] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:05:23,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.73785972, 61.05160491, 1.0, 2.0, 0.4136771665465438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510890.3000610391, 510890.3000610395, 130523.1882180334]
[2019-03-24 01:05:23,586] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:05:23,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5924165e-19 1.0000000e+00 3.4514896e-26 2.3028257e-15 3.0667470e-29], sampled 0.6142728041415749
[2019-03-24 01:05:36,734] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:05:36,734] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.16666666666666, 62.33333333333333, 1.0, 2.0, 0.7122091989382329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811724.3787429582, 811724.3787429582, 178470.3298083227]
[2019-03-24 01:05:36,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:05:36,740] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3253229e-19 1.0000000e+00 2.0861866e-27 4.6422080e-16 1.3276887e-30], sampled 0.8358432984368029
[2019-03-24 01:05:55,925] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:05:55,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 76.0, 1.0, 2.0, 0.6050799797326909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691644.7686493061, 691644.7686493061, 159056.360687621]
[2019-03-24 01:05:55,929] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:05:55,931] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.7595453e-19 1.0000000e+00 3.5367241e-26 2.3353632e-15 3.1518325e-29], sampled 0.11601240249762579
[2019-03-24 01:06:34,698] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:06:34,700] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.2, 87.0, 1.0, 2.0, 0.2581176140241959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 332938.8867309367, 332938.8867309362, 110279.4997997272]
[2019-03-24 01:06:34,700] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:06:34,702] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.1342184e-19 1.0000000e+00 1.8314996e-26 1.6038154e-15 1.5091999e-29], sampled 0.5207885376475034
[2019-03-24 01:06:34,848] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:06:34,849] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.98998092333333, 97.46904644666668, 1.0, 2.0, 0.4857632632114965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579413.086008027, 579413.0860080266, 140677.8029173096]
[2019-03-24 01:06:34,851] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:06:34,855] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.9276061e-19 1.0000000e+00 2.1760384e-26 1.7698051e-15 1.8303026e-29], sampled 0.6714196310806293
[2019-03-24 01:06:39,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.36874658]
[2019-03-24 01:06:39,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.97681073666667, 69.94877063166668, 1.0, 2.0, 0.3867221988364573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480275.1388133757, 480275.1388133757, 126788.3919706226]
[2019-03-24 01:06:39,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:06:39,309] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5409891e-19 1.0000000e+00 8.4037568e-27 1.0281445e-15 6.3119066e-30], sampled 0.09290318279216314
[2019-03-24 01:06:40,211] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:06:40,311] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:06:40,406] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:06:40,514] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:06:40,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:06:41,534] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 400000, evaluation results [400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:06:47,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3009396e-21 1.0000000e+00 3.2874096e-26 3.5380646e-16 9.0325240e-31], sum to 1.0000
[2019-03-24 01:06:47,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-24 01:06:47,545] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 88.00000000000001, 1.0, 2.0, 0.3640197409298821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456053.0149187755, 456053.0149187755, 123764.0353621402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7157400.0000, 
sim time next is 7158000.0000, 
raw observation next is [19.9, 88.0, 1.0, 2.0, 0.362943577975341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 454706.0149397912, 454706.0149397908, 123619.1514898649], 
processed observation next is [1.0, 0.8695652173913043, 0.2925925925925925, 0.88, 1.0, 1.0, 0.24159949758969165, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1623950053356397, 0.16239500533563958, 0.23772913748050942], 
reward next is 0.7623, 
noisyNet noise sample is [array([-1.7531593], dtype=float32), 1.269378]. 
=============================================
[2019-03-24 01:06:47,561] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.954865]
 [68.07798 ]
 [68.000565]
 [67.97085 ]
 [67.93023 ]], R is [[67.96374512]
 [68.04610443]
 [68.1275177 ]
 [68.20830536]
 [68.28844452]].
[2019-03-24 01:06:49,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3008012e-17 1.0000000e+00 1.4158038e-24 8.9238919e-15 4.4551851e-29], sum to 1.0000
[2019-03-24 01:06:49,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1351
[2019-03-24 01:06:49,030] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 94.66666666666667, 1.0, 2.0, 0.3856493201842415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478838.4914127259, 478838.4914127259, 126637.8301794826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177800.0000, 
sim time next is 7178400.0000, 
raw observation next is [19.8, 95.0, 1.0, 2.0, 0.3866188356758198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479785.0833465317, 479785.0833465313, 126766.5325592238], 
processed observation next is [1.0, 0.08695652173913043, 0.2888888888888889, 0.95, 1.0, 1.0, 0.26978432818549974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1713518154809042, 0.17135181548090403, 0.24378179338312267], 
reward next is 0.7562, 
noisyNet noise sample is [array([-0.0503073], dtype=float32), -0.73840207]. 
=============================================
[2019-03-24 01:06:53,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0599657e-23 1.0000000e+00 1.3097016e-28 7.3792137e-18 8.0595145e-37], sum to 1.0000
[2019-03-24 01:06:53,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9828
[2019-03-24 01:06:53,360] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 88.0, 1.0, 2.0, 0.380397147072299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473553.1630198655, 473553.1630198651, 125939.1404054783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7272000.0000, 
sim time next is 7272600.0000, 
raw observation next is [20.38333333333333, 88.16666666666667, 1.0, 2.0, 0.3951354048263004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491826.0920008105, 491826.0920008105, 127983.7356977605], 
processed observation next is [1.0, 0.17391304347826086, 0.3104938271604937, 0.8816666666666667, 1.0, 1.0, 0.27992310098369094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17565217571457517, 0.17565217571457517, 0.2461225686495394], 
reward next is 0.7539, 
noisyNet noise sample is [array([1.4116054], dtype=float32), -0.27101523]. 
=============================================
[2019-03-24 01:06:56,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6277446e-20 1.0000000e+00 3.3138956e-29 4.2533673e-17 1.2182481e-31], sum to 1.0000
[2019-03-24 01:06:56,108] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6622
[2019-03-24 01:06:56,111] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 67.0, 1.0, 2.0, 0.4672983411746771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564699.6388333003, 564699.6388333003, 138105.9361107594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324200.0000, 
sim time next is 7324800.0000, 
raw observation next is [25.3, 67.66666666666667, 1.0, 2.0, 0.4648905495241168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562119.9053760772, 562119.9053760772, 137751.2968816088], 
processed observation next is [1.0, 0.782608695652174, 0.49259259259259264, 0.6766666666666667, 1.0, 1.0, 0.36296493990966283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20075710906288471, 0.20075710906288471, 0.26490634015694003], 
reward next is 0.7351, 
noisyNet noise sample is [array([0.5197338], dtype=float32), 1.0696639]. 
=============================================
[2019-03-24 01:07:01,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2696680e-23 1.0000000e+00 1.1309633e-30 6.1127217e-21 1.6486496e-33], sum to 1.0000
[2019-03-24 01:07:01,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-24 01:07:01,408] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 90.0, 1.0, 2.0, 0.4066161897624124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 502922.4981816666, 502922.4981816661, 129534.7772656822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7411200.0000, 
sim time next is 7411800.0000, 
raw observation next is [20.55, 90.0, 1.0, 2.0, 0.4019145753052049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497462.3336650471, 497462.3336650471, 128877.279266843], 
processed observation next is [1.0, 0.782608695652174, 0.3166666666666667, 0.9, 1.0, 1.0, 0.2879935420300059, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17766511916608824, 0.17766511916608824, 0.24784092166700578], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.86912763], dtype=float32), -1.5694039]. 
=============================================
[2019-03-24 01:07:01,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8735654e-20 1.0000000e+00 5.1754298e-27 5.2634421e-16 1.4490978e-30], sum to 1.0000
[2019-03-24 01:07:01,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9780
[2019-03-24 01:07:01,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.21666666666667, 90.16666666666666, 1.0, 2.0, 0.920116615919139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.06974164789084, 6.9112, 121.9252064374165, 1207346.21372802, 1126159.27650634, 225519.6288389837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7401000.0000, 
sim time next is 7401600.0000, 
raw observation next is [21.2, 90.0, 1.0, 2.0, 0.836787159252744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259471227492, 1024645.926452411, 1024645.92645241, 206761.7152974361], 
processed observation next is [1.0, 0.6956521739130435, 0.34074074074074073, 0.9, 1.0, 1.0, 0.8056989991104095, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.809461494846502, 0.36594497373300394, 0.3659449737330036, 0.3976186832643002], 
reward next is 0.6024, 
noisyNet noise sample is [array([-0.00512907], dtype=float32), 0.22337927]. 
=============================================
[2019-03-24 01:07:08,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.611674e-21 1.000000e+00 5.140108e-29 1.478867e-17 5.411060e-32], sum to 1.0000
[2019-03-24 01:07:08,220] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-24 01:07:08,225] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.550584524850294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642699.1485445423, 642699.1485445423, 150501.3420745481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7561800.0000, 
sim time next is 7562400.0000, 
raw observation next is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.555509550605777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647134.6803561316, 647134.6803561316, 151257.7424783309], 
processed observation next is [0.0, 0.5217391304347826, 0.5679012345679011, 0.6866666666666668, 1.0, 1.0, 0.47084470310211546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23111952869861843, 0.23111952869861843, 0.29088027399679023], 
reward next is 0.7091, 
noisyNet noise sample is [array([-0.6111344], dtype=float32), 0.41555434]. 
=============================================
[2019-03-24 01:07:18,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7763352e-19 1.0000000e+00 3.3379688e-26 1.0043620e-15 1.7583173e-31], sum to 1.0000
[2019-03-24 01:07:18,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6141
[2019-03-24 01:07:18,916] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 70.33333333333333, 1.0, 2.0, 0.378987418929265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472471.0058132401, 472471.0058132401, 125758.6489936269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7767600.0000, 
sim time next is 7768200.0000, 
raw observation next is [22.53333333333333, 70.66666666666667, 1.0, 2.0, 0.3758581387554833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 469047.4860167538, 469047.4860167534, 125338.9934704163], 
processed observation next is [1.0, 0.9130434782608695, 0.3901234567901234, 0.7066666666666667, 1.0, 1.0, 0.2569739747089087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1675169592916978, 0.16751695929169766, 0.24103652590464675], 
reward next is 0.7590, 
noisyNet noise sample is [array([1.1939746], dtype=float32), 0.28747934]. 
=============================================
[2019-03-24 01:07:20,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2323769e-16 1.0000000e+00 2.4941222e-22 7.5654446e-13 1.3187383e-24], sum to 1.0000
[2019-03-24 01:07:20,158] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2870
[2019-03-24 01:07:20,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 70.0, 1.0, 2.0, 0.3428224228008647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434800.6448680773, 434800.6448680773, 121015.1443465122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7786800.0000, 
sim time next is 7787400.0000, 
raw observation next is [21.25, 69.5, 1.0, 2.0, 0.3971308849451556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503782.1853691591, 503782.1853691591, 128401.9333725019], 
processed observation next is [1.0, 0.13043478260869565, 0.3425925925925926, 0.695, 1.0, 1.0, 0.2822986725537566, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17992220906041395, 0.17992220906041395, 0.24692679494711903], 
reward next is 0.7531, 
noisyNet noise sample is [array([-0.2942966], dtype=float32), 0.4707751]. 
=============================================
[2019-03-24 01:07:20,322] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9583393e-17 1.0000000e+00 7.7608142e-23 6.9120664e-13 5.5079402e-25], sum to 1.0000
[2019-03-24 01:07:20,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2185
[2019-03-24 01:07:20,335] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 61.5, 1.0, 2.0, 0.320832217644189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407902.0004886099, 407902.0004886099, 118181.4393829911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7795800.0000, 
sim time next is 7796400.0000, 
raw observation next is [22.5, 60.66666666666666, 1.0, 2.0, 0.3217241037067766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 408789.4560981231, 408789.4560981226, 118293.4019961991], 
processed observation next is [1.0, 0.21739130434782608, 0.3888888888888889, 0.6066666666666666, 1.0, 1.0, 0.1925286948890198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14599623432075826, 0.14599623432075806, 0.22748731153115212], 
reward next is 0.7725, 
noisyNet noise sample is [array([-0.29407972], dtype=float32), 0.10489028]. 
=============================================
[2019-03-24 01:07:24,403] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.877375e-19 1.000000e+00 5.064942e-27 3.664468e-15 1.854938e-30], sum to 1.0000
[2019-03-24 01:07:24,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-24 01:07:24,420] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 73.83333333333333, 1.0, 2.0, 0.3887099986312569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484560.4938643465, 484560.493864346, 127101.4624891581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890600.0000, 
sim time next is 7891200.0000, 
raw observation next is [22.3, 73.0, 1.0, 2.0, 0.3909878153811938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487350.0498356816, 487350.0498356816, 127417.6485808743], 
processed observation next is [1.0, 0.34782608695652173, 0.38148148148148153, 0.73, 1.0, 1.0, 0.27498549450142123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17405358922702915, 0.17405358922702915, 0.24503393957860442], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.73640096], dtype=float32), -0.65559196]. 
=============================================
[2019-03-24 01:07:27,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:27,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:27,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-24 01:07:27,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:27,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:27,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-24 01:07:28,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,076] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-24 01:07:28,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-24 01:07:28,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-24 01:07:28,369] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-24 01:07:28,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-24 01:07:28,912] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,912] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-24 01:07:28,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-24 01:07:28,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:28,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:28,969] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-24 01:07:29,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-24 01:07:29,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-24 01:07:29,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-24 01:07:29,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-24 01:07:29,285] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,285] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-24 01:07:29,457] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:07:29,457] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:29,458] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-24 01:07:31,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3864711e-19 1.0000000e+00 1.6156602e-23 2.3469800e-13 2.7082566e-27], sum to 1.0000
[2019-03-24 01:07:31,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3354
[2019-03-24 01:07:31,036] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 76.0, 1.0, 2.0, 0.2809553294433497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 362417.6367861002, 362417.6367861002, 109942.3556714755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 10800.0000, 
sim time next is 11400.0000, 
raw observation next is [18.26666666666667, 76.0, 1.0, 2.0, 0.3297031688773617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425317.2298047053, 425317.2298047053, 116086.5721881591], 
processed observation next is [1.0, 0.13043478260869565, 0.23209876543209887, 0.76, 1.0, 1.0, 0.20202758199685913, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15189901064453762, 0.15189901064453762, 0.22324340805415213], 
reward next is 0.7768, 
noisyNet noise sample is [array([0.84151685], dtype=float32), 0.76615673]. 
=============================================
[2019-03-24 01:07:31,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6240693e-21 1.0000000e+00 1.2193717e-26 9.6632094e-15 1.1692611e-30], sum to 1.0000
[2019-03-24 01:07:31,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4529
[2019-03-24 01:07:31,450] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 51.0, 1.0, 2.0, 0.2782287702170556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358899.6954481937, 358899.6954481937, 110190.3335170448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27600.0000, 
sim time next is 28200.0000, 
raw observation next is [22.46666666666667, 49.5, 1.0, 2.0, 0.275674296765582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 355603.8023152149, 355603.8023152149, 110489.21991733], 
processed observation next is [1.0, 0.30434782608695654, 0.3876543209876544, 0.495, 1.0, 1.0, 0.13770749614950242, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1270013579697196, 0.1270013579697196, 0.21247926907178846], 
reward next is 0.7875, 
noisyNet noise sample is [array([0.45692736], dtype=float32), 1.1621577]. 
=============================================
[2019-03-24 01:07:32,052] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 01:07:32,054] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:07:32,055] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:07:32,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:32,056] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:32,059] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:07:32,060] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:32,061] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:07:32,063] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:32,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:07:32,069] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:32,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-24 01:07:32,097] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-24 01:07:32,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-24 01:07:32,121] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-24 01:07:32,122] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-24 01:08:02,569] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:08:02,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.7, 95.66666666666667, 1.0, 2.0, 0.5355844393508734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632312.6618941576, 632312.6618941572, 148346.0603482004]
[2019-03-24 01:08:02,573] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:08:02,577] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3254183e-20 1.0000000e+00 2.1524082e-28 1.2172089e-14 3.4307929e-31], sampled 0.09790248336472196
[2019-03-24 01:08:14,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:08:14,288] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.98163777, 75.09088721, 1.0, 2.0, 0.5457303185585719, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8688204403409105, 6.9112, 6.9112, 121.9258464949667, 1244318.618334362, 1244318.618334362, 273338.69779314]
[2019-03-24 01:08:14,290] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:08:14,293] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2743586e-23 1.0000000e+00 1.2144434e-31 2.9177913e-16 9.1458833e-35], sampled 0.242617610071591
[2019-03-24 01:08:56,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:08:56,705] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.13333333333333, 86.33333333333334, 1.0, 2.0, 0.4937418765900969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591291.9303601391, 591291.9303601386, 142002.4580575171]
[2019-03-24 01:08:56,707] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:08:56,710] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.1645595e-21 1.0000000e+00 5.7598107e-29 6.2823117e-15 8.0537873e-32], sampled 0.7667641300299151
[2019-03-24 01:08:59,562] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:08:59,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.33333333333334, 55.5, 1.0, 2.0, 0.4334784570936817, 1.0, 2.0, 0.4334784570936817, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 988208.3090289382, 988208.3090289382, 215577.1170086412]
[2019-03-24 01:08:59,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:08:59,566] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2980678e-23 1.0000000e+00 1.4913426e-31 3.2154530e-16 1.1510433e-34], sampled 0.8844090475064942
[2019-03-24 01:08:59,903] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:08:59,904] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.664396255, 42.512537305, 1.0, 2.0, 0.9912089475322344, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.48097462032195, 6.9112, 121.9240185878995, 1494232.979704205, 1202462.291828209, 242119.6376607601]
[2019-03-24 01:08:59,905] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:08:59,910] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1731446e-21 1.0000000e+00 7.3270809e-30 2.2749901e-15 8.2710773e-33], sampled 0.7367632943471025
[2019-03-24 01:08:59,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1494232.979704205 W.
[2019-03-24 01:09:17,619] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.38697723]
[2019-03-24 01:09:17,621] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.00253056333333, 51.50576060499999, 1.0, 2.0, 0.5408205825104555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 664236.3140238004, 664236.3140238, 150073.9480930477]
[2019-03-24 01:09:17,622] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:09:17,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7607537e-21 1.0000000e+00 2.4019991e-29 4.0707518e-15 3.0732186e-32], sampled 0.893635903191654
[2019-03-24 01:09:19,737] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:09:20,032] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:09:20,136] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:09:20,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:09:20,167] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:09:21,183] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 425000, evaluation results [425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:09:28,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0230124e-21 1.0000000e+00 5.3658033e-30 6.0238972e-15 1.9986594e-33], sum to 1.0000
[2019-03-24 01:09:28,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-24 01:09:28,368] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 14.5, 1.0, 2.0, 0.3235100725565564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417325.9590405229, 417325.9590405229, 98182.76276014521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 177000.0000, 
sim time next is 177600.0000, 
raw observation next is [27.4, 15.0, 1.0, 2.0, 0.32188791530345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415232.8198535319, 415232.8198535324, 97813.45741621965], 
processed observation next is [0.0, 0.043478260869565216, 0.5703703703703703, 0.15, 1.0, 1.0, 0.19272370869458336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14829743566197567, 0.14829743566197587, 0.18810280272349933], 
reward next is 0.8119, 
noisyNet noise sample is [array([-0.9411842], dtype=float32), -0.89649934]. 
=============================================
[2019-03-24 01:09:32,251] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1350578e-20 1.0000000e+00 6.9660824e-27 7.5917056e-14 3.1409790e-31], sum to 1.0000
[2019-03-24 01:09:32,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4364
[2019-03-24 01:09:32,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 37.0, 1.0, 2.0, 0.3127599866469592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402092.699505245, 402092.699505245, 117162.8882401845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 252000.0000, 
sim time next is 252600.0000, 
raw observation next is [25.36666666666667, 38.16666666666667, 1.0, 2.0, 0.3091859978633472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397677.9359154766, 397677.9359154766, 116713.2116388459], 
processed observation next is [0.0, 0.9565217391304348, 0.49506172839506185, 0.3816666666666667, 1.0, 1.0, 0.17760237840874668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14202783425552734, 0.14202783425552734, 0.2244484839208575], 
reward next is 0.7756, 
noisyNet noise sample is [array([-1.577678], dtype=float32), -0.5240161]. 
=============================================
[2019-03-24 01:09:38,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8812265e-12 1.0000000e+00 2.2560429e-18 3.3654421e-09 3.5017213e-21], sum to 1.0000
[2019-03-24 01:09:38,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1070
[2019-03-24 01:09:38,928] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 30.5, 1.0, 2.0, 0.825086479965565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154913, 1055009.078818609, 1055009.078818609, 205060.5286455875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 383400.0000, 
sim time next is 384000.0000, 
raw observation next is [28.13333333333333, 30.0, 1.0, 2.0, 0.8317433585152408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1063225.56967228, 1063225.56967228, 206510.1691732751], 
processed observation next is [1.0, 0.43478260869565216, 0.5975308641975308, 0.3, 1.0, 1.0, 0.7996944744229058, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3797234177401, 0.3797234177401, 0.3971349407178367], 
reward next is 0.6029, 
noisyNet noise sample is [array([0.51962936], dtype=float32), 0.2987546]. 
=============================================
[2019-03-24 01:09:38,940] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[49.46283 ]
 [49.122253]
 [48.719673]
 [48.258995]
 [48.249065]], R is [[49.75272369]
 [49.86084747]
 [49.96868515]
 [50.0566597 ]
 [49.55609512]].
[2019-03-24 01:09:41,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9953259e-15 1.0000000e+00 3.6718309e-21 5.2515503e-08 1.3404254e-24], sum to 1.0000
[2019-03-24 01:09:41,453] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5704
[2019-03-24 01:09:41,460] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 38.0, 1.0, 2.0, 0.3136754477819499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400519.385772969, 400519.385772969, 117282.5242185253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424800.0000, 
sim time next is 425400.0000, 
raw observation next is [26.25, 38.33333333333334, 1.0, 2.0, 0.311753491638161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398265.748650837, 398265.748650837, 117041.0589012262], 
processed observation next is [1.0, 0.9565217391304348, 0.5277777777777778, 0.3833333333333334, 1.0, 1.0, 0.18065891861685834, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14223776737529892, 0.14223776737529892, 0.22507895942543502], 
reward next is 0.7749, 
noisyNet noise sample is [array([0.22993685], dtype=float32), 1.0866241]. 
=============================================
[2019-03-24 01:09:44,491] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2116522e-14 1.0000000e+00 1.0421032e-22 4.6288004e-10 1.9225271e-23], sum to 1.0000
[2019-03-24 01:09:44,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1004
[2019-03-24 01:09:44,503] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 65.16666666666667, 1.0, 2.0, 0.4141352823241541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525956.2625765825, 525956.2625765825, 130827.4496827826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 544200.0000, 
sim time next is 544800.0000, 
raw observation next is [22.0, 64.33333333333334, 1.0, 2.0, 0.4715555234869563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598341.9757254666, 598341.9757254666, 139379.5471130596], 
processed observation next is [1.0, 0.30434782608695654, 0.37037037037037035, 0.6433333333333334, 1.0, 1.0, 0.370899432722567, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21369356275909523, 0.21369356275909523, 0.2680375906020377], 
reward next is 0.7320, 
noisyNet noise sample is [array([1.0480403], dtype=float32), 1.1617765]. 
=============================================
[2019-03-24 01:09:45,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6106655e-13 1.0000000e+00 5.4601344e-19 9.2826120e-09 1.0273646e-22], sum to 1.0000
[2019-03-24 01:09:45,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8787
[2019-03-24 01:09:45,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1511467.765037671 W.
[2019-03-24 01:09:45,027] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.63333333333333, 22.66666666666666, 1.0, 2.0, 0.9652316665801289, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.505679110203243, 6.9112, 121.9235736762393, 1511467.765037671, 1207047.4911519, 236905.3837031542], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 492000.0000, 
sim time next is 492600.0000, 
raw observation next is [32.66666666666667, 22.33333333333334, 1.0, 2.0, 0.5478138387712224, 1.0, 1.0, 0.5478138387712224, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9256846303119, 1356583.894756408, 1356583.894756408, 254659.0734657969], 
processed observation next is [1.0, 0.6956521739130435, 0.7654320987654323, 0.22333333333333338, 1.0, 1.0, 0.4616831413943123, 1.0, 0.5, 0.4616831413943123, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094597521696911, 0.48449424812728853, 0.48449424812728853, 0.48972898743422477], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16392662], dtype=float32), -0.31369984]. 
=============================================
[2019-03-24 01:09:45,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.02056845e-13 9.99999762e-01 2.51632664e-18 2.08080479e-07
 8.53097700e-21], sum to 1.0000
[2019-03-24 01:09:45,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2557
[2019-03-24 01:09:45,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1460381.240039242 W.
[2019-03-24 01:09:45,092] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.25, 25.66666666666667, 1.0, 2.0, 0.5948073893094359, 1.0, 1.0, 0.5948073893094359, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9255380508971, 1460381.240039242, 1460381.240039242, 270428.5364408102], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 486600.0000, 
sim time next is 487200.0000, 
raw observation next is [32.3, 25.33333333333334, 1.0, 2.0, 0.3819476613859741, 1.0, 2.0, 0.3819476613859741, 1.0, 1.0, 0.6217206846905641, 6.9112, 6.9112, 121.94756008, 1392497.24755606, 1392497.24755606, 288319.4870026083], 
processed observation next is [1.0, 0.6521739130434783, 0.7518518518518518, 0.2533333333333334, 1.0, 1.0, 0.2642234064118739, 1.0, 1.0, 0.2642234064118739, 1.0, 0.5, 0.5271508558632051, 0.0, 0.0, 0.8096049824067558, 0.49732044555573574, 0.49732044555573574, 0.5544605519280928], 
reward next is 0.4455, 
noisyNet noise sample is [array([-0.5424109], dtype=float32), 0.6251647]. 
=============================================
[2019-03-24 01:09:49,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3229625e-13 9.9999774e-01 2.5028482e-21 2.2572010e-06 3.1488924e-22], sum to 1.0000
[2019-03-24 01:09:49,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3081
[2019-03-24 01:09:49,857] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1406779.39273244 W.
[2019-03-24 01:09:49,866] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.8, 34.33333333333334, 1.0, 2.0, 0.5787773598723333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9421312862019994, 6.9112, 6.9112, 121.9260426156618, 1406779.39273244, 1406779.39273244, 283019.6304982266], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 570000.0000, 
sim time next is 570600.0000, 
raw observation next is [30.9, 34.0, 1.0, 2.0, 0.57347748299923, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9340697444063188, 6.911199999999999, 6.9112, 121.9260426156618, 1394989.936055134, 1394989.936055134, 280964.434841393], 
processed observation next is [1.0, 0.6086956521739131, 0.7, 0.34, 1.0, 1.0, 0.49223509880860705, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9175871805078986, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4982106914482622, 0.4982106914482622, 0.5403162208488328], 
reward next is 0.4597, 
noisyNet noise sample is [array([-0.5111767], dtype=float32), 0.7191247]. 
=============================================
[2019-03-24 01:10:07,677] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1034552e-14 1.0000000e+00 1.1380270e-21 6.0568892e-09 1.8423347e-24], sum to 1.0000
[2019-03-24 01:10:07,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-24 01:10:07,689] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.28333333333333, 53.33333333333334, 1.0, 2.0, 0.6968560615823723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 870666.5200076648, 870666.5200076643, 178431.6215826817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996600.0000, 
sim time next is 997200.0000, 
raw observation next is [25.3, 53.0, 1.0, 2.0, 0.7480375515767496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 935030.0220709128, 935030.0220709128, 188599.0079201573], 
processed observation next is [1.0, 0.5652173913043478, 0.49259259259259264, 0.53, 1.0, 1.0, 0.7000447042580352, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33393929359675456, 0.33393929359675456, 0.36269039984645635], 
reward next is 0.6373, 
noisyNet noise sample is [array([0.5574659], dtype=float32), 1.1988829]. 
=============================================
[2019-03-24 01:10:09,756] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 01:10:09,757] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:10:09,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:09,760] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:10:09,762] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:10:09,762] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:09,763] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:10:09,763] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:09,764] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:10:09,767] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:09,768] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:09,781] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-24 01:10:09,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-24 01:10:09,804] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-24 01:10:09,826] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-24 01:10:09,883] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-24 01:10:19,427] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:10:19,429] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.895164115, 52.43681611, 1.0, 2.0, 0.5355470651288421, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9139774641316091, 6.9112, 6.9112, 121.9478118541735, 1352825.433233178, 1352825.433233178, 263208.3673414957]
[2019-03-24 01:10:19,431] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:10:19,433] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5771566e-15 1.0000000e+00 3.5097838e-22 2.6783222e-09 1.2971100e-24], sampled 0.9192343553241361
[2019-03-24 01:10:19,435] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1352825.433233178 W.
[2019-03-24 01:10:21,944] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:10:21,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 23.33333333333333, 1.0, 2.0, 0.3249288922096535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419156.727671279, 419156.727671279, 118093.5151044914]
[2019-03-24 01:10:21,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:10:21,951] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9822584e-17 1.0000000e+00 1.0835155e-24 2.7095615e-10 2.0943596e-27], sampled 0.4988384285797477
[2019-03-24 01:10:41,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:10:41,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.815068295, 105.8416244, 1.0, 2.0, 0.5257970778275946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626560.416543862, 626560.416543862, 146986.3141447436]
[2019-03-24 01:10:41,765] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:10:41,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.711374e-16 1.000000e+00 6.037906e-23 1.333268e-09 1.831801e-25], sampled 0.24184757462815942
[2019-03-24 01:10:48,268] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:10:48,271] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.75, 85.5, 1.0, 2.0, 0.590203106112348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685855.1116733907, 685855.1116733907, 157030.9943384645]
[2019-03-24 01:10:48,272] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:10:48,275] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.8788930e-17 1.0000000e+00 6.2022272e-24 5.4103366e-10 1.4578723e-26], sampled 0.9955670197804171
[2019-03-24 01:10:54,770] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:10:54,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.69657626, 91.38109576, 1.0, 2.0, 0.5436482885609659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637703.6400553636, 637703.6400553636, 149495.3071404813]
[2019-03-24 01:10:54,772] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:10:54,775] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.2355103e-16 1.0000000e+00 2.0380431e-23 8.6694552e-10 5.4743175e-26], sampled 0.6127451198355033
[2019-03-24 01:11:01,139] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:11:01,140] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 92.33333333333334, 1.0, 2.0, 0.5899079852292333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683555.668662965, 683555.668662965, 156891.4739972191]
[2019-03-24 01:11:01,141] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:11:01,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3212613e-16 1.0000000e+00 9.4733344e-24 6.3993966e-10 2.3351186e-26], sampled 0.15723750852037022
[2019-03-24 01:11:14,094] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:11:14,096] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.6755061229902269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769871.8672639655, 769871.8672639655, 171557.1365517173]
[2019-03-24 01:11:14,099] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:11:14,101] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3760420e-16 1.0000000e+00 2.2273308e-23 8.9802266e-10 6.0424360e-26], sampled 0.4574441012587428
[2019-03-24 01:11:29,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.3988817]
[2019-03-24 01:11:29,483] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333334, 80.5, 1.0, 2.0, 0.6958916192196674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811982.5765840405, 811982.5765840405, 176282.8735078909]
[2019-03-24 01:11:29,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:11:29,487] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7666012e-16 1.0000000e+00 2.7802604e-23 9.8048358e-10 7.7324633e-26], sampled 0.4306597970517191
[2019-03-24 01:11:57,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:11:57,744] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:11:57,799] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:11:57,932] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:11:57,978] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:11:58,996] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 450000, evaluation results [450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:12:14,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8135538e-16 1.0000000e+00 1.1129237e-23 2.6827611e-12 1.3248942e-25], sum to 1.0000
[2019-03-24 01:12:14,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9428
[2019-03-24 01:12:14,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1339309.53854049 W.
[2019-03-24 01:12:14,831] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.25, 55.5, 1.0, 2.0, 0.5549464043614509, 1.0, 1.0, 0.5549464043614509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9256942503898, 1339309.53854049, 1339309.53854049, 256029.9685810816], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1265400.0000, 
sim time next is 1266000.0000, 
raw observation next is [26.26666666666667, 55.33333333333333, 1.0, 2.0, 0.3571964181387655, 1.0, 2.0, 0.3571964181387655, 1.0, 1.0, 0.5751839130860373, 6.911199999999999, 6.9112, 121.94756008, 1279620.584753186, 1279620.584753187, 278481.130170571], 
processed observation next is [1.0, 0.6521739130434783, 0.5283950617283951, 0.5533333333333332, 1.0, 1.0, 0.23475764064138752, 1.0, 1.0, 0.23475764064138752, 1.0, 0.5, 0.46897989135754664, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4570073516975664, 0.45700735169756673, 0.5355406349434058], 
reward next is 0.4645, 
noisyNet noise sample is [array([0.5384553], dtype=float32), 0.1045188]. 
=============================================
[2019-03-24 01:12:14,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.34176 ]
 [58.040386]
 [57.867325]
 [57.45154 ]
 [57.575623]], R is [[58.33322525]
 [57.74989319]
 [57.1723938 ]
 [57.12826538]
 [57.07444382]].
[2019-03-24 01:12:17,245] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0760756e-20 1.0000000e+00 1.8101403e-27 1.1550879e-15 2.8348034e-31], sum to 1.0000
[2019-03-24 01:12:17,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7491
[2019-03-24 01:12:17,254] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 86.0, 1.0, 2.0, 0.3633694465966808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455571.8980364757, 455571.8980364757, 123681.8531703116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1298400.0000, 
sim time next is 1299000.0000, 
raw observation next is [19.98333333333333, 86.0, 1.0, 2.0, 0.3614184378642232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453589.4943546316, 453589.4943546316, 123426.8805597462], 
processed observation next is [1.0, 0.0, 0.2956790123456789, 0.86, 1.0, 1.0, 0.2397838546002657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.161996247983797, 0.161996247983797, 0.23735938569181964], 
reward next is 0.7626, 
noisyNet noise sample is [array([0.04475166], dtype=float32), 0.68338794]. 
=============================================
[2019-03-24 01:12:17,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.26392]
 [70.28962]
 [70.2702 ]
 [70.23693]
 [70.41061]], R is [[70.18414307]
 [70.24445343]
 [70.30382538]
 [70.36211395]
 [70.41895294]].
[2019-03-24 01:12:20,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2065309e-20 1.0000000e+00 9.2422904e-29 2.0688109e-16 5.4792372e-30], sum to 1.0000
[2019-03-24 01:12:20,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8951
[2019-03-24 01:12:20,459] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 67.0, 1.0, 2.0, 0.3206613036968219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 407230.302336377, 407230.3023363766, 118156.5028984461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1386600.0000, 
sim time next is 1387200.0000, 
raw observation next is [21.43333333333334, 67.0, 1.0, 2.0, 0.3182712589061885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404527.5561542539, 404527.5561542539, 117855.2418182865], 
processed observation next is [0.0, 0.043478260869565216, 0.349382716049383, 0.67, 1.0, 1.0, 0.18841816536451014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14447412719794783, 0.14447412719794783, 0.2266446958043971], 
reward next is 0.7734, 
noisyNet noise sample is [array([0.03127086], dtype=float32), 0.9005123]. 
=============================================
[2019-03-24 01:12:25,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3949159e-19 1.0000000e+00 5.2241764e-23 5.0091923e-15 5.4388844e-28], sum to 1.0000
[2019-03-24 01:12:25,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6244
[2019-03-24 01:12:25,542] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.61666666666667, 72.5, 1.0, 2.0, 0.3566151025036465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448753.7596018103, 448753.7596018103, 122801.5739246442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1487400.0000, 
sim time next is 1488000.0000, 
raw observation next is [21.93333333333334, 71.0, 1.0, 2.0, 0.3591392910892195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451423.1299883565, 451423.129988356, 123131.8898022294], 
processed observation next is [0.0, 0.21739130434782608, 0.3679012345679015, 0.71, 1.0, 1.0, 0.2370705846300232, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16122254642441303, 0.16122254642441286, 0.2367920957735181], 
reward next is 0.7632, 
noisyNet noise sample is [array([1.0204271], dtype=float32), -0.7108788]. 
=============================================
[2019-03-24 01:12:25,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.89463 ]
 [65.02391 ]
 [65.10521 ]
 [65.193085]
 [65.29028 ]], R is [[64.89723206]
 [65.01210022]
 [65.12658691]
 [65.24073029]
 [65.35443115]].
[2019-03-24 01:12:26,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4930487e-21 1.0000000e+00 7.6408887e-34 1.3025100e-16 8.6998733e-35], sum to 1.0000
[2019-03-24 01:12:26,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-24 01:12:27,001] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.7, 29.0, 1.0, 2.0, 0.4301339109524268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525207.6928327834, 525207.6928327834, 132746.603740009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510200.0000, 
sim time next is 1510800.0000, 
raw observation next is [33.83333333333334, 28.33333333333334, 1.0, 2.0, 0.425680469210107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520381.6508326149, 520381.6508326149, 132116.5490910289], 
processed observation next is [0.0, 0.4782608695652174, 0.8086419753086423, 0.2833333333333334, 1.0, 1.0, 0.31628627286917504, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18585058958307676, 0.18585058958307676, 0.2540702867135171], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.14547251], dtype=float32), -0.6843302]. 
=============================================
[2019-03-24 01:12:27,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6563296e-23 1.0000000e+00 3.3436423e-32 3.2328177e-17 6.0936341e-35], sum to 1.0000
[2019-03-24 01:12:27,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-24 01:12:27,238] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.83333333333334, 28.33333333333334, 1.0, 2.0, 0.425680469210107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520381.6508326149, 520381.6508326149, 132116.5490910289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [33.96666666666667, 27.66666666666666, 1.0, 2.0, 0.4212594752889006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515594.0870352512, 515594.0870352517, 131494.3581827258], 
processed observation next is [0.0, 0.4782608695652174, 0.8135802469135803, 0.2766666666666666, 1.0, 1.0, 0.31102318486773883, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18414074536973257, 0.18414074536973277, 0.2528737657360111], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.07636245], dtype=float32), 0.36390173]. 
=============================================
[2019-03-24 01:12:29,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.08505392e-17 1.00000000e+00 2.33031036e-21 7.22765337e-12
 1.22649066e-26], sum to 1.0000
[2019-03-24 01:12:29,848] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8418
[2019-03-24 01:12:29,860] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 65.5, 1.0, 2.0, 0.4260652149790158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537272.7089941041, 537272.7089941036, 132518.2774377753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [22.63333333333333, 64.0, 1.0, 2.0, 0.3881047563349218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489495.7460383771, 489495.7460383771, 127108.6077645705], 
processed observation next is [1.0, 0.30434782608695654, 0.393827160493827, 0.64, 1.0, 1.0, 0.2715532813510974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1748199092994204, 0.1748199092994204, 0.24443963031648172], 
reward next is 0.7556, 
noisyNet noise sample is [array([0.8696538], dtype=float32), -0.92467636]. 
=============================================
[2019-03-24 01:12:35,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0937018e-17 1.0000000e+00 3.4817593e-26 3.6653389e-09 1.2993273e-26], sum to 1.0000
[2019-03-24 01:12:35,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3791
[2019-03-24 01:12:35,076] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.98333333333333, 82.5, 1.0, 2.0, 0.3467417275070088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442165.939018779, 442165.939018779, 121544.8955610541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656600.0000, 
sim time next is 1657200.0000, 
raw observation next is [18.76666666666667, 84.0, 1.0, 2.0, 0.3244949031253458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413928.9163509767, 413928.9163509767, 118655.1615628645], 
processed observation next is [1.0, 0.17391304347826086, 0.2506172839506174, 0.84, 1.0, 1.0, 0.19582726562541167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14783175583963454, 0.14783175583963454, 0.22818300300550864], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.40680978], dtype=float32), 1.1895981]. 
=============================================
[2019-03-24 01:12:39,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2741764e-13 9.9972337e-01 2.2447131e-20 2.7666549e-04 7.7625796e-22], sum to 1.0000
[2019-03-24 01:12:39,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6570
[2019-03-24 01:12:39,628] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 74.0, 1.0, 2.0, 0.462404737404545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572362.5602640273, 572362.5602640273, 137743.9900929949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1756800.0000, 
sim time next is 1757400.0000, 
raw observation next is [22.81666666666667, 73.66666666666667, 1.0, 2.0, 0.501472165999581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620150.0185629986, 620150.0185629986, 143802.3596487848], 
processed observation next is [1.0, 0.34782608695652173, 0.4006172839506174, 0.7366666666666667, 1.0, 1.0, 0.4065144833328345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2214821494867852, 0.2214821494867852, 0.27654299932458615], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.5945661], dtype=float32), 0.85559475]. 
=============================================
[2019-03-24 01:12:46,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3601029e-15 9.9997497e-01 6.5982693e-24 2.5050251e-05 1.7095621e-23], sum to 1.0000
[2019-03-24 01:12:46,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-24 01:12:46,192] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 86.5, 1.0, 2.0, 0.9326659768059486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.156626543208534, 6.9112, 121.9249615768642, 1267959.64820087, 1142280.436428168, 228477.5729955247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870200.0000, 
sim time next is 1870800.0000, 
raw observation next is [21.63333333333333, 86.66666666666667, 1.0, 2.0, 0.9515967732111069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.281133901943291, 6.9112, 121.9242768060582, 1354819.976214788, 1165383.497680776, 232952.77184672], 
processed observation next is [1.0, 0.6521739130434783, 0.35679012345678995, 0.8666666666666667, 1.0, 1.0, 0.9423771109656035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03699339019432912, 0.0, 0.8094504056806806, 0.4838642772195671, 0.4162083920288486, 0.44798609970523073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.51001674], dtype=float32), -0.27459463]. 
=============================================
[2019-03-24 01:12:47,623] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 01:12:47,624] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:12:47,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:47,626] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:12:47,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:12:47,628] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:12:47,628] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:47,628] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:12:47,630] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:47,629] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:47,631] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:47,646] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-24 01:12:47,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-24 01:12:47,693] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-24 01:12:47,694] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-24 01:12:47,719] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-24 01:12:49,992] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:12:49,993] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.65, 50.5, 1.0, 2.0, 0.223917383982764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 288827.825179274, 288827.825179274, 84979.42545416753]
[2019-03-24 01:12:49,995] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:12:49,996] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.1600037e-16 9.9999702e-01 6.4355139e-24 2.9843745e-06 2.6853500e-26], sampled 0.6460414324022129
[2019-03-24 01:13:21,896] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:13:21,897] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.03333333333334, 47.66666666666667, 1.0, 2.0, 0.6271677926837492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714755.1635857184, 714755.1635857184, 162813.86765957]
[2019-03-24 01:13:21,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:13:21,902] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0735554e-17 9.9999857e-01 2.8585023e-25 1.4336765e-06 8.6972367e-28], sampled 0.27588768588246115
[2019-03-24 01:13:45,398] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:13:45,399] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 75.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 20.45699398621377, 6.9112, 146.0438938758473, 11358318.69848506, 3049540.601060941, 520148.0364383837]
[2019-03-24 01:13:45,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:13:45,404] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5343025e-18 9.9999964e-01 6.5821530e-28 3.4429610e-07 1.0850836e-30], sampled 0.9941343005899126
[2019-03-24 01:13:45,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 11358318.69848506 W.
[2019-03-24 01:14:07,304] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:14:07,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.66666666666666, 38.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.602620144788737, 6.9112, 121.9233358433482, 1517117.991180379, 1163056.938988257, 245581.1060188489]
[2019-03-24 01:14:07,306] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:14:07,309] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4683942e-16 9.9999738e-01 3.9349127e-24 2.6580924e-06 1.5619657e-26], sampled 0.8450246641147408
[2019-03-24 01:14:07,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1517117.991180379 W.
[2019-03-24 01:14:22,559] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:14:22,559] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.91666666666667, 84.0, 1.0, 2.0, 0.712990972410858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812615.8597626445, 812615.8597626445, 178617.4896954319]
[2019-03-24 01:14:22,561] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:14:22,565] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.3958938e-16 9.9999666e-01 1.0343090e-23 3.3368299e-06 4.5289799e-26], sampled 0.4661932194481925
[2019-03-24 01:14:23,368] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.41099805]
[2019-03-24 01:14:23,369] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.99591311, 72.378521835, 1.0, 2.0, 0.5488961235224427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8738605049464624, 6.911199999999999, 6.9112, 121.9260426156618, 1251542.858999596, 1251542.858999597, 274504.6128534843]
[2019-03-24 01:14:23,370] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:14:23,372] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2736976e-15 9.9999607e-01 1.9597050e-23 3.8790804e-06 9.1523463e-26], sampled 0.7280853108468418
[2019-03-24 01:14:34,778] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:14:34,965] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7712 2248688554.2202 553.0000
[2019-03-24 01:14:34,990] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:14:35,019] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:14:35,157] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:14:36,174] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.771152089494, 2248688554.2202086, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:14:45,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0372076e-15 9.9999595e-01 4.6408396e-25 4.0308942e-06 2.7328308e-27], sum to 1.0000
[2019-03-24 01:14:45,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6644
[2019-03-24 01:14:45,905] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 79.33333333333333, 1.0, 2.0, 0.478826902810175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576136.8639626428, 576136.8639626424, 139786.2508609622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2072400.0000, 
sim time next is 2073000.0000, 
raw observation next is [23.7, 79.66666666666667, 1.0, 2.0, 0.4758308572736851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 573028.7340849779, 573028.7340849784, 139343.105364208], 
processed observation next is [0.0, 1.0, 0.4333333333333333, 0.7966666666666667, 1.0, 1.0, 0.37598911580200606, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20465311931606353, 0.2046531193160637, 0.2679675103157846], 
reward next is 0.7320, 
noisyNet noise sample is [array([0.23807815], dtype=float32), -0.44715303]. 
=============================================
[2019-03-24 01:14:45,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.35055 ]
 [74.388855]
 [74.42349 ]
 [74.46071 ]
 [74.5184  ]], R is [[74.30573273]
 [74.29385376]
 [74.28141785]
 [74.26831818]
 [74.25435638]].
[2019-03-24 01:14:47,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1602171e-18 1.0000000e+00 4.9705570e-28 3.0555447e-09 1.7735452e-27], sum to 1.0000
[2019-03-24 01:14:47,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0074
[2019-03-24 01:14:47,633] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 53.0, 1.0, 2.0, 0.5792285028509783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669910.774673067, 669910.774673067, 155014.1349035241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2125800.0000, 
sim time next is 2126400.0000, 
raw observation next is [30.83333333333333, 52.33333333333334, 1.0, 2.0, 0.5759607596927167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666944.4779764172, 666944.4779764172, 154499.3183581641], 
processed observation next is [0.0, 0.6086956521739131, 0.6975308641975307, 0.5233333333333334, 1.0, 1.0, 0.4951913805865674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.238194456420149, 0.238194456420149, 0.2971140737657002], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.55215997], dtype=float32), -1.3509058]. 
=============================================
[2019-03-24 01:14:51,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4754676e-11 9.9999988e-01 1.7086336e-15 1.1010413e-07 5.0233279e-17], sum to 1.0000
[2019-03-24 01:14:51,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9916
[2019-03-24 01:14:51,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5634136835033086, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8969729332399213, 6.911199999999999, 6.9112, 121.9260426156618, 1284672.231932527, 1284672.231932527, 279894.4978926795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2198400.0000, 
sim time next is 2199000.0000, 
raw observation next is [24.31666666666667, 92.66666666666666, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.411732986051758, 6.9112, 121.9239710117059, 1425224.5692557, 1168911.298272236, 245924.5916292824], 
processed observation next is [1.0, 0.43478260869565216, 0.456172839506173, 0.9266666666666665, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05005329860517582, 0.0, 0.809448375524185, 0.5090087747341786, 0.41746832081151286, 0.47293190697938925], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6972511], dtype=float32), 1.7453269]. 
=============================================
[2019-03-24 01:14:51,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[41.791035]
 [41.82697 ]
 [41.612946]
 [41.53873 ]
 [42.33488 ]], R is [[41.43463516]
 [41.02029037]
 [40.61008835]
 [40.20398712]
 [40.28059006]].
[2019-03-24 01:15:06,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6328556e-13 9.9970597e-01 3.7215534e-20 2.9395489e-04 7.0427290e-22], sum to 1.0000
[2019-03-24 01:15:06,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6525
[2019-03-24 01:15:06,409] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 53.5, 1.0, 2.0, 0.3742559402737002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467030.4670301467, 467030.4670301467, 125119.8329004066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2512200.0000, 
sim time next is 2512800.0000, 
raw observation next is [25.4, 54.0, 1.0, 2.0, 0.3740219852286415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466753.7112345413, 466753.7112345417, 125088.1926295091], 
processed observation next is [1.0, 0.08695652173913043, 0.49629629629629624, 0.54, 1.0, 1.0, 0.25478807765314465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1666977540123362, 0.16669775401233633, 0.2405542165952098], 
reward next is 0.7594, 
noisyNet noise sample is [array([0.11566774], dtype=float32), 0.47424644]. 
=============================================
[2019-03-24 01:15:11,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6456720e-16 9.9999869e-01 5.7132780e-22 1.3525670e-06 8.2752385e-24], sum to 1.0000
[2019-03-24 01:15:11,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8339
[2019-03-24 01:15:11,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 70.66666666666667, 1.0, 2.0, 0.5825132772857482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677560.9032543139, 677560.9032543139, 155746.3949956327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2652000.0000, 
sim time next is 2652600.0000, 
raw observation next is [27.0, 69.83333333333333, 1.0, 2.0, 0.5755915833288033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671320.1103972632, 671320.1103972637, 154652.7947814921], 
processed observation next is [0.0, 0.6956521739130435, 0.5555555555555556, 0.6983333333333333, 1.0, 1.0, 0.494751884915242, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23975718228473686, 0.23975718228473702, 0.2974092207336386], 
reward next is 0.7026, 
noisyNet noise sample is [array([-1.9923446], dtype=float32), -1.3046453]. 
=============================================
[2019-03-24 01:15:15,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4895747e-13 9.9999869e-01 1.3994888e-24 1.3310909e-06 4.6424437e-26], sum to 1.0000
[2019-03-24 01:15:15,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-24 01:15:15,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 99.0, 1.0, 2.0, 0.5340143153335939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631805.7616883946, 631805.7616883946, 148144.2619045123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2692200.0000, 
sim time next is 2692800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5308392581345565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628640.656417229, 628640.656417229, 147651.9438111495], 
processed observation next is [0.0, 0.17391304347826086, 0.37037037037037035, 1.0, 1.0, 1.0, 0.4414753073030434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22451452014901035, 0.22451452014901035, 0.2839460457906721], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.59944534], dtype=float32), 0.011999329]. 
=============================================
[2019-03-24 01:15:17,444] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8536538e-16 9.9999297e-01 8.1074253e-25 7.0029901e-06 5.3731732e-25], sum to 1.0000
[2019-03-24 01:15:17,452] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4684
[2019-03-24 01:15:17,458] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 91.66666666666667, 1.0, 2.0, 0.5285864532427091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625529.5899619831, 625529.5899619831, 147269.7765175283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688000.0000, 
sim time next is 2688600.0000, 
raw observation next is [23.05, 92.83333333333334, 1.0, 2.0, 0.5340881922470008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630841.836855951, 630841.836855951, 148114.5748794064], 
processed observation next is [0.0, 0.08695652173913043, 0.40925925925925927, 0.9283333333333335, 1.0, 1.0, 0.4453430860083342, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2253006560199825, 0.2253006560199825, 0.2848357209219354], 
reward next is 0.7152, 
noisyNet noise sample is [array([-2.0112042], dtype=float32), -1.348446]. 
=============================================
[2019-03-24 01:15:24,510] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 01:15:24,512] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:15:24,514] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:15:24,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:24,515] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:24,515] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:15:24,516] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:15:24,517] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:24,517] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:24,515] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:15:24,518] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:24,522] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-24 01:15:24,522] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-24 01:15:24,568] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-24 01:15:24,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-24 01:15:24,625] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-24 01:15:55,885] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4189928]
[2019-03-24 01:15:55,889] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.16666666666666, 37.5, 1.0, 2.0, 0.4281650438155244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521918.2689909324, 521918.2689909319, 132434.3479819603]
[2019-03-24 01:15:55,891] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:15:55,894] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7415595e-17 1.0000000e+00 1.5430129e-26 1.7213331e-10 1.2492404e-27], sampled 0.21296734387681282
[2019-03-24 01:16:00,465] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4189928]
[2019-03-24 01:16:00,466] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.53333333333333, 46.0, 1.0, 2.0, 0.8390840575980861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1671550.854855973, 1671550.854855974, 344126.7956786714]
[2019-03-24 01:16:00,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:16:00,470] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2731897e-12 1.0000000e+00 9.2330294e-20 5.9578955e-08 1.4303281e-20], sampled 0.08905795593709132
[2019-03-24 01:16:00,470] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1671550.854855973 W.
[2019-03-24 01:16:37,313] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4189928]
[2019-03-24 01:16:37,314] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666667, 61.33333333333334, 1.0, 2.0, 0.516875979753546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612777.458854131, 612777.458854131, 145430.9459966501]
[2019-03-24 01:16:37,317] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:16:37,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3342987e-16 1.0000000e+00 3.7019048e-26 2.3893512e-10 3.1079702e-27], sampled 0.8367145091802168
[2019-03-24 01:16:38,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4189928]
[2019-03-24 01:16:38,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.6, 88.0, 1.0, 2.0, 0.7140854653223083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813863.9463922792, 813863.9463922792, 178828.5491492015]
[2019-03-24 01:16:38,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:16:38,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5827255e-15 1.0000000e+00 1.9724165e-24 1.0599230e-09 1.9540896e-25], sampled 0.9719489319267932
[2019-03-24 01:16:58,001] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4189928]
[2019-03-24 01:16:58,003] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.89719116, 59.96002366, 1.0, 2.0, 0.2742779127365485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 348410.2476488553, 348410.2476488549, 112449.1135735637]
[2019-03-24 01:16:58,003] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:16:58,006] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.48503188e-16 1.00000000e+00 1.00582157e-25 3.47466278e-10
 8.80420693e-27], sampled 0.7910736904729229
[2019-03-24 01:17:14,906] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:17:14,979] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:17:15,245] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:17:15,254] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:17:15,288] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:17:16,301] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 500000, evaluation results [500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:17:28,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0788923e-16 1.0000000e+00 1.7363540e-24 1.3178594e-11 2.5937981e-26], sum to 1.0000
[2019-03-24 01:17:28,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7965
[2019-03-24 01:17:28,989] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 57.16666666666667, 1.0, 2.0, 0.6238361973363974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752170.240793109, 752170.240793109, 163996.7169246564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3136200.0000, 
sim time next is 3136800.0000, 
raw observation next is [27.93333333333334, 56.33333333333334, 1.0, 2.0, 0.7014058117158612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841758.430332202, 841758.430332202, 178306.5183256296], 
processed observation next is [1.0, 0.30434782608695654, 0.5901234567901237, 0.5633333333333335, 1.0, 1.0, 0.6445307282331681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3006280108329293, 0.3006280108329293, 0.34289715062621073], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.2784709], dtype=float32), -0.33440018]. 
=============================================
[2019-03-24 01:17:31,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0146324e-15 1.0000000e+00 1.4422873e-22 4.8261761e-08 1.1001802e-23], sum to 1.0000
[2019-03-24 01:17:31,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7264
[2019-03-24 01:17:31,374] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 49.33333333333334, 1.0, 2.0, 0.4526217666113923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550812.7630090285, 550812.7630090285, 136014.7007601045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3116400.0000, 
sim time next is 3117000.0000, 
raw observation next is [28.33333333333334, 47.16666666666666, 1.0, 2.0, 0.4371854902916439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534959.9507497991, 534959.9507497987, 133810.7054013289], 
processed observation next is [1.0, 0.043478260869565216, 0.6049382716049385, 0.47166666666666657, 1.0, 1.0, 0.32998272653767124, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1910571252677854, 0.19105712526778523, 0.2573282796179402], 
reward next is 0.7427, 
noisyNet noise sample is [array([1.1638215], dtype=float32), -0.55779225]. 
=============================================
[2019-03-24 01:17:31,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.631798]
 [59.742443]
 [59.821846]
 [59.9263  ]
 [60.153214]], R is [[59.47182846]
 [59.61554337]
 [59.753479  ]
 [59.88589096]
 [60.01325607]].
[2019-03-24 01:17:38,584] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8975831e-19 1.0000000e+00 5.2295212e-30 9.6685888e-12 1.1027713e-33], sum to 1.0000
[2019-03-24 01:17:38,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8083
[2019-03-24 01:17:38,597] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 95.33333333333334, 1.0, 2.0, 0.4892970731677373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588348.2121808582, 588348.2121808582, 141393.2011902075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3302400.0000, 
sim time next is 3303000.0000, 
raw observation next is [21.85, 96.5, 1.0, 2.0, 0.4968673966927494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595430.429264803, 595430.429264803, 142505.7491053981], 
processed observation next is [0.0, 0.21739130434782608, 0.36481481481481487, 0.965, 1.0, 1.0, 0.4010326151104159, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21265372473742963, 0.21265372473742963, 0.274049517510381], 
reward next is 0.7260, 
noisyNet noise sample is [array([0.32208458], dtype=float32), -0.48226905]. 
=============================================
[2019-03-24 01:17:38,641] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.93293 ]
 [76.98883 ]
 [77.06144 ]
 [77.03794 ]
 [77.014725]], R is [[76.84496307]
 [76.80460358]
 [76.7666626 ]
 [76.73033142]
 [76.69342804]].
[2019-03-24 01:17:43,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0314837e-16 1.0000000e+00 1.7927211e-26 2.2311095e-09 7.4496627e-27], sum to 1.0000
[2019-03-24 01:17:43,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3604
[2019-03-24 01:17:43,274] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 83.16666666666666, 1.0, 2.0, 0.6928554004809137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789654.9607325121, 789654.9607325121, 174795.6478156993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3358200.0000, 
sim time next is 3358800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6979569764497696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795472.3003719143, 795472.3003719138, 175757.9735903208], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6404249719640114, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28409725013282655, 0.2840972501328264, 0.33799610305830924], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.09916023], dtype=float32), -0.33345187]. 
=============================================
[2019-03-24 01:17:44,432] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7517106e-10 9.9999726e-01 8.8775211e-15 2.6868306e-06 3.6191952e-16], sum to 1.0000
[2019-03-24 01:17:44,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-24 01:17:44,450] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.860166784669735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984644.4854469792, 984644.4854469792, 208906.5570230112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3399000.0000, 
sim time next is 3399600.0000, 
raw observation next is [26.2, 81.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.158518105453687, 6.9112, 121.9171819196473, 2316454.662203919, 1165710.562969478, 245705.4606181436], 
processed observation next is [1.0, 0.34782608695652173, 0.5259259259259259, 0.8166666666666668, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.22473181054536875, 0.0, 0.8094033030130741, 0.8273052365013996, 0.4163252010605279, 0.4725105011887377], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40305054], dtype=float32), 0.23655125]. 
=============================================
[2019-03-24 01:17:48,156] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0854258e-13 1.0000000e+00 7.8508106e-20 4.9524850e-08 1.4419634e-21], sum to 1.0000
[2019-03-24 01:17:48,162] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4680
[2019-03-24 01:17:48,166] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 93.0, 1.0, 2.0, 0.6530873355043881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 744308.8517556136, 744308.8517556131, 167450.8929907721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [24.75, 92.5, 1.0, 2.0, 0.6448359529837285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734900.4300069927, 734900.4300069927, 165961.2960603199], 
processed observation next is [1.0, 0.043478260869565216, 0.4722222222222222, 0.925, 1.0, 1.0, 0.5771856583139625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26246443928821167, 0.26246443928821167, 0.3191563385775383], 
reward next is 0.6808, 
noisyNet noise sample is [array([-0.1930651], dtype=float32), 1.1300256]. 
=============================================
[2019-03-24 01:17:56,554] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9841104e-15 9.9899000e-01 2.6256370e-25 1.0100511e-03 3.9950990e-28], sum to 1.0000
[2019-03-24 01:17:56,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7807
[2019-03-24 01:17:56,561] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 81.66666666666667, 1.0, 2.0, 0.5246369835500817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620811.9951095437, 620811.9951095437, 146630.6733424421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615600.0000, 
sim time next is 3616200.0000, 
raw observation next is [24.35, 83.5, 1.0, 2.0, 0.5283848439583234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 623569.5899793094, 623569.5899793089, 147168.5574954386], 
processed observation next is [1.0, 0.8695652173913043, 0.4574074074074075, 0.835, 1.0, 1.0, 0.4385533856646707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22270342499261048, 0.2227034249926103, 0.2830164567219973], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.6679836], dtype=float32), 1.8810432]. 
=============================================
[2019-03-24 01:17:56,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3590079e-12 9.9744761e-01 3.0058296e-19 2.5524623e-03 3.0489364e-21], sum to 1.0000
[2019-03-24 01:17:56,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0387
[2019-03-24 01:17:56,992] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 81.66666666666667, 1.0, 2.0, 0.5246369835495015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620811.9951095437, 620811.9951095437, 146630.6733423758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615600.0000, 
sim time next is 3616200.0000, 
raw observation next is [24.35, 83.5, 1.0, 2.0, 0.5283848439581853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 623569.5899793094, 623569.5899793089, 147168.5574954229], 
processed observation next is [1.0, 0.8695652173913043, 0.4574074074074075, 0.835, 1.0, 1.0, 0.4385533856645063, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22270342499261048, 0.2227034249926103, 0.2830164567219671], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.75932664], dtype=float32), 0.66704315]. 
=============================================
[2019-03-24 01:18:04,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.0275589e-14 1.0000000e+00 1.2529669e-21 5.0214929e-08 1.3635061e-21], sum to 1.0000
[2019-03-24 01:18:04,334] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7801
[2019-03-24 01:18:04,341] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 99.00000000000001, 1.0, 2.0, 0.7451789994152415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849321.7853846975, 849321.7853846975, 184869.1291250879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3741000.0000, 
sim time next is 3741600.0000, 
raw observation next is [24.46666666666667, 98.0, 1.0, 2.0, 0.7228655253780567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 823876.2141232145, 823876.214123214, 180514.6112697776], 
processed observation next is [1.0, 0.30434782608695654, 0.46172839506172847, 0.98, 1.0, 1.0, 0.6700780064024484, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29424150504400515, 0.294241505044005, 0.34714348321111077], 
reward next is 0.6529, 
noisyNet noise sample is [array([0.7950008], dtype=float32), -1.3013684]. 
=============================================
[2019-03-24 01:18:05,197] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 01:18:05,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:18:05,199] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:05,199] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:18:05,199] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:05,200] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:18:05,201] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:05,201] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:18:05,202] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:18:05,204] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:05,206] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:05,221] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-24 01:18:05,221] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-24 01:18:05,263] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-24 01:18:05,286] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-24 01:18:05,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-24 01:18:07,416] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:18:07,417] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.26447418, 87.18502909, 1.0, 2.0, 0.4715345375199962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570046.5171227485, 570046.5171227485, 138757.737086441]
[2019-03-24 01:18:07,418] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:18:07,422] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0316586e-19 1.0000000e+00 1.4237550e-31 2.1965873e-12 1.3823155e-32], sampled 0.5855359817570915
[2019-03-24 01:18:30,066] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:18:30,066] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.4995826808136949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616592.5863857033, 616592.5863857033, 143473.1180567852]
[2019-03-24 01:18:30,067] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:18:30,070] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4107244e-19 1.0000000e+00 2.1153694e-30 6.0706197e-12 2.2395048e-31], sampled 0.753478502174885
[2019-03-24 01:18:39,380] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:18:39,381] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.08333333333333, 33.33333333333334, 1.0, 2.0, 0.6044195052464849, 0.0, 2.0, 0.0, 1.0, 2.0, 0.956937749747629, 6.9112, 6.9112, 121.9260426156618, 1449758.126584265, 1449758.126584265, 289110.853732059]
[2019-03-24 01:18:39,383] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:18:39,388] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9749017e-16 1.0000000e+00 3.1443198e-26 2.2637721e-10 4.5306000e-27], sampled 0.11159110404146577
[2019-03-24 01:18:39,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1449758.126584265 W.
[2019-03-24 01:18:46,734] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:18:46,735] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333334, 98.0, 1.0, 2.0, 0.7928298938103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 903664.1680251531, 903664.1680251526, 194458.1663382591]
[2019-03-24 01:18:46,736] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:18:46,740] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2080519e-18 1.0000000e+00 7.8231771e-30 9.9368968e-12 8.6370623e-31], sampled 0.08657026086549091
[2019-03-24 01:19:05,845] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:19:05,846] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.92255447333334, 84.5784425, 1.0, 2.0, 0.4599735290797589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 555749.4262820132, 555749.4262820127, 136994.9948151754]
[2019-03-24 01:19:05,847] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:19:05,850] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7549908e-19 1.0000000e+00 3.3819095e-31 3.0427859e-12 3.3759398e-32], sampled 0.5071890698154856
[2019-03-24 01:19:13,416] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:19:13,416] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.1, 73.0, 1.0, 2.0, 0.7088494455202153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807893.157448888, 807893.157448888, 177827.9214548496]
[2019-03-24 01:19:13,417] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:19:13,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5759506e-19 1.0000000e+00 2.8384827e-31 2.8488208e-12 2.8172409e-32], sampled 0.32229764458856747
[2019-03-24 01:19:15,138] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:19:15,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 50.5, 1.0, 2.0, 0.5404205862663731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634058.3340365621, 634058.3340365621, 148972.4225749032]
[2019-03-24 01:19:15,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:19:15,146] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7987565e-20 1.0000000e+00 4.0948413e-32 1.3736980e-12 3.8194170e-33], sampled 0.8066184562071302
[2019-03-24 01:19:28,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:19:28,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.8, 72.66666666666667, 1.0, 2.0, 0.6792118160656754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774097.3647544967, 774097.3647544967, 172246.8644569625]
[2019-03-24 01:19:28,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:19:28,362] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8072636e-19 1.0000000e+00 3.5478902e-31 3.0990614e-12 3.5463862e-32], sampled 0.14236618647132493
[2019-03-24 01:19:30,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.42772144]
[2019-03-24 01:19:30,741] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.297470605, 72.62299762500001, 1.0, 2.0, 0.7425119182958413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846280.2870290059, 846280.2870290059, 184355.4948632288]
[2019-03-24 01:19:30,743] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:19:30,745] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0698654e-19 1.0000000e+00 4.4245927e-31 3.3673698e-12 4.4545497e-32], sampled 0.8230371357888701
[2019-03-24 01:19:52,490] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:19:52,582] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:19:52,624] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:19:52,670] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:19:52,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:19:53,881] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 525000, evaluation results [525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:19:56,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2151970e-18 1.0000000e+00 9.3027453e-28 4.6837006e-11 1.8754804e-29], sum to 1.0000
[2019-03-24 01:19:56,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1934
[2019-03-24 01:19:56,902] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333333, 74.0, 1.0, 2.0, 0.5917612412142687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686358.2195252635, 686358.2195252635, 157239.0434101971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808200.0000, 
sim time next is 3808800.0000, 
raw observation next is [26.7, 72.0, 1.0, 2.0, 0.579787430937748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675223.980189638, 675223.980189638, 155320.1993962217], 
processed observation next is [0.0, 0.08695652173913043, 0.5444444444444444, 0.72, 1.0, 1.0, 0.4997469415925571, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24115142149629928, 0.24115142149629928, 0.2986926911465802], 
reward next is 0.7013, 
noisyNet noise sample is [array([0.54340786], dtype=float32), 0.8899021]. 
=============================================
[2019-03-24 01:20:00,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1746976e-15 1.0000000e+00 3.0581419e-26 4.3776063e-10 1.2078535e-26], sum to 1.0000
[2019-03-24 01:20:00,663] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2220
[2019-03-24 01:20:00,671] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 87.0, 1.0, 2.0, 0.7534482578789281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858751.9974890278, 858751.9974890278, 186512.6232461117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3916800.0000, 
sim time next is 3917400.0000, 
raw observation next is [27.25, 87.33333333333333, 1.0, 2.0, 0.731532317407196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 833759.4458841903, 833759.4458841903, 182202.9903047603], 
processed observation next is [0.0, 0.34782608695652173, 0.5648148148148148, 0.8733333333333333, 1.0, 1.0, 0.6803956159609477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2977712306729251, 0.2977712306729251, 0.35039036597069284], 
reward next is 0.6496, 
noisyNet noise sample is [array([-1.4487834], dtype=float32), 1.5631827]. 
=============================================
[2019-03-24 01:20:03,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8927163e-13 1.0000000e+00 9.2975891e-23 4.2464110e-10 4.1365436e-23], sum to 1.0000
[2019-03-24 01:20:03,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2799
[2019-03-24 01:20:03,923] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 93.0, 1.0, 2.0, 0.9105997078504414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425998823, 1039738.354404613, 1039738.354404612, 219942.2068273376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996000.0000, 
sim time next is 3996600.0000, 
raw observation next is [24.56666666666667, 93.16666666666667, 1.0, 2.0, 0.8298231261644952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615657, 947697.429640825, 947697.429640825, 202272.2717090232], 
processed observation next is [1.0, 0.2608695652173913, 0.46543209876543223, 0.9316666666666668, 1.0, 1.0, 0.7974084835291609, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128820104, 0.3384633677288661, 0.3384633677288661, 0.38898513790196765], 
reward next is 0.6110, 
noisyNet noise sample is [array([1.5892457], dtype=float32), 0.051244207]. 
=============================================
[2019-03-24 01:20:05,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3982183e-12 1.0000000e+00 7.2755115e-19 1.5596532e-08 1.7734384e-18], sum to 1.0000
[2019-03-24 01:20:05,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0577
[2019-03-24 01:20:05,713] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 92.0, 1.0, 2.0, 0.8826519204009644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1008366.369759076, 1008366.369759076, 213726.8395163029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3992400.0000, 
sim time next is 3993000.0000, 
raw observation next is [24.68333333333333, 92.16666666666667, 1.0, 2.0, 1.004259822161704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.18494469156619, 6.9112, 121.9250583469639, 1287714.780913994, 1147534.163450201, 241901.0347235064], 
processed observation next is [1.0, 0.21739130434782608, 0.46975308641975294, 0.9216666666666667, 1.0, 1.0, 1.0050712168591716, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.027374469156618987, 0.0, 0.8094555942995492, 0.4598981360407121, 0.40983362980364324, 0.4651942975452046], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06647804], dtype=float32), 1.0619833]. 
=============================================
[2019-03-24 01:20:05,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[42.250313]
 [42.39245 ]
 [42.236984]
 [42.44537 ]
 [41.914997]], R is [[42.17362595]
 [42.34087372]
 [42.49283218]
 [42.63454819]
 [42.20820236]].
[2019-03-24 01:20:08,462] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5515835e-17 1.0000000e+00 8.4479335e-24 3.3545184e-11 1.2252761e-24], sum to 1.0000
[2019-03-24 01:20:08,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4612
[2019-03-24 01:20:08,472] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 96.5, 1.0, 2.0, 0.4376691659331796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538725.5857014358, 538725.5857014358, 133966.633616251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4077000.0000, 
sim time next is 4077600.0000, 
raw observation next is [20.2, 95.33333333333334, 1.0, 2.0, 0.4180380766699103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515219.5914448884, 515219.5914448884, 131124.2416938972], 
processed observation next is [1.0, 0.17391304347826086, 0.3037037037037037, 0.9533333333333335, 1.0, 1.0, 0.30718818651179797, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18400699694460299, 0.18400699694460299, 0.2521620032574946], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.0307723], dtype=float32), 0.8964213]. 
=============================================
[2019-03-24 01:20:15,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7955592e-11 9.9999499e-01 9.9377644e-18 5.0068261e-06 1.0049260e-19], sum to 1.0000
[2019-03-24 01:20:15,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5460
[2019-03-24 01:20:15,475] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 77.5, 1.0, 2.0, 0.5465301217519308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677377.8455829934, 677377.8455829934, 151175.6642337254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4248600.0000, 
sim time next is 4249200.0000, 
raw observation next is [22.2, 77.0, 1.0, 2.0, 0.4956386920677866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 613995.0537195951, 613995.0537195947, 142903.2026076799], 
processed observation next is [1.0, 0.17391304347826086, 0.37777777777777777, 0.77, 1.0, 1.0, 0.3995698715092698, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21928394775699825, 0.2192839477569981, 0.27481385116861523], 
reward next is 0.7252, 
noisyNet noise sample is [array([-1.4710058], dtype=float32), -0.040164758]. 
=============================================
[2019-03-24 01:20:15,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3084061e-12 9.9999976e-01 1.6409139e-17 2.4005735e-07 4.9694219e-19], sum to 1.0000
[2019-03-24 01:20:15,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5098
[2019-03-24 01:20:15,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1676173.376123996 W.
[2019-03-24 01:20:15,830] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.43333333333334, 33.0, 1.0, 2.0, 0.4806250080231573, 1.0, 1.0, 0.4806250080231573, 1.0, 1.0, 0.7669058045421445, 6.9112, 6.9112, 121.94756008, 1676173.376123996, 1676173.376123996, 334291.0918868673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4195200.0000, 
sim time next is 4195800.0000, 
raw observation next is [33.65, 31.5, 1.0, 2.0, 0.7152286205976168, 1.0, 2.0, 0.7152286205976168, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260424815479, 1678644.847684372, 1678644.847684371, 312275.6580605023], 
processed observation next is [1.0, 0.5652173913043478, 0.8018518518518518, 0.315, 1.0, 1.0, 0.660986453092401, 1.0, 1.0, 0.660986453092401, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621279297591, 0.5995160170301328, 0.5995160170301325, 0.6005301116548122], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9273251], dtype=float32), -0.13643004]. 
=============================================
[2019-03-24 01:20:15,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1013180e-13 1.0000000e+00 1.0288638e-20 5.7659726e-08 1.1806903e-23], sum to 1.0000
[2019-03-24 01:20:15,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0557
[2019-03-24 01:20:15,960] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.66666666666667, 1.0, 2.0, 0.5217911379591517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621058.6713063611, 621058.6713063611, 146311.8581473749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4227600.0000, 
sim time next is 4228200.0000, 
raw observation next is [26.0, 66.0, 1.0, 2.0, 0.5023300941921532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 602390.7041604364, 602390.7041604369, 143378.6910909408], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.66, 1.0, 1.0, 0.40753582641923003, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21513953720015586, 0.21513953720015602, 0.27572825209796303], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.41364583], dtype=float32), -0.49452096]. 
=============================================
[2019-03-24 01:20:24,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9668014e-15 1.0000000e+00 5.9234690e-24 1.4297188e-10 1.1468853e-24], sum to 1.0000
[2019-03-24 01:20:24,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0420
[2019-03-24 01:20:24,816] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 79.0, 1.0, 2.0, 0.6879747634897274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784089.5996775646, 784089.5996775646, 173878.9654873349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4396800.0000, 
sim time next is 4397400.0000, 
raw observation next is [27.1, 79.0, 1.0, 2.0, 0.6775886004070231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 772246.454769025, 772246.4547690245, 171942.6377932013], 
processed observation next is [1.0, 0.9130434782608695, 0.5592592592592593, 0.79, 1.0, 1.0, 0.616176905246456, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27580230527465177, 0.2758023052746516, 0.33065891883307946], 
reward next is 0.6693, 
noisyNet noise sample is [array([0.6967938], dtype=float32), 1.0197146]. 
=============================================
[2019-03-24 01:20:27,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6838722e-21 1.0000000e+00 8.9909097e-35 1.9955618e-15 4.0176450e-33], sum to 1.0000
[2019-03-24 01:20:27,748] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1943
[2019-03-24 01:20:27,752] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 93.0, 1.0, 2.0, 0.490122371264707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588272.6634561362, 588272.6634561362, 141484.4883310192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4426800.0000, 
sim time next is 4427400.0000, 
raw observation next is [22.06666666666667, 93.5, 1.0, 2.0, 0.4904930150644758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588766.5316148774, 588766.5316148774, 141543.9065313584], 
processed observation next is [0.0, 0.21739130434782608, 0.3728395061728396, 0.935, 1.0, 1.0, 0.3934440655529474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21027376129102765, 0.21027376129102765, 0.2721998202526123], 
reward next is 0.7278, 
noisyNet noise sample is [array([0.00914942], dtype=float32), -1.6529952]. 
=============================================
[2019-03-24 01:20:28,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0304605e-19 1.0000000e+00 4.1917602e-30 8.2280519e-12 1.4939911e-30], sum to 1.0000
[2019-03-24 01:20:28,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8986
[2019-03-24 01:20:28,403] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6381782678915837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727309.2639811118, 727309.2639811118, 164769.3508700177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.64254036287586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 732282.9643369211, 732282.9643369206, 165550.1397304996], 
processed observation next is [0.0, 0.391304347826087, 0.5370370370370371, 0.815, 1.0, 1.0, 0.5744528129474524, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.261529630120329, 0.2615296301203288, 0.31836565332788386], 
reward next is 0.6816, 
noisyNet noise sample is [array([-0.5789382], dtype=float32), 0.8366027]. 
=============================================
[2019-03-24 01:20:30,666] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4846020e-20 1.0000000e+00 1.0092237e-31 1.1793786e-11 1.3330727e-31], sum to 1.0000
[2019-03-24 01:20:30,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9323
[2019-03-24 01:20:30,677] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 90.66666666666666, 1.0, 2.0, 0.5821452260075626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678814.8038914395, 678814.8038914395, 155758.6119874034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4499400.0000, 
sim time next is 4500000.0000, 
raw observation next is [23.9, 90.0, 1.0, 2.0, 0.5758414299129048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672894.3147900609, 672894.3147900609, 154751.2391499531], 
processed observation next is [0.0, 0.08695652173913043, 0.4407407407407407, 0.9, 1.0, 1.0, 0.4950493213248866, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24031939813930744, 0.24031939813930744, 0.29759853682683285], 
reward next is 0.7024, 
noisyNet noise sample is [array([-1.3800896], dtype=float32), 0.40098023]. 
=============================================
[2019-03-24 01:20:30,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.48023 ]
 [79.426125]
 [79.467636]
 [79.265816]
 [79.2621  ]], R is [[79.45331573]
 [79.3592453 ]
 [79.2641983 ]
 [79.16809845]
 [79.07063293]].
[2019-03-24 01:20:32,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3569065e-16 1.0000000e+00 3.7863986e-26 7.7924445e-10 3.6311366e-25], sum to 1.0000
[2019-03-24 01:20:32,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9606
[2019-03-24 01:20:32,228] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 95.5, 1.0, 2.0, 0.5708696445012513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667570.8440646096, 667570.8440646096, 153932.6382542769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4509000.0000, 
sim time next is 4509600.0000, 
raw observation next is [23.2, 94.0, 1.0, 2.0, 0.5636546138181381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660971.600547737, 660971.600547737, 152800.1867324495], 
processed observation next is [0.0, 0.17391304347826086, 0.4148148148148148, 0.94, 1.0, 1.0, 0.4805412069263548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23606128590990608, 0.23606128590990608, 0.2938465129470183], 
reward next is 0.7062, 
noisyNet noise sample is [array([1.8381852], dtype=float32), -1.5673608]. 
=============================================
[2019-03-24 01:20:35,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5562644e-19 1.0000000e+00 3.9954573e-31 3.1689535e-13 9.2939391e-30], sum to 1.0000
[2019-03-24 01:20:35,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8335
[2019-03-24 01:20:35,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.485498669125758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 140847.245355948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.482080270977471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581640.2062659106, 581640.2062659106, 140340.8982551762], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3834288940207989, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20772864509496808, 0.20772864509496808, 0.2698863427984158], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.37194556], dtype=float32), 1.1716455]. 
=============================================
[2019-03-24 01:20:39,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7188320e-15 9.9999988e-01 4.1730141e-22 6.0969022e-08 1.6860325e-20], sum to 1.0000
[2019-03-24 01:20:39,893] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4948
[2019-03-24 01:20:39,900] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.6126828871171806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721221.0181866242, 721221.0181866242, 161334.4457623793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4687200.0000, 
sim time next is 4687800.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.6068843315299293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 713655.9125132433, 713655.9125132428, 160284.9571075685], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.95, 1.0, 1.0, 0.5320051565832491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2548771116118726, 0.25487711161187243, 0.3082403021299394], 
reward next is 0.6918, 
noisyNet noise sample is [array([0.38738874], dtype=float32), -1.766918]. 
=============================================
[2019-03-24 01:20:42,650] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 01:20:42,651] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:20:42,651] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:20:42,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:42,652] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:42,653] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:20:42,652] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:20:42,656] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:42,657] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:42,653] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:20:42,659] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:42,670] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-24 01:20:42,692] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-24 01:20:42,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-24 01:20:42,742] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-24 01:20:42,773] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-24 01:21:08,514] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:21:08,514] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.63333333333334, 74.33333333333334, 1.0, 2.0, 0.4386000005018506, 0.0, 2.0, 0.0, 1.0, 2.0, 0.703862025497322, 6.911199999999999, 6.9112, 121.9260425227682, 1039325.657485819, 1039325.657485819, 235314.5485023115]
[2019-03-24 01:21:08,515] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:21:08,518] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6157474e-10 9.9862921e-01 3.0025804e-18 1.3708548e-03 3.1827131e-18], sampled 0.6529354735509382
[2019-03-24 01:21:28,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:21:28,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.75804815333333, 109.6979201666667, 1.0, 2.0, 0.9157629440862397, 1.0, 2.0, 0.9157629440862397, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156468, 2089081.48209316, 2089081.48209316, 393912.4459166206]
[2019-03-24 01:21:28,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:21:28,765] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9994298e-11 9.9880433e-01 1.2698941e-18 1.1956396e-03 1.3421609e-18], sampled 0.5429094411642361
[2019-03-24 01:21:28,766] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2089081.48209316 W.
[2019-03-24 01:21:41,841] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:21:41,843] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.83333333333334, 78.66666666666666, 1.0, 2.0, 0.4212447843804178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515644.9466889605, 515644.94668896, 131494.3327467268]
[2019-03-24 01:21:41,844] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:21:41,848] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7568568e-12 9.9962676e-01 8.8865986e-22 3.7322182e-04 9.5808144e-22], sampled 0.17750081908741566
[2019-03-24 01:21:42,288] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:21:42,291] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.35, 81.5, 1.0, 2.0, 0.4717825879523994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568469.7874456454, 568469.7874456454, 138734.367730219]
[2019-03-24 01:21:42,292] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:21:42,295] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.6192297e-13 9.9970657e-01 1.9811212e-22 2.9338707e-04 2.1420128e-22], sampled 0.15607257502619443
[2019-03-24 01:21:59,105] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:21:59,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.46666666666667, 59.0, 1.0, 2.0, 0.7310137922418457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 833168.1388088327, 833168.1388088337, 182103.2319418014]
[2019-03-24 01:21:59,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:21:59,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3252613e-13 9.9976891e-01 4.4646485e-23 2.3111081e-04 4.8427448e-23], sampled 0.5057981502153363
[2019-03-24 01:22:02,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:22:02,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.66666666666667, 60.83333333333334, 1.0, 2.0, 0.8115029506728096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924960.4834527194, 924960.4834527194, 198325.2331542075]
[2019-03-24 01:22:02,335] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:22:02,339] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.5425725e-12 9.9943238e-01 1.2185950e-20 5.6760316e-04 1.3065839e-20], sampled 0.2748454838498736
[2019-03-24 01:22:11,499] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.44034776]
[2019-03-24 01:22:11,502] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.63333333333333, 86.33333333333334, 1.0, 2.0, 0.7010688177298479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799020.762325753, 799020.762325753, 176346.6171541886]
[2019-03-24 01:22:11,504] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:22:11,505] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9134483e-12 9.9961746e-01 1.0359115e-21 3.8252358e-04 1.1165593e-21], sampled 0.03937911978265907
[2019-03-24 01:22:29,787] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8919.8180 2120519171.5953 430.0000
[2019-03-24 01:22:29,845] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8767.6083 2170673610.9919 492.0000
[2019-03-24 01:22:29,894] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8223 2248651647.3309 553.0000
[2019-03-24 01:22:30,083] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8092.0165 2445300597.0128 744.0000
[2019-03-24 01:22:30,098] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8696.7576 2195120354.5774 572.0000
[2019-03-24 01:22:31,115] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 550000, evaluation results [550000.0, 8092.016461461668, 2445300597.012759, 744.0, 8767.608320495647, 2170673610.991902, 492.0, 8919.818004267461, 2120519171.5953481, 430.0, 8582.822326570013, 2248651647.3308954, 553.0, 8696.757615616114, 2195120354.5774183, 572.0]
[2019-03-24 01:22:32,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5280473e-08 9.4155771e-01 3.6705471e-17 5.8442269e-02 2.7453518e-16], sum to 1.0000
[2019-03-24 01:22:32,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-24 01:22:32,457] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.621511455295912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717234.2221847743, 717234.2221847743, 162253.1271309469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765800.0000, 
sim time next is 4766400.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6204293235643069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716035.3029573772, 716035.3029573772, 162064.6078402404], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5481301471003653, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25572689391334896, 0.25572689391334896, 0.31166270738507773], 
reward next is 0.6883, 
noisyNet noise sample is [array([-0.4137552], dtype=float32), -0.9677029]. 
=============================================
[2019-03-24 01:22:34,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0051187e-12 9.9964166e-01 2.8014617e-20 3.5828425e-04 8.3928366e-19], sum to 1.0000
[2019-03-24 01:22:34,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-24 01:22:34,302] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 93.16666666666666, 1.0, 2.0, 0.6485724538229161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751335.5322836897, 751335.5322836897, 167228.9432808035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4780200.0000, 
sim time next is 4780800.0000, 
raw observation next is [23.9, 93.0, 1.0, 2.0, 0.6909999649853855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801138.2635046736, 801138.2635046736, 175115.7764558863], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.93, 1.0, 1.0, 0.6321428154587923, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2861208083945263, 0.2861208083945263, 0.33676110856901215], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.72260904], dtype=float32), -0.6895222]. 
=============================================
[2019-03-24 01:22:35,473] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9575138e-08 9.7478163e-01 2.6204974e-13 2.5218274e-02 5.5382023e-14], sum to 1.0000
[2019-03-24 01:22:35,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5850
[2019-03-24 01:22:35,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1867421.485601881 W.
[2019-03-24 01:22:35,492] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.75, 87.0, 1.0, 2.0, 0.8186982752505599, 1.0, 2.0, 0.8186982752505599, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155778, 1867421.485601881, 1867421.485601881, 351541.7610543923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4800600.0000, 
sim time next is 4801200.0000, 
raw observation next is [27.0, 86.33333333333334, 1.0, 2.0, 0.5629951600416956, 1.0, 2.0, 0.5629951600416956, 1.0, 1.0, 0.8963066302586761, 6.911199999999999, 6.9112, 121.94756008, 1926320.820369415, 1926320.820369415, 375582.4084034199], 
processed observation next is [1.0, 0.5652173913043478, 0.5555555555555556, 0.8633333333333334, 1.0, 1.0, 0.4797561429067804, 1.0, 1.0, 0.4797561429067804, 1.0, 0.5, 0.870383287823345, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6879717215605053, 0.6879717215605053, 0.722273862314269], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03394479], dtype=float32), 0.045110874]. 
=============================================
[2019-03-24 01:22:42,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0120084e-11 9.8603779e-01 2.3998744e-22 1.3962221e-02 8.4823766e-20], sum to 1.0000
[2019-03-24 01:22:42,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-24 01:22:42,030] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8385345432811339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 955790.620458339, 955790.620458339, 204044.320501997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4905000.0000, 
sim time next is 4905600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.8765319382996154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999129.5980529427, 999129.5980529427, 212273.6395617696], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.8530142122614469, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3568319993046224, 0.3568319993046224, 0.40821853761878774], 
reward next is 0.5918, 
noisyNet noise sample is [array([0.5897989], dtype=float32), -0.0062298304]. 
=============================================
[2019-03-24 01:22:43,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4723184e-14 9.9999690e-01 1.1628197e-25 3.1012642e-06 1.1147102e-21], sum to 1.0000
[2019-03-24 01:22:43,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8482
[2019-03-24 01:22:43,978] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.0, 1.0, 2.0, 0.6002352684911779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715399.1818101091, 715399.1818101091, 159507.9042993387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4953600.0000, 
sim time next is 4954200.0000, 
raw observation next is [24.58333333333334, 78.83333333333333, 1.0, 2.0, 0.6426762023879594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 764585.5794506848, 764585.5794506858, 167027.4465527595], 
processed observation next is [1.0, 0.34782608695652173, 0.4660493827160496, 0.7883333333333333, 1.0, 1.0, 0.5746145266523326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2730662783752446, 0.27306627837524494, 0.32120662798607597], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.6793097], dtype=float32), 0.031830214]. 
=============================================
[2019-03-24 01:22:47,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2196680e-12 9.9963319e-01 3.8052545e-23 3.6684776e-04 4.5770444e-21], sum to 1.0000
[2019-03-24 01:22:47,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-24 01:22:47,186] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 99.66666666666667, 1.0, 2.0, 0.5740523582291339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 667192.7543001956, 667192.7543001951, 154289.0270048716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5026200.0000, 
sim time next is 5026800.0000, 
raw observation next is [22.9, 99.33333333333334, 1.0, 2.0, 0.5716528761345233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665642.2873980385, 665642.2873980385, 153940.0467931122], 
processed observation next is [0.0, 0.17391304347826086, 0.4037037037037037, 0.9933333333333334, 1.0, 1.0, 0.4900629477791944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23772938835644233, 0.23772938835644233, 0.2960385515252158], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.61318195], dtype=float32), 0.0023639682]. 
=============================================
[2019-03-24 01:22:48,975] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6322324e-17 9.9999833e-01 5.1597890e-27 1.7214224e-06 1.0971298e-26], sum to 1.0000
[2019-03-24 01:22:48,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1792
[2019-03-24 01:22:48,989] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.83333333333333, 1.0, 2.0, 0.828484626226719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944328.3200474208, 944328.3200474208, 201904.1090829918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8169351814601947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931155.9647937408, 931155.9647937408, 199471.6414838236], 
processed observation next is [0.0, 0.7391304347826086, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7820656922145175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3325557017120503, 0.3325557017120503, 0.3835993105458146], 
reward next is 0.6164, 
noisyNet noise sample is [array([-0.6386947], dtype=float32), -0.5171887]. 
=============================================
[2019-03-24 01:22:51,360] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5611843e-18 9.9997520e-01 4.7225285e-28 2.4838349e-05 1.9297578e-26], sum to 1.0000
[2019-03-24 01:22:51,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4379
[2019-03-24 01:22:51,373] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 83.16666666666667, 1.0, 2.0, 0.7849912267545391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 894724.4730229318, 894724.4730229314, 192865.8666804119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5083800.0000, 
sim time next is 5084400.0000, 
raw observation next is [28.53333333333333, 84.33333333333334, 1.0, 2.0, 0.8031391150066346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 915421.5927297543, 915421.5927297538, 196596.9557620139], 
processed observation next is [0.0, 0.8695652173913043, 0.6123456790123456, 0.8433333333333334, 1.0, 1.0, 0.7656418035793269, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3269362831177694, 0.32693628311776923, 0.37807106877310365], 
reward next is 0.6219, 
noisyNet noise sample is [array([-0.38414752], dtype=float32), -0.5057113]. 
=============================================
[2019-03-24 01:22:55,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0907386e-10 9.9981219e-01 5.6912594e-17 1.8784094e-04 1.8276767e-15], sum to 1.0000
[2019-03-24 01:22:55,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3771
[2019-03-24 01:22:55,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.9622737242469174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.978508697015533, 6.9112, 121.925490496278, 1143699.200723414, 1109231.28795062, 232429.1120256383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.9135084249693003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.926002055527, 1053605.539520958, 1053605.539520957, 221175.4159297462], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.897033839249167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094618595430204, 0.37628769268605644, 0.3762876926860561, 0.425337338326435], 
reward next is 0.5747, 
noisyNet noise sample is [array([0.31980258], dtype=float32), -0.06398617]. 
=============================================
[2019-03-24 01:22:56,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5440719e-10 9.9653471e-01 6.4631144e-16 3.4652671e-03 1.4524247e-14], sum to 1.0000
[2019-03-24 01:22:56,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2409
[2019-03-24 01:22:56,283] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748494630513809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 171435.6612174352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5187000.0000, 
sim time next is 5187600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6746178602351648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768859.0097118813, 768859.0097118813, 171392.8369413446], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6126403098037676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27459250346852904, 0.27459250346852904, 0.32960160950258577], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.04252832], dtype=float32), 1.273017]. 
=============================================
[2019-03-24 01:23:00,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9684432e-12 9.9854702e-01 3.2937329e-19 1.4530012e-03 3.1025216e-18], sum to 1.0000
[2019-03-24 01:23:00,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3223
[2019-03-24 01:23:00,068] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 88.0, 1.0, 2.0, 0.7140854653223083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813863.9463922792, 813863.9463922792, 178828.5491492019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259600.0000, 
sim time next is 5260200.0000, 
raw observation next is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.6998923328327609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797679.2035729453, 797679.2035729453, 176124.6613501185], 
processed observation next is [1.0, 0.9130434782608695, 0.5376543209876544, 0.8833333333333334, 1.0, 1.0, 0.6427289676580487, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2848854298474805, 0.2848854298474805, 0.33870127182715093], 
reward next is 0.6613, 
noisyNet noise sample is [array([0.95008224], dtype=float32), 0.07291211]. 
=============================================
[2019-03-24 01:23:00,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1407946e-10 9.4105875e-01 5.9457598e-18 5.8941279e-02 5.2710966e-15], sum to 1.0000
[2019-03-24 01:23:00,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3450
[2019-03-24 01:23:00,343] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 90.0, 1.0, 2.0, 0.6970723638055253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794463.5712312438, 794463.5712312438, 175589.9969296917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265000.0000, 
sim time next is 5265600.0000, 
raw observation next is [25.9, 90.0, 1.0, 2.0, 0.6943389435803018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791346.644029029, 791346.6440290285, 175074.4022322376], 
processed observation next is [1.0, 0.9565217391304348, 0.5148148148148147, 0.9, 1.0, 1.0, 0.6361177899765498, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2826238014389389, 0.2826238014389387, 0.33668154275430306], 
reward next is 0.6633, 
noisyNet noise sample is [array([-0.5415743], dtype=float32), -0.16576795]. 
=============================================
[2019-03-24 01:23:11,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6404441e-14 4.0319491e-02 5.4370629e-23 9.5968056e-01 1.3640869e-20], sum to 1.0000
[2019-03-24 01:23:11,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2367
[2019-03-24 01:23:11,721] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 86.0, 1.0, 2.0, 0.3338624120076567, 1.0, 2.0, 0.3338624120076567, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760999.146912909, 760999.1469129093, 188785.6168990859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5521200.0000, 
sim time next is 5521800.0000, 
raw observation next is [26.15, 86.5, 1.0, 2.0, 0.3348962879467905, 1.0, 2.0, 0.3348962879467905, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 763356.9160029654, 763356.9160029658, 189046.0341186022], 
processed observation next is [1.0, 0.9130434782608695, 0.524074074074074, 0.865, 1.0, 1.0, 0.20820986660332202, 1.0, 1.0, 0.20820986660332202, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2726274700010591, 0.2726274700010592, 0.36355006561269654], 
reward next is 0.6364, 
noisyNet noise sample is [array([0.30062956], dtype=float32), -1.1292769]. 
=============================================
[2019-03-24 01:23:16,519] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4057557e-16 2.3680623e-07 4.1323388e-27 9.9999976e-01 1.1892968e-23], sum to 1.0000
[2019-03-24 01:23:16,530] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7244
[2019-03-24 01:23:16,534] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.2971196601878816, 1.0, 2.0, 0.2971196601878816, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679309.509513712, 679309.5095137124, 179876.309245618], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5623800.0000, 
sim time next is 5624400.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.2969628596518198, 1.0, 2.0, 0.2969628596518198, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678962.0365427902, 678962.0365427907, 179839.3580068989], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 1.0, 1.0, 0.16305102339502356, 1.0, 1.0, 0.16305102339502356, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24248644162242508, 0.24248644162242525, 0.3458449192440363], 
reward next is 0.6542, 
noisyNet noise sample is [array([1.5977206], dtype=float32), -0.3064659]. 
=============================================
[2019-03-24 01:23:18,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5603269e-13 1.9223813e-05 2.2157942e-25 9.9998081e-01 1.1435836e-22], sum to 1.0000
[2019-03-24 01:23:18,529] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-24 01:23:18,535] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.51666666666667, 81.50000000000001, 1.0, 2.0, 0.3480422368448201, 1.0, 2.0, 0.3480422368448201, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793337.0757349993, 793337.0757349993, 192389.9552462136], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5656200.0000, 
sim time next is 5656800.0000, 
raw observation next is [27.63333333333334, 81.0, 1.0, 2.0, 0.348947712832394, 1.0, 2.0, 0.348947712832394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 795402.1135971049, 795402.1135971054, 192622.4813637914], 
processed observation next is [0.0, 0.4782608695652174, 0.5790123456790126, 0.81, 1.0, 1.0, 0.22493775337189764, 1.0, 1.0, 0.22493775337189764, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2840721834275375, 0.28407218342753765, 0.3704278487765219], 
reward next is 0.6296, 
noisyNet noise sample is [array([0.6224296], dtype=float32), 1.3975035]. 
=============================================
[2019-03-24 01:23:19,417] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 01:23:19,418] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:23:19,418] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:23:19,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:19,419] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:23:19,420] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:19,422] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:23:19,423] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:19,425] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:19,422] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:23:19,430] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:19,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-24 01:23:19,444] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-24 01:23:19,482] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-24 01:23:19,503] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-24 01:23:19,521] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-24 01:23:30,239] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:23:30,240] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.94661035, 59.27671989, 1.0, 2.0, 0.1699858740894002, 1.0, 2.0, 0.1699858740894002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427469.0862674574, 427469.0862674579, 153840.4514346499]
[2019-03-24 01:23:30,241] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:23:30,244] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3815783e-14 2.3490058e-05 6.4549742e-25 9.9997652e-01 4.0286076e-22], sampled 0.6096382943096113
[2019-03-24 01:23:50,118] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:23:50,119] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.5, 60.0, 1.0, 2.0, 0.2556347382212372, 1.0, 2.0, 0.2556347382212372, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603058.7558304594, 603058.7558304599, 171134.8718873278]
[2019-03-24 01:23:50,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:23:50,122] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5221757e-15 1.0862570e-05 1.1938142e-26 9.9998915e-01 1.1756618e-23], sampled 0.9377345500103639
[2019-03-24 01:24:09,199] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:24:09,200] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.76544966333333, 88.49480960666668, 1.0, 2.0, 0.2689194409088753, 1.0, 2.0, 0.2689194409088753, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 627545.9890420213, 627545.9890420218, 173883.6540693429]
[2019-03-24 01:24:09,201] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:24:09,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.8074980e-14 2.4857185e-05 8.6467310e-25 9.9997509e-01 5.2196465e-22], sampled 0.3818834937852169
[2019-03-24 01:24:27,348] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:24:27,349] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.91666666666667, 57.83333333333334, 1.0, 2.0, 0.7207992255768333, 1.0, 2.0, 0.7207992255768333, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1643911.778128285, 1643911.778128285, 312114.6284564256]
[2019-03-24 01:24:27,349] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:24:27,352] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.3941965e-14 3.1099778e-05 2.7616431e-24 9.9996889e-01 1.4586039e-21], sampled 0.3162445292146526
[2019-03-24 01:24:30,834] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:24:30,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.58979175, 77.766861455, 1.0, 2.0, 0.5611024731545791, 1.0, 2.0, 0.5611024731545791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1279397.906091005, 1279397.906091006, 254930.9575390674]
[2019-03-24 01:24:30,836] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:24:30,841] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9519955e-14 2.5284475e-05 9.4578536e-25 9.9997473e-01 5.6475287e-22], sampled 0.7954203513425376
[2019-03-24 01:24:40,487] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.4508564]
[2019-03-24 01:24:40,489] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.9, 87.0, 1.0, 2.0, 0.2456992644107768, 1.0, 2.0, 0.2456992644107768, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583938.0493559403, 583938.0493559408, 169076.7151053914]
[2019-03-24 01:24:40,491] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:24:40,494] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7896572e-14 2.9862913e-05 2.2344284e-24 9.9997008e-01 1.2100616e-21], sampled 0.5609284648958789
[2019-03-24 01:25:03,710] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.2146 2668554499.6500 68.0000
[2019-03-24 01:25:04,055] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 01:25:04,069] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 01:25:04,075] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 01:25:04,133] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 01:25:05,148] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 575000, evaluation results [575000.0, 7523.2146477705855, 2668554499.6499534, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 01:25:09,667] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.5910250e-13 5.4797965e-06 2.2832810e-22 9.9999452e-01 2.0210875e-20], sum to 1.0000
[2019-03-24 01:25:09,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1211
[2019-03-24 01:25:09,684] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.05, 63.5, 1.0, 2.0, 0.2828543953856408, 1.0, 2.0, 0.2828543953856408, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 653572.8784409192, 653572.8784409197, 176837.0028873947], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5758200.0000, 
sim time next is 5758800.0000, 
raw observation next is [28.06666666666667, 64.0, 1.0, 2.0, 0.2846305198201576, 1.0, 2.0, 0.2846305198201576, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 656316.5082436496, 656316.5082436501, 177190.0320769857], 
processed observation next is [0.0, 0.6521739130434783, 0.5950617283950619, 0.64, 1.0, 1.0, 0.14836966645256855, 1.0, 1.0, 0.14836966645256855, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23439875294416057, 0.23439875294416074, 0.34075006168651095], 
reward next is 0.6592, 
noisyNet noise sample is [array([0.7272136], dtype=float32), -1.3390231]. 
=============================================
[2019-03-24 01:25:15,345] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6057832e-14 8.2910865e-06 1.3007411e-24 9.9999166e-01 2.2804022e-22], sum to 1.0000
[2019-03-24 01:25:15,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7330
[2019-03-24 01:25:15,361] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3371966639361263, 1.0, 2.0, 0.3371966639361263, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829368.332388261, 829368.332388261, 192007.0534363624], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5833200.0000, 
sim time next is 5833800.0000, 
raw observation next is [27.05, 46.5, 1.0, 2.0, 0.3263600018503594, 1.0, 2.0, 0.3263600018503594, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802481.9336866095, 802481.93368661, 189214.969594726], 
processed observation next is [1.0, 0.5217391304347826, 0.5574074074074075, 0.465, 1.0, 1.0, 0.19804762125042788, 1.0, 1.0, 0.19804762125042788, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28660069060236054, 0.2866006906023607, 0.36387494152831923], 
reward next is 0.6361, 
noisyNet noise sample is [array([-0.01366485], dtype=float32), -0.4501919]. 
=============================================
[2019-03-24 01:25:18,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6960573e-12 1.4152316e-03 1.3293267e-19 9.9858475e-01 2.7111916e-18], sum to 1.0000
[2019-03-24 01:25:18,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-24 01:25:18,023] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 52.0, 1.0, 2.0, 0.5620635586207514, 1.0, 2.0, 0.5620635586207514, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1339804.232917314, 1339804.232917313, 257816.5285500127], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5918400.0000, 
sim time next is 5919000.0000, 
raw observation next is [27.76666666666667, 51.16666666666667, 1.0, 2.0, 0.4689889606685937, 1.0, 2.0, 0.4689889606685937, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1120666.291901306, 1120666.291901305, 228176.1887649471], 
processed observation next is [1.0, 0.5217391304347826, 0.5839506172839507, 0.5116666666666667, 1.0, 1.0, 0.3678440007959449, 1.0, 1.0, 0.3678440007959449, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40023796139332357, 0.40023796139332324, 0.43880036300951364], 
reward next is 0.5612, 
noisyNet noise sample is [array([-0.564253], dtype=float32), -1.3109988]. 
=============================================
[2019-03-24 01:25:18,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.428585]
 [54.20791 ]
 [54.196056]
 [54.157715]
 [54.172466]], R is [[55.1283226 ]
 [55.08124161]
 [55.01567459]
 [54.951931  ]
 [54.8895874 ]].
[2019-03-24 01:25:21,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4580055e-13 1.5204415e-07 1.3403091e-22 9.9999988e-01 1.5360531e-19], sum to 1.0000
[2019-03-24 01:25:21,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8951
[2019-03-24 01:25:21,663] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 68.33333333333333, 1.0, 2.0, 0.2475265032517312, 1.0, 2.0, 0.2475265032517312, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 588593.9999869991, 588593.9999869996, 169500.2596500063], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5949600.0000, 
sim time next is 5950200.0000, 
raw observation next is [25.4, 69.66666666666667, 1.0, 2.0, 0.2482003044570786, 1.0, 2.0, 0.2482003044570786, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 589979.5869789043, 589979.5869789047, 169643.1040287696], 
processed observation next is [1.0, 0.8695652173913043, 0.49629629629629624, 0.6966666666666668, 1.0, 1.0, 0.10500036244890311, 1.0, 1.0, 0.10500036244890311, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21070699534960868, 0.21070699534960882, 0.3262367385168646], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.43173617], dtype=float32), -0.6406992]. 
=============================================
[2019-03-24 01:25:29,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0643822e-14 8.1309345e-06 5.7838528e-21 9.9999189e-01 1.2189703e-20], sum to 1.0000
[2019-03-24 01:25:29,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6841
[2019-03-24 01:25:29,827] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.38333333333333, 83.83333333333334, 1.0, 2.0, 0.3738595790540523, 1.0, 2.0, 0.3738595790540523, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868197.6461563673, 868197.6461563673, 199878.5795777279], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6163800.0000, 
sim time next is 6164400.0000, 
raw observation next is [24.56666666666667, 82.66666666666667, 1.0, 2.0, 0.5477838101919675, 1.0, 2.0, 0.5477838101919675, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1265229.274764352, 1265229.274764352, 251335.6106679315], 
processed observation next is [1.0, 0.34782608695652173, 0.46543209876543223, 0.8266666666666667, 1.0, 1.0, 0.4616473930856756, 1.0, 1.0, 0.4616473930856756, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4518675981301257, 0.4518675981301257, 0.4833377128229452], 
reward next is 0.5167, 
noisyNet noise sample is [array([0.01558237], dtype=float32), -0.7124098]. 
=============================================
[2019-03-24 01:25:35,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6786623e-16 1.6426064e-08 1.2471235e-24 1.0000000e+00 4.7037125e-21], sum to 1.0000
[2019-03-24 01:25:35,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9237
[2019-03-24 01:25:35,928] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.31666666666667, 88.66666666666667, 1.0, 2.0, 0.2390680823552515, 1.0, 2.0, 0.2390680823552515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571891.9158904551, 571891.9158904556, 167747.0485642512], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6239400.0000, 
sim time next is 6240000.0000, 
raw observation next is [22.43333333333333, 88.33333333333334, 1.0, 2.0, 0.2401772142834177, 1.0, 2.0, 0.2401772142834177, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573824.6437426492, 573824.6437426492, 167965.5014380489], 
processed observation next is [0.0, 0.21739130434782608, 0.3864197530864196, 0.8833333333333334, 1.0, 1.0, 0.09544906462311632, 1.0, 1.0, 0.09544906462311632, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20493737276523186, 0.20493737276523186, 0.32301057968855557], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.1740149], dtype=float32), -1.4073699]. 
=============================================
[2019-03-24 01:25:35,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.70492 ]
 [64.787056]
 [64.82456 ]
 [64.85837 ]
 [64.893005]], R is [[64.67342377]
 [64.70409393]
 [64.73487854]
 [64.76548767]
 [64.79581451]].
[2019-03-24 01:25:38,887] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4511164e-18 1.9549862e-08 4.1238322e-29 1.0000000e+00 1.4605123e-24], sum to 1.0000
[2019-03-24 01:25:38,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0585
[2019-03-24 01:25:38,899] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 71.0, 1.0, 2.0, 0.2973555121339462, 1.0, 2.0, 0.2973555121339462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682800.1067577282, 682800.1067577286, 180078.380835982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6296400.0000, 
sim time next is 6297000.0000, 
raw observation next is [26.83333333333333, 72.0, 1.0, 2.0, 0.2976746710892184, 1.0, 2.0, 0.2976746710892184, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683662.2588360508, 683662.2588360512, 180161.2062836274], 
processed observation next is [0.0, 0.9130434782608695, 0.5493827160493825, 0.72, 1.0, 1.0, 0.16389841796335525, 1.0, 1.0, 0.16389841796335525, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24416509244144669, 0.24416509244144685, 0.346463858237745], 
reward next is 0.6535, 
noisyNet noise sample is [array([-0.84869903], dtype=float32), 0.86977816]. 
=============================================
[2019-03-24 01:25:38,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.3568  ]
 [73.397026]
 [73.43608 ]
 [73.467865]
 [73.4955  ]], R is [[73.19286346]
 [73.11463165]
 [73.03681946]
 [72.95952606]
 [72.88285828]].
[2019-03-24 01:25:45,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8227951e-10 1.5791252e-02 1.7993296e-17 9.8420876e-01 2.2564683e-14], sum to 1.0000
[2019-03-24 01:25:45,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4146
[2019-03-24 01:25:45,614] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666666, 83.16666666666667, 1.0, 2.0, 0.4910135981878534, 1.0, 2.0, 0.4910135981878534, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1119467.978034957, 1119467.978034957, 232617.7874344346], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6491400.0000, 
sim time next is 6492000.0000, 
raw observation next is [26.63333333333333, 83.33333333333334, 1.0, 2.0, 0.4582494545558721, 1.0, 2.0, 0.4582494545558721, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1044717.674859914, 1044717.674859914, 222773.2047514599], 
processed observation next is [1.0, 0.13043478260869565, 0.5419753086419752, 0.8333333333333335, 1.0, 1.0, 0.3550588744712764, 1.0, 1.0, 0.3550588744712764, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37311345530711215, 0.37311345530711215, 0.4284100091374229], 
reward next is 0.5716, 
noisyNet noise sample is [array([-1.2193902], dtype=float32), -0.33698088]. 
=============================================
[2019-03-24 01:25:45,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[45.883896]
 [45.691605]
 [45.297623]
 [44.91548 ]
 [44.504135]], R is [[46.07026291]
 [46.16222   ]
 [46.2730217 ]
 [46.37565994]
 [46.45841599]].
[2019-03-24 01:25:47,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2427173e-09 1.2342539e-02 1.7787135e-16 9.8765743e-01 4.9204544e-14], sum to 1.0000
[2019-03-24 01:25:47,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-24 01:25:47,297] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.65, 55.0, 1.0, 2.0, 0.9754608416834831, 1.0, 2.0, 0.9754608416834831, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2225436.851004463, 2225436.851004463, 421591.4770466593], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6451800.0000, 
sim time next is 6452400.0000, 
raw observation next is [31.6, 55.0, 1.0, 2.0, 0.9290047789797007, 1.0, 2.0, 0.9290047789797007, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2119325.227174796, 2119325.227174797, 399944.4138451154], 
processed observation next is [1.0, 0.6956521739130435, 0.725925925925926, 0.55, 1.0, 1.0, 0.9154818797377389, 1.0, 1.0, 0.9154818797377389, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7569018668481415, 0.7569018668481419, 0.7691238727790681], 
reward next is 0.2309, 
noisyNet noise sample is [array([1.9393516], dtype=float32), -1.7892581]. 
=============================================
[2019-03-24 01:25:49,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5639783e-08 1.2918436e-02 4.1990790e-16 9.8708159e-01 1.2084021e-14], sum to 1.0000
[2019-03-24 01:25:49,101] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6889
[2019-03-24 01:25:49,106] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 86.0, 1.0, 2.0, 0.4143916741840187, 1.0, 2.0, 0.4143916741840187, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944669.0211754552, 944669.0211754557, 210177.6150553583], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6498000.0000, 
sim time next is 6498600.0000, 
raw observation next is [26.3, 86.16666666666667, 1.0, 2.0, 0.4144557599439915, 1.0, 2.0, 0.4144557599439915, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944815.2044985482, 944815.2044985486, 210195.5468283191], 
processed observation next is [1.0, 0.21739130434782608, 0.5296296296296297, 0.8616666666666667, 1.0, 1.0, 0.30292352374284703, 1.0, 1.0, 0.30292352374284703, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33743400160662435, 0.3374340016066245, 0.40422220543907517], 
reward next is 0.5958, 
noisyNet noise sample is [array([1.2354577], dtype=float32), 1.7587314]. 
=============================================
[2019-03-24 01:25:53,828] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 01:25:53,829] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:25:53,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:25:53,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:25:53,831] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:25:53,832] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:25:53,834] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:25:53,831] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:25:53,836] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:25:53,835] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:25:53,836] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:25:53,852] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-24 01:25:53,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-24 01:25:53,853] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-24 01:25:53,904] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-24 01:25:53,930] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-24 01:26:17,080] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.46296838]
[2019-03-24 01:26:17,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.67703360833333, 82.71379955166667, 1.0, 2.0, 0.1935882680953105, 1.0, 2.0, 0.1935882680953105, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479471.2553052248, 479471.2553052248, 158567.8910746584]
[2019-03-24 01:26:17,170] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:26:17,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2142342e-14 2.3737834e-06 3.3032314e-24 9.9999762e-01 5.7213446e-21], sampled 0.33568896857692776
[2019-03-24 01:26:24,160] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.46296838]
[2019-03-24 01:26:24,161] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.05324552666667, 80.74244928666667, 1.0, 2.0, 0.2552251166675702, 1.0, 2.0, 0.2552251166675702, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601437.7730281841, 601437.7730281841, 171013.3336169545]
[2019-03-24 01:26:24,163] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:26:24,167] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.7961167e-15 1.3082140e-06 2.8028403e-25 9.9999869e-01 6.8063570e-22], sampled 0.20096158526780006
[2019-03-24 01:26:48,833] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.46296838]
[2019-03-24 01:26:48,834] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.84713363666667, 58.48167392333333, 1.0, 2.0, 0.2182763492727349, 1.0, 2.0, 0.2182763492727349, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 531005.1200733897, 531005.1200733902, 163528.6536134594]
[2019-03-24 01:26:48,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:26:48,840] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.4882685e-16 4.2848828e-07 2.7584280e-27 9.9999952e-01 1.2615113e-23], sampled 0.1756705507581311
[2019-03-24 01:27:01,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.46296838]
[2019-03-24 01:27:01,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.3863810800711315, 1.0, 2.0, 0.3863810800711315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880777.9062713592, 880777.9062713597, 202483.2203446152]
[2019-03-24 01:27:01,674] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:27:01,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6436978e-15 8.3012958e-07 4.2624722e-26 9.9999917e-01 1.3397815e-22], sampled 0.08189890477742745
[2019-03-24 01:27:38,926] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 01:27:39,388] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 01:27:39,421] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 01:27:39,450] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 01:27:39,626] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 01:27:40,643] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 600000, evaluation results [600000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 01:27:42,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8774290e-11 4.3446380e-05 1.9414755e-20 9.9995661e-01 1.9089666e-17], sum to 1.0000
[2019-03-24 01:27:42,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2324
[2019-03-24 01:27:42,427] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 45.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399534.3522952533, 399534.3522952533, 150071.0400619562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6667200.0000, 
sim time next is 6667800.0000, 
raw observation next is [22.98333333333333, 44.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400638.268411719, 400638.268411719, 150209.82778286], 
processed observation next is [1.0, 0.17391304347826086, 0.40679012345679005, 0.4483333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14308509586132823, 0.14308509586132823, 0.28886505342857693], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5837448], dtype=float32), 1.1356077]. 
=============================================
[2019-03-24 01:27:44,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3953204e-07 2.0561870e-03 3.1284849e-13 9.9794322e-01 4.1893173e-12], sum to 1.0000
[2019-03-24 01:27:44,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4264
[2019-03-24 01:27:44,106] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.05, 33.5, 1.0, 2.0, 0.4141005405500501, 1.0, 2.0, 0.4141005405500501, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1036723.646791521, 1036723.646791521, 213379.9705491455], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6696600.0000, 
sim time next is 6697200.0000, 
raw observation next is [28.2, 33.0, 1.0, 2.0, 0.3147452833719392, 1.0, 2.0, 0.3147452833719392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 789493.5023644894, 789493.5023644898, 186622.9371905049], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.33, 1.0, 1.0, 0.18422057544278475, 1.0, 1.0, 0.18422057544278475, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2819619651301748, 0.28196196513017496, 0.358890263827894], 
reward next is 0.6411, 
noisyNet noise sample is [array([1.34543], dtype=float32), -0.438038]. 
=============================================
[2019-03-24 01:27:50,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8857995e-14 2.3300608e-04 2.2992782e-23 9.9976701e-01 3.6759923e-21], sum to 1.0000
[2019-03-24 01:27:50,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-24 01:27:50,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 73.0, 1.0, 2.0, 0.239770645876373, 1.0, 2.0, 0.239770645876373, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573521.5870802063, 573521.5870802063, 167901.4574354938], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6814800.0000, 
sim time next is 6815400.0000, 
raw observation next is [24.43333333333333, 73.66666666666667, 1.0, 2.0, 0.2395944213266452, 1.0, 2.0, 0.2395944213266452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572851.3072298729, 572851.3072298734, 167852.3589767032], 
processed observation next is [1.0, 0.9130434782608695, 0.4604938271604937, 0.7366666666666667, 1.0, 1.0, 0.09475526348410145, 1.0, 1.0, 0.09475526348410145, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20458975258209747, 0.20458975258209763, 0.3227929980321215], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.30652273], dtype=float32), -0.46524897]. 
=============================================
[2019-03-24 01:27:52,291] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9565969e-16 1.8793898e-07 1.5859498e-26 9.9999976e-01 2.2016078e-23], sum to 1.0000
[2019-03-24 01:27:52,303] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2069
[2019-03-24 01:27:52,307] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.43333333333333, 73.66666666666667, 1.0, 2.0, 0.2395944213266452, 1.0, 2.0, 0.2395944213266452, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572851.3072298729, 572851.3072298734, 167852.3589767032], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6815400.0000, 
sim time next is 6816000.0000, 
raw observation next is [24.36666666666667, 74.33333333333334, 1.0, 2.0, 0.2390616927548897, 1.0, 2.0, 0.2390616927548897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571272.1156407197, 571272.1156407197, 167721.6252904769], 
processed observation next is [1.0, 0.9130434782608695, 0.4580246913580248, 0.7433333333333334, 1.0, 1.0, 0.09412106280344011, 1.0, 1.0, 0.09412106280344011, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2040257555859713, 0.2040257555859713, 0.3225415870970709], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.40636846], dtype=float32), 0.18951802]. 
=============================================
[2019-03-24 01:27:52,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.14025 ]
 [73.708664]
 [73.58852 ]
 [73.45942 ]
 [73.331696]], R is [[74.28570557]
 [74.22005463]
 [74.15496826]
 [74.09098053]
 [74.02801514]].
[2019-03-24 01:27:58,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4827232e-12 1.0499641e-05 1.1776654e-21 9.9998951e-01 1.7500271e-17], sum to 1.0000
[2019-03-24 01:27:58,963] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6857
[2019-03-24 01:27:58,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.73333333333333, 59.16666666666666, 1.0, 2.0, 0.2544083581665328, 1.0, 2.0, 0.2544083581665328, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599965.4252305895, 599965.4252305895, 170847.6656576304], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6951000.0000, 
sim time next is 6951600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.2551154771259601, 1.0, 2.0, 0.2551154771259601, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 601211.1909503365, 601211.190950337, 170989.900809669], 
processed observation next is [0.0, 0.4782608695652174, 0.5925925925925926, 0.58, 1.0, 1.0, 0.11323271086423822, 1.0, 1.0, 0.11323271086423822, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21471828248226305, 0.2147182824822632, 0.3288267323262865], 
reward next is 0.6712, 
noisyNet noise sample is [array([-0.2556256], dtype=float32), 0.17308225]. 
=============================================
[2019-03-24 01:28:01,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1854280e-12 1.3523784e-05 4.4697272e-23 9.9998653e-01 2.6163105e-19], sum to 1.0000
[2019-03-24 01:28:01,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1687
[2019-03-24 01:28:01,622] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.48333333333333, 71.16666666666667, 1.0, 2.0, 0.6266642757587222, 1.0, 2.0, 0.6266642757587222, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1461748.333976065, 1461748.333976066, 278902.4624944309], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7038600.0000, 
sim time next is 7039200.0000, 
raw observation next is [25.66666666666667, 70.33333333333334, 1.0, 2.0, 0.6004057938767641, 1.0, 2.0, 0.6004057938767641, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1399212.517497916, 1399212.517497916, 269615.9244018758], 
processed observation next is [1.0, 0.4782608695652174, 0.506172839506173, 0.7033333333333335, 1.0, 1.0, 0.5242926117580524, 1.0, 1.0, 0.5242926117580524, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4997187562492557, 0.4997187562492557, 0.5184921623112997], 
reward next is 0.4815, 
noisyNet noise sample is [array([0.35684672], dtype=float32), 0.20861115]. 
=============================================
[2019-03-24 01:28:07,712] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1149789e-17 5.3222936e-07 3.2026485e-30 9.9999952e-01 1.5737223e-25], sum to 1.0000
[2019-03-24 01:28:07,723] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4355
[2019-03-24 01:28:07,726] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.63333333333333, 76.5, 1.0, 2.0, 0.2107325859266243, 1.0, 2.0, 0.2107325859266243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514864.677233495, 514864.6772334955, 161982.2997368341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7095000.0000, 
sim time next is 7095600.0000, 
raw observation next is [22.5, 77.0, 1.0, 2.0, 0.2097660260985603, 1.0, 2.0, 0.2097660260985603, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513007.2668827572, 513007.2668827577, 161792.3104051511], 
processed observation next is [1.0, 0.13043478260869565, 0.3888888888888889, 0.77, 1.0, 1.0, 0.05924526916495273, 1.0, 1.0, 0.05924526916495273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18321688102955613, 0.18321688102955633, 0.3111390584714444], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.8071568], dtype=float32), 0.063136354]. 
=============================================
[2019-03-24 01:28:09,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2862978e-17 5.1808332e-08 9.1934649e-33 1.0000000e+00 6.6083494e-27], sum to 1.0000
[2019-03-24 01:28:09,072] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9500
[2019-03-24 01:28:09,079] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.1833163988597837, 1.0, 2.0, 0.1833163988597837, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455359.204793984, 455359.2047939844, 156465.3031379285], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7149600.0000, 
sim time next is 7150200.0000, 
raw observation next is [21.81666666666667, 74.16666666666667, 1.0, 2.0, 0.1839834393254212, 1.0, 2.0, 0.1839834393254212, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 457063.5208351429, 457063.5208351433, 156605.8703532465], 
processed observation next is [1.0, 0.782608695652174, 0.3635802469135804, 0.7416666666666667, 1.0, 1.0, 0.028551713482644268, 1.0, 1.0, 0.028551713482644268, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16323697172683674, 0.16323697172683688, 0.3011651352947048], 
reward next is 0.6988, 
noisyNet noise sample is [array([-0.15334882], dtype=float32), 0.26082864]. 
=============================================
[2019-03-24 01:28:10,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7388394e-17 1.0269918e-08 1.7948268e-28 1.0000000e+00 1.6115132e-21], sum to 1.0000
[2019-03-24 01:28:10,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7487
[2019-03-24 01:28:10,475] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.8, 90.33333333333334, 1.0, 2.0, 0.1836054531180619, 1.0, 2.0, 0.1836054531180619, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455727.6475576625, 455727.6475576625, 156515.9747189472], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7170000.0000, 
sim time next is 7170600.0000, 
raw observation next is [19.8, 90.66666666666667, 1.0, 2.0, 0.1846990574542716, 1.0, 2.0, 0.1846990574542716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 458186.8068123186, 458186.806812319, 156737.3125348288], 
processed observation next is [1.0, 1.0, 0.2888888888888889, 0.9066666666666667, 1.0, 1.0, 0.029403639826513797, 1.0, 1.0, 0.029403639826513797, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1636381452901138, 0.16363814529011392, 0.3014179087208246], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.42201206], dtype=float32), -0.9030215]. 
=============================================
[2019-03-24 01:28:14,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6189969e-14 1.3869814e-06 1.2125625e-23 9.9999857e-01 2.8678687e-21], sum to 1.0000
[2019-03-24 01:28:14,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2308
[2019-03-24 01:28:14,529] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.1952452492285122, 1.0, 2.0, 0.1952452492285122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 480080.1603252466, 480080.1603252471, 158812.4754689144], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7279200.0000, 
sim time next is 7279800.0000, 
raw observation next is [20.55, 90.0, 1.0, 2.0, 0.1949827789862134, 1.0, 2.0, 0.1949827789862134, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479069.37230135, 479069.3723013505, 158746.4067978575], 
processed observation next is [1.0, 0.2608695652173913, 0.3166666666666667, 0.9, 1.0, 1.0, 0.04164616545977787, 1.0, 1.0, 0.04164616545977787, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17109620439333928, 0.17109620439333947, 0.30528155153434133], 
reward next is 0.6947, 
noisyNet noise sample is [array([2.5190446], dtype=float32), -1.0107025]. 
=============================================
[2019-03-24 01:28:19,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7981194e-17 2.1277258e-09 1.3321924e-32 1.0000000e+00 5.9526354e-27], sum to 1.0000
[2019-03-24 01:28:19,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6050
[2019-03-24 01:28:19,648] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.55, 75.5, 1.0, 2.0, 0.2250122434597538, 1.0, 2.0, 0.2250122434597538, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543408.8420226715, 543408.842022672, 164852.1604217277], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7331400.0000, 
sim time next is 7332000.0000, 
raw observation next is [23.4, 76.33333333333334, 1.0, 2.0, 0.2251279645475715, 1.0, 2.0, 0.2251279645475715, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543909.8304822799, 543909.8304822803, 164885.5500411713], 
processed observation next is [1.0, 0.8695652173913043, 0.42222222222222217, 0.7633333333333334, 1.0, 1.0, 0.07753329112806132, 1.0, 1.0, 0.07753329112806132, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19425351088652854, 0.1942535108865287, 0.3170875962330217], 
reward next is 0.6829, 
noisyNet noise sample is [array([-0.11369862], dtype=float32), 2.230823]. 
=============================================
[2019-03-24 01:28:19,665] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.41067 ]
 [76.50563 ]
 [76.47837 ]
 [76.517136]
 [76.43708 ]], R is [[76.29220581]
 [76.21225739]
 [76.13323212]
 [76.0550766 ]
 [75.97758484]].
[2019-03-24 01:28:22,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1189666e-19 1.1628116e-11 1.8007778e-30 1.0000000e+00 2.0931376e-27], sum to 1.0000
[2019-03-24 01:28:22,827] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9530
[2019-03-24 01:28:22,832] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.3, 92.0, 1.0, 2.0, 0.1943683786610348, 1.0, 2.0, 0.1943683786610348, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 477629.7916401061, 477629.7916401066, 158620.5623791558], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7459200.0000, 
sim time next is 7459800.0000, 
raw observation next is [20.46666666666667, 91.5, 1.0, 2.0, 0.1960235589898244, 1.0, 2.0, 0.1960235589898244, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481037.2848531922, 481037.2848531926, 158945.0897183628], 
processed observation next is [0.0, 0.34782608695652173, 0.31358024691358033, 0.915, 1.0, 1.0, 0.04288518927360048, 1.0, 1.0, 0.04288518927360048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1717990303047115, 0.17179903030471166, 0.3056636340737746], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.0981144], dtype=float32), -1.4971756]. 
=============================================
[2019-03-24 01:28:22,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4531364e-18 4.5561685e-10 1.5114442e-25 1.0000000e+00 1.0101600e-23], sum to 1.0000
[2019-03-24 01:28:22,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9362
[2019-03-24 01:28:23,001] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 91.16666666666667, 1.0, 2.0, 0.3704879065319603, 1.0, 2.0, 0.3704879065319603, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 891360.1030494439, 891360.1030494444, 200215.0584397641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7397400.0000, 
sim time next is 7398000.0000, 
raw observation next is [21.3, 91.0, 1.0, 2.0, 0.4041961607245662, 1.0, 2.0, 0.4041961607245662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 972304.9031433752, 972304.9031433756, 209486.9281724183], 
processed observation next is [1.0, 0.6521739130434783, 0.3444444444444445, 0.91, 1.0, 1.0, 0.29070971514829314, 1.0, 1.0, 0.29070971514829314, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.347251751122634, 0.3472517511226342, 0.40285947725465054], 
reward next is 0.5971, 
noisyNet noise sample is [array([-1.5625708], dtype=float32), -0.14558174]. 
=============================================
[2019-03-24 01:28:23,026] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.646404]
 [63.505672]
 [63.325165]
 [63.32629 ]
 [63.322964]], R is [[63.56087112]
 [63.54023361]
 [63.51356888]
 [63.4703064 ]
 [63.43274689]].
[2019-03-24 01:28:24,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2997119e-18 4.7203630e-11 1.0841489e-30 1.0000000e+00 1.5462242e-26], sum to 1.0000
[2019-03-24 01:28:24,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6801
[2019-03-24 01:28:24,936] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.2, 96.0, 1.0, 2.0, 0.1847642126474941, 1.0, 2.0, 0.1847642126474941, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 458144.6642470029, 458144.6642470033, 156745.1667312182], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7444800.0000, 
sim time next is 7445400.0000, 
raw observation next is [19.15, 96.16666666666666, 1.0, 2.0, 0.1840680518286798, 1.0, 2.0, 0.1840680518286798, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456594.4384761308, 456594.4384761308, 156604.6739992471], 
processed observation next is [0.0, 0.17391304347826086, 0.2648148148148148, 0.9616666666666666, 1.0, 1.0, 0.028652442653190238, 1.0, 1.0, 0.028652442653190238, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16306944231290385, 0.16306944231290385, 0.3011628346139368], 
reward next is 0.6988, 
noisyNet noise sample is [array([1.4822584], dtype=float32), -0.83608496]. 
=============================================
[2019-03-24 01:28:28,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0650962e-14 1.4519111e-08 3.9968678e-27 1.0000000e+00 1.4264680e-23], sum to 1.0000
[2019-03-24 01:28:28,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5141
[2019-03-24 01:28:28,031] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.2, 96.0, 1.0, 2.0, 0.2291226508423941, 1.0, 2.0, 0.2291226508423941, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550094.4537530479, 550094.4537530483, 165629.7892154221], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [21.15, 96.0, 1.0, 2.0, 0.2282419497198685, 1.0, 2.0, 0.2282419497198685, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548422.7231916204, 548422.7231916209, 165453.9303148692], 
processed observation next is [0.0, 0.043478260869565216, 0.33888888888888885, 0.96, 1.0, 1.0, 0.08124041633317679, 1.0, 1.0, 0.08124041633317679, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19586525828272158, 0.19586525828272175, 0.31818063522090234], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.35398674], dtype=float32), 1.2607509]. 
=============================================
[2019-03-24 01:28:28,043] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.4588  ]
 [65.467636]
 [65.462006]
 [65.48604 ]
 [65.53333 ]], R is [[65.45667267]
 [65.48358917]
 [65.509758  ]
 [65.53526306]
 [65.56030273]].
[2019-03-24 01:28:28,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4683606e-17 1.1136674e-07 1.5580439e-31 9.9999988e-01 7.4895698e-23], sum to 1.0000
[2019-03-24 01:28:28,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3316
[2019-03-24 01:28:28,409] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.2402550736596928, 1.0, 2.0, 0.2402550736596928, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978136, 167895.3997496155], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7513200.0000, 
sim time next is 7513800.0000, 
raw observation next is [21.75, 95.0, 1.0, 2.0, 0.2395838638364578, 1.0, 2.0, 0.2395838638364578, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803318, 167763.397366431], 
processed observation next is [0.0, 1.0, 0.3611111111111111, 0.95, 1.0, 1.0, 0.09474269504340214, 1.0, 1.0, 0.09474269504340214, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20381316452868978, 0.20381316452868994, 0.3226219180123673], 
reward next is 0.6774, 
noisyNet noise sample is [array([1.7398285], dtype=float32), 1.7136549]. 
=============================================
[2019-03-24 01:28:28,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2096859e-14 7.2403061e-08 4.0914381e-24 9.9999988e-01 1.8933809e-20], sum to 1.0000
[2019-03-24 01:28:28,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8975
[2019-03-24 01:28:28,770] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.41666666666666, 62.0, 1.0, 2.0, 0.2596328505161408, 1.0, 2.0, 0.2596328505161408, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609676.6512104865, 609676.6512104865, 171923.8313191254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7577400.0000, 
sim time next is 7578000.0000, 
raw observation next is [27.3, 62.0, 1.0, 2.0, 0.2567814082614762, 1.0, 2.0, 0.2567814082614762, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441992, 171329.0931738438], 
processed observation next is [0.0, 0.7391304347826086, 0.5666666666666667, 0.62, 1.0, 1.0, 0.11521596221604312, 1.0, 1.0, 0.11521596221604312, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21579624565864255, 0.21579624565864255, 0.329479025334315], 
reward next is 0.6705, 
noisyNet noise sample is [array([1.0412928], dtype=float32), 0.6435509]. 
=============================================
[2019-03-24 01:28:28,794] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[60.961674]
 [60.92181 ]
 [60.86488 ]
 [60.805676]
 [60.740944]], R is [[61.06694794]
 [61.12565613]
 [61.18259811]
 [61.23781204]
 [61.29144287]].
[2019-03-24 01:28:29,573] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 01:28:29,574] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:28:29,575] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:28:29,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:29,576] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:28:29,575] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:29,577] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:29,576] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:28:29,577] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:28:29,579] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:29,579] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:29,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-24 01:28:29,621] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-24 01:28:29,644] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-24 01:28:29,666] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-24 01:28:29,688] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-24 01:28:49,410] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48349714]
[2019-03-24 01:28:49,412] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.26666666666667, 78.66666666666667, 1.0, 2.0, 0.3525286603627746, 1.0, 2.0, 0.3525286603627746, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880580.877161484, 880580.8771614844, 196330.6887380712]
[2019-03-24 01:28:49,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:28:49,416] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7866473e-16 3.3116421e-09 1.0756193e-27 1.0000000e+00 4.7567188e-24], sampled 0.3460046429851581
[2019-03-24 01:29:21,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48349714]
[2019-03-24 01:29:21,563] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.81876213666666, 87.79420111666667, 1.0, 2.0, 0.2835224706247762, 1.0, 2.0, 0.2835224706247762, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 671095.3090938991, 671095.3090938996, 177705.4764536853]
[2019-03-24 01:29:21,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:29:21,566] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2137388e-17 7.7475992e-10 1.0680622e-29 1.0000000e+00 8.7730318e-26], sampled 0.13607544650758785
[2019-03-24 01:29:26,680] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48349714]
[2019-03-24 01:29:26,682] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.4, 91.0, 1.0, 2.0, 0.3082145445432487, 1.0, 2.0, 0.3082145445432487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 741529.9549785248, 741529.9549785253, 184130.213558306]
[2019-03-24 01:29:26,685] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:29:26,690] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3073235e-17 1.3315018e-09 5.9604462e-29 1.0000000e+00 3.8867495e-25], sampled 0.2032344644034929
[2019-03-24 01:29:44,472] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48349714]
[2019-03-24 01:29:44,473] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.5, 54.0, 1.0, 2.0, 0.3141065881002899, 1.0, 2.0, 0.3141065881002899, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715947.0969139375, 715947.096913938, 183880.6334178717]
[2019-03-24 01:29:44,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:29:44,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4645746e-18 5.9583893e-10 4.6399617e-30 1.0000000e+00 4.2625409e-26], sampled 0.07825382013519111
[2019-03-24 01:29:54,452] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48349714]
[2019-03-24 01:29:54,453] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.53417914333334, 89.5498413, 1.0, 2.0, 0.6606165608530723, 1.0, 2.0, 0.6606165608530723, 0.0, 2.0, 0.0, 6.9112, 6.9112, 124.4689129583361, 1506497.864781596, 1506497.864781596, 289925.2753612665]
[2019-03-24 01:29:54,454] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:29:54,457] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.17977545e-17 7.62968078e-10 1.01741959e-29 1.00000000e+00
 8.41075300e-26], sampled 0.8664059423303908
[2019-03-24 01:30:14,329] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 01:30:14,611] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 01:30:14,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 01:30:14,978] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 01:30:15,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 01:30:16,082] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 625000, evaluation results [625000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 01:30:17,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9245209e-17 8.6703603e-11 4.4516462e-24 1.0000000e+00 3.0144464e-23], sum to 1.0000
[2019-03-24 01:30:17,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-24 01:30:17,521] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 66.0, 1.0, 2.0, 0.2733747607974645, 1.0, 2.0, 0.2733747607974645, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 633328.8675052646, 633328.867505265, 174702.469886679], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7569000.0000, 
sim time next is 7569600.0000, 
raw observation next is [27.66666666666666, 66.0, 1.0, 2.0, 0.277509739635078, 1.0, 2.0, 0.277509739635078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 640866.6289445808, 640866.6289445813, 175567.8477126367], 
processed observation next is [0.0, 0.6086956521739131, 0.5802469135802467, 0.66, 1.0, 1.0, 0.1398925471846167, 1.0, 1.0, 0.1398925471846167, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22888093890877886, 0.22888093890877903, 0.3376304763704552], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.27031487], dtype=float32), 0.21869063]. 
=============================================
[2019-03-24 01:30:27,205] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1427322e-15 3.4437093e-08 3.3847593e-25 1.0000000e+00 2.8045808e-22], sum to 1.0000
[2019-03-24 01:30:27,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2969
[2019-03-24 01:30:27,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333334, 46.0, 1.0, 2.0, 0.6229239491956022, 1.0, 2.0, 0.6229239491956022, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1471609.438195808, 1471609.438195808, 278378.0758449709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7741200.0000, 
sim time next is 7741800.0000, 
raw observation next is [29.5, 46.5, 1.0, 2.0, 0.6293567022825001, 1.0, 2.0, 0.6293567022825001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1484686.083948816, 1484686.083948816, 280588.5627015592], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.465, 1.0, 1.0, 0.5587579789077382, 1.0, 1.0, 0.5587579789077382, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.53024502998172, 0.53024502998172, 0.5395933898106908], 
reward next is 0.4604, 
noisyNet noise sample is [array([-0.20113617], dtype=float32), -2.360655]. 
=============================================
[2019-03-24 01:30:29,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9152315e-13 4.0519346e-08 2.2162775e-24 1.0000000e+00 1.1678356e-21], sum to 1.0000
[2019-03-24 01:30:29,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0007
[2019-03-24 01:30:29,071] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.28333333333333, 65.16666666666666, 1.0, 2.0, 0.206196092366918, 1.0, 2.0, 0.206196092366918, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504448.5323179531, 504448.5323179527, 161037.9950651999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7761000.0000, 
sim time next is 7761600.0000, 
raw observation next is [24.0, 66.0, 1.0, 2.0, 0.2042624602316249, 1.0, 2.0, 0.2042624602316249, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970243, 500729.4896970248, 160660.7870382279], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.66, 1.0, 1.0, 0.05269340503764868, 1.0, 1.0, 0.05269340503764868, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17883196060608011, 0.17883196060608028, 0.3089630519965921], 
reward next is 0.6910, 
noisyNet noise sample is [array([0.34589222], dtype=float32), -0.014341862]. 
=============================================
[2019-03-24 01:30:32,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00248314e-14 1.72264125e-09 4.06419856e-25 1.00000000e+00
 1.37731151e-22], sum to 1.0000
[2019-03-24 01:30:32,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0326
[2019-03-24 01:30:32,674] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.61666666666667, 42.66666666666667, 1.0, 2.0, 0.2091431138387509, 1.0, 2.0, 0.2091431138387509, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506587.7141664604, 506587.7141664604, 161490.1109314103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7840200.0000, 
sim time next is 7840800.0000, 
raw observation next is [29.3, 44.0, 1.0, 2.0, 0.2120766555088316, 1.0, 2.0, 0.2120766555088316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513543.278049476, 513543.2780494764, 162110.2755627233], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.44, 1.0, 1.0, 0.06199601846289475, 1.0, 1.0, 0.06199601846289475, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18340831358909856, 0.1834083135890987, 0.3117505299283141], 
reward next is 0.6882, 
noisyNet noise sample is [array([1.2217629], dtype=float32), -1.4703754]. 
=============================================
[2019-03-24 01:30:36,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:36,524] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:36,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-24 01:30:37,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:37,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:37,670] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-24 01:30:37,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:37,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:37,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-24 01:30:38,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-24 01:30:38,314] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-24 01:30:38,359] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,361] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-24 01:30:38,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-24 01:30:38,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-24 01:30:38,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-24 01:30:38,693] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,693] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-24 01:30:38,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,794] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-24 01:30:38,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,848] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-24 01:30:38,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-24 01:30:38,955] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:38,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:38,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-24 01:30:39,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:39,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:39,091] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-24 01:30:39,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:30:39,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:30:39,255] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-24 01:30:40,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9802543e-16 9.4782411e-11 1.5393200e-27 1.0000000e+00 2.2148313e-25], sum to 1.0000
[2019-03-24 01:30:40,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8775
[2019-03-24 01:30:40,544] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.4, 75.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 392969.4682731695, 392969.4682731699, 149201.6955237608], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [18.35, 75.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 398441.248475043, 398441.2484750435, 149997.589867915], 
processed observation next is [1.0, 0.08695652173913043, 0.23518518518518525, 0.7583333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14230044588394392, 0.1423004458839441, 0.2884569035921442], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.82263803], dtype=float32), -2.0978389]. 
=============================================
[2019-03-24 01:30:41,499] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5826537e-10 2.0961879e-06 1.7473028e-14 9.9999785e-01 7.3899778e-13], sum to 1.0000
[2019-03-24 01:30:41,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3443
[2019-03-24 01:30:41,514] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 43.0, 1.0, 2.0, 0.3691360173987881, 1.0, 2.0, 0.3691360173987881, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 929037.9418627203, 929037.9418627208, 200902.9674639234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 36000.0000, 
sim time next is 36600.0000, 
raw observation next is [25.73333333333333, 42.66666666666667, 1.0, 2.0, 0.3719937966520316, 1.0, 2.0, 0.3719937966520316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 934249.3013005966, 934249.301300597, 201649.7811501454], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.4266666666666667, 1.0, 1.0, 0.25237356744289474, 1.0, 1.0, 0.25237356744289474, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33366046475021305, 0.3336604647502132, 0.38778804067335654], 
reward next is 0.6122, 
noisyNet noise sample is [array([-0.59402394], dtype=float32), 0.7136928]. 
=============================================
[2019-03-24 01:30:41,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3556584e-09 3.8781602e-07 6.6290879e-16 9.9999964e-01 6.4740037e-13], sum to 1.0000
[2019-03-24 01:30:41,832] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8540
[2019-03-24 01:30:41,835] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.0, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 319680.3761426542, 319680.3761426542, 132601.7100898294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 19800.0000, 
sim time next is 20400.0000, 
raw observation next is [18.0, 73.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 318143.4472765018, 318143.4472765023, 131684.7811820569], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.7366666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11362265974160779, 0.11362265974160797, 0.2532399638116479], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2409422], dtype=float32), -1.7339458]. 
=============================================
[2019-03-24 01:30:47,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2460436e-14 3.1761791e-09 8.8389870e-23 1.0000000e+00 1.6719175e-19], sum to 1.0000
[2019-03-24 01:30:47,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7882
[2019-03-24 01:30:47,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.3, 8.0, 1.0, 2.0, 0.6863585211917128, 1.0, 2.0, 0.6863585211917128, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1719025.904039602, 1719025.904039602, 304797.7999233896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 145200.0000, 
sim time next is 145800.0000, 
raw observation next is [37.3, 7.5, 1.0, 2.0, 0.6835907221443335, 1.0, 2.0, 0.6835907221443335, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1715149.386336982, 1715149.386336982, 303791.6617931032], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.075, 1.0, 1.0, 0.6233222882670636, 1.0, 1.0, 0.6233222882670636, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6125533522632078, 0.6125533522632078, 0.5842147342175061], 
reward next is 0.4158, 
noisyNet noise sample is [array([-0.9254517], dtype=float32), 0.52569544]. 
=============================================
[2019-03-24 01:30:50,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3075919e-07 6.0595725e-05 6.1105342e-13 9.9993932e-01 3.2049691e-10], sum to 1.0000
[2019-03-24 01:30:50,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-24 01:30:50,990] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.9, 14.66666666666667, 1.0, 2.0, 0.1871790318480135, 1.0, 2.0, 0.1871790318480135, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 478748.241021255, 478748.2410212555, 157485.351431661], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [33.1, 13.83333333333333, 1.0, 2.0, 0.1878623853515643, 1.0, 2.0, 0.1878623853515643, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979043, 157627.3217016878], 
processed observation next is [0.0, 0.5652173913043478, 0.7814814814814816, 0.1383333333333333, 1.0, 1.0, 0.033169506370909874, 1.0, 1.0, 0.033169506370909874, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17178849667782298, 0.17178849667782298, 0.30312946481093805], 
reward next is 0.6969, 
noisyNet noise sample is [array([-0.02358285], dtype=float32), -0.69510025]. 
=============================================
[2019-03-24 01:30:57,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1647556e-14 1.0000000e+00 1.1706703e-32 5.9600294e-09 4.9601441e-26], sum to 1.0000
[2019-03-24 01:30:57,772] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-24 01:30:57,775] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333334, 43.0, 1.0, 2.0, 0.2932592385387378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 377608.8539673844, 377608.853967384, 114738.8258633974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 339600.0000, 
sim time next is 340200.0000, 
raw observation next is [24.0, 43.5, 1.0, 2.0, 0.2919038243552602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375938.5143793615, 375938.5143793615, 114572.5366859188], 
processed observation next is [0.0, 0.9565217391304348, 0.4444444444444444, 0.435, 1.0, 1.0, 0.1570283623276907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13426375513548627, 0.13426375513548627, 0.22033180131907462], 
reward next is 0.7797, 
noisyNet noise sample is [array([0.6203834], dtype=float32), 1.0066503]. 
=============================================
[2019-03-24 01:30:58,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0929460e-12 9.9999964e-01 2.2623438e-24 3.2056749e-07 6.7743992e-22], sum to 1.0000
[2019-03-24 01:30:58,919] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8481
[2019-03-24 01:30:58,922] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 35.0, 1.0, 2.0, 0.7052131157444003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905575.2641721091, 905575.2641721091, 180295.3343873203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 378000.0000, 
sim time next is 378600.0000, 
raw observation next is [26.4, 34.5, 1.0, 2.0, 0.8563181533836159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.922452020368901, 6.9112, 121.926002644575, 1104591.097022721, 1098829.058788648, 211932.8331543257], 
processed observation next is [1.0, 0.391304347826087, 0.5333333333333333, 0.345, 1.0, 1.0, 0.8289501825995428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.001125202036890105, 0.0, 0.8094618634536865, 0.3944968203652575, 0.39243894956737435, 0.40756314068139554], 
reward next is 0.5362, 
noisyNet noise sample is [array([-0.7088957], dtype=float32), -2.01032]. 
=============================================
[2019-03-24 01:31:04,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7789542e-09 9.9999976e-01 2.8730433e-19 2.8371932e-07 5.3061363e-17], sum to 1.0000
[2019-03-24 01:31:04,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3336
[2019-03-24 01:31:04,244] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 41.33333333333334, 1.0, 2.0, 0.9153667708204895, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.152685039326468, 6.9112, 121.9249835665213, 1265209.917736824, 1141549.068040774, 225007.6978412651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469200.0000, 
sim time next is 469800.0000, 
raw observation next is [28.05, 40.5, 1.0, 2.0, 0.936479655595171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.307614768804655, 6.9112, 121.9241946761607, 1373293.683159265, 1170296.967093441, 230015.262266746], 
processed observation next is [1.0, 0.43478260869565216, 0.5944444444444444, 0.405, 1.0, 1.0, 0.9243805423752035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.039641476880465466, 0.0, 0.8094498604235703, 0.4904620296997375, 0.41796320253337177, 0.4423370428206654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00645352], dtype=float32), -0.2521707]. 
=============================================
[2019-03-24 01:31:04,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9344477e-14 1.0000000e+00 6.6814088e-25 3.1366199e-09 5.9680237e-21], sum to 1.0000
[2019-03-24 01:31:04,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9863
[2019-03-24 01:31:04,332] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.16666666666667, 26.33333333333334, 1.0, 2.0, 0.5255529881616083, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8638382451544168, 6.911199999999999, 6.9112, 121.9260426156618, 1291716.323750742, 1291716.323750742, 262608.0346166058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 485400.0000, 
sim time next is 486000.0000, 
raw observation next is [32.2, 26.0, 1.0, 2.0, 1.004673779569926, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.749204460612442, 6.9112, 121.9226119766746, 1681355.265911265, 1252234.156630178, 246481.2350224783], 
processed observation next is [1.0, 0.6521739130434783, 0.7481481481481482, 0.26, 1.0, 1.0, 1.0055640232975311, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.08380044606124422, 0.0, 0.809439352944874, 0.6004840235397375, 0.44722648451077784, 0.4740023750432275], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8579858], dtype=float32), 0.15339816]. 
=============================================
[2019-03-24 01:31:04,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.296295]
 [56.123226]
 [55.77275 ]
 [54.750286]
 [54.888603]], R is [[56.86539459]
 [56.79172516]
 [56.68981171]
 [56.5813942 ]
 [56.01557922]].
[2019-03-24 01:31:06,658] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 01:31:06,659] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:31:06,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:06,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:31:06,661] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:06,662] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:31:06,662] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:31:06,664] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:06,664] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:06,664] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:31:06,671] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:06,683] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-24 01:31:06,705] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-24 01:31:06,728] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-24 01:31:06,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-24 01:31:06,779] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-24 01:31:14,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48508918]
[2019-03-24 01:31:14,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.2, 67.66666666666667, 1.0, 2.0, 0.2251338910429266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 290397.2772618603, 290397.2772618598, 90449.90133774294]
[2019-03-24 01:31:14,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:31:14,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1988302e-10 9.9998724e-01 2.1274897e-22 1.2742516e-05 1.7540189e-18], sampled 0.48039544386660693
[2019-03-24 01:31:53,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48508918]
[2019-03-24 01:31:53,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.2, 59.33333333333333, 1.0, 2.0, 0.9476496022207587, 1.0, 2.0, 0.9476496022207587, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2161910.88716102, 2161910.88716102, 408546.0578621977]
[2019-03-24 01:31:53,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:31:53,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5188692e-12 9.9999762e-01 9.0539828e-26 2.3434402e-06 3.0741784e-21], sampled 0.4200297553732243
[2019-03-24 01:31:53,824] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2161910.88716102 W.
[2019-03-24 01:32:16,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48508918]
[2019-03-24 01:32:16,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6717273716628738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765563.0874924831, 765563.0874924826, 170862.0771313858]
[2019-03-24 01:32:16,901] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:32:16,903] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.6542904e-11 9.9998975e-01 7.9329033e-23 1.0270298e-05 7.8251705e-19], sampled 0.12195874389371575
[2019-03-24 01:32:37,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48508918]
[2019-03-24 01:32:37,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 66.0, 1.0, 2.0, 0.5761011361386391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667673.4299832692, 667673.4299832692, 154548.8650439561]
[2019-03-24 01:32:37,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:32:37,291] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2658476e-11 9.9999070e-01 5.1079801e-23 9.3276731e-06 5.4607920e-19], sampled 0.9195340606984017
[2019-03-24 01:32:47,874] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.48508918]
[2019-03-24 01:32:47,874] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.75, 33.83333333333334, 1.0, 2.0, 0.3182677122663834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405450.1186350725, 405450.118635072, 117859.9564847594]
[2019-03-24 01:32:47,878] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:32:47,884] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.02180285e-10 9.99988198e-01 1.49739141e-22 1.17991276e-05
 1.31604311e-18], sampled 0.6567681794138281
[2019-03-24 01:32:51,194] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:32:51,588] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:32:51,636] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.8338 2248680104.8793 553.0000
[2019-03-24 01:32:51,647] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:32:51,673] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:32:52,687] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 650000, evaluation results [650000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.833806464901, 2248680104.8793406, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:32:55,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8278931e-12 9.9998260e-01 1.2181402e-21 1.7447630e-05 9.2759124e-18], sum to 1.0000
[2019-03-24 01:32:55,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3283
[2019-03-24 01:32:55,751] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.1, 35.66666666666667, 1.0, 2.0, 0.3852835825060827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478208.0778363843, 478208.0778363843, 126583.3517199136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 588000.0000, 
sim time next is 588600.0000, 
raw observation next is [29.95, 36.0, 1.0, 2.0, 0.3838811703048735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476751.3385225848, 476751.3385225848, 126395.6538998972], 
processed observation next is [1.0, 0.8260869565217391, 0.6648148148148147, 0.36, 1.0, 1.0, 0.266525202743897, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17026833518663745, 0.17026833518663745, 0.24306856519210998], 
reward next is 0.7569, 
noisyNet noise sample is [array([-1.4794408], dtype=float32), -0.24201952]. 
=============================================
[2019-03-24 01:32:58,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0716705e-09 9.9999559e-01 1.1158452e-20 4.4009953e-06 6.8673187e-20], sum to 1.0000
[2019-03-24 01:32:58,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-24 01:32:58,366] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.71666666666667, 66.0, 1.0, 2.0, 0.3259983066991414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414029.3941627031, 414029.3941627031, 118838.3386751046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 625800.0000, 
sim time next is 626400.0000, 
raw observation next is [22.0, 65.0, 1.0, 2.0, 0.3291919683594992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417547.6164941831, 417547.6164941831, 119244.4324815846], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.65, 1.0, 1.0, 0.20141900995178477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14912414874792254, 0.14912414874792254, 0.22931621631073962], 
reward next is 0.7707, 
noisyNet noise sample is [array([-0.0621011], dtype=float32), -0.3972991]. 
=============================================
[2019-03-24 01:32:58,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7358380e-12 9.9999809e-01 1.6581030e-23 1.8688497e-06 7.0122411e-21], sum to 1.0000
[2019-03-24 01:32:58,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2038
[2019-03-24 01:32:58,653] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 53.0, 1.0, 2.0, 0.4922886365096949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616087.730119346, 616087.730119346, 142501.3983444929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 633600.0000, 
sim time next is 634200.0000, 
raw observation next is [25.65, 51.83333333333334, 1.0, 2.0, 0.4779964051570907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597505.5995872298, 597505.5995872298, 140255.3365924944], 
processed observation next is [1.0, 0.34782608695652173, 0.5055555555555555, 0.5183333333333334, 1.0, 1.0, 0.3785671489965366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2133948569954392, 0.2133948569954392, 0.2697218011394123], 
reward next is 0.7303, 
noisyNet noise sample is [array([-0.7343844], dtype=float32), -0.80302006]. 
=============================================
[2019-03-24 01:33:03,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2533996e-13 1.0000000e+00 1.3363047e-25 5.6465079e-11 1.7017076e-21], sum to 1.0000
[2019-03-24 01:33:03,489] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8176
[2019-03-24 01:33:03,493] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 53.66666666666667, 1.0, 2.0, 0.9103181716571105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.163527288703433, 6.9112, 121.9251462793076, 1272773.325267275, 1143560.150608481, 224006.0594571217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 721200.0000, 
sim time next is 721800.0000, 
raw observation next is [24.9, 53.5, 1.0, 2.0, 0.968574675130987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.549014907931839, 6.9112, 121.9232214373847, 1541699.861654386, 1215089.178979863, 237796.0977590043], 
processed observation next is [1.0, 0.34782608695652173, 0.47777777777777775, 0.535, 1.0, 1.0, 0.9625888989654607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.06378149079318388, 0.0, 0.8094433991301946, 0.550607093447995, 0.43396042106423677, 0.4573001879980852], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.509318], dtype=float32), -1.9522303]. 
=============================================
[2019-03-24 01:33:09,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2307729e-17 1.0000000e+00 1.9468208e-32 1.3865148e-12 3.2309008e-28], sum to 1.0000
[2019-03-24 01:33:09,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9817
[2019-03-24 01:33:09,077] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 52.33333333333334, 1.0, 2.0, 0.3692141146161365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461885.0981395594, 461885.0981395594, 124454.7929737234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 935400.0000, 
sim time next is 936000.0000, 
raw observation next is [25.3, 53.0, 1.0, 2.0, 0.3679012882718943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460425.8846916244, 460425.8846916244, 124280.0559414445], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.53, 1.0, 1.0, 0.247501533657017, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16443781596129442, 0.16443781596129442, 0.23900010757970097], 
reward next is 0.7610, 
noisyNet noise sample is [array([-1.2006541], dtype=float32), 1.4132508]. 
=============================================
[2019-03-24 01:33:09,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.3715  ]
 [72.40348 ]
 [72.43537 ]
 [72.46249 ]
 [72.473206]], R is [[72.38249207]
 [72.41933441]
 [72.45547485]
 [72.49094391]
 [72.52577972]].
[2019-03-24 01:33:16,406] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0946671e-15 1.0000000e+00 1.4426006e-30 1.5913931e-10 4.7063974e-24], sum to 1.0000
[2019-03-24 01:33:16,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2699
[2019-03-24 01:33:16,418] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.0, 1.0, 2.0, 0.2893191973240508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373209.212769734, 373209.212769734, 112660.0829748012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 961200.0000, 
sim time next is 961800.0000, 
raw observation next is [20.95, 58.33333333333334, 1.0, 2.0, 0.3401718822859179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438825.738604555, 438825.738604555, 119563.6406718922], 
processed observation next is [1.0, 0.13043478260869565, 0.33148148148148143, 0.5833333333333335, 1.0, 1.0, 0.21449033605466414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15672347807305537, 0.15672347807305537, 0.2299300782151773], 
reward next is 0.7701, 
noisyNet noise sample is [array([-0.32346562], dtype=float32), -0.028172895]. 
=============================================
[2019-03-24 01:33:19,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5306800e-16 1.0000000e+00 3.3995047e-36 1.2955892e-13 6.5681597e-28], sum to 1.0000
[2019-03-24 01:33:19,520] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2377
[2019-03-24 01:33:19,529] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.71666666666667, 47.5, 1.0, 2.0, 0.2912141426690363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 373448.2280913525, 373448.228091352, 114496.929719345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1021800.0000, 
sim time next is 1022400.0000, 
raw observation next is [24.2, 44.0, 1.0, 2.0, 0.2858875778603654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367218.219333115, 367218.219333115, 113847.3605599759], 
processed observation next is [1.0, 0.8695652173913043, 0.45185185185185184, 0.44, 1.0, 1.0, 0.14986616411948261, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13114936404754107, 0.13114936404754107, 0.2189372318461075], 
reward next is 0.7811, 
noisyNet noise sample is [array([1.2731776], dtype=float32), 0.17864075]. 
=============================================
[2019-03-24 01:33:22,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5707574e-12 9.9999964e-01 1.2131963e-25 2.9876469e-07 8.9884030e-20], sum to 1.0000
[2019-03-24 01:33:22,651] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2481
[2019-03-24 01:33:22,655] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 42.0, 1.0, 2.0, 0.8590978293620841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1083739.319574894, 1083739.319574894, 212424.8035439431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1090800.0000, 
sim time next is 1091400.0000, 
raw observation next is [26.66666666666666, 42.33333333333334, 1.0, 2.0, 0.9352190045395541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.356773885880745, 6.9112, 121.9243605425165, 1407587.73567661, 1179417.229012703, 229917.0750505536], 
processed observation next is [1.0, 0.6521739130434783, 0.5432098765432096, 0.42333333333333345, 1.0, 1.0, 0.9228797673089929, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04455738858807452, 0.0, 0.8094509616036839, 0.5027099055987893, 0.42122043893310823, 0.4421482212510646], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03302431], dtype=float32), 1.9388855]. 
=============================================
[2019-03-24 01:33:28,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7413698e-17 1.0000000e+00 3.3054443e-32 4.0604776e-11 2.0325344e-27], sum to 1.0000
[2019-03-24 01:33:28,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-24 01:33:28,882] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 90.0, 1.0, 2.0, 0.3485143357753054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439090.6535321958, 439090.6535321958, 121733.0009825939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1202400.0000, 
sim time next is 1203000.0000, 
raw observation next is [19.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3495238078883664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 440330.1255956798, 440330.1255956793, 121866.0178029454], 
processed observation next is [1.0, 0.9565217391304348, 0.2641975308641974, 0.9066666666666667, 1.0, 1.0, 0.2256235808194838, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1572607591413142, 0.15726075914131402, 0.23435772654412576], 
reward next is 0.7656, 
noisyNet noise sample is [array([1.3391957], dtype=float32), -1.2431229]. 
=============================================
[2019-03-24 01:33:28,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.77527 ]
 [78.76419 ]
 [78.790596]
 [78.81755 ]
 [78.81186 ]], R is [[78.72795105]
 [78.70657349]
 [78.68543243]
 [78.6646347 ]
 [78.64416504]].
[2019-03-24 01:33:33,532] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.797144e-13 9.999976e-01 9.488622e-29 2.395737e-06 7.212207e-21], sum to 1.0000
[2019-03-24 01:33:33,540] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6741
[2019-03-24 01:33:33,544] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.4095421816569274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505133.4675446501, 505133.4675446501, 129917.3779599373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1285200.0000, 
sim time next is 1285800.0000, 
raw observation next is [22.91666666666667, 74.0, 1.0, 2.0, 0.4073931142348451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502749.453168884, 502749.453168884, 129618.1884573517], 
processed observation next is [1.0, 0.9130434782608695, 0.4043209876543212, 0.74, 1.0, 1.0, 0.2945156121843394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17955337613174427, 0.17955337613174427, 0.24926574703336865], 
reward next is 0.7507, 
noisyNet noise sample is [array([-1.5988404], dtype=float32), 0.12858066]. 
=============================================
[2019-03-24 01:33:38,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0213521e-17 9.9998331e-01 5.4243109e-28 1.6726926e-05 9.7281405e-23], sum to 1.0000
[2019-03-24 01:33:38,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9986
[2019-03-24 01:33:38,351] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 47.16666666666666, 1.0, 2.0, 0.3122410126676226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396351.6650192451, 396351.6650192451, 117090.4799731505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1408200.0000, 
sim time next is 1408800.0000, 
raw observation next is [25.5, 46.33333333333333, 1.0, 2.0, 0.3176862812737647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402611.0206456096, 402611.0206456096, 117772.2486669651], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.46333333333333326, 1.0, 1.0, 0.18772176342114844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14378965023057486, 0.14378965023057486, 0.2264850935903175], 
reward next is 0.7735, 
noisyNet noise sample is [array([0.8470313], dtype=float32), 0.32609224]. 
=============================================
[2019-03-24 01:33:41,558] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 01:33:41,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:33:41,559] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:33:41,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:33:41,560] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:33:41,559] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:33:41,561] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:33:41,562] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:33:41,559] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:33:41,562] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:33:41,567] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:33:41,585] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-24 01:33:41,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-24 01:33:41,630] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-24 01:33:41,630] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-24 01:33:41,683] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-24 01:33:48,933] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.49910235]
[2019-03-24 01:33:48,934] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.44933445, 40.31013095666667, 1.0, 2.0, 0.5696020511734184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9130984208037942, 6.911199999999999, 6.9112, 121.9260425501638, 1346177.793769068, 1346177.793769068, 281187.5880433191]
[2019-03-24 01:33:48,935] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:33:48,937] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2280279e-11 9.9999559e-01 5.7444156e-25 4.4330136e-06 3.6907486e-19], sampled 0.283882104556341
[2019-03-24 01:33:48,938] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1346177.793769068 W.
[2019-03-24 01:34:19,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.49910235]
[2019-03-24 01:34:19,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.76666666666667, 93.66666666666667, 1.0, 2.0, 0.4668632020727522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 562814.4737017695, 562814.473701769, 137994.9788680333]
[2019-03-24 01:34:19,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:34:19,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9911202e-12 9.9999809e-01 9.7950686e-27 1.8584187e-06 1.6817963e-20], sampled 0.28965402748213964
[2019-03-24 01:34:40,262] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.49910235]
[2019-03-24 01:34:40,265] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.8, 83.0, 1.0, 2.0, 0.6836428328303706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779149.9590076822, 779149.9590076822, 173069.7228048954]
[2019-03-24 01:34:40,266] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:34:40,270] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9369849e-12 9.9999821e-01 9.2136288e-27 1.8337031e-06 1.6059266e-20], sampled 0.7541157733757534
[2019-03-24 01:35:05,603] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.49910235]
[2019-03-24 01:35:05,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.85, 87.0, 1.0, 2.0, 0.6093571944120318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719173.4672372431, 719173.4672372431, 160827.3831726168]
[2019-03-24 01:35:05,610] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:35:05,614] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8986926e-12 9.9999774e-01 2.2696587e-26 2.2242332e-06 3.1813744e-20], sampled 0.061245040728249434
[2019-03-24 01:35:24,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:35:25,029] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:35:25,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:35:25,186] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:35:25,235] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:35:26,249] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 675000, evaluation results [675000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:35:28,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2767603e-13 9.9999726e-01 6.7960383e-32 2.6876019e-06 7.1911227e-24], sum to 1.0000
[2019-03-24 01:35:28,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-24 01:35:28,626] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.96666666666667, 27.66666666666666, 1.0, 2.0, 0.4212594752889006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515594.0870352512, 515594.0870352517, 131494.3581827258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1511400.0000, 
sim time next is 1512000.0000, 
raw observation next is [34.1, 27.0, 1.0, 2.0, 0.4170290904303036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 511041.1909136, 511041.1909135996, 130902.7156969573], 
processed observation next is [0.0, 0.5217391304347826, 0.8185185185185185, 0.27, 1.0, 1.0, 0.30598701241702814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18251471104057143, 0.1825147110405713, 0.2517359917249179], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.4826362], dtype=float32), -0.44088766]. 
=============================================
[2019-03-24 01:35:28,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[82.666466]
 [82.46863 ]
 [82.268845]
 [82.05551 ]
 [81.80005 ]], R is [[82.78762054]
 [82.70687103]
 [82.62573242]
 [82.54419708]
 [82.46163177]].
[2019-03-24 01:35:29,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0834442e-12 9.9999666e-01 3.7627193e-31 3.3217577e-06 7.2002629e-23], sum to 1.0000
[2019-03-24 01:35:29,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2208
[2019-03-24 01:35:29,763] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.8, 20.0, 1.0, 2.0, 0.4154023829005045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514950.3441350589, 514950.3441350584, 130815.7064806316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1519200.0000, 
sim time next is 1519800.0000, 
raw observation next is [35.63333333333333, 21.16666666666667, 1.0, 2.0, 0.4301012811385961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532126.7258112546, 532126.7258112546, 132922.7652851475], 
processed observation next is [0.0, 0.6086956521739131, 0.8753086419753087, 0.21166666666666673, 1.0, 1.0, 0.32154914421261444, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1900452592183052, 0.1900452592183052, 0.2556207024714375], 
reward next is 0.7444, 
noisyNet noise sample is [array([0.99466807], dtype=float32), -1.2238332]. 
=============================================
[2019-03-24 01:35:30,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.4263852e-10 9.9994361e-01 4.6655758e-23 5.6356948e-05 1.7157210e-16], sum to 1.0000
[2019-03-24 01:35:30,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4911
[2019-03-24 01:35:30,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 76.5, 1.0, 2.0, 0.496140355854865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596880.7825688266, 596880.7825688266, 142472.1912430766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540200.0000, 
sim time next is 1540800.0000, 
raw observation next is [23.7, 79.0, 1.0, 2.0, 0.4910760330590257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592050.1420405145, 592050.1420405145, 141722.7921592199], 
processed observation next is [0.0, 0.8695652173913043, 0.4333333333333333, 0.79, 1.0, 1.0, 0.3941381345940782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21144647930018376, 0.21144647930018376, 0.2725438310754229], 
reward next is 0.7275, 
noisyNet noise sample is [array([-0.3173537], dtype=float32), 0.38210848]. 
=============================================
[2019-03-24 01:35:34,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.10488614e-11 9.07608151e-01 1.63896335e-24 9.23918635e-02
 2.46223626e-15], sum to 1.0000
[2019-03-24 01:35:34,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-24 01:35:34,843] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 51.5, 1.0, 2.0, 0.3361747634077341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424842.2911265926, 424842.2911265926, 120132.4257631971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1631400.0000, 
sim time next is 1632000.0000, 
raw observation next is [24.53333333333333, 52.00000000000001, 1.0, 2.0, 0.3408569719750899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430909.8144955377, 430909.8144955377, 120744.3711516927], 
processed observation next is [1.0, 0.9130434782608695, 0.46419753086419746, 0.52, 1.0, 1.0, 0.21530591901796417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1538963623198349, 0.1538963623198349, 0.23220071375325518], 
reward next is 0.7678, 
noisyNet noise sample is [array([0.58071524], dtype=float32), -1.166159]. 
=============================================
[2019-03-24 01:35:34,864] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.6871  ]
 [68.678894]
 [68.368454]
 [68.21977 ]
 [68.085236]], R is [[68.82637024]
 [68.9070816 ]
 [68.98712921]
 [69.0659256 ]
 [69.14335632]].
[2019-03-24 01:35:35,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1413441e-11 9.9964833e-01 3.6082574e-23 3.5166816e-04 2.9897071e-16], sum to 1.0000
[2019-03-24 01:35:35,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0638
[2019-03-24 01:35:35,435] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 41.5, 1.0, 2.0, 0.8809514751005451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.926858856024099, 6.9112, 121.9258789937655, 1107665.813341554, 1099647.090245499, 217128.0506100965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1614600.0000, 
sim time next is 1615200.0000, 
raw observation next is [27.93333333333333, 41.33333333333334, 1.0, 2.0, 0.884584176046647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.952286157674327, 6.9112, 121.9257659757748, 1125404.884238083, 1104365.147007219, 217956.4727127021], 
processed observation next is [1.0, 0.6956521739130435, 0.5901234567901233, 0.41333333333333344, 1.0, 1.0, 0.8626002095793416, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.004108615767432688, 0.0, 0.8094602922189714, 0.4019303157993153, 0.39441612393114966, 0.41914706290904247], 
reward next is 0.3754, 
noisyNet noise sample is [array([1.1195489], dtype=float32), 0.31796283]. 
=============================================
[2019-03-24 01:35:42,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1138400e-09 9.9957758e-01 3.2579739e-19 4.2247429e-04 1.7387715e-13], sum to 1.0000
[2019-03-24 01:35:42,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1203
[2019-03-24 01:35:42,240] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 86.5, 1.0, 2.0, 0.3678677610694014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459694.2830426893, 459694.2830426893, 124263.3245468323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [20.2, 87.0, 1.0, 2.0, 0.3666595404633242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458310.6505138573, 458310.6505138573, 124102.1657658223], 
processed observation next is [1.0, 0.17391304347826086, 0.3037037037037037, 0.87, 1.0, 1.0, 0.24602326245633835, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16368237518352047, 0.16368237518352047, 0.2386580110881198], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.8191966], dtype=float32), -0.5709602]. 
=============================================
[2019-03-24 01:35:51,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6772763e-08 9.9854726e-01 2.5155067e-21 1.4526802e-03 3.7408816e-13], sum to 1.0000
[2019-03-24 01:35:51,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9352
[2019-03-24 01:35:51,365] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 89.5, 1.0, 2.0, 0.6940574445489933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856109.9264352293, 856109.9264352293, 177633.9631878823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [20.96666666666667, 89.33333333333333, 1.0, 2.0, 0.7194215747614887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886016.5895010707, 886016.5895010707, 182548.3134626615], 
processed observation next is [1.0, 0.34782608695652173, 0.3320987654320988, 0.8933333333333333, 1.0, 1.0, 0.6659780651922484, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3164344962503824, 0.3164344962503824, 0.3510544489666567], 
reward next is 0.6489, 
noisyNet noise sample is [array([0.47570336], dtype=float32), -0.23694028]. 
=============================================
[2019-03-24 01:35:51,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.35853 ]
 [59.88782 ]
 [60.608677]
 [60.636345]
 [60.681316]], R is [[59.08815384]
 [59.15567017]
 [59.24956894]
 [59.4005127 ]
 [59.55337524]].
[2019-03-24 01:35:54,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7559061e-14 1.0000000e+00 2.4186020e-31 1.0643880e-09 6.5043033e-21], sum to 1.0000
[2019-03-24 01:35:54,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3644
[2019-03-24 01:35:54,590] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 87.0, 1.0, 2.0, 0.448148355845819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546946.9995369295, 546946.9995369295, 135393.55182687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1980000.0000, 
sim time next is 1980600.0000, 
raw observation next is [21.43333333333333, 87.5, 1.0, 2.0, 0.4363546164499478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535014.3736467432, 535014.3736467432, 133717.9234384684], 
processed observation next is [1.0, 0.9565217391304348, 0.3493827160493826, 0.875, 1.0, 1.0, 0.32899359101184256, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.191076562016694, 0.191076562016694, 0.2571498527662854], 
reward next is 0.7429, 
noisyNet noise sample is [array([0.45360672], dtype=float32), -0.0616833]. 
=============================================
[2019-03-24 01:35:58,261] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6591019e-11 9.9999380e-01 8.7955003e-25 6.2215995e-06 7.0146297e-18], sum to 1.0000
[2019-03-24 01:35:58,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-24 01:35:58,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333333, 63.00000000000001, 1.0, 2.0, 0.5689610538106166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 660437.3479950974, 660437.3479950969, 153394.9671641707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2042400.0000, 
sim time next is 2043000.0000, 
raw observation next is [28.6, 63.0, 1.0, 2.0, 0.5725778069390548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663793.2016338893, 663793.2016338893, 153964.4684291083], 
processed observation next is [0.0, 0.6521739130434783, 0.6148148148148148, 0.63, 1.0, 1.0, 0.49116405587982714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23706900058353192, 0.23706900058353192, 0.29608551620982365], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.82401615], dtype=float32), 1.0347553]. 
=============================================
[2019-03-24 01:35:58,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.92935 ]
 [68.91825 ]
 [68.930275]
 [68.90896 ]
 [68.89257 ]], R is [[68.97131348]
 [68.98661041]
 [69.00305176]
 [69.02063751]
 [69.03908539]].
[2019-03-24 01:36:00,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1840227e-13 1.0000000e+00 3.7598534e-28 1.0549855e-09 1.1911292e-19], sum to 1.0000
[2019-03-24 01:36:00,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6161
[2019-03-24 01:36:00,443] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 87.66666666666667, 1.0, 2.0, 0.4330045806721641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529278.3306750356, 529278.3306750356, 133181.9017389592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2085000.0000, 
sim time next is 2085600.0000, 
raw observation next is [21.6, 88.33333333333334, 1.0, 2.0, 0.4338735243679513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530466.2885022311, 530466.2885022311, 133312.6453040194], 
processed observation next is [0.0, 0.13043478260869565, 0.3555555555555556, 0.8833333333333334, 1.0, 1.0, 0.32603990996184684, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18945224589365398, 0.18945224589365398, 0.2563704717384988], 
reward next is 0.7436, 
noisyNet noise sample is [array([-1.635537], dtype=float32), -0.58532774]. 
=============================================
[2019-03-24 01:36:01,204] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7603017e-16 1.0000000e+00 3.2665674e-28 3.5503786e-10 3.2930331e-18], sum to 1.0000
[2019-03-24 01:36:01,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2488
[2019-03-24 01:36:01,213] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 50.00000000000001, 1.0, 2.0, 0.5651955083141743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657008.7065250205, 657008.7065250205, 152806.8928094555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2128800.0000, 
sim time next is 2129400.0000, 
raw observation next is [31.25, 49.5, 1.0, 2.0, 0.5635779201009963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655526.4354074282, 655526.4354074282, 152554.5250223405], 
processed observation next is [0.0, 0.6521739130434783, 0.7129629629629629, 0.495, 1.0, 1.0, 0.4804499048821384, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2341165840740815, 0.2341165840740815, 0.29337408658142405], 
reward next is 0.7066, 
noisyNet noise sample is [array([0.6821911], dtype=float32), 0.8083417]. 
=============================================
[2019-03-24 01:36:02,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7543623e-13 9.9999952e-01 1.4248637e-22 4.4429456e-07 5.8449932e-17], sum to 1.0000
[2019-03-24 01:36:02,357] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0430
[2019-03-24 01:36:02,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 70.0, 1.0, 2.0, 0.6563333015962293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748010.0108094546, 748010.0108094546, 168041.5673702869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2145600.0000, 
sim time next is 2146200.0000, 
raw observation next is [28.53333333333333, 70.5, 1.0, 2.0, 0.6558834171228645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747497.036426043, 747497.036426043, 167959.4801845015], 
processed observation next is [0.0, 0.8695652173913043, 0.6123456790123456, 0.705, 1.0, 1.0, 0.5903374013367434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26696322729501537, 0.26696322729501537, 0.3229990003548106], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.12379003], dtype=float32), 0.5465005]. 
=============================================
[2019-03-24 01:36:07,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2391489e-10 1.0000000e+00 2.2958409e-25 8.9118251e-09 2.4263260e-17], sum to 1.0000
[2019-03-24 01:36:07,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-24 01:36:07,771] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.16666666666667, 1.0, 2.0, 0.4164290415373986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512100.9669835112, 512100.9669835112, 130864.1754999739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [20.4, 95.33333333333334, 1.0, 2.0, 0.4120643149659357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506610.2435691757, 506610.2435691757, 130236.0139397872], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9533333333333335, 1.0, 1.0, 0.30007656543563777, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1809322298461342, 0.1809322298461342, 0.2504538729611292], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.38392562], dtype=float32), -0.48487103]. 
=============================================
[2019-03-24 01:36:15,473] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 01:36:15,474] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:36:15,475] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:36:15,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:15,477] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:15,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:36:15,477] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:36:15,479] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:36:15,481] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:15,481] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:15,484] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:15,497] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-24 01:36:15,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-24 01:36:15,519] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-24 01:36:15,579] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-24 01:36:15,580] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-24 01:36:34,714] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:36:34,716] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.32319299, 43.12450206, 1.0, 2.0, 0.1690140823383991, 1.0, 2.0, 0.1690140823383991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 424468.4185367593, 424468.4185367598, 153631.0336940481]
[2019-03-24 01:36:34,717] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:36:34,721] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4283413e-08 4.2877847e-01 3.5852042e-19 5.7122147e-01 5.2156272e-11], sampled 0.6578444384296811
[2019-03-24 01:36:36,197] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:36:36,198] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.53333333333333, 74.83333333333334, 1.0, 2.0, 0.4290076117271791, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530218.5400437736, 530218.5400437736, 132749.2538518802]
[2019-03-24 01:36:36,198] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:36:36,200] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2471078e-08 4.2841136e-01 3.1231305e-19 5.7158870e-01 4.8313728e-11], sampled 0.9287013288589788
[2019-03-24 01:37:09,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:37:09,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.4, 82.16666666666667, 1.0, 2.0, 0.6988269988598464, 1.0, 2.0, 0.6988269988598464, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1593755.481204465, 1593755.481204465, 303723.6951880105]
[2019-03-24 01:37:09,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:37:09,409] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.5574569e-08 4.3417403e-01 2.6660997e-18 5.6582594e-01 1.5789677e-10], sampled 0.4064720045268343
[2019-03-24 01:37:09,411] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1593755.481204465 W.
[2019-03-24 01:37:11,523] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:37:11,524] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.4373537, 68.03262320333334, 1.0, 2.0, 0.5607119878549495, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655151.4518792607, 655151.4518792607, 152207.7198966952]
[2019-03-24 01:37:11,524] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:37:11,526] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0783372e-08 4.2807859e-01 2.7282500e-19 5.7192141e-01 4.4876703e-11], sampled 0.18013730308258857
[2019-03-24 01:37:36,849] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:37:36,850] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.86666666666667, 83.16666666666667, 1.0, 2.0, 0.5731200115680184, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667535.1512033342, 667535.1512033342, 154194.7808666577]
[2019-03-24 01:37:36,852] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:37:36,855] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8294465e-08 4.2746300e-01 2.2037309e-19 5.7253700e-01 3.9871710e-11], sampled 0.9014071737191497
[2019-03-24 01:37:37,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:37:37,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.89241193, 78.83017454, 1.0, 2.0, 0.5956778508835895, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687588.8147385574, 687588.8147385574, 157758.4121653439]
[2019-03-24 01:37:37,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:37:37,240] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4794368e-08 4.2885882e-01 3.7231782e-19 5.7114112e-01 5.3260108e-11], sampled 0.32415736386455807
[2019-03-24 01:37:50,037] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.51274157]
[2019-03-24 01:37:50,038] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.3333576901581018, 1.0, 1.0, 0.3333576901581018, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 759848.1240413841, 759848.1240413846, 188658.8725946412]
[2019-03-24 01:37:50,039] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:37:50,041] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9362866e-08 4.2772445e-01 2.4207151e-19 5.7227558e-01 4.2004501e-11], sampled 0.6967773268423699
[2019-03-24 01:37:59,094] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 5923.4187 2322866083.1619 260.0000
[2019-03-24 01:37:59,232] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6037.0657 2347723686.3945 302.0000
[2019-03-24 01:37:59,295] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5844.3308 2575130650.9135 416.0000
[2019-03-24 01:37:59,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5701.7899 2390980710.4787 302.0000
[2019-03-24 01:37:59,340] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6207.7377 2287048986.9754 227.0000
[2019-03-24 01:38:00,357] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 700000, evaluation results [700000.0, 5844.330841718274, 2575130650.9134536, 416.0, 5923.4187268195765, 2322866083.161884, 260.0, 6207.737664978735, 2287048986.975353, 227.0, 5701.789930647696, 2390980710.478693, 302.0, 6037.065727681627, 2347723686.394518, 302.0]
[2019-03-24 01:38:07,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1763236e-11 2.7234992e-03 7.4994529e-26 9.9727648e-01 9.5456795e-11], sum to 1.0000
[2019-03-24 01:38:07,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-24 01:38:07,589] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.3, 30.0, 1.0, 2.0, 0.5468837895422602, 1.0, 2.0, 0.5468837895422602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1307785.098777949, 1307785.09877795, 252914.3222963271], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2553000.0000, 
sim time next is 2553600.0000, 
raw observation next is [33.40000000000001, 30.0, 1.0, 2.0, 0.6601946975004285, 1.0, 2.0, 0.6601946975004285, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1572870.197645308, 1572870.197645308, 292439.5671582089], 
processed observation next is [1.0, 0.5652173913043478, 0.7925925925925931, 0.3, 1.0, 1.0, 0.5954698779767006, 1.0, 1.0, 0.5954698779767006, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5617393563018958, 0.5617393563018958, 0.5623837829965557], 
reward next is 0.4376, 
noisyNet noise sample is [array([0.79182684], dtype=float32), 0.7450242]. 
=============================================
[2019-03-24 01:38:10,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0359841e-11 2.1841470e-03 1.9516095e-23 9.9781585e-01 1.0013058e-13], sum to 1.0000
[2019-03-24 01:38:10,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-24 01:38:10,610] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 59.33333333333334, 1.0, 2.0, 0.2524897952182158, 1.0, 2.0, 0.2524897952182158, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 597085.5785328925, 597085.578532893, 170483.674877937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2582400.0000, 
sim time next is 2583000.0000, 
raw observation next is [27.3, 60.5, 1.0, 2.0, 0.2523236342260281, 1.0, 2.0, 0.2523236342260281, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 596809.9868693404, 596809.9868693409, 170451.047506165], 
processed observation next is [1.0, 0.9130434782608695, 0.5666666666666667, 0.605, 1.0, 1.0, 0.10990908836431917, 1.0, 1.0, 0.10990908836431917, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2131464238819073, 0.21314642388190747, 0.3277904759733942], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.84091866], dtype=float32), 1.3068141]. 
=============================================
[2019-03-24 01:38:10,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.36743]
 [70.85286]
 [70.97467]
 [71.3362 ]
 [71.4854 ]], R is [[70.3595047 ]
 [70.32805634]
 [70.29650116]
 [70.26468658]
 [70.23246765]].
[2019-03-24 01:38:15,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7158853e-13 9.9999607e-01 4.9632140e-32 3.9440770e-06 2.5930193e-16], sum to 1.0000
[2019-03-24 01:38:15,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8786
[2019-03-24 01:38:15,314] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.5628861965184881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 658571.8013575623, 658571.8013575628, 152607.7776513331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2669400.0000, 
sim time next is 2670000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.5667616806254794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663101.7677438912, 663101.7677438912, 153256.5875951818], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.4842400959827135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23682205990853258, 0.23682205990853258, 0.2947242069138112], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.49833447], dtype=float32), -0.1621898]. 
=============================================
[2019-03-24 01:38:15,337] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[85.33423 ]
 [85.37969 ]
 [85.42042 ]
 [85.48663 ]
 [85.510544]], R is [[85.10328674]
 [84.95877838]
 [84.81568146]
 [84.67372131]
 [84.53249359]].
[2019-03-24 01:38:42,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1626348e-12 9.9999905e-01 1.6087759e-24 9.3610032e-07 1.7907874e-16], sum to 1.0000
[2019-03-24 01:38:42,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-24 01:38:42,559] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 74.83333333333334, 1.0, 2.0, 0.5796350760077945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675639.7203346051, 675639.7203346051, 155320.5163890673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3196200.0000, 
sim time next is 3196800.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5633336866446553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 660411.1262160483, 660411.1262160479, 152738.4712860762], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.74, 1.0, 1.0, 0.4801591507674468, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23586111650573152, 0.23586111650573138, 0.2937278293963004], 
reward next is 0.7063, 
noisyNet noise sample is [array([-1.3658749], dtype=float32), 0.5510364]. 
=============================================
[2019-03-24 01:38:49,701] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:38:49,702] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:38:49,702] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:38:49,707] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:38:49,708] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:38:49,709] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:38:49,711] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:38:49,711] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:38:49,713] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:38:49,713] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:38:49,714] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:38:49,735] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-24 01:38:49,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-24 01:38:49,758] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-24 01:38:49,781] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-24 01:38:49,832] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-24 01:38:51,909] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:38:51,911] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.2, 76.83333333333334, 1.0, 2.0, 0.3967393186077334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498021.3938532458, 498021.3938532458, 128283.9030225855]
[2019-03-24 01:38:51,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:38:51,914] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9335534e-14 1.0000000e+00 1.7419964e-28 3.8762259e-08 7.6350574e-20], sampled 0.9762653665394191
[2019-03-24 01:39:10,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:10,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.23811921, 93.246941985, 1.0, 2.0, 0.5120432432570523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640585.7733868889, 640585.7733868889, 145644.3306278551]
[2019-03-24 01:39:10,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:39:10,471] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1013942e-14 1.0000000e+00 4.5450517e-28 4.9939182e-08 1.4784933e-19], sampled 0.6071609964730096
[2019-03-24 01:39:19,088] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:19,093] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.53333333333333, 44.83333333333334, 1.0, 2.0, 0.4966322385739098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611129.583010579, 611129.583010579, 142960.565283522]
[2019-03-24 01:39:19,095] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:39:19,099] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2116776e-14 1.0000000e+00 2.2881694e-28 4.1658232e-08 9.2139946e-20], sampled 0.3387631830039983
[2019-03-24 01:39:26,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:26,672] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.02156984166667, 70.35334934833332, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 134.9345181545345, 6.9112, 121.94756008, 68574555.34826933, 3003603.962646886, 512363.425667698]
[2019-03-24 01:39:26,674] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:39:26,677] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1721023e-21 0.0000000e+00], sampled 0.6395529018413181
[2019-03-24 01:39:26,679] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 68574555.34826933 W.
[2019-03-24 01:39:30,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:30,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.685454455, 77.218058, 1.0, 2.0, 0.5428235333066721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637488.8807321856, 637488.8807321856, 149392.0045596592]
[2019-03-24 01:39:30,558] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:39:30,560] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5606155e-14 1.0000000e+00 1.1274925e-28 3.4554340e-08 5.6573590e-20], sampled 0.5142132740247766
[2019-03-24 01:39:51,881] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:51,884] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 87.0, 1.0, 2.0, 0.6259468701033004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736732.5513146862, 736732.5513146862, 163682.9935615902]
[2019-03-24 01:39:51,886] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:39:51,888] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4428144e-14 1.0000000e+00 2.7998794e-28 4.3940151e-08 1.0588144e-19], sampled 0.09698920769025465
[2019-03-24 01:39:55,667] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:39:55,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 74.0, 1.0, 2.0, 0.6002512027597415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690913.195410927, 690913.195410927, 158455.374397421]
[2019-03-24 01:39:55,669] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:39:55,672] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1709579e-14 1.0000000e+00 6.2937085e-29 2.9621019e-08 3.7855003e-20], sampled 0.32970438293788484
[2019-03-24 01:40:22,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5239228]
[2019-03-24 01:40:22,045] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.807529766942779, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1635534.754157758, 1635534.754157758, 337736.9474538081]
[2019-03-24 01:40:22,046] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:40:22,051] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.835158e-12 9.999989e-01 5.419053e-23 1.095705e-06 4.656765e-16], sampled 0.27390870451040783
[2019-03-24 01:40:22,051] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1635534.754157758 W.
[2019-03-24 01:40:32,180] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:40:32,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-03-24 01:40:32,688] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:40:32,797] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:40:32,821] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:40:33,838] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 725000, evaluation results [725000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:40:34,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4701538e-12 1.0000000e+00 2.7215050e-25 7.9390922e-10 7.3825365e-18], sum to 1.0000
[2019-03-24 01:40:34,715] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0476
[2019-03-24 01:40:34,724] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6577575185660002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 749633.9562521745, 749633.956252174, 168299.5946329774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3329400.0000, 
sim time next is 3330000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6595120227149743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751634.5122163635, 751634.5122163635, 168619.1155783043], 
processed observation next is [0.0, 0.5652173913043478, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5946571698987789, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2684408972201298, 0.2684408972201298, 0.3242675299582775], 
reward next is 0.6757, 
noisyNet noise sample is [array([-0.79359573], dtype=float32), 1.0811019]. 
=============================================
[2019-03-24 01:40:34,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.3892  ]
 [73.355705]
 [73.335915]
 [73.31623 ]
 [73.31844 ]], R is [[73.37010956]
 [73.31275177]
 [73.25656891]
 [73.20145416]
 [73.1476059 ]].
[2019-03-24 01:40:40,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3858943e-09 9.5660371e-01 1.6697711e-15 4.3396354e-02 2.4806572e-09], sum to 1.0000
[2019-03-24 01:40:40,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-24 01:40:40,856] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1875190.602160211 W.
[2019-03-24 01:40:40,860] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8221007702632493, 1.0, 1.0, 0.8221007702632493, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1875190.602160211, 1875190.602160211, 352972.2728449752], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.939394679194756, 6.9112, 121.9257104054318, 1892529.879445857, 1878091.723025867, 384033.7932608619], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.89, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.00281946791947556, 0.0, 0.8094599232896831, 0.6759035283735203, 0.6707470439378096, 0.7385265255016574], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09257496], dtype=float32), 0.2079125]. 
=============================================
[2019-03-24 01:40:47,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9220845e-09 5.6242473e-02 7.4962687e-17 9.4375759e-01 2.6072963e-10], sum to 1.0000
[2019-03-24 01:40:47,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-24 01:40:48,001] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2852412645551605, 1.0, 2.0, 0.2852412645551605, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657345.8346910371, 657345.8346910375, 177315.6975072418], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3610800.0000, 
sim time next is 3611400.0000, 
raw observation next is [24.95, 82.16666666666667, 1.0, 2.0, 0.2824643734332268, 1.0, 2.0, 0.2824643734332268, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652701.9635590657, 652701.9635590657, 176746.7136842989], 
processed observation next is [1.0, 0.8260869565217391, 0.47962962962962963, 0.8216666666666668, 1.0, 1.0, 0.1457909207538414, 1.0, 1.0, 0.1457909207538414, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23310784412823776, 0.23310784412823776, 0.33989752631595943], 
reward next is 0.6601, 
noisyNet noise sample is [array([-0.01399039], dtype=float32), -0.55374014]. 
=============================================
[2019-03-24 01:40:56,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0792664e-12 1.5901491e-05 1.5715072e-19 9.9998415e-01 1.7997408e-10], sum to 1.0000
[2019-03-24 01:40:56,637] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9041
[2019-03-24 01:40:56,643] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.6, 68.33333333333334, 1.0, 2.0, 0.3885937657505354, 1.0, 2.0, 0.3885937657505354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885824.7655829461, 885824.7655829461, 203081.2734114358], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3872400.0000, 
sim time next is 3873000.0000, 
raw observation next is [30.25, 68.66666666666666, 1.0, 2.0, 0.3813725184775284, 1.0, 2.0, 0.3813725184775284, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 869354.1264120702, 869354.1264120707, 201135.5929982952], 
processed observation next is [0.0, 0.8260869565217391, 0.6759259259259259, 0.6866666666666665, 1.0, 1.0, 0.2635387124732481, 1.0, 1.0, 0.2635387124732481, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31048361657573936, 0.31048361657573953, 0.38679921730441386], 
reward next is 0.6132, 
noisyNet noise sample is [array([0.84268105], dtype=float32), 1.8133377]. 
=============================================
[2019-03-24 01:40:56,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[59.964214]
 [59.972015]
 [60.009895]
 [59.958015]
 [59.938595]], R is [[60.00055695]
 [60.01000977]
 [60.01746368]
 [60.02714157]
 [60.03094864]].
[2019-03-24 01:41:05,356] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2328764e-10 6.4390618e-04 6.8572518e-19 9.9935609e-01 4.0533514e-08], sum to 1.0000
[2019-03-24 01:41:05,364] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-24 01:41:05,369] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.3676657456861233, 1.0, 2.0, 0.3676657456861233, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 838091.8984092404, 838091.8984092409, 197492.3680254499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3913200.0000, 
sim time next is 3913800.0000, 
raw observation next is [26.21666666666667, 92.83333333333334, 1.0, 2.0, 0.3693652673732227, 1.0, 2.0, 0.3693652673732227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 841968.0759794725, 841968.075979473, 197940.5803309102], 
processed observation next is [0.0, 0.30434782608695654, 0.5265432098765432, 0.9283333333333335, 1.0, 1.0, 0.24924436592050325, 1.0, 1.0, 0.24924436592050325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30070288427838304, 0.3007028842783832, 0.3806549621748273], 
reward next is 0.6193, 
noisyNet noise sample is [array([-0.40314877], dtype=float32), -0.4505762]. 
=============================================
[2019-03-24 01:41:09,307] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5213013e-09 5.4026459e-06 3.4702093e-16 9.9999464e-01 1.0572648e-08], sum to 1.0000
[2019-03-24 01:41:09,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7932
[2019-03-24 01:41:09,325] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 91.33333333333334, 1.0, 2.0, 0.451419150402286, 1.0, 2.0, 0.451419150402286, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1029135.481822065, 1029135.481822066, 220767.2712077492], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3990000.0000, 
sim time next is 3990600.0000, 
raw observation next is [24.85, 91.5, 1.0, 2.0, 0.4622537710242947, 1.0, 2.0, 0.4622537710242947, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053852.998441075, 1053852.998441075, 223955.8800701747], 
processed observation next is [1.0, 0.17391304347826086, 0.475925925925926, 0.915, 1.0, 1.0, 0.35982591788606516, 1.0, 1.0, 0.35982591788606516, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3763760708718125, 0.3763760708718125, 0.43068438475033594], 
reward next is 0.5693, 
noisyNet noise sample is [array([-0.38048467], dtype=float32), -0.7807588]. 
=============================================
[2019-03-24 01:41:11,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0377837e-08 4.5759439e-06 6.0527827e-21 9.9999547e-01 4.3248985e-12], sum to 1.0000
[2019-03-24 01:41:11,721] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-24 01:41:11,724] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3318126229650499, 1.0, 2.0, 0.3318126229650499, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756324.5946833993, 756324.5946833998, 188270.343345655], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4050000.0000, 
sim time next is 4050600.0000, 
raw observation next is [24.83333333333334, 95.0, 1.0, 2.0, 0.3335228224994136, 1.0, 2.0, 0.3335228224994136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 760224.7096911407, 760224.7096911411, 188700.0513617336], 
processed observation next is [1.0, 0.9130434782608695, 0.47530864197530887, 0.95, 1.0, 1.0, 0.20657478868977813, 1.0, 1.0, 0.20657478868977813, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2715088248896931, 0.27150882488969325, 0.36288471415718004], 
reward next is 0.6371, 
noisyNet noise sample is [array([-0.58692724], dtype=float32), -0.85021377]. 
=============================================
[2019-03-24 01:41:12,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8305433e-11 2.0475774e-08 3.0186710e-22 1.0000000e+00 1.8516252e-12], sum to 1.0000
[2019-03-24 01:41:12,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2868
[2019-03-24 01:41:12,959] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.2586143618892193, 1.0, 2.0, 0.2586143618892193, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627776.091196317, 627776.091196317, 172493.8067968301], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4073400.0000, 
sim time next is 4074000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.2459598733544437, 1.0, 2.0, 0.2459598733544437, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 597263.1327373404, 597263.1327373409, 169613.8251997521], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.10233318256481391, 1.0, 1.0, 0.10233318256481391, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21330826169190728, 0.21330826169190745, 0.32618043307644634], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.41226402], dtype=float32), 1.1148983]. 
=============================================
[2019-03-24 01:41:12,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.522396]
 [60.722637]
 [60.70265 ]
 [61.00852 ]
 [61.111984]], R is [[60.70370102]
 [60.76494598]
 [60.82429504]
 [60.8684845 ]
 [60.93677521]].
[2019-03-24 01:41:16,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4135183e-13 1.8952028e-08 5.2878900e-25 1.0000000e+00 3.6087568e-15], sum to 1.0000
[2019-03-24 01:41:16,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8552
[2019-03-24 01:41:16,749] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.41666666666666, 91.33333333333334, 1.0, 2.0, 0.2277660120274491, 1.0, 2.0, 0.2277660120274491, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550032.1768368715, 550032.176836872, 165453.3322399824], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4128600.0000, 
sim time next is 4129200.0000, 
raw observation next is [21.3, 92.0, 1.0, 2.0, 0.2273509474205874, 1.0, 2.0, 0.2273509474205874, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 549350.231683758, 549350.2316837584, 165374.1305940601], 
processed observation next is [1.0, 0.8260869565217391, 0.3444444444444445, 0.92, 1.0, 1.0, 0.08017969931022309, 1.0, 1.0, 0.08017969931022309, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19619651131562785, 0.196196511315628, 0.31802717421934634], 
reward next is 0.6820, 
noisyNet noise sample is [array([-0.12718803], dtype=float32), 1.1056001]. 
=============================================
[2019-03-24 01:41:19,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2645239e-12 7.0122996e-07 2.1684393e-25 9.9999928e-01 4.1989152e-13], sum to 1.0000
[2019-03-24 01:41:19,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8825
[2019-03-24 01:41:19,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.291900002907715, 1.0, 2.0, 0.291900002907715, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667303.5507137883, 667303.5507137887, 178628.969607677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4222800.0000, 
sim time next is 4223400.0000, 
raw observation next is [28.5, 64.0, 1.0, 2.0, 0.2942075013466314, 1.0, 2.0, 0.2942075013466314, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672507.1802205545, 672507.1802205549, 179173.9954932084], 
processed observation next is [1.0, 0.9130434782608695, 0.6111111111111112, 0.64, 1.0, 1.0, 0.15977083493646593, 1.0, 1.0, 0.15977083493646593, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24018113579305517, 0.24018113579305533, 0.3445653759484777], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.19519044], dtype=float32), 0.5815288]. 
=============================================
[2019-03-24 01:41:20,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2966416e-13 7.5622518e-07 2.1521022e-21 9.9999928e-01 2.4603984e-11], sum to 1.0000
[2019-03-24 01:41:20,199] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8066
[2019-03-24 01:41:20,206] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.26666666666667, 56.33333333333333, 1.0, 2.0, 0.26924756968063, 1.0, 2.0, 0.26924756968063, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 625960.756420276, 625960.7564202765, 173850.9267554477], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4221600.0000, 
sim time next is 4222200.0000, 
raw observation next is [29.13333333333333, 59.16666666666667, 1.0, 2.0, 0.2802570221332755, 1.0, 2.0, 0.2802570221332755, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646108.8661326368, 646108.8661326368, 176156.9408449514], 
processed observation next is [1.0, 0.8695652173913043, 0.6345679012345677, 0.5916666666666667, 1.0, 1.0, 0.14316312158723277, 1.0, 1.0, 0.14316312158723277, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2307531664759417, 0.2307531664759417, 0.3387633477787527], 
reward next is 0.6612, 
noisyNet noise sample is [array([0.31541678], dtype=float32), -0.00676745]. 
=============================================
[2019-03-24 01:41:23,157] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 01:41:23,160] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:41:23,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:23,161] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:41:23,162] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:23,163] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:41:23,167] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:41:23,168] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:41:23,169] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:23,169] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:23,170] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:23,180] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-24 01:41:23,204] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-24 01:41:23,235] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-24 01:41:23,239] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-24 01:41:23,293] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-24 01:41:24,635] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:41:24,636] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.05823487333333, 85.63072055333335, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 279880.7217989083, 279880.7217989088, 118339.5774636402]
[2019-03-24 01:41:24,639] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:41:24,640] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.5456925e-11 1.3577295e-05 1.6593957e-20 9.9998641e-01 4.7272297e-10], sampled 0.9578994190955437
[2019-03-24 01:41:40,123] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:41:40,124] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.59823324333334, 20.7230085, 1.0, 2.0, 0.1602753847144433, 1.0, 2.0, 0.1602753847144433, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413507.447387217, 413507.447387217, 147041.9226827875]
[2019-03-24 01:41:40,126] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:41:40,128] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9576870e-11 1.1049834e-05 7.3034531e-21 9.9998891e-01 3.2057518e-10], sampled 0.054488460585957355
[2019-03-24 01:41:56,823] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:41:56,825] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333334, 69.83333333333333, 1.0, 2.0, 0.2510141822148165, 1.0, 2.0, 0.2510141822148165, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595746.3759749496, 595746.3759749496, 170240.3623199768]
[2019-03-24 01:41:56,826] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:41:56,829] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.2788883e-11 9.0246531e-06 3.2582735e-21 9.9999094e-01 2.1869628e-10], sampled 0.641087512109448
[2019-03-24 01:42:10,141] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:42:10,143] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.21418528833333, 80.906654565, 1.0, 2.0, 0.3434446378374167, 1.0, 2.0, 0.3434446378374167, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 782851.8299331414, 782851.8299331418, 191213.5154645078]
[2019-03-24 01:42:10,144] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:42:10,147] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9493617e-11 9.8851833e-06 4.6843808e-21 9.9999011e-01 2.5975561e-10], sampled 0.30220371124209466
[2019-03-24 01:42:12,375] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:42:12,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.3, 83.0, 1.0, 2.0, 0.3431952196262043, 1.0, 2.0, 0.3431952196262043, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 782283.0129505999, 782283.0129506004, 191149.4141118024]
[2019-03-24 01:42:12,377] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:42:12,381] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8287734e-11 9.7362545e-06 4.4108711e-21 9.9999022e-01 2.5245719e-10], sampled 0.5793898836320416
[2019-03-24 01:42:15,434] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:42:15,435] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.01666666666667, 63.0, 1.0, 2.0, 0.8966908673647943, 1.0, 2.0, 0.8966908673647943, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2045523.531482531, 2045523.531482531, 385329.8163897799]
[2019-03-24 01:42:15,436] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:42:15,439] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4524296e-10 3.5760077e-05 7.8926927e-19 9.9996424e-01 2.9471956e-09], sampled 0.9377114221813231
[2019-03-24 01:42:57,525] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.5389903]
[2019-03-24 01:42:57,527] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.83333333333334, 90.16666666666667, 1.0, 2.0, 0.2164332104877825, 1.0, 2.0, 0.2164332104877825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529127.9296021007, 529127.9296021012, 163217.6840547027]
[2019-03-24 01:42:57,527] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:42:57,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.4379004e-11 1.4341114e-05 2.0642757e-20 9.9998569e-01 5.2422827e-10], sampled 0.6248715193754438
[2019-03-24 01:43:06,361] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 01:43:06,387] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.0980 2495385081.8943 47.0000
[2019-03-24 01:43:06,481] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 01:43:06,493] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 01:43:06,502] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 01:43:07,518] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 750000, evaluation results [750000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6906.097973430718, 2495385081.894323, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 01:43:16,324] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.108670e-08 2.194703e-04 5.616755e-18 9.997806e-01 3.229079e-08], sum to 1.0000
[2019-03-24 01:43:16,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-24 01:43:16,337] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.25, 85.66666666666667, 1.0, 2.0, 0.2774217966956101, 1.0, 2.0, 0.2774217966956101, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 645055.1733294473, 645055.1733294477, 175754.7466539528], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4435800.0000, 
sim time next is 4436400.0000, 
raw observation next is [24.6, 85.33333333333334, 1.0, 2.0, 0.2832981444200012, 1.0, 2.0, 0.2832981444200012, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654852.9203018256, 654852.9203018256, 176953.5772285911], 
processed observation next is [0.0, 0.34782608695652173, 0.46666666666666673, 0.8533333333333334, 1.0, 1.0, 0.14678350526190617, 1.0, 1.0, 0.14678350526190617, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23387604296493772, 0.23387604296493772, 0.34029534082421364], 
reward next is 0.6597, 
noisyNet noise sample is [array([2.6255393], dtype=float32), -0.5860907]. 
=============================================
[2019-03-24 01:43:22,920] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1482878e-10 1.0496251e-04 1.0353156e-18 9.9989498e-01 3.9738808e-08], sum to 1.0000
[2019-03-24 01:43:22,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7426
[2019-03-24 01:43:22,940] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333333, 94.0, 1.0, 2.0, 0.2865147539931838, 1.0, 2.0, 0.2865147539931838, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662329.4128457914, 662329.4128457914, 177714.3928688305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4564200.0000, 
sim time next is 4564800.0000, 
raw observation next is [23.2, 94.0, 1.0, 2.0, 0.2830252775218292, 1.0, 2.0, 0.2830252775218292, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656113.584995315, 656113.584995315, 176978.7491025567], 
processed observation next is [0.0, 0.8695652173913043, 0.4148148148148148, 0.94, 1.0, 1.0, 0.14645866371646335, 1.0, 1.0, 0.14645866371646335, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23432628035546962, 0.23432628035546962, 0.3403437482741475], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.4016902], dtype=float32), 1.3484101]. 
=============================================
[2019-03-24 01:43:25,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9241887e-09 2.8512857e-06 1.6819325e-16 9.9999690e-01 2.6692848e-07], sum to 1.0000
[2019-03-24 01:43:25,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2081
[2019-03-24 01:43:25,448] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.7034805817381907, 1.0, 2.0, 0.7034805817381907, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1604378.042292706, 1604378.042292706, 305483.7534036308], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [27.0, 71.0, 1.0, 2.0, 0.6656067060591, 1.0, 2.0, 0.6656067060591, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1517919.383902403, 1517919.383902404, 291348.9005153807], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.71, 1.0, 1.0, 0.6019127453084524, 1.0, 1.0, 0.6019127453084524, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5421140656794297, 0.54211406567943, 0.560286347144963], 
reward next is 0.4397, 
noisyNet noise sample is [array([0.10811522], dtype=float32), -1.4220805]. 
=============================================
[2019-03-24 01:43:29,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0178789e-08 4.7257916e-05 1.1263243e-15 9.9995232e-01 4.8411880e-07], sum to 1.0000
[2019-03-24 01:43:29,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7548
[2019-03-24 01:43:29,875] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5690132798906518, 1.0, 2.0, 0.5690132798906518, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1297451.009935012, 1297451.009935012, 257551.2963722742], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4797600.0000, 
sim time next is 4798200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5669577734979176, 1.0, 2.0, 0.5669577734979176, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1292760.136391223, 1292760.136391222, 256867.1844840912], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.48447353987847336, 1.0, 1.0, 0.48447353987847336, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46170004871115106, 0.4617000487111507, 0.4939753547770985], 
reward next is 0.5060, 
noisyNet noise sample is [array([0.03145912], dtype=float32), -1.2127265]. 
=============================================
[2019-03-24 01:43:31,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7759139e-09 8.5872234e-05 1.1887132e-17 9.9991405e-01 8.1342243e-08], sum to 1.0000
[2019-03-24 01:43:31,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-24 01:43:31,082] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 96.66666666666666, 1.0, 2.0, 0.5640162179807281, 1.0, 2.0, 0.5640162179807281, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1286047.259073551, 1286047.259073552, 255889.5621908124], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4696800.0000, 
sim time next is 4697400.0000, 
raw observation next is [23.3, 98.33333333333334, 1.0, 2.0, 0.5579053694084646, 1.0, 2.0, 0.5579053694084646, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1272101.976252126, 1272101.976252127, 253870.568420796], 
processed observation next is [1.0, 0.34782608695652173, 0.41851851851851857, 0.9833333333333334, 1.0, 1.0, 0.4736968683434102, 1.0, 1.0, 0.4736968683434102, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.4543221343757593, 0.45432213437575963, 0.4882126315784538], 
reward next is 0.5118, 
noisyNet noise sample is [array([0.07705432], dtype=float32), -0.46456504]. 
=============================================
[2019-03-24 01:43:35,261] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3922697e-07 3.0967917e-06 3.4851639e-16 9.9999571e-01 1.1222320e-06], sum to 1.0000
[2019-03-24 01:43:35,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0774
[2019-03-24 01:43:35,274] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 87.66666666666667, 1.0, 2.0, 0.7680884206911307, 1.0, 2.0, 0.7680884206911307, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1751869.011740344, 1751869.011740344, 330744.6715386263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4800000.0000, 
sim time next is 4800600.0000, 
raw observation next is [26.75, 87.0, 1.0, 2.0, 0.8187120242219803, 1.0, 2.0, 0.8187120242219803, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1867452.879299278, 1867452.879299278, 351547.5329206274], 
processed observation next is [1.0, 0.5652173913043478, 0.5462962962962963, 0.87, 1.0, 1.0, 0.7841809812166433, 1.0, 1.0, 0.7841809812166433, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6669474568925993, 0.6669474568925993, 0.6760529479242834], 
reward next is 0.3239, 
noisyNet noise sample is [array([-1.7756836], dtype=float32), 0.6269237]. 
=============================================
[2019-03-24 01:43:36,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5961830e-07 2.9507355e-04 1.7516750e-16 9.9896622e-01 7.3781301e-04], sum to 1.0000
[2019-03-24 01:43:36,185] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5766
[2019-03-24 01:43:36,189] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.25, 88.33333333333334, 1.0, 2.0, 0.6234549860856085, 1.0, 2.0, 0.6234549860856085, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1421702.949389113, 1421702.949389113, 276203.5052055251], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4799400.0000, 
sim time next is 4800000.0000, 
raw observation next is [26.5, 87.66666666666667, 1.0, 2.0, 0.7680884206911307, 1.0, 2.0, 0.7680884206911307, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1751869.011740344, 1751869.011740344, 330744.6715386263], 
processed observation next is [1.0, 0.5652173913043478, 0.5370370370370371, 0.8766666666666667, 1.0, 1.0, 0.7239147865370603, 1.0, 1.0, 0.7239147865370603, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.62566750419298, 0.62566750419298, 0.6360474452665891], 
reward next is 0.3640, 
noisyNet noise sample is [array([-0.610912], dtype=float32), 0.40072852]. 
=============================================
[2019-03-24 01:43:36,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.22373 ]
 [46.2123  ]
 [46.24697 ]
 [45.942417]
 [45.629425]], R is [[45.14152145]
 [45.15894318]
 [45.19037247]
 [45.24449158]
 [45.29675293]].
[2019-03-24 01:43:42,388] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0348853e-06 1.7889513e-04 3.0793150e-15 6.3460475e-01 3.6521429e-01], sum to 1.0000
[2019-03-24 01:43:42,398] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6678
[2019-03-24 01:43:42,403] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 82.0, 1.0, 2.0, 0.4054000125185527, 1.0, 2.0, 0.4054000125185527, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 924158.7975617517, 924158.7975617521, 207676.4285434494], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4935600.0000, 
sim time next is 4936200.0000, 
raw observation next is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.3303234036628414, 1.0, 2.0, 0.3303234036628414, 1.0, 1.0, 0.5258856165134539, 6.911199999999999, 6.9112, 121.94756008, 1129669.991757039, 1129669.991757039, 267906.8984202309], 
processed observation next is [1.0, 0.13043478260869565, 0.4876543209876545, 0.8316666666666667, 1.0, 1.0, 0.20276595674147788, 1.0, 1.0, 0.20276595674147788, 1.0, 0.5, 0.40735702064181734, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4034535684846568, 0.4034535684846568, 0.5152055738850594], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7191116], dtype=float32), 0.9310401]. 
=============================================
[2019-03-24 01:43:44,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8702566e-06 2.0307635e-03 3.9291615e-14 8.2696667e-03 9.8969674e-01], sum to 1.0000
[2019-03-24 01:43:44,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-24 01:43:44,483] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.1881458175760223, 1.0, 2.0, 0.1881458175760223, 1.0, 2.0, 0.3004488781613597, 6.911199999999999, 6.9112, 121.94756008, 658114.2341787347, 658114.2341787352, 216685.8455997061], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4946400.0000, 
sim time next is 4947000.0000, 
raw observation next is [24.0, 84.0, 1.0, 2.0, 0.2166101770592269, 1.0, 2.0, 0.2166101770592269, 1.0, 2.0, 0.3456776957649823, 6.911200000000001, 6.9112, 121.94756008, 755468.0352103064, 755468.0352103059, 226060.0235447824], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.84, 1.0, 1.0, 0.06739306792765105, 1.0, 1.0, 0.06739306792765105, 1.0, 1.0, 0.18209711970622786, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26981001257510945, 0.2698100125751093, 0.43473081450919693], 
reward next is 0.5653, 
noisyNet noise sample is [array([0.88236976], dtype=float32), 0.9668978]. 
=============================================
[2019-03-24 01:43:44,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[45.102608]
 [45.108192]
 [45.099136]
 [45.152035]
 [45.12655 ]], R is [[45.29072952]
 [45.42111969]
 [45.54563522]
 [45.66832733]
 [45.79245377]].
[2019-03-24 01:43:44,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9357310e-07 9.1250316e-05 2.0089324e-14 3.6802614e-04 9.9954009e-01], sum to 1.0000
[2019-03-24 01:43:44,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2491
[2019-03-24 01:43:44,667] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.5191002378957029, 1.0, 2.0, 0.5191002378957029, 1.0, 2.0, 0.826424484644444, 6.9112, 6.9112, 121.94756008, 1775982.489829737, 1775982.489829737, 353062.5735246649], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4968000.0000, 
sim time next is 4968600.0000, 
raw observation next is [26.0, 84.83333333333333, 1.0, 2.0, 0.4929115361989622, 1.0, 2.0, 0.4929115361989622, 1.0, 2.0, 0.784731218636763, 6.911199999999999, 6.9112, 121.94756008, 1686299.295271313, 1686299.295271314, 340123.5514795872], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.8483333333333333, 1.0, 1.0, 0.3963232573797169, 1.0, 1.0, 0.3963232573797169, 1.0, 1.0, 0.7309140232959538, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6022497483111833, 0.6022497483111836, 0.65408375284536], 
reward next is 0.3459, 
noisyNet noise sample is [array([0.12366967], dtype=float32), -0.30702892]. 
=============================================
[2019-03-24 01:43:44,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2724050e-08 4.0581112e-06 2.5280998e-14 3.8486742e-04 9.9961108e-01], sum to 1.0000
[2019-03-24 01:43:44,954] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6484
[2019-03-24 01:43:44,958] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 86.5, 1.0, 2.0, 0.4404324534865052, 1.0, 2.0, 0.4404324534865052, 1.0, 2.0, 0.7011828098341276, 6.9112, 6.9112, 121.94756008, 1506601.197239824, 1506601.197239824, 315246.4363222967], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4969800.0000, 
sim time next is 4970400.0000, 
raw observation next is [26.0, 87.33333333333333, 1.0, 2.0, 0.3767136535549283, 1.0, 2.0, 0.3767136535549283, 1.0, 2.0, 0.5997404051666191, 6.9112, 6.9112, 121.94756008, 1288452.976540454, 1288452.976540454, 287031.7419415751], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.8733333333333333, 1.0, 1.0, 0.257992444708248, 1.0, 1.0, 0.257992444708248, 1.0, 1.0, 0.4996755064582738, 0.0, 0.0, 0.8096049824067558, 0.46016177733587643, 0.46016177733587643, 0.5519841191184136], 
reward next is 0.4480, 
noisyNet noise sample is [array([0.6983209], dtype=float32), 1.2984366]. 
=============================================
[2019-03-24 01:43:47,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3099699e-05 2.7968086e-02 4.8925980e-17 4.2428183e-03 9.6774596e-01], sum to 1.0000
[2019-03-24 01:43:47,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2942
[2019-03-24 01:43:47,513] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.9, 99.33333333333334, 1.0, 2.0, 0.1943286500112735, 1.0, 2.0, 0.1943286500112735, 1.0, 2.0, 0.3094063979349137, 6.911199999999999, 6.9112, 121.94756008, 665645.3137743461, 665645.3137743466, 218755.9899192075], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5026800.0000, 
sim time next is 5027400.0000, 
raw observation next is [22.85, 99.0, 1.0, 2.0, 0.1929740083740955, 1.0, 2.0, 0.1929740083740955, 1.0, 2.0, 0.3072883553962863, 6.911200000000001, 6.9112, 121.94756008, 662315.2286159759, 662315.2286159755, 218321.1613850608], 
processed observation next is [0.0, 0.17391304347826086, 0.4018518518518519, 0.99, 1.0, 1.0, 0.03925477187392322, 1.0, 1.0, 0.03925477187392322, 1.0, 1.0, 0.13411044424535784, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.23654115307713428, 0.2365411530771341, 0.4198483872789631], 
reward next is 0.5802, 
noisyNet noise sample is [array([0.5015265], dtype=float32), 0.29912707]. 
=============================================
[2019-03-24 01:43:47,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4159041e-08 1.8791778e-05 5.1372714e-18 2.0683746e-04 9.9977440e-01], sum to 1.0000
[2019-03-24 01:43:47,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3917
[2019-03-24 01:43:47,599] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.95, 99.66666666666667, 1.0, 2.0, 0.1951319947522075, 1.0, 2.0, 0.1951319947522075, 1.0, 2.0, 0.3106578104958356, 6.9112, 6.9112, 121.94756008, 667195.8061521207, 667195.8061521207, 219011.5752978162], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5026200.0000, 
sim time next is 5026800.0000, 
raw observation next is [22.9, 99.33333333333334, 1.0, 2.0, 0.1943286500110393, 1.0, 2.0, 0.1943286500110393, 1.0, 2.0, 0.3094063979345618, 6.911199999999999, 6.9112, 121.94756008, 665645.3137743461, 665645.3137743466, 218755.9899191342], 
processed observation next is [0.0, 0.17391304347826086, 0.4037037037037037, 0.9933333333333334, 1.0, 1.0, 0.040867440489332496, 1.0, 1.0, 0.040867440489332496, 1.0, 1.0, 0.13675799741820224, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2377304692051236, 0.23773046920512378, 0.420684595998335], 
reward next is 0.5793, 
noisyNet noise sample is [array([0.03162996], dtype=float32), 0.96986234]. 
=============================================
[2019-03-24 01:43:49,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1573188e-07 1.2233382e-03 6.5910281e-16 8.6355060e-03 9.9014038e-01], sum to 1.0000
[2019-03-24 01:43:49,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2461
[2019-03-24 01:43:49,023] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.08333333333333, 66.83333333333333, 1.0, 2.0, 0.2466061519777042, 1.0, 2.0, 0.2466061519777042, 1.0, 2.0, 0.3926050253501737, 6.9112, 6.9112, 121.94756008, 843208.6343148104, 843208.6343148104, 236425.2357623725], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5062200.0000, 
sim time next is 5062800.0000, 
raw observation next is [31.26666666666667, 67.66666666666667, 1.0, 2.0, 0.2521646635299219, 1.0, 2.0, 0.2521646635299219, 1.0, 2.0, 0.4014543567693872, 6.9112, 6.9112, 121.94756008, 862225.2762256707, 862225.2762256707, 238394.3244083577], 
processed observation next is [0.0, 0.6086956521739131, 0.7135802469135804, 0.6766666666666667, 1.0, 1.0, 0.1097198375356213, 1.0, 1.0, 0.1097198375356213, 1.0, 1.0, 0.25181794596173396, 0.0, 0.0, 0.8096049824067558, 0.30793759865202525, 0.30793759865202525, 0.45845062386222635], 
reward next is 0.5415, 
noisyNet noise sample is [array([0.15893945], dtype=float32), -1.2627914]. 
=============================================
[2019-03-24 01:43:57,008] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:43:57,009] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:43:57,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:43:57,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:43:57,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:43:57,013] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:43:57,013] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:43:57,014] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:43:57,014] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:43:57,015] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:43:57,015] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:43:57,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-24 01:43:57,055] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-24 01:43:57,078] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-24 01:43:57,102] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-24 01:43:57,123] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-24 01:44:09,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.55015606]
[2019-03-24 01:44:09,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666667, 45.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 377362.9163097935, 377362.9163097939, 172515.1936830835]
[2019-03-24 01:44:09,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:44:09,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.5757841e-07 9.8443154e-05 1.1142877e-13 4.7030690e-04 9.9943084e-01], sampled 0.7618054926862027
[2019-03-24 01:44:34,044] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.55015606]
[2019-03-24 01:44:34,046] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.2, 80.0, 1.0, 2.0, 0.1780400761070626, 1.0, 2.0, 0.1780400761070626, 1.0, 2.0, 0.2836764060185783, 6.9112, 6.9112, 121.94756008, 614852.2864255598, 614852.2864255598, 213556.5347361891]
[2019-03-24 01:44:34,048] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:44:34,053] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9168120e-07 6.6342356e-05 3.1714906e-14 3.4177228e-04 9.9959165e-01], sampled 0.2953765980563575
[2019-03-24 01:44:59,678] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.55015606]
[2019-03-24 01:44:59,679] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.80081245333334, 91.13815361, 1.0, 2.0, 0.2205323677379063, 1.0, 2.0, 0.2205323677379063, 1.0, 2.0, 0.3510947116765459, 6.9112, 6.9112, 121.94756008, 754011.9459398863, 754011.9459398863, 227419.1237145824]
[2019-03-24 01:44:59,679] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:44:59,682] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0249797e-07 8.8555629e-05 7.9539911e-14 4.3169293e-04 9.9947947e-01], sampled 0.6144592045070156
[2019-03-24 01:45:15,150] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.55015606]
[2019-03-24 01:45:15,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.13333333333333, 90.0, 1.0, 2.0, 0.2215965853548444, 1.0, 2.0, 0.2215965853548444, 1.0, 2.0, 0.3534785527136423, 6.911199999999999, 6.9112, 121.94756008, 771107.7976949182, 771107.7976949187, 227759.9950501932]
[2019-03-24 01:45:15,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:45:15,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8276586e-07 6.4369247e-05 2.8809383e-14 3.3354652e-04 9.9960190e-01], sampled 0.878832807722181
[2019-03-24 01:45:34,340] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0041532], dtype=float32), 0.55015606]
[2019-03-24 01:45:34,341] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.46666666666667, 76.66666666666666, 1.0, 2.0, 0.1811789536167898, 1.0, 2.0, 0.1811789536167898, 1.0, 2.0, 0.2888348044577162, 6.9112, 6.9112, 121.94756008, 628188.9291887905, 628188.9291887905, 214531.8445250624]
[2019-03-24 01:45:34,343] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:45:34,346] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8971534e-07 6.5911467e-05 3.1062253e-14 3.3997046e-04 9.9959391e-01], sampled 0.4657541007274316
[2019-03-24 01:45:38,848] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4391.4468 2875643692.6801 8.0000
[2019-03-24 01:45:39,346] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4608.3815 2894499844.8517 12.0000
[2019-03-24 01:45:39,396] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4509.7673 3107203958.1402 0.0000
[2019-03-24 01:45:39,422] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4275.6653 2920039637.1381 33.0000
[2019-03-24 01:45:39,428] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4488.4494 2940571225.4001 28.0000
[2019-03-24 01:45:40,442] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 775000, evaluation results [775000.0, 4509.76733358239, 3107203958.140197, 0.0, 4608.381532085218, 2894499844.8516655, 12.0, 4391.446773485237, 2875643692.680117, 8.0, 4488.449418416944, 2940571225.400067, 28.0, 4275.665320627496, 2920039637.138085, 33.0]
[2019-03-24 01:45:42,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7962893e-06 5.7199009e-04 7.0826674e-12 6.7284674e-04 9.9874938e-01], sum to 1.0000
[2019-03-24 01:45:42,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-24 01:45:42,643] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.6211901435290652, 1.0, 2.0, 0.6211901435290652, 1.0, 2.0, 0.9889549392488642, 6.9112, 6.9112, 121.94756008, 2125675.300185118, 2125675.300185118, 407041.8974432159], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5235600.0000, 
sim time next is 5236200.0000, 
raw observation next is [29.25, 70.5, 1.0, 2.0, 0.6450114533719531, 1.0, 2.0, 0.6358703886624112, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2175971.417190367, 2175971.417190368, 414790.5717302787], 
processed observation next is [1.0, 0.6086956521739131, 0.6388888888888888, 0.705, 1.0, 1.0, 0.5773945873475632, 1.0, 1.0, 0.5665123674552514, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7771326489965596, 0.77713264899656, 0.7976741764043822], 
reward next is 0.2023, 
noisyNet noise sample is [array([0.63778836], dtype=float32), 0.3034152]. 
=============================================
[2019-03-24 01:45:49,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7208456e-10 2.6277930e-06 1.9330219e-20 2.1998578e-06 9.9999511e-01], sum to 1.0000
[2019-03-24 01:45:49,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5076
[2019-03-24 01:45:49,229] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.2, 90.66666666666667, 1.0, 2.0, 0.2377674211742051, 1.0, 2.0, 0.2377674211742051, 1.0, 2.0, 0.3785334780536372, 6.9112, 6.9112, 121.94756008, 812970.7590771724, 812970.7590771724, 233329.6853553734], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5373600.0000, 
sim time next is 5374200.0000, 
raw observation next is [24.15, 90.83333333333334, 1.0, 2.0, 0.2427624430473229, 1.0, 2.0, 0.2427624430473229, 1.0, 2.0, 0.3864857155521461, 6.911200000000001, 6.9112, 121.94756008, 830058.9085124707, 830058.9085124702, 235073.7061585539], 
processed observation next is [1.0, 0.17391304347826086, 0.44999999999999996, 0.9083333333333334, 1.0, 1.0, 0.09852671791347963, 1.0, 1.0, 0.09852671791347963, 1.0, 1.0, 0.23310714444018263, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29644961018302524, 0.29644961018302507, 0.45206481953568056], 
reward next is 0.5479, 
noisyNet noise sample is [array([-2.6271555], dtype=float32), -0.5156015]. 
=============================================
[2019-03-24 01:45:49,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1925433e-10 5.0256506e-07 5.4903348e-18 1.8819573e-07 9.9999928e-01], sum to 1.0000
[2019-03-24 01:45:49,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4288
[2019-03-24 01:45:49,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 88.0, 1.0, 2.0, 0.253523586778053, 1.0, 2.0, 0.253523586778053, 1.0, 2.0, 0.4036178068374524, 6.911200000000001, 6.9112, 121.94756008, 866874.4625170068, 866874.4625170063, 238878.3447793586], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5367600.0000, 
sim time next is 5368200.0000, 
raw observation next is [24.65, 88.33333333333334, 1.0, 2.0, 0.2665174088398596, 1.0, 2.0, 0.2665174088398596, 1.0, 2.0, 0.4243043947390894, 6.9112, 6.9112, 121.94756008, 911330.7145619666, 911330.7145619666, 243558.542547477], 
processed observation next is [1.0, 0.13043478260869565, 0.46851851851851845, 0.8833333333333334, 1.0, 1.0, 0.12680643909507094, 1.0, 1.0, 0.12680643909507094, 1.0, 1.0, 0.2803804934238617, 0.0, 0.0, 0.8096049824067558, 0.32547525520070236, 0.32547525520070236, 0.4683818125913019], 
reward next is 0.5316, 
noisyNet noise sample is [array([-1.7968656], dtype=float32), -0.41493675]. 
=============================================
[2019-03-24 01:45:51,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2287366e-05 9.0119510e-04 1.1889292e-09 6.9398861e-03 9.9213660e-01], sum to 1.0000
[2019-03-24 01:45:51,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2618
[2019-03-24 01:45:51,560] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 75.5, 1.0, 2.0, 0.7456326336009764, 1.0, 2.0, 0.686180978776923, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2348362.466338473, 2348362.466338473, 441727.4270883466], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5416200.0000, 
sim time next is 5416800.0000, 
raw observation next is [29.66666666666667, 74.33333333333334, 1.0, 2.0, 0.7453341396685004, 1.0, 2.0, 0.686031731810685, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2347851.017008282, 2347851.017008282, 441644.2815851395], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.7433333333333334, 1.0, 1.0, 0.6968263567482147, 1.0, 1.0, 0.6262282521555773, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8385182203601006, 0.8385182203601006, 0.8493159261252683], 
reward next is 0.1507, 
noisyNet noise sample is [array([0.02694629], dtype=float32), 0.590087]. 
=============================================
[2019-03-24 01:45:55,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4443894e-08 1.1482333e-05 1.3101807e-15 3.1087970e-06 9.9998534e-01], sum to 1.0000
[2019-03-24 01:45:55,469] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7488
[2019-03-24 01:45:55,474] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 91.0, 1.0, 2.0, 0.212464100508095, 1.0, 2.0, 0.212464100508095, 1.0, 2.0, 0.3382497674815673, 6.911199999999999, 6.9112, 121.94756008, 726413.0406838754, 726413.0406838759, 224709.2941419378], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5594400.0000, 
sim time next is 5595000.0000, 
raw observation next is [25.33333333333334, 91.16666666666667, 1.0, 2.0, 0.2151441420015429, 1.0, 2.0, 0.2151441420015429, 1.0, 2.0, 0.3425164808219942, 6.911199999999999, 6.9112, 121.94756008, 735580.4765235457, 735580.4765235462, 225605.3803835529], 
processed observation next is [1.0, 0.782608695652174, 0.49382716049382736, 0.9116666666666667, 1.0, 1.0, 0.06564778809707486, 1.0, 1.0, 0.06564778809707486, 1.0, 1.0, 0.17814560102749274, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2627073130441235, 0.26270731304412365, 0.43385650073760174], 
reward next is 0.5661, 
noisyNet noise sample is [array([1.4945263], dtype=float32), -0.9173176]. 
=============================================
[2019-03-24 01:45:55,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[49.391384]
 [49.486347]
 [49.50533 ]
 [49.187263]
 [48.558697]], R is [[49.35119247]
 [49.42554855]
 [49.50201797]
 [49.58042145]
 [49.65995407]].
[2019-03-24 01:45:59,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4768496e-08 2.2740824e-06 2.0932596e-17 1.7684580e-06 9.9999595e-01], sum to 1.0000
[2019-03-24 01:45:59,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9726
[2019-03-24 01:45:59,094] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.56666666666667, 92.33333333333334, 1.0, 2.0, 0.2275225822135803, 1.0, 2.0, 0.2275225822135803, 1.0, 2.0, 0.362223360777211, 6.9112, 6.9112, 121.94756008, 777923.988357655, 777923.988357655, 229796.3155766492], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5534400.0000, 
sim time next is 5535000.0000, 
raw observation next is [25.55, 92.5, 1.0, 2.0, 0.2275034745794668, 1.0, 2.0, 0.2275034745794668, 1.0, 2.0, 0.36219294080141, 6.9112, 6.9112, 121.94756008, 777858.6241738911, 777858.6241738911, 229789.7803172412], 
processed observation next is [1.0, 0.043478260869565216, 0.5018518518518519, 0.925, 1.0, 1.0, 0.08036127926126999, 1.0, 1.0, 0.08036127926126999, 1.0, 1.0, 0.2027411760017625, 0.0, 0.0, 0.8096049824067558, 0.2778066514906754, 0.2778066514906754, 0.4419034236870023], 
reward next is 0.5581, 
noisyNet noise sample is [array([-0.5391649], dtype=float32), -0.93612576]. 
=============================================
[2019-03-24 01:45:59,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[47.461487]
 [47.49964 ]
 [47.94652 ]
 [48.180275]
 [48.512676]], R is [[47.4281311 ]
 [47.51193237]
 [47.59487152]
 [47.67694473]
 [47.75804138]].
[2019-03-24 01:46:01,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2030579e-09 7.6958786e-06 2.2480071e-20 3.5556582e-07 9.9999189e-01], sum to 1.0000
[2019-03-24 01:46:01,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-24 01:46:01,620] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.75, 92.83333333333333, 1.0, 2.0, 0.2315206439190434, 1.0, 2.0, 0.2315206439190434, 1.0, 2.0, 0.3685884052200877, 6.911200000000001, 6.9112, 121.94756008, 791600.8455080003, 791600.8455079999, 231168.2366438053], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [25.8, 93.0, 1.0, 2.0, 0.232963887824669, 1.0, 2.0, 0.232963887824669, 1.0, 2.0, 0.3708860965210162, 6.9112, 6.9112, 121.94756008, 796538.058043301, 796538.058043301, 231665.6761005787], 
processed observation next is [1.0, 0.8695652173913043, 0.5111111111111112, 0.93, 1.0, 1.0, 0.08686177121984405, 1.0, 1.0, 0.08686177121984405, 1.0, 1.0, 0.2136076206512702, 0.0, 0.0, 0.8096049824067558, 0.2844778778726075, 0.2844778778726075, 0.44551091557803596], 
reward next is 0.5545, 
noisyNet noise sample is [array([0.36597377], dtype=float32), -2.2676344]. 
=============================================
[2019-03-24 01:46:05,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0092307e-09 2.1346323e-06 1.9635985e-20 2.2072816e-06 9.9999571e-01], sum to 1.0000
[2019-03-24 01:46:05,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4617
[2019-03-24 01:46:05,591] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.56666666666667, 66.33333333333334, 1.0, 2.0, 0.2360438123431197, 1.0, 2.0, 0.2360438123431197, 1.0, 2.0, 0.3757894366605284, 6.911199999999999, 6.9112, 121.94756008, 807074.3196855967, 807074.3196855971, 232731.1201898781], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5674800.0000, 
sim time next is 5675400.0000, 
raw observation next is [30.65, 66.0, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.38150158233819, 6.9112, 6.9112, 121.94756008, 819348.719401112, 819348.719401112, 233978.9952542289], 
processed observation next is [0.0, 0.6956521739130435, 0.6907407407407407, 0.66, 1.0, 1.0, 0.09479972636716331, 1.0, 1.0, 0.09479972636716331, 1.0, 1.0, 0.22687697792273745, 0.0, 0.0, 0.8096049824067558, 0.29262454264325427, 0.29262454264325427, 0.4499596062581325], 
reward next is 0.5500, 
noisyNet noise sample is [array([1.6311992], dtype=float32), -1.4657915]. 
=============================================
[2019-03-24 01:46:06,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8596026e-11 3.2203382e-06 3.1951905e-18 1.1789633e-07 9.9999666e-01], sum to 1.0000
[2019-03-24 01:46:06,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9979
[2019-03-24 01:46:06,023] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.23333333333333, 76.0, 1.0, 2.0, 0.249483493272046, 1.0, 2.0, 0.249483493272046, 1.0, 2.0, 0.3971858463992297, 6.911200000000001, 6.9112, 121.94756008, 853052.4641168907, 853052.4641168902, 237442.3719909699], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.06666666666666, 77.0, 1.0, 2.0, 0.2498660317222393, 1.0, 2.0, 0.2498660317222393, 1.0, 2.0, 0.397794860070345, 6.9112, 6.9112, 121.94756008, 854361.1968684477, 854361.1968684477, 237577.9471108664], 
processed observation next is [0.0, 0.782608695652174, 0.6320987654320985, 0.77, 1.0, 1.0, 0.10698337109790394, 1.0, 1.0, 0.10698337109790394, 1.0, 1.0, 0.2472435750879312, 0.0, 0.0, 0.8096049824067558, 0.30512899888158845, 0.30512899888158845, 0.4568806675208969], 
reward next is 0.5431, 
noisyNet noise sample is [array([-1.8983635], dtype=float32), 0.71584505]. 
=============================================
[2019-03-24 01:46:06,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2253059e-10 5.3368152e-05 4.2374330e-19 1.3897042e-05 9.9993277e-01], sum to 1.0000
[2019-03-24 01:46:06,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3436
[2019-03-24 01:46:06,443] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.38150158233819, 6.9112, 6.9112, 121.94756008, 819348.719401112, 819348.719401112, 233978.9952542289], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.2409791137689406, 1.0, 2.0, 0.2409791137689406, 1.0, 2.0, 0.3836465972619816, 6.911199999999999, 6.9112, 121.94756008, 823958.0312067362, 823958.0312067367, 234449.4532205895], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.09640370686778643, 1.0, 1.0, 0.09640370686778643, 1.0, 1.0, 0.22955824657747695, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2942707254309772, 0.2942707254309774, 0.45086433311651825], 
reward next is 0.5491, 
noisyNet noise sample is [array([1.0137069], dtype=float32), -0.41366345]. 
=============================================
[2019-03-24 01:46:06,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[58.891453]
 [58.873554]
 [58.827995]
 [58.79358 ]
 [58.754055]], R is [[58.87215424]
 [58.83347321]
 [58.79758072]
 [58.76169968]
 [58.72418976]].
[2019-03-24 01:46:09,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9736329e-04 1.1464822e-01 9.7834372e-09 5.8235768e-02 8.2681870e-01], sum to 1.0000
[2019-03-24 01:46:09,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6893
[2019-03-24 01:46:09,060] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.2, 96.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2573592424986253, 6.911199999999999, 6.9112, 121.94756008, 571603.6892693227, 571603.6892693231, 207529.7511362157], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5718000.0000, 
sim time next is 5718600.0000, 
raw observation next is [21.15, 96.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2556088614250573, 6.9112, 6.9112, 121.94756008, 568109.768602152, 568109.768602152, 206930.8108226456], 
processed observation next is [0.0, 0.17391304347826086, 0.33888888888888885, 0.965, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0695110767813216, 0.0, 0.0, 0.8096049824067558, 0.20289634592934, 0.20289634592934, 0.39794386696662615], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08203726], dtype=float32), -0.07241044]. 
=============================================
[2019-03-24 01:46:10,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3457294e-10 2.3066741e-03 8.7021634e-19 6.1920751e-04 9.9707413e-01], sum to 1.0000
[2019-03-24 01:46:10,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8360
[2019-03-24 01:46:10,016] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.8, 68.5, 1.0, 2.0, 0.2009005233289806, 1.0, 2.0, 0.2009005233289806, 1.0, 2.0, 0.3198401760130001, 6.9112, 6.9112, 121.94756008, 686859.5546866627, 686859.5546866627, 220889.0387792961], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5765400.0000, 
sim time next is 5766000.0000, 
raw observation next is [27.63333333333333, 69.0, 1.0, 2.0, 0.1999721645043041, 1.0, 2.0, 0.1999721645043041, 1.0, 2.0, 0.318362198529579, 6.911200000000001, 6.9112, 121.94756008, 683684.170112495, 683684.1701124945, 220585.583018743], 
processed observation next is [0.0, 0.7391304347826086, 0.5790123456790122, 0.69, 1.0, 1.0, 0.04758591012417155, 1.0, 1.0, 0.04758591012417155, 1.0, 1.0, 0.1479527481619737, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24417291789731962, 0.24417291789731946, 0.42420304426681343], 
reward next is 0.5758, 
noisyNet noise sample is [array([0.10240165], dtype=float32), 1.1281574]. 
=============================================
[2019-03-24 01:46:10,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.07106 ]
 [62.65914 ]
 [62.370068]
 [62.07714 ]
 [61.83697 ]], R is [[63.02565002]
 [62.97060776]
 [62.9155426 ]
 [62.86055374]
 [62.80595398]].
[2019-03-24 01:46:13,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4705624e-08 6.0248736e-04 2.3391158e-15 1.2242858e-04 9.9927503e-01], sum to 1.0000
[2019-03-24 01:46:13,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4295
[2019-03-24 01:46:13,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.46666666666667, 93.0, 1.0, 2.0, 0.1694083104059633, 1.0, 2.0, 0.1694083104059633, 1.0, 2.0, 0.2727513909666084, 6.9112, 6.9112, 121.94756008, 606430.3044340423, 606430.3044340423, 210372.3020849036], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [21.6, 92.0, 1.0, 2.0, 0.1665272475446231, 1.0, 2.0, 0.1665272475446231, 1.0, 2.0, 0.2681780880588943, 6.911199999999999, 6.9112, 121.94756008, 596408.2606378072, 596408.2606378077, 209468.9098170715], 
processed observation next is [1.0, 0.21739130434782608, 0.3555555555555556, 0.92, 1.0, 1.0, 0.007770532791217989, 1.0, 1.0, 0.007770532791217989, 1.0, 1.0, 0.08522261007361788, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.21300295022778828, 0.21300295022778845, 0.4028248265712913], 
reward next is 0.5972, 
noisyNet noise sample is [array([-1.7696081], dtype=float32), 0.64474195]. 
=============================================
[2019-03-24 01:46:14,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0940473e-14 2.2952406e-06 3.1000471e-31 5.3244569e-09 9.9999774e-01], sum to 1.0000
[2019-03-24 01:46:14,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5936
[2019-03-24 01:46:14,181] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666666, 41.33333333333334, 1.0, 2.0, 0.3508447528951234, 1.0, 2.0, 0.3508447528951234, 1.0, 2.0, 0.5688074290894787, 6.911199999999999, 6.9112, 121.94756008, 1271797.823900843, 1271797.823900843, 275473.1943816238], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5849400.0000, 
sim time next is 5850000.0000, 
raw observation next is [28.2, 41.0, 1.0, 2.0, 0.3454721525414378, 1.0, 2.0, 0.3454721525414378, 1.0, 2.0, 0.5603941838551303, 6.911200000000001, 6.9112, 121.94756008, 1253299.627727858, 1253299.627727858, 273237.8976972075], 
processed observation next is [1.0, 0.7391304347826086, 0.6, 0.41, 1.0, 1.0, 0.22080018159694978, 1.0, 1.0, 0.22080018159694978, 1.0, 1.0, 0.4504927298189128, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44760700990280644, 0.44760700990280644, 0.525457495571553], 
reward next is 0.4745, 
noisyNet noise sample is [array([0.14034751], dtype=float32), 0.46164677]. 
=============================================
[2019-03-24 01:46:14,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[93.75821 ]
 [93.82621 ]
 [93.86867 ]
 [93.912476]
 [93.84345 ]], R is [[93.22661591]
 [92.76459503]
 [92.3065033 ]
 [91.85488892]
 [91.40914917]].
[2019-03-24 01:46:17,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2919453e-19 1.0000000e+00 1.7027717e-37 1.6570598e-19 1.5816480e-19], sum to 1.0000
[2019-03-24 01:46:17,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-24 01:46:17,623] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.3419930923763765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 431777.2474732111, 431777.2474732107, 120886.6209565427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5886000.0000, 
sim time next is 5886600.0000, 
raw observation next is [19.55, 85.00000000000001, 1.0, 2.0, 0.4854951512675987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 613202.2677670219, 613202.2677670214, 141517.1457929709], 
processed observation next is [1.0, 0.13043478260869565, 0.2796296296296297, 0.8500000000000001, 1.0, 1.0, 0.3874942276995222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21900080991679355, 0.21900080991679338, 0.2721483572941748], 
reward next is 0.7279, 
noisyNet noise sample is [array([0.4154217], dtype=float32), -0.64561707]. 
=============================================
[2019-03-24 01:46:18,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7805816e-18 1.0000000e+00 2.0076697e-32 5.4778159e-15 2.5879898e-16], sum to 1.0000
[2019-03-24 01:46:18,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2065
[2019-03-24 01:46:18,127] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.81666666666667, 81.66666666666666, 1.0, 2.0, 0.3219198326897927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407597.4392806796, 407597.4392806796, 118306.5251485142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5896200.0000, 
sim time next is 5896800.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.3311716937992474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418852.2398602603, 418852.2398602603, 119488.3197189456], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 0.81, 1.0, 1.0, 0.20377582595148497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14959008566437867, 0.14959008566437867, 0.22978523022874153], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.39601997], dtype=float32), -0.70867944]. 
=============================================
[2019-03-24 01:46:19,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5834209e-14 1.0000000e+00 8.9243097e-28 5.7253608e-11 5.6657750e-15], sum to 1.0000
[2019-03-24 01:46:19,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0603
[2019-03-24 01:46:19,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1341547.064391468 W.
[2019-03-24 01:46:19,426] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.76666666666667, 46.16666666666667, 1.0, 2.0, 0.9520270967475813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.262109305418153, 6.9112, 121.9247772271569, 1341547.064391468, 1161852.001053281, 232918.982967729], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5922600.0000, 
sim time next is 5923200.0000, 
raw observation next is [28.93333333333334, 45.33333333333334, 1.0, 2.0, 0.5648772004335155, 1.0, 1.0, 0.5648772004335155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258313042256, 1353439.000035819, 1353439.000035819, 259022.2507481272], 
processed observation next is [1.0, 0.5652173913043478, 0.6271604938271608, 0.4533333333333334, 1.0, 1.0, 0.4819966671827566, 1.0, 0.5, 0.4819966671827566, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809460725931948, 0.4833710714413639, 0.4833710714413639, 0.49811971297716773], 
reward next is 0.5019, 
noisyNet noise sample is [array([-1.501486], dtype=float32), 0.9072825]. 
=============================================
[2019-03-24 01:46:20,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5523767e-10 1.0000000e+00 2.2696805e-19 8.6692731e-10 8.1456557e-11], sum to 1.0000
[2019-03-24 01:46:20,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-24 01:46:20,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333333, 81.83333333333333, 1.0, 2.0, 0.4165101210103482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515608.3905253241, 515608.3905253241, 130958.8991112534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5982600.0000, 
sim time next is 5983200.0000, 
raw observation next is [21.7, 81.0, 1.0, 2.0, 0.4128936045076517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 511118.7475398088, 511118.7475398084, 130439.7511947408], 
processed observation next is [1.0, 0.2608695652173913, 0.3592592592592592, 0.81, 1.0, 1.0, 0.3010638148900616, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.182542409835646, 0.18254240983564585, 0.25084567537450153], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.8888984], dtype=float32), 0.6247323]. 
=============================================
[2019-03-24 01:46:26,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0606985e-11 1.0000000e+00 6.2542796e-25 4.4748285e-12 9.6427501e-12], sum to 1.0000
[2019-03-24 01:46:26,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0370
[2019-03-24 01:46:26,955] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1541636.749897975 W.
[2019-03-24 01:46:26,963] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 60.0, 1.0, 2.0, 0.7244053200338658, 0.0, 1.0, 0.0, 1.0, 1.0, 0.996647935322132, 6.9112, 6.9112, 121.9260426156618, 1541636.749897975, 1541636.749897975, 321521.0883714558], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6091200.0000, 
sim time next is 6091800.0000, 
raw observation next is [29.05, 59.33333333333333, 1.0, 2.0, 0.5581563653292518, 1.0, 1.0, 0.5581563653292518, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1272674.757349334, 1272674.757349334, 253953.0939582255], 
processed observation next is [1.0, 0.5217391304347826, 0.6314814814814815, 0.5933333333333333, 1.0, 1.0, 0.4739956730110141, 1.0, 0.5, 0.4739956730110141, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.45452669905333354, 0.45452669905333354, 0.48837133453504905], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.324914], dtype=float32), 0.53927773]. 
=============================================
[2019-03-24 01:46:29,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9911698e-14 1.0000000e+00 1.1194146e-27 6.2611050e-18 1.4044222e-12], sum to 1.0000
[2019-03-24 01:46:29,955] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3429
[2019-03-24 01:46:29,961] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 89.33333333333334, 1.0, 2.0, 0.5359147507013405, 1.0, 1.0, 0.5359147507013405, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9255644473683, 1241693.829395172, 1241693.829395173, 247653.6400828333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6142800.0000, 
sim time next is 6143400.0000, 
raw observation next is [23.4, 89.5, 1.0, 2.0, 0.8378281830096593, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260424698526, 984160.3312552898, 984160.3312552898, 205347.8664759711], 
processed observation next is [1.0, 0.08695652173913043, 0.42222222222222217, 0.895, 1.0, 1.0, 0.8069383131067372, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621278521145, 0.35148583259117494, 0.35148583259117494, 0.39489974322302135], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0185301], dtype=float32), -1.6710842]. 
=============================================
[2019-03-24 01:46:30,099] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:46:30,100] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:46:30,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:30,103] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:46:30,103] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:30,104] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:46:30,104] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:46:30,105] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:46:30,105] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:30,106] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:30,106] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:30,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-24 01:46:30,147] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-24 01:46:30,148] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-24 01:46:30,194] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-24 01:46:30,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-24 01:46:56,589] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5602863]
[2019-03-24 01:46:56,591] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 77.0, 1.0, 2.0, 0.6595467517907952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807602.739724431, 807602.739724431, 170916.3333107409]
[2019-03-24 01:46:56,592] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:46:56,596] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3216034e-12 1.0000000e+00 9.4795885e-24 1.5041421e-14 1.9064363e-10], sampled 0.7158516867067086
[2019-03-24 01:47:05,606] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5602863]
[2019-03-24 01:47:05,606] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.58568307, 105.098323965, 1.0, 2.0, 0.6434946426569701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 123.0537652762392, 782370.7981726712, 782370.7981726708, 167943.5267520852]
[2019-03-24 01:47:05,607] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:47:05,610] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4236121e-13 1.0000000e+00 5.3391916e-25 2.1770055e-15 4.0075644e-11], sampled 0.18735751019763447
[2019-03-24 01:47:08,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5602863]
[2019-03-24 01:47:08,097] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.88076636666667, 83.74938203333333, 1.0, 2.0, 0.5524689066417335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645236.6037287383, 645236.6037287383, 150827.1102902236]
[2019-03-24 01:47:08,099] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:47:08,102] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1480784e-12 1.0000000e+00 1.9998431e-24 6.7380857e-15 1.1966819e-10], sampled 0.3593000927390908
[2019-03-24 01:47:19,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5602863]
[2019-03-24 01:47:19,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.11666666666667, 68.16666666666667, 1.0, 2.0, 0.9675456470198164, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1818192.039747906, 1818192.039747907, 371955.6333388882]
[2019-03-24 01:47:19,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:47:19,273] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3372604e-12 1.0000000e+00 7.9346454e-24 9.8981035e-15 1.0837568e-10], sampled 0.5565629941005403
[2019-03-24 01:47:19,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1818192.039747906 W.
[2019-03-24 01:47:19,521] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5602863]
[2019-03-24 01:47:19,522] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.40422902666667, 102.004905055, 1.0, 2.0, 0.5701812486980697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671693.1571750971, 671693.1571750971, 154025.6293028129]
[2019-03-24 01:47:19,523] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:47:19,526] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.0009388e-13 1.0000000e+00 7.3550716e-26 8.1927060e-16 2.3956795e-11], sampled 0.12295992750781115
[2019-03-24 01:48:11,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:48:12,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:48:12,348] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:48:12,409] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:48:12,426] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.1765 2445373825.0869 746.0000
[2019-03-24 01:48:13,443] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 800000, evaluation results [800000.0, 8099.176546418246, 2445373825.086897, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:48:17,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4667467e-17 1.0000000e+00 6.5529520e-33 2.7437571e-20 4.4091088e-16], sum to 1.0000
[2019-03-24 01:48:17,307] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3498
[2019-03-24 01:48:17,311] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 66.33333333333333, 1.0, 2.0, 0.5500297519962076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 645212.8137516091, 645212.8137516086, 150545.0820507121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6208800.0000, 
sim time next is 6209400.0000, 
raw observation next is [27.15, 66.66666666666667, 1.0, 2.0, 0.545943454676016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641478.5198232052, 641478.5198232052, 149916.5894746914], 
processed observation next is [1.0, 0.8695652173913043, 0.561111111111111, 0.6666666666666667, 1.0, 1.0, 0.4594564936619238, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22909947136543043, 0.22909947136543043, 0.2883011336051758], 
reward next is 0.7117, 
noisyNet noise sample is [array([1.711062], dtype=float32), 1.3218163]. 
=============================================
[2019-03-24 01:48:29,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.9836121e-10 9.9999964e-01 1.3741724e-15 9.9478867e-13 3.3810531e-07], sum to 1.0000
[2019-03-24 01:48:29,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8107
[2019-03-24 01:48:29,485] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 91.0, 1.0, 2.0, 0.818769208892621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933247.6918610901, 933247.6918610901, 199843.2961964347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [25.43333333333333, 90.16666666666667, 1.0, 2.0, 0.9123862135286642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1040026.429018072, 1040026.429018072, 220249.558686042], 
processed observation next is [1.0, 0.34782608695652173, 0.49753086419753073, 0.9016666666666667, 1.0, 1.0, 0.8956978732484098, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.37143801036359714, 0.37143801036359714, 0.42355684362700385], 
reward next is 0.5764, 
noisyNet noise sample is [array([0.9276758], dtype=float32), 0.2973026]. 
=============================================
[2019-03-24 01:48:29,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[33.11287 ]
 [33.187283]
 [33.240868]
 [33.118176]
 [33.42533 ]], R is [[33.05899429]
 [33.34408951]
 [33.63254929]
 [33.90631104]
 [34.12905884]].
[2019-03-24 01:48:29,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.60260232e-08 9.99998927e-01 1.06553806e-14 5.35863132e-10
 1.07855715e-06], sum to 1.0000
[2019-03-24 01:48:29,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9922
[2019-03-24 01:48:29,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2249757.581951662 W.
[2019-03-24 01:48:29,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.25, 54.0, 1.0, 2.0, 0.688081328276845, 1.0, 2.0, 0.6574053261148572, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2249757.581951662, 2249757.581951662, 426052.6796401328], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [32.2, 54.0, 1.0, 2.0, 0.6267970324619264, 1.0, 2.0, 0.6267631782073979, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2144768.78976357, 2144768.78976357, 410148.4442901065], 
processed observation next is [1.0, 0.6086956521739131, 0.7481481481481482, 0.54, 1.0, 1.0, 0.5557107529308648, 1.0, 1.0, 0.5556704502469022, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7659888534869892, 0.7659888534869892, 0.7887470082502047], 
reward next is 0.2113, 
noisyNet noise sample is [array([-1.514554], dtype=float32), -0.8482114]. 
=============================================
[2019-03-24 01:48:30,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8216101e-09 9.9999392e-01 2.0646029e-17 1.0104735e-12 6.1170058e-06], sum to 1.0000
[2019-03-24 01:48:30,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4336
[2019-03-24 01:48:30,408] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 82.33333333333333, 1.0, 2.0, 0.5013854595244869, 1.0, 2.0, 0.5013854595244869, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155619, 1143132.554267045, 1143132.554267045, 235811.7299338742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6489600.0000, 
sim time next is 6490200.0000, 
raw observation next is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.9383041809762268, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1069590.866271131, 1069590.866271131, 226168.3661790959], 
processed observation next is [1.0, 0.08695652173913043, 0.545679012345679, 0.8266666666666667, 1.0, 1.0, 0.92655259640027, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3819967379539754, 0.3819967379539754, 0.4349391657290306], 
reward next is 0.5651, 
noisyNet noise sample is [array([-0.567045], dtype=float32), -1.2981614]. 
=============================================
[2019-03-24 01:48:34,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3467487e-12 1.0000000e+00 6.8307870e-23 2.0222816e-17 4.9059938e-08], sum to 1.0000
[2019-03-24 01:48:34,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2754
[2019-03-24 01:48:34,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1469917.480123049 W.
[2019-03-24 01:48:34,643] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 80.0, 1.0, 2.0, 0.6445780832240504, 1.0, 2.0, 0.6445780832240504, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1469917.480123049, 1469917.480123049, 283717.3693952216], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6525000.0000, 
sim time next is 6525600.0000, 
raw observation next is [27.8, 80.0, 1.0, 2.0, 0.4499661149511138, 1.0, 2.0, 0.4499661149511138, 1.0, 1.0, 0.716360709375462, 6.911200000000001, 6.9112, 121.94756008, 1539246.064961814, 1539246.064961813, 319661.2078627761], 
processed observation next is [1.0, 0.5217391304347826, 0.5851851851851853, 0.8, 1.0, 1.0, 0.3451977558941831, 1.0, 1.0, 0.3451977558941831, 1.0, 0.5, 0.6454508867193276, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5497307374863621, 0.5497307374863618, 0.6147330920438002], 
reward next is 0.3853, 
noisyNet noise sample is [array([1.1852398], dtype=float32), -0.7219624]. 
=============================================
[2019-03-24 01:48:35,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.4647953e-12 1.0000000e+00 7.6417845e-21 2.9261177e-16 2.6447218e-09], sum to 1.0000
[2019-03-24 01:48:35,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9931
[2019-03-24 01:48:35,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1741107.831730115 W.
[2019-03-24 01:48:35,163] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.15, 80.83333333333333, 1.0, 2.0, 0.7633748888584845, 1.0, 2.0, 0.7633748888584845, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.926042553636, 1741107.831730115, 1741107.831730116, 328852.6755490521], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6531000.0000, 
sim time next is 6531600.0000, 
raw observation next is [27.2, 80.66666666666667, 1.0, 2.0, 0.8045946443875422, 1.0, 2.0, 0.8045946443875422, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156429, 1835218.558096579, 1835218.558096579, 345656.5806396282], 
processed observation next is [1.0, 0.6086956521739131, 0.5629629629629629, 0.8066666666666668, 1.0, 1.0, 0.767374576651836, 1.0, 1.0, 0.767374576651836, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200105, 0.6554351993202068, 0.6554351993202068, 0.6647241935377466], 
reward next is 0.3353, 
noisyNet noise sample is [array([1.458424], dtype=float32), 0.88781804]. 
=============================================
[2019-03-24 01:48:35,455] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8195558e-14 1.0000000e+00 7.1953807e-28 2.1705133e-22 4.1549891e-13], sum to 1.0000
[2019-03-24 01:48:35,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5057
[2019-03-24 01:48:35,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333334, 87.33333333333334, 1.0, 2.0, 0.7118480545265401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811312.5546968142, 811312.5546968142, 178400.2484096313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6553200.0000, 
sim time next is 6553800.0000, 
raw observation next is [26.7, 87.0, 1.0, 2.0, 0.7080239363191182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 806951.8090254724, 806951.8090254732, 177669.3734280939], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.87, 1.0, 1.0, 0.6524094479989502, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.28819707465195443, 0.2881970746519547, 0.3416718719771037], 
reward next is 0.6583, 
noisyNet noise sample is [array([2.2186477], dtype=float32), -1.6347889]. 
=============================================
[2019-03-24 01:48:35,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2509531e-14 1.0000000e+00 1.1063163e-23 2.5737917e-17 6.2413380e-10], sum to 1.0000
[2019-03-24 01:48:35,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0854
[2019-03-24 01:48:35,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2016710.821448152 W.
[2019-03-24 01:48:35,760] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 78.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.181640752759309, 6.9112, 121.9249977901782, 2016710.821448152, 1878222.17108143, 383164.2480587247], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6541200.0000, 
sim time next is 6541800.0000, 
raw observation next is [27.83333333333333, 78.5, 1.0, 2.0, 0.4452853102723018, 1.0, 1.0, 0.4452853102723018, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9258797610421, 1015142.425560226, 1015142.425560226, 218981.0947271493], 
processed observation next is [1.0, 0.7391304347826086, 0.5864197530864196, 0.785, 1.0, 1.0, 0.33962536937178783, 1.0, 0.5, 0.33962536937178783, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.809461047634818, 0.3625508662715093, 0.3625508662715093, 0.4211174898599025], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07768212], dtype=float32), 0.20823993]. 
=============================================
[2019-03-24 01:48:37,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4688148e-13 1.0000000e+00 2.2006763e-23 5.7520039e-18 6.1756074e-13], sum to 1.0000
[2019-03-24 01:48:37,181] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9659
[2019-03-24 01:48:37,187] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 65.33333333333333, 1.0, 2.0, 0.4830683809156288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 581762.7520718966, 581762.7520718961, 140457.5088719251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6568800.0000, 
sim time next is 6569400.0000, 
raw observation next is [25.83333333333333, 63.66666666666667, 1.0, 2.0, 0.4692971675876609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567988.4845255965, 567988.4845255965, 138437.7989306739], 
processed observation next is [1.0, 0.0, 0.5123456790123455, 0.6366666666666667, 1.0, 1.0, 0.36821091379483445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20285303018771303, 0.20285303018771303, 0.2662265364051421], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.3839908], dtype=float32), -0.096674]. 
=============================================
[2019-03-24 01:48:42,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1261974e-15 1.0000000e+00 2.4655219e-25 3.4144672e-19 1.5771539e-11], sum to 1.0000
[2019-03-24 01:48:42,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8204
[2019-03-24 01:48:42,050] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.5, 1.0, 2.0, 0.3419342180291132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439851.6006547666, 439851.6006547661, 120908.7430965111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6678600.0000, 
sim time next is 6679200.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.3070942449783921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394748.5963924245, 394748.5963924245, 116453.2585880276], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.5, 1.0, 1.0, 0.17511219640284775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14098164156872303, 0.14098164156872303, 0.2239485742077454], 
reward next is 0.7761, 
noisyNet noise sample is [array([0.00314821], dtype=float32), -1.2182757]. 
=============================================
[2019-03-24 01:48:49,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5780965e-09 2.9554868e-01 2.0094401e-20 4.5727311e-12 7.0445126e-01], sum to 1.0000
[2019-03-24 01:48:49,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3947
[2019-03-24 01:48:49,203] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.55, 63.0, 1.0, 2.0, 0.1638507022176479, 1.0, 2.0, 0.1638507022176479, 1.0, 2.0, 0.2626080454590061, 6.911199999999999, 6.9112, 121.94756008, 580250.2111538072, 580250.2111538077, 208893.0796526168], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6805800.0000, 
sim time next is 6806400.0000, 
raw observation next is [26.36666666666667, 63.66666666666666, 1.0, 2.0, 0.1624347630347233, 1.0, 2.0, 0.1624347630347233, 1.0, 2.0, 0.2604460458830565, 6.9112, 6.9112, 121.94756008, 575883.295814118, 575883.295814118, 208438.4289907505], 
processed observation next is [1.0, 0.782608695652174, 0.5320987654320989, 0.6366666666666666, 1.0, 1.0, 0.0028985274222896266, 1.0, 1.0, 0.0028985274222896266, 1.0, 1.0, 0.07555755735382058, 0.0, 0.0, 0.8096049824067558, 0.2056726056478993, 0.2056726056478993, 0.40084313267452015], 
reward next is 0.5992, 
noisyNet noise sample is [array([-1.0795143], dtype=float32), -0.82616925]. 
=============================================
[2019-03-24 01:48:56,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9342219e-11 9.9997973e-01 2.3481620e-22 3.3816363e-15 2.0283487e-05], sum to 1.0000
[2019-03-24 01:48:56,677] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7344
[2019-03-24 01:48:56,681] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666666, 50.0, 1.0, 2.0, 0.5470125664690597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641367.9207773753, 641367.9207773753, 150035.2416244709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6961200.0000, 
sim time next is 6961800.0000, 
raw observation next is [30.83333333333334, 49.5, 1.0, 2.0, 0.5517018943095723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646316.7451461897, 646316.7451461897, 150785.0973729597], 
processed observation next is [0.0, 0.5652173913043478, 0.6975308641975311, 0.495, 1.0, 1.0, 0.466311778939967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23082740898078202, 0.23082740898078202, 0.2899713411018456], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.8542941], dtype=float32), -0.41003937]. 
=============================================
[2019-03-24 01:48:56,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3656535e-15 1.0000000e+00 6.1663436e-32 3.1046383e-21 2.9705247e-09], sum to 1.0000
[2019-03-24 01:48:56,923] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8904
[2019-03-24 01:48:56,938] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 54.5, 1.0, 2.0, 0.5246464465592374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 620392.4114560523, 620392.4114560519, 146615.0313878551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6955800.0000, 
sim time next is 6956400.0000, 
raw observation next is [29.33333333333334, 54.0, 1.0, 2.0, 0.527084253111175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622644.0091294512, 622644.0091294512, 146982.9184539112], 
processed observation next is [0.0, 0.5217391304347826, 0.6419753086419755, 0.54, 1.0, 1.0, 0.4370050632275893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22237286040337545, 0.22237286040337545, 0.28265945856521385], 
reward next is 0.7173, 
noisyNet noise sample is [array([-1.7038193], dtype=float32), -0.6635849]. 
=============================================
[2019-03-24 01:49:03,366] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 01:49:03,367] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:49:03,368] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:03,368] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:49:03,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:49:03,370] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:03,372] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:49:03,370] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:49:03,375] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:03,374] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:03,377] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:03,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-24 01:49:03,408] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-24 01:49:03,410] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-24 01:49:03,443] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-24 01:49:03,493] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-24 01:49:27,061] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.58753866]
[2019-03-24 01:49:27,064] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.3, 80.0, 1.0, 2.0, 0.3635906528171326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453432.3227724496, 453432.3227724496, 123668.8505689695]
[2019-03-24 01:49:27,065] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:49:27,067] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.20245707e-14 9.99999881e-01 1.24351095e-27 4.92789707e-17
 1.42094933e-07], sampled 0.21016127938038176
[2019-03-24 01:49:45,504] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.58753866]
[2019-03-24 01:49:45,506] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.29249976, 86.6038421, 1.0, 2.0, 0.7093416352254052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 827093.9803175436, 827093.9803175431, 178829.1555268413]
[2019-03-24 01:49:45,508] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:49:45,510] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9814471e-14 9.9999976e-01 6.9160375e-27 1.4276540e-16 2.3214118e-07], sampled 0.37280754155230533
[2019-03-24 01:49:55,109] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.58753866]
[2019-03-24 01:49:55,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666667, 69.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.847711151750495, 6.9112, 121.9214318108679, 2358140.24378747, 1878580.965568755, 380781.1520716028]
[2019-03-24 01:49:55,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:49:55,119] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4842653e-13 9.9999952e-01 7.5419934e-26 6.8048261e-16 5.3296179e-07], sampled 0.7933728049682064
[2019-03-24 01:49:55,121] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2358140.24378747 W.
[2019-03-24 01:49:56,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.58753866]
[2019-03-24 01:49:56,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.99951432, 52.03189714, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.8451395347413, 6.9112, 121.922471198594, 2356826.07072667, 1878579.563418627, 380778.8079528956]
[2019-03-24 01:49:56,325] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:49:56,328] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.8226681e-13 9.9999905e-01 4.6732046e-25 2.1510332e-15 9.2419702e-07], sampled 0.2426536503555613
[2019-03-24 01:49:56,331] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2356826.07072667 W.
[2019-03-24 01:50:16,404] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.58753866]
[2019-03-24 01:50:16,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.7, 80.66666666666667, 1.0, 2.0, 0.40553496212964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 502198.8234528573, 502198.8234528569, 129395.4478999498]
[2019-03-24 01:50:16,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:50:16,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7089099e-14 9.9999988e-01 8.9402207e-28 4.3259213e-17 1.4873197e-07], sampled 0.27265778801867047
[2019-03-24 01:50:44,647] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:50:44,753] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:50:44,909] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:50:44,926] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:50:44,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:50:45,945] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 825000, evaluation results [825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:50:56,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2237262e-12 9.9996412e-01 2.7442106e-22 9.6952166e-13 3.5892059e-05], sum to 1.0000
[2019-03-24 01:50:56,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1341
[2019-03-24 01:50:56,886] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.43333333333333, 87.33333333333334, 1.0, 2.0, 0.3778095166899872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470637.4411611676, 470637.4411611676, 125589.9885384235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [20.41666666666666, 87.66666666666667, 1.0, 2.0, 0.3776865029981464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 470332.5415418759, 470332.5415418754, 125570.1126512082], 
processed observation next is [1.0, 0.13043478260869565, 0.31172839506172817, 0.8766666666666667, 1.0, 1.0, 0.2591505988073171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1679759076935271, 0.16797590769352694, 0.24148098586770808], 
reward next is 0.7585, 
noisyNet noise sample is [array([3.0179806], dtype=float32), -0.3572726]. 
=============================================
[2019-03-24 01:50:58,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.90082021e-11 9.98300612e-01 1.72538789e-24 1.24192725e-14
 1.69944542e-03], sum to 1.0000
[2019-03-24 01:50:58,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7759
[2019-03-24 01:50:58,317] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 90.0, 1.0, 2.0, 0.3843985690999762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 478198.0789497389, 478198.0789497384, 126483.9810908769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7420200.0000, 
sim time next is 7420800.0000, 
raw observation next is [20.2, 90.0, 1.0, 2.0, 0.3863921011124367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480676.0466058301, 480676.0466058301, 126759.8270123583], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 1.0, 1.0, 0.26951440608623417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1716700166449393, 0.1716700166449393, 0.24376889810068905], 
reward next is 0.7562, 
noisyNet noise sample is [array([0.30809498], dtype=float32), -1.8122476]. 
=============================================
[2019-03-24 01:51:07,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4302372e-12 1.0000000e+00 3.0641206e-26 1.6164419e-17 1.1795642e-09], sum to 1.0000
[2019-03-24 01:51:07,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4714
[2019-03-24 01:51:07,545] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 93.33333333333333, 1.0, 2.0, 0.4789473946605188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575275.3882957068, 575275.3882957068, 139770.3168073402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7510200.0000, 
sim time next is 7510800.0000, 
raw observation next is [22.0, 93.66666666666667, 1.0, 2.0, 0.478144122133895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574402.9506259514, 574402.9506259514, 139650.0789666493], 
processed observation next is [0.0, 0.9565217391304348, 0.37037037037037035, 0.9366666666666668, 1.0, 1.0, 0.3787430025403512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2051439109378398, 0.2051439109378398, 0.2685578441666333], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.9336652], dtype=float32), 0.24602738]. 
=============================================
[2019-03-24 01:51:09,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4614567e-15 9.9999976e-01 3.5347351e-29 2.0118705e-17 2.6243828e-07], sum to 1.0000
[2019-03-24 01:51:09,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7819
[2019-03-24 01:51:09,931] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 86.83333333333333, 1.0, 2.0, 0.4817097468288104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576662.2134818739, 576662.2134818734, 140127.9247231103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [23.3, 86.0, 1.0, 2.0, 0.4859719934882878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580847.5959282393, 580847.5959282388, 140753.2304730742], 
processed observation next is [0.0, 0.43478260869565216, 0.41851851851851857, 0.86, 1.0, 1.0, 0.3880618970098664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20744556997437116, 0.207445569974371, 0.27067928937129654], 
reward next is 0.7293, 
noisyNet noise sample is [array([-1.1031942], dtype=float32), -1.724964]. 
=============================================
[2019-03-24 01:51:12,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6301748e-10 9.9990070e-01 6.1231505e-22 2.2184065e-11 9.9288787e-05], sum to 1.0000
[2019-03-24 01:51:12,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9605
[2019-03-24 01:51:12,163] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4944272570502453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589003.7397275171, 589003.7397275171, 141996.2653553995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554000.0000, 
sim time next is 7554600.0000, 
raw observation next is [23.85, 84.0, 1.0, 2.0, 0.4987379226910527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593153.3766666291, 593153.3766666291, 142633.6857086556], 
processed observation next is [0.0, 0.43478260869565216, 0.43888888888888894, 0.84, 1.0, 1.0, 0.4032594317750628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21184049166665325, 0.21184049166665325, 0.2742955494397223], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.888107], dtype=float32), 1.5544045]. 
=============================================
[2019-03-24 01:51:27,599] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:27,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:27,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-24 01:51:27,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0068902e-04 9.9403846e-01 2.2747360e-10 9.6040014e-05 5.5649681e-03], sum to 1.0000
[2019-03-24 01:51:27,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2056
[2019-03-24 01:51:27,789] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 71.66666666666667, 1.0, 2.0, 0.4168781465707127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513009.4138335757, 513009.4138335757, 130937.8160749763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [23.38333333333333, 72.33333333333333, 1.0, 2.0, 0.4182734718677428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514639.5537546831, 514639.5537546831, 131136.2545304224], 
processed observation next is [1.0, 1.0, 0.4216049382716048, 0.7233333333333333, 1.0, 1.0, 0.30746841889016996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18379984062667254, 0.18379984062667254, 0.2521851048661969], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.05597702], dtype=float32), -1.056663]. 
=============================================
[2019-03-24 01:51:28,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.12008465e-05 9.83860731e-01 2.21161058e-11 9.75534058e-05
 1.60304569e-02], sum to 1.0000
[2019-03-24 01:51:28,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3166
[2019-03-24 01:51:28,270] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1396508.014477782 W.
[2019-03-24 01:51:28,275] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.36666666666667, 51.5, 1.0, 2.0, 0.5907696308923429, 1.0, 1.0, 0.5907696308923429, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1396508.014477782, 1396508.014477782, 267138.5372493759], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7906200.0000, 
sim time next is 7906800.0000, 
raw observation next is [28.53333333333333, 51.0, 1.0, 2.0, 0.5186424825591364, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8330835559966453, 6.9112, 6.9112, 121.9260426156618, 1231918.864677367, 1231918.864677367, 262344.9361516943], 
processed observation next is [1.0, 0.5217391304347826, 0.6123456790123456, 0.51, 1.0, 1.0, 0.4269553363799242, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7913544449958065, 0.0, 0.0, 0.8094621288201359, 0.43997102309905967, 0.43997102309905967, 0.504509492599412], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6150761], dtype=float32), 0.75078106]. 
=============================================
[2019-03-24 01:51:28,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1029962e-12 9.9999952e-01 1.5523687e-20 9.2638891e-10 5.2701040e-07], sum to 1.0000
[2019-03-24 01:51:28,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5004
[2019-03-24 01:51:28,683] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 71.66666666666667, 1.0, 2.0, 0.4168390452591194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513009.4173097277, 513009.4173097272, 130933.4420308272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [23.38333333333333, 72.33333333333333, 1.0, 2.0, 0.4182689471960223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514639.5537558015, 514639.5537558015, 131135.7481375911], 
processed observation next is [1.0, 1.0, 0.4216049382716048, 0.7233333333333333, 1.0, 1.0, 0.3074630323762171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18379984062707197, 0.18379984062707197, 0.25218413103382903], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.15459809], dtype=float32), -0.8794872]. 
=============================================
[2019-03-24 01:51:31,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:31,418] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:31,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-24 01:51:31,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3443316e-08 9.2912287e-01 2.0889798e-19 1.3247657e-07 7.0877030e-02], sum to 1.0000
[2019-03-24 01:51:31,690] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1221
[2019-03-24 01:51:31,695] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 64.33333333333334, 1.0, 2.0, 0.4750508168262238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573439.3853359406, 573439.3853359402, 139268.5506149639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7937400.0000, 
sim time next is 7938000.0000, 
raw observation next is [25.8, 65.0, 1.0, 2.0, 0.4726978886126599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571043.3898741233, 571043.3898741233, 138922.9817274841], 
processed observation next is [1.0, 0.9130434782608695, 0.5111111111111112, 0.65, 1.0, 1.0, 0.3722593912055475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20394406781218688, 0.20394406781218688, 0.26715958024516173], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.47194347], dtype=float32), -0.4624462]. 
=============================================
[2019-03-24 01:51:31,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.583477]
 [61.96311 ]
 [62.517246]
 [63.01177 ]
 [62.680435]], R is [[62.38467026]
 [62.49300003]
 [62.5995903 ]
 [62.7044754 ]
 [62.807724  ]].
[2019-03-24 01:51:31,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:31,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:31,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-24 01:51:31,985] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:31,985] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:31,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-24 01:51:32,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-24 01:51:32,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,231] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-24 01:51:32,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,284] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-24 01:51:32,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-24 01:51:32,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,751] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-24 01:51:32,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,942] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-24 01:51:32,969] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:32,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:32,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-24 01:51:33,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:33,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:33,004] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-24 01:51:33,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:33,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:33,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-24 01:51:33,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:33,100] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:33,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-24 01:51:33,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:33,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:33,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-24 01:51:33,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:51:33,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:33,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-24 01:51:37,413] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:51:37,415] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:51:37,415] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:37,415] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:51:37,417] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:51:37,418] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:51:37,420] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:37,421] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:37,421] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:51:37,423] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:37,425] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:51:37,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-24 01:51:37,454] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-24 01:51:37,456] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-24 01:51:37,477] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-24 01:51:37,502] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-24 01:51:46,048] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:51:46,049] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.4, 36.0, 1.0, 2.0, 0.3272721080907216, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415272.7446069425, 415272.7446069425, 118997.9514714677]
[2019-03-24 01:51:46,050] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:51:46,052] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.5078593e-07 7.0091194e-01 7.7753877e-14 3.2030387e-04 2.9876682e-01], sampled 0.42553663392575514
[2019-03-24 01:51:58,549] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:51:58,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.22870238666667, 61.85729300166667, 1.0, 2.0, 0.4624488108537133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564446.4847566291, 564446.4847566291, 137541.5079062467]
[2019-03-24 01:51:58,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:51:58,554] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3360607e-06 6.9873488e-01 1.6767168e-13 3.8512819e-04 3.0087858e-01], sampled 0.7032766812987764
[2019-03-24 01:52:07,475] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:52:07,479] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.75, 87.0, 1.0, 2.0, 0.539267106056352, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633746.856857394, 633746.856857394, 148826.2842431626]
[2019-03-24 01:52:07,480] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:52:07,485] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3397790e-06 6.9474983e-01 5.9384632e-13 5.2121736e-04 3.0472663e-01], sampled 0.5706957115878485
[2019-03-24 01:52:20,404] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:52:20,405] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.5, 64.0, 1.0, 2.0, 0.932552561803386, 1.0, 2.0, 0.932552561803386, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425095105, 2127428.374831261, 2127428.374831262, 401575.0593782332]
[2019-03-24 01:52:20,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:52:20,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3518880e-06 6.9738662e-01 1.7218839e-13 3.8774562e-04 3.0222425e-01], sampled 0.46579425723707557
[2019-03-24 01:52:20,410] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2127428.374831261 W.
[2019-03-24 01:52:50,220] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:52:50,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.33333333333334, 79.66666666666667, 1.0, 2.0, 0.3506994627703611, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441414.9120225091, 441414.9120225091, 122015.4678260046]
[2019-03-24 01:52:50,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:52:50,226] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0801839e-06 6.9296646e-01 1.1058161e-12 6.0407486e-04 3.0642632e-01], sampled 0.6203722529214564
[2019-03-24 01:53:06,727] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:53:06,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 83.33333333333333, 1.0, 2.0, 0.6880752760627303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784204.2131535008, 784204.2131535008, 173899.0429403807]
[2019-03-24 01:53:06,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:53:06,733] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0356381e-06 7.0045060e-01 9.4336960e-14 3.3572025e-04 2.9921266e-01], sampled 0.054197179015426866
[2019-03-24 01:53:17,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.5995866]
[2019-03-24 01:53:17,139] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.5, 83.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2311071814970061, 6.9112, 6.9112, 121.94756008, 517969.4070020856, 517969.4070020856, 197620.4226513217]
[2019-03-24 01:53:17,141] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:53:17,146] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2372240e-06 6.9513893e-01 5.3686753e-13 5.0869107e-04 3.0435011e-01], sampled 0.1656953971595717
[2019-03-24 01:53:18,163] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5462.4769 2645460105.4886 578.0000
[2019-03-24 01:53:18,274] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 5886.9780 2391530564.7261 372.0000
[2019-03-24 01:53:18,332] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5715.4283 2457307910.2806 434.0000
[2019-03-24 01:53:18,415] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 5780.4505 2415666884.9723 418.0000
[2019-03-24 01:53:18,472] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 5941.7220 2347789261.5511 315.0000
[2019-03-24 01:53:19,487] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 850000, evaluation results [850000.0, 5462.476861728385, 2645460105.4886456, 578.0, 5886.977952663593, 2391530564.7260656, 372.0, 5941.722045570353, 2347789261.551119, 315.0, 5715.428329635467, 2457307910.2806253, 434.0, 5780.450450880477, 2415666884.972312, 418.0]
[2019-03-24 01:53:24,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2748738e-12 5.3276700e-01 4.7800914e-21 7.2988855e-09 4.6723300e-01], sum to 1.0000
[2019-03-24 01:53:24,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3436
[2019-03-24 01:53:24,564] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333334, 14.33333333333333, 1.0, 2.0, 0.3632835877120347, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 467979.7886908306, 467979.7886908301, 118281.8864641483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 160800.0000, 
sim time next is 161400.0000, 
raw observation next is [31.86666666666667, 14.16666666666667, 1.0, 2.0, 0.3637121554031938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469186.214220279, 469186.214220279, 118029.6160320255], 
processed observation next is [1.0, 0.8695652173913043, 0.7358024691358026, 0.1416666666666667, 1.0, 1.0, 0.24251447071808785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16756650507867107, 0.16756650507867107, 0.22698003083081827], 
reward next is 0.7730, 
noisyNet noise sample is [array([-0.09171805], dtype=float32), 1.0224334]. 
=============================================
[2019-03-24 01:53:41,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2239811e-04 9.0948939e-01 2.9460761e-08 8.0736168e-03 8.2314692e-02], sum to 1.0000
[2019-03-24 01:53:42,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1078
[2019-03-24 01:53:42,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1357104.992041496 W.
[2019-03-24 01:53:42,013] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.4, 24.66666666666667, 1.0, 2.0, 0.3722526508035378, 1.0, 2.0, 0.3722526508035378, 1.0, 2.0, 0.6059343997582274, 6.9112, 6.9112, 121.94756008, 1357104.992041496, 1357104.992041496, 284184.6316691447], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 488400.0000, 
sim time next is 489000.0000, 
raw observation next is [32.45, 24.33333333333333, 1.0, 2.0, 0.3703726042905026, 1.0, 2.0, 0.3703726042905026, 1.0, 2.0, 0.603198734709709, 6.9112, 6.9112, 121.94756008, 1351197.182102934, 1351197.182102934, 283356.9990166155], 
processed observation next is [1.0, 0.6521739130434783, 0.7574074074074075, 0.2433333333333333, 1.0, 1.0, 0.25044357653631266, 1.0, 1.0, 0.25044357653631266, 1.0, 1.0, 0.5039984183871362, 0.0, 0.0, 0.8096049824067558, 0.48257042217961926, 0.48257042217961926, 0.5449173058011837], 
reward next is 0.4551, 
noisyNet noise sample is [array([-0.8748977], dtype=float32), -0.7211532]. 
=============================================
[2019-03-24 01:53:42,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[28.785849]
 [27.76148 ]
 [27.404043]
 [27.052965]
 [26.772982]], R is [[29.04123306]
 [29.20431137]
 [28.91226768]
 [28.62314606]
 [28.33691406]].
[2019-03-24 01:53:42,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0639676e-05 2.3156661e-01 1.1999498e-12 9.3021314e-05 7.6831973e-01], sum to 1.0000
[2019-03-24 01:53:42,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8369
[2019-03-24 01:53:42,695] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 44.66666666666667, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 431676.1646536381, 431676.1646536386, 183338.1982395375], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 508800.0000, 
sim time next is 509400.0000, 
raw observation next is [26.0, 45.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 427837.7931233321, 427837.7931233321, 182784.1671386631], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.455, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.15279921182976147, 0.15279921182976147, 0.35150801372819823], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4944333], dtype=float32), 1.2090988]. 
=============================================
[2019-03-24 01:54:01,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8709821e-12 9.9995756e-01 2.8357277e-19 5.1731089e-08 4.2380292e-05], sum to 1.0000
[2019-03-24 01:54:01,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5523
[2019-03-24 01:54:01,267] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.8, 36.33333333333334, 1.0, 2.0, 0.4463970462088809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 542148.1730974347, 542148.1730974342, 135054.1864242529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 836400.0000, 
sim time next is 837000.0000, 
raw observation next is [31.7, 36.5, 1.0, 2.0, 0.444187834935987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 539816.6277281623, 539816.6277281628, 134737.4024350435], 
processed observation next is [0.0, 0.6956521739130435, 0.7296296296296296, 0.365, 1.0, 1.0, 0.33831885111427024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19279165276005797, 0.19279165276005814, 0.2591103892981606], 
reward next is 0.7409, 
noisyNet noise sample is [array([0.42012155], dtype=float32), -0.97702426]. 
=============================================
[2019-03-24 01:54:01,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.48011]
 [72.47516]
 [72.54883]
 [72.56934]
 [72.56232]], R is [[72.49719238]
 [72.51250458]
 [72.52558136]
 [72.53946686]
 [72.55335999]].
[2019-03-24 01:54:05,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2665682e-10 9.9999940e-01 3.9027335e-25 1.3030797e-10 5.4039776e-07], sum to 1.0000
[2019-03-24 01:54:05,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7094
[2019-03-24 01:54:05,651] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 43.33333333333334, 1.0, 2.0, 0.4018693865085279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497276.6360656028, 497276.6360656028, 128867.8858197386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 922800.0000, 
sim time next is 923400.0000, 
raw observation next is [28.35, 43.0, 1.0, 2.0, 0.3986226479395992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493803.474535409, 493803.474535409, 128422.8755190818], 
processed observation next is [0.0, 0.6956521739130435, 0.6055555555555556, 0.43, 1.0, 1.0, 0.2840745808804752, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17635838376264606, 0.17635838376264606, 0.24696706830592655], 
reward next is 0.7530, 
noisyNet noise sample is [array([-0.5507109], dtype=float32), -0.50930005]. 
=============================================
[2019-03-24 01:54:07,309] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6407396e-10 9.9984813e-01 5.7378512e-18 1.2142529e-07 1.5168867e-04], sum to 1.0000
[2019-03-24 01:54:07,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4231331e-08 9.9990916e-01 2.0095044e-15 4.3016112e-06 8.6468586e-05], sum to 1.0000
[2019-03-24 01:54:07,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2710
[2019-03-24 01:54:07,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9978
[2019-03-24 01:54:07,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.63333333333333, 60.66666666666667, 1.0, 2.0, 0.2588584172150412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 333907.5741308543, 333907.5741308543, 109453.434273958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 969600.0000, 
sim time next is 970200.0000, 
raw observation next is [20.75, 60.5, 1.0, 2.0, 0.2595513449419527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334777.3806723494, 334777.3806723494, 110710.4662628514], 
processed observation next is [1.0, 0.21739130434782608, 0.32407407407407407, 0.605, 1.0, 1.0, 0.11851350588327703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1195633502401248, 0.1195633502401248, 0.21290474281317578], 
reward next is 0.7871, 
noisyNet noise sample is [array([-0.9000643], dtype=float32), -1.1794479]. 
=============================================
[2019-03-24 01:54:07,326] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 60.16666666666666, 1.0, 2.0, 0.2899905560081428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 374075.447557412, 374075.4475574115, 112672.0874268806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 965400.0000, 
sim time next is 966000.0000, 
raw observation next is [20.6, 60.33333333333334, 1.0, 2.0, 0.2764986519003993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 356667.4197398776, 356667.4197398776, 110583.1499343881], 
processed observation next is [1.0, 0.17391304347826086, 0.3185185185185186, 0.6033333333333334, 1.0, 1.0, 0.13868887130999916, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12738122133567056, 0.12738122133567056, 0.21265990371997712], 
reward next is 0.7873, 
noisyNet noise sample is [array([0.8333375], dtype=float32), 0.056815844]. 
=============================================
[2019-03-24 01:54:07,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.576942]
 [61.446045]
 [61.439766]
 [61.671165]
 [61.75436 ]], R is [[61.71816635]
 [61.88430786]
 [62.04809189]
 [62.20997238]
 [62.36889648]].
[2019-03-24 01:54:09,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7904323e-07 9.9815851e-01 1.6585538e-12 4.7254096e-07 1.8408076e-03], sum to 1.0000
[2019-03-24 01:54:09,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5878
[2019-03-24 01:54:09,113] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 56.5, 1.0, 2.0, 0.4847075385577413, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7999709964441013, 6.911199999999999, 6.9112, 121.9258692417385, 1196005.372536066, 1196005.372536067, 248077.6137786402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 988200.0000, 
sim time next is 988800.0000, 
raw observation next is [24.73333333333333, 56.33333333333333, 1.0, 2.0, 0.9110540423095099, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.114153929648143, 6.9112, 121.9251262683552, 1238329.421561412, 1134399.650865575, 223964.6738163284], 
processed observation next is [1.0, 0.43478260869565216, 0.4716049382716048, 0.5633333333333332, 1.0, 1.0, 0.894111955130369, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.020295392964814328, 0.0, 0.8094560452269541, 0.4422605077005043, 0.4051427324519911, 0.43070129580063155], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43822145], dtype=float32), 0.68588]. 
=============================================
[2019-03-24 01:54:09,539] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 01:54:09,542] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:54:09,543] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:54:09,544] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:09,544] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:54:09,544] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:09,545] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:54:09,545] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:54:09,546] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:09,547] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:09,547] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:09,564] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-24 01:54:09,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-24 01:54:09,587] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-24 01:54:09,611] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-24 01:54:09,657] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-24 01:54:11,130] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:54:11,131] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.55032893, 44.49259628666667, 1.0, 2.0, 0.2682010358079757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 345961.556202667, 345961.556202667, 110888.8020855809]
[2019-03-24 01:54:11,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:54:11,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.4672872e-06 7.4265760e-01 8.6436972e-13 9.4004517e-04 2.5639591e-01], sampled 0.8804517692936269
[2019-03-24 01:54:28,829] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:54:28,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.95532418666667, 38.93062415333334, 1.0, 2.0, 0.6265495333587447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793659.7537234011, 793659.7537234011, 165397.0677462191]
[2019-03-24 01:54:28,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:54:28,833] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.8201994e-06 7.5009364e-01 1.0024367e-12 9.5670222e-04 2.4894281e-01], sampled 0.46067101703608626
[2019-03-24 01:54:31,408] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:54:31,409] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4950970398376273, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602137.144915907, 602137.144915907, 142517.889667798]
[2019-03-24 01:54:31,410] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:54:31,411] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2672086e-05 7.3587203e-01 4.4317675e-12 1.3444877e-03 2.6277077e-01], sampled 0.7906585598371977
[2019-03-24 01:54:42,121] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:54:42,123] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.77609098, 81.08336148999999, 1.0, 2.0, 0.9200099681365278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1048722.672114572, 1048722.672114571, 221983.2356586632]
[2019-03-24 01:54:42,123] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:54:42,125] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5641180e-06 7.3763168e-01 2.2310532e-12 1.1588897e-03 2.6119983e-01], sampled 0.5464666097274241
[2019-03-24 01:54:47,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:54:47,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.4968565212616644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596458.5941132623, 596458.5941132623, 142540.3913952684]
[2019-03-24 01:54:47,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:54:47,719] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5150254e-06 7.4970591e-01 1.9701496e-13 6.7876483e-04 2.4961185e-01], sampled 0.4007491382258661
[2019-03-24 01:55:02,441] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:55:02,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 70.66666666666667, 1.0, 2.0, 0.6862697645720186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782145.4091733857, 782145.4091733857, 173560.4175241155]
[2019-03-24 01:55:02,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:55:02,447] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0599271e-06 7.5483608e-01 2.8433937e-13 7.2652195e-04 2.4443340e-01], sampled 0.7845713410983108
[2019-03-24 01:55:07,942] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:55:07,943] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.41666666666666, 72.0, 1.0, 2.0, 0.6654273128552696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807000.4880046564, 807000.4880046564, 171773.4715068934]
[2019-03-24 01:55:07,944] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:55:07,946] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2102308e-05 7.3317504e-01 3.9343268e-12 1.3172441e-03 2.6549572e-01], sampled 0.16606994224140603
[2019-03-24 01:55:33,787] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:55:33,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.21666666666667, 51.16666666666667, 1.0, 2.0, 0.3768158624000833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482693.0523720712, 482693.0523720707, 125595.3629460143]
[2019-03-24 01:55:33,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:55:33,793] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.3672165e-06 7.5034904e-01 5.5759911e-13 8.4462500e-04 2.4880099e-01], sampled 0.8797834533300279
[2019-03-24 01:55:40,216] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.61658764]
[2019-03-24 01:55:40,217] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 99.00000000000001, 1.0, 2.0, 0.7194423285572856, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 819972.5848281034, 819972.5848281038, 179853.2317948267]
[2019-03-24 01:55:40,220] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:55:40,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0094243e-05 7.3513049e-01 2.5314690e-12 1.1960753e-03 2.6366335e-01], sampled 0.7734102184232828
[2019-03-24 01:55:49,515] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6155.7688 2417438023.8108 456.0000
[2019-03-24 01:55:50,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6301.0368 2352823694.1553 387.0000
[2019-03-24 01:55:50,356] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6296.5043 2308014153.7761 331.0000
[2019-03-24 01:55:50,361] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6176.2896 2375677663.9126 462.0000
[2019-03-24 01:55:50,496] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5798.9191 2612366342.3188 588.0000
[2019-03-24 01:55:51,513] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 875000, evaluation results [875000.0, 5798.919132919253, 2612366342.318808, 588.0, 6301.036757771965, 2352823694.1552854, 387.0, 6296.504307378666, 2308014153.776141, 331.0, 6155.768772959904, 2417438023.8107777, 456.0, 6176.289621606753, 2375677663.912583, 462.0]
[2019-03-24 01:55:56,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7129541e-06 2.3327006e-02 1.5182557e-15 2.0697621e-04 9.7646028e-01], sum to 1.0000
[2019-03-24 01:55:56,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3409
[2019-03-24 01:55:56,676] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.05, 55.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 425632.9186480321, 425632.9186480316, 182435.8463410517], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1103400.0000, 
sim time next is 1104000.0000, 
raw observation next is [23.8, 56.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 424341.3031070366, 424341.3031070366, 182165.9820101245], 
processed observation next is [1.0, 0.782608695652174, 0.43703703703703706, 0.5666666666666665, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.15155046539537023, 0.15155046539537023, 0.35031919617331636], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44049528], dtype=float32), 0.8963998]. 
=============================================
[2019-03-24 01:55:56,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[61.466953]
 [61.208935]
 [61.532524]
 [61.31448 ]
 [62.93534 ]], R is [[60.76377869]
 [60.15614319]
 [59.55458069]
 [58.95903397]
 [58.3694458 ]].
[2019-03-24 01:55:59,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0811649e-11 9.9999845e-01 8.1982020e-22 1.2324987e-08 1.5957388e-06], sum to 1.0000
[2019-03-24 01:55:59,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3682
[2019-03-24 01:55:59,289] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.78333333333333, 76.5, 1.0, 2.0, 0.2787632795616618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358684.1325584986, 358684.1325584986, 112986.0276861038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.86666666666667, 76.0, 1.0, 2.0, 0.2712903170955951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 349015.4611896209, 349015.4611896209, 112096.3647437751], 
processed observation next is [1.0, 0.21739130434782608, 0.25432098765432115, 0.76, 1.0, 1.0, 0.1324884727328513, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12464837899629318, 0.12464837899629318, 0.21556993219956752], 
reward next is 0.7844, 
noisyNet noise sample is [array([-0.3073745], dtype=float32), -0.026663197]. 
=============================================
[2019-03-24 01:56:06,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6168506e-15 1.0000000e+00 1.4302247e-27 6.0716497e-16 7.1358362e-12], sum to 1.0000
[2019-03-24 01:56:06,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8500
[2019-03-24 01:56:06,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 81.33333333333334, 1.0, 2.0, 0.3962839516709105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 490937.0195801841, 490937.0195801846, 128095.1939043202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [21.4, 82.5, 1.0, 2.0, 0.3951004080636598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489764.0622078954, 489764.0622078954, 127935.9275438229], 
processed observation next is [1.0, 0.9565217391304348, 0.3481481481481481, 0.825, 1.0, 1.0, 0.27988143817102357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17491573650281977, 0.17491573650281977, 0.2460306298919671], 
reward next is 0.7540, 
noisyNet noise sample is [array([1.2568742], dtype=float32), 0.23016377]. 
=============================================
[2019-03-24 01:56:08,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2494936e-12 1.0000000e+00 6.1369601e-18 7.2330218e-11 1.1943203e-09], sum to 1.0000
[2019-03-24 01:56:08,520] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9627
[2019-03-24 01:56:08,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1452857.085561479 W.
[2019-03-24 01:56:08,535] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.91666666666666, 29.66666666666666, 1.0, 2.0, 0.3973411386998331, 1.0, 1.0, 0.3973411386998331, 1.0, 1.0, 0.6482410805582786, 6.911199999999999, 6.9112, 121.94756008, 1452857.085561479, 1452857.085561479, 294859.0826403609], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1354200.0000, 
sim time next is 1354800.0000, 
raw observation next is [30.93333333333333, 29.33333333333334, 1.0, 2.0, 0.5218052174895392, 1.0, 2.0, 0.5218052174895392, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425337623, 1279063.478406927, 1279063.478406927, 245746.4013012087], 
processed observation next is [1.0, 0.6956521739130435, 0.7012345679012344, 0.2933333333333334, 1.0, 1.0, 0.43072049701135623, 1.0, 1.0, 0.43072049701135623, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621282764084, 0.4568083851453311, 0.4568083851453311, 0.4725892332715552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5817348], dtype=float32), -1.3164581]. 
=============================================
[2019-03-24 01:56:18,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1916543e-15 1.0000000e+00 1.2908946e-25 1.7125360e-15 8.0230659e-16], sum to 1.0000
[2019-03-24 01:56:18,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9766
[2019-03-24 01:56:18,794] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 24.0, 1.0, 2.0, 0.4112055431347459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326127, 130109.4829956549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515600.0000, 
sim time next is 1516200.0000, 
raw observation next is [35.13333333333333, 23.33333333333333, 1.0, 2.0, 0.421640286768461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 518829.0113772424, 518829.0113772419, 131622.911452389], 
processed observation next is [0.0, 0.5652173913043478, 0.8567901234567901, 0.23333333333333328, 1.0, 1.0, 0.31147653186721547, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18529607549187227, 0.18529607549187213, 0.2531209835622865], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.37573984], dtype=float32), -0.95863193]. 
=============================================
[2019-03-24 01:56:20,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4592216e-14 1.0000000e+00 2.9744439e-23 2.1460800e-12 9.9943098e-10], sum to 1.0000
[2019-03-24 01:56:20,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-24 01:56:20,742] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 52.0, 1.0, 2.0, 0.5317715958465058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628449.0041842716, 628449.0041842716, 147751.7730522341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1533600.0000, 
sim time next is 1534200.0000, 
raw observation next is [29.2, 54.0, 1.0, 2.0, 0.5493174414445497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650148.1797353628, 650148.1797353628, 150663.7779339637], 
processed observation next is [0.0, 0.782608695652174, 0.637037037037037, 0.54, 1.0, 1.0, 0.4634731445768449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23219577847691528, 0.23219577847691528, 0.2897380344883917], 
reward next is 0.7103, 
noisyNet noise sample is [array([-0.06339929], dtype=float32), 0.24704951]. 
=============================================
[2019-03-24 01:56:22,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9616286e-14 1.0000000e+00 3.1655110e-20 2.4875848e-11 9.5591049e-11], sum to 1.0000
[2019-03-24 01:56:22,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9891
[2019-03-24 01:56:22,252] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 76.0, 1.0, 2.0, 0.3840485144116421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479699.6430867161, 479699.6430867161, 126473.2350892989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1562400.0000, 
sim time next is 1563000.0000, 
raw observation next is [21.58333333333333, 76.5, 1.0, 2.0, 0.7765180891641663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9341472741746, 969851.2106623066, 969851.2106623063, 194439.8588268324], 
processed observation next is [1.0, 0.08695652173913043, 0.35493827160493807, 0.765, 1.0, 1.0, 0.7339501061478171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8095159353244101, 0.3463754323793952, 0.3463754323793951, 0.3739228054362162], 
reward next is 0.6261, 
noisyNet noise sample is [array([-0.64105785], dtype=float32), 0.045829568]. 
=============================================
[2019-03-24 01:56:22,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.37533 ]
 [60.32981 ]
 [60.4462  ]
 [60.404972]
 [60.533085]], R is [[59.2883606 ]
 [59.45225906]
 [59.61439133]
 [59.77479553]
 [59.93354797]].
[2019-03-24 01:56:27,906] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.19254056e-08 9.99969244e-01 1.09071787e-18 6.75575802e-06
 2.39308520e-05], sum to 1.0000
[2019-03-24 01:56:27,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5310
[2019-03-24 01:56:27,913] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 69.0, 1.0, 2.0, 0.7779736947052366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 966567.9933523152, 966567.9933523152, 194629.0634808405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1692000.0000, 
sim time next is 1692600.0000, 
raw observation next is [23.15, 69.0, 1.0, 2.0, 0.8716805066612843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1082083.92529159, 1082083.92529159, 214894.0712606461], 
processed observation next is [1.0, 0.6086956521739131, 0.4129629629629629, 0.69, 1.0, 1.0, 0.8472386984062908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3864585447469964, 0.3864585447469964, 0.41325782934739635], 
reward next is 0.5867, 
noisyNet noise sample is [array([0.57264256], dtype=float32), 0.9583537]. 
=============================================
[2019-03-24 01:56:31,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4651740e-09 9.9999774e-01 1.9643192e-15 3.0339027e-07 1.8780449e-06], sum to 1.0000
[2019-03-24 01:56:31,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2605
[2019-03-24 01:56:31,870] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.28333333333333, 72.33333333333333, 1.0, 2.0, 0.7554004784194259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 930104.7571202646, 930104.7571202641, 189759.3936838607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1759800.0000, 
sim time next is 1760400.0000, 
raw observation next is [23.4, 72.0, 1.0, 2.0, 0.75216536025585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925277.8708283833, 925277.8708283833, 189077.4284736365], 
processed observation next is [1.0, 0.391304347826087, 0.42222222222222217, 0.72, 1.0, 1.0, 0.7049587622093453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3304563824387083, 0.3304563824387083, 0.3636104393723779], 
reward next is 0.6364, 
noisyNet noise sample is [array([-0.8938337], dtype=float32), -0.25172076]. 
=============================================
[2019-03-24 01:56:33,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9039287e-07 1.1758566e-01 8.6113278e-12 6.3431060e-01 2.4810331e-01], sum to 1.0000
[2019-03-24 01:56:33,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-24 01:56:33,253] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.35, 65.33333333333334, 1.0, 2.0, 0.4417497106619919, 1.0, 2.0, 0.4417497106619919, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1054752.163448632, 1054752.163448632, 220011.9703539781], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1774200.0000, 
sim time next is 1774800.0000, 
raw observation next is [25.4, 65.0, 1.0, 2.0, 0.2998988277532825, 1.0, 2.0, 0.2998988277532825, 1.0, 1.0, 0.4812344914361553, 6.911200000000001, 6.9112, 121.94756008, 1065769.804816409, 1065769.804816409, 255781.3314512486], 
processed observation next is [1.0, 0.5652173913043478, 0.49629629629629624, 0.65, 1.0, 1.0, 0.16654622351581252, 1.0, 1.0, 0.16654622351581252, 1.0, 0.5, 0.35154311429519414, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3806320731487175, 0.3806320731487175, 0.4918871758677858], 
reward next is 0.5081, 
noisyNet noise sample is [array([-0.29342508], dtype=float32), 0.53940713]. 
=============================================
[2019-03-24 01:56:36,894] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.10496036e-10 9.99995351e-01 4.34229272e-14 2.58350292e-06
 2.01628109e-06], sum to 1.0000
[2019-03-24 01:56:36,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0581
[2019-03-24 01:56:36,905] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 76.83333333333333, 1.0, 2.0, 0.3496408414912117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438628.0898494672, 438628.0898494672, 121854.5935392862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1842600.0000, 
sim time next is 1843200.0000, 
raw observation next is [21.4, 76.0, 1.0, 2.0, 0.3508679474837298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439982.8287792619, 439982.8287792619, 122014.0061126359], 
processed observation next is [1.0, 0.34782608695652173, 0.3481481481481481, 0.76, 1.0, 1.0, 0.22722374700444023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1571367245640221, 0.1571367245640221, 0.23464231944737673], 
reward next is 0.7654, 
noisyNet noise sample is [array([-0.10753772], dtype=float32), -0.6560409]. 
=============================================
[2019-03-24 01:56:38,755] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0867912e-12 9.9999774e-01 2.9907415e-23 5.2785242e-07 1.8358475e-06], sum to 1.0000
[2019-03-24 01:56:38,763] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1696
[2019-03-24 01:56:38,765] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 89.33333333333334, 1.0, 2.0, 0.4288329418315157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 526006.1069870442, 526006.1069870439, 132623.3051702865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1880400.0000, 
sim time next is 1881000.0000, 
raw observation next is [21.25, 89.5, 1.0, 2.0, 0.4280587106093559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525022.0943225239, 525022.0943225239, 132509.6385498411], 
processed observation next is [1.0, 0.782608695652174, 0.3425925925925926, 0.895, 1.0, 1.0, 0.3191175126301856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18750789082947283, 0.18750789082947283, 0.25482622798046367], 
reward next is 0.7452, 
noisyNet noise sample is [array([-1.2680463], dtype=float32), -0.14779693]. 
=============================================
[2019-03-24 01:56:38,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[86.161736]
 [86.17907 ]
 [85.96045 ]
 [85.24157 ]
 [84.73731 ]], R is [[85.93952942]
 [85.8250885 ]
 [85.71231842]
 [85.60131836]
 [85.49143219]].
[2019-03-24 01:56:39,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9226686e-10 9.9997926e-01 3.6106492e-16 1.4212582e-06 1.9276838e-05], sum to 1.0000
[2019-03-24 01:56:39,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0469
[2019-03-24 01:56:39,217] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 92.0, 1.0, 2.0, 0.3868195387417978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480389.1251618484, 480389.1251618484, 126801.8812157684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1903800.0000, 
sim time next is 1904400.0000, 
raw observation next is [20.0, 92.0, 1.0, 2.0, 0.38422171268601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477601.3701964495, 477601.3701964495, 126451.6807122734], 
processed observation next is [1.0, 0.043478260869565216, 0.2962962962962963, 0.92, 1.0, 1.0, 0.26693061034048815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1705719179273034, 0.1705719179273034, 0.24317630906206422], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.01658965], dtype=float32), 0.20065063]. 
=============================================
[2019-03-24 01:56:41,486] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 01:56:41,487] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:56:41,489] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:56:41,489] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:56:41,492] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:56:41,491] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:56:41,493] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:56:41,493] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:56:41,494] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:56:41,495] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:56:41,495] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:56:41,512] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-24 01:56:41,512] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-24 01:56:41,513] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-24 01:56:41,558] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-24 01:56:41,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-24 01:56:49,810] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:56:49,811] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.49898546333333, 21.45570400833333, 1.0, 2.0, 0.3880824670331607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485871.7953634097, 485871.7953634097, 127051.2227929603]
[2019-03-24 01:56:49,812] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:56:49,815] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.3565860e-10 9.9821305e-01 2.7836679e-16 2.5654375e-05 1.7612079e-03], sampled 0.5708996339221332
[2019-03-24 01:57:32,746] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:57:32,748] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 99.00000000000001, 1.0, 2.0, 0.588081176196052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9362443849709203, 6.9112, 6.9112, 121.9260426156618, 1340967.247747805, 1340967.247747805, 289254.6424519992]
[2019-03-24 01:57:32,749] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:57:32,753] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.4225318e-09 9.9678588e-01 7.0865250e-15 6.5111235e-05 3.1489730e-03], sampled 0.46358053735659943
[2019-03-24 01:57:32,755] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1340967.247747805 W.
[2019-03-24 01:57:33,246] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:57:33,248] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.9, 93.50000000000001, 1.0, 2.0, 0.5395078217052846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648878.6605050241, 648878.6605050241, 149433.5528802167]
[2019-03-24 01:57:33,249] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:57:33,252] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3618273e-09 9.9636650e-01 4.4802834e-15 6.2988598e-05 3.5705063e-03], sampled 0.0848195183793915
[2019-03-24 01:57:55,289] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:57:55,291] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.3, 45.0, 1.0, 2.0, 0.5613916776457077, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9054352710118185, 6.9112, 6.9112, 121.9260426156277, 1344978.334174513, 1344978.334174513, 277440.2074954833]
[2019-03-24 01:57:55,293] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:57:55,295] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7283997e-09 9.9737942e-01 2.1454966e-15 4.6444016e-05 2.5741661e-03], sampled 0.9251747413826273
[2019-03-24 01:57:55,297] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1344978.334174513 W.
[2019-03-24 01:58:09,029] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:58:09,030] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.6987808692160443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 796411.7914630122, 796411.7914630118, 175915.8484739143]
[2019-03-24 01:58:09,031] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:58:09,033] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6727667e-09 9.9675590e-01 1.8863871e-15 5.0127390e-05 3.1939209e-03], sampled 0.8577954379208765
[2019-03-24 01:58:09,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6302058]
[2019-03-24 01:58:09,785] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.9, 60.0, 1.0, 2.0, 0.4433550173271879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541874.1605286038, 541874.1605286038, 134704.2088413212]
[2019-03-24 01:58:09,786] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:58:09,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3493195e-09 9.9785334e-01 6.2885108e-16 3.3000801e-05 2.1136936e-03], sampled 0.2715645802096981
[2019-03-24 01:58:21,343] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8735.1863 2172573658.3703 491.0000
[2019-03-24 01:58:21,570] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8551.4198 2250567766.7946 549.0000
[2019-03-24 01:58:21,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8882.7193 2122646897.6983 430.0000
[2019-03-24 01:58:21,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8667.3294 2197140100.9276 570.0000
[2019-03-24 01:58:22,010] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8064.1288 2447207362.2117 745.0000
[2019-03-24 01:58:23,026] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 900000, evaluation results [900000.0, 8064.128776992326, 2447207362.2116847, 745.0, 8735.186296258622, 2172573658.370341, 491.0, 8882.719260050708, 2122646897.6983428, 430.0, 8551.419751336694, 2250567766.794632, 549.0, 8667.329399792234, 2197140100.927587, 570.0]
[2019-03-24 01:58:29,476] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7826419e-12 9.9999666e-01 4.1463964e-19 2.0728706e-10 3.3352071e-06], sum to 1.0000
[2019-03-24 01:58:29,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-24 01:58:29,492] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 65.0, 1.0, 2.0, 0.6005102148633794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688854.058490721, 688854.058490721, 158386.7279439515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [28.63333333333333, 65.66666666666667, 1.0, 2.0, 0.6013776537253146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 689753.4332320658, 689753.4332320653, 158531.7395171375], 
processed observation next is [0.0, 0.7391304347826086, 0.6160493827160493, 0.6566666666666667, 1.0, 1.0, 0.5254495877682317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2463405118685949, 0.24634051186859474, 0.30486872984064906], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.66666764], dtype=float32), 0.5349748]. 
=============================================
[2019-03-24 01:58:31,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9796417e-12 9.9744320e-01 1.3084842e-18 2.4336222e-08 2.5568269e-03], sum to 1.0000
[2019-03-24 01:58:31,120] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-24 01:58:31,128] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.11666666666667, 89.66666666666667, 1.0, 2.0, 0.4585347505719484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554713.3335544587, 554713.3335544587, 136800.8364213576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2099400.0000, 
sim time next is 2100000.0000, 
raw observation next is [22.23333333333333, 89.33333333333334, 1.0, 2.0, 0.461499729708419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557604.3524556154, 557604.3524556154, 137225.1633563873], 
processed observation next is [0.0, 0.30434782608695654, 0.37901234567901226, 0.8933333333333334, 1.0, 1.0, 0.3589282496528798, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19914441159129123, 0.19914441159129123, 0.2638945449161294], 
reward next is 0.7361, 
noisyNet noise sample is [array([0.88409954], dtype=float32), 0.6857477]. 
=============================================
[2019-03-24 01:58:31,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.48572]
 [70.56514]
 [70.62356]
 [70.66735]
 [70.74522]], R is [[70.4826355 ]
 [70.51473236]
 [70.54736328]
 [70.58071899]
 [70.61490631]].
[2019-03-24 01:58:34,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9250950e-09 9.9999166e-01 1.0133427e-13 3.8594688e-08 8.3585210e-06], sum to 1.0000
[2019-03-24 01:58:34,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8353
[2019-03-24 01:58:34,943] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 89.0, 1.0, 2.0, 0.6245746367383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728599.8148983652, 728599.8148983652, 163155.0482917241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2170200.0000, 
sim time next is 2170800.0000, 
raw observation next is [24.1, 89.0, 1.0, 2.0, 0.6137767161400187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716503.1697562041, 716503.1697562041, 161268.3274942555], 
processed observation next is [1.0, 0.13043478260869565, 0.4481481481481482, 0.89, 1.0, 1.0, 0.5402103763571652, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2558939891986443, 0.2558939891986443, 0.31013139902741443], 
reward next is 0.6899, 
noisyNet noise sample is [array([0.63423276], dtype=float32), 0.8064985]. 
=============================================
[2019-03-24 01:58:39,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0414244e-13 1.0000000e+00 1.9966902e-21 1.6301878e-11 3.7649328e-10], sum to 1.0000
[2019-03-24 01:58:39,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1474
[2019-03-24 01:58:39,477] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 95.0, 1.0, 2.0, 0.5294701392274793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626096.1465590566, 626096.1465590566, 147393.6886032473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2235600.0000, 
sim time next is 2236200.0000, 
raw observation next is [22.7, 95.16666666666667, 1.0, 2.0, 0.5318051403469574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628605.945992335, 628605.945992335, 147762.101599602], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9516666666666667, 1.0, 1.0, 0.4426251670797111, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22450212356869106, 0.22450212356869106, 0.2841578876915423], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.5241286], dtype=float32), -0.18546985]. 
=============================================
[2019-03-24 01:58:42,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7315152e-09 9.9392372e-01 9.5086394e-14 1.8832195e-03 4.1931178e-03], sum to 1.0000
[2019-03-24 01:58:42,383] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8189
[2019-03-24 01:58:42,387] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 68.0, 1.0, 2.0, 0.4905587553139672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426014446, 585435.1681056835, 585435.168105684, 141432.0537174933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2308800.0000, 
sim time next is 2309400.0000, 
raw observation next is [25.95, 68.5, 1.0, 2.0, 0.4846134532627567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156575, 578764.0903029642, 578764.0903029637, 140526.3155325905], 
processed observation next is [1.0, 0.7391304347826086, 0.5166666666666666, 0.685, 1.0, 1.0, 0.3864445872175675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201074, 0.20670146082248722, 0.20670146082248705, 0.27024291448575094], 
reward next is 0.7298, 
noisyNet noise sample is [array([1.0215892], dtype=float32), -1.0565557]. 
=============================================
[2019-03-24 01:58:43,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.91130578e-09 1.16077654e-01 9.63458552e-17 2.83624022e-03
 8.81086171e-01], sum to 1.0000
[2019-03-24 01:58:43,220] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2295
[2019-03-24 01:58:43,231] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.16666666666666, 24.0, 1.0, 2.0, 0.4760228823751517, 1.0, 2.0, 0.4760228823751517, 1.0, 2.0, 0.7647287205794643, 6.9112, 6.9112, 121.94756008, 1697065.785938246, 1697065.785938246, 331836.3066644173], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2478000.0000, 
sim time next is 2478600.0000, 
raw observation next is [34.09999999999999, 24.0, 1.0, 2.0, 0.471687141067709, 1.0, 2.0, 0.471687141067709, 1.0, 2.0, 0.758024339260767, 6.911199999999999, 6.9112, 121.94756008, 1682932.029143786, 1682932.029143787, 329748.7840620281], 
processed observation next is [1.0, 0.6956521739130435, 0.8185185185185181, 0.24, 1.0, 1.0, 0.3710561203187012, 1.0, 1.0, 0.3710561203187012, 1.0, 1.0, 0.6975304240759586, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6010471532656378, 0.6010471532656382, 0.6341322770423617], 
reward next is 0.3659, 
noisyNet noise sample is [array([0.62277496], dtype=float32), 2.7180526]. 
=============================================
[2019-03-24 01:58:51,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3665012e-09 9.9926156e-01 1.8973681e-12 7.3384703e-04 4.5100178e-06], sum to 1.0000
[2019-03-24 01:58:51,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-24 01:58:51,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1602558.956526501 W.
[2019-03-24 01:58:51,493] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.76666666666667, 23.0, 1.0, 2.0, 0.4494288321191912, 1.0, 2.0, 0.4494288321191912, 1.0, 2.0, 0.7220806790924879, 6.911199999999999, 6.9112, 121.94756008, 1602558.956526501, 1602558.956526502, 319282.9237161257], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2468400.0000, 
sim time next is 2469000.0000, 
raw observation next is [34.88333333333333, 23.0, 1.0, 2.0, 0.4504355188474224, 1.0, 2.0, 0.4504355188474224, 1.0, 2.0, 0.7234016808607303, 6.9112, 6.9112, 121.94756008, 1604605.182559231, 1604605.182559231, 319772.5104857122], 
processed observation next is [1.0, 0.5652173913043478, 0.8475308641975309, 0.23, 1.0, 1.0, 0.3457565700564552, 1.0, 1.0, 0.3457565700564552, 1.0, 1.0, 0.6542521010759128, 0.0, 0.0, 0.8096049824067558, 0.5730732794854396, 0.5730732794854396, 0.6149471355494466], 
reward next is 0.3851, 
noisyNet noise sample is [array([0.24501885], dtype=float32), 2.1842325]. 
=============================================
[2019-03-24 01:58:51,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[45.46054 ]
 [45.233128]
 [45.32982 ]
 [46.41528 ]
 [45.53903 ]], R is [[44.88748169]
 [44.82460022]
 [44.73300934]
 [44.28567886]
 [43.84282303]].
[2019-03-24 01:58:51,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3899863e-09 9.9999857e-01 3.4247226e-15 1.4366192e-06 4.5552171e-09], sum to 1.0000
[2019-03-24 01:58:51,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1058
[2019-03-24 01:58:51,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1604601.794930502 W.
[2019-03-24 01:58:51,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.88333333333333, 23.0, 1.0, 2.0, 0.7336082415964185, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9575992267182032, 6.9112, 6.9112, 121.926042615586, 1604601.794930502, 1604601.794930502, 312972.1355570391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2469000.0000, 
sim time next is 2469600.0000, 
raw observation next is [35.0, 23.0, 1.0, 2.0, 0.6813414644258642, 1.0, 1.0, 0.6813414644258642, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1640332.833012758, 1640332.833012757, 301001.1865244076], 
processed observation next is [1.0, 0.6086956521739131, 0.8518518518518519, 0.23, 1.0, 1.0, 0.6206446005069811, 1.0, 0.5, 0.6206446005069811, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5858331546474136, 0.5858331546474131, 0.5788484356238608], 
reward next is 0.4212, 
noisyNet noise sample is [array([0.2993889], dtype=float32), -0.8161158]. 
=============================================
[2019-03-24 01:58:56,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3299634e-20 1.0000000e+00 5.3864661e-26 1.7468567e-14 1.6165513e-19], sum to 1.0000
[2019-03-24 01:58:56,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6621
[2019-03-24 01:58:56,852] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.85, 50.16666666666667, 1.0, 2.0, 0.6014721112367123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690502.9683938372, 690502.9683938372, 158579.2507669561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2736600.0000, 
sim time next is 2737200.0000, 
raw observation next is [31.7, 51.33333333333334, 1.0, 2.0, 0.6079834962933525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696333.3104685412, 696333.3104685412, 159627.1134719914], 
processed observation next is [0.0, 0.6956521739130435, 0.7296296296296296, 0.5133333333333334, 1.0, 1.0, 0.5333136860635148, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.248690468024479, 0.248690468024479, 0.3069752182153681], 
reward next is 0.6930, 
noisyNet noise sample is [array([-0.04458003], dtype=float32), -0.7060831]. 
=============================================
[2019-03-24 01:58:57,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2104416e-15 1.0000000e+00 3.0874705e-18 1.9647446e-10 2.2603343e-13], sum to 1.0000
[2019-03-24 01:58:57,049] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1802
[2019-03-24 01:58:57,057] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1658996.356807721 W.
[2019-03-24 01:58:57,063] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 33.33333333333334, 1.0, 2.0, 0.4785790621433932, 1.0, 2.0, 0.4785790621433932, 1.0, 1.0, 0.7628489587874904, 6.911200000000001, 6.9112, 121.94756008, 1658996.356807721, 1658996.35680772, 333304.2848899035], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2564400.0000, 
sim time next is 2565000.0000, 
raw observation next is [33.3, 33.5, 1.0, 2.0, 0.4692925850697896, 1.0, 2.0, 0.4692925850697896, 1.0, 2.0, 0.7479082670259897, 6.9112, 6.9112, 121.94756008, 1624639.404597283, 1624639.404597283, 328869.6574761283], 
processed observation next is [1.0, 0.6956521739130435, 0.7888888888888888, 0.335, 1.0, 1.0, 0.3682054584164162, 1.0, 1.0, 0.3682054584164162, 1.0, 1.0, 0.684885333782487, 0.0, 0.0, 0.8096049824067558, 0.580228358784744, 0.580228358784744, 0.6324416489925544], 
reward next is 0.3676, 
noisyNet noise sample is [array([0.2773321], dtype=float32), -0.62443876]. 
=============================================
[2019-03-24 01:58:57,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[57.90167 ]
 [56.961548]
 [57.238037]
 [57.026165]
 [56.815895]], R is [[58.16889954]
 [57.58721161]
 [57.38201141]
 [57.13532639]
 [56.56397247]].
[2019-03-24 01:58:59,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0085180e-19 1.0000000e+00 1.2680572e-26 1.8005691e-14 2.8894758e-19], sum to 1.0000
[2019-03-24 01:58:59,712] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6528
[2019-03-24 01:58:59,719] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 76.66666666666667, 1.0, 2.0, 0.5955955626364241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688882.8743650052, 688882.8743650052, 157810.0457502649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2659200.0000, 
sim time next is 2659800.0000, 
raw observation next is [26.16666666666667, 77.33333333333333, 1.0, 2.0, 0.5915847291854271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685114.0522935295, 685114.052293529, 157161.2581270841], 
processed observation next is [0.0, 0.782608695652174, 0.5246913580246916, 0.7733333333333333, 1.0, 1.0, 0.5137913442683656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24468359010483196, 0.2446835901048318, 0.30223318870593097], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.5704252], dtype=float32), -0.91624045]. 
=============================================
[2019-03-24 01:59:01,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6834886e-19 1.0000000e+00 7.2720411e-27 5.4352881e-16 2.3880886e-18], sum to 1.0000
[2019-03-24 01:59:01,431] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-24 01:59:01,438] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.5986578121553612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689836.6107010539, 689836.6107010539, 158216.7572131577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2646000.0000, 
sim time next is 2646600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6022181316752384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693378.3783867675, 693378.3783867675, 158804.9116806921], 
processed observation next is [0.0, 0.6521739130434783, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5264501567562362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24763513513813123, 0.24763513513813123, 0.3053940609244079], 
reward next is 0.6946, 
noisyNet noise sample is [array([0.77359813], dtype=float32), 0.08843905]. 
=============================================
[2019-03-24 01:59:03,517] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6355710e-17 1.0000000e+00 2.5692739e-21 5.4408775e-09 8.4387235e-16], sum to 1.0000
[2019-03-24 01:59:03,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9019
[2019-03-24 01:59:03,529] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.5383783991913562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635819.5482339564, 635819.5482339564, 148810.0212394636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2691000.0000, 
sim time next is 2691600.0000, 
raw observation next is [22.33333333333334, 98.0, 1.0, 2.0, 0.5366923813171431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634392.7787497571, 634392.7787497571, 148557.4451103701], 
processed observation next is [0.0, 0.13043478260869565, 0.38271604938271625, 0.98, 1.0, 1.0, 0.44844331109183705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2265688495534847, 0.2265688495534847, 0.28568739444301944], 
reward next is 0.7143, 
noisyNet noise sample is [array([-0.5968259], dtype=float32), -1.4777768]. 
=============================================
[2019-03-24 01:59:05,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.41449386e-14 1.00000000e+00 1.06799785e-20 1.91713763e-11
 2.67204206e-12], sum to 1.0000
[2019-03-24 01:59:05,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7739
[2019-03-24 01:59:05,862] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 55.0, 1.0, 2.0, 0.6044936363699682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692800.4162241672, 692800.4162241672, 159044.906823813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2727000.0000, 
sim time next is 2727600.0000, 
raw observation next is [30.8, 56.0, 1.0, 2.0, 0.6148286752558585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702341.1321619293, 702341.1321619293, 160729.3108956975], 
processed observation next is [0.0, 0.5652173913043478, 0.6962962962962963, 0.56, 1.0, 1.0, 0.5414627086379268, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2508361186292605, 0.2508361186292605, 0.30909482864557214], 
reward next is 0.6909, 
noisyNet noise sample is [array([0.08635662], dtype=float32), 0.23485881]. 
=============================================
[2019-03-24 01:59:09,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8576309e-09 1.0000000e+00 7.6666963e-12 5.8669144e-08 2.2337208e-08], sum to 1.0000
[2019-03-24 01:59:09,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4461
[2019-03-24 01:59:09,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2432068.425652338 W.
[2019-03-24 01:59:09,074] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.78333333333333, 63.0, 1.0, 2.0, 0.794483108311278, 1.0, 2.0, 0.7106062161320736, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2432068.425652338, 2432068.425652338, 455594.2618915114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2807400.0000, 
sim time next is 2808000.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.153432273623912, 6.9112, 121.9252660292798, 2451387.362888529, 2327343.578398143, 443049.1730189873], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.63, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.024223227362391242, 0.0, 0.8094569730941523, 0.8754954867459032, 0.8311941351421939, 0.8520176404211294], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4703735], dtype=float32), 0.5727698]. 
=============================================
[2019-03-24 01:59:09,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[30.599072]
 [30.845354]
 [30.626242]
 [31.028387]
 [31.333435]], R is [[30.44572067]
 [30.14126396]
 [29.83985138]
 [29.70939064]
 [29.65116501]].
[2019-03-24 01:59:09,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6963678e-10 1.0000000e+00 3.4044761e-13 1.5510915e-08 1.9115312e-09], sum to 1.0000
[2019-03-24 01:59:09,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2304
[2019-03-24 01:59:09,575] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1864052.911224639 W.
[2019-03-24 01:59:09,577] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.8172229943874847, 1.0, 2.0, 0.8172229943874847, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156617, 1864052.911224639, 1864052.911224638, 350923.0304450472], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2797200.0000, 
sim time next is 2797800.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5723942500327646, 1.0, 2.0, 0.5723942500327646, 1.0, 1.0, 0.9112702876314484, 6.9112, 6.9112, 121.94756008, 1958515.612060671, 1958515.612060671, 380539.8429359879], 
processed observation next is [1.0, 0.391304347826087, 0.5987654320987656, 0.7816666666666667, 1.0, 1.0, 0.49094553575329114, 1.0, 1.0, 0.49094553575329114, 1.0, 0.5, 0.8890878595393104, 0.0, 0.0, 0.8096049824067558, 0.6994698614502396, 0.6994698614502396, 0.7318073902615152], 
reward next is 0.2682, 
noisyNet noise sample is [array([1.0185869], dtype=float32), -0.42128345]. 
=============================================
[2019-03-24 01:59:10,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3193925e-18 1.0000000e+00 4.1118434e-23 9.6908808e-18 7.1657448e-20], sum to 1.0000
[2019-03-24 01:59:10,645] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4169
[2019-03-24 01:59:10,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 94.0, 1.0, 2.0, 0.5736945876654089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683408.4484021896, 683408.4484021896, 154919.4182314637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869200.0000, 
sim time next is 2869800.0000, 
raw observation next is [22.33333333333334, 94.00000000000001, 1.0, 2.0, 0.569494795220718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679207.9421276824, 679207.9421276824, 154237.2180370298], 
processed observation next is [1.0, 0.21739130434782608, 0.38271604938271625, 0.9400000000000002, 1.0, 1.0, 0.48749380383418806, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24257426504560084, 0.24257426504560084, 0.29661003468659575], 
reward next is 0.7034, 
noisyNet noise sample is [array([0.0544516], dtype=float32), 1.3525723]. 
=============================================
[2019-03-24 01:59:13,152] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 01:59:13,154] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:59:13,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:59:13,156] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:13,157] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:13,157] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:59:13,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:59:13,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:59:13,159] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:13,159] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:13,160] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:13,172] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-24 01:59:13,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-24 01:59:13,193] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-24 01:59:13,243] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-24 01:59:13,271] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-24 01:59:23,148] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 01:59:23,150] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.76020351833333, 47.83892888666666, 1.0, 2.0, 0.3956564013478581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488386.1952696094, 488386.1952696094, 127966.296716098]
[2019-03-24 01:59:23,151] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:59:23,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.3302622e-26 1.0000000e+00 1.8815964e-33 5.6942631e-24 5.6638359e-28], sampled 0.20227712937825393
[2019-03-24 01:59:24,253] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 01:59:24,256] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.54538122833334, 54.01568569166666, 1.0, 2.0, 0.2888535212707523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 370690.7566728781, 370690.7566728776, 114208.9355215237]
[2019-03-24 01:59:24,256] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:59:24,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0745212e-25 1.0000000e+00 2.2347577e-33 6.5996679e-24 6.8546273e-28], sampled 0.28061927900010986
[2019-03-24 01:59:27,619] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 01:59:27,623] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.75, 26.5, 1.0, 2.0, 0.3523197760731396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446014.063563931, 446014.063563931, 122261.2769497325]
[2019-03-24 01:59:27,625] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:59:27,628] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.7850461e-26 1.0000000e+00 2.1348136e-33 5.5123151e-24 5.0305300e-28], sampled 0.8044581138589915
[2019-03-24 02:00:13,639] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 02:00:13,640] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.12708305333333, 87.00565914666666, 1.0, 2.0, 0.9059302151715779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032662.296034238, 1032662.296034238, 218816.9519248313]
[2019-03-24 02:00:13,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:00:13,644] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6720293e-25 1.0000000e+00 2.8816962e-32 4.2084060e-23 6.2038267e-27], sampled 0.40682876262012735
[2019-03-24 02:00:16,174] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 02:00:16,177] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.25, 83.5, 1.0, 2.0, 0.4947849973666048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585070.7264717, 585070.7264717, 141884.9573187579]
[2019-03-24 02:00:16,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:00:16,181] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6556149e-24 1.0000000e+00 7.6080880e-32 9.0256378e-23 1.6082236e-26], sampled 0.6937591825806846
[2019-03-24 02:00:34,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 02:00:34,156] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.95793413, 87.269456625, 1.0, 2.0, 0.79642322244327, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260425548406, 1622858.077997459, 1622858.077997458, 335528.181241947]
[2019-03-24 02:00:34,157] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:00:34,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.7058969e-22 1.0000000e+00 9.3603722e-29 1.3416559e-20 5.5570959e-24], sampled 0.42586520162355823
[2019-03-24 02:00:34,160] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1622858.077997459 W.
[2019-03-24 02:00:35,100] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.63946]
[2019-03-24 02:00:35,101] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666667, 77.33333333333334, 1.0, 2.0, 0.6397504083446436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729101.8290981132, 729101.8290981132, 165052.9473723045]
[2019-03-24 02:00:35,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:00:35,106] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5334089e-24 1.0000000e+00 6.9921819e-32 8.2399103e-23 1.4106270e-26], sampled 0.061275686753401226
[2019-03-24 02:00:53,019] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 02:00:53,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:00:53,162] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:00:53,393] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:00:53,466] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:00:54,482] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 925000, evaluation results [925000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:00:55,561] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.01882746e-14 1.00000000e+00 1.03915234e-17 1.31084049e-14
 5.83139409e-15], sum to 1.0000
[2019-03-24 02:00:55,566] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0434
[2019-03-24 02:00:55,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1819894.890709173 W.
[2019-03-24 02:00:55,583] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5319222921759272, 1.0, 2.0, 0.5319222921759272, 1.0, 1.0, 0.8468376126437159, 6.911200000000001, 6.9112, 121.94756008, 1819894.890709173, 1819894.890709173, 359533.0512695993], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2906400.0000, 
sim time next is 2907000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 1.006363853226999, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260362056874, 1862508.448147873, 1862508.448147873, 380919.7489023833], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 1.0075760157464273, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094620862645718, 0.6651815886242404, 0.6651815886242404, 0.7325379786584295], 
reward next is 0.2675, 
noisyNet noise sample is [array([-2.837731], dtype=float32), -0.107025534]. 
=============================================
[2019-03-24 02:00:55,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[37.662643]
 [38.22729 ]
 [36.644676]
 [35.343243]
 [34.933838]], R is [[37.12121964]
 [37.05859756]
 [37.03831482]
 [37.01306534]
 [36.64293671]].
[2019-03-24 02:00:56,772] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5584822e-24 1.0000000e+00 6.2813951e-32 5.3527179e-23 5.7496496e-28], sum to 1.0000
[2019-03-24 02:00:56,780] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0480
[2019-03-24 02:00:56,787] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 89.0, 1.0, 2.0, 0.6507398556777464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741632.1879140491, 741632.1879140491, 167025.783518373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2934000.0000, 
sim time next is 2934600.0000, 
raw observation next is [25.26666666666667, 89.33333333333334, 1.0, 2.0, 0.6470245451821439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737395.9034064623, 737395.9034064623, 166355.5035753583], 
processed observation next is [1.0, 1.0, 0.49135802469135814, 0.8933333333333334, 1.0, 1.0, 0.579791125216838, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26335567978802227, 0.26335567978802227, 0.31991442995261216], 
reward next is 0.6801, 
noisyNet noise sample is [array([1.0143564], dtype=float32), 1.320432]. 
=============================================
[2019-03-24 02:00:58,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2869445e-16 1.0000000e+00 5.2344353e-21 1.8541102e-15 1.6274482e-18], sum to 1.0000
[2019-03-24 02:00:58,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3152
[2019-03-24 02:00:58,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1837734.472745181 W.
[2019-03-24 02:00:58,958] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.11666666666667, 88.5, 1.0, 2.0, 0.805696535548667, 1.0, 1.0, 0.805696535548667, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1837734.472745181, 1837734.472745181, 346113.924339416], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2995800.0000, 
sim time next is 2996400.0000, 
raw observation next is [26.23333333333333, 88.0, 1.0, 2.0, 0.4660755271178461, 1.0, 2.0, 0.4660755271178461, 1.0, 1.0, 0.7420074181918267, 6.9112, 6.9112, 121.94756008, 1594408.734243745, 1594408.734243745, 327235.1480955339], 
processed observation next is [1.0, 0.6956521739130435, 0.5271604938271603, 0.88, 1.0, 1.0, 0.3643756275212454, 1.0, 1.0, 0.3643756275212454, 1.0, 0.5, 0.6775092727397832, 0.0, 0.0, 0.8096049824067558, 0.5694316908013375, 0.5694316908013375, 0.6292983617221806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1316426], dtype=float32), 0.5418291]. 
=============================================
[2019-03-24 02:01:01,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9857916e-22 1.0000000e+00 7.1639358e-29 2.4743119e-18 1.5474224e-18], sum to 1.0000
[2019-03-24 02:01:01,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-24 02:01:01,681] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5914666362410865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684653.6211759099, 684653.6211759099, 157126.2176617032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3025800.0000, 
sim time next is 3026400.0000, 
raw observation next is [23.66666666666667, 96.0, 1.0, 2.0, 0.593603293646465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686502.2740586746, 686502.2740586746, 157464.0472233082], 
processed observation next is [1.0, 0.0, 0.43209876543209896, 0.96, 1.0, 1.0, 0.5161943971981726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24517938359238378, 0.24517938359238378, 0.3028154754294389], 
reward next is 0.6972, 
noisyNet noise sample is [array([-1.2925903], dtype=float32), 0.7872839]. 
=============================================
[2019-03-24 02:01:02,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4283909e-13 1.0000000e+00 2.8648594e-18 4.0351175e-10 1.7731200e-11], sum to 1.0000
[2019-03-24 02:01:02,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1872
[2019-03-24 02:01:02,462] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 94.5, 1.0, 2.0, 0.7942704914518192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905307.1249669809, 905307.1249669809, 194757.2223432814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3040200.0000, 
sim time next is 3040800.0000, 
raw observation next is [25.53333333333333, 92.66666666666666, 1.0, 2.0, 0.7904975280052943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 901004.1846112127, 901004.1846112127, 193982.1355526789], 
processed observation next is [1.0, 0.17391304347826086, 0.5012345679012346, 0.9266666666666665, 1.0, 1.0, 0.750592295244398, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32178720878971884, 0.32178720878971884, 0.37304256837053634], 
reward next is 0.6270, 
noisyNet noise sample is [array([0.5351109], dtype=float32), -1.0914112]. 
=============================================
[2019-03-24 02:01:17,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9425678e-18 1.0000000e+00 5.9245703e-26 5.1675237e-14 4.9939834e-16], sum to 1.0000
[2019-03-24 02:01:17,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8978
[2019-03-24 02:01:17,948] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 93.0, 1.0, 2.0, 0.4776977374101379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 577467.5769175891, 577467.5769175894, 139702.0195370146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3301200.0000, 
sim time next is 3301800.0000, 
raw observation next is [21.75, 94.16666666666666, 1.0, 2.0, 0.482124503988314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581624.7681033005, 581624.7681033005, 140345.7039859392], 
processed observation next is [0.0, 0.21739130434782608, 0.3611111111111111, 0.9416666666666665, 1.0, 1.0, 0.38348155236704057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20772313146546445, 0.20772313146546445, 0.2698955845883446], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.8681113], dtype=float32), -0.35753873]. 
=============================================
[2019-03-24 02:01:20,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1730710e-13 1.0000000e+00 1.3243411e-21 6.2939769e-09 2.0703715e-11], sum to 1.0000
[2019-03-24 02:01:20,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-24 02:01:20,083] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 84.0, 1.0, 2.0, 0.6069522121642174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701743.0764262204, 701743.0764262204, 159763.0549890244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3366000.0000, 
sim time next is 3366600.0000, 
raw observation next is [25.16666666666666, 85.66666666666667, 1.0, 2.0, 0.6082598380911403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702074.0059086432, 702074.0059086432, 159936.0031114781], 
processed observation next is [0.0, 1.0, 0.4876543209876541, 0.8566666666666667, 1.0, 1.0, 0.5336426643942146, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25074071639594403, 0.25074071639594403, 0.3075692367528425], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.36632434], dtype=float32), -0.3333283]. 
=============================================
[2019-03-24 02:01:20,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7229442e-12 1.0000000e+00 1.1358305e-17 4.2115857e-08 6.3970779e-10], sum to 1.0000
[2019-03-24 02:01:20,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8635
[2019-03-24 02:01:20,525] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.8523167641471905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984086.5899090671, 984086.5899090671, 207650.103297307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3380400.0000, 
sim time next is 3381000.0000, 
raw observation next is [24.0, 94.00000000000001, 1.0, 2.0, 0.8426452954427411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972214.9253807475, 972214.9253807475, 205526.0386251759], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.9400000000000002, 1.0, 1.0, 0.812672970765168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3472196162074098, 0.3472196162074098, 0.3952423819714921], 
reward next is 0.6048, 
noisyNet noise sample is [array([-1.324832], dtype=float32), 0.008087661]. 
=============================================
[2019-03-24 02:01:20,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.39151 ]
 [51.97454 ]
 [52.256866]
 [52.53195 ]
 [52.401596]], R is [[50.25534821]
 [50.35346985]
 [50.44427109]
 [50.52257538]
 [50.01734924]].
[2019-03-24 02:01:24,217] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9666467e-08 9.9999774e-01 3.0902420e-12 2.0340833e-06 2.3208558e-07], sum to 1.0000
[2019-03-24 02:01:24,223] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7393
[2019-03-24 02:01:24,227] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 91.5, 1.0, 2.0, 0.624325809276818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715861.685375062, 715861.685375062, 162527.6061608159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3462600.0000, 
sim time next is 3463200.0000, 
raw observation next is [24.5, 91.0, 1.0, 2.0, 0.6147613657161599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707218.8974127766, 707218.8974127766, 160959.4492349096], 
processed observation next is [1.0, 0.08695652173913043, 0.46296296296296297, 0.91, 1.0, 1.0, 0.5413825782335236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2525781776474202, 0.2525781776474202, 0.3095374023748262], 
reward next is 0.6905, 
noisyNet noise sample is [array([1.8077397], dtype=float32), 1.3543495]. 
=============================================
[2019-03-24 02:01:30,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2301332e-08 7.2922212e-01 2.0203790e-15 2.7046528e-01 3.1261277e-04], sum to 1.0000
[2019-03-24 02:01:30,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4632
[2019-03-24 02:01:30,313] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 79.83333333333334, 1.0, 2.0, 0.6393759818285681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728674.9050862273, 728674.9050862273, 164982.9304330549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525000.0000, 
sim time next is 3525600.0000, 
raw observation next is [26.23333333333333, 80.66666666666667, 1.0, 2.0, 0.6270577107400991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716635.5239556787, 716635.5239556787, 162893.862783712], 
processed observation next is [1.0, 0.8260869565217391, 0.5271604938271603, 0.8066666666666668, 1.0, 1.0, 0.5560210842144037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2559412585555995, 0.2559412585555995, 0.31325742843021537], 
reward next is 0.6867, 
noisyNet noise sample is [array([0.43641847], dtype=float32), -1.6098709]. 
=============================================
[2019-03-24 02:01:31,056] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3694166e-14 9.9999988e-01 5.0492383e-27 8.2867828e-08 4.2614266e-15], sum to 1.0000
[2019-03-24 02:01:31,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4793
[2019-03-24 02:01:31,070] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 86.83333333333334, 1.0, 2.0, 0.5809108778489365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694926.4599862677, 694926.4599862677, 156259.9536244734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3557400.0000, 
sim time next is 3558000.0000, 
raw observation next is [23.06666666666667, 84.66666666666667, 1.0, 2.0, 0.5123284281197534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615583.6811216474, 615583.6811216474, 145007.3634543359], 
processed observation next is [1.0, 0.17391304347826086, 0.40987654320987665, 0.8466666666666667, 1.0, 1.0, 0.4194386049044683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21985131468630262, 0.21985131468630262, 0.2788603143352613], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.8056926], dtype=float32), 0.2895435]. 
=============================================
[2019-03-24 02:01:31,085] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[83.596886]
 [83.800804]
 [83.97158 ]
 [84.02331 ]
 [84.228264]], R is [[83.5898819 ]
 [83.45348358]
 [83.33105469]
 [83.2080307 ]
 [83.08454132]].
[2019-03-24 02:01:32,143] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4964509e-09 9.9938393e-01 5.8761600e-13 6.1388646e-04 2.1802043e-06], sum to 1.0000
[2019-03-24 02:01:32,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1947
[2019-03-24 02:01:32,153] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5337744292817004, 0.0, 2.0, 0.0, 1.0, 1.0, 0.854537867636152, 6.9112, 6.9112, 121.9257721617435, 1256611.786999111, 1256611.786999111, 268142.0727946789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3578400.0000, 
sim time next is 3579000.0000, 
raw observation next is [23.11666666666667, 87.83333333333334, 1.0, 2.0, 1.003933211954491, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.427260384214214, 6.9112, 121.9238998839212, 1456761.117538178, 1192496.720138413, 244180.7255694295], 
processed observation next is [1.0, 0.43478260869565216, 0.41172839506172854, 0.8783333333333334, 1.0, 1.0, 1.0046823951839179, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05160603842142138, 0.0, 0.8094479033096623, 0.5202718276922065, 0.4258916857637189, 0.469578318402749], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09267276], dtype=float32), 0.5705819]. 
=============================================
[2019-03-24 02:01:32,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[42.695053]
 [44.001816]
 [44.54767 ]
 [45.310814]
 [45.225777]], R is [[42.18406677]
 [42.24656677]
 [41.82410049]
 [41.4058609 ]
 [40.99180222]].
[2019-03-24 02:01:33,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0784264e-07 9.8857051e-01 2.0723740e-12 1.1422931e-02 6.4526662e-06], sum to 1.0000
[2019-03-24 02:01:33,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5345
[2019-03-24 02:01:33,245] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1462181.301967361 W.
[2019-03-24 02:01:33,253] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4274593407408105, 1.0, 1.0, 0.4274593407408105, 1.0, 2.0, 0.6805291918381962, 6.911200000000001, 6.9112, 121.94756008, 1462181.301967361, 1462181.30196736, 309319.6754641898], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3597600.0000, 
sim time next is 3598200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6680793722791104, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9962385621450939, 6.9112, 6.9112, 121.9260426156618, 1477602.923390967, 1477602.923390967, 311267.1776089805], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.6048563955703695, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9952982026813673, 0.0, 0.0, 0.8094621288201359, 0.5277153297824883, 0.5277153297824883, 0.5985907261711163], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.93688464], dtype=float32), 1.1241078]. 
=============================================
[2019-03-24 02:01:40,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4112049e-09 3.8754754e-04 1.6685527e-13 9.9860698e-01 1.0054149e-03], sum to 1.0000
[2019-03-24 02:01:40,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5490
[2019-03-24 02:01:40,681] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 95.33333333333334, 1.0, 2.0, 0.3317792834628963, 1.0, 2.0, 0.3317792834628963, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756248.5640490529, 756248.5640490534, 188261.9618591425], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3721200.0000, 
sim time next is 3721800.0000, 
raw observation next is [24.75, 95.66666666666666, 1.0, 2.0, 0.3318130782948002, 1.0, 2.0, 0.3318130782948002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756325.633061577, 756325.6330615774, 188270.4378174652], 
processed observation next is [1.0, 0.043478260869565216, 0.4722222222222222, 0.9566666666666666, 1.0, 1.0, 0.20453937892238122, 1.0, 1.0, 0.20453937892238122, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2701162975219918, 0.27011629752199195, 0.36205853426435614], 
reward next is 0.6379, 
noisyNet noise sample is [array([-0.56196636], dtype=float32), -1.5584201]. 
=============================================
[2019-03-24 02:01:44,927] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 02:01:44,928] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:01:44,930] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:01:44,930] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:01:44,930] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:01:44,930] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:01:44,931] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:01:44,932] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:01:44,935] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:01:44,935] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:01:44,936] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:01:44,953] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-24 02:01:44,974] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-24 02:01:45,000] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-24 02:01:45,000] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-24 02:01:45,050] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-24 02:01:52,744] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:01:52,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.1066589, 28.98349391, 1.0, 2.0, 0.1793405652518541, 1.0, 2.0, 0.1793405652518541, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445368.5601994903, 445368.5601994898, 155635.4255926996]
[2019-03-24 02:01:52,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:01:52,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.0541060e-12 3.0835317e-03 3.6967442e-20 9.9690908e-01 7.3200176e-06], sampled 0.38698163511736094
[2019-03-24 02:02:03,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:02:03,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.5420333, 41.60819784166667, 1.0, 2.0, 0.2168410059011336, 1.0, 2.0, 0.2168410059011336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528887.0585014928, 528887.0585014933, 163265.2485370816]
[2019-03-24 02:02:03,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:02:03,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7823520e-11 1.0422660e-02 6.9931229e-19 9.8956645e-01 1.0941290e-05], sampled 0.8123062641507528
[2019-03-24 02:02:15,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:02:15,883] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.176301155, 83.703770915, 1.0, 2.0, 0.3799988876546989, 1.0, 2.0, 0.3799988876546989, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 866221.1097142644, 866221.1097142649, 200768.8738220716]
[2019-03-24 02:02:15,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:02:15,888] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7990890e-11 9.3519082e-03 3.3317915e-19 9.9063897e-01 9.0615167e-06], sampled 0.22085355854163802
[2019-03-24 02:02:23,572] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:02:23,573] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.06666666666667, 28.33333333333334, 1.0, 2.0, 0.381220231589794, 1.0, 2.0, 0.381220231589794, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 893326.0350981266, 893326.0350981266, 202205.2942928391]
[2019-03-24 02:02:23,574] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:02:23,577] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.6904134e-12 6.1170538e-03 8.5807465e-20 9.9387592e-01 7.0227534e-06], sampled 0.3186370897232088
[2019-03-24 02:02:32,158] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:02:32,159] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.28333333333333, 97.33333333333334, 1.0, 2.0, 0.293367420648416, 1.0, 2.0, 0.293367420648416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699492.2599861127, 699492.2599861131, 180262.3450724956]
[2019-03-24 02:02:32,161] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:02:32,164] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.3206557e-11 8.4346989e-03 2.5273468e-18 9.9154621e-01 1.8990755e-05], sampled 0.12277669435181404
[2019-03-24 02:03:19,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6555024]
[2019-03-24 02:03:19,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.30595493833333, 77.97612664666667, 1.0, 2.0, 0.6774356572546855, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772072.0579583659, 772072.0579583659, 171924.799290241]
[2019-03-24 02:03:19,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:03:19,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5169564e-11 1.0562597e-02 5.8491068e-19 9.8942697e-01 1.0465784e-05], sampled 0.9026582954474792
[2019-03-24 02:03:23,958] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7087.2211 2436671715.5154 39.0000
[2019-03-24 02:03:24,479] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6865.8661 2493021429.9813 50.0000
[2019-03-24 02:03:24,504] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7464.1006 2666648199.5760 72.0000
[2019-03-24 02:03:24,505] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7746.2681 2408482839.0650 25.0000
[2019-03-24 02:03:24,761] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7420.5789 2463007340.5291 48.0000
[2019-03-24 02:03:25,777] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 950000, evaluation results [950000.0, 7464.100556556094, 2666648199.576044, 72.0, 7087.2211073861035, 2436671715.515396, 39.0, 7746.268087383248, 2408482839.064975, 25.0, 6865.866113687244, 2493021429.9812694, 50.0, 7420.57887293541, 2463007340.5291157, 48.0]
[2019-03-24 02:03:32,649] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0352339e-10 2.1556203e-01 3.1479185e-17 7.8338844e-01 1.0495214e-03], sum to 1.0000
[2019-03-24 02:03:32,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8253
[2019-03-24 02:03:32,659] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.75, 70.0, 1.0, 2.0, 0.781960970938658, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891268.6120320054, 891268.6120320054, 192247.6764275983], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3930600.0000, 
sim time next is 3931200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.3989324715770418, 1.0, 1.0, 0.3989324715770418, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 909406.5010389801, 909406.5010389804, 205898.6567136105], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.2844434185440974, 1.0, 0.5, 0.2844434185440974, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32478803608535, 0.3247880360853502, 0.3959589552184817], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26265746], dtype=float32), -0.6563625]. 
=============================================
[2019-03-24 02:03:32,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8728247e-09 7.1254547e-04 1.4278397e-16 9.9927562e-01 1.1773775e-05], sum to 1.0000
[2019-03-24 02:03:32,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-24 02:03:32,931] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.93333333333333, 69.5, 1.0, 2.0, 0.3987674396437244, 1.0, 2.0, 0.3987674396437244, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909030.0711087168, 909030.0711087168, 205853.2213500637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3941400.0000, 
sim time next is 3942000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.4039480034360764, 1.0, 2.0, 0.4039480034360764, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 920846.7770247284, 920846.7770247288, 207278.4192342484], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.7, 1.0, 1.0, 0.29041428980485284, 1.0, 1.0, 0.29041428980485284, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.328873848937403, 0.3288738489374032, 0.3986123446812469], 
reward next is 0.6014, 
noisyNet noise sample is [array([0.1627114], dtype=float32), -0.07612528]. 
=============================================
[2019-03-24 02:03:32,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[55.79126 ]
 [55.824867]
 [55.875504]
 [55.88292 ]
 [55.859383]], R is [[55.80892563]
 [55.85496521]
 [55.90448761]
 [55.96116257]
 [56.02179718]].
[2019-03-24 02:03:35,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2753497e-08 2.1533268e-03 1.1640554e-13 9.9679512e-01 1.0515755e-03], sum to 1.0000
[2019-03-24 02:03:35,207] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-24 02:03:35,212] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.63333333333333, 92.66666666666667, 1.0, 2.0, 0.471560472639749, 1.0, 2.0, 0.471560472639749, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1075085.440036522, 1075085.440036522, 226727.293096813], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3994800.0000, 
sim time next is 3995400.0000, 
raw observation next is [24.61666666666667, 92.83333333333333, 1.0, 2.0, 0.4590637808439791, 1.0, 2.0, 0.4590637808439791, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1046575.444812252, 1046575.444812252, 223012.7921517494], 
processed observation next is [1.0, 0.21739130434782608, 0.4672839506172841, 0.9283333333333332, 1.0, 1.0, 0.35602831052854655, 1.0, 1.0, 0.35602831052854655, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3737769445758043, 0.3737769445758043, 0.4288707541379796], 
reward next is 0.5711, 
noisyNet noise sample is [array([-0.11779646], dtype=float32), -0.3821226]. 
=============================================
[2019-03-24 02:03:52,834] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1674796e-10 2.0558457e-04 1.2739862e-17 9.9978501e-01 9.4466759e-06], sum to 1.0000
[2019-03-24 02:03:52,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7170
[2019-03-24 02:03:52,848] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.46666666666667, 84.66666666666667, 1.0, 2.0, 0.3442478230316089, 1.0, 2.0, 0.3442478230316089, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 784683.5570222636, 784683.557022264, 191418.2706778298], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4486800.0000, 
sim time next is 4487400.0000, 
raw observation next is [26.2, 85.0, 1.0, 2.0, 0.3416935702674677, 1.0, 2.0, 0.3416935702674677, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 778858.3976114192, 778858.3976114197, 190767.1535650291], 
processed observation next is [0.0, 0.9565217391304348, 0.5259259259259259, 0.85, 1.0, 1.0, 0.216301869366033, 1.0, 1.0, 0.216301869366033, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27816371343264973, 0.2781637134326499, 0.36685991070197904], 
reward next is 0.6331, 
noisyNet noise sample is [array([0.5722106], dtype=float32), -0.19927089]. 
=============================================
[2019-03-24 02:03:59,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3482834e-10 9.6114783e-04 7.3304498e-18 9.9877590e-01 2.6289152e-04], sum to 1.0000
[2019-03-24 02:03:59,713] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3406
[2019-03-24 02:03:59,722] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666666, 68.0, 1.0, 2.0, 0.3264867516071522, 1.0, 2.0, 0.3264867516071522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744179.0566972746, 744179.056697275, 186938.3582616037], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4455600.0000, 
sim time next is 4456200.0000, 
raw observation next is [28.83333333333334, 66.5, 1.0, 2.0, 0.3236773556852505, 1.0, 2.0, 0.3236773556852505, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 737772.3657206857, 737772.365720686, 186239.7351647386], 
processed observation next is [0.0, 0.5652173913043478, 0.623456790123457, 0.665, 1.0, 1.0, 0.19485399486339347, 1.0, 1.0, 0.19485399486339347, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2634901306145306, 0.26349013061453075, 0.35815333685526657], 
reward next is 0.6418, 
noisyNet noise sample is [array([-0.851506], dtype=float32), -0.039710093]. 
=============================================
[2019-03-24 02:04:02,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2147050e-12 3.9910572e-07 1.3876830e-17 9.9998832e-01 1.1293381e-05], sum to 1.0000
[2019-03-24 02:04:02,652] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2060
[2019-03-24 02:04:02,658] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 94.00000000000001, 1.0, 2.0, 0.332674938530623, 1.0, 2.0, 0.332674938530623, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758291.1053561361, 758291.1053561366, 188486.7750168041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4493400.0000, 
sim time next is 4494000.0000, 
raw observation next is [24.66666666666667, 94.0, 1.0, 2.0, 0.3292639004810448, 1.0, 2.0, 0.3292639004810448, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750512.2624758724, 750512.2624758729, 187631.5406585577], 
processed observation next is [0.0, 0.0, 0.469135802469136, 0.94, 1.0, 1.0, 0.20150464342981525, 1.0, 1.0, 0.20150464342981525, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.268040093741383, 0.26804009374138316, 0.3608298858818417], 
reward next is 0.6392, 
noisyNet noise sample is [array([-1.8768029], dtype=float32), -0.34955683]. 
=============================================
[2019-03-24 02:04:02,687] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.665123]
 [63.65446 ]
 [63.987045]
 [63.997166]
 [64.00593 ]], R is [[63.74871063]
 [63.74874878]
 [63.74800491]
 [63.74884796]
 [63.75113678]].
[2019-03-24 02:04:08,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8372407e-11 4.1481508e-05 1.2169459e-16 9.9993753e-01 2.0965885e-05], sum to 1.0000
[2019-03-24 02:04:08,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-24 02:04:08,596] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.2, 99.5, 1.0, 2.0, 0.2483271373412157, 1.0, 2.0, 0.2483271373412157, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363582, 169720.6027860318], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4599000.0000, 
sim time next is 4599600.0000, 
raw observation next is [21.13333333333333, 99.66666666666666, 1.0, 2.0, 0.2444527802750265, 1.0, 2.0, 0.2444527802750265, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 582815.624805106, 582815.6248051064, 168872.4709299541], 
processed observation next is [1.0, 0.21739130434782608, 0.33827160493827146, 0.9966666666666666, 1.0, 1.0, 0.10053902413693633, 1.0, 1.0, 0.10053902413693633, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.208148437430395, 0.20814843743039516, 0.3247547517883733], 
reward next is 0.6752, 
noisyNet noise sample is [array([0.8188737], dtype=float32), -0.34142476]. 
=============================================
[2019-03-24 02:04:16,008] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 02:04:16,009] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:04:16,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:04:16,010] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:16,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:16,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:04:16,012] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:16,013] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:04:16,015] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:16,014] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:04:16,020] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:16,043] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-24 02:04:16,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-24 02:04:16,089] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-24 02:04:16,090] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-24 02:04:16,090] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-24 02:05:06,890] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6651806]
[2019-03-24 02:05:06,891] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.86666666666667, 49.0, 1.0, 2.0, 1.004568156891881, 1.0, 2.0, 1.004568156891881, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2291928.130530465, 2291928.130530465, 435535.4767894485]
[2019-03-24 02:05:06,892] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:05:06,894] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5823619e-10 2.3762170e-05 5.2087722e-17 9.9992406e-01 5.2245101e-05], sampled 0.6556396406945691
[2019-03-24 02:05:07,832] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6651806]
[2019-03-24 02:05:07,833] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.65853527, 91.73530406500001, 1.0, 2.0, 0.3120242693905378, 1.0, 2.0, 0.3120242693905378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 711198.6399648609, 711198.6399648613, 183371.2251950341]
[2019-03-24 02:05:07,834] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:05:07,836] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3634311e-11 1.2550551e-05 6.0708770e-18 9.9995768e-01 2.9755853e-05], sampled 0.28637205774116503
[2019-03-24 02:05:08,829] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6651806]
[2019-03-24 02:05:08,832] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.46666666666667, 70.0, 1.0, 2.0, 0.2935338810184327, 1.0, 2.0, 0.2935338810184327, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670839.6467913155, 670839.6467913155, 179007.2703375044]
[2019-03-24 02:05:08,833] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:05:08,837] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8496263e-11 1.4512824e-05 9.8987794e-18 9.9995160e-01 3.3842589e-05], sampled 0.24191942815470124
[2019-03-24 02:05:50,039] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6651806]
[2019-03-24 02:05:50,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 377691.9635425251, 377691.9635425255, 147652.5143391501]
[2019-03-24 02:05:50,043] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:05:50,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3325586e-10 2.8455352e-05 1.0022997e-16 9.9990964e-01 6.1892533e-05], sampled 0.7510386568897356
[2019-03-24 02:05:55,082] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 02:05:55,365] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3507 2466007225.7507 46.0000
[2019-03-24 02:05:55,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.2064 2495472694.8701 47.0000
[2019-03-24 02:05:55,457] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 02:05:55,563] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 02:05:56,580] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 975000, evaluation results [975000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.206367210996, 2495472694.87013, 47.0, 7478.3506670776715, 2466007225.750693, 46.0]
[2019-03-24 02:05:58,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9949960e-09 3.4524117e-05 4.1730989e-14 9.9987495e-01 9.0465997e-05], sum to 1.0000
[2019-03-24 02:05:58,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3288
[2019-03-24 02:05:58,494] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 87.33333333333333, 1.0, 2.0, 0.7797817685599628, 1.0, 2.0, 0.7797817685599628, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1778565.948175345, 1778565.948175345, 335470.4753886668], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4792200.0000, 
sim time next is 4792800.0000, 
raw observation next is [26.0, 87.66666666666667, 1.0, 2.0, 0.7442412122128897, 1.0, 2.0, 0.7442412122128897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1697426.220650043, 1697426.220650043, 321252.45574505], 
processed observation next is [1.0, 0.4782608695652174, 0.5185185185185185, 0.8766666666666667, 1.0, 1.0, 0.6955252526343926, 1.0, 1.0, 0.6955252526343926, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6062236502321583, 0.6062236502321583, 0.6177931841250961], 
reward next is 0.3822, 
noisyNet noise sample is [array([-0.29636002], dtype=float32), 2.0817456]. 
=============================================
[2019-03-24 02:05:58,830] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4182707e-07 2.6781144e-04 2.8070645e-12 9.9746346e-01 2.2682273e-03], sum to 1.0000
[2019-03-24 02:05:58,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5113
[2019-03-24 02:05:58,840] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 86.33333333333334, 1.0, 2.0, 0.8234199559058114, 1.0, 2.0, 0.8234199559058114, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1878202.794342337, 1878202.794342338, 353527.743398518], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4803600.0000, 
sim time next is 4804200.0000, 
raw observation next is [27.25, 87.0, 1.0, 2.0, 0.8448477693401747, 1.0, 2.0, 0.8448477693401747, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1927131.896420543, 1927131.896420543, 362635.5130789924], 
processed observation next is [1.0, 0.6086956521739131, 0.5648148148148148, 0.87, 1.0, 1.0, 0.8152949635002079, 1.0, 1.0, 0.8152949635002079, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6882613915787654, 0.6882613915787654, 0.6973759866903699], 
reward next is 0.3026, 
noisyNet noise sample is [array([0.83160454], dtype=float32), -0.123308085]. 
=============================================
[2019-03-24 02:05:59,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2711407e-10 8.2921411e-05 2.9928179e-17 9.9991429e-01 2.8010033e-06], sum to 1.0000
[2019-03-24 02:05:59,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6915
[2019-03-24 02:05:59,880] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.01666666666667, 92.83333333333333, 1.0, 2.0, 0.3561889711801754, 1.0, 2.0, 0.3561889711801754, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811916.8021170964, 811916.8021170964, 194492.0484849799], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4831800.0000, 
sim time next is 4832400.0000, 
raw observation next is [26.03333333333333, 92.66666666666667, 1.0, 2.0, 0.3567377191626041, 1.0, 2.0, 0.3567377191626041, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 813168.3120896538, 813168.3120896543, 194634.4539157989], 
processed observation next is [1.0, 0.9565217391304348, 0.519753086419753, 0.9266666666666667, 1.0, 1.0, 0.23421157043167157, 1.0, 1.0, 0.23421157043167157, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2904172543177335, 0.2904172543177337, 0.37429702676115173], 
reward next is 0.6257, 
noisyNet noise sample is [array([2.0539382], dtype=float32), 1.115138]. 
=============================================
[2019-03-24 02:06:02,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8913871e-09 5.5075376e-05 2.9144896e-14 9.9977654e-01 1.6840950e-04], sum to 1.0000
[2019-03-24 02:06:02,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0212
[2019-03-24 02:06:02,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 89.0, 1.0, 2.0, 0.9137243198203153, 1.0, 2.0, 0.9137243198203153, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 2084425.448527273, 2084425.448527273, 392989.0394190561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4874400.0000, 
sim time next is 4875000.0000, 
raw observation next is [27.51666666666667, 88.16666666666667, 1.0, 2.0, 0.8310696358117333, 1.0, 2.0, 0.8310696358117333, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1895670.063119297, 1895670.063119297, 356761.3414264455], 
processed observation next is [1.0, 0.43478260869565216, 0.5746913580246914, 0.8816666666666667, 1.0, 1.0, 0.7988924235853968, 1.0, 1.0, 0.7988924235853968, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.677025022542606, 0.677025022542606, 0.6860795027431644], 
reward next is 0.3139, 
noisyNet noise sample is [array([-0.27022365], dtype=float32), -2.9768503]. 
=============================================
[2019-03-24 02:06:02,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.93582 ]
 [43.808853]
 [43.69381 ]
 [43.66679 ]
 [43.66593 ]], R is [[44.17629242]
 [43.97878265]
 [43.79618454]
 [43.62359619]
 [43.46987915]].
[2019-03-24 02:06:03,045] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2691946e-09 1.2939436e-05 9.8140075e-15 9.9972636e-01 2.6058545e-04], sum to 1.0000
[2019-03-24 02:06:03,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5887
[2019-03-24 02:06:03,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 87.33333333333333, 1.0, 2.0, 0.9467081117911932, 1.0, 2.0, 0.9467081117911932, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2159760.429703574, 2159760.429703575, 408107.3743055961], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4880400.0000, 
sim time next is 4881000.0000, 
raw observation next is [28.1, 88.16666666666667, 1.0, 2.0, 0.9581011641302234, 1.0, 2.0, 0.9581011641302234, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2185783.638368313, 2185783.638368314, 413416.8733818923], 
processed observation next is [1.0, 0.4782608695652174, 0.5962962962962963, 0.8816666666666667, 1.0, 1.0, 0.9501204334883612, 1.0, 1.0, 0.9501204334883612, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.780637013702969, 0.7806370137029693, 0.7950324488113313], 
reward next is 0.2050, 
noisyNet noise sample is [array([0.804544], dtype=float32), 0.123126835]. 
=============================================
[2019-03-24 02:06:03,075] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[48.675156]
 [48.75889 ]
 [48.729347]
 [48.45061 ]
 [48.476036]], R is [[48.39321136]
 [48.12445831]
 [47.8931694 ]
 [47.66898727]
 [47.41139603]].
[2019-03-24 02:06:04,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.84713394e-06 1.83100831e-02 1.03871104e-11 1.35113791e-01
 8.46572220e-01], sum to 1.0000
[2019-03-24 02:06:04,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4634
[2019-03-24 02:06:04,752] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.13333333333333, 78.66666666666667, 1.0, 2.0, 0.8838594253411073, 1.0, 2.0, 0.7552943746469883, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2585236.291388398, 2585236.291388398, 482300.3113110865], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4891800.0000, 
sim time next is 4892400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.8642049891338419, 1.0, 2.0, 0.7454671565433557, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2551551.422402473, 2551551.422402474, 476279.3485194226], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.79, 1.0, 1.0, 0.8383392727783833, 1.0, 1.0, 0.6969847101706615, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9112683651437404, 0.9112683651437408, 0.9159218240758127], 
reward next is 0.0841, 
noisyNet noise sample is [array([-0.7698183], dtype=float32), -0.25289944]. 
=============================================
[2019-03-24 02:06:14,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0949598e-11 1.8554218e-05 2.1417686e-19 1.3103349e-04 9.9985039e-01], sum to 1.0000
[2019-03-24 02:06:14,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5873
[2019-03-24 02:06:14,210] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 89.83333333333334, 1.0, 2.0, 0.2653945579343283, 1.0, 2.0, 0.2653945579343283, 1.0, 2.0, 0.4225167795287826, 6.9112, 6.9112, 121.94756008, 907488.960756677, 907488.960756677, 243150.3864126982], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5087400.0000, 
sim time next is 5088000.0000, 
raw observation next is [27.66666666666667, 90.66666666666667, 1.0, 2.0, 0.2704602870753239, 1.0, 2.0, 0.2704602870753239, 1.0, 2.0, 0.4305815853005278, 6.9112, 6.9112, 121.94756008, 924821.1420535619, 924821.1420535619, 244997.3517280655], 
processed observation next is [0.0, 0.9130434782608695, 0.580246913580247, 0.9066666666666667, 1.0, 1.0, 0.13150034175633796, 1.0, 1.0, 0.13150034175633796, 1.0, 1.0, 0.28822698162565974, 0.0, 0.0, 0.8096049824067558, 0.33029326501912926, 0.33029326501912926, 0.4711487533232029], 
reward next is 0.5289, 
noisyNet noise sample is [array([-0.3589265], dtype=float32), -0.51851237]. 
=============================================
[2019-03-24 02:06:14,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.597107]
 [59.571434]
 [59.578957]
 [59.609966]
 [59.644928]], R is [[59.50677109]
 [59.44410706]
 [59.3756218 ]
 [59.3085556 ]
 [59.24300385]].
[2019-03-24 02:06:20,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2913252e-08 2.1149232e-05 2.0932524e-14 3.8460392e-04 9.9959427e-01], sum to 1.0000
[2019-03-24 02:06:20,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9930
[2019-03-24 02:06:20,229] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3073080270585835, 1.0, 2.0, 0.3073080270585835, 1.0, 2.0, 0.4892443874009887, 6.9112, 6.9112, 121.94756008, 1050905.945564699, 1050905.945564699, 258862.7115662008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5196600.0000, 
sim time next is 5197200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3073139033284444, 1.0, 2.0, 0.3073139033284444, 1.0, 2.0, 0.489253742613984, 6.9112, 6.9112, 121.94756008, 1050926.054512744, 1050926.054512744, 258864.9830826695], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.17537369443862427, 1.0, 1.0, 0.17537369443862427, 1.0, 1.0, 0.36156717826747997, 0.0, 0.0, 0.8096049824067558, 0.37533073375455145, 0.37533073375455145, 0.4978172751589798], 
reward next is 0.5022, 
noisyNet noise sample is [array([-1.4368503], dtype=float32), -0.85884863]. 
=============================================
[2019-03-24 02:06:20,310] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1127717e-10 1.3350357e-06 3.7321902e-15 4.6688845e-05 9.9995196e-01], sum to 1.0000
[2019-03-24 02:06:20,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5538
[2019-03-24 02:06:20,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.98333333333333, 78.0, 1.0, 2.0, 0.5980763998469633, 1.0, 2.0, 0.5980763998469633, 1.0, 2.0, 0.9521571065448794, 6.9112, 6.9112, 121.94756008, 2046490.840063918, 2046490.840063918, 394328.5138260337], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.6134373426977203, 1.0, 2.0, 0.6134373426977203, 1.0, 2.0, 0.9766122278342675, 6.9112, 6.9112, 121.94756008, 2099114.503995996, 2099114.503995996, 402745.5469068641], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.79, 1.0, 1.0, 0.539806360354429, 1.0, 1.0, 0.539806360354429, 1.0, 1.0, 0.9707652847928344, 0.0, 0.0, 0.8096049824067558, 0.7496837514271414, 0.7496837514271414, 0.7745106671285849], 
reward next is 0.2255, 
noisyNet noise sample is [array([-0.45978424], dtype=float32), -0.8680856]. 
=============================================
[2019-03-24 02:06:21,217] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8349964e-08 9.5316655e-06 5.1339795e-14 3.8035095e-04 9.9961013e-01], sum to 1.0000
[2019-03-24 02:06:21,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1084
[2019-03-24 02:06:21,230] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3073080270585835, 1.0, 2.0, 0.3073080270585835, 1.0, 2.0, 0.4892443874009887, 6.9112, 6.9112, 121.94756008, 1050905.945564699, 1050905.945564699, 258862.7115662008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5196600.0000, 
sim time next is 5197200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3073139033284444, 1.0, 2.0, 0.3073139033284444, 1.0, 2.0, 0.489253742613984, 6.9112, 6.9112, 121.94756008, 1050926.054512744, 1050926.054512744, 258864.9830826695], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.17537369443862427, 1.0, 1.0, 0.17537369443862427, 1.0, 1.0, 0.36156717826747997, 0.0, 0.0, 0.8096049824067558, 0.37533073375455145, 0.37533073375455145, 0.4978172751589798], 
reward next is 0.5022, 
noisyNet noise sample is [array([1.546255], dtype=float32), -1.1279093]. 
=============================================
[2019-03-24 02:06:22,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3769618e-05 2.4079599e-03 3.7916639e-10 2.9021797e-03 9.9467611e-01], sum to 1.0000
[2019-03-24 02:06:22,896] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9333
[2019-03-24 02:06:22,901] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.81666666666667, 75.66666666666667, 1.0, 2.0, 0.2291030931508987, 1.0, 2.0, 0.2291030931508987, 1.0, 2.0, 0.3647395856630695, 6.911200000000001, 6.9112, 121.94756008, 783330.6847299857, 783330.6847299853, 230337.5942538223], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5249400.0000, 
sim time next is 5250000.0000, 
raw observation next is [28.63333333333333, 77.33333333333334, 1.0, 2.0, 0.2316865867724977, 1.0, 2.0, 0.2316865867724977, 1.0, 2.0, 0.3688525916471684, 6.9112, 6.9112, 121.94756008, 792168.5200349088, 792168.5200349088, 231225.3725259299], 
processed observation next is [1.0, 0.782608695652174, 0.6160493827160493, 0.7733333333333334, 1.0, 1.0, 0.08534117472916393, 1.0, 1.0, 0.08534117472916393, 1.0, 1.0, 0.21106573955896046, 0.0, 0.0, 0.8096049824067558, 0.282917328583896, 0.282917328583896, 0.4446641779344806], 
reward next is 0.5553, 
noisyNet noise sample is [array([-2.5646083], dtype=float32), -1.21976]. 
=============================================
[2019-03-24 02:06:22,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[29.171482]
 [28.858555]
 [28.516438]
 [28.449783]
 [27.954205]], R is [[29.65109253]
 [29.91162491]
 [30.17075539]
 [29.86904907]
 [30.20949745]].
[2019-03-24 02:06:24,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4015319e-13 7.9134279e-06 2.0834655e-20 3.1688035e-08 9.9999201e-01], sum to 1.0000
[2019-03-24 02:06:24,047] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3105
[2019-03-24 02:06:24,052] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.61666666666667, 87.33333333333333, 1.0, 2.0, 0.2182682539528351, 1.0, 2.0, 0.2182682539528351, 1.0, 2.0, 0.3474901687936745, 6.9112, 6.9112, 121.94756008, 746267.0523753833, 746267.0523753833, 226655.0165569938], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5273400.0000, 
sim time next is 5274000.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.2164288616653298, 1.0, 2.0, 0.2164288616653298, 1.0, 2.0, 0.3445617963671414, 6.911200000000001, 6.9112, 121.94756008, 739975.0686548888, 739975.0686548883, 226036.3582499973], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.87, 1.0, 1.0, 0.06717721626824975, 1.0, 1.0, 0.06717721626824975, 1.0, 1.0, 0.18070224545892674, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2642768102338888, 0.26427681023388866, 0.43468530432691793], 
reward next is 0.5653, 
noisyNet noise sample is [array([0.6286118], dtype=float32), 0.24463293]. 
=============================================
[2019-03-24 02:06:24,074] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1427994e-12 6.1207952e-06 2.2545446e-19 1.4772515e-06 9.9999237e-01], sum to 1.0000
[2019-03-24 02:06:24,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.103188]
 [61.264954]
 [61.460567]
 [61.686653]
 [61.91536 ]], R is [[60.97698975]
 [60.93134689]
 [60.88536835]
 [60.83952332]
 [60.79363632]].
[2019-03-24 02:06:24,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-24 02:06:24,090] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.2272741191535836, 1.0, 2.0, 0.2272741191535836, 1.0, 2.0, 0.3618277994938193, 6.9112, 6.9112, 121.94756008, 777074.0360974617, 777074.0360974617, 229711.3513102288], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5248800.0000, 
sim time next is 5249400.0000, 
raw observation next is [28.81666666666667, 75.66666666666667, 1.0, 2.0, 0.2291030931894728, 1.0, 2.0, 0.2291030931894728, 1.0, 2.0, 0.3647395857244808, 6.9112, 6.9112, 121.94756008, 783330.6848619424, 783330.6848619424, 230337.5942670499], 
processed observation next is [1.0, 0.782608695652174, 0.6228395061728397, 0.7566666666666667, 1.0, 1.0, 0.08226558713032477, 1.0, 1.0, 0.08226558713032477, 1.0, 1.0, 0.20592448215560097, 0.0, 0.0, 0.8096049824067558, 0.27976095887926516, 0.27976095887926516, 0.44295691205201904], 
reward next is 0.5570, 
noisyNet noise sample is [array([0.02516264], dtype=float32), -0.7491375]. 
=============================================
[2019-03-24 02:06:24,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4281122e-12 1.9210925e-06 5.3104339e-20 1.4953817e-05 9.9998307e-01], sum to 1.0000
[2019-03-24 02:06:24,246] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9618
[2019-03-24 02:06:24,250] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.08333333333333, 82.33333333333333, 1.0, 2.0, 0.2432025117055521, 1.0, 2.0, 0.2432025117055521, 1.0, 2.0, 0.3871863191880826, 6.9112, 6.9112, 121.94756008, 831564.417473951, 831564.417473951, 235228.0251949737], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5251800.0000, 
sim time next is 5252400.0000, 
raw observation next is [27.9, 84.0, 1.0, 2.0, 0.2464782824517671, 1.0, 2.0, 0.2464782824517671, 1.0, 2.0, 0.3924014529004621, 6.9112, 6.9112, 121.94756008, 842771.1758139265, 842771.1758139265, 236380.1413940275], 
processed observation next is [1.0, 0.8260869565217391, 0.5888888888888888, 0.84, 1.0, 1.0, 0.10295033625210367, 1.0, 1.0, 0.10295033625210367, 1.0, 1.0, 0.24050181612557758, 0.0, 0.0, 0.8096049824067558, 0.3009897056478309, 0.3009897056478309, 0.45457719498851445], 
reward next is 0.5454, 
noisyNet noise sample is [array([-1.0355918], dtype=float32), 0.31217286]. 
=============================================
[2019-03-24 02:06:26,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4791131e-08 6.1331881e-04 1.0640192e-14 1.3104913e-06 9.9938536e-01], sum to 1.0000
[2019-03-24 02:06:26,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-24 02:06:26,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.43333333333333, 66.33333333333334, 1.0, 2.0, 0.5324332711162145, 1.0, 2.0, 0.5324332711162145, 1.0, 2.0, 0.8476511077580756, 6.9112, 6.9112, 121.94756008, 1821644.913367005, 1821644.913367005, 359792.7537282027], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5329200.0000, 
sim time next is 5329800.0000, 
raw observation next is [28.45, 66.5, 1.0, 2.0, 0.5388849869037098, 1.0, 2.0, 0.5388849869037098, 1.0, 2.0, 0.8579224494094821, 6.9112, 6.9112, 121.94756008, 1843741.32206723, 1843741.32206723, 363083.9568895742], 
processed observation next is [1.0, 0.6956521739130435, 0.6092592592592593, 0.665, 1.0, 1.0, 0.4510535558377497, 1.0, 1.0, 0.4510535558377497, 1.0, 1.0, 0.8224030617618527, 0.0, 0.0, 0.8096049824067558, 0.6584790435954393, 0.6584790435954393, 0.6982383786337965], 
reward next is 0.3018, 
noisyNet noise sample is [array([0.49745926], dtype=float32), 0.44504037]. 
=============================================
[2019-03-24 02:06:30,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9060493e-08 3.8965218e-04 2.0539995e-12 4.1315542e-04 9.9919719e-01], sum to 1.0000
[2019-03-24 02:06:30,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2486
[2019-03-24 02:06:30,790] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 77.33333333333334, 1.0, 2.0, 0.5389142092301485, 1.0, 2.0, 0.5389142092301485, 1.0, 2.0, 0.8579689723048773, 6.9112, 6.9112, 121.94756008, 1843841.406527126, 1843841.406527126, 363098.9152479119], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5397000.0000, 
sim time next is 5397600.0000, 
raw observation next is [27.66666666666667, 78.66666666666667, 1.0, 2.0, 0.5494335539423523, 1.0, 2.0, 0.5494335539423523, 1.0, 2.0, 0.8747161116778455, 6.911200000000001, 6.9112, 121.94756008, 1879870.167822116, 1879870.167822115, 368513.5679759068], 
processed observation next is [1.0, 0.4782608695652174, 0.580246913580247, 0.7866666666666667, 1.0, 1.0, 0.46361137374089556, 1.0, 1.0, 0.46361137374089556, 1.0, 1.0, 0.8433951395973068, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6713822027936128, 0.6713822027936125, 0.7086799384152054], 
reward next is 0.2913, 
noisyNet noise sample is [array([0.0342716], dtype=float32), -0.49642548]. 
=============================================
[2019-03-24 02:06:46,951] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 02:06:46,956] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:06:46,957] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:06:46,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:06:46,961] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:06:46,968] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-24 02:06:46,989] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:06:46,990] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:06:46,991] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:06:46,992] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:06:46,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-24 02:06:47,020] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:06:47,022] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:06:47,025] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-24 02:06:47,048] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-24 02:06:47,073] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-24 02:06:59,109] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:06:59,110] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.28333333333333, 27.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2010724116235736, 6.911199999999999, 6.9112, 121.94756008, 448108.2956358943, 448108.2956358948, 185582.0153713249]
[2019-03-24 02:06:59,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:06:59,113] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2040754e-12 2.9066803e-07 4.5458483e-20 1.6271028e-07 9.9999952e-01], sampled 0.3405933115604577
[2019-03-24 02:07:01,002] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:01,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.66666666666667, 47.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 294095.7554436993, 294095.7554436993, 135777.5050706271]
[2019-03-24 02:07:01,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:07:01,006] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.8223821e-12 8.9205378e-07 1.1627060e-18 5.0417282e-07 9.9999857e-01], sampled 0.23902215233984425
[2019-03-24 02:07:11,854] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:11,855] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.56241149666667, 84.98691913666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 391306.3835207446, 391306.3835207446, 175519.4988995061]
[2019-03-24 02:07:11,856] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:07:11,858] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8414084e-11 1.3500195e-06 3.8515386e-18 7.6574048e-07 9.9999785e-01], sampled 0.7323644466762401
[2019-03-24 02:07:15,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:15,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 76.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2207911933761815, 6.911199999999999, 6.9112, 121.94756008, 493792.2919193166, 493792.291919317, 195603.0883516303]
[2019-03-24 02:07:15,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:07:15,444] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9470003e-12 7.1444612e-07 6.1188339e-19 4.0302197e-07 9.9999893e-01], sampled 0.6066276570124648
[2019-03-24 02:07:21,911] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:21,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.58333333333334, 81.5, 1.0, 2.0, 0.2650869131119458, 1.0, 2.0, 0.2650869131119458, 1.0, 2.0, 0.4220269989522573, 6.911199999999999, 6.9112, 121.94756008, 906436.3794318561, 906436.3794318566, 243038.6803808124]
[2019-03-24 02:07:21,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:07:21,915] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1141394e-11 1.0173941e-06 1.6999558e-18 5.7564944e-07 9.9999845e-01], sampled 0.6896232815657549
[2019-03-24 02:07:22,513] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:22,514] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.831084215, 95.430365275, 1.0, 2.0, 0.1849707071258933, 1.0, 2.0, 0.1849707071258933, 1.0, 2.0, 0.2947458865395046, 6.911199999999999, 6.9112, 121.94756008, 639265.9582226304, 639265.9582226309, 215748.0899755653]
[2019-03-24 02:07:22,514] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:07:22,517] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.7141028e-12 9.4180393e-07 1.3599842e-18 5.3254519e-07 9.9999857e-01], sampled 0.8005731298739686
[2019-03-24 02:07:34,374] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:34,376] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.50174762666667, 96.44792838666666, 1.0, 2.0, 0.2622456966910994, 1.0, 2.0, 0.2622456966910994, 1.0, 2.0, 0.4175036898783109, 6.9112, 6.9112, 121.94756008, 896715.4606646934, 896715.4606646934, 242009.5297867449]
[2019-03-24 02:07:34,377] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:07:34,379] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5112920e-12 3.3034235e-07 6.5804467e-20 1.8512971e-07 9.9999952e-01], sampled 0.6576724491969985
[2019-03-24 02:07:48,545] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:07:48,547] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.43333333333333, 85.16666666666667, 1.0, 2.0, 0.2587193868180596, 1.0, 2.0, 0.2587193868180596, 1.0, 2.0, 0.4118896897165367, 6.911199999999999, 6.9112, 121.94756008, 884650.7392148364, 884650.7392148369, 240738.4907322958]
[2019-03-24 02:07:48,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:07:48,551] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1105058e-12 4.9601033e-07 2.1307428e-19 2.7890604e-07 9.9999917e-01], sampled 0.6981262851940857
[2019-03-24 02:08:04,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6746861]
[2019-03-24 02:08:04,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.58333333333333, 67.5, 1.0, 2.0, 0.2272276283121483, 1.0, 2.0, 0.2272276283121483, 1.0, 2.0, 0.3617537845601533, 6.9112, 6.9112, 121.94756008, 776914.9984934274, 776914.9984934274, 229695.4571662185]
[2019-03-24 02:08:04,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:08:04,728] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4155203e-12 3.1839082e-07 5.9152364e-20 1.7837348e-07 9.9999952e-01], sampled 0.49245397315853734
[2019-03-24 02:08:28,622] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4489.4114 2940779206.0371 28.0000
[2019-03-24 02:08:29,095] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.1813 2875918929.5409 8.0000
[2019-03-24 02:08:29,214] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4275.9573 2920152679.8633 33.0000
[2019-03-24 02:08:29,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.0871 2894700717.8337 12.0000
[2019-03-24 02:08:29,381] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4510.8774 3107552039.9913 0.0000
[2019-03-24 02:08:30,397] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1000000, evaluation results [1000000.0, 4510.87741702582, 3107552039.9912515, 0.0, 4609.087071503921, 2894700717.8336563, 12.0, 4392.181277017246, 2875918929.540856, 8.0, 4489.411365254514, 2940779206.037067, 28.0, 4275.9572757857495, 2920152679.8633223, 33.0]
[2019-03-24 02:08:35,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9272688e-08 9.5512176e-01 3.4857259e-17 5.1125200e-03 3.9765716e-02], sum to 1.0000
[2019-03-24 02:08:35,780] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7608
[2019-03-24 02:08:35,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 90.5, 1.0, 2.0, 0.4712100025652114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572586.5953604312, 572586.5953604312, 138801.2725726253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5801400.0000, 
sim time next is 5802000.0000, 
raw observation next is [21.63333333333333, 91.0, 1.0, 2.0, 0.463631290178957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563491.4813862455, 563491.4813862455, 137651.414612366], 
processed observation next is [1.0, 0.13043478260869565, 0.35679012345678995, 0.91, 1.0, 1.0, 0.36146582164161545, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2012469576379448, 0.2012469576379448, 0.2647142588699346], 
reward next is 0.7353, 
noisyNet noise sample is [array([0.29779485], dtype=float32), -0.78896165]. 
=============================================
[2019-03-24 02:08:35,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.25984 ]
 [56.399876]
 [55.823746]
 [56.710773]
 [57.020645]], R is [[56.36006165]
 [56.5295372 ]
 [55.96424103]
 [55.99427795]
 [56.15028763]].
[2019-03-24 02:08:41,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7889712e-14 1.0000000e+00 1.0414469e-23 2.3397641e-11 2.3913971e-11], sum to 1.0000
[2019-03-24 02:08:41,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6945
[2019-03-24 02:08:41,892] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1334694.44851108 W.
[2019-03-24 02:08:41,898] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.35, 65.0, 1.0, 2.0, 0.9413476595919941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.252285634251525, 6.9112, 121.9244880806547, 1334694.44851108, 1160030.344850394, 230745.1570126223], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5909400.0000, 
sim time next is 5910000.0000, 
raw observation next is [24.6, 64.0, 1.0, 2.0, 0.5060459640615498, 1.0, 1.0, 0.5060459640615498, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9258371898836, 1225002.677944964, 1225002.677944965, 240211.6291315551], 
processed observation next is [1.0, 0.391304347826087, 0.46666666666666673, 0.64, 1.0, 1.0, 0.4119594810256545, 1.0, 0.5, 0.4119594810256545, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094607650065964, 0.43750095640891573, 0.43750095640891606, 0.46194544063760595], 
reward next is 0.5381, 
noisyNet noise sample is [array([1.353605], dtype=float32), -0.8671681]. 
=============================================
[2019-03-24 02:08:41,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.182907]
 [63.911583]
 [64.83326 ]
 [65.985886]
 [65.91877 ]], R is [[62.24820328]
 [61.62572098]
 [61.00946426]
 [60.9940567 ]
 [61.04928589]].
[2019-03-24 02:08:46,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4701991e-17 1.0000000e+00 3.0714918e-27 6.0028619e-15 2.0620833e-15], sum to 1.0000
[2019-03-24 02:08:46,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-24 02:08:46,039] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 90.0, 1.0, 2.0, 0.5438060850796692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649013.3225257574, 649013.3225257569, 149961.6289841782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6148800.0000, 
sim time next is 6149400.0000, 
raw observation next is [22.73333333333333, 90.16666666666667, 1.0, 2.0, 0.6764061169193923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807928.40074331, 807928.4007433095, 173394.2724496577], 
processed observation next is [1.0, 0.17391304347826086, 0.39753086419753075, 0.9016666666666667, 1.0, 1.0, 0.6147691868088004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.288545857408325, 0.28854585740832484, 0.3334505239416494], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.72272027], dtype=float32), 0.12549293]. 
=============================================
[2019-03-24 02:08:47,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1082138e-12 1.0000000e+00 8.6503989e-20 2.2060418e-09 2.0907240e-08], sum to 1.0000
[2019-03-24 02:08:47,652] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4890
[2019-03-24 02:08:47,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1567633.635905948 W.
[2019-03-24 02:08:47,661] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 58.16666666666666, 1.0, 2.0, 0.7455087245939588, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9945829270746565, 6.9112, 6.9112, 121.9260426156618, 1567633.635905948, 1567633.635905948, 325140.8718389214], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6015000.0000, 
sim time next is 6015600.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.7464239656775274, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9905964610377842, 6.911199999999997, 6.9112, 121.9260426156618, 1572440.336264094, 1572440.336264096, 324638.513397168], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.58, 1.0, 1.0, 0.6981237686637232, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9882455762972303, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.5615858343800336, 0.5615858343800343, 0.6243048334560923], 
reward next is 0.3757, 
noisyNet noise sample is [array([-1.0489526], dtype=float32), 0.9179185]. 
=============================================
[2019-03-24 02:08:53,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1938218e-15 9.9998617e-01 1.0621826e-25 2.8306205e-12 1.3794629e-05], sum to 1.0000
[2019-03-24 02:08:53,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9614
[2019-03-24 02:08:53,231] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 61.5, 1.0, 2.0, 0.5469287657847349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639820.8303352107, 639820.8303352103, 149959.6585461551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6115800.0000, 
sim time next is 6116400.0000, 
raw observation next is [28.2, 62.0, 1.0, 2.0, 0.5466682988667239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640149.1109863515, 640149.1109863515, 149943.9168529086], 
processed observation next is [1.0, 0.8260869565217391, 0.6, 0.62, 1.0, 1.0, 0.46031940341276645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22862468249512555, 0.22862468249512555, 0.28835368625559343], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.05875284], dtype=float32), -1.1062555]. 
=============================================
[2019-03-24 02:08:54,229] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8277198e-11 9.7399604e-01 1.2587705e-18 8.7170022e-08 2.6003860e-02], sum to 1.0000
[2019-03-24 02:08:54,239] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2500
[2019-03-24 02:08:54,249] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 85.0, 1.0, 2.0, 0.5722804451056006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674183.4465577886, 674183.4465577886, 154380.5151350378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6163200.0000, 
sim time next is 6163800.0000, 
raw observation next is [24.38333333333333, 83.83333333333334, 1.0, 2.0, 0.7374864327764032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 868197.6461563682, 868197.6461563677, 184692.1576177024], 
processed observation next is [1.0, 0.34782608695652173, 0.4586419753086418, 0.8383333333333334, 1.0, 1.0, 0.6874838485433372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31007058791298864, 0.31007058791298847, 0.3551772261878893], 
reward next is 0.6448, 
noisyNet noise sample is [array([0.8817638], dtype=float32), 0.31788963]. 
=============================================
[2019-03-24 02:08:57,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6314149e-13 1.0000000e+00 3.4625344e-22 4.0492203e-13 1.5908787e-08], sum to 1.0000
[2019-03-24 02:08:57,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2394
[2019-03-24 02:08:57,523] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 58.0, 1.0, 2.0, 0.54192003199951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635162.890026953, 635162.890026953, 149190.0224460395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6201000.0000, 
sim time next is 6201600.0000, 
raw observation next is [28.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5435793765739267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636912.6331849054, 636912.6331849054, 149453.3904314429], 
processed observation next is [1.0, 0.782608695652174, 0.623456790123457, 0.5866666666666667, 1.0, 1.0, 0.4566421149689604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22746879756603763, 0.22746879756603763, 0.28741036621431326], 
reward next is 0.7126, 
noisyNet noise sample is [array([0.34414676], dtype=float32), -0.36491707]. 
=============================================
[2019-03-24 02:08:59,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8426153e-17 1.0000000e+00 5.4123278e-29 3.8977716e-15 1.6754527e-10], sum to 1.0000
[2019-03-24 02:08:59,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2082
[2019-03-24 02:08:59,939] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.73333333333333, 66.5, 1.0, 2.0, 0.6277933932402094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716262.7669283702, 716262.7669283702, 162963.6303132376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6268200.0000, 
sim time next is 6268800.0000, 
raw observation next is [28.86666666666667, 66.0, 1.0, 2.0, 0.6292031585544916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717252.6895110175, 717252.6895110175, 163181.9238293973], 
processed observation next is [0.0, 0.5652173913043478, 0.6246913580246916, 0.66, 1.0, 1.0, 0.5585751887553472, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2561616748253634, 0.2561616748253634, 0.3138113919796102], 
reward next is 0.6862, 
noisyNet noise sample is [array([1.300281], dtype=float32), -0.64396644]. 
=============================================
[2019-03-24 02:09:07,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7491217e-15 1.0000000e+00 8.6209555e-26 9.5768649e-14 5.3451958e-09], sum to 1.0000
[2019-03-24 02:09:07,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8002
[2019-03-24 02:09:07,344] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.58333333333333, 66.66666666666667, 1.0, 2.0, 0.6774718663992432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772113.34623236, 772113.34623236, 171922.801966374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6379800.0000, 
sim time next is 6380400.0000, 
raw observation next is [29.46666666666667, 67.33333333333334, 1.0, 2.0, 0.6825491346180683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 777902.8350825787, 777902.8350825774, 172866.2782798299], 
processed observation next is [0.0, 0.8695652173913043, 0.6469135802469137, 0.6733333333333335, 1.0, 1.0, 0.622082303116748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.27782244110092097, 0.2778224411009205, 0.3324351505381344], 
reward next is 0.6676, 
noisyNet noise sample is [array([1.0764906], dtype=float32), -1.9398171]. 
=============================================
[2019-03-24 02:09:12,183] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3207995e-10 9.9987233e-01 2.8717395e-16 4.9925425e-10 1.2762706e-04], sum to 1.0000
[2019-03-24 02:09:12,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9081
[2019-03-24 02:09:12,198] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 83.5, 1.0, 2.0, 0.9018253614474901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426022197, 1027980.068837909, 1027980.068837909, 217872.678669613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492600.0000, 
sim time next is 6493200.0000, 
raw observation next is [26.56666666666666, 83.66666666666667, 1.0, 2.0, 0.8810939485090248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156577, 1004333.089517471, 1004333.089517471, 213260.8461816489], 
processed observation next is [1.0, 0.13043478260869565, 0.5395061728395059, 0.8366666666666667, 1.0, 1.0, 0.858445176796458, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201088, 0.3586903891133825, 0.3586903891133825, 0.4101170118877863], 
reward next is 0.5899, 
noisyNet noise sample is [array([-0.27674153], dtype=float32), 0.6169239]. 
=============================================
[2019-03-24 02:09:12,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.04143194e-10 9.73373771e-01 9.05297320e-21 9.20317333e-09
 2.66262442e-02], sum to 1.0000
[2019-03-24 02:09:12,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-24 02:09:12,474] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 68.0, 1.0, 2.0, 0.6730435517253472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767063.8794604953, 767063.8794604953, 171102.9612840949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6471000.0000, 
sim time next is 6471600.0000, 
raw observation next is [29.1, 68.33333333333334, 1.0, 2.0, 0.6715352287084476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765343.9941575972, 765343.9941575972, 170824.528098556], 
processed observation next is [1.0, 0.9130434782608695, 0.6333333333333334, 0.6833333333333335, 1.0, 1.0, 0.6089705103671995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2733371407705704, 0.2733371407705704, 0.3285087078818385], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.66190773], dtype=float32), -0.891662]. 
=============================================
[2019-03-24 02:09:20,875] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 02:09:20,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:09:20,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:09:20,878] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:09:20,878] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:09:20,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:09:20,880] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:09:20,880] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:09:20,881] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:09:20,881] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:09:20,881] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:09:20,894] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-24 02:09:20,917] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-24 02:09:20,942] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-24 02:09:20,969] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-24 02:09:21,000] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-24 02:09:26,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6817581]
[2019-03-24 02:09:26,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.10523533833333, 76.50032679, 1.0, 2.0, 0.4411067055859227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 565192.6278630763, 565192.6278630767, 134789.368076098]
[2019-03-24 02:09:26,880] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:09:26,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.1108876e-11 9.9779081e-01 2.8688863e-18 3.0361338e-08 2.2091379e-03], sampled 0.1686396212594714
[2019-03-24 02:09:42,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6817581]
[2019-03-24 02:09:42,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.88736960833333, 81.70301783166667, 1.0, 2.0, 0.4117572244401516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514971.3306649796, 514971.3306649796, 130384.3508470859]
[2019-03-24 02:09:42,693] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:09:42,696] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3901559e-11 9.9814105e-01 7.8178282e-19 1.7627283e-08 1.8589346e-03], sampled 0.26095577204727516
[2019-03-24 02:10:11,218] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6817581]
[2019-03-24 02:10:11,219] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.86666666666667, 87.0, 1.0, 2.0, 0.4305360365704811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525918.1185334316, 525918.1185334316, 132811.7540055849]
[2019-03-24 02:10:11,221] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:10:11,223] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5537354e-11 9.9845004e-01 1.9888122e-19 9.9434478e-09 1.5499885e-03], sampled 0.6365388928700053
[2019-03-24 02:10:13,545] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6817581]
[2019-03-24 02:10:13,546] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.556729765, 82.39086420999999, 1.0, 2.0, 0.4432796338820503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540118.700309016, 540118.7003090156, 134644.8864250171]
[2019-03-24 02:10:13,546] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:10:13,549] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.7820372e-12 9.9868065e-01 5.9128227e-20 5.9866760e-09 1.3193230e-03], sampled 0.6177509847028091
[2019-03-24 02:10:34,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.6817581]
[2019-03-24 02:10:34,531] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.03579749, 79.4513948, 1.0, 2.0, 0.4230706563727171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 516458.4286876342, 516458.4286876342, 131718.6217506394]
[2019-03-24 02:10:34,532] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:10:34,536] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.2191148e-11 9.9831593e-01 3.7174019e-19 1.2916060e-08 1.6840356e-03], sampled 0.6020995571646137
[2019-03-24 02:10:59,299] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8905.6607 2121574221.3578 427.0000
[2019-03-24 02:10:59,543] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8555.8122 2250211429.8753 552.0000
[2019-03-24 02:10:59,769] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8753.0250 2171726374.0859 490.0000
[2019-03-24 02:10:59,785] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8078.3523 2446672579.8592 746.0000
[2019-03-24 02:10:59,811] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8681.5436 2196291628.7661 571.0000
[2019-03-24 02:11:00,825] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1025000, evaluation results [1025000.0, 8078.352338232688, 2446672579.859206, 746.0, 8753.025006512942, 2171726374.0859227, 490.0, 8905.660706311468, 2121574221.3578203, 427.0, 8555.812184212593, 2250211429.875327, 552.0, 8681.543565023787, 2196291628.766148, 571.0]
[2019-03-24 02:11:09,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9301116e-11 9.9794430e-01 2.2044506e-18 3.5284561e-08 2.0557579e-03], sum to 1.0000
[2019-03-24 02:11:09,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3865
[2019-03-24 02:11:09,907] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1412181.910963888 W.
[2019-03-24 02:11:09,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.1, 56.0, 1.0, 2.0, 0.6008368851589336, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9613756030800978, 6.9112, 6.9112, 121.9260426156618, 1412181.910963888, 1412181.910963888, 293351.8481896905], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6800400.0000, 
sim time next is 6801000.0000, 
raw observation next is [27.93333333333333, 56.83333333333334, 1.0, 2.0, 0.2109269625847654, 1.0, 1.0, 0.2109269625847654, 1.0, 2.0, 0.336834070536576, 6.9112, 6.9112, 121.94756008, 737896.2542162361, 737896.2542162361, 224130.6943313107], 
processed observation next is [1.0, 0.7391304347826086, 0.5901234567901233, 0.5683333333333335, 1.0, 1.0, 0.060627336410434995, 1.0, 0.5, 0.060627336410434995, 1.0, 1.0, 0.17104258817071996, 0.0, 0.0, 0.8096049824067558, 0.2635343765057986, 0.2635343765057986, 0.4310205660217513], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29096833], dtype=float32), 0.024218857]. 
=============================================
[2019-03-24 02:11:09,933] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[49.585434]
 [49.130962]
 [49.645016]
 [48.613277]
 [48.220898]], R is [[50.96548462]
 [50.45582962]
 [49.95127106]
 [49.45175934]
 [48.95724106]].
[2019-03-24 02:11:10,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1043092e-14 9.9616086e-01 2.3297971e-24 7.4243305e-09 3.8391137e-03], sum to 1.0000
[2019-03-24 02:11:10,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2713
[2019-03-24 02:11:10,471] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 67.5, 1.0, 2.0, 0.4720384374848593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569151.8501968605, 569151.85019686, 138786.1550796269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6809400.0000, 
sim time next is 6810000.0000, 
raw observation next is [25.33333333333333, 68.33333333333333, 1.0, 2.0, 0.4725303201531359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569993.0515011649, 569993.0515011649, 138869.5140865136], 
processed observation next is [1.0, 0.8260869565217391, 0.49382716049382697, 0.6833333333333332, 1.0, 1.0, 0.3720599049442094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20356894696470176, 0.20356894696470176, 0.26705675785868], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.5445649], dtype=float32), 1.0168461]. 
=============================================
[2019-03-24 02:11:10,482] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.153175]
 [77.97804 ]
 [77.95671 ]
 [77.84065 ]
 [78.10332 ]], R is [[78.38174438]
 [78.3310318 ]
 [78.28089905]
 [78.23129272]
 [78.18195343]].
[2019-03-24 02:11:15,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6663467e-11 9.9978071e-01 1.8911326e-20 5.2110574e-09 2.1934166e-04], sum to 1.0000
[2019-03-24 02:11:15,159] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9750
[2019-03-24 02:11:15,169] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 59.33333333333334, 1.0, 2.0, 0.4383704275454699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535919.550871799, 535919.550871799, 133971.8442861775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [25.85, 60.0, 1.0, 2.0, 0.436948972285028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534386.5107737497, 534386.5107737492, 133768.4299294778], 
processed observation next is [0.0, 0.8695652173913043, 0.5129629629629631, 0.6, 1.0, 1.0, 0.3297011574821762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19085232527633916, 0.190852325276339, 0.2572469806336112], 
reward next is 0.7428, 
noisyNet noise sample is [array([0.79360557], dtype=float32), 0.9510472]. 
=============================================
[2019-03-24 02:11:19,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9173731e-14 9.9977344e-01 3.8294661e-24 8.5407098e-12 2.2661992e-04], sum to 1.0000
[2019-03-24 02:11:19,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-24 02:11:19,448] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.18333333333333, 52.16666666666667, 1.0, 2.0, 0.473126321463081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572006.1422724889, 572006.1422724889, 139002.9050885648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6979800.0000, 
sim time next is 6980400.0000, 
raw observation next is [27.9, 53.0, 1.0, 2.0, 0.4688073845849569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567657.0767631304, 567657.0767631304, 138371.7943564291], 
processed observation next is [0.0, 0.8260869565217391, 0.5888888888888888, 0.53, 1.0, 1.0, 0.3676278387916154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20273467027254657, 0.20273467027254657, 0.2660996045315944], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.09063245], dtype=float32), -0.3705102]. 
=============================================
[2019-03-24 02:11:19,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5316481e-16 9.9999988e-01 1.0264917e-28 3.7777632e-11 1.5471565e-07], sum to 1.0000
[2019-03-24 02:11:19,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1706
[2019-03-24 02:11:19,717] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 64.0, 1.0, 2.0, 0.4395417753620542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538232.7389857145, 538232.7389857145, 134168.9580189884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6989400.0000, 
sim time next is 6990000.0000, 
raw observation next is [24.9, 64.66666666666667, 1.0, 2.0, 0.4369798538099142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535366.4628040831, 535366.4628040831, 133798.9836556029], 
processed observation next is [0.0, 0.9130434782608695, 0.47777777777777775, 0.6466666666666667, 1.0, 1.0, 0.3297379212022788, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1912023081443154, 0.1912023081443154, 0.2573057377992364], 
reward next is 0.7427, 
noisyNet noise sample is [array([-1.307001], dtype=float32), -0.5571085]. 
=============================================
[2019-03-24 02:11:19,733] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[80.326035]
 [80.422424]
 [80.525246]
 [80.659615]
 [80.73589 ]], R is [[80.1782074 ]
 [80.1184082 ]
 [80.05874634]
 [79.99967957]
 [79.94110107]].
[2019-03-24 02:11:38,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4719030e-14 9.9999857e-01 2.6861985e-23 6.2534866e-09 1.3819206e-06], sum to 1.0000
[2019-03-24 02:11:38,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5855
[2019-03-24 02:11:38,059] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 83.66666666666666, 1.0, 2.0, 0.373513506901339, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465154.2150709766, 465154.2150709766, 124999.2484300761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350000.0000, 
sim time next is 7350600.0000, 
raw observation next is [20.63333333333333, 83.33333333333334, 1.0, 2.0, 0.3686350286785818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460804.3252419184, 460804.3252419184, 124369.9065053732], 
processed observation next is [1.0, 0.043478260869565216, 0.3197530864197529, 0.8333333333333335, 1.0, 1.0, 0.2483750341411688, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16457297330068513, 0.16457297330068513, 0.2391728971257177], 
reward next is 0.7608, 
noisyNet noise sample is [array([1.3881992], dtype=float32), -0.69495136]. 
=============================================
[2019-03-24 02:11:43,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.09768505e-17 1.00000000e+00 1.21830238e-26 1.12226016e-12
 4.62281449e-08], sum to 1.0000
[2019-03-24 02:11:43,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-24 02:11:43,195] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 77.33333333333334, 1.0, 2.0, 0.5161157677850269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611864.2530964919, 611864.2530964919, 145309.0092605137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7586400.0000, 
sim time next is 7587000.0000, 
raw observation next is [24.8, 78.5, 1.0, 2.0, 0.5162448837938803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611921.5841124976, 611921.5841124976, 145325.8971434121], 
processed observation next is [0.0, 0.8260869565217391, 0.4740740740740741, 0.785, 1.0, 1.0, 0.4241010521355718, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185434228973206, 0.2185434228973206, 0.27947287912194635], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.69872534], dtype=float32), 1.0768335]. 
=============================================
[2019-03-24 02:11:43,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[81.32949 ]
 [81.34559 ]
 [81.385345]
 [81.366295]
 [81.37327 ]], R is [[81.20944977]
 [81.11791229]
 [81.02734375]
 [80.93778992]
 [80.84918213]].
[2019-03-24 02:11:48,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7156280e-14 9.9928588e-01 4.2350755e-21 2.7516714e-10 7.1413792e-04], sum to 1.0000
[2019-03-24 02:11:48,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0276
[2019-03-24 02:11:48,932] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4394773957613979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 535349.2350271017, 535349.2350271012, 134079.5545276153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7524600.0000, 
sim time next is 7525200.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4390476502703463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534832.6214761016, 534832.6214761011, 134016.4608693031], 
processed observation next is [0.0, 0.08695652173913043, 0.32962962962962955, 0.96, 1.0, 1.0, 0.33219958365517416, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19101165052717914, 0.19101165052717897, 0.25772396321019825], 
reward next is 0.7423, 
noisyNet noise sample is [array([0.82836646], dtype=float32), -0.5649007]. 
=============================================
[2019-03-24 02:11:51,099] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 02:11:51,101] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:11:51,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:11:51,102] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:11:51,103] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:11:51,103] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:11:51,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:11:51,104] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:11:51,104] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:11:51,104] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:11:51,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:11:51,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-24 02:11:51,122] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-24 02:11:51,145] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-24 02:11:51,201] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-24 02:11:51,230] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-24 02:12:02,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:12:02,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.33333333333333, 65.83333333333333, 1.0, 2.0, 0.3428335462047565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432694.0969878626, 432694.0969878626, 120995.1947149653]
[2019-03-24 02:12:02,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:12:02,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0131483e-15 9.9999666e-01 6.0749871e-24 1.7816809e-11 3.3667072e-06], sampled 0.6850092303832843
[2019-03-24 02:12:23,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:12:23,310] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.20330022333333, 98.02840301333333, 1.0, 2.0, 0.7481296205093826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 852686.6424367318, 852686.6424367318, 185461.5308369242]
[2019-03-24 02:12:23,311] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:12:23,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.6110478e-16 9.9999797e-01 5.8067129e-25 6.1383711e-12 2.0045086e-06], sampled 0.7365876741734009
[2019-03-24 02:12:38,385] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:12:38,385] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.35, 72.66666666666666, 1.0, 2.0, 0.7224314756641901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823381.246105018, 823381.246105018, 180441.9487731631]
[2019-03-24 02:12:38,388] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:12:38,390] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3239651e-16 9.9999845e-01 1.9493587e-25 3.7406866e-12 1.5755979e-06], sampled 0.14944378557827454
[2019-03-24 02:12:47,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:12:47,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.8, 64.0, 1.0, 2.0, 0.401639230194015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499922.5820600818, 499922.5820600818, 128898.888288068]
[2019-03-24 02:12:47,411] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:12:47,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8753085e-15 9.9999666e-01 5.4257396e-24 1.6926531e-11 3.2839287e-06], sampled 0.1635109017469375
[2019-03-24 02:12:57,895] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:12:57,896] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.89395553, 81.31045328, 1.0, 2.0, 0.5695367456050534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666528.1230721723, 666528.1230721723, 153729.9075046277]
[2019-03-24 02:12:57,897] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:12:57,900] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5827833e-16 9.9999774e-01 1.0236760e-24 7.9401416e-12 2.2719078e-06], sampled 0.5572539498758846
[2019-03-24 02:13:03,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:13:03,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.7, 58.0, 1.0, 2.0, 0.720163079718124, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260423321789, 1535815.321117657, 1535815.321117657, 320918.3831941341]
[2019-03-24 02:13:03,850] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:13:03,852] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.9714653e-14 9.9998724e-01 2.5716534e-21 2.7741306e-10 1.2811387e-05], sampled 0.7391103880828738
[2019-03-24 02:13:03,853] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1535815.321117657 W.
[2019-03-24 02:13:12,341] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.70284975]
[2019-03-24 02:13:12,343] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.86666666666667, 88.00000000000001, 1.0, 2.0, 0.4447951187253621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541623.4006573847, 541623.4006573847, 134859.3498294437]
[2019-03-24 02:13:12,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:13:12,346] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6882740e-15 9.9999630e-01 9.6285412e-24 2.1960231e-11 3.7273644e-06], sampled 0.32580552603389634
[2019-03-24 02:13:29,214] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8101.2234 2445363294.9332 746.0000
[2019-03-24 02:13:29,694] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:13:29,698] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:13:29,749] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:13:29,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.0143 2248728856.9478 553.0000
[2019-03-24 02:13:30,883] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1050000, evaluation results [1050000.0, 8101.223408152135, 2445363294.9332376, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.014266265609, 2248728856.947815, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:13:33,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0698220e-16 9.9999988e-01 1.2848130e-24 3.5047774e-12 6.8647708e-08], sum to 1.0000
[2019-03-24 02:13:33,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3376
[2019-03-24 02:13:33,725] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3278235164303551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414819.0924372801, 414819.0924372801, 119059.1947107262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [21.03333333333333, 72.5, 1.0, 2.0, 0.4486899322629758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567874.2232937695, 567874.2232937695, 135888.8191509578], 
processed observation next is [1.0, 0.08695652173913043, 0.3345679012345678, 0.725, 1.0, 1.0, 0.3436784907892569, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20281222260491769, 0.20281222260491769, 0.2613246522133804], 
reward next is 0.7387, 
noisyNet noise sample is [array([-0.7055262], dtype=float32), -1.7247826]. 
=============================================
[2019-03-24 02:13:43,590] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:43,590] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:43,655] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-24 02:13:50,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:50,839] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:50,897] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-24 02:13:51,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,152] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,158] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-24 02:13:51,310] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1060100: loss 0.6281
[2019-03-24 02:13:51,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1060100: learning rate 0.0001
[2019-03-24 02:13:51,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,604] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-24 02:13:51,741] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,741] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-24 02:13:51,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,803] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-24 02:13:51,840] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-24 02:13:51,875] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,875] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-24 02:13:51,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,950] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-24 02:13:51,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,985] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:51,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:51,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-24 02:13:52,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:52,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:52,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-24 02:13:52,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:52,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:52,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-24 02:13:52,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-24 02:13:52,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:52,170] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:52,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-24 02:13:52,219] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:52,219] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:52,221] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:13:52,221] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:13:52,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-24 02:13:52,283] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-24 02:13:53,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7164382e-13 9.9628520e-01 2.9436110e-15 4.6387818e-06 3.7101621e-03], sum to 1.0000
[2019-03-24 02:13:53,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9141
[2019-03-24 02:13:53,441] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 74.66666666666667, 1.0, 2.0, 0.2593170419313834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334499.2939728476, 334499.2939728476, 101406.370129977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [18.0, 74.33333333333334, 1.0, 2.0, 0.2493206403070959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 321601.9913945755, 321601.9913945755, 99532.10862250344], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.7433333333333334, 1.0, 1.0, 0.10633409560368558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11485785406949126, 0.11485785406949126, 0.191407901197122], 
reward next is 0.8086, 
noisyNet noise sample is [array([0.06217619], dtype=float32), 0.1972268]. 
=============================================
[2019-03-24 02:13:53,928] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9364504e-14 9.9954575e-01 7.4270753e-19 1.4306023e-06 4.5281672e-04], sum to 1.0000
[2019-03-24 02:13:53,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-24 02:13:53,937] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 72.66666666666667, 1.0, 2.0, 0.3319025418188325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421423.9842119759, 421423.9842119759, 119596.6424619486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2400.0000, 
sim time next is 3000.0000, 
raw observation next is [19.6, 73.83333333333333, 1.0, 2.0, 0.3085799110488455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 394616.9469517344, 394616.946951734, 116642.9987535124], 
processed observation next is [1.0, 0.0, 0.28148148148148155, 0.7383333333333333, 1.0, 1.0, 0.17688084648672087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1409346239113337, 0.14093462391133357, 0.22431345914137], 
reward next is 0.7757, 
noisyNet noise sample is [array([0.14534536], dtype=float32), -1.1362336]. 
=============================================
[2019-03-24 02:13:53,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.20746 ]
 [65.07141 ]
 [64.173676]
 [63.731678]
 [61.214993]], R is [[67.50603485]
 [67.60098267]
 [67.68870544]
 [67.76927185]
 [67.84294891]].
[2019-03-24 02:13:54,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3375321e-14 9.9997604e-01 7.5252930e-18 4.9472726e-10 2.4014877e-05], sum to 1.0000
[2019-03-24 02:13:54,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0730
[2019-03-24 02:13:54,412] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.23333333333333, 76.0, 1.0, 2.0, 0.2751337770083078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354906.4019499148, 354906.4019499148, 108422.7324735145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [18.2, 76.0, 1.0, 2.0, 0.2814448782833823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363049.2785798542, 363049.2785798542, 108582.338313043], 
processed observation next is [1.0, 0.13043478260869565, 0.2296296296296296, 0.76, 1.0, 1.0, 0.14457723605164563, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1296604566356622, 0.1296604566356622, 0.20881218906354423], 
reward next is 0.7912, 
noisyNet noise sample is [array([0.69196093], dtype=float32), -0.3926952]. 
=============================================
[2019-03-24 02:14:00,597] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1063918: loss 1.3682
[2019-03-24 02:14:00,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1063920: learning rate 0.0001
[2019-03-24 02:14:00,633] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1063931: loss 0.5895
[2019-03-24 02:14:00,635] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1063932: learning rate 0.0001
[2019-03-24 02:14:00,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9716371e-06 8.6364782e-01 1.0133909e-09 1.1648209e-03 1.3518430e-01], sum to 1.0000
[2019-03-24 02:14:00,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1769
[2019-03-24 02:14:00,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1444900.261564383 W.
[2019-03-24 02:14:00,718] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.18333333333333, 32.33333333333334, 1.0, 2.0, 0.6129027665844805, 1.0, 2.0, 0.6129027665844805, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1444900.261564383, 1444900.261564383, 274698.5642273561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 130200.0000, 
sim time next is 130800.0000, 
raw observation next is [33.56666666666666, 30.66666666666667, 1.0, 2.0, 0.5115131520289335, 1.0, 2.0, 0.5115131520289335, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1214580.628297324, 1214580.628297324, 241104.3721444176], 
processed observation next is [1.0, 0.5217391304347826, 0.7987654320987653, 0.3066666666666667, 1.0, 1.0, 0.41846803812968275, 1.0, 1.0, 0.41846803812968275, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43377879582047285, 0.43377879582047285, 0.46366225412388], 
reward next is 0.5363, 
noisyNet noise sample is [array([-0.28556952], dtype=float32), 1.037382]. 
=============================================
[2019-03-24 02:14:01,383] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064301: loss 5.1257
[2019-03-24 02:14:01,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064301: learning rate 0.0001
[2019-03-24 02:14:01,501] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064354: loss -1.2223
[2019-03-24 02:14:01,504] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064355: learning rate 0.0001
[2019-03-24 02:14:01,560] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064384: loss 4.8938
[2019-03-24 02:14:01,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064384: learning rate 0.0001
[2019-03-24 02:14:01,619] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064418: loss -1.4060
[2019-03-24 02:14:01,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064418: learning rate 0.0001
[2019-03-24 02:14:01,646] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064430: loss 8.2645
[2019-03-24 02:14:01,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064430: learning rate 0.0001
[2019-03-24 02:14:01,661] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064433: loss 0.2292
[2019-03-24 02:14:01,663] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064434: learning rate 0.0001
[2019-03-24 02:14:01,789] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064497: loss 0.4191
[2019-03-24 02:14:01,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064497: learning rate 0.0001
[2019-03-24 02:14:01,828] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064516: loss -0.9924
[2019-03-24 02:14:01,831] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064516: learning rate 0.0001
[2019-03-24 02:14:01,916] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1064558: loss -0.1883
[2019-03-24 02:14:01,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1064558: learning rate 0.0001
[2019-03-24 02:14:02,085] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064643: loss -0.7765
[2019-03-24 02:14:02,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064643: learning rate 0.0001
[2019-03-24 02:14:02,133] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064665: loss -0.4752
[2019-03-24 02:14:02,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064667: learning rate 0.0001
[2019-03-24 02:14:02,268] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064730: loss 3.1293
[2019-03-24 02:14:02,269] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064730: learning rate 0.0001
[2019-03-24 02:14:02,339] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064765: loss -4.2338
[2019-03-24 02:14:02,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064765: learning rate 0.0001
[2019-03-24 02:14:03,552] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1065373: loss 1.5939
[2019-03-24 02:14:03,554] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1065373: learning rate 0.0001
[2019-03-24 02:14:10,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4380370e-16 9.9999583e-01 4.8993809e-19 1.2071939e-08 4.1886769e-06], sum to 1.0000
[2019-03-24 02:14:10,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3583
[2019-03-24 02:14:10,130] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 30.66666666666666, 1.0, 2.0, 0.3184419884592032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410411.1732270969, 410411.1732270969, 117873.4281333943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [27.1, 30.83333333333334, 1.0, 2.0, 0.3193981825392953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 411273.4774249746, 411273.4774249742, 117997.9533682266], 
processed observation next is [0.0, 0.5217391304347826, 0.5592592592592593, 0.3083333333333334, 1.0, 1.0, 0.1897597411182087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14688338479463378, 0.14688338479463364, 0.22691914109274347], 
reward next is 0.7731, 
noisyNet noise sample is [array([1.12661], dtype=float32), 0.45034802]. 
=============================================
[2019-03-24 02:14:16,724] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1071899: loss 0.3535
[2019-03-24 02:14:16,728] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1071899: learning rate 0.0001
[2019-03-24 02:14:16,808] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1071940: loss 0.7289
[2019-03-24 02:14:16,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1071943: learning rate 0.0001
[2019-03-24 02:14:17,430] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072249: loss 0.0145
[2019-03-24 02:14:17,432] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072250: learning rate 0.0001
[2019-03-24 02:14:17,488] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072274: loss 0.2718
[2019-03-24 02:14:17,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072274: learning rate 0.0001
[2019-03-24 02:14:17,686] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072374: loss 0.0117
[2019-03-24 02:14:17,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072376: learning rate 0.0001
[2019-03-24 02:14:17,744] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072404: loss 0.0061
[2019-03-24 02:14:17,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072404: learning rate 0.0001
[2019-03-24 02:14:17,775] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072416: loss 0.0459
[2019-03-24 02:14:17,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072416: learning rate 0.0001
[2019-03-24 02:14:17,895] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072478: loss 0.2205
[2019-03-24 02:14:17,897] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072479: learning rate 0.0001
[2019-03-24 02:14:17,899] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072479: loss 0.1678
[2019-03-24 02:14:17,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072479: learning rate 0.0001
[2019-03-24 02:14:17,954] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072503: loss 0.0885
[2019-03-24 02:14:17,955] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072503: loss 0.0272
[2019-03-24 02:14:17,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072503: learning rate 0.0001
[2019-03-24 02:14:17,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072504: learning rate 0.0001
[2019-03-24 02:14:18,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072600: loss 0.0058
[2019-03-24 02:14:18,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072601: learning rate 0.0001
[2019-03-24 02:14:18,208] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072627: loss 0.0089
[2019-03-24 02:14:18,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072627: learning rate 0.0001
[2019-03-24 02:14:18,353] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072687: loss 0.0245
[2019-03-24 02:14:18,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072689: learning rate 0.0001
[2019-03-24 02:14:18,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072726: loss 0.0881
[2019-03-24 02:14:18,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072726: learning rate 0.0001
[2019-03-24 02:14:20,266] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1073588: loss -3.6861
[2019-03-24 02:14:20,269] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1073588: learning rate 0.0001
[2019-03-24 02:14:22,968] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 02:14:22,970] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:14:22,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:14:22,974] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:14:22,975] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:14:22,974] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:14:22,975] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:14:22,976] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:14:22,975] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:14:22,977] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:14:22,978] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:14:22,989] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-24 02:14:23,014] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-24 02:14:23,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-24 02:14:23,041] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-24 02:14:23,089] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-24 02:15:40,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7121459]
[2019-03-24 02:15:40,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 72.66666666666667, 1.0, 2.0, 0.6453689114453138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735508.1183772519, 735508.1183772519, 166058.5374081046]
[2019-03-24 02:15:40,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:15:40,032] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.1976148e-10 9.6474111e-01 3.5944082e-12 3.2610092e-02 2.6488348e-03], sampled 0.3448365084938326
[2019-03-24 02:15:51,511] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7121459]
[2019-03-24 02:15:51,512] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.64922707833333, 90.74820338333333, 1.0, 2.0, 0.4064463948515989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501449.6537370963, 501449.6537370963, 129480.4190035205]
[2019-03-24 02:15:51,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:15:51,515] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7386337e-10 9.7170275e-01 4.9784428e-13 2.6512612e-02 1.7846075e-03], sampled 0.03157579094658902
[2019-03-24 02:15:55,093] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7121459]
[2019-03-24 02:15:55,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.51309378000001, 79.09463349333333, 1.0, 2.0, 0.3160495317577069, 1.0, 1.0, 0.3160495317577069, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720377.753713198, 720377.7537131985, 184356.8312284905]
[2019-03-24 02:15:55,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:15:55,099] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.1812999e-10 9.6931434e-01 1.0773807e-12 2.8620323e-02 2.0653103e-03], sampled 0.012863159010190417
[2019-03-24 02:15:57,949] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7121459]
[2019-03-24 02:15:57,951] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.25, 92.50000000000001, 1.0, 2.0, 0.296585796231668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376666.0548537141, 376666.0548537141, 115145.6542513471]
[2019-03-24 02:15:57,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:15:57,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3377702e-10 9.7272360e-01 3.5643686e-13 2.5605962e-02 1.6703140e-03], sampled 0.33310008888322784
[2019-03-24 02:16:00,803] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8474.9277 2178567273.3179 474.0000
[2019-03-24 02:16:01,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7855.4866 2451721411.4865 714.0000
[2019-03-24 02:16:01,160] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8397.3015 2204201920.6289 561.0000
[2019-03-24 02:16:01,332] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8615.4637 2130269536.1406 418.0000
[2019-03-24 02:16:01,471] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8338.0163 2255321442.4445 533.0000
[2019-03-24 02:16:02,487] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1075000, evaluation results [1075000.0, 7855.486626813704, 2451721411.4864807, 714.0, 8474.927703259404, 2178567273.317898, 474.0, 8615.463746536092, 2130269536.1406024, 418.0, 8338.016349645737, 2255321442.4445457, 533.0, 8397.30152743733, 2204201920.628862, 561.0]
[2019-03-24 02:16:10,496] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7765772e-16 9.9999988e-01 1.6142271e-20 6.2538675e-08 1.9179622e-09], sum to 1.0000
[2019-03-24 02:16:10,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-24 02:16:10,509] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 35.0, 1.0, 2.0, 0.3370094001806503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426805.2562799744, 426805.2562799744, 120250.2592987338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 687600.0000, 
sim time next is 688200.0000, 
raw observation next is [28.06666666666667, 35.16666666666667, 1.0, 2.0, 0.3352135773565864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424763.7503991032, 424763.7503991032, 120018.9910553417], 
processed observation next is [1.0, 1.0, 0.5950617283950619, 0.35166666666666674, 1.0, 1.0, 0.2085875920911743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15170133942825115, 0.15170133942825115, 0.23080575202950326], 
reward next is 0.7692, 
noisyNet noise sample is [array([-0.4432435], dtype=float32), 1.0715]. 
=============================================
[2019-03-24 02:16:10,703] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0119963e-18 1.0000000e+00 5.3191293e-24 1.5375074e-11 4.3106872e-12], sum to 1.0000
[2019-03-24 02:16:10,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-24 02:16:10,719] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 48.83333333333333, 1.0, 2.0, 0.3344117963600645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 428747.20113726, 428747.2011372595, 119933.9550742812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 706200.0000, 
sim time next is 706800.0000, 
raw observation next is [23.36666666666667, 49.66666666666666, 1.0, 2.0, 0.3042910665982783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 116107.7854659753], 
processed observation next is [1.0, 0.17391304347826086, 0.4209876543209878, 0.4966666666666666, 1.0, 1.0, 0.17177507928366467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1393542509817288, 0.1393542509817288, 0.2232842028191833], 
reward next is 0.7767, 
noisyNet noise sample is [array([-1.6675605], dtype=float32), 0.4495289]. 
=============================================
[2019-03-24 02:16:12,561] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1079999: loss 29.6055
[2019-03-24 02:16:12,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1079999: learning rate 0.0001
[2019-03-24 02:16:12,655] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080046: loss 14.0607
[2019-03-24 02:16:12,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080048: learning rate 0.0001
[2019-03-24 02:16:13,124] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080283: loss 28.3118
[2019-03-24 02:16:13,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080284: learning rate 0.0001
[2019-03-24 02:16:13,340] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080390: loss 23.1434
[2019-03-24 02:16:13,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080390: learning rate 0.0001
[2019-03-24 02:16:13,374] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080408: loss 19.4653
[2019-03-24 02:16:13,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080410: learning rate 0.0001
[2019-03-24 02:16:13,441] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080441: loss 24.7204
[2019-03-24 02:16:13,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080441: learning rate 0.0001
[2019-03-24 02:16:13,459] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080449: loss 24.3521
[2019-03-24 02:16:13,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080451: learning rate 0.0001
[2019-03-24 02:16:13,469] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080454: loss 15.3322
[2019-03-24 02:16:13,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080454: learning rate 0.0001
[2019-03-24 02:16:13,489] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080464: loss 19.7142
[2019-03-24 02:16:13,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080464: learning rate 0.0001
[2019-03-24 02:16:13,510] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080476: loss 22.0935
[2019-03-24 02:16:13,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080476: learning rate 0.0001
[2019-03-24 02:16:13,562] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080501: loss 16.3466
[2019-03-24 02:16:13,563] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080501: learning rate 0.0001
[2019-03-24 02:16:13,721] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080581: loss 10.6206
[2019-03-24 02:16:13,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080582: learning rate 0.0001
[2019-03-24 02:16:13,870] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080658: loss 8.4255
[2019-03-24 02:16:13,874] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080659: learning rate 0.0001
[2019-03-24 02:16:13,908] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080673: loss 10.8865
[2019-03-24 02:16:13,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080674: learning rate 0.0001
[2019-03-24 02:16:14,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080747: loss 6.5376
[2019-03-24 02:16:14,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080748: learning rate 0.0001
[2019-03-24 02:16:15,207] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1081325: loss 0.8500
[2019-03-24 02:16:15,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1081325: learning rate 0.0001
[2019-03-24 02:16:16,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4135851e-17 1.0000000e+00 5.8336901e-21 5.1056598e-12 1.5653877e-11], sum to 1.0000
[2019-03-24 02:16:16,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-24 02:16:16,053] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 58.0, 1.0, 2.0, 0.3120308511521739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396570.7243281645, 396570.7243281645, 117067.42074699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.58, 1.0, 1.0, 0.18342182099366253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14246955213933976, 0.14246955213933957, 0.22562094760006463], 
reward next is 0.7744, 
noisyNet noise sample is [array([-0.7470558], dtype=float32), -1.1248031]. 
=============================================
[2019-03-24 02:16:16,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4328204e-17 1.0000000e+00 1.8013523e-18 4.5271988e-11 1.1251048e-11], sum to 1.0000
[2019-03-24 02:16:16,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9156
[2019-03-24 02:16:16,504] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 50.66666666666667, 1.0, 2.0, 0.3917939236719075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485483.0727770826, 485483.0727770826, 127469.9898725707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 812400.0000, 
sim time next is 813000.0000, 
raw observation next is [27.0, 49.83333333333334, 1.0, 2.0, 0.3969954509344281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491184.094864478, 491184.094864478, 128180.6637397082], 
processed observation next is [0.0, 0.391304347826087, 0.5555555555555556, 0.4983333333333334, 1.0, 1.0, 0.28213744158860493, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17542289102302785, 0.17542289102302785, 0.24650127642251576], 
reward next is 0.7535, 
noisyNet noise sample is [array([-2.0200834], dtype=float32), 0.50757086]. 
=============================================
[2019-03-24 02:16:16,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.068634]
 [74.08914 ]
 [74.071945]
 [74.03052 ]
 [74.03906 ]], R is [[74.05181885]
 [74.06616974]
 [74.08139038]
 [74.097435  ]
 [74.11439514]].
[2019-03-24 02:16:17,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0453805e-21 1.0000000e+00 3.4960917e-27 1.5103172e-14 3.2974739e-16], sum to 1.0000
[2019-03-24 02:16:17,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3760
[2019-03-24 02:16:17,418] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 36.0, 1.0, 2.0, 0.4473507633109658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542850.2934537557, 542850.2934537557, 135181.9119275453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 824400.0000, 
sim time next is 825000.0000, 
raw observation next is [31.93333333333333, 36.0, 1.0, 2.0, 0.448106289458143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543968.848006919, 543968.848006919, 135300.3192743601], 
processed observation next is [0.0, 0.5652173913043478, 0.7382716049382715, 0.36, 1.0, 1.0, 0.3429836779263607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19427458857389965, 0.19427458857389965, 0.26019292168146174], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.17520767], dtype=float32), -0.17301962]. 
=============================================
[2019-03-24 02:16:17,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[94.33987 ]
 [94.128815]
 [93.950294]
 [93.77107 ]
 [93.59677 ]], R is [[94.28244019]
 [94.07965088]
 [93.87928009]
 [93.68144226]
 [93.48629761]].
[2019-03-24 02:16:28,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0083868e-10 9.9800569e-01 2.5091466e-13 5.9024041e-04 1.4040774e-03], sum to 1.0000
[2019-03-24 02:16:28,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1772
[2019-03-24 02:16:28,134] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 46.5, 1.0, 2.0, 0.2835979524466106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364564.3301331811, 364564.3301331811, 113569.3236691056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1027800.0000, 
sim time next is 1028400.0000, 
raw observation next is [23.6, 46.66666666666667, 1.0, 2.0, 0.2830587515776933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363916.1781013479, 363916.1781013479, 113504.0363684698], 
processed observation next is [1.0, 0.9130434782608695, 0.4296296296296297, 0.46666666666666673, 1.0, 1.0, 0.1464985137829682, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12997006360762425, 0.12997006360762425, 0.21827699301628806], 
reward next is 0.7817, 
noisyNet noise sample is [array([-0.90135187], dtype=float32), 0.54146665]. 
=============================================
[2019-03-24 02:16:28,438] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1087872: loss 0.5040
[2019-03-24 02:16:28,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1087872: learning rate 0.0001
[2019-03-24 02:16:28,657] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1087979: loss 0.2291
[2019-03-24 02:16:28,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1087979: learning rate 0.0001
[2019-03-24 02:16:29,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088286: loss 0.3921
[2019-03-24 02:16:29,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088287: learning rate 0.0001
[2019-03-24 02:16:29,522] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088406: loss 1.4662
[2019-03-24 02:16:29,522] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088406: loss 1.3322
[2019-03-24 02:16:29,526] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088406: learning rate 0.0001
[2019-03-24 02:16:29,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088406: learning rate 0.0001
[2019-03-24 02:16:29,608] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088449: loss 1.9747
[2019-03-24 02:16:29,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088449: learning rate 0.0001
[2019-03-24 02:16:29,629] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088457: loss 1.9985
[2019-03-24 02:16:29,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088457: learning rate 0.0001
[2019-03-24 02:16:29,632] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088457: loss 2.1585
[2019-03-24 02:16:29,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088460: learning rate 0.0001
[2019-03-24 02:16:29,642] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088464: loss 2.2274
[2019-03-24 02:16:29,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088464: learning rate 0.0001
[2019-03-24 02:16:29,710] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088501: loss 2.2823
[2019-03-24 02:16:29,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088501: learning rate 0.0001
[2019-03-24 02:16:29,752] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088523: loss 1.9545
[2019-03-24 02:16:29,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088523: learning rate 0.0001
[2019-03-24 02:16:29,761] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088523: loss 2.0212
[2019-03-24 02:16:29,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088523: learning rate 0.0001
[2019-03-24 02:16:30,058] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088675: loss 1.0416
[2019-03-24 02:16:30,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088676: learning rate 0.0001
[2019-03-24 02:16:30,141] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088717: loss 0.9049
[2019-03-24 02:16:30,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088718: learning rate 0.0001
[2019-03-24 02:16:30,202] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088749: loss 0.8385
[2019-03-24 02:16:30,206] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088749: learning rate 0.0001
[2019-03-24 02:16:31,389] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1089337: loss 31.4654
[2019-03-24 02:16:31,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1089338: learning rate 0.0001
[2019-03-24 02:16:39,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2387271e-16 9.9999976e-01 5.1505403e-17 2.3129017e-07 5.6537786e-08], sum to 1.0000
[2019-03-24 02:16:39,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-24 02:16:39,767] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.76666666666667, 88.83333333333334, 1.0, 2.0, 0.3212298525647462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407456.800549154, 407456.800549154, 118225.1559950018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1235400.0000, 
sim time next is 1236000.0000, 
raw observation next is [18.83333333333334, 88.66666666666667, 1.0, 2.0, 0.333517934196144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422818.9020351854, 422818.9020351854, 119801.0807006167], 
processed observation next is [1.0, 0.30434782608695654, 0.25308641975308666, 0.8866666666666667, 1.0, 1.0, 0.2065689692811238, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15100675072685193, 0.15100675072685193, 0.23038669365503212], 
reward next is 0.7696, 
noisyNet noise sample is [array([2.948195], dtype=float32), -0.46537766]. 
=============================================
[2019-03-24 02:16:39,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.21939 ]
 [73.23487 ]
 [73.19539 ]
 [73.15874 ]
 [73.108154]], R is [[73.20372009]
 [73.24433136]
 [73.28471375]
 [73.32367706]
 [73.36032867]].
[2019-03-24 02:16:44,742] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1095954: loss -27.4457
[2019-03-24 02:16:44,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1095956: learning rate 0.0001
[2019-03-24 02:16:44,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8465652e-15 9.9999905e-01 2.3035177e-15 7.2644313e-10 9.9633303e-07], sum to 1.0000
[2019-03-24 02:16:44,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8459
[2019-03-24 02:16:44,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1356323.48416104 W.
[2019-03-24 02:16:44,776] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.8, 41.5, 1.0, 2.0, 0.9324386242027977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.283289024314552, 6.9112, 121.9242486955599, 1356323.48416104, 1165783.450263894, 229072.4400827722], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1337400.0000, 
sim time next is 1338000.0000, 
raw observation next is [28.0, 41.0, 1.0, 2.0, 0.4982285221812179, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8233435199073703, 6.911199999999999, 6.9112, 121.9258185011756, 1230845.63731525, 1230845.637315251, 252591.7534435081], 
processed observation next is [1.0, 0.4782608695652174, 0.5925925925925926, 0.41, 1.0, 1.0, 0.402653002596688, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7791793998842128, -8.881784197001253e-17, 0.0, 0.8094606409330102, 0.4395877276125893, 0.43958772761258963, 0.48575337200674634], 
reward next is 0.5142, 
noisyNet noise sample is [array([-0.76525646], dtype=float32), -0.02458129]. 
=============================================
[2019-03-24 02:16:44,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.446236]
 [60.57953 ]
 [60.914772]
 [61.481842]
 [61.30568 ]], R is [[60.26966858]
 [59.66697311]
 [59.07030487]
 [58.47960281]
 [58.52534485]].
[2019-03-24 02:16:44,893] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096028: loss -2.7254
[2019-03-24 02:16:44,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096028: learning rate 0.0001
[2019-03-24 02:16:45,405] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096284: loss 2.7392
[2019-03-24 02:16:45,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096284: learning rate 0.0001
[2019-03-24 02:16:45,654] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096409: loss -12.8152
[2019-03-24 02:16:45,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096410: learning rate 0.0001
[2019-03-24 02:16:45,691] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096423: loss 0.6027
[2019-03-24 02:16:45,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096423: learning rate 0.0001
[2019-03-24 02:16:45,735] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096444: loss -33.7636
[2019-03-24 02:16:45,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096445: learning rate 0.0001
[2019-03-24 02:16:45,753] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096453: loss -13.2682
[2019-03-24 02:16:45,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096453: learning rate 0.0001
[2019-03-24 02:16:45,801] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096479: loss -1.0032
[2019-03-24 02:16:45,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096479: learning rate 0.0001
[2019-03-24 02:16:45,828] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096489: loss 6.3788
[2019-03-24 02:16:45,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096489: learning rate 0.0001
[2019-03-24 02:16:45,845] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096499: loss -10.3545
[2019-03-24 02:16:45,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096499: learning rate 0.0001
[2019-03-24 02:16:45,870] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096508: loss 14.7414
[2019-03-24 02:16:45,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096508: learning rate 0.0001
[2019-03-24 02:16:45,913] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096528: loss -39.7174
[2019-03-24 02:16:45,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096529: learning rate 0.0001
[2019-03-24 02:16:46,137] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096643: loss -37.2929
[2019-03-24 02:16:46,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096647: learning rate 0.0001
[2019-03-24 02:16:46,174] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096658: loss -28.3098
[2019-03-24 02:16:46,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096658: learning rate 0.0001
[2019-03-24 02:16:46,271] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096708: loss -32.6035
[2019-03-24 02:16:46,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096708: learning rate 0.0001
[2019-03-24 02:16:47,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5038581e-13 9.9990118e-01 8.9121241e-15 7.8660203e-05 2.0102825e-05], sum to 1.0000
[2019-03-24 02:16:47,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6768
[2019-03-24 02:16:47,228] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 59.0, 1.0, 2.0, 0.3617843355449866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 453667.6622166314, 453667.662216631, 123470.02657682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1374600.0000, 
sim time next is 1375200.0000, 
raw observation next is [23.8, 60.0, 1.0, 2.0, 0.3591863863820412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 450700.817990955, 450700.817990955, 123126.1839754896], 
processed observation next is [1.0, 0.9565217391304348, 0.43703703703703706, 0.6, 1.0, 1.0, 0.23712665045481096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16096457785391252, 0.16096457785391252, 0.2367811230297877], 
reward next is 0.7632, 
noisyNet noise sample is [array([0.97575533], dtype=float32), 1.3106407]. 
=============================================
[2019-03-24 02:16:47,696] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1097419: loss 0.2097
[2019-03-24 02:16:47,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1097419: learning rate 0.0001
[2019-03-24 02:16:48,376] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6939084e-17 9.9999976e-01 3.9440112e-18 3.6506793e-09 2.2212475e-07], sum to 1.0000
[2019-03-24 02:16:48,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1503
[2019-03-24 02:16:48,387] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 51.0, 1.0, 2.0, 0.2927123233612687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 373828.4581916349, 373828.4581916344, 114680.6400026384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1405800.0000, 
sim time next is 1406400.0000, 
raw observation next is [24.06666666666667, 50.0, 1.0, 2.0, 0.2972871724154282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 379097.4992567076, 379097.4992567071, 115240.2722419807], 
processed observation next is [0.0, 0.2608695652173913, 0.4469135802469137, 0.5, 1.0, 1.0, 0.1634371100183669, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13539196402025272, 0.13539196402025253, 0.2216159081576552], 
reward next is 0.7784, 
noisyNet noise sample is [array([-0.29863155], dtype=float32), 1.4234445]. 
=============================================
[2019-03-24 02:16:52,953] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 02:16:52,957] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:16:52,959] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:16:52,960] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:16:52,962] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:16:52,963] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:16:52,964] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:16:52,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:16:52,965] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:16:52,966] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:16:52,969] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:16:52,982] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-24 02:16:52,982] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-24 02:16:53,035] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-24 02:16:53,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-24 02:16:53,096] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-24 02:17:04,537] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:17:04,538] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.84881218666666, 51.27691683333333, 1.0, 2.0, 0.3215712121797588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408620.6596800516, 408620.6596800516, 118273.2940542811]
[2019-03-24 02:17:04,538] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:17:04,543] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.2411764e-13 9.9993634e-01 2.6924026e-15 1.8943840e-05 4.4736720e-05], sampled 0.1753877771928647
[2019-03-24 02:17:06,788] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:17:06,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [16.62314216666667, 60.289046125, 1.0, 2.0, 0.2042801233464767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 263493.6531963474, 263493.6531963474, 78593.1841964475]
[2019-03-24 02:17:06,791] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:17:06,793] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2118367e-12 9.9991488e-01 7.3356018e-15 2.5837842e-05 5.9288544e-05], sampled 0.4328351064322813
[2019-03-24 02:17:12,139] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:17:12,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.91666666666667, 29.5, 1.0, 2.0, 0.6161690447279926, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9630772706604508, 6.911199999999999, 6.9112, 121.9260426156342, 1451142.244048628, 1451142.244048628, 294462.5998596585]
[2019-03-24 02:17:12,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:17:12,143] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6047297e-12 9.9990654e-01 1.0273080e-14 2.8614488e-05 6.4831453e-05], sampled 0.47261221597271585
[2019-03-24 02:17:12,145] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1451142.244048628 W.
[2019-03-24 02:17:12,387] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:17:12,389] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.15801208, 45.54091387333334, 1.0, 2.0, 0.3667685619904501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457103.3881765456, 457103.3881765456, 124091.4204210668]
[2019-03-24 02:17:12,390] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:17:12,392] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.6310127e-13 9.9993479e-01 2.9340317e-15 1.9446778e-05 4.5775105e-05], sampled 0.1335666885914072
[2019-03-24 02:17:26,971] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:17:26,972] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 94.0, 1.0, 2.0, 0.5981745354080575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 682065.3492258429, 682065.3492258433, 157781.9554387263]
[2019-03-24 02:17:26,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:17:26,978] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3451443e-13 9.9994540e-01 1.5733150e-15 1.6043477e-05 3.8492617e-05], sampled 0.0023909399450684488
[2019-03-24 02:18:07,996] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:18:07,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.56666666666666, 71.66666666666667, 1.0, 2.0, 0.6173215064595821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708046.7071200135, 708046.7071200135, 161305.976863522]
[2019-03-24 02:18:07,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:18:08,003] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6027268e-13 9.9994409e-01 1.7196607e-15 1.6484550e-05 3.9421629e-05], sampled 0.7923186266686782
[2019-03-24 02:18:13,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7293755]
[2019-03-24 02:18:13,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666667, 83.0, 1.0, 2.0, 0.4893502224336145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584816.6873942823, 584816.6873942823, 141274.2973647702]
[2019-03-24 02:18:13,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:18:13,610] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.4783240e-13 9.9993527e-01 2.8381918e-15 1.9258701e-05 4.5426310e-05], sampled 0.3186327633491105
[2019-03-24 02:18:30,736] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:18:30,830] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.1499 2248636747.1484 553.0000
[2019-03-24 02:18:30,846] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0729 2170635039.9212 493.0000
[2019-03-24 02:18:30,876] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:18:30,881] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:18:31,896] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1100000, evaluation results [1100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.07289139456, 2170635039.921214, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.14993615413, 2248636747.1484036, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:18:39,673] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1103865: loss 0.0591
[2019-03-24 02:18:39,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1103866: learning rate 0.0001
[2019-03-24 02:18:39,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2169616e-13 9.9995399e-01 8.2079075e-16 4.5407585e-05 6.2010020e-07], sum to 1.0000
[2019-03-24 02:18:39,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7640
[2019-03-24 02:18:39,799] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 91.5, 1.0, 2.0, 0.4231512163953767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519857.8386050754, 519857.838605075, 131820.1063953915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1895400.0000, 
sim time next is 1896000.0000, 
raw observation next is [20.9, 91.66666666666666, 1.0, 2.0, 0.4234004909734668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520004.9313856516, 520004.9313856516, 131852.0258799559], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9166666666666665, 1.0, 1.0, 0.313572013063651, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18571604692344698, 0.18571604692344698, 0.2535615882306844], 
reward next is 0.7464, 
noisyNet noise sample is [array([1.1821172], dtype=float32), -0.61562777]. 
=============================================
[2019-03-24 02:18:39,817] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.60609 ]
 [80.053246]
 [80.10709 ]
 [80.05551 ]
 [79.70859 ]], R is [[79.63841248]
 [79.58852386]
 [79.53952026]
 [79.49175262]
 [79.44515991]].
[2019-03-24 02:18:39,936] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1103976: loss 0.0562
[2019-03-24 02:18:39,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1103976: learning rate 0.0001
[2019-03-24 02:18:40,599] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104229: loss 0.2260
[2019-03-24 02:18:40,602] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104230: learning rate 0.0001
[2019-03-24 02:18:40,890] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104375: loss 0.2131
[2019-03-24 02:18:40,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104376: learning rate 0.0001
[2019-03-24 02:18:40,992] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104424: loss 0.0786
[2019-03-24 02:18:40,993] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104424: learning rate 0.0001
[2019-03-24 02:18:41,002] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104426: loss 0.1161
[2019-03-24 02:18:41,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104426: learning rate 0.0001
[2019-03-24 02:18:41,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104459: loss 0.0028
[2019-03-24 02:18:41,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104461: learning rate 0.0001
[2019-03-24 02:18:41,075] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104463: loss 0.0495
[2019-03-24 02:18:41,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104463: learning rate 0.0001
[2019-03-24 02:18:41,096] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104471: loss 0.0211
[2019-03-24 02:18:41,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104471: learning rate 0.0001
[2019-03-24 02:18:41,126] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104486: loss 0.0454
[2019-03-24 02:18:41,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104487: learning rate 0.0001
[2019-03-24 02:18:41,157] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104501: loss 0.0235
[2019-03-24 02:18:41,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104501: learning rate 0.0001
[2019-03-24 02:18:41,269] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104558: loss 0.2132
[2019-03-24 02:18:41,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104559: learning rate 0.0001
[2019-03-24 02:18:41,358] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104605: loss 0.1299
[2019-03-24 02:18:41,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104605: learning rate 0.0001
[2019-03-24 02:18:41,437] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104641: loss 0.0208
[2019-03-24 02:18:41,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104642: learning rate 0.0001
[2019-03-24 02:18:41,781] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104808: loss 0.0595
[2019-03-24 02:18:41,783] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104809: learning rate 0.0001
[2019-03-24 02:18:43,294] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1105557: loss 53.4414
[2019-03-24 02:18:43,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1105558: learning rate 0.0001
[2019-03-24 02:18:46,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6116316e-09 9.8755091e-01 5.7341549e-09 3.8306387e-03 8.6184526e-03], sum to 1.0000
[2019-03-24 02:18:46,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3725
[2019-03-24 02:18:46,748] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 73.0, 1.0, 2.0, 0.7506458070916131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926070.9052026729, 926070.9052026729, 188842.2717063745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1758600.0000, 
sim time next is 1759200.0000, 
raw observation next is [23.16666666666666, 72.66666666666667, 1.0, 2.0, 0.7464334993573952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 919915.7682511035, 919915.768251103, 187962.6898719355], 
processed observation next is [1.0, 0.34782608695652173, 0.41358024691358003, 0.7266666666666667, 1.0, 1.0, 0.6981351182826133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32854134580396555, 0.3285413458039654, 0.36146671129218366], 
reward next is 0.6385, 
noisyNet noise sample is [array([-0.2564775], dtype=float32), -0.4461518]. 
=============================================
[2019-03-24 02:18:47,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4474262e-10 7.4348485e-01 5.8303517e-08 9.9015988e-02 1.5749905e-01], sum to 1.0000
[2019-03-24 02:18:47,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7037
[2019-03-24 02:18:47,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462132.244590076 W.
[2019-03-24 02:18:47,513] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 60.66666666666667, 1.0, 2.0, 0.4254507472432189, 1.0, 2.0, 0.4254507472432189, 1.0, 1.0, 0.6775201353690147, 6.911200000000001, 6.9112, 121.94756008, 1462132.244590076, 1462132.244590076, 308455.9157662893], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1783200.0000, 
sim time next is 1783800.0000, 
raw observation next is [27.5, 62.0, 1.0, 2.0, 0.635793842722294, 1.0, 2.0, 0.635793842722294, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1468376.47430104, 1468376.474301039, 281485.1243410521], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.62, 1.0, 1.0, 0.5664212413360643, 1.0, 1.0, 0.5664212413360643, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5244201693932286, 0.5244201693932282, 0.5413175468097156], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5613133], dtype=float32), 0.6223547]. 
=============================================
[2019-03-24 02:18:51,183] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8329469e-11 9.9864370e-01 1.4508229e-10 1.3484119e-03 7.8651419e-06], sum to 1.0000
[2019-03-24 02:18:51,191] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0752
[2019-03-24 02:18:51,196] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 82.0, 1.0, 2.0, 0.5983516778743974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 737041.9472002728, 737041.9472002723, 159952.7045874802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861200.0000, 
sim time next is 1861800.0000, 
raw observation next is [21.88333333333333, 82.33333333333334, 1.0, 2.0, 0.5633046309584263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693586.0208831154, 693586.0208831154, 153888.7456176037], 
processed observation next is [1.0, 0.5652173913043478, 0.36604938271604925, 0.8233333333333335, 1.0, 1.0, 0.4801245606647932, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2477092931725412, 0.2477092931725412, 0.29593989541846866], 
reward next is 0.7041, 
noisyNet noise sample is [array([1.03814], dtype=float32), 0.7556138]. 
=============================================
[2019-03-24 02:18:54,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3561218e-15 9.9989343e-01 7.4189109e-15 1.0652319e-04 1.2291978e-08], sum to 1.0000
[2019-03-24 02:18:54,623] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9262
[2019-03-24 02:18:54,630] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 92.0, 1.0, 2.0, 0.3656142412663756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457160.9042486206, 457160.9042486206, 123963.8114241449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1911000.0000, 
sim time next is 1911600.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.3722792995069982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465392.399655237, 465392.399655237, 124865.650532632], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.92, 1.0, 1.0, 0.2527134517940455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16621157130544179, 0.16621157130544179, 0.2401262510242923], 
reward next is 0.7599, 
noisyNet noise sample is [array([0.03157458], dtype=float32), 0.60795224]. 
=============================================
[2019-03-24 02:18:56,036] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1111897: loss 12.2263
[2019-03-24 02:18:56,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1111897: learning rate 0.0001
[2019-03-24 02:18:56,354] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112054: loss 2.3176
[2019-03-24 02:18:56,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112055: learning rate 0.0001
[2019-03-24 02:18:56,864] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112307: loss 7.8954
[2019-03-24 02:18:56,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112307: learning rate 0.0001
[2019-03-24 02:18:56,972] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112362: loss -22.3110
[2019-03-24 02:18:56,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112362: learning rate 0.0001
[2019-03-24 02:18:56,989] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112368: loss -25.1102
[2019-03-24 02:18:56,991] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112369: loss -10.6073
[2019-03-24 02:18:56,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112369: learning rate 0.0001
[2019-03-24 02:18:56,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112371: learning rate 0.0001
[2019-03-24 02:18:57,087] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112418: loss -17.2931
[2019-03-24 02:18:57,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112420: learning rate 0.0001
[2019-03-24 02:18:57,185] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112466: loss -39.8520
[2019-03-24 02:18:57,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112466: learning rate 0.0001
[2019-03-24 02:18:57,220] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112484: loss 6.5369
[2019-03-24 02:18:57,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112484: learning rate 0.0001
[2019-03-24 02:18:57,234] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112490: loss 25.3442
[2019-03-24 02:18:57,236] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112490: learning rate 0.0001
[2019-03-24 02:18:57,270] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112507: loss 44.0158
[2019-03-24 02:18:57,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112507: learning rate 0.0001
[2019-03-24 02:18:57,292] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112517: loss -48.1064
[2019-03-24 02:18:57,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112517: learning rate 0.0001
[2019-03-24 02:18:57,403] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112571: loss 33.8430
[2019-03-24 02:18:57,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112573: learning rate 0.0001
[2019-03-24 02:18:57,591] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112663: loss 42.6828
[2019-03-24 02:18:57,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112663: learning rate 0.0001
[2019-03-24 02:18:57,882] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112805: loss 41.3843
[2019-03-24 02:18:57,886] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112805: learning rate 0.0001
[2019-03-24 02:18:59,371] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1113552: loss 0.1757
[2019-03-24 02:18:59,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1113552: learning rate 0.0001
[2019-03-24 02:19:05,319] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7607919e-16 9.9999988e-01 9.0165102e-17 1.2033281e-07 3.4691461e-10], sum to 1.0000
[2019-03-24 02:19:05,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0230
[2019-03-24 02:19:05,329] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 90.33333333333333, 1.0, 2.0, 0.4515707080069766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547833.4032518009, 547833.4032518006, 135806.2651613702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2098200.0000, 
sim time next is 2098800.0000, 
raw observation next is [22.0, 90.0, 1.0, 2.0, 0.4554272849326774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 551679.174389162, 551679.1743891616, 136357.3280289862], 
processed observation next is [0.0, 0.30434782608695654, 0.37037037037037035, 0.9, 1.0, 1.0, 0.3516991487293779, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19702827656755786, 0.19702827656755773, 0.26222563082497347], 
reward next is 0.7378, 
noisyNet noise sample is [array([0.56992507], dtype=float32), -0.31362313]. 
=============================================
[2019-03-24 02:19:07,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6767631e-13 9.9999642e-01 2.4458293e-12 2.4850094e-06 1.0284487e-06], sum to 1.0000
[2019-03-24 02:19:07,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-24 02:19:07,547] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 89.0, 1.0, 2.0, 0.7623787226478497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 887235.4145293842, 887235.4145293842, 189204.8082051947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2168400.0000, 
sim time next is 2169000.0000, 
raw observation next is [24.2, 89.0, 1.0, 2.0, 0.6540617840472356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761833.754535147, 761833.754535147, 168418.9108535517], 
processed observation next is [1.0, 0.08695652173913043, 0.45185185185185184, 0.89, 1.0, 1.0, 0.5881687905324233, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2720834837625525, 0.2720834837625525, 0.3238825208722148], 
reward next is 0.6761, 
noisyNet noise sample is [array([-0.6340031], dtype=float32), -0.008967228]. 
=============================================
[2019-03-24 02:19:07,570] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.661484]
 [58.51181 ]
 [58.941643]
 [58.95847 ]
 [58.94377 ]], R is [[58.77821732]
 [58.82658005]
 [58.81669617]
 [58.93196487]
 [59.04587555]].
[2019-03-24 02:19:12,329] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1119937: loss 0.9491
[2019-03-24 02:19:12,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1119937: learning rate 0.0001
[2019-03-24 02:19:12,585] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120062: loss 0.3641
[2019-03-24 02:19:12,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120063: learning rate 0.0001
[2019-03-24 02:19:13,010] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120275: loss 0.1272
[2019-03-24 02:19:13,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120275: learning rate 0.0001
[2019-03-24 02:19:13,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3109042e-12 9.9999034e-01 1.6421487e-12 1.1875823e-06 8.4109979e-06], sum to 1.0000
[2019-03-24 02:19:13,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7572
[2019-03-24 02:19:13,072] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 98.0, 1.0, 2.0, 0.5543085610405415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649008.1765999633, 649008.1765999629, 151200.9548823911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2247000.0000, 
sim time next is 2247600.0000, 
raw observation next is [22.86666666666667, 98.0, 1.0, 2.0, 0.5556797360083232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650171.8538421027, 650171.8538421027, 151409.3525944071], 
processed observation next is [1.0, 0.0, 0.4024691358024693, 0.98, 1.0, 1.0, 0.47104730477181334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23220423351503666, 0.23220423351503666, 0.2911718319123213], 
reward next is 0.7088, 
noisyNet noise sample is [array([0.2096025], dtype=float32), 1.4199662]. 
=============================================
[2019-03-24 02:19:13,120] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120327: loss 0.2806
[2019-03-24 02:19:13,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120328: learning rate 0.0001
[2019-03-24 02:19:13,197] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120366: loss 0.2136
[2019-03-24 02:19:13,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120368: learning rate 0.0001
[2019-03-24 02:19:13,254] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120400: loss 0.1803
[2019-03-24 02:19:13,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120400: learning rate 0.0001
[2019-03-24 02:19:13,263] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120402: loss 0.1609
[2019-03-24 02:19:13,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120402: learning rate 0.0001
[2019-03-24 02:19:13,277] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120407: loss 0.1681
[2019-03-24 02:19:13,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120407: learning rate 0.0001
[2019-03-24 02:19:13,371] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120455: loss 0.2156
[2019-03-24 02:19:13,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120456: learning rate 0.0001
[2019-03-24 02:19:13,420] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120478: loss 0.1668
[2019-03-24 02:19:13,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120478: learning rate 0.0001
[2019-03-24 02:19:13,478] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120505: loss 0.1686
[2019-03-24 02:19:13,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120505: learning rate 0.0001
[2019-03-24 02:19:13,554] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120546: loss 0.1117
[2019-03-24 02:19:13,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120546: learning rate 0.0001
[2019-03-24 02:19:13,575] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120554: loss 0.0981
[2019-03-24 02:19:13,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120556: learning rate 0.0001
[2019-03-24 02:19:13,786] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120664: loss 0.2509
[2019-03-24 02:19:13,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120664: learning rate 0.0001
[2019-03-24 02:19:13,887] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120715: loss 0.2875
[2019-03-24 02:19:13,890] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120715: learning rate 0.0001
[2019-03-24 02:19:14,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1157668e-14 9.9999845e-01 2.2154051e-15 3.3977589e-08 1.5375866e-06], sum to 1.0000
[2019-03-24 02:19:14,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2102
[2019-03-24 02:19:14,319] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 52.33333333333334, 1.0, 2.0, 0.4188157309926226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520280.2137873103, 520280.2137873103, 131331.0552642928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2528400.0000, 
sim time next is 2529000.0000, 
raw observation next is [26.4, 51.5, 1.0, 2.0, 0.4223403011895947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524059.2419611163, 524059.2419611163, 131827.8745422124], 
processed observation next is [1.0, 0.2608695652173913, 0.5333333333333333, 0.515, 1.0, 1.0, 0.31230988236856516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18716401498611296, 0.18716401498611296, 0.2535151433504085], 
reward next is 0.7465, 
noisyNet noise sample is [array([-1.2249844], dtype=float32), -1.3385173]. 
=============================================
[2019-03-24 02:19:14,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.13476 ]
 [69.11001 ]
 [69.17642 ]
 [69.29147 ]
 [69.328156]], R is [[69.22986603]
 [69.28500366]
 [69.33505249]
 [69.3883667 ]
 [69.44197083]].
[2019-03-24 02:19:15,884] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1121686: loss -35.5998
[2019-03-24 02:19:15,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1121686: learning rate 0.0001
[2019-03-24 02:19:22,602] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 02:19:22,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:19:22,604] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:19:22,605] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:19:22,606] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:19:22,606] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:19:22,607] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:19:22,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:19:22,607] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:19:22,610] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:19:22,613] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:19:22,623] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-24 02:19:22,650] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-24 02:19:22,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-24 02:19:22,651] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-24 02:19:22,701] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-24 02:20:01,154] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:01,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.224989475, 104.92974464, 1.0, 2.0, 0.6575120247954085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 749354.0348301295, 749354.034830129, 168255.5301706982]
[2019-03-24 02:20:01,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:20:01,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0716005e-10 9.6320307e-01 5.1557937e-08 3.6073163e-02 7.2375208e-04], sampled 0.6413667106694085
[2019-03-24 02:20:05,539] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:05,540] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 79.0, 1.0, 2.0, 0.868122790301149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 989538.1010136049, 989538.1010136049, 210433.2077684517]
[2019-03-24 02:20:05,540] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:20:05,544] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0286509e-10 9.6646756e-01 3.0301308e-08 3.2948777e-02 5.8362621e-04], sampled 0.1366671787526138
[2019-03-24 02:20:10,565] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:10,566] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.09586531333333, 98.23215948166666, 1.0, 2.0, 0.4995727790119587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593337.7796111192, 593337.7796111192, 142733.8663135796]
[2019-03-24 02:20:10,566] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:20:10,568] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1812658e-10 9.6584499e-01 3.3654114e-08 3.3546571e-02 6.0848391e-04], sampled 0.5175883007699926
[2019-03-24 02:20:16,554] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:16,559] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.650709765, 102.0391703333333, 1.0, 2.0, 0.5813017345611012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679564.4575574918, 679564.4575574918, 155691.0829217333]
[2019-03-24 02:20:16,560] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:20:16,563] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3028353e-10 9.6539992e-01 3.6253155e-08 3.3972938e-02 6.2712561e-04], sampled 0.926533893278827
[2019-03-24 02:20:22,280] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:22,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 98.0, 1.0, 2.0, 0.7156782170151418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829289.8749294311, 829289.8749294311, 179808.8733696586]
[2019-03-24 02:20:22,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:20:22,286] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8918158e-10 9.6002090e-01 8.3210416e-08 3.9100792e-02 8.7819353e-04], sampled 0.43363534723045516
[2019-03-24 02:20:54,808] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7398718]
[2019-03-24 02:20:54,809] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 96.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394993.5331499761, 394993.5331499766, 149980.647191464]
[2019-03-24 02:20:54,810] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:20:54,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1020796e-10 9.6314901e-01 5.2128840e-08 3.6124513e-02 7.2645809e-04], sampled 0.9974273885330944
[2019-03-24 02:20:59,322] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8392.5776 2180676606.4802 471.0000
[2019-03-24 02:20:59,593] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7751.4161 2454160458.8466 717.0000
[2019-03-24 02:20:59,835] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8543.1276 2131286571.7992 415.0000
[2019-03-24 02:20:59,837] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8254.6544 2256396888.4459 535.0000
[2019-03-24 02:20:59,922] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8360.7520 2204397686.6728 552.0000
[2019-03-24 02:21:00,940] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1125000, evaluation results [1125000.0, 7751.416065848354, 2454160458.846626, 717.0, 8392.577614947259, 2180676606.480211, 471.0, 8543.127583954489, 2131286571.7992253, 415.0, 8254.65441433505, 2256396888.445906, 535.0, 8360.75198893212, 2204397686.672763, 552.0]
[2019-03-24 02:21:05,326] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.92404128e-11 9.94968474e-01 1.07152744e-07 4.74479375e-03
 2.86631926e-04], sum to 1.0000
[2019-03-24 02:21:05,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0351
[2019-03-24 02:21:05,339] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 48.5, 1.0, 2.0, 0.3791652975687472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 472729.8935025401, 472729.8935025397, 125783.8746809641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2505000.0000, 
sim time next is 2505600.0000, 
raw observation next is [26.5, 49.0, 1.0, 2.0, 0.3790672305382004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472574.7179946811, 472574.7179946811, 125769.7694342747], 
processed observation next is [1.0, 0.0, 0.5370370370370371, 0.49, 1.0, 1.0, 0.2607943220692862, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1687766849981004, 0.1687766849981004, 0.24186494121975904], 
reward next is 0.7581, 
noisyNet noise sample is [array([-0.20127486], dtype=float32), -0.20840219]. 
=============================================
[2019-03-24 02:21:07,149] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128057: loss -7.9858
[2019-03-24 02:21:07,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128057: learning rate 0.0001
[2019-03-24 02:21:07,399] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128182: loss -55.5660
[2019-03-24 02:21:07,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128182: learning rate 0.0001
[2019-03-24 02:21:07,558] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128263: loss -30.1114
[2019-03-24 02:21:07,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128263: learning rate 0.0001
[2019-03-24 02:21:07,704] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128336: loss -18.4577
[2019-03-24 02:21:07,708] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128336: learning rate 0.0001
[2019-03-24 02:21:07,789] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128372: loss -25.9435
[2019-03-24 02:21:07,790] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128372: learning rate 0.0001
[2019-03-24 02:21:07,813] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128386: loss -66.7840
[2019-03-24 02:21:07,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128387: learning rate 0.0001
[2019-03-24 02:21:07,828] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128394: loss -65.3210
[2019-03-24 02:21:07,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128394: learning rate 0.0001
[2019-03-24 02:21:07,859] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128412: loss -39.8983
[2019-03-24 02:21:07,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128412: learning rate 0.0001
[2019-03-24 02:21:07,916] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128433: loss -22.9689
[2019-03-24 02:21:07,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128433: learning rate 0.0001
[2019-03-24 02:21:07,948] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128447: loss -26.3965
[2019-03-24 02:21:07,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128449: learning rate 0.0001
[2019-03-24 02:21:08,048] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128499: loss -101.3968
[2019-03-24 02:21:08,051] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128499: learning rate 0.0001
[2019-03-24 02:21:08,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128508: loss -70.0130
[2019-03-24 02:21:08,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128509: learning rate 0.0001
[2019-03-24 02:21:08,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128525: loss -62.9192
[2019-03-24 02:21:08,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128525: learning rate 0.0001
[2019-03-24 02:21:08,344] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128647: loss -60.3155
[2019-03-24 02:21:08,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128647: learning rate 0.0001
[2019-03-24 02:21:08,358] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128649: loss -119.0004
[2019-03-24 02:21:08,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128650: learning rate 0.0001
[2019-03-24 02:21:10,542] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1129732: loss 0.1740
[2019-03-24 02:21:10,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1129732: learning rate 0.0001
[2019-03-24 02:21:10,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9934982e-15 9.9812108e-01 2.8053187e-11 1.8510694e-03 2.7873397e-05], sum to 1.0000
[2019-03-24 02:21:10,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5463
[2019-03-24 02:21:10,822] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 95.33333333333334, 1.0, 2.0, 0.4613519655701986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 560278.8899265549, 560278.8899265544, 137292.8598242629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [21.16666666666667, 94.16666666666666, 1.0, 2.0, 0.457409307275566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556452.3208468297, 556452.3208468297, 136727.7618162233], 
processed observation next is [0.0, 0.30434782608695654, 0.33950617283950635, 0.9416666666666665, 1.0, 1.0, 0.3540586991375786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1987329717310106, 0.1987329717310106, 0.2629380034927371], 
reward next is 0.7371, 
noisyNet noise sample is [array([-2.152565], dtype=float32), -0.5719339]. 
=============================================
[2019-03-24 02:21:17,237] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3509293e-15 9.9997866e-01 4.7082780e-14 2.1298205e-05 2.3820574e-09], sum to 1.0000
[2019-03-24 02:21:17,245] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-24 02:21:17,248] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.5524707414923744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 646913.2783311197, 646913.2783311193, 150899.117735362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2719200.0000, 
sim time next is 2719800.0000, 
raw observation next is [29.25, 56.5, 1.0, 2.0, 0.54992011293115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644544.5848432257, 644544.5848432252, 150504.2166778472], 
processed observation next is [0.0, 0.4782608695652174, 0.6388888888888888, 0.565, 1.0, 1.0, 0.46419061063232137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2301944945868663, 0.23019449458686614, 0.2894311859189369], 
reward next is 0.7106, 
noisyNet noise sample is [array([0.1776428], dtype=float32), 1.0985771]. 
=============================================
[2019-03-24 02:21:17,984] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9618855e-12 9.9997711e-01 1.0388028e-11 2.2709610e-05 1.4866606e-07], sum to 1.0000
[2019-03-24 02:21:17,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6458
[2019-03-24 02:21:18,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2370690.251335967 W.
[2019-03-24 02:21:18,006] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 73.5, 1.0, 2.0, 0.7586634906391793, 1.0, 2.0, 0.6926964072960242, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2370690.251335967, 2370690.251335967, 445375.9485453445], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2986200.0000, 
sim time next is 2986800.0000, 
raw observation next is [29.8, 71.66666666666666, 1.0, 2.0, 0.9763051855342689, 1.0, 2.0, 0.9763051855342689, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2227365.557677329, 2227365.55767733, 421992.9928685519], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.7166666666666666, 1.0, 1.0, 0.9717918875407964, 1.0, 1.0, 0.9717918875407964, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7954876991704747, 0.795487699170475, 0.8115249862856768], 
reward next is 0.1885, 
noisyNet noise sample is [array([-2.2393265], dtype=float32), -0.44632033]. 
=============================================
[2019-03-24 02:21:18,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1700388e-10 9.9978489e-01 3.2052412e-12 2.1056485e-04 4.5107577e-06], sum to 1.0000
[2019-03-24 02:21:18,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7608
[2019-03-24 02:21:18,937] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 94.0, 1.0, 2.0, 0.6410600937339325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733669.0350922153, 733669.0350922153, 165438.1497868057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [24.16666666666666, 94.0, 1.0, 2.0, 0.6289381756983491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722478.1603080739, 722478.1603080739, 163408.6516677465], 
processed observation next is [1.0, 0.0, 0.45061728395061706, 0.94, 1.0, 1.0, 0.558259732974225, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2580279143957407, 0.2580279143957407, 0.3142474070533587], 
reward next is 0.6858, 
noisyNet noise sample is [array([0.9566635], dtype=float32), -0.90460235]. 
=============================================
[2019-03-24 02:21:21,783] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2037985e-09 9.9999154e-01 2.1799147e-09 7.9867241e-06 5.1235747e-07], sum to 1.0000
[2019-03-24 02:21:21,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2974
[2019-03-24 02:21:21,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1800607.141121805 W.
[2019-03-24 02:21:21,800] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.91666666666666, 63.0, 1.0, 2.0, 0.7894356217621156, 1.0, 2.0, 0.7894356217621156, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426094709, 1800607.141121805, 1800607.141121805, 339408.8757302563], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2805000.0000, 
sim time next is 2805600.0000, 
raw observation next is [31.13333333333333, 63.00000000000001, 1.0, 2.0, 0.919896327507321, 1.0, 2.0, 0.919896327507321, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156599, 2098521.830753224, 2098521.830753224, 395788.7716392649], 
processed observation next is [1.0, 0.4782608695652174, 0.7086419753086418, 0.6300000000000001, 1.0, 1.0, 0.904638485127763, 1.0, 1.0, 0.904638485127763, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201233, 0.7494720824118657, 0.7494720824118657, 0.7611322531524325], 
reward next is 0.2389, 
noisyNet noise sample is [array([0.02036222], dtype=float32), 0.7599323]. 
=============================================
[2019-03-24 02:21:23,048] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1135952: loss 0.0108
[2019-03-24 02:21:23,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1135952: learning rate 0.0001
[2019-03-24 02:21:23,496] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136175: loss 0.0039
[2019-03-24 02:21:23,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136176: learning rate 0.0001
[2019-03-24 02:21:23,643] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136248: loss 0.1545
[2019-03-24 02:21:23,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136248: learning rate 0.0001
[2019-03-24 02:21:23,725] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136285: loss 0.3787
[2019-03-24 02:21:23,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136287: learning rate 0.0001
[2019-03-24 02:21:23,777] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136316: loss 0.6361
[2019-03-24 02:21:23,779] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136316: learning rate 0.0001
[2019-03-24 02:21:23,792] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136325: loss 0.3469
[2019-03-24 02:21:23,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136327: learning rate 0.0001
[2019-03-24 02:21:23,882] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136363: loss 0.5010
[2019-03-24 02:21:23,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136364: learning rate 0.0001
[2019-03-24 02:21:23,926] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136387: loss 0.3662
[2019-03-24 02:21:23,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136389: learning rate 0.0001
[2019-03-24 02:21:23,935] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136393: loss 0.3081
[2019-03-24 02:21:23,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136393: learning rate 0.0001
[2019-03-24 02:21:23,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136418: loss 0.1536
[2019-03-24 02:21:23,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136418: learning rate 0.0001
[2019-03-24 02:21:23,997] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136419: loss 0.1947
[2019-03-24 02:21:23,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136419: learning rate 0.0001
[2019-03-24 02:21:24,040] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136437: loss 0.0933
[2019-03-24 02:21:24,047] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136438: learning rate 0.0001
[2019-03-24 02:21:24,244] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136536: loss 0.1506
[2019-03-24 02:21:24,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136537: learning rate 0.0001
[2019-03-24 02:21:24,662] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136755: loss 0.1872
[2019-03-24 02:21:24,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136756: learning rate 0.0001
[2019-03-24 02:21:24,692] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136763: loss 0.0779
[2019-03-24 02:21:24,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136763: learning rate 0.0001
[2019-03-24 02:21:25,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4782038e-18 1.0000000e+00 5.0846259e-21 1.9430919e-14 6.5796283e-18], sum to 1.0000
[2019-03-24 02:21:25,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6328
[2019-03-24 02:21:25,112] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.8150437547452789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 964900.7504894309, 964900.7504894309, 200820.551809004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863800.0000, 
sim time next is 2864400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.7052093528442885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834916.6055221698, 834916.6055221694, 178590.6699612033], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.6490587533860578, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29818450197220353, 0.29818450197220336, 0.34344359607923713], 
reward next is 0.6566, 
noisyNet noise sample is [array([-0.94957113], dtype=float32), 1.1195107]. 
=============================================
[2019-03-24 02:21:27,221] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1138014: loss 86.5355
[2019-03-24 02:21:27,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1138016: learning rate 0.0001
[2019-03-24 02:21:31,555] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0090121e-12 9.9994862e-01 8.5842181e-11 5.1367017e-05 5.3203809e-08], sum to 1.0000
[2019-03-24 02:21:31,559] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0483
[2019-03-24 02:21:31,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1824813.194767863 W.
[2019-03-24 02:21:31,573] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.58333333333333, 86.5, 1.0, 2.0, 0.5333583566338805, 1.0, 1.0, 0.5333583566338805, 1.0, 2.0, 0.8491238740301317, 6.9112, 6.9112, 121.94756008, 1824813.194767863, 1824813.194767863, 360263.2831624979], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2998200.0000, 
sim time next is 2998800.0000, 
raw observation next is [26.7, 86.0, 1.0, 2.0, 1.002091861534802, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1857631.264723184, 1857631.264723185, 379920.3145692454], 
processed observation next is [1.0, 0.7391304347826086, 0.5444444444444444, 0.86, 1.0, 1.0, 1.0024903113509547, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6634397374011372, 0.6634397374011375, 0.7306159895562411], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5054958], dtype=float32), -1.033016]. 
=============================================
[2019-03-24 02:21:34,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8131370e-16 9.9999893e-01 4.8889166e-14 1.0398094e-06 4.9382598e-10], sum to 1.0000
[2019-03-24 02:21:34,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0109
[2019-03-24 02:21:34,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 93.0, 1.0, 2.0, 0.521608904554189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621764.1691819209, 621764.1691819209, 146317.3848632402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3288600.0000, 
sim time next is 3289200.0000, 
raw observation next is [22.26666666666667, 92.66666666666666, 1.0, 2.0, 0.5109196523147407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611514.9687537698, 611514.9687537698, 144698.8087238302], 
processed observation next is [0.0, 0.043478260869565216, 0.38024691358024704, 0.9266666666666665, 1.0, 1.0, 0.41776149085088177, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21839820312634634, 0.21839820312634634, 0.27826693985351963], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.12515132], dtype=float32), 0.4119575]. 
=============================================
[2019-03-24 02:21:37,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9129446e-14 9.9999964e-01 1.8705506e-13 3.5401655e-07 1.4844993e-09], sum to 1.0000
[2019-03-24 02:21:37,864] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8951
[2019-03-24 02:21:37,869] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5058524108876513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602698.475924039, 602698.475924039, 143793.9451421387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3114000.0000, 
sim time next is 3114600.0000, 
raw observation next is [28.06666666666667, 55.83333333333334, 1.0, 2.0, 0.4961729811979046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593677.2994905453, 593677.2994905453, 142363.407114281], 
processed observation next is [1.0, 0.043478260869565216, 0.5950617283950619, 0.5583333333333335, 1.0, 1.0, 0.40020592999750554, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21202760696090903, 0.21202760696090903, 0.2737757829120788], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.5001537], dtype=float32), -0.44783795]. 
=============================================
[2019-03-24 02:21:39,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144002: loss -69.2210
[2019-03-24 02:21:39,363] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144002: learning rate 0.0001
[2019-03-24 02:21:39,878] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144259: loss -58.0784
[2019-03-24 02:21:39,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144260: learning rate 0.0001
[2019-03-24 02:21:39,942] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144294: loss -36.9062
[2019-03-24 02:21:39,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144294: learning rate 0.0001
[2019-03-24 02:21:39,964] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144305: loss -24.3868
[2019-03-24 02:21:39,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144305: learning rate 0.0001
[2019-03-24 02:21:39,978] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144308: loss 36.5990
[2019-03-24 02:21:39,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144308: learning rate 0.0001
[2019-03-24 02:21:40,014] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144326: loss 26.3077
[2019-03-24 02:21:40,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144326: learning rate 0.0001
[2019-03-24 02:21:40,090] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144365: loss 65.2629
[2019-03-24 02:21:40,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144365: learning rate 0.0001
[2019-03-24 02:21:40,108] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144376: loss 49.3643
[2019-03-24 02:21:40,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144376: learning rate 0.0001
[2019-03-24 02:21:40,152] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144392: loss -3.6616
[2019-03-24 02:21:40,153] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144392: learning rate 0.0001
[2019-03-24 02:21:40,199] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144413: loss -76.6952
[2019-03-24 02:21:40,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144413: learning rate 0.0001
[2019-03-24 02:21:40,289] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144459: loss -28.6294
[2019-03-24 02:21:40,291] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144459: learning rate 0.0001
[2019-03-24 02:21:40,348] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144483: loss -6.3271
[2019-03-24 02:21:40,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144483: learning rate 0.0001
[2019-03-24 02:21:40,440] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144531: loss 35.9009
[2019-03-24 02:21:40,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144532: learning rate 0.0001
[2019-03-24 02:21:40,829] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144721: loss 28.0312
[2019-03-24 02:21:40,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144721: learning rate 0.0001
[2019-03-24 02:21:41,002] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144804: loss -41.7773
[2019-03-24 02:21:41,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144804: learning rate 0.0001
[2019-03-24 02:21:41,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1578271e-12 1.0000000e+00 3.0669576e-14 3.4395736e-08 3.9307110e-11], sum to 1.0000
[2019-03-24 02:21:41,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4583
[2019-03-24 02:21:41,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.83333333333334, 33.0, 1.0, 2.0, 0.4738083036990047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 568670.7461727466, 568670.7461727471, 138967.7948562199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3175800.0000, 
sim time next is 3176400.0000, 
raw observation next is [33.66666666666667, 34.0, 1.0, 2.0, 0.4773714787500349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571747.0970667274, 571747.0970667274, 139471.1402412343], 
processed observation next is [1.0, 0.782608695652174, 0.8024691358024693, 0.34, 1.0, 1.0, 0.3778231889881368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2041953918095455, 0.2041953918095455, 0.2682137312331429], 
reward next is 0.7318, 
noisyNet noise sample is [array([1.6414529], dtype=float32), -2.4062269]. 
=============================================
[2019-03-24 02:21:42,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3839567e-24 1.0000000e+00 1.5921246e-29 2.6862275e-12 1.6700601e-22], sum to 1.0000
[2019-03-24 02:21:42,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9158
[2019-03-24 02:21:42,533] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 74.83333333333334, 1.0, 2.0, 0.5796350760077945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675639.7203346051, 675639.7203346051, 155320.5163890673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3196200.0000, 
sim time next is 3196800.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5633336866446553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 660411.1262160483, 660411.1262160479, 152738.4712860762], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.74, 1.0, 1.0, 0.4801591507674468, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23586111650573152, 0.23586111650573138, 0.2937278293963004], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.48989886], dtype=float32), -0.17049734]. 
=============================================
[2019-03-24 02:21:43,119] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1145854: loss 1.1184
[2019-03-24 02:21:43,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1145854: learning rate 0.0001
[2019-03-24 02:21:49,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9097748e-23 1.0000000e+00 3.3806153e-26 1.2093263e-15 1.3143264e-20], sum to 1.0000
[2019-03-24 02:21:49,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-24 02:21:49,018] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 74.66666666666667, 1.0, 2.0, 0.7026989524696257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 800879.6268972837, 800879.6268972832, 176656.8618590602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.7116793828858077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 811120.213328846, 811120.2133288456, 178368.9789102207], 
processed observation next is [0.0, 0.6521739130434783, 0.6296296296296297, 0.74, 1.0, 1.0, 0.656761170102152, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28968579047458787, 0.2896857904745877, 0.3430172671350398], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.6377299], dtype=float32), -0.09934587]. 
=============================================
[2019-03-24 02:21:51,544] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 02:21:51,546] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:21:51,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:21:51,547] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:21:51,548] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:21:51,549] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:21:51,549] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:21:51,547] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:21:51,550] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:21:51,552] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:21:51,553] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:21:51,568] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-24 02:21:51,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-24 02:21:51,599] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-24 02:21:51,599] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-24 02:21:51,600] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-24 02:22:07,595] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7491938]
[2019-03-24 02:22:07,595] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.33333333333334, 30.83333333333334, 1.0, 2.0, 0.4246982921593899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 528755.6411342905, 528755.64113429, 132207.1973453611]
[2019-03-24 02:22:07,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:22:07,599] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3161329e-19 1.0000000e+00 1.2185611e-21 2.0426088e-11 2.1502373e-17], sampled 0.10634697122504766
[2019-03-24 02:22:22,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7491938]
[2019-03-24 02:22:22,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.83216399666667, 85.20638591, 1.0, 2.0, 0.8115814225262082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925049.980564634, 925049.980564634, 198360.0280598919]
[2019-03-24 02:22:22,698] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:22:22,700] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0860136e-19 1.0000000e+00 5.1881930e-22 1.3237746e-11 1.0913304e-17], sampled 0.8256594078627962
[2019-03-24 02:22:41,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7491938]
[2019-03-24 02:22:41,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.96516692, 43.62193282, 1.0, 2.0, 0.8009387356784534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 979159.8904385932, 979159.8904385932, 199011.8915235069]
[2019-03-24 02:22:41,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:22:41,730] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4023357e-17 1.0000000e+00 1.0630361e-18 6.3662342e-10 4.6508423e-15], sampled 0.0628203197363042
[2019-03-24 02:22:55,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7491938]
[2019-03-24 02:22:55,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.9, 54.0, 1.0, 2.0, 0.9298042199367557, 1.0, 2.0, 0.9298042199367557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2121151.14653552, 2121151.14653552, 400312.9427354092]
[2019-03-24 02:22:55,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:22:55,822] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4322309e-16 1.0000000e+00 1.7085205e-18 8.0984874e-10 6.7787428e-15], sampled 0.7746303701033574
[2019-03-24 02:22:55,825] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2121151.14653552 W.
[2019-03-24 02:23:28,676] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:23:29,006] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 02:23:29,014] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:23:29,078] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:23:29,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:23:30,110] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1150000, evaluation results [1150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:23:33,892] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1151859: loss 2.9156
[2019-03-24 02:23:33,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1151859: learning rate 0.0001
[2019-03-24 02:23:34,438] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152125: loss 0.4193
[2019-03-24 02:23:34,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152126: learning rate 0.0001
[2019-03-24 02:23:34,722] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152266: loss 0.7819
[2019-03-24 02:23:34,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152268: learning rate 0.0001
[2019-03-24 02:23:34,738] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152274: loss 1.1168
[2019-03-24 02:23:34,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152274: learning rate 0.0001
[2019-03-24 02:23:34,749] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152279: loss 1.1232
[2019-03-24 02:23:34,750] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152279: learning rate 0.0001
[2019-03-24 02:23:34,786] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152294: loss 1.3597
[2019-03-24 02:23:34,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152295: learning rate 0.0001
[2019-03-24 02:23:34,888] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1152350: loss 1.1621
[2019-03-24 02:23:34,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1152351: learning rate 0.0001
[2019-03-24 02:23:34,930] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152370: loss 1.3368
[2019-03-24 02:23:34,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152370: learning rate 0.0001
[2019-03-24 02:23:34,976] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152382: loss 2.2922
[2019-03-24 02:23:34,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152383: learning rate 0.0001
[2019-03-24 02:23:35,105] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152450: loss 0.9095
[2019-03-24 02:23:35,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152451: learning rate 0.0001
[2019-03-24 02:23:35,137] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152463: loss 1.1352
[2019-03-24 02:23:35,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152464: learning rate 0.0001
[2019-03-24 02:23:35,209] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152504: loss 0.7258
[2019-03-24 02:23:35,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152504: learning rate 0.0001
[2019-03-24 02:23:35,242] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152520: loss 1.0053
[2019-03-24 02:23:35,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152522: learning rate 0.0001
[2019-03-24 02:23:35,816] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152793: loss 1.2060
[2019-03-24 02:23:35,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152794: learning rate 0.0001
[2019-03-24 02:23:35,952] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152861: loss 1.0994
[2019-03-24 02:23:35,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152861: learning rate 0.0001
[2019-03-24 02:23:38,086] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1153916: loss 0.0590
[2019-03-24 02:23:38,089] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1153917: learning rate 0.0001
[2019-03-24 02:23:38,565] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8001744e-15 9.9759787e-01 2.7545056e-17 2.4020770e-03 1.9305091e-11], sum to 1.0000
[2019-03-24 02:23:38,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4146
[2019-03-24 02:23:38,584] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 82.33333333333334, 1.0, 2.0, 0.5975563031231651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690486.6893729181, 690486.6893729176, 158116.708223777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [25.08333333333333, 83.16666666666666, 1.0, 2.0, 0.5835881223258392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677994.3369030578, 677994.3369030578, 155892.5362945039], 
processed observation next is [1.0, 0.8260869565217391, 0.4845679012345677, 0.8316666666666666, 1.0, 1.0, 0.5042715741974276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2421408346082349, 0.2421408346082349, 0.2997933390278921], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.6947846], dtype=float32), -0.27000785]. 
=============================================
[2019-03-24 02:23:39,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9528499e-16 9.9831557e-01 6.5823949e-17 1.6844422e-03 3.9949402e-12], sum to 1.0000
[2019-03-24 02:23:39,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5702
[2019-03-24 02:23:39,067] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 79.0, 1.0, 2.0, 0.5804207540177303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673755.4397561047, 673755.4397561047, 155329.1859642632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3529800.0000, 
sim time next is 3530400.0000, 
raw observation next is [26.23333333333333, 77.33333333333333, 1.0, 2.0, 0.5871021634567262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679718.8854588561, 679718.8854588561, 156385.0360809136], 
processed observation next is [1.0, 0.8695652173913043, 0.5271604938271603, 0.7733333333333333, 1.0, 1.0, 0.5084549564961026, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24275674480673434, 0.24275674480673434, 0.3007404540017569], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.6950005], dtype=float32), -1.4554988]. 
=============================================
[2019-03-24 02:23:40,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.25379543e-15 9.98800278e-01 1.02688495e-20 1.19974441e-03
 1.34531058e-14], sum to 1.0000
[2019-03-24 02:23:40,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7150
[2019-03-24 02:23:40,674] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4587310381878363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558442.2371080577, 558442.2371080577, 136938.0111734343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559800.0000, 
sim time next is 3560400.0000, 
raw observation next is [23.2, 76.0, 1.0, 2.0, 0.4516783102535216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552176.2378203205, 552176.2378203205, 135946.6862769811], 
processed observation next is [1.0, 0.21739130434782608, 0.4148148148148148, 0.76, 1.0, 1.0, 0.34723608363514485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19720579922154305, 0.19720579922154305, 0.2614359351480406], 
reward next is 0.7386, 
noisyNet noise sample is [array([-0.7424919], dtype=float32), 1.3239092]. 
=============================================
[2019-03-24 02:23:41,504] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6237155e-12 9.9792874e-01 7.5130171e-16 2.0712772e-03 6.6788942e-11], sum to 1.0000
[2019-03-24 02:23:41,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9053
[2019-03-24 02:23:41,512] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 84.66666666666667, 1.0, 2.0, 0.5123284281197534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615583.6811216474, 615583.6811216474, 145007.3634543359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3558000.0000, 
sim time next is 3558600.0000, 
raw observation next is [23.1, 82.5, 1.0, 2.0, 0.4951853033610343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597636.1841620754, 597636.1841620754, 142386.3215946755], 
processed observation next is [1.0, 0.17391304347826086, 0.41111111111111115, 0.825, 1.0, 1.0, 0.3990301230488503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21344149434359835, 0.21344149434359835, 0.2738198492205298], 
reward next is 0.7262, 
noisyNet noise sample is [array([0.7674121], dtype=float32), -1.2874076]. 
=============================================
[2019-03-24 02:23:46,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2344990e-12 3.6269876e-01 3.2733768e-13 6.3729906e-01 2.2392248e-06], sum to 1.0000
[2019-03-24 02:23:46,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7024
[2019-03-24 02:23:46,306] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.85, 94.33333333333334, 1.0, 2.0, 0.72122255099944, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822002.6521444863, 822002.6521444863, 180201.9697870589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3909000.0000, 
sim time next is 3909600.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.3635933157329284, 1.0, 1.0, 0.3635933157329284, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 828803.7991768749, 828803.7991768754, 196422.5879269481], 
processed observation next is [0.0, 0.2608695652173913, 0.5185185185185185, 0.94, 1.0, 1.0, 0.24237299492015288, 1.0, 0.5, 0.24237299492015288, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2960013568488839, 0.29600135684888407, 0.37773574601336174], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07010094], dtype=float32), 0.84748]. 
=============================================
[2019-03-24 02:23:49,072] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0011664e-15 1.8020717e-03 3.9371190e-16 9.9819797e-01 1.4850751e-10], sum to 1.0000
[2019-03-24 02:23:49,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5508
[2019-03-24 02:23:49,084] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3326852001019743, 1.0, 2.0, 0.3326852001019743, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758314.5069002811, 758314.5069002811, 188489.4806948973], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3321322185343663, 1.0, 2.0, 0.3321322185343663, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757053.4318002438, 757053.4318002443, 188350.5802818485], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20491930777900752, 1.0, 1.0, 0.20491930777900752, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2703762256429442, 0.2703762256429444, 0.3622126543881702], 
reward next is 0.6378, 
noisyNet noise sample is [array([-0.6408713], dtype=float32), -1.4776543]. 
=============================================
[2019-03-24 02:23:50,147] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1159916: loss 0.3050
[2019-03-24 02:23:50,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1159916: learning rate 0.0001
[2019-03-24 02:23:50,748] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160206: loss 0.6192
[2019-03-24 02:23:50,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160206: learning rate 0.0001
[2019-03-24 02:23:50,858] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160258: loss 0.5668
[2019-03-24 02:23:50,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160258: learning rate 0.0001
[2019-03-24 02:23:50,943] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160302: loss 0.6132
[2019-03-24 02:23:50,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160302: learning rate 0.0001
[2019-03-24 02:23:50,948] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160303: loss 0.6079
[2019-03-24 02:23:50,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160303: learning rate 0.0001
[2019-03-24 02:23:51,060] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160353: loss 0.7569
[2019-03-24 02:23:51,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160354: learning rate 0.0001
[2019-03-24 02:23:51,069] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160359: loss 0.6245
[2019-03-24 02:23:51,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160360: learning rate 0.0001
[2019-03-24 02:23:51,088] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160365: loss 0.6400
[2019-03-24 02:23:51,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160367: learning rate 0.0001
[2019-03-24 02:23:51,122] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160389: loss 0.4883
[2019-03-24 02:23:51,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160390: learning rate 0.0001
[2019-03-24 02:23:51,135] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160395: loss 0.4150
[2019-03-24 02:23:51,137] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160395: learning rate 0.0001
[2019-03-24 02:23:51,189] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160422: loss 0.4093
[2019-03-24 02:23:51,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160422: learning rate 0.0001
[2019-03-24 02:23:51,320] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160484: loss 0.3341
[2019-03-24 02:23:51,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160484: learning rate 0.0001
[2019-03-24 02:23:51,526] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160584: loss 0.0897
[2019-03-24 02:23:51,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160584: learning rate 0.0001
[2019-03-24 02:23:51,836] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160741: loss -4.7729
[2019-03-24 02:23:51,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160741: learning rate 0.0001
[2019-03-24 02:23:52,127] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160883: loss 0.0285
[2019-03-24 02:23:52,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160884: learning rate 0.0001
[2019-03-24 02:23:54,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6859309e-13 1.7054253e-03 8.7598445e-15 9.9828172e-01 1.2903584e-05], sum to 1.0000
[2019-03-24 02:23:54,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-24 02:23:54,042] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.46666666666667, 72.66666666666667, 1.0, 2.0, 0.2874961000715685, 1.0, 2.0, 0.2874961000715685, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663772.2166963525, 663772.2166963529, 177907.3174730554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3810000.0000, 
sim time next is 3810600.0000, 
raw observation next is [26.35, 73.0, 1.0, 2.0, 0.2853976892918433, 1.0, 2.0, 0.2853976892918433, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 659774.0340548811, 659774.0340548815, 177451.7120572475], 
processed observation next is [0.0, 0.08695652173913043, 0.5314814814814816, 0.73, 1.0, 1.0, 0.14928296344267059, 1.0, 1.0, 0.14928296344267059, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23563358359102896, 0.23563358359102912, 0.3412532924177836], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.10938976], dtype=float32), 0.4143937]. 
=============================================
[2019-03-24 02:23:54,155] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1161870: loss 0.0257
[2019-03-24 02:23:54,158] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1161870: learning rate 0.0001
[2019-03-24 02:24:00,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9565369e-13 1.4116320e-04 1.8647081e-14 9.9985886e-01 3.1884294e-08], sum to 1.0000
[2019-03-24 02:24:00,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-24 02:24:00,020] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.25, 87.33333333333333, 1.0, 2.0, 0.3657661587035976, 1.0, 2.0, 0.3657661587035976, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 833759.4458841893, 833759.4458841898, 196992.9478929845], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3917400.0000, 
sim time next is 3918000.0000, 
raw observation next is [27.2, 87.66666666666667, 1.0, 2.0, 0.3630357615432661, 1.0, 2.0, 0.3630357615432661, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827532.1792775752, 827532.1792775752, 196276.8410250088], 
processed observation next is [0.0, 0.34782608695652173, 0.5629629629629629, 0.8766666666666667, 1.0, 1.0, 0.24170923993245966, 1.0, 1.0, 0.24170923993245966, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2955472068848483, 0.2955472068848483, 0.37745546350963227], 
reward next is 0.6225, 
noisyNet noise sample is [array([-0.9170667], dtype=float32), 0.61842823]. 
=============================================
[2019-03-24 02:24:00,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.24793 ]
 [66.22407 ]
 [66.237404]
 [66.276665]
 [66.34348 ]], R is [[66.22923279]
 [66.18811035]
 [66.14182281]
 [66.09618378]
 [66.05258942]].
[2019-03-24 02:24:02,487] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0041423e-15 2.5262598e-06 3.3081118e-16 9.9999750e-01 4.5287205e-09], sum to 1.0000
[2019-03-24 02:24:02,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4173
[2019-03-24 02:24:02,502] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.3806579488076302, 1.0, 2.0, 0.3806579488076302, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 867724.3137536534, 867724.3137536539, 200944.1752144561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3966000.0000, 
sim time next is 3966600.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.3813964366196826, 1.0, 2.0, 0.3813964366196826, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 869408.679712227, 869408.6797122274, 201142.0707161202], 
processed observation next is [0.0, 0.9130434782608695, 0.5617283950617282, 0.8816666666666667, 1.0, 1.0, 0.2635671864520031, 1.0, 1.0, 0.2635671864520031, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3105030998972239, 0.3105030998972241, 0.38681167445407727], 
reward next is 0.6132, 
noisyNet noise sample is [array([1.671126], dtype=float32), -1.1172297]. 
=============================================
[2019-03-24 02:24:06,072] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2789307e-12 1.0270517e-05 6.6962202e-15 9.9998915e-01 5.4650161e-07], sum to 1.0000
[2019-03-24 02:24:06,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9284
[2019-03-24 02:24:06,084] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.775762452599904, 1.0, 2.0, 0.775762452599904, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1769389.408125893, 1769389.408125894, 333840.9210522475], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030200.0000, 
sim time next is 4030800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.7670631271679097, 1.0, 2.0, 0.7670631271679097, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1749528.214953174, 1749528.214953173, 330332.443118698], 
processed observation next is [1.0, 0.6521739130434783, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.7226941990094163, 1.0, 1.0, 0.7226941990094163, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6248315053404193, 0.6248315053404189, 0.6352546983051885], 
reward next is 0.3647, 
noisyNet noise sample is [array([-0.29783767], dtype=float32), -1.4557844]. 
=============================================
[2019-03-24 02:24:06,389] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1167943: loss 0.0746
[2019-03-24 02:24:06,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1167943: learning rate 0.0001
[2019-03-24 02:24:06,757] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168127: loss 0.0122
[2019-03-24 02:24:06,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168127: learning rate 0.0001
[2019-03-24 02:24:06,959] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168226: loss 0.0595
[2019-03-24 02:24:06,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168226: learning rate 0.0001
[2019-03-24 02:24:07,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168293: loss 0.0646
[2019-03-24 02:24:07,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168293: learning rate 0.0001
[2019-03-24 02:24:07,094] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168295: loss 0.1427
[2019-03-24 02:24:07,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168295: learning rate 0.0001
[2019-03-24 02:24:07,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168304: loss 0.1283
[2019-03-24 02:24:07,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168304: learning rate 0.0001
[2019-03-24 02:24:07,217] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168356: loss 0.1490
[2019-03-24 02:24:07,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168357: learning rate 0.0001
[2019-03-24 02:24:07,271] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168379: loss 0.1006
[2019-03-24 02:24:07,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168380: learning rate 0.0001
[2019-03-24 02:24:07,281] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168383: loss 0.0886
[2019-03-24 02:24:07,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168383: learning rate 0.0001
[2019-03-24 02:24:07,414] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168452: loss 0.0482
[2019-03-24 02:24:07,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168453: learning rate 0.0001
[2019-03-24 02:24:07,428] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168458: loss 0.0638
[2019-03-24 02:24:07,431] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168459: learning rate 0.0001
[2019-03-24 02:24:07,546] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168516: loss 0.0134
[2019-03-24 02:24:07,554] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168516: learning rate 0.0001
[2019-03-24 02:24:07,846] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168657: loss 0.0941
[2019-03-24 02:24:07,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168659: learning rate 0.0001
[2019-03-24 02:24:07,989] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168726: loss 0.0504
[2019-03-24 02:24:07,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168728: learning rate 0.0001
[2019-03-24 02:24:08,200] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168831: loss 0.0438
[2019-03-24 02:24:08,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168831: learning rate 0.0001
[2019-03-24 02:24:10,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6317639e-14 2.5333695e-06 2.2209026e-15 9.9999738e-01 1.6566246e-07], sum to 1.0000
[2019-03-24 02:24:10,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9048
[2019-03-24 02:24:10,046] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.8745474417005952, 1.0, 2.0, 0.8745474417005952, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1994953.715590352, 1994953.715590353, 375521.4403274791], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4118400.0000, 
sim time next is 4119000.0000, 
raw observation next is [29.03333333333333, 69.33333333333334, 1.0, 2.0, 0.9464131714187496, 1.0, 2.0, 0.9464131714187496, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2159086.757725154, 2159086.757725154, 407968.7275518339], 
processed observation next is [1.0, 0.6956521739130435, 0.6308641975308641, 0.6933333333333335, 1.0, 1.0, 0.9362061564508923, 1.0, 1.0, 0.9362061564508923, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7711024134732694, 0.7711024134732694, 0.7845552452919883], 
reward next is 0.2154, 
noisyNet noise sample is [array([1.0131893], dtype=float32), -0.34023044]. 
=============================================
[2019-03-24 02:24:10,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.38271 ]
 [57.309124]
 [57.238407]
 [57.11292 ]
 [56.879597]], R is [[56.68846893]
 [56.39942932]
 [56.1056633 ]
 [55.81500244]
 [55.52799988]].
[2019-03-24 02:24:10,243] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1169847: loss 0.4193
[2019-03-24 02:24:10,249] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1169850: learning rate 0.0001
[2019-03-24 02:24:10,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9939952e-10 1.6327546e-04 8.4101503e-13 9.9982256e-01 1.4213696e-05], sum to 1.0000
[2019-03-24 02:24:10,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6421
[2019-03-24 02:24:10,390] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.9609000970578918, 1.0, 2.0, 0.9609000970578918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2192176.880118255, 2192176.880118255, 414726.9549580511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4114800.0000, 
sim time next is 4115400.0000, 
raw observation next is [29.0, 73.33333333333334, 1.0, 2.0, 0.8777474496087739, 1.0, 2.0, 0.8777474496087739, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2002261.52304141, 2002261.52304141, 376928.6652184406], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7333333333333334, 1.0, 1.0, 0.8544612495342547, 1.0, 1.0, 0.8544612495342547, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7150934010862178, 0.7150934010862178, 0.7248628177277704], 
reward next is 0.2751, 
noisyNet noise sample is [array([-0.39736858], dtype=float32), -2.4194028]. 
=============================================
[2019-03-24 02:24:11,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5515226e-17 5.7469510e-06 7.8715864e-18 9.9999428e-01 6.9094965e-09], sum to 1.0000
[2019-03-24 02:24:11,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0938
[2019-03-24 02:24:11,994] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 91.0, 1.0, 2.0, 0.2364106553693766, 1.0, 2.0, 0.2364106553693766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 567381.7504105831, 567381.7504105836, 167229.0865763343], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4146000.0000, 
sim time next is 4146600.0000, 
raw observation next is [21.9, 89.5, 1.0, 2.0, 0.2337532958291149, 1.0, 2.0, 0.2337532958291149, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 561876.6619051371, 561876.6619051376, 166674.3775426494], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.895, 1.0, 1.0, 0.0878015426537082, 1.0, 1.0, 0.0878015426537082, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20067023639469184, 0.200670236394692, 0.3205276491204796], 
reward next is 0.6795, 
noisyNet noise sample is [array([1.5560714], dtype=float32), -0.28387254]. 
=============================================
[2019-03-24 02:24:15,103] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1030188e-10 2.7640600e-04 4.0543058e-11 9.9972254e-01 1.1092883e-06], sum to 1.0000
[2019-03-24 02:24:15,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1017
[2019-03-24 02:24:15,115] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 30.66666666666667, 1.0, 2.0, 0.825835533372477, 1.0, 2.0, 0.825835533372477, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1929750.780341405, 1929750.780341405, 356907.5551161568], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4206000.0000, 
sim time next is 4206600.0000, 
raw observation next is [34.25, 29.0, 1.0, 2.0, 0.8098860986067454, 1.0, 2.0, 0.8098860986067454, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1903714.153193492, 1903714.153193492, 350686.5536465179], 
processed observation next is [1.0, 0.6956521739130435, 0.8240740740740741, 0.29, 1.0, 1.0, 0.7736739269127921, 1.0, 1.0, 0.7736739269127921, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6798979118548185, 0.6798979118548185, 0.674397218550996], 
reward next is 0.3256, 
noisyNet noise sample is [array([0.7723282], dtype=float32), -1.0544449]. 
=============================================
[2019-03-24 02:24:16,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4047569e-15 5.9411846e-06 5.5364556e-16 9.9999404e-01 2.6880966e-09], sum to 1.0000
[2019-03-24 02:24:16,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8686
[2019-03-24 02:24:16,913] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.2, 77.0, 1.0, 2.0, 0.2503631402646223, 1.0, 2.0, 0.2503631402646223, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613995.0537195951, 613995.0537195951, 170803.0508879925], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4249200.0000, 
sim time next is 4249800.0000, 
raw observation next is [22.3, 76.5, 1.0, 2.0, 0.2439656848684004, 1.0, 2.0, 0.2439656848684004, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598358.6958820296, 598358.6958820301, 169353.0499874301], 
processed observation next is [1.0, 0.17391304347826086, 0.38148148148148153, 0.765, 1.0, 1.0, 0.09995914865285761, 1.0, 1.0, 0.09995914865285761, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.213699534243582, 0.21369953424358218, 0.3256789422835194], 
reward next is 0.6743, 
noisyNet noise sample is [array([0.14256819], dtype=float32), -1.3657174]. 
=============================================
[2019-03-24 02:24:20,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3365275e-14 9.8151509e-07 2.1413692e-18 9.9999905e-01 5.8595610e-08], sum to 1.0000
[2019-03-24 02:24:20,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4370
[2019-03-24 02:24:20,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.66666666666667, 53.0, 1.0, 2.0, 0.2900833063680384, 1.0, 2.0, 0.2900833063680384, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664224.2060385807, 664224.2060385807, 178251.8709190652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4299600.0000, 
sim time next is 4300200.0000, 
raw observation next is [30.5, 53.5, 1.0, 2.0, 0.2901933764097461, 1.0, 2.0, 0.2901933764097461, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 665099.0963027622, 665099.0963027626, 178308.8584095476], 
processed observation next is [1.0, 0.782608695652174, 0.6851851851851852, 0.535, 1.0, 1.0, 0.15499211477350724, 1.0, 1.0, 0.15499211477350724, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23753539153670078, 0.23753539153670095, 0.34290165078759155], 
reward next is 0.6571, 
noisyNet noise sample is [array([1.401144], dtype=float32), -1.5718315]. 
=============================================
[2019-03-24 02:24:20,734] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 02:24:20,737] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:24:20,738] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:24:20,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:24:20,739] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:24:20,739] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:24:20,740] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:24:20,741] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:24:20,740] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:24:20,741] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:24:20,742] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:24:20,761] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-24 02:24:20,785] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-24 02:24:20,787] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-24 02:24:20,836] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-24 02:24:20,863] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-24 02:24:23,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76256526]
[2019-03-24 02:24:23,489] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.59354594, 83.55073308333334, 1.0, 2.0, 0.2227201412229114, 1.0, 2.0, 0.2227201412229114, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534607.1882763656, 534607.1882763661, 164228.5140406949]
[2019-03-24 02:24:23,490] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:24:23,494] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9452161e-16 9.4808820e-07 4.5191722e-18 9.9999905e-01 1.2110185e-09], sampled 0.21959362307952257
[2019-03-24 02:24:30,143] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76256526]
[2019-03-24 02:24:30,144] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.37852597333333, 48.27629600333333, 1.0, 2.0, 0.2088036963530842, 1.0, 2.0, 0.2088036963530842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 505501.1291698937, 505501.1291698942, 161408.2279928262]
[2019-03-24 02:24:30,145] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:24:30,147] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4083966e-16 6.3018354e-07 1.4088788e-18 9.9999940e-01 6.6679356e-10], sampled 0.11562474508721432
[2019-03-24 02:24:44,614] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76256526]
[2019-03-24 02:24:44,616] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.1801632713744365, 1.0, 2.0, 0.1801632713744365, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 449139.7827809188, 449139.7827809193, 155851.7870756666]
[2019-03-24 02:24:44,617] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:24:44,620] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5189582e-16 1.2863779e-06 1.0795532e-17 9.9999869e-01 1.8919812e-09], sampled 0.7469391378982452
[2019-03-24 02:24:50,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76256526]
[2019-03-24 02:24:50,668] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.60263673, 49.59467132, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393044.3976488061, 393044.3976488065, 150204.8992291398]
[2019-03-24 02:24:50,669] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:24:50,671] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9653546e-16 8.4672286e-07 3.2698603e-18 9.9999917e-01 1.0267907e-09], sampled 0.19800475807212914
[2019-03-24 02:24:56,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76256526]
[2019-03-24 02:24:56,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.3362394565128345, 1.0, 2.0, 0.3362394565128345, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769731.6945293206, 769731.694529321, 189546.6213730754]
[2019-03-24 02:24:56,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:24:56,994] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9372841e-16 1.0363118e-06 5.8224209e-18 9.9999893e-01 1.3795014e-09], sampled 0.1593305409713942
[2019-03-24 02:25:57,750] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 02:25:57,900] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 02:25:58,134] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 02:25:58,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 02:25:58,199] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 02:25:59,215] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1175000, evaluation results [1175000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 02:26:01,142] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1175962: loss 0.8350
[2019-03-24 02:26:01,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1175964: learning rate 0.0001
[2019-03-24 02:26:01,381] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176074: loss 2.0637
[2019-03-24 02:26:01,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176074: learning rate 0.0001
[2019-03-24 02:26:01,551] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176160: loss 2.3771
[2019-03-24 02:26:01,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176160: learning rate 0.0001
[2019-03-24 02:26:01,611] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176188: loss 2.0647
[2019-03-24 02:26:01,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176190: learning rate 0.0001
[2019-03-24 02:26:01,670] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176217: loss 2.0503
[2019-03-24 02:26:01,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176217: learning rate 0.0001
[2019-03-24 02:26:01,876] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176319: loss 1.1699
[2019-03-24 02:26:01,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176320: learning rate 0.0001
[2019-03-24 02:26:01,890] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176326: loss 1.1091
[2019-03-24 02:26:01,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176326: learning rate 0.0001
[2019-03-24 02:26:02,114] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176443: loss 0.6435
[2019-03-24 02:26:02,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176443: learning rate 0.0001
[2019-03-24 02:26:02,158] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176464: loss 0.4827
[2019-03-24 02:26:02,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176464: learning rate 0.0001
[2019-03-24 02:26:02,167] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176467: loss 0.5304
[2019-03-24 02:26:02,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176467: learning rate 0.0001
[2019-03-24 02:26:02,223] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176492: loss 0.4513
[2019-03-24 02:26:02,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176492: learning rate 0.0001
[2019-03-24 02:26:02,315] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176539: loss 0.3141
[2019-03-24 02:26:02,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176540: learning rate 0.0001
[2019-03-24 02:26:02,507] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176631: loss 0.3575
[2019-03-24 02:26:02,510] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176633: learning rate 0.0001
[2019-03-24 02:26:02,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7210054e-06 5.8264513e-02 6.5947901e-08 9.4093388e-01 7.9987303e-04], sum to 1.0000
[2019-03-24 02:26:02,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-24 02:26:02,631] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.7135158492313183, 1.0, 2.0, 0.7135158492313183, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1627285.605163534, 1627285.605163534, 309313.2266451312], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4612800.0000, 
sim time next is 4613400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.7008846597548747, 1.0, 2.0, 0.7008846597548747, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1598452.411858324, 1598452.411858324, 304499.792135987], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.84, 1.0, 1.0, 0.6439103092319937, 1.0, 1.0, 0.6439103092319937, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5708758613779729, 0.5708758613779729, 0.5855765233384366], 
reward next is 0.4144, 
noisyNet noise sample is [array([1.2993515], dtype=float32), -1.851977]. 
=============================================
[2019-03-24 02:26:02,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5222877e-06 2.1541554e-02 1.2113556e-07 9.7785449e-01 6.0226576e-04], sum to 1.0000
[2019-03-24 02:26:02,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8342
[2019-03-24 02:26:02,688] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 79.0, 1.0, 2.0, 0.806254548203071, 1.0, 2.0, 0.806254548203071, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1839008.568807857, 1839008.568807856, 346345.7547166844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4354800.0000, 
sim time next is 4355400.0000, 
raw observation next is [27.83333333333334, 79.0, 1.0, 2.0, 0.8447625853733975, 1.0, 2.0, 0.8447625853733975, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1926937.378732705, 1926937.378732705, 362598.4242492188], 
processed observation next is [1.0, 0.391304347826087, 0.58641975308642, 0.79, 1.0, 1.0, 0.8151935540159495, 1.0, 1.0, 0.8151935540159495, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.688191920975966, 0.688191920975966, 0.6973046620177284], 
reward next is 0.3027, 
noisyNet noise sample is [array([-1.3564534], dtype=float32), 0.4000814]. 
=============================================
[2019-03-24 02:26:02,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176739: loss 0.1454
[2019-03-24 02:26:02,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176739: learning rate 0.0001
[2019-03-24 02:26:02,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3180382e-07 8.8981055e-03 9.6105346e-08 9.9086082e-01 2.4027737e-04], sum to 1.0000
[2019-03-24 02:26:02,750] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8169
[2019-03-24 02:26:02,757] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 51.0, 1.0, 2.0, 0.7873289461296211, 1.0, 2.0, 0.7070291350412452, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2419809.179972263, 2419809.179972263, 453531.2159146811], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4375800.0000, 
sim time next is 4376400.0000, 
raw observation next is [33.0, 50.33333333333333, 1.0, 2.0, 1.003086667959083, 1.0, 2.0, 1.003086667959083, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424721612, 2288543.772488429, 2288543.77248843, 434819.0179155995], 
processed observation next is [1.0, 0.6521739130434783, 0.7777777777777778, 0.5033333333333333, 1.0, 1.0, 1.0036746047131941, 1.0, 1.0, 1.0036746047131941, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621278674412, 0.8173370616030105, 0.8173370616030108, 0.8361904190684606], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36753443], dtype=float32), -0.625024]. 
=============================================
[2019-03-24 02:26:03,123] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176939: loss -2.2065
[2019-03-24 02:26:03,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176941: learning rate 0.0001
[2019-03-24 02:26:04,919] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1177840: loss 0.7752
[2019-03-24 02:26:04,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1177840: learning rate 0.0001
[2019-03-24 02:26:14,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9520519e-11 3.2951871e-03 6.7465323e-15 9.9662364e-01 8.1189908e-05], sum to 1.0000
[2019-03-24 02:26:14,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1340
[2019-03-24 02:26:14,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.4, 98.66666666666666, 1.0, 2.0, 0.2449481570233562, 1.0, 2.0, 0.2449481570233562, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582765.0997817398, 582765.0997817398, 168933.4746953694], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4585200.0000, 
sim time next is 4585800.0000, 
raw observation next is [21.5, 98.33333333333334, 1.0, 2.0, 0.2462182084817079, 1.0, 2.0, 0.2462182084817079, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585111.6153674611, 585111.6153674611, 169190.7515861268], 
processed observation next is [1.0, 0.043478260869565216, 0.35185185185185186, 0.9833333333333334, 1.0, 1.0, 0.10264072438298558, 1.0, 1.0, 0.10264072438298558, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20896843405980753, 0.20896843405980753, 0.3253668299733208], 
reward next is 0.6746, 
noisyNet noise sample is [array([-0.00534283], dtype=float32), -0.08838285]. 
=============================================
[2019-03-24 02:26:17,145] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1183887: loss 0.1465
[2019-03-24 02:26:17,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1183887: learning rate 0.0001
[2019-03-24 02:26:17,374] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1183999: loss 0.2853
[2019-03-24 02:26:17,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1183999: learning rate 0.0001
[2019-03-24 02:26:17,725] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184168: loss 0.1004
[2019-03-24 02:26:17,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184171: learning rate 0.0001
[2019-03-24 02:26:17,808] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184209: loss 0.1163
[2019-03-24 02:26:17,812] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184210: learning rate 0.0001
[2019-03-24 02:26:17,909] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184260: loss 0.0533
[2019-03-24 02:26:17,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184260: learning rate 0.0001
[2019-03-24 02:26:17,951] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184282: loss 0.0725
[2019-03-24 02:26:17,954] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184282: learning rate 0.0001
[2019-03-24 02:26:18,119] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184364: loss 0.0110
[2019-03-24 02:26:18,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184365: learning rate 0.0001
[2019-03-24 02:26:18,284] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184442: loss 0.1169
[2019-03-24 02:26:18,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184442: learning rate 0.0001
[2019-03-24 02:26:18,318] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184463: loss 0.1172
[2019-03-24 02:26:18,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184465: learning rate 0.0001
[2019-03-24 02:26:18,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184481: loss 0.2408
[2019-03-24 02:26:18,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184481: learning rate 0.0001
[2019-03-24 02:26:18,369] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184487: loss 0.3885
[2019-03-24 02:26:18,373] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184487: learning rate 0.0001
[2019-03-24 02:26:18,514] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184562: loss 0.4657
[2019-03-24 02:26:18,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184563: learning rate 0.0001
[2019-03-24 02:26:18,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184570: loss 0.4172
[2019-03-24 02:26:18,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184570: learning rate 0.0001
[2019-03-24 02:26:18,994] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1184794: loss 0.8387
[2019-03-24 02:26:19,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1184794: learning rate 0.0001
[2019-03-24 02:26:19,396] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184984: loss 0.7132
[2019-03-24 02:26:19,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184984: learning rate 0.0001
[2019-03-24 02:26:20,216] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2270342e-15 7.8013672e-06 4.8314420e-16 9.9999213e-01 1.6178285e-07], sum to 1.0000
[2019-03-24 02:26:20,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3048
[2019-03-24 02:26:20,235] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.307351992418316, 1.0, 2.0, 0.307351992418316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713655.9125132425, 713655.9125132428, 182864.3773397486], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4687800.0000, 
sim time next is 4688400.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.3011029916716906, 1.0, 2.0, 0.3011029916716906, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697633.9532020235, 697633.9532020235, 181275.5940003495], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.96, 1.0, 1.0, 0.16797975199010784, 1.0, 1.0, 0.16797975199010784, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24915498328643698, 0.24915498328643698, 0.34860691153913365], 
reward next is 0.6514, 
noisyNet noise sample is [array([0.5369382], dtype=float32), -0.5529329]. 
=============================================
[2019-03-24 02:26:21,144] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1185853: loss 2.7589
[2019-03-24 02:26:21,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1185853: learning rate 0.0001
[2019-03-24 02:26:22,367] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6158541e-13 1.1544631e-04 3.7270936e-15 9.9982905e-01 5.5451259e-05], sum to 1.0000
[2019-03-24 02:26:22,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1885
[2019-03-24 02:26:22,382] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.23333333333333, 86.66666666666666, 1.0, 2.0, 0.3361816446549549, 1.0, 2.0, 0.3361816446549549, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 766288.2007511503, 766288.2007511507, 189370.3859853472], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4740000.0000, 
sim time next is 4740600.0000, 
raw observation next is [26.11666666666667, 87.83333333333334, 1.0, 2.0, 0.3376440192490093, 1.0, 2.0, 0.3376440192490093, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769623.1923828269, 769623.1923828274, 189740.0409816376], 
processed observation next is [1.0, 0.8695652173913043, 0.5228395061728397, 0.8783333333333334, 1.0, 1.0, 0.2114809752964396, 1.0, 1.0, 0.2114809752964396, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2748654258510096, 0.27486542585100976, 0.36488469419545694], 
reward next is 0.6351, 
noisyNet noise sample is [array([0.09968735], dtype=float32), -0.2384821]. 
=============================================
[2019-03-24 02:26:29,105] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1654646e-13 2.1973805e-05 1.1411408e-13 9.9994171e-01 3.6347938e-05], sum to 1.0000
[2019-03-24 02:26:29,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2245
[2019-03-24 02:26:29,119] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 95.0, 1.0, 2.0, 0.3337950837189286, 1.0, 2.0, 0.3337950837189286, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760845.6040244477, 760845.6040244477, 188768.6990787837], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4858200.0000, 
sim time next is 4858800.0000, 
raw observation next is [25.0, 94.66666666666666, 1.0, 2.0, 0.3313282781309885, 1.0, 2.0, 0.3313282781309885, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755220.0484877022, 755220.0484877026, 188148.9086476359], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.9466666666666665, 1.0, 1.0, 0.20396223587022438, 1.0, 1.0, 0.20396223587022438, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26972144588846503, 0.2697214458884652, 0.3618248243223767], 
reward next is 0.6382, 
noisyNet noise sample is [array([1.2208916], dtype=float32), 0.3280007]. 
=============================================
[2019-03-24 02:26:33,591] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1191990: loss 4.5360
[2019-03-24 02:26:33,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1191991: learning rate 0.0001
[2019-03-24 02:26:33,606] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1191999: loss 3.8078
[2019-03-24 02:26:33,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1191999: learning rate 0.0001
[2019-03-24 02:26:34,043] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192213: loss 2.8847
[2019-03-24 02:26:34,046] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192214: learning rate 0.0001
[2019-03-24 02:26:34,126] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192252: loss 2.0416
[2019-03-24 02:26:34,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192253: learning rate 0.0001
[2019-03-24 02:26:34,168] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192273: loss 1.9679
[2019-03-24 02:26:34,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192273: learning rate 0.0001
[2019-03-24 02:26:34,197] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192285: loss 3.0113
[2019-03-24 02:26:34,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192286: learning rate 0.0001
[2019-03-24 02:26:34,304] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192338: loss 2.9154
[2019-03-24 02:26:34,305] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192339: learning rate 0.0001
[2019-03-24 02:26:34,309] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192340: loss 2.8416
[2019-03-24 02:26:34,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192340: learning rate 0.0001
[2019-03-24 02:26:34,397] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192386: loss 3.2137
[2019-03-24 02:26:34,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192388: learning rate 0.0001
[2019-03-24 02:26:34,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192508: loss 1.1541
[2019-03-24 02:26:34,634] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192508: loss -7.0501
[2019-03-24 02:26:34,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192508: learning rate 0.0001
[2019-03-24 02:26:34,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192508: learning rate 0.0001
[2019-03-24 02:26:34,700] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192544: loss 2.5840
[2019-03-24 02:26:34,702] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192544: learning rate 0.0001
[2019-03-24 02:26:34,752] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192570: loss 2.3262
[2019-03-24 02:26:34,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192571: learning rate 0.0001
[2019-03-24 02:26:35,199] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1192790: loss 2.0517
[2019-03-24 02:26:35,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1192791: learning rate 0.0001
[2019-03-24 02:26:35,542] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192957: loss 1.2274
[2019-03-24 02:26:35,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192958: learning rate 0.0001
[2019-03-24 02:26:37,307] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1193839: loss 0.0118
[2019-03-24 02:26:37,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1193840: learning rate 0.0001
[2019-03-24 02:26:49,669] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1199964: loss 1.3748
[2019-03-24 02:26:49,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1199965: learning rate 0.0001
[2019-03-24 02:26:49,742] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 02:26:49,744] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:26:49,744] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:26:49,745] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:26:49,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:26:49,745] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:26:49,746] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:26:49,747] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:26:49,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:26:49,749] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:26:49,750] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:26:49,766] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-24 02:26:49,794] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-24 02:26:49,794] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-24 02:26:49,853] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-24 02:26:49,877] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-24 02:26:56,841] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:26:56,841] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 54.16666666666667, 1.0, 2.0, 0.2131478919903172, 1.0, 2.0, 0.2131478919903172, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540590.2507510791, 540590.2507510795, 162949.8738594829]
[2019-03-24 02:26:56,842] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:26:56,844] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2756525e-08 4.7169178e-04 1.2443312e-09 9.9762207e-01 1.9062869e-03], sampled 0.01685254236870204
[2019-03-24 02:27:13,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:27:13,456] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.49629159333333, 103.0833545066667, 1.0, 2.0, 0.2563530860743771, 1.0, 2.0, 0.2563530860743771, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605960.4801248515, 605960.4801248515, 171349.9914051977]
[2019-03-24 02:27:13,457] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:27:13,461] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8539340e-08 4.4309377e-04 1.0536907e-09 9.9774444e-01 1.8125726e-03], sampled 0.1268130210980336
[2019-03-24 02:27:18,781] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:27:18,781] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.1, 54.0, 1.0, 2.0, 0.3063589103412258, 1.0, 2.0, 0.3063589103412258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698279.6744791464, 698279.6744791464, 181993.7857828214]
[2019-03-24 02:27:18,782] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:27:18,785] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9743475e-09 1.8112363e-04 9.7665258e-11 9.9893767e-01 8.8118995e-04], sampled 0.2940407748160996
[2019-03-24 02:27:23,845] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:27:23,845] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.5605768080936206, 1.0, 2.0, 0.5605768080936206, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1291526.43159152, 1291526.43159152, 255398.6821586895]
[2019-03-24 02:27:23,848] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:27:23,852] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2130509e-07 8.5406937e-04 6.0374901e-09 9.9606931e-01 3.0764493e-03], sampled 0.4757528812953995
[2019-03-24 02:27:28,742] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:27:28,743] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.29452746, 96.39624964, 1.0, 2.0, 0.2477655762638732, 1.0, 2.0, 0.2477655762638732, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591767.6399929855, 591767.6399929859, 169659.1627993014]
[2019-03-24 02:27:28,744] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:27:28,747] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.0697165e-09 2.6339226e-04 2.6426605e-10 9.9854481e-01 1.1917565e-03], sampled 0.4318637543830045
[2019-03-24 02:27:33,337] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7662687]
[2019-03-24 02:27:33,340] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.9, 94.0, 1.0, 2.0, 0.753497625453526, 1.0, 2.0, 0.753497625453526, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1718558.068303025, 1718558.068303024, 324914.0265218718]
[2019-03-24 02:27:33,342] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:27:33,346] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5340670e-07 1.3865064e-03 2.1927319e-08 9.9406660e-01 4.5465394e-03], sampled 0.15449656075912632
[2019-03-24 02:28:26,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7502.2108 2669300486.9989 69.0000
[2019-03-24 02:28:27,229] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7104.1301 2439417304.0150 34.0000
[2019-03-24 02:28:27,252] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6894.3383 2495790644.3971 47.0000
[2019-03-24 02:28:27,398] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7774.3208 2411499605.8079 24.0000
[2019-03-24 02:28:27,529] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7457.9864 2466761568.4519 46.0000
[2019-03-24 02:28:28,546] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1200000, evaluation results [1200000.0, 7502.2108493196465, 2669300486.9988956, 69.0, 7104.130075537039, 2439417304.01502, 34.0, 7774.32082416001, 2411499605.807881, 24.0, 6894.338317373475, 2495790644.397091, 47.0, 7457.986431276557, 2466761568.4518824, 46.0]
[2019-03-24 02:28:28,809] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200127: loss 1.1472
[2019-03-24 02:28:28,811] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200127: learning rate 0.0001
[2019-03-24 02:28:28,934] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200186: loss 1.0619
[2019-03-24 02:28:28,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200186: learning rate 0.0001
[2019-03-24 02:28:28,974] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200206: loss 0.9451
[2019-03-24 02:28:28,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200208: learning rate 0.0001
[2019-03-24 02:28:29,035] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1200231: loss 1.1931
[2019-03-24 02:28:29,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1200231: learning rate 0.0001
[2019-03-24 02:28:29,066] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200245: loss 1.1473
[2019-03-24 02:28:29,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200246: learning rate 0.0001
[2019-03-24 02:28:29,097] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200264: loss 1.1389
[2019-03-24 02:28:29,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200264: learning rate 0.0001
[2019-03-24 02:28:29,314] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200375: loss 0.8147
[2019-03-24 02:28:29,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200376: learning rate 0.0001
[2019-03-24 02:28:29,350] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200387: loss 0.6669
[2019-03-24 02:28:29,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200389: learning rate 0.0001
[2019-03-24 02:28:29,509] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200470: loss 0.4432
[2019-03-24 02:28:29,513] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200470: learning rate 0.0001
[2019-03-24 02:28:29,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200530: loss 0.3487
[2019-03-24 02:28:29,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200530: learning rate 0.0001
[2019-03-24 02:28:29,652] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200541: loss 0.4875
[2019-03-24 02:28:29,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200543: learning rate 0.0001
[2019-03-24 02:28:29,767] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200604: loss 0.3679
[2019-03-24 02:28:29,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200604: learning rate 0.0001
[2019-03-24 02:28:30,028] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200732: loss 0.3472
[2019-03-24 02:28:30,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200733: learning rate 0.0001
[2019-03-24 02:28:30,636] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201038: loss 0.2631
[2019-03-24 02:28:30,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201039: learning rate 0.0001
[2019-03-24 02:28:32,294] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1201867: loss 0.1035
[2019-03-24 02:28:32,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1201867: learning rate 0.0001
[2019-03-24 02:28:32,658] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0453929e-08 1.9964819e-04 6.7150313e-10 9.9379516e-01 6.0052318e-03], sum to 1.0000
[2019-03-24 02:28:32,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4274
[2019-03-24 02:28:32,669] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.31666666666667, 64.33333333333334, 1.0, 2.0, 0.7667353405152681, 1.0, 2.0, 0.7667353405152681, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1748779.862799094, 1748779.862799095, 330199.3152352344], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5325000.0000, 
sim time next is 5325600.0000, 
raw observation next is [28.33333333333334, 64.66666666666667, 1.0, 2.0, 0.7840133739594983, 1.0, 2.0, 0.7840133739594983, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1788227.270219274, 1788227.270219275, 337191.4838983066], 
processed observation next is [1.0, 0.6521739130434783, 0.6049382716049385, 0.6466666666666667, 1.0, 1.0, 0.742873064237498, 1.0, 1.0, 0.742873064237498, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6386525965068836, 0.6386525965068839, 0.6484451613428973], 
reward next is 0.3516, 
noisyNet noise sample is [array([0.8073246], dtype=float32), -0.45714012]. 
=============================================
[2019-03-24 02:28:38,936] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5298047e-13 2.5387698e-07 2.4457797e-15 9.7201443e-01 2.7985379e-02], sum to 1.0000
[2019-03-24 02:28:38,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3002
[2019-03-24 02:28:38,946] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.71666666666667, 81.5, 1.0, 2.0, 0.3867584402441162, 1.0, 2.0, 0.3867584402441162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 881638.6152818279, 881638.6152818283, 202585.4441874152], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5429400.0000, 
sim time next is 5430000.0000, 
raw observation next is [28.63333333333334, 82.0, 1.0, 2.0, 0.3867905181707048, 1.0, 2.0, 0.3867905181707048, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 881711.7808654008, 881711.7808654013, 202594.1016009608], 
processed observation next is [1.0, 0.8695652173913043, 0.6160493827160496, 0.82, 1.0, 1.0, 0.2699887121079819, 1.0, 1.0, 0.2699887121079819, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.314897064594786, 0.31489706459478617, 0.38960404154030925], 
reward next is 0.6104, 
noisyNet noise sample is [array([0.21142834], dtype=float32), 0.60843784]. 
=============================================
[2019-03-24 02:28:38,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.26571 ]
 [63.261757]
 [63.42552 ]
 [63.30793 ]
 [63.299843]], R is [[63.17454147]
 [63.15320969]
 [63.13232803]
 [63.11221695]
 [63.09285355]].
[2019-03-24 02:28:43,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8539796e-12 3.2028843e-06 1.3148314e-13 8.3738668e-03 9.9162287e-01], sum to 1.0000
[2019-03-24 02:28:43,937] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4503
[2019-03-24 02:28:43,944] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 81.0, 1.0, 2.0, 0.2175427479153918, 1.0, 2.0, 0.2175427479153918, 1.0, 2.0, 0.3463351395539826, 6.9112, 6.9112, 121.94756008, 743785.3177551285, 743785.3177551285, 226410.7749488011], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5514000.0000, 
sim time next is 5514600.0000, 
raw observation next is [26.61666666666667, 81.0, 1.0, 2.0, 0.2175928143317965, 1.0, 2.0, 0.2175928143317965, 1.0, 2.0, 0.3464148469194483, 6.9112, 6.9112, 121.94756008, 743956.5794197682, 743956.5794197682, 226427.6203488997], 
processed observation next is [1.0, 0.8260869565217391, 0.5413580246913582, 0.81, 1.0, 1.0, 0.06856287420451965, 1.0, 1.0, 0.06856287420451965, 1.0, 1.0, 0.18301855864931035, 0.0, 0.0, 0.8096049824067558, 0.2656987783642029, 0.2656987783642029, 0.43543773144019177], 
reward next is 0.5646, 
noisyNet noise sample is [array([0.5650367], dtype=float32), -0.7058205]. 
=============================================
[2019-03-24 02:28:44,576] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1207976: loss 0.1079
[2019-03-24 02:28:44,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1207976: learning rate 0.0001
[2019-03-24 02:28:44,933] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208150: loss -2.7523
[2019-03-24 02:28:44,938] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208151: learning rate 0.0001
[2019-03-24 02:28:44,980] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208171: loss 0.0253
[2019-03-24 02:28:44,982] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208171: loss 0.0730
[2019-03-24 02:28:44,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208171: learning rate 0.0001
[2019-03-24 02:28:44,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208172: learning rate 0.0001
[2019-03-24 02:28:45,127] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208242: loss 0.0225
[2019-03-24 02:28:45,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208245: learning rate 0.0001
[2019-03-24 02:28:45,233] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208293: loss 0.0481
[2019-03-24 02:28:45,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208294: learning rate 0.0001
[2019-03-24 02:28:45,265] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208311: loss 0.0986
[2019-03-24 02:28:45,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208311: learning rate 0.0001
[2019-03-24 02:28:45,382] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208371: loss 0.0301
[2019-03-24 02:28:45,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208371: learning rate 0.0001
[2019-03-24 02:28:45,527] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208441: loss 0.0320
[2019-03-24 02:28:45,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208441: learning rate 0.0001
[2019-03-24 02:28:45,584] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208471: loss 0.0273
[2019-03-24 02:28:45,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208471: learning rate 0.0001
[2019-03-24 02:28:45,678] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208516: loss 0.0313
[2019-03-24 02:28:45,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208516: learning rate 0.0001
[2019-03-24 02:28:45,741] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208547: loss 0.1316
[2019-03-24 02:28:45,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208547: learning rate 0.0001
[2019-03-24 02:28:45,788] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208569: loss 0.2810
[2019-03-24 02:28:45,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208572: learning rate 0.0001
[2019-03-24 02:28:46,124] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208734: loss 0.0683
[2019-03-24 02:28:46,126] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208734: learning rate 0.0001
[2019-03-24 02:28:46,502] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6842757e-07 1.2522672e-03 3.1519509e-08 8.8222250e-02 9.1052443e-01], sum to 1.0000
[2019-03-24 02:28:46,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-24 02:28:46,516] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.9, 75.0, 1.0, 2.0, 0.9716133835793103, 1.0, 2.0, 0.9716133835793103, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2216648.282729228, 2216648.282729228, 419771.9867875622], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5578200.0000, 
sim time next is 5578800.0000, 
raw observation next is [30.1, 74.66666666666666, 1.0, 2.0, 0.6774918443340432, 1.0, 2.0, 0.6521105841434562, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2231615.394311721, 2231615.394311721, 423246.5133738203], 
processed observation next is [1.0, 0.5652173913043478, 0.6703703703703704, 0.7466666666666666, 1.0, 1.0, 0.6160617194452895, 1.0, 1.0, 0.5858459335041145, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7970054979684718, 0.7970054979684718, 0.8139356026419621], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6033917], dtype=float32), 0.50437796]. 
=============================================
[2019-03-24 02:28:46,768] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209052: loss 0.4122
[2019-03-24 02:28:46,770] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209052: learning rate 0.0001
[2019-03-24 02:28:48,290] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1209808: loss 3.9401
[2019-03-24 02:28:48,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1209808: learning rate 0.0001
[2019-03-24 02:28:48,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4327920e-13 2.3052019e-07 5.3213585e-16 8.0707294e-05 9.9991906e-01], sum to 1.0000
[2019-03-24 02:28:48,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1202
[2019-03-24 02:28:48,398] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.21666666666667, 93.83333333333334, 1.0, 2.0, 0.2272849028193019, 1.0, 2.0, 0.2272849028193019, 1.0, 2.0, 0.3618449674408422, 6.9112, 6.9112, 121.94756008, 777110.9252679893, 777110.9252679893, 229715.0381689463], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5604600.0000, 
sim time next is 5605200.0000, 
raw observation next is [25.1, 94.0, 1.0, 2.0, 0.2251653114345049, 1.0, 2.0, 0.2251653114345049, 1.0, 2.0, 0.3584705089259733, 6.911200000000001, 6.9112, 121.94756008, 769860.181206173, 769860.1812061726, 228991.6146797505], 
processed observation next is [1.0, 0.9130434782608695, 0.4851851851851852, 0.94, 1.0, 1.0, 0.07757775170774395, 1.0, 1.0, 0.07757775170774395, 1.0, 1.0, 0.19808813615746662, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27495006471649036, 0.2749500647164902, 0.4403684897687509], 
reward next is 0.5596, 
noisyNet noise sample is [array([-0.6708638], dtype=float32), 0.1927448]. 
=============================================
[2019-03-24 02:28:54,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0865168e-04 1.6264051e-01 1.4015633e-04 2.0454428e-01 6.3236648e-01], sum to 1.0000
[2019-03-24 02:28:54,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9490
[2019-03-24 02:28:54,975] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.33333333333334, 84.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2238557691797813, 6.911199999999999, 6.9112, 121.94756008, 501584.4766015642, 501584.4766015646, 195729.2078999758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5977200.0000, 
sim time next is 5977800.0000, 
raw observation next is [21.25, 84.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2229795254689575, 6.911200000000001, 6.9112, 121.94756008, 499664.8634407613, 499664.8634407609, 195412.1523757204], 
processed observation next is [1.0, 0.17391304347826086, 0.3425925925925926, 0.845, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.028724406836196856, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.17845173694312902, 0.17845173694312888, 0.3757926007225392], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8682456], dtype=float32), 1.5562477]. 
=============================================
[2019-03-24 02:29:00,657] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1215928: loss 0.6096
[2019-03-24 02:29:00,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1215930: learning rate 0.0001
[2019-03-24 02:29:01,022] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216104: loss 0.8837
[2019-03-24 02:29:01,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216104: learning rate 0.0001
[2019-03-24 02:29:01,107] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216152: loss 2.9080
[2019-03-24 02:29:01,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216152: learning rate 0.0001
[2019-03-24 02:29:01,124] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216159: loss 1.3689
[2019-03-24 02:29:01,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216159: learning rate 0.0001
[2019-03-24 02:29:01,305] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216241: loss 0.6175
[2019-03-24 02:29:01,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216242: learning rate 0.0001
[2019-03-24 02:29:01,451] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216318: loss 0.5290
[2019-03-24 02:29:01,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216319: learning rate 0.0001
[2019-03-24 02:29:01,557] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216369: loss 0.5105
[2019-03-24 02:29:01,560] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216370: learning rate 0.0001
[2019-03-24 02:29:01,617] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216400: loss 0.2343
[2019-03-24 02:29:01,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216400: learning rate 0.0001
[2019-03-24 02:29:01,653] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216412: loss 0.4199
[2019-03-24 02:29:01,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216412: learning rate 0.0001
[2019-03-24 02:29:01,775] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216476: loss 0.0576
[2019-03-24 02:29:01,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216476: learning rate 0.0001
[2019-03-24 02:29:01,838] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216502: loss 0.0882
[2019-03-24 02:29:01,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216502: learning rate 0.0001
[2019-03-24 02:29:01,962] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216563: loss 0.0965
[2019-03-24 02:29:01,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216563: learning rate 0.0001
[2019-03-24 02:29:02,159] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216659: loss 0.2528
[2019-03-24 02:29:02,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216659: learning rate 0.0001
[2019-03-24 02:29:02,302] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216731: loss 0.9563
[2019-03-24 02:29:02,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216733: learning rate 0.0001
[2019-03-24 02:29:02,819] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216987: loss 0.0549
[2019-03-24 02:29:02,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216988: learning rate 0.0001
[2019-03-24 02:29:04,896] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1218016: loss 0.1929
[2019-03-24 02:29:04,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1218016: learning rate 0.0001
[2019-03-24 02:29:10,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4799006e-13 9.3917716e-01 1.1548106e-12 1.0601726e-03 5.9762724e-02], sum to 1.0000
[2019-03-24 02:29:10,490] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8075
[2019-03-24 02:29:10,497] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 58.33333333333334, 1.0, 2.0, 0.5141020453979388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 608219.6914435233, 608219.6914435237, 144938.627342802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6025800.0000, 
sim time next is 6026400.0000, 
raw observation next is [28.2, 59.0, 1.0, 2.0, 0.5189634645672523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614043.0751565674, 614043.0751565674, 145717.4291704381], 
processed observation next is [1.0, 0.782608695652174, 0.6, 0.59, 1.0, 1.0, 0.42733745781815746, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21930109827020264, 0.21930109827020264, 0.2802258253277656], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.9511014], dtype=float32), 1.2820781]. 
=============================================
[2019-03-24 02:29:11,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8208649e-14 9.9920231e-01 1.2224056e-14 4.3249244e-04 3.6524018e-04], sum to 1.0000
[2019-03-24 02:29:11,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6559
[2019-03-24 02:29:11,499] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 80.66666666666667, 1.0, 2.0, 0.5108899044135126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608792.0660081594, 608792.0660081594, 144595.9352939198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6046800.0000, 
sim time next is 6047400.0000, 
raw observation next is [24.03333333333333, 81.33333333333334, 1.0, 2.0, 0.5088371662904053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606754.1908036242, 606754.1908036242, 144285.1246995776], 
processed observation next is [1.0, 1.0, 0.4456790123456789, 0.8133333333333335, 1.0, 1.0, 0.41528234082191107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21669792528700865, 0.21669792528700865, 0.27747139365303386], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.4730611], dtype=float32), 1.7291937]. 
=============================================
[2019-03-24 02:29:12,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2410170e-13 9.9990594e-01 1.5408302e-14 4.0672367e-06 8.9998255e-05], sum to 1.0000
[2019-03-24 02:29:12,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5652
[2019-03-24 02:29:12,316] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 89.66666666666667, 1.0, 2.0, 0.4978324332559956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596156.4978418098, 596156.4978418098, 142641.519422304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6054000.0000, 
sim time next is 6054600.0000, 
raw observation next is [22.53333333333333, 90.33333333333334, 1.0, 2.0, 0.4964225927353234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594970.7288474158, 594970.7288474158, 142438.3102175984], 
processed observation next is [1.0, 0.043478260869565216, 0.3901234567901234, 0.9033333333333334, 1.0, 1.0, 0.4005030865896707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2124895460169342, 0.2124895460169342, 0.27391982734153536], 
reward next is 0.7261, 
noisyNet noise sample is [array([-0.5055831], dtype=float32), 2.2040956]. 
=============================================
[2019-03-24 02:29:13,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4642376e-14 9.9208212e-01 1.6823501e-15 6.5275130e-04 7.2651976e-03], sum to 1.0000
[2019-03-24 02:29:13,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-24 02:29:13,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 82.66666666666667, 1.0, 2.0, 0.5718375886006896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679337.4781324554, 679337.4781324558, 154532.7647036214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6072000.0000, 
sim time next is 6072600.0000, 
raw observation next is [24.13333333333333, 82.33333333333334, 1.0, 2.0, 0.6052981757217534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718762.138545017, 718762.138545017, 160291.4443373738], 
processed observation next is [1.0, 0.2608695652173913, 0.44938271604938257, 0.8233333333333335, 1.0, 1.0, 0.5301168758592302, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2567007637660775, 0.2567007637660775, 0.3082527775718727], 
reward next is 0.6917, 
noisyNet noise sample is [array([0.97767836], dtype=float32), -1.3224756]. 
=============================================
[2019-03-24 02:29:16,904] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1223911: loss 0.6126
[2019-03-24 02:29:16,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1223911: learning rate 0.0001
[2019-03-24 02:29:17,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224108: loss 0.1827
[2019-03-24 02:29:17,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224108: learning rate 0.0001
[2019-03-24 02:29:17,403] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224157: loss 0.2241
[2019-03-24 02:29:17,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224157: learning rate 0.0001
[2019-03-24 02:29:17,466] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224186: loss 0.1018
[2019-03-24 02:29:17,469] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224187: learning rate 0.0001
[2019-03-24 02:29:17,507] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224208: loss 0.0955
[2019-03-24 02:29:17,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224209: learning rate 0.0001
[2019-03-24 02:29:17,640] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224271: loss 0.0509
[2019-03-24 02:29:17,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224271: learning rate 0.0001
[2019-03-24 02:29:17,724] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224317: loss 0.1932
[2019-03-24 02:29:17,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224317: learning rate 0.0001
[2019-03-24 02:29:17,746] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224325: loss 0.1699
[2019-03-24 02:29:17,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224325: learning rate 0.0001
[2019-03-24 02:29:17,860] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224381: loss 0.0878
[2019-03-24 02:29:17,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224381: learning rate 0.0001
[2019-03-24 02:29:18,057] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224477: loss 0.1211
[2019-03-24 02:29:18,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224479: learning rate 0.0001
[2019-03-24 02:29:18,077] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224489: loss 0.1064
[2019-03-24 02:29:18,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224490: learning rate 0.0001
[2019-03-24 02:29:18,138] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224521: loss 0.1602
[2019-03-24 02:29:18,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224521: learning rate 0.0001
[2019-03-24 02:29:18,539] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224719: loss 0.4812
[2019-03-24 02:29:18,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224719: learning rate 0.0001
[2019-03-24 02:29:18,574] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224734: loss 0.1765
[2019-03-24 02:29:18,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224734: learning rate 0.0001
[2019-03-24 02:29:19,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224970: loss 0.1272
[2019-03-24 02:29:19,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224970: learning rate 0.0001
[2019-03-24 02:29:19,116] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 02:29:19,117] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:29:19,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:19,119] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:29:19,119] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:29:19,120] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:29:19,120] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:19,122] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:19,123] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:29:19,122] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:19,124] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:19,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-24 02:29:19,164] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-24 02:29:19,165] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-24 02:29:19,166] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-24 02:29:19,244] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-24 02:29:31,495] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7706445]
[2019-03-24 02:29:31,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.2, 52.0, 1.0, 2.0, 0.4293459571620378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526569.5558470953, 526569.5558470953, 132696.3340628253]
[2019-03-24 02:29:31,497] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:29:31,499] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2591146e-17 1.0000000e+00 7.0291844e-20 1.2721829e-11 1.5539356e-10], sampled 0.47777302844685376
[2019-03-24 02:29:42,143] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7706445]
[2019-03-24 02:29:42,144] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 92.0, 1.0, 2.0, 0.4666021426360297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572046.735832091, 572046.7358320905, 138244.8895456805]
[2019-03-24 02:29:42,145] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:29:42,148] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5339007e-16 1.0000000e+00 3.1831678e-19 2.9821593e-11 3.3538292e-10], sampled 0.3068904919591092
[2019-03-24 02:30:11,310] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7706445]
[2019-03-24 02:30:11,314] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.9, 77.0, 1.0, 2.0, 0.6376975047696746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727754.4905832832, 727754.4905832832, 164732.8213618477]
[2019-03-24 02:30:11,315] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:30:11,319] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7405865e-17 1.0000000e+00 9.9926197e-20 1.5515034e-11 1.8591825e-10], sampled 0.9667800138940315
[2019-03-24 02:30:12,203] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7706445]
[2019-03-24 02:30:12,203] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.53333333333333, 91.83333333333334, 1.0, 2.0, 0.5585691727709623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655157.0146453024, 655157.0146453024, 151957.825524335]
[2019-03-24 02:30:12,206] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:30:12,208] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.85360650e-17 1.00000000e+00 6.24637943e-20 1.19018935e-11
 1.46316306e-10], sampled 0.37632506759176043
[2019-03-24 02:30:45,234] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7706445]
[2019-03-24 02:30:45,236] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.95, 78.50000000000001, 1.0, 2.0, 0.7908158170355476, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1616458.022286529, 1616458.022286529, 334419.3263991608]
[2019-03-24 02:30:45,238] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:30:45,241] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9994307e-14 1.0000000e+00 3.6195502e-16 1.5769448e-09 1.2064830e-08], sampled 0.13240472963838312
[2019-03-24 02:30:45,241] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1616458.022286529 W.
[2019-03-24 02:30:56,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:30:56,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 02:30:56,460] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:30:56,658] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:30:56,832] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:30:57,851] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1225000, evaluation results [1225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:30:59,692] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1225909: loss 761.0222
[2019-03-24 02:30:59,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1225910: learning rate 0.0001
[2019-03-24 02:31:00,654] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8485395e-21 1.0000000e+00 1.6021875e-24 8.8832233e-18 1.5638916e-16], sum to 1.0000
[2019-03-24 02:31:00,664] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1077
[2019-03-24 02:31:00,669] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 77.0, 1.0, 2.0, 0.4893858700537079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588245.7135229128, 588245.7135229128, 141399.5589991224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6226200.0000, 
sim time next is 6226800.0000, 
raw observation next is [24.13333333333333, 77.33333333333334, 1.0, 2.0, 0.4862316547172054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584625.3984355974, 584625.398435597, 140915.4986687577], 
processed observation next is [0.0, 0.043478260869565216, 0.44938271604938257, 0.7733333333333334, 1.0, 1.0, 0.38837101752048264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2087947851555705, 0.20879478515557034, 0.2709913435937648], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.18314254], dtype=float32), -0.5946355]. 
=============================================
[2019-03-24 02:31:03,786] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5103901e-20 1.0000000e+00 3.0820717e-24 3.0389792e-17 9.4913144e-16], sum to 1.0000
[2019-03-24 02:31:03,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7523
[2019-03-24 02:31:03,806] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 83.16666666666667, 1.0, 2.0, 0.5713169825878418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667535.1512033342, 667535.1512033342, 153983.9570384516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6304200.0000, 
sim time next is 6304800.0000, 
raw observation next is [24.83333333333334, 83.33333333333334, 1.0, 2.0, 0.5704158159465161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666613.2154517521, 666613.2154517521, 153837.8578928058], 
processed observation next is [0.0, 1.0, 0.47530864197530887, 0.8333333333333335, 1.0, 1.0, 0.48859025707918585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23807614837562574, 0.23807614837562574, 0.2958420344092419], 
reward next is 0.7042, 
noisyNet noise sample is [array([0.65748405], dtype=float32), -0.65177613]. 
=============================================
[2019-03-24 02:31:05,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.48581510e-23 1.00000000e+00 1.04528615e-26 2.14672828e-18
 4.62724587e-18], sum to 1.0000
[2019-03-24 02:31:05,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9683
[2019-03-24 02:31:05,529] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 73.0, 1.0, 2.0, 0.5894172518688824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685318.2628575763, 685318.2628575763, 156913.5257397964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6297600.0000, 
sim time next is 6298200.0000, 
raw observation next is [26.5, 74.0, 1.0, 2.0, 0.5883157234798744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684090.7232672597, 684090.7232672597, 156727.2379581392], 
processed observation next is [0.0, 0.9130434782608695, 0.5370370370370371, 0.74, 1.0, 1.0, 0.5098996708093743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24431811545259274, 0.24431811545259274, 0.3013985345348831], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.4126054], dtype=float32), 0.13042955]. 
=============================================
[2019-03-24 02:31:06,684] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8944976e-23 1.0000000e+00 2.9553495e-25 1.2141562e-16 4.8251417e-17], sum to 1.0000
[2019-03-24 02:31:06,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5858
[2019-03-24 02:31:06,702] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 79.0, 1.0, 2.0, 0.6417951382813794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 731433.2501939355, 731433.2501939351, 165416.4292208121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340200.0000, 
sim time next is 6340800.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.6541449564695797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745514.7845746785, 745514.7845746785, 167643.1314047589], 
processed observation next is [0.0, 0.391304347826087, 0.5592592592592593, 0.78, 1.0, 1.0, 0.5882678053209283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2662552802052423, 0.2662552802052423, 0.32239063731684403], 
reward next is 0.6776, 
noisyNet noise sample is [array([0.39038828], dtype=float32), 2.0892377]. 
=============================================
[2019-03-24 02:31:10,029] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2814975e-13 1.0000000e+00 6.3187933e-16 4.5465649e-11 4.4651902e-10], sum to 1.0000
[2019-03-24 02:31:10,040] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8662
[2019-03-24 02:31:10,047] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 82.5, 1.0, 2.0, 0.6825589677407253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777914.0476021738, 777914.0476021738, 172866.6964049963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6395400.0000, 
sim time next is 6396000.0000, 
raw observation next is [26.53333333333333, 83.0, 1.0, 2.0, 0.6792880249236382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774184.2638142337, 774184.2638142337, 172258.1782375922], 
processed observation next is [1.0, 0.0, 0.5382716049382715, 0.83, 1.0, 1.0, 0.6182000296709977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2764943799336549, 0.2764943799336549, 0.331265727379985], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.58454347], dtype=float32), 0.32471982]. 
=============================================
[2019-03-24 02:31:10,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[41.19464 ]
 [42.226852]
 [43.855377]
 [46.090485]
 [49.57467 ]], R is [[40.82085037]
 [41.08020782]
 [41.3371048 ]
 [41.59382629]
 [41.84274292]].
[2019-03-24 02:31:11,996] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232008: loss 706.1661
[2019-03-24 02:31:11,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232008: learning rate 0.0001
[2019-03-24 02:31:12,187] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232099: loss 610.0508
[2019-03-24 02:31:12,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232099: learning rate 0.0001
[2019-03-24 02:31:12,418] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232213: loss 472.3729
[2019-03-24 02:31:12,422] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232215: loss 559.8840
[2019-03-24 02:31:12,423] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232214: learning rate 0.0001
[2019-03-24 02:31:12,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232216: learning rate 0.0001
[2019-03-24 02:31:12,531] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232268: loss 552.0869
[2019-03-24 02:31:12,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232268: learning rate 0.0001
[2019-03-24 02:31:12,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232283: loss 631.3017
[2019-03-24 02:31:12,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232283: learning rate 0.0001
[2019-03-24 02:31:12,650] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232319: loss 663.3852
[2019-03-24 02:31:12,652] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232319: learning rate 0.0001
[2019-03-24 02:31:12,778] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232384: loss 547.5970
[2019-03-24 02:31:12,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232385: learning rate 0.0001
[2019-03-24 02:31:12,867] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232423: loss 523.2824
[2019-03-24 02:31:12,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232426: learning rate 0.0001
[2019-03-24 02:31:12,966] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1232476: loss 578.4731
[2019-03-24 02:31:12,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1232477: learning rate 0.0001
[2019-03-24 02:31:12,998] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232490: loss 558.5905
[2019-03-24 02:31:13,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232491: learning rate 0.0001
[2019-03-24 02:31:13,075] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1232528: loss 498.9666
[2019-03-24 02:31:13,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1232528: learning rate 0.0001
[2019-03-24 02:31:13,469] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232725: loss 590.1683
[2019-03-24 02:31:13,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232726: learning rate 0.0001
[2019-03-24 02:31:13,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4070579e-15 1.0000000e+00 3.8113683e-18 1.2808073e-10 2.2488957e-09], sum to 1.0000
[2019-03-24 02:31:13,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9307
[2019-03-24 02:31:13,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 27.66666666666667, 1.0, 2.0, 0.3448160798598136, 1.0, 2.0, 0.3448160798598136, 1.0, 2.0, 0.567292012322643, 6.911199999999999, 6.9112, 121.94756008, 1272418.879175176, 1272418.879175177, 272134.7749531902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6711600.0000, 
sim time next is 6712200.0000, 
raw observation next is [30.35, 27.5, 1.0, 2.0, 0.9552169957365538, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.467267968011413, 6.9112, 121.9240671788662, 1484670.910619321, 1199919.023810397, 234602.1921325878], 
processed observation next is [1.0, 0.6956521739130435, 0.6796296296296297, 0.275, 1.0, 1.0, 0.9466868996863737, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05560679680114129, 0.0, 0.8094490139741226, 0.5302396109354718, 0.42854250850371317, 0.4511580617934381], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14400128], dtype=float32), -1.197052]. 
=============================================
[2019-03-24 02:31:13,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232834: loss 603.2917
[2019-03-24 02:31:13,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232834: learning rate 0.0001
[2019-03-24 02:31:13,918] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232947: loss 480.5944
[2019-03-24 02:31:13,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232948: learning rate 0.0001
[2019-03-24 02:31:16,012] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1233973: loss 0.5955
[2019-03-24 02:31:16,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1233974: learning rate 0.0001
[2019-03-24 02:31:21,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3622176e-12 9.9680722e-01 2.4230009e-11 1.1986178e-06 3.1915857e-03], sum to 1.0000
[2019-03-24 02:31:21,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3788
[2019-03-24 02:31:21,795] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 50.16666666666666, 1.0, 2.0, 0.3600641518150154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450192.4326572239, 450192.4326572234, 123216.955878931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6635400.0000, 
sim time next is 6636000.0000, 
raw observation next is [25.73333333333333, 52.33333333333333, 1.0, 2.0, 0.365135670435808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455760.4741943211, 455760.4741943211, 123884.6923480999], 
processed observation next is [1.0, 0.8260869565217391, 0.5086419753086419, 0.5233333333333333, 1.0, 1.0, 0.24420913147120005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16277159792654325, 0.16277159792654325, 0.23823979297711517], 
reward next is 0.7618, 
noisyNet noise sample is [array([1.5232496], dtype=float32), 1.6693969]. 
=============================================
[2019-03-24 02:31:21,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.643158]
 [56.451332]
 [57.003403]
 [57.36805 ]
 [58.061146]], R is [[55.86774063]
 [56.07210541]
 [56.2753334 ]
 [56.47619629]
 [56.67477417]].
[2019-03-24 02:31:23,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4073716e-12 9.8300457e-01 1.2284294e-14 1.8387434e-05 1.6977036e-02], sum to 1.0000
[2019-03-24 02:31:23,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-24 02:31:23,023] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 38.5, 1.0, 2.0, 0.2911994331424241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375562.2578579417, 375562.2578579417, 114481.5650195515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6649800.0000, 
sim time next is 6650400.0000, 
raw observation next is [24.8, 39.0, 1.0, 2.0, 0.2905587837146344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374714.5512582209, 374714.5512582209, 114403.6986039948], 
processed observation next is [1.0, 1.0, 0.4740740740740741, 0.39, 1.0, 1.0, 0.15542712346980286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1338266254493646, 0.1338266254493646, 0.22000711269999], 
reward next is 0.7800, 
noisyNet noise sample is [array([0.0665601], dtype=float32), -1.3024256]. 
=============================================
[2019-03-24 02:31:28,009] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1239885: loss -0.0048
[2019-03-24 02:31:28,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1239885: learning rate 0.0001
[2019-03-24 02:31:28,259] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1240009: loss 0.4353
[2019-03-24 02:31:28,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1240010: learning rate 0.0001
[2019-03-24 02:31:28,453] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240108: loss 3.6906
[2019-03-24 02:31:28,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240109: learning rate 0.0001
[2019-03-24 02:31:28,637] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240198: loss 0.0179
[2019-03-24 02:31:28,642] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240198: learning rate 0.0001
[2019-03-24 02:31:28,822] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240292: loss 0.0662
[2019-03-24 02:31:28,823] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240292: learning rate 0.0001
[2019-03-24 02:31:28,844] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240302: loss 0.2543
[2019-03-24 02:31:28,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240302: learning rate 0.0001
[2019-03-24 02:31:28,894] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240328: loss 0.1433
[2019-03-24 02:31:28,898] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240330: learning rate 0.0001
[2019-03-24 02:31:28,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1163804e-13 9.9994648e-01 3.7692065e-18 2.0340915e-06 5.1509214e-05], sum to 1.0000
[2019-03-24 02:31:28,940] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240351: loss 0.0832
[2019-03-24 02:31:28,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240353: learning rate 0.0001
[2019-03-24 02:31:28,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0730
[2019-03-24 02:31:28,954] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.3348279307541155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423978.2947817222, 423978.2947817222, 119966.2030870809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6739200.0000, 
sim time next is 6739800.0000, 
raw observation next is [20.41666666666667, 76.16666666666667, 1.0, 2.0, 0.3347053743663242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424096.9879644146, 424096.9879644146, 119952.8556046682], 
processed observation next is [1.0, 0.0, 0.31172839506172856, 0.7616666666666667, 1.0, 1.0, 0.20798258853133833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15146320998729093, 0.15146320998729093, 0.2306785684705158], 
reward next is 0.7693, 
noisyNet noise sample is [array([-1.6250049], dtype=float32), -0.27311113]. 
=============================================
[2019-03-24 02:31:29,132] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1240446: loss 0.0525
[2019-03-24 02:31:29,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1240447: learning rate 0.0001
[2019-03-24 02:31:29,138] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240447: loss 0.0263
[2019-03-24 02:31:29,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240447: learning rate 0.0001
[2019-03-24 02:31:29,230] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1240492: loss 0.0208
[2019-03-24 02:31:29,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1240494: learning rate 0.0001
[2019-03-24 02:31:29,285] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240519: loss 0.0191
[2019-03-24 02:31:29,290] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240522: learning rate 0.0001
[2019-03-24 02:31:29,733] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240737: loss 0.0767
[2019-03-24 02:31:29,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240737: learning rate 0.0001
[2019-03-24 02:31:29,821] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240780: loss 0.1408
[2019-03-24 02:31:29,823] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240780: learning rate 0.0001
[2019-03-24 02:31:30,325] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1241031: loss 0.0447
[2019-03-24 02:31:30,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1241031: learning rate 0.0001
[2019-03-24 02:31:32,072] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1241898: loss 0.1547
[2019-03-24 02:31:32,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1241898: learning rate 0.0001
[2019-03-24 02:31:33,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.32273557e-17 9.99969363e-01 1.02762626e-16 3.04088171e-05
 2.46488355e-07], sum to 1.0000
[2019-03-24 02:31:33,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2996
[2019-03-24 02:31:33,889] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 76.0, 1.0, 2.0, 0.3776883484977662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470924.6257695958, 470924.6257695958, 125581.8922766255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6841200.0000, 
sim time next is 6841800.0000, 
raw observation next is [21.8, 76.0, 1.0, 2.0, 0.3761919241859058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469256.3173579847, 469256.3173579847, 125380.7604996984], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.76, 1.0, 1.0, 0.2573713383165545, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16759154191356598, 0.16759154191356598, 0.2411168471148046], 
reward next is 0.7589, 
noisyNet noise sample is [array([0.33827752], dtype=float32), 0.66919965]. 
=============================================
[2019-03-24 02:31:40,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1099237e-20 9.9998415e-01 7.9940918e-18 1.4277595e-05 1.5076199e-06], sum to 1.0000
[2019-03-24 02:31:40,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2268
[2019-03-24 02:31:40,255] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 80.66666666666666, 1.0, 2.0, 0.4487509998773194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545846.3269574678, 545846.3269574678, 135429.732364164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6939600.0000, 
sim time next is 6940200.0000, 
raw observation next is [23.08333333333333, 80.33333333333334, 1.0, 2.0, 0.4517415931224061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548877.4606845522, 548877.4606845522, 135857.5047616914], 
processed observation next is [0.0, 0.30434782608695654, 0.41049382716049365, 0.8033333333333335, 1.0, 1.0, 0.3473114203838168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1960276645301972, 0.1960276645301972, 0.26126443223402196], 
reward next is 0.7387, 
noisyNet noise sample is [array([-0.19896175], dtype=float32), 0.66992784]. 
=============================================
[2019-03-24 02:31:41,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9907649e-14 9.9738938e-01 1.4192434e-14 2.5949960e-03 1.5707776e-05], sum to 1.0000
[2019-03-24 02:31:41,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9083
[2019-03-24 02:31:41,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 66.66666666666667, 1.0, 2.0, 0.4315750944132516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529509.7766815688, 529509.7766815693, 133027.1922884852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6991800.0000, 
sim time next is 6992400.0000, 
raw observation next is [24.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4305148063830414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 528386.3500231773, 528386.3500231769, 132877.0102742246], 
processed observation next is [0.0, 0.9565217391304348, 0.4567901234567903, 0.6733333333333335, 1.0, 1.0, 0.32204143617028735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18870941072256334, 0.18870941072256317, 0.2555327120658165], 
reward next is 0.7445, 
noisyNet noise sample is [array([0.63012683], dtype=float32), 0.98412913]. 
=============================================
[2019-03-24 02:31:42,354] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0233369e-15 9.9998605e-01 1.6030102e-15 1.2109174e-05 1.8442139e-06], sum to 1.0000
[2019-03-24 02:31:42,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1572
[2019-03-24 02:31:42,362] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 79.0, 1.0, 2.0, 0.4159142170483269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513231.1795302689, 513231.1795302689, 130834.512390661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7005600.0000, 
sim time next is 7006200.0000, 
raw observation next is [22.11666666666667, 79.66666666666667, 1.0, 2.0, 0.7945986060762406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.0442652705934, 980058.2135485086, 980058.2135485086, 197947.5896566149], 
processed observation next is [1.0, 0.08695652173913043, 0.3746913580246915, 0.7966666666666667, 1.0, 1.0, 0.7554745310431435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8102470043059856, 0.3500207905530388, 0.3500207905530388, 0.3806684416473364], 
reward next is 0.6193, 
noisyNet noise sample is [array([1.5733509], dtype=float32), -1.7615083]. 
=============================================
[2019-03-24 02:31:44,321] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1247949: loss 78.2626
[2019-03-24 02:31:44,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1247951: learning rate 0.0001
[2019-03-24 02:31:44,579] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1248072: loss 48.8019
[2019-03-24 02:31:44,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1248073: learning rate 0.0001
[2019-03-24 02:31:44,769] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1248168: loss 28.0923
[2019-03-24 02:31:44,771] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1248168: learning rate 0.0001
[2019-03-24 02:31:44,872] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248220: loss -2.3164
[2019-03-24 02:31:44,872] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248220: learning rate 0.0001
[2019-03-24 02:31:45,114] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248336: loss 63.1353
[2019-03-24 02:31:45,116] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248336: learning rate 0.0001
[2019-03-24 02:31:45,157] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1248360: loss 12.3129
[2019-03-24 02:31:45,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1248360: learning rate 0.0001
[2019-03-24 02:31:45,173] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248368: loss -1.2415
[2019-03-24 02:31:45,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248371: learning rate 0.0001
[2019-03-24 02:31:45,178] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248371: loss 49.3088
[2019-03-24 02:31:45,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248371: learning rate 0.0001
[2019-03-24 02:31:45,289] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248420: loss -8.1902
[2019-03-24 02:31:45,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248420: learning rate 0.0001
[2019-03-24 02:31:45,369] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248462: loss 10.9088
[2019-03-24 02:31:45,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248463: learning rate 0.0001
[2019-03-24 02:31:45,405] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1248477: loss -18.2618
[2019-03-24 02:31:45,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1248479: learning rate 0.0001
[2019-03-24 02:31:45,422] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248485: loss 77.6185
[2019-03-24 02:31:45,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248488: learning rate 0.0001
[2019-03-24 02:31:45,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248728: loss 10.0468
[2019-03-24 02:31:45,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248728: learning rate 0.0001
[2019-03-24 02:31:46,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248797: loss -26.2972
[2019-03-24 02:31:46,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248798: learning rate 0.0001
[2019-03-24 02:31:46,437] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248990: loss 17.0190
[2019-03-24 02:31:46,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248990: learning rate 0.0001
[2019-03-24 02:31:48,155] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1249836: loss 0.0078
[2019-03-24 02:31:48,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1249836: learning rate 0.0001
[2019-03-24 02:31:48,488] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 02:31:48,489] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:31:48,490] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:31:48,490] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:31:48,492] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:31:48,493] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:31:48,492] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:31:48,496] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:31:48,494] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:31:48,497] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:31:48,496] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:31:48,517] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-24 02:31:48,517] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-24 02:31:48,579] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-24 02:31:48,580] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-24 02:31:48,581] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-24 02:31:56,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:31:56,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.2615534903769774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 336600.7004948413, 336600.7004948408, 110950.9117465833]
[2019-03-24 02:31:56,958] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:31:56,962] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3101024e-13 9.9958831e-01 4.8840787e-13 3.8362210e-04 2.8119814e-05], sampled 0.6266466711219155
[2019-03-24 02:32:18,867] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:32:18,868] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.93333333333333, 52.0, 1.0, 2.0, 0.6418540036119921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743553.7620177243, 743553.7620177243, 166014.0341890864]
[2019-03-24 02:32:18,868] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:32:18,870] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4992823e-13 9.9968922e-01 1.6857623e-13 2.9141942e-04 1.9450717e-05], sampled 0.9883968682259054
[2019-03-24 02:32:20,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:32:20,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.1, 96.5, 1.0, 2.0, 0.4649914472316469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563720.9689343616, 563720.9689343616, 137813.5575080437]
[2019-03-24 02:32:20,464] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:32:20,467] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2860351e-13 9.9970132e-01 1.4448199e-13 2.8014835e-04 1.8448276e-05], sampled 0.3000938600745927
[2019-03-24 02:32:40,376] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:32:40,379] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.25694441, 53.50426851666667, 1.0, 2.0, 0.8541352273524159, 1.0, 2.0, 0.8541352273524159, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260424441657, 1948340.071786547, 1948340.071786548, 366632.3995365479]
[2019-03-24 02:32:40,380] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:32:40,383] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5634103e-13 9.9953997e-01 7.4583997e-13 4.2755521e-04 3.2515145e-05], sampled 0.30370988787535
[2019-03-24 02:32:40,383] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1948340.071786547 W.
[2019-03-24 02:32:56,577] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:32:56,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.80874752333334, 60.44429279333335, 1.0, 2.0, 0.5147554348206121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611548.1764356111, 611548.1764356111, 145142.4970332097]
[2019-03-24 02:32:56,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:32:56,581] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.11416870e-14 9.99727666e-01 1.02120976e-13 2.56043248e-04
 1.63503246e-05], sampled 0.8040668710729065
[2019-03-24 02:32:56,801] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:32:56,804] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.46666666666667, 67.0, 1.0, 2.0, 0.5620677160051537, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9101532817738673, 6.9112, 6.9112, 121.9260426156618, 1355862.497490284, 1355862.497490284, 277278.9078183893]
[2019-03-24 02:32:56,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:32:56,808] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4061178e-12 9.9923575e-01 5.0727556e-12 7.0116151e-04 6.3144988e-05], sampled 0.5272962191992456
[2019-03-24 02:32:56,810] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1355862.497490284 W.
[2019-03-24 02:33:19,107] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:33:19,110] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.86087634, 95.08052689, 1.0, 2.0, 0.4423678408016343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 554954.9098183402, 554954.9098183397, 134879.5359843872]
[2019-03-24 02:33:19,112] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:33:19,115] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0634683e-13 9.9962413e-01 3.4623053e-13 3.5099039e-04 2.4963159e-05], sampled 0.7296952724674509
[2019-03-24 02:33:21,527] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7845392]
[2019-03-24 02:33:21,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.2902260710208601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 370221.6292048049, 370221.6292048044, 114375.9609162352]
[2019-03-24 02:33:21,529] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:33:21,531] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8240951e-13 9.9963188e-01 3.1900453e-13 3.4377701e-04 2.4279496e-05], sampled 0.5508531304256099
[2019-03-24 02:33:25,790] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.7304 2445364202.2077 746.0000
[2019-03-24 02:33:26,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0859 2170634094.3912 493.0000
[2019-03-24 02:33:26,106] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8697.4540 2195116707.6508 572.0000
[2019-03-24 02:33:26,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.2139 2248722165.3892 553.0000
[2019-03-24 02:33:26,344] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4678 2120451862.8623 430.0000
[2019-03-24 02:33:27,360] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1250000, evaluation results [1250000.0, 8097.730431938878, 2445364202.207678, 746.0, 8771.085917099032, 2170634094.391242, 493.0, 8923.467760974505, 2120451862.8623226, 430.0, 8582.213906127852, 2248722165.3892393, 553.0, 8697.453965001472, 2195116707.6507535, 572.0]
[2019-03-24 02:33:32,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4880784e-19 1.0000000e+00 5.2833664e-20 5.3448826e-08 1.3829831e-09], sum to 1.0000
[2019-03-24 02:33:32,808] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6331
[2019-03-24 02:33:32,813] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.8038952463510833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 986767.8494391013, 986767.8494391008, 199761.6820791365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7221600.0000, 
sim time next is 7222200.0000, 
raw observation next is [24.0, 69.83333333333333, 1.0, 2.0, 0.9063937156213081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.987986366465219, 6.9112, 121.9257698447458, 1150310.213611499, 1110988.818863118, 222396.5984709193], 
processed observation next is [1.0, 0.6086956521739131, 0.4444444444444444, 0.6983333333333333, 1.0, 1.0, 0.888563947168224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.007678636646521931, 0.0, 0.8094603179049155, 0.41082507628982107, 0.39678172102254217, 0.4276857662902294], 
reward next is 0.1884, 
noisyNet noise sample is [array([0.22460452], dtype=float32), 0.29535884]. 
=============================================
[2019-03-24 02:33:37,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9816311e-15 9.9986112e-01 2.1561676e-14 1.3454576e-04 4.3102164e-06], sum to 1.0000
[2019-03-24 02:33:37,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3369
[2019-03-24 02:33:37,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1320035.429977299 W.
[2019-03-24 02:33:37,701] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 62.0, 1.0, 2.0, 0.5630975996939864, 1.0, 2.0, 0.5630975996939864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1320035.429977299, 1320035.4299773, 257261.2983854153], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [26.8, 62.0, 1.0, 2.0, 0.3801973322850456, 1.0, 2.0, 0.3801973322850456, 1.0, 1.0, 0.6065137277727788, 6.911199999999999, 6.9112, 121.94756008, 1323997.960942674, 1323997.960942674, 288578.4308158106], 
processed observation next is [1.0, 0.6086956521739131, 0.5481481481481482, 0.62, 1.0, 1.0, 0.26213968129172094, 1.0, 1.0, 0.26213968129172094, 1.0, 0.5, 0.5081421597159734, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.47285641462238354, 0.47285641462238354, 0.5549585207996358], 
reward next is 0.4450, 
noisyNet noise sample is [array([0.7718621], dtype=float32), 0.5637558]. 
=============================================
[2019-03-24 02:33:39,284] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1255868: loss 0.1615
[2019-03-24 02:33:39,287] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1255869: learning rate 0.0001
[2019-03-24 02:33:39,859] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1256148: loss 0.0094
[2019-03-24 02:33:39,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1256148: learning rate 0.0001
[2019-03-24 02:33:39,904] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256172: loss 0.0232
[2019-03-24 02:33:39,905] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256172: learning rate 0.0001
[2019-03-24 02:33:40,044] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256241: loss 0.0021
[2019-03-24 02:33:40,051] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256243: learning rate 0.0001
[2019-03-24 02:33:40,169] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256304: loss 0.0117
[2019-03-24 02:33:40,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256304: learning rate 0.0001
[2019-03-24 02:33:40,190] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256315: loss 0.0257
[2019-03-24 02:33:40,193] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256315: learning rate 0.0001
[2019-03-24 02:33:40,257] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1256350: loss 0.0034
[2019-03-24 02:33:40,258] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1256350: learning rate 0.0001
[2019-03-24 02:33:40,295] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256368: loss 0.0041
[2019-03-24 02:33:40,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256368: learning rate 0.0001
[2019-03-24 02:33:40,438] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1256443: loss 0.0795
[2019-03-24 02:33:40,440] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1256443: learning rate 0.0001
[2019-03-24 02:33:40,474] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256460: loss 0.2561
[2019-03-24 02:33:40,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256460: learning rate 0.0001
[2019-03-24 02:33:40,504] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256475: loss 0.3089
[2019-03-24 02:33:40,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256475: learning rate 0.0001
[2019-03-24 02:33:40,626] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256540: loss 0.2829
[2019-03-24 02:33:40,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256541: learning rate 0.0001
[2019-03-24 02:33:40,780] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256618: loss 0.1608
[2019-03-24 02:33:40,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256618: learning rate 0.0001
[2019-03-24 02:33:41,027] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256739: loss 0.0167
[2019-03-24 02:33:41,030] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256740: learning rate 0.0001
[2019-03-24 02:33:41,516] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256983: loss 0.0226
[2019-03-24 02:33:41,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256984: learning rate 0.0001
[2019-03-24 02:33:41,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0324207e-13 9.9735790e-01 2.0444813e-13 1.0300856e-03 1.6120197e-03], sum to 1.0000
[2019-03-24 02:33:41,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7276
[2019-03-24 02:33:41,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 92.5, 1.0, 2.0, 0.8501557459962151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1039262.091460317, 1039262.091460317, 209635.5744914916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7392600.0000, 
sim time next is 7393200.0000, 
raw observation next is [21.13333333333333, 92.33333333333333, 1.0, 2.0, 0.8563775635154556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1045746.05894753, 1045746.05894753, 210972.7082405446], 
processed observation next is [1.0, 0.5652173913043478, 0.33827160493827146, 0.9233333333333333, 1.0, 1.0, 0.8290209089469709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3734807353384036, 0.3734807353384036, 0.4057167466164319], 
reward next is 0.5943, 
noisyNet noise sample is [array([0.51161295], dtype=float32), 0.55107284]. 
=============================================
[2019-03-24 02:33:43,357] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1257884: loss -177.8486
[2019-03-24 02:33:43,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1257884: learning rate 0.0001
[2019-03-24 02:33:46,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3804902e-16 9.9999976e-01 2.8436471e-19 1.9534140e-07 2.1619908e-09], sum to 1.0000
[2019-03-24 02:33:46,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6949
[2019-03-24 02:33:46,165] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 84.0, 1.0, 2.0, 0.446704625465028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541789.3584816528, 541789.3584816528, 135077.3838553633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7468200.0000, 
sim time next is 7468800.0000, 
raw observation next is [22.86666666666667, 83.33333333333334, 1.0, 2.0, 0.4495048309900979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544509.3103551534, 544509.3103551534, 135472.5435487642], 
processed observation next is [0.0, 0.43478260869565216, 0.4024691358024693, 0.8333333333333335, 1.0, 1.0, 0.3446486083215452, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1944676108411262, 0.1944676108411262, 0.26052412220916193], 
reward next is 0.7395, 
noisyNet noise sample is [array([-1.354958], dtype=float32), -0.4238882]. 
=============================================
[2019-03-24 02:33:47,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8860026e-20 9.9999785e-01 3.6379354e-18 1.9099521e-06 2.4886000e-07], sum to 1.0000
[2019-03-24 02:33:47,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4149
[2019-03-24 02:33:47,337] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 78.0, 1.0, 2.0, 0.5199300058996031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615932.3355638115, 615932.3355638115, 145901.4905615465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7491600.0000, 
sim time next is 7492200.0000, 
raw observation next is [24.78333333333333, 78.66666666666667, 1.0, 2.0, 0.5185310200625776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614441.4705036068, 614441.4705036068, 145683.9262028838], 
processed observation next is [0.0, 0.7391304347826086, 0.4734567901234567, 0.7866666666666667, 1.0, 1.0, 0.42682264293163996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21944338232271673, 0.21944338232271673, 0.2801613965440073], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.26468933], dtype=float32), -0.6334953]. 
=============================================
[2019-03-24 02:33:50,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0195261e-14 9.9982709e-01 5.2795426e-16 1.3298404e-05 1.5962934e-04], sum to 1.0000
[2019-03-24 02:33:50,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0343
[2019-03-24 02:33:50,407] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 86.83333333333333, 1.0, 2.0, 0.4817097468288104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576662.2134818739, 576662.2134818734, 140127.9247231103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [23.3, 86.0, 1.0, 2.0, 0.4859719934882878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580847.5959282393, 580847.5959282388, 140753.2304730742], 
processed observation next is [0.0, 0.43478260869565216, 0.41851851851851857, 0.86, 1.0, 1.0, 0.3880618970098664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20744556997437116, 0.207445569974371, 0.27067928937129654], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.10213017], dtype=float32), 0.595811]. 
=============================================
[2019-03-24 02:33:55,472] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8949331e-11 9.9915624e-01 2.4407570e-11 2.1458817e-04 6.2908087e-04], sum to 1.0000
[2019-03-24 02:33:55,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4628
[2019-03-24 02:33:55,487] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 85.33333333333334, 1.0, 2.0, 0.8928720569332268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1080033.891940228, 1080033.891940228, 218803.3800703943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7636200.0000, 
sim time next is 7636800.0000, 
raw observation next is [22.93333333333333, 84.66666666666667, 1.0, 2.0, 0.8884462518652094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1071342.973196152, 1071342.973196152, 217673.5930311434], 
processed observation next is [1.0, 0.391304347826087, 0.40493827160493817, 0.8466666666666667, 1.0, 1.0, 0.867197918887154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3826224904271971, 0.3826224904271971, 0.4186030635214296], 
reward next is 0.5814, 
noisyNet noise sample is [array([-0.4328668], dtype=float32), 1.0092442]. 
=============================================
[2019-03-24 02:33:55,511] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1263913: loss -87.5558
[2019-03-24 02:33:55,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1263914: learning rate 0.0001
[2019-03-24 02:33:56,048] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264180: loss -38.4219
[2019-03-24 02:33:56,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264180: learning rate 0.0001
[2019-03-24 02:33:56,097] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264202: loss -61.8699
[2019-03-24 02:33:56,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264203: learning rate 0.0001
[2019-03-24 02:33:56,105] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264208: loss -32.8941
[2019-03-24 02:33:56,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264210: learning rate 0.0001
[2019-03-24 02:33:56,294] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264301: loss -4.8623
[2019-03-24 02:33:56,296] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264301: learning rate 0.0001
[2019-03-24 02:33:56,320] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264309: loss -34.5825
[2019-03-24 02:33:56,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264310: learning rate 0.0001
[2019-03-24 02:33:56,393] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264346: loss -36.0878
[2019-03-24 02:33:56,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264347: learning rate 0.0001
[2019-03-24 02:33:56,478] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264388: loss -9.1575
[2019-03-24 02:33:56,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264391: learning rate 0.0001
[2019-03-24 02:33:56,532] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264414: loss -13.1196
[2019-03-24 02:33:56,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264416: learning rate 0.0001
[2019-03-24 02:33:56,623] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264459: loss -12.5242
[2019-03-24 02:33:56,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264459: learning rate 0.0001
[2019-03-24 02:33:56,691] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264492: loss -3.1700
[2019-03-24 02:33:56,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264495: learning rate 0.0001
[2019-03-24 02:33:56,733] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264515: loss -6.4462
[2019-03-24 02:33:56,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264515: learning rate 0.0001
[2019-03-24 02:33:56,841] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264567: loss -49.4950
[2019-03-24 02:33:56,844] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264567: learning rate 0.0001
[2019-03-24 02:33:57,238] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264760: loss -67.2586
[2019-03-24 02:33:57,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264760: learning rate 0.0001
[2019-03-24 02:33:57,648] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264965: loss -30.8619
[2019-03-24 02:33:57,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264965: learning rate 0.0001
[2019-03-24 02:34:00,296] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:00,297] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:00,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-24 02:34:04,302] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9868412e-12 9.9820364e-01 7.8810482e-12 1.7764999e-03 1.9898303e-05], sum to 1.0000
[2019-03-24 02:34:04,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7455
[2019-03-24 02:34:04,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462208.481361526 W.
[2019-03-24 02:34:04,318] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 36.33333333333333, 1.0, 2.0, 0.6168449861149675, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9578220307728709, 6.911200000000001, 6.9112, 121.9260424312685, 1462208.481361526, 1462208.481361525, 291936.2012913673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7825200.0000, 
sim time next is 7825800.0000, 
raw observation next is [30.5, 36.66666666666667, 1.0, 2.0, 0.6056911799297472, 1.0, 1.0, 0.6056911799297472, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156056, 1458801.415238942, 1458801.415238942, 273361.2211050071], 
processed observation next is [1.0, 0.5652173913043478, 0.6851851851851852, 0.3666666666666667, 1.0, 1.0, 0.5305847380116038, 1.0, 0.5, 0.5305847380116038, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288197628, 0.5210005054424793, 0.5210005054424793, 0.5256946559711675], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5261083], dtype=float32), 0.38856417]. 
=============================================
[2019-03-24 02:34:12,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,040] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-24 02:34:12,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-24 02:34:12,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-24 02:34:12,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,689] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-24 02:34:12,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-24 02:34:12,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,805] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-24 02:34:12,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,828] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,842] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-24 02:34:12,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,884] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-24 02:34:12,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-24 02:34:12,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-24 02:34:12,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:12,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:12,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:13,004] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:13,003] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:34:13,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:13,001] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-24 02:34:13,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-24 02:34:13,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-24 02:34:13,177] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-24 02:34:13,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-24 02:34:18,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5539047e-11 1.2572734e-03 7.6165314e-08 9.9873835e-01 4.2510883e-06], sum to 1.0000
[2019-03-24 02:34:18,636] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3084
[2019-03-24 02:34:18,643] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.4, 77.0, 1.0, 2.0, 0.200948250649445, 1.0, 2.0, 0.200948250649445, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 498832.2206010259, 498832.2206010263, 160140.5628366322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 102600.0000, 
sim time next is 103200.0000, 
raw observation next is [21.3, 77.0, 1.0, 2.0, 0.1979155132939742, 1.0, 2.0, 0.1979155132939742, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491976.6283981489, 491976.6283981493, 159519.1156770576], 
processed observation next is [1.0, 0.17391304347826086, 0.3444444444444445, 0.77, 1.0, 1.0, 0.045137515826159755, 1.0, 1.0, 0.045137515826159755, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1757059387136246, 0.17570593871362475, 0.3067675301481877], 
reward next is 0.6932, 
noisyNet noise sample is [array([1.1545098], dtype=float32), -0.18283239]. 
=============================================
[2019-03-24 02:34:19,646] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 02:34:19,648] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:34:19,648] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:34:19,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:19,650] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:34:19,650] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:19,650] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:34:19,651] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:19,652] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:34:19,652] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:19,653] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:34:19,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-24 02:34:19,701] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-24 02:34:19,728] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-24 02:34:19,753] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-24 02:34:19,790] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-24 02:34:35,154] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:34:35,155] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.05452511833333, 61.28273186333334, 1.0, 2.0, 0.1680753167530403, 1.0, 2.0, 0.1680753167530403, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421950.4470583408, 421950.4470583412, 153436.5515703029]
[2019-03-24 02:34:35,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:34:35,158] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0221981e-12 6.5064977e-04 2.2086650e-09 9.9932134e-01 2.8008286e-05], sampled 0.8091454717863015
[2019-03-24 02:34:39,248] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:34:39,249] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.05657406666667, 28.33720985, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406273.7697142545, 406273.7697142545, 151035.3514243043]
[2019-03-24 02:34:39,250] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:34:39,252] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4015011e-13 3.6488599e-04 5.1480531e-10 9.9962187e-01 1.3278429e-05], sampled 0.813183035065495
[2019-03-24 02:35:03,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:03,139] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.775895165, 83.96906157333333, 1.0, 2.0, 0.3459933864307238, 1.0, 2.0, 0.3459933864307238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796381.9856023703, 796381.9856023708, 192236.3434760789]
[2019-03-24 02:35:03,140] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:35:03,142] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.7280571e-13 5.1984895e-04 1.2551713e-09 9.9945921e-01 2.0966108e-05], sampled 0.18391320684809087
[2019-03-24 02:35:26,037] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:26,038] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.1166875, 92.22293540999999, 1.0, 2.0, 0.2711632366938945, 1.0, 2.0, 0.2711632366938945, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633403.2829052634, 633403.2829052634, 174431.4081288176]
[2019-03-24 02:35:26,038] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:35:26,042] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8714179e-13 4.9045711e-04 1.0841039e-09 9.9949014e-01 1.9449108e-05], sampled 0.8589539376053938
[2019-03-24 02:35:33,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:33,507] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 86.33333333333334, 1.0, 2.0, 0.2384846693105794, 1.0, 2.0, 0.2384846693105794, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 570488.965311004, 570488.9653110044, 167616.9778818985]
[2019-03-24 02:35:33,508] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:35:33,510] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1762620e-12 6.7782769e-04 2.4481845e-09 9.9929261e-01 2.9526835e-05], sampled 0.8920699015125527
[2019-03-24 02:35:36,050] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:36,051] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666666, 67.33333333333333, 1.0, 2.0, 0.3288176262153713, 1.0, 2.0, 0.3288176262153713, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749494.5436980246, 749494.543698025, 187520.7029621121]
[2019-03-24 02:35:36,053] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:35:36,057] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6106115e-13 5.1607320e-04 1.2322614e-09 9.9946326e-01 2.0769414e-05], sampled 0.7014897078567288
[2019-03-24 02:35:43,365] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:43,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.64857555, 56.89225388999999, 1.0, 2.0, 0.2463208648310959, 1.0, 2.0, 0.2463208648310959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584873.0897030265, 584873.0897030269, 169193.7438062965]
[2019-03-24 02:35:43,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:35:43,373] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0626418e-12 6.5806060e-04 2.2724425e-09 9.9931347e-01 2.8420682e-05], sampled 0.48606480193239887
[2019-03-24 02:35:56,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.5613 2668433942.5274 68.0000
[2019-03-24 02:35:57,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.79476804]
[2019-03-24 02:35:57,468] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.04322654166667, 48.434146625, 1.0, 2.0, 0.22593856051672, 1.0, 2.0, 0.22593856051672, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 554135.7741047298, 554135.7741047293, 165340.3510649998]
[2019-03-24 02:35:57,468] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:35:57,471] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.2446164e-13 5.6372373e-04 1.5391174e-09 9.9941301e-01 2.3276512e-05], sampled 0.18328991570035047
[2019-03-24 02:35:57,613] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.4821 2495361042.0403 47.0000
[2019-03-24 02:35:57,629] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.6888 2438643371.2520 33.0000
[2019-03-24 02:35:57,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7472.8831 2465640587.4354 47.0000
[2019-03-24 02:35:57,729] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.0679 2410626207.8958 22.0000
[2019-03-24 02:35:58,747] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1275000, evaluation results [1275000.0, 7522.56128009868, 2668433942.527354, 68.0, 7120.688845489337, 2438643371.251983, 33.0, 7797.067905160829, 2410626207.895825, 22.0, 6905.4820630314625, 2495361042.040276, 47.0, 7472.883066694829, 2465640587.435405, 47.0]
[2019-03-24 02:36:01,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0427693e-15 1.7420053e-04 1.7547475e-13 9.9982399e-01 1.8098135e-06], sum to 1.0000
[2019-03-24 02:36:01,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3267
[2019-03-24 02:36:01,794] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.71666666666667, 13.66666666666667, 1.0, 2.0, 0.1826121946558125, 1.0, 2.0, 0.1826121946558125, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 471109.7231940877, 471109.7231940881, 155748.5745051709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 162600.0000, 
sim time next is 163200.0000, 
raw observation next is [31.63333333333334, 13.33333333333333, 1.0, 2.0, 0.180825943557997, 1.0, 2.0, 0.180825943557997, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466543.6017816181, 466543.6017816185, 153180.6702691168], 
processed observation next is [1.0, 0.9130434782608695, 0.7271604938271607, 0.1333333333333333, 1.0, 1.0, 0.024792789949996424, 1.0, 1.0, 0.024792789949996424, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16662271492200645, 0.16662271492200662, 0.2945782120559938], 
reward next is 0.7054, 
noisyNet noise sample is [array([-0.08350406], dtype=float32), -0.4058031]. 
=============================================
[2019-03-24 02:36:02,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7112531e-17 1.9248513e-05 1.3972145e-13 9.9998021e-01 5.8448205e-07], sum to 1.0000
[2019-03-24 02:36:02,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-24 02:36:02,661] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.63333333333334, 13.33333333333333, 1.0, 2.0, 0.180825943557997, 1.0, 2.0, 0.180825943557997, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466543.6017816181, 466543.6017816185, 153180.6702691168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 163200.0000, 
sim time next is 163800.0000, 
raw observation next is [31.55, 13.0, 1.0, 2.0, 0.1796992561652482, 1.0, 2.0, 0.1796992561652482, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463635.8160297151, 463635.8160297155, 151140.3132326923], 
processed observation next is [1.0, 0.9130434782608695, 0.7240740740740741, 0.13, 1.0, 1.0, 0.02345149543481929, 1.0, 1.0, 0.02345149543481929, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16558422001061254, 0.16558422001061268, 0.2906544485244083], 
reward next is 0.7093, 
noisyNet noise sample is [array([-0.2465846], dtype=float32), 0.30672836]. 
=============================================
[2019-03-24 02:36:09,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0619483e-23 9.9285889e-01 2.7232107e-18 7.1411459e-03 7.9588029e-12], sum to 1.0000
[2019-03-24 02:36:09,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-24 02:36:09,655] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 32.0, 1.0, 2.0, 0.2978803236302427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384255.4609591938, 384255.4609591938, 103190.7185487567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 293400.0000, 
sim time next is 294000.0000, 
raw observation next is [25.06666666666667, 31.66666666666666, 1.0, 2.0, 0.3004322919857179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387548.2449174193, 387548.2449174193, 103756.6038384358], 
processed observation next is [0.0, 0.391304347826087, 0.4839506172839507, 0.3166666666666666, 1.0, 1.0, 0.16718129998299752, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13841008747050687, 0.13841008747050687, 0.19953193045853038], 
reward next is 0.8005, 
noisyNet noise sample is [array([0.2909553], dtype=float32), 1.0701501]. 
=============================================
[2019-03-24 02:36:09,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[98.23467 ]
 [98.14571 ]
 [98.04835 ]
 [98.003815]
 [97.875465]], R is [[98.13105011]
 [97.95130157]
 [97.77438354]
 [97.59983063]
 [97.42782593]].
[2019-03-24 02:36:09,908] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4435478e-18 9.9998510e-01 1.2738544e-14 1.4905822e-05 4.6034128e-09], sum to 1.0000
[2019-03-24 02:36:09,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9408
[2019-03-24 02:36:09,925] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 29.33333333333333, 1.0, 2.0, 0.3066636552112818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395588.581481632, 395588.581481632, 106371.3755917808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 298200.0000, 
sim time next is 298800.0000, 
raw observation next is [26.1, 29.0, 1.0, 2.0, 0.3077439914011608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 396982.5493317747, 396982.5493317743, 106792.2689551882], 
processed observation next is [0.0, 0.4782608695652174, 0.5222222222222223, 0.29, 1.0, 1.0, 0.17588570404900097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14177948190420525, 0.1417794819042051, 0.20536974799074656], 
reward next is 0.7946, 
noisyNet noise sample is [array([2.3200917], dtype=float32), 0.8603785]. 
=============================================
[2019-03-24 02:36:10,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2516343e-17 9.9995458e-01 1.8515100e-15 4.5368568e-05 4.1033816e-09], sum to 1.0000
[2019-03-24 02:36:10,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3296
[2019-03-24 02:36:10,091] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 29.33333333333333, 1.0, 2.0, 0.3066636552112818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395588.581481632, 395588.581481632, 106371.3755917808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 298200.0000, 
sim time next is 298800.0000, 
raw observation next is [26.1, 29.0, 1.0, 2.0, 0.3077439914011608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 396982.5493317747, 396982.5493317743, 106792.2689551882], 
processed observation next is [0.0, 0.4782608695652174, 0.5222222222222223, 0.29, 1.0, 1.0, 0.17588570404900097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14177948190420525, 0.1417794819042051, 0.20536974799074656], 
reward next is 0.7946, 
noisyNet noise sample is [array([-0.7233988], dtype=float32), 1.6453583]. 
=============================================
[2019-03-24 02:36:15,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9739139e-11 9.6105212e-01 2.6601435e-07 3.7436884e-02 1.5108142e-03], sum to 1.0000
[2019-03-24 02:36:15,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8753
[2019-03-24 02:36:15,053] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 37.33333333333334, 1.0, 2.0, 0.3163184085753277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403567.0707129933, 403567.0707129933, 117615.3130906125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423600.0000, 
sim time next is 424200.0000, 
raw observation next is [26.53333333333333, 37.66666666666666, 1.0, 2.0, 0.3149462239385354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401978.4640544046, 401978.4640544046, 117442.3954273157], 
processed observation next is [1.0, 0.9130434782608695, 0.5382716049382715, 0.3766666666666666, 1.0, 1.0, 0.18445979040301833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14356373716228735, 0.14356373716228735, 0.22585076043714558], 
reward next is 0.7741, 
noisyNet noise sample is [array([-1.5315219], dtype=float32), 1.8332441]. 
=============================================
[2019-03-24 02:36:16,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7478728e-08 5.1527679e-01 3.2230218e-05 4.6254417e-01 2.2146793e-02], sum to 1.0000
[2019-03-24 02:36:16,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2070
[2019-03-24 02:36:16,773] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 66.33333333333334, 1.0, 2.0, 0.3789120870673118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486698.5514011913, 486698.5514011913, 125879.9536945464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 440400.0000, 
sim time next is 441000.0000, 
raw observation next is [20.15, 67.0, 1.0, 2.0, 0.3244512574360005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 417013.0308456767, 417013.0308456763, 118646.8910213209], 
processed observation next is [1.0, 0.08695652173913043, 0.3018518518518518, 0.67, 1.0, 1.0, 0.19577530647142918, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1489332253020274, 0.14893322530202727, 0.22816709811792482], 
reward next is 0.7718, 
noisyNet noise sample is [array([-1.6593903], dtype=float32), -0.061414212]. 
=============================================
[2019-03-24 02:36:16,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[40.13162 ]
 [39.86717 ]
 [39.801548]
 [39.500774]
 [39.863346]], R is [[41.20492172]
 [41.55079651]
 [41.8665657 ]
 [41.44789886]
 [41.03342056]].
[2019-03-24 02:36:21,222] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3444247e-11 5.4942751e-03 1.5620083e-04 9.8884940e-01 5.5001606e-03], sum to 1.0000
[2019-03-24 02:36:21,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3682
[2019-03-24 02:36:21,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4069672e-10 2.2964973e-02 8.1884164e-06 9.5738006e-01 1.9646814e-02], sum to 1.0000
[2019-03-24 02:36:21,233] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.26666666666667, 55.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 398967.7801920803, 398967.7801920808, 150981.0708037172], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 516000.0000, 
sim time next is 516600.0000, 
raw observation next is [23.1, 56.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398976.6811603922, 398976.6811603922, 150987.828909941], 
processed observation next is [1.0, 1.0, 0.41111111111111115, 0.56, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14249167184299721, 0.14249167184299721, 0.29036120944219423], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1020844], dtype=float32), 0.36364874]. 
=============================================
[2019-03-24 02:36:21,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6169
[2019-03-24 02:36:21,244] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 56.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398976.6811603922, 398976.6811603922, 150987.8289117313], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 516600.0000, 
sim time next is 517200.0000, 
raw observation next is [22.93333333333333, 57.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398616.4628994123, 398616.4628994118, 150938.4020642245], 
processed observation next is [1.0, 1.0, 0.40493827160493817, 0.57, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14236302246407584, 0.14236302246407564, 0.29026615781581633], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.897226], dtype=float32), -1.4261459]. 
=============================================
[2019-03-24 02:36:25,142] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5446395e-16 2.4176261e-05 3.2965424e-09 9.9995995e-01 1.5848724e-05], sum to 1.0000
[2019-03-24 02:36:25,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7937
[2019-03-24 02:36:25,159] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 36.33333333333333, 1.0, 2.0, 0.1927349715430807, 1.0, 2.0, 0.1927349715430807, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475173.9947923815, 475173.9947923819, 158328.261946944], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 589200.0000, 
sim time next is 589800.0000, 
raw observation next is [29.65, 36.66666666666667, 1.0, 2.0, 0.192087816908893, 1.0, 2.0, 0.192087816908893, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473888.8460095005, 473888.846009501, 158202.9799793139], 
processed observation next is [1.0, 0.8260869565217391, 0.6537037037037037, 0.3666666666666667, 1.0, 1.0, 0.03819978203439644, 1.0, 1.0, 0.03819978203439644, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16924601643196446, 0.16924601643196466, 0.30423649996021906], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.55021346], dtype=float32), 0.6681121]. 
=============================================
[2019-03-24 02:36:33,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5446784e-13 1.5892028e-05 1.4784850e-08 9.9998307e-01 1.0841335e-06], sum to 1.0000
[2019-03-24 02:36:33,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8112
[2019-03-24 02:36:33,173] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.16666666666667, 23.0, 1.0, 2.0, 0.503000147776918, 1.0, 2.0, 0.503000147776918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1247459.541097456, 1247459.541097457, 240081.6716430794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 742800.0000, 
sim time next is 743400.0000, 
raw observation next is [32.15000000000001, 23.0, 1.0, 2.0, 0.4985938555066737, 1.0, 2.0, 0.4985938555066737, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1237041.904898489, 1237041.904898489, 238693.8676791554], 
processed observation next is [1.0, 0.6086956521739131, 0.7462962962962968, 0.23, 1.0, 1.0, 0.4030879232222305, 1.0, 1.0, 0.4030879232222305, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44180068032088887, 0.44180068032088887, 0.4590266686137604], 
reward next is 0.5410, 
noisyNet noise sample is [array([-0.09662715], dtype=float32), 2.2467308]. 
=============================================
[2019-03-24 02:36:38,572] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9431569e-16 2.0904904e-03 3.4339596e-06 9.9787664e-01 2.9400815e-05], sum to 1.0000
[2019-03-24 02:36:38,581] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2419
[2019-03-24 02:36:38,586] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 37.33333333333334, 1.0, 2.0, 0.221414275381624, 1.0, 2.0, 0.221414275381624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534146.7608772811, 534146.7608772815, 164048.1155488683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 822000.0000, 
sim time next is 822600.0000, 
raw observation next is [31.5, 37.0, 1.0, 2.0, 0.2227780078146298, 1.0, 2.0, 0.2227780078146298, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536928.9737933243, 536928.9737933243, 164325.1160295072], 
processed observation next is [0.0, 0.5217391304347826, 0.7222222222222222, 0.37, 1.0, 1.0, 0.074735723588845, 1.0, 1.0, 0.074735723588845, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19176034778333012, 0.19176034778333012, 0.31600983851828307], 
reward next is 0.6840, 
noisyNet noise sample is [array([0.2680366], dtype=float32), 0.8104459]. 
=============================================
[2019-03-24 02:36:43,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2526143e-16 1.6572791e-05 5.7050928e-09 9.9998307e-01 3.2420542e-07], sum to 1.0000
[2019-03-24 02:36:43,459] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4612
[2019-03-24 02:36:43,463] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 44.5, 1.0, 2.0, 0.1920831359243624, 1.0, 2.0, 0.1920831359243624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475027.706693118, 475027.7066931185, 158234.9987335148], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 928200.0000, 
sim time next is 928800.0000, 
raw observation next is [27.3, 45.0, 1.0, 2.0, 0.1916159976218752, 1.0, 2.0, 0.1916159976218752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474163.383506585, 474163.383506585, 158146.1056709161], 
processed observation next is [0.0, 0.782608695652174, 0.5666666666666667, 0.45, 1.0, 1.0, 0.037638092406994283, 1.0, 1.0, 0.037638092406994283, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16934406553806608, 0.16934406553806608, 0.30412712629022326], 
reward next is 0.6959, 
noisyNet noise sample is [array([-1.4612026], dtype=float32), 0.17967404]. 
=============================================
[2019-03-24 02:36:49,484] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 02:36:49,485] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:36:49,485] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:36:49,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:36:49,487] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:36:49,486] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:36:49,488] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:36:49,487] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:36:49,492] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:36:49,493] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:36:49,493] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:36:49,516] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-24 02:36:49,545] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-24 02:36:49,546] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-24 02:36:49,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-24 02:36:49,585] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-24 02:36:59,433] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:36:59,435] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.0, 30.0, 1.0, 2.0, 0.6114625245721601, 1.0, 2.0, 0.6114625245721601, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1461370.434678368, 1461370.434678369, 274985.2883588409]
[2019-03-24 02:36:59,436] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:36:59,438] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.1484862e-08 5.0657928e-01 4.7330096e-04 4.9231148e-01 6.3588220e-04], sampled 0.027233149220044273
[2019-03-24 02:36:59,440] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1461370.434678368 W.
[2019-03-24 02:37:03,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:37:03,782] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 53.5, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 316143.6677664607, 316143.6677664611, 133631.7987658717]
[2019-03-24 02:37:03,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:37:03,787] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.7968783e-06 5.8431816e-01 3.0006994e-03 4.0944433e-01 3.2320283e-03], sampled 0.7336724511950383
[2019-03-24 02:37:12,953] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:37:12,954] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.48333333333333, 90.16666666666667, 1.0, 2.0, 0.3177609826366223, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402980.9734693601, 402980.9734693601, 117783.4599211288]
[2019-03-24 02:37:12,955] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:37:12,958] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0298219e-06 5.7914144e-01 2.7982115e-03 4.1501287e-01 3.0435047e-03], sampled 0.11206263647573589
[2019-03-24 02:37:43,163] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:37:43,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.58333333333334, 73.0, 1.0, 2.0, 0.5111250109604406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606291.8354252224, 606291.8354252224, 144527.7147744317]
[2019-03-24 02:37:43,165] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:37:43,167] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.0223153e-07 5.5333287e-01 1.4873646e-03 4.4343761e-01 1.7413034e-03], sampled 0.13325359371330425
[2019-03-24 02:37:48,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:37:48,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.795705745, 74.02639816, 1.0, 2.0, 0.6773233941019317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771944.0474418211, 771944.0474418211, 171897.6685443282]
[2019-03-24 02:37:48,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:37:48,596] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6758695e-08 5.0954866e-01 5.2095111e-04 4.8923737e-01 6.9290044e-04], sampled 0.8603300266675464
[2019-03-24 02:38:04,460] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:38:04,461] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.94439164, 83.566079835, 1.0, 2.0, 0.3164409740027268, 1.0, 2.0, 0.3164409740027268, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721270.3952778698, 721270.3952778702, 184452.9487318045]
[2019-03-24 02:38:04,462] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:38:04,465] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4282833e-06 5.6235868e-01 1.8028740e-03 4.3377703e-01 2.0599631e-03], sampled 0.7047995599669183
[2019-03-24 02:38:09,199] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7946448]
[2019-03-24 02:38:09,199] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333334, 86.33333333333334, 1.0, 2.0, 0.520313656331924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620681.2214228783, 620681.2214228783, 146126.5639426999]
[2019-03-24 02:38:09,200] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:38:09,204] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.4414801e-07 5.4372329e-01 1.2018291e-03 4.5362937e-01 1.4449717e-03], sampled 0.7360310352017694
[2019-03-24 02:38:27,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6318.9234 2254409517.8080 255.0000
[2019-03-24 02:38:27,228] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 5952.8166 2290280205.9534 293.0000
[2019-03-24 02:38:27,295] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5924.3869 2547945635.3473 497.0000
[2019-03-24 02:38:27,372] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5828.4862 2362992824.9205 361.0000
[2019-03-24 02:38:27,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6093.2172 2320880713.3866 344.0000
[2019-03-24 02:38:28,404] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1300000, evaluation results [1300000.0, 5924.386857331674, 2547945635.347313, 497.0, 5952.816569162086, 2290280205.953363, 293.0, 6318.923377707344, 2254409517.8080482, 255.0, 5828.486150310853, 2362992824.920519, 361.0, 6093.217227697438, 2320880713.3865767, 344.0]
[2019-03-24 02:38:30,733] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0602202e-17 9.9817944e-01 2.7028042e-09 1.8206320e-03 1.0431096e-09], sum to 1.0000
[2019-03-24 02:38:30,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2863
[2019-03-24 02:38:30,747] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 64.0, 1.0, 2.0, 0.2835325650198129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363959.7611884105, 363959.7611884105, 113563.9102683237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1395000.0000, 
sim time next is 1395600.0000, 
raw observation next is [20.76666666666667, 63.66666666666667, 1.0, 2.0, 0.2804720131479989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360282.7635492733, 360282.7635492733, 113194.4452493282], 
processed observation next is [0.0, 0.13043478260869565, 0.32469135802469146, 0.6366666666666667, 1.0, 1.0, 0.14341906327142728, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1286724155533119, 0.1286724155533119, 0.2176816254794773], 
reward next is 0.7823, 
noisyNet noise sample is [array([-0.01845363], dtype=float32), 0.48813105]. 
=============================================
[2019-03-24 02:38:35,358] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4295987e-16 9.9959093e-01 2.0197295e-08 4.0911717e-04 1.4869780e-09], sum to 1.0000
[2019-03-24 02:38:35,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5830
[2019-03-24 02:38:35,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 81.0, 1.0, 2.0, 0.3475096675432442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438048.4804608754, 438048.4804608754, 121603.2986556565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1192800.0000, 
sim time next is 1193400.0000, 
raw observation next is [20.2, 81.5, 1.0, 2.0, 0.3474305155465945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437959.4448598127, 437959.4448598127, 121592.9953803159], 
processed observation next is [1.0, 0.8260869565217391, 0.3037037037037037, 0.815, 1.0, 1.0, 0.2231315661268982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1564140874499331, 0.1564140874499331, 0.23383268342368443], 
reward next is 0.7662, 
noisyNet noise sample is [array([0.74957037], dtype=float32), -0.28389016]. 
=============================================
[2019-03-24 02:38:39,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1552785e-16 9.9321657e-01 8.0177120e-10 6.7834328e-03 3.6081169e-09], sum to 1.0000
[2019-03-24 02:38:39,111] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-24 02:38:39,114] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 86.83333333333334, 1.0, 2.0, 0.3589442947429838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453787.9137586771, 453787.9137586775, 123138.9932620744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1239000.0000, 
sim time next is 1239600.0000, 
raw observation next is [19.5, 85.66666666666667, 1.0, 2.0, 0.4970114902677935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627773.3200402112, 627773.3200402112, 143332.1610441149], 
processed observation next is [1.0, 0.34782608695652173, 0.2777777777777778, 0.8566666666666667, 1.0, 1.0, 0.4012041550807066, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2242047571572183, 0.2242047571572183, 0.2756387712386825], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.17757909], dtype=float32), 1.6558844]. 
=============================================
[2019-03-24 02:38:45,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6823795e-18 1.0000000e+00 1.3775610e-11 1.3330221e-08 3.1903939e-12], sum to 1.0000
[2019-03-24 02:38:45,235] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6995
[2019-03-24 02:38:45,239] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 62.33333333333334, 1.0, 2.0, 0.3567125890707269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447839.8186637912, 447839.8186637912, 122799.2689491714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1376400.0000, 
sim time next is 1377000.0000, 
raw observation next is [23.15, 63.5, 1.0, 2.0, 0.3563243196673936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 447465.9499623749, 447465.9499623745, 122749.1923845047], 
processed observation next is [1.0, 0.9565217391304348, 0.4129629629629629, 0.635, 1.0, 1.0, 0.23371942817546856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15980926784370533, 0.1598092678437052, 0.23605613920097057], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.35171595], dtype=float32), 0.8984439]. 
=============================================
[2019-03-24 02:38:45,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.083294]
 [61.100197]
 [61.134342]
 [61.131836]
 [61.143364]], R is [[61.23205185]
 [61.38357925]
 [61.53334427]
 [61.68122864]
 [61.82697678]].
[2019-03-24 02:38:52,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8726214e-22 1.0000000e+00 1.1125760e-15 3.8200593e-10 9.1732177e-14], sum to 1.0000
[2019-03-24 02:38:52,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5578
[2019-03-24 02:38:52,984] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.53333333333333, 39.0, 1.0, 2.0, 0.4352515093201046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532294.248256023, 532294.248256023, 133518.75373278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1503600.0000, 
sim time next is 1504200.0000, 
raw observation next is [30.86666666666667, 38.0, 1.0, 2.0, 0.4385223940285022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535892.0774215152, 535892.0774215152, 133988.3035383107], 
processed observation next is [0.0, 0.391304347826087, 0.6987654320987656, 0.38, 1.0, 1.0, 0.33157427860535976, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19139002765054117, 0.19139002765054117, 0.2576698144967513], 
reward next is 0.7423, 
noisyNet noise sample is [array([-1.5176231], dtype=float32), 0.39350837]. 
=============================================
[2019-03-24 02:38:53,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2155730e-28 1.0000000e+00 5.8705499e-20 3.9376387e-14 1.5881482e-18], sum to 1.0000
[2019-03-24 02:38:53,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-24 02:38:53,221] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 37.0, 1.0, 2.0, 0.4414443186797329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 539102.6298717994, 539102.6298717989, 134409.1585452934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1504800.0000, 
sim time next is 1505400.0000, 
raw observation next is [31.55, 36.0, 1.0, 2.0, 0.443436040795871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541142.9888488117, 541142.9888488117, 134692.5941756158], 
processed observation next is [0.0, 0.43478260869565216, 0.7240740740740741, 0.36, 1.0, 1.0, 0.33742385809032266, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1932653531602899, 0.1932653531602899, 0.259024219568492], 
reward next is 0.7410, 
noisyNet noise sample is [array([2.886221], dtype=float32), 0.42133442]. 
=============================================
[2019-03-24 02:38:58,376] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9855921e-15 9.9999833e-01 4.2366474e-10 1.6261242e-06 1.2533399e-10], sum to 1.0000
[2019-03-24 02:38:58,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9448
[2019-03-24 02:38:58,393] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 52.5, 1.0, 2.0, 0.9181770293864833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.138986687876633, 6.9112, 121.9249451929859, 1255653.744205626, 1139007.650578415, 225515.5943807279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596600.0000, 
sim time next is 1597200.0000, 
raw observation next is [26.13333333333333, 52.0, 1.0, 2.0, 0.9235776555241131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.176754270788921, 6.9112, 121.9246801997987, 1282001.829764493, 1146015.827689647, 226784.3093999608], 
processed observation next is [1.0, 0.4782608695652174, 0.5234567901234567, 0.52, 1.0, 1.0, 0.909021018481087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02655542707889209, 0.0, 0.8094530837956176, 0.4578577963444618, 0.4092913670320168, 0.43612367192300155], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.77580166], dtype=float32), 1.6570915]. 
=============================================
[2019-03-24 02:38:58,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7159897e-15 9.9999976e-01 2.8351629e-10 1.9259960e-07 1.6421853e-09], sum to 1.0000
[2019-03-24 02:38:58,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5093
[2019-03-24 02:38:58,531] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 56.0, 1.0, 2.0, 0.9157873801037628, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.130967067483772, 6.9112, 121.9250544663935, 1250058.815908844, 1137519.346882755, 224996.2524210156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1591200.0000, 
sim time next is 1591800.0000, 
raw observation next is [25.13333333333334, 55.66666666666667, 1.0, 2.0, 0.9040971080534733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.067632028147134, 6.9112, 121.9250854645901, 1205874.820797781, 1125768.269512579, 222357.4792868576], 
processed observation next is [1.0, 0.43478260869565216, 0.48641975308642, 0.5566666666666668, 1.0, 1.0, 0.8858298905398492, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.01564320281471341, 0.0, 0.8094557743323868, 0.4306695788563504, 0.4020600962544925, 0.42761053709011076], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5571093], dtype=float32), 0.16925968]. 
=============================================
[2019-03-24 02:38:58,808] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4706915e-13 9.9999905e-01 6.6641921e-11 9.6266672e-07 1.6287839e-08], sum to 1.0000
[2019-03-24 02:38:58,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-24 02:38:58,821] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 53.00000000000001, 1.0, 2.0, 0.9100976290273736, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.042278705030012, 6.9112, 121.9254179188628, 1188186.8594633, 1121063.1907209, 223418.2195527547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596000.0000, 
sim time next is 1596600.0000, 
raw observation next is [26.05, 52.5, 1.0, 2.0, 0.9182325219213644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.138931474735204, 6.9112, 121.9249455254188, 1255615.22552266, 1138997.405386306, 225526.4577587832], 
processed observation next is [1.0, 0.4782608695652174, 0.5203703703703704, 0.525, 1.0, 1.0, 0.9026577641921004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02277314747352044, 0.0, 0.8094548452818159, 0.4484340091152357, 0.4067847876379665, 0.43370472645919844], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2469512], dtype=float32), 1.3694628]. 
=============================================
[2019-03-24 02:39:02,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0473936e-18 9.9999988e-01 3.9467531e-13 6.7337922e-08 1.2828424e-12], sum to 1.0000
[2019-03-24 02:39:02,570] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-24 02:39:02,579] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 88.33333333333334, 1.0, 2.0, 0.3198285374633505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407892.3619867942, 407892.3619867942, 118059.9253192836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1665600.0000, 
sim time next is 1666200.0000, 
raw observation next is [18.35, 88.16666666666667, 1.0, 2.0, 0.3255112126296354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415000.7290615857, 415000.7290615857, 118784.5599321794], 
processed observation next is [1.0, 0.2608695652173913, 0.23518518518518525, 0.8816666666666667, 1.0, 1.0, 0.1970371578924231, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14821454609342347, 0.14821454609342347, 0.22843184602342193], 
reward next is 0.7716, 
noisyNet noise sample is [array([2.2773356], dtype=float32), -0.50003093]. 
=============================================
[2019-03-24 02:39:07,606] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4898576e-18 9.9998057e-01 7.4688322e-10 1.9444218e-05 4.1342957e-11], sum to 1.0000
[2019-03-24 02:39:07,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8095
[2019-03-24 02:39:07,619] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 80.66666666666667, 1.0, 2.0, 0.3878713943317872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482502.2868317083, 482502.2868317083, 126964.7539012021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1752000.0000, 
sim time next is 1752600.0000, 
raw observation next is [21.55, 79.83333333333334, 1.0, 2.0, 0.3917666191467478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487099.6334474399, 487099.6334474399, 127501.7593080895], 
processed observation next is [1.0, 0.2608695652173913, 0.35370370370370374, 0.7983333333333335, 1.0, 1.0, 0.27591264184136644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1739641548026571, 0.1739641548026571, 0.2451956909770952], 
reward next is 0.7548, 
noisyNet noise sample is [array([1.2996145], dtype=float32), -0.008349802]. 
=============================================
[2019-03-24 02:39:11,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2218587e-17 9.9699283e-01 6.6845829e-10 3.0071265e-03 2.5637714e-10], sum to 1.0000
[2019-03-24 02:39:11,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-24 02:39:11,684] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 83.0, 1.0, 2.0, 0.3629908797728466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457155.5864622861, 457155.5864622861, 123661.5328101723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837800.0000, 
sim time next is 1838400.0000, 
raw observation next is [20.23333333333333, 82.33333333333334, 1.0, 2.0, 0.3586523463831733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451444.6773719257, 451444.6773719257, 123075.6441675862], 
processed observation next is [1.0, 0.2608695652173913, 0.3049382716049382, 0.8233333333333335, 1.0, 1.0, 0.23649088855139677, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16123024191854488, 0.16123024191854488, 0.23668393109151192], 
reward next is 0.7633, 
noisyNet noise sample is [array([2.0667617], dtype=float32), 1.0800627]. 
=============================================
[2019-03-24 02:39:13,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5277074e-17 9.9999332e-01 1.0028414e-11 6.6683729e-06 2.5963533e-12], sum to 1.0000
[2019-03-24 02:39:13,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0670
[2019-03-24 02:39:13,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333333, 82.33333333333334, 1.0, 2.0, 0.5633046309584263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693586.0208831154, 693586.0208831154, 153888.7456176037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861800.0000, 
sim time next is 1862400.0000, 
raw observation next is [21.86666666666667, 82.66666666666667, 1.0, 2.0, 0.6952761516331016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855664.0010903981, 855664.0010903981, 177816.788434387], 
processed observation next is [1.0, 0.5652173913043478, 0.36543209876543226, 0.8266666666666667, 1.0, 1.0, 0.6372335138489305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3055942861037136, 0.3055942861037136, 0.3419553623738212], 
reward next is 0.6580, 
noisyNet noise sample is [array([-0.08040693], dtype=float32), 0.14524475]. 
=============================================
[2019-03-24 02:39:17,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4518377e-14 9.9994481e-01 5.6439835e-09 5.5228193e-05 1.0050134e-08], sum to 1.0000
[2019-03-24 02:39:17,421] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6636
[2019-03-24 02:39:17,427] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 63.16666666666667, 1.0, 2.0, 0.545575857738115, 1.0, 2.0, 0.545575857738115, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260425269404, 1273140.027139963, 1273140.027139964, 251202.6804964838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1950600.0000, 
sim time next is 1951200.0000, 
raw observation next is [27.2, 62.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.607048386729196, 6.9112, 121.9232396421231, 1565147.7043377, 1208819.327976672, 248014.3257876689], 
processed observation next is [1.0, 0.6086956521739131, 0.5629629629629629, 0.62, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0695848386729196, 0.0, 0.809443519990726, 0.55898132297775, 0.43172118856309716, 0.4769506265147479], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37601787], dtype=float32), 0.26224872]. 
=============================================
[2019-03-24 02:39:17,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0397031e-15 9.9999094e-01 1.2479052e-08 9.0954682e-06 1.2175214e-09], sum to 1.0000
[2019-03-24 02:39:17,609] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-24 02:39:17,614] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.0, 1.0, 2.0, 0.4179662713676398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513691.4985777623, 513691.4985777623, 131077.110338146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2264400.0000, 
sim time next is 2265000.0000, 
raw observation next is [20.4, 95.16666666666667, 1.0, 2.0, 0.4164290415373986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512100.9669835112, 512100.9669835112, 130864.1754999739], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9516666666666667, 1.0, 1.0, 0.30527266849690315, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18289320249411115, 0.18289320249411115, 0.25166187596148826], 
reward next is 0.7483, 
noisyNet noise sample is [array([-2.892326], dtype=float32), -0.35734683]. 
=============================================
[2019-03-24 02:39:17,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.030483]
 [54.97107 ]
 [54.936703]
 [54.87156 ]
 [54.861813]], R is [[55.28404617]
 [55.47913361]
 [55.66983795]
 [55.85612488]
 [56.03858948]].
[2019-03-24 02:39:18,944] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 02:39:18,946] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:39:18,946] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:39:18,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:39:18,948] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:39:18,948] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:39:18,950] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:39:18,951] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:39:18,952] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:39:18,953] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:39:18,951] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:39:18,980] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-24 02:39:19,005] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-24 02:39:19,036] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-24 02:39:19,036] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-24 02:39:19,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-24 02:39:22,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:39:22,984] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.62383976833333, 27.78089108333333, 1.0, 2.0, 0.3414909292977226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 434468.9584774236, 434468.9584774231, 120849.906570094]
[2019-03-24 02:39:22,986] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:39:22,989] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.35095690e-18 9.99999881e-01 9.97114067e-13 1.06663265e-07
 2.68498629e-13], sampled 0.028951790922377096
[2019-03-24 02:39:24,542] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:39:24,543] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.05186213333333, 37.85480021666667, 1.0, 2.0, 0.3210628591265406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408183.3031440732, 408183.3031440732, 118210.8312351508]
[2019-03-24 02:39:24,544] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:39:24,547] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7061302e-18 9.9999988e-01 1.3616982e-12 1.2699670e-07 3.7017172e-13], sampled 0.9074112727603433
[2019-03-24 02:39:36,126] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:39:36,128] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.06666666666667, 93.0, 1.0, 2.0, 0.3374145842352683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428873.8842380997, 428873.8842380997, 120315.3872880323]
[2019-03-24 02:39:36,129] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:39:36,131] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2882918e-18 9.9999988e-01 6.6900690e-13 8.6011930e-08 1.7841433e-13], sampled 0.6140453238367288
[2019-03-24 02:39:43,295] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:39:43,296] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.46666666666667, 87.33333333333334, 1.0, 2.0, 0.4478688372542448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 549494.2082955523, 549494.2082955518, 135432.3980108052]
[2019-03-24 02:39:43,298] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:39:43,300] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1064789e-18 9.9999988e-01 1.2120137e-12 1.1928847e-07 3.2857885e-13], sampled 0.6690667368023182
[2019-03-24 02:39:50,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:39:50,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.37743932666667, 41.45667691333334, 1.0, 2.0, 0.323773434951896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411149.9296125564, 411149.9296125564, 118553.3332740808]
[2019-03-24 02:39:50,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:39:50,829] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5362660e-18 9.9999988e-01 1.0510051e-12 1.0989432e-07 2.8349320e-13], sampled 0.906631793648788
[2019-03-24 02:40:10,664] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:40:10,664] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 84.0, 1.0, 2.0, 0.4692168683716647, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7470085357742481, 6.911200000000001, 6.9112, 121.9260419674076, 1069738.652463197, 1069738.652463196, 246436.830547808]
[2019-03-24 02:40:10,665] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:40:10,667] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.3568849e-23 1.0000000e+00 6.8607646e-16 1.8635253e-09 1.4962032e-16], sampled 0.26541249207569007
[2019-03-24 02:40:29,125] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.810843]
[2019-03-24 02:40:29,126] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.52229205, 46.25535188666667, 1.0, 2.0, 0.5489427470573061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671452.0047338697, 671452.0047338697, 151348.6537384295]
[2019-03-24 02:40:29,127] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:40:29,130] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.07673572e-18 9.99999881e-01 1.19706870e-12 1.18043744e-07
 3.24059030e-13], sampled 0.8177259559693002
[2019-03-24 02:40:56,858] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:40:56,904] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:40:56,946] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:40:57,019] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 02:40:57,025] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:40:58,040] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1325000, evaluation results [1325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:41:05,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4505931e-24 1.0000000e+00 1.8082741e-15 5.1194857e-09 4.9963080e-16], sum to 1.0000
[2019-03-24 02:41:05,913] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8466
[2019-03-24 02:41:05,919] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 83.0, 1.0, 2.0, 0.497192507726356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592639.7584507526, 592639.7584507526, 142441.2381236009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2105400.0000, 
sim time next is 2106000.0000, 
raw observation next is [24.1, 82.0, 1.0, 2.0, 0.5015166498277277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596795.9251734093, 596795.9251734093, 143082.6785052525], 
processed observation next is [0.0, 0.391304347826087, 0.4481481481481482, 0.82, 1.0, 1.0, 0.40656744027110436, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21314140184764618, 0.21314140184764618, 0.2751589971254856], 
reward next is 0.7248, 
noisyNet noise sample is [array([-0.5343146], dtype=float32), 1.1193912]. 
=============================================
[2019-03-24 02:41:05,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[81.61054 ]
 [81.59072 ]
 [81.57988 ]
 [81.566444]
 [81.56315 ]], R is [[81.55197906]
 [81.46253204]
 [81.37519836]
 [81.28992462]
 [81.20668793]].
[2019-03-24 02:41:11,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7000777e-15 1.0000000e+00 3.7700565e-10 3.4195047e-08 1.8303961e-11], sum to 1.0000
[2019-03-24 02:41:11,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-24 02:41:11,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 95.0, 1.0, 2.0, 0.5465838865148078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642914.3163847816, 642914.3163847816, 150050.3369262207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2227800.0000, 
sim time next is 2228400.0000, 
raw observation next is [22.9, 95.0, 1.0, 2.0, 0.5443240040579651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640891.8095727265, 640891.8095727265, 149705.0785408613], 
processed observation next is [1.0, 0.8260869565217391, 0.4037037037037037, 0.95, 1.0, 1.0, 0.45752857625948223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22888993199025945, 0.22888993199025945, 0.2878943818093486], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.69343054], dtype=float32), -0.5722241]. 
=============================================
[2019-03-24 02:41:12,647] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3939371e-19 1.0000000e+00 1.4992842e-14 4.5378130e-08 5.1708268e-14], sum to 1.0000
[2019-03-24 02:41:12,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4479
[2019-03-24 02:41:12,662] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.08333333333334, 98.0, 1.0, 2.0, 0.5688693642929773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662549.2272326476, 662549.2272326476, 153478.7623568388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2253000.0000, 
sim time next is 2253600.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.5690891194874756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 662573.5889974631, 662573.5889974636, 153505.3937153124], 
processed observation next is [1.0, 0.08695652173913043, 0.41111111111111115, 0.98, 1.0, 1.0, 0.4870108565327091, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2366334246419511, 0.23663342464195128, 0.29520268022175467], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.4302269], dtype=float32), 0.63915664]. 
=============================================
[2019-03-24 02:41:15,050] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9796637e-17 9.9999928e-01 2.3199507e-12 6.8393246e-07 9.0291849e-14], sum to 1.0000
[2019-03-24 02:41:15,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0449
[2019-03-24 02:41:15,064] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 88.5, 1.0, 2.0, 0.4688911711659262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 567974.3782852229, 567974.3782852234, 138391.4704171092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2597400.0000, 
sim time next is 2598000.0000, 
raw observation next is [22.0, 89.33333333333334, 1.0, 2.0, 0.4673259137837938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 566482.3879252571, 566482.3879252566, 138166.0109717776], 
processed observation next is [0.0, 0.043478260869565216, 0.37037037037037035, 0.8933333333333334, 1.0, 1.0, 0.36586418307594504, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20231513854473468, 0.2023151385447345, 0.2657038672534185], 
reward next is 0.7343, 
noisyNet noise sample is [array([-1.82436], dtype=float32), -0.76332504]. 
=============================================
[2019-03-24 02:41:15,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[60.081863]
 [59.98343 ]
 [60.10038 ]
 [60.11925 ]
 [60.14836 ]], R is [[60.08729172]
 [60.22028351]
 [60.35149384]
 [60.48088074]
 [60.60850143]].
[2019-03-24 02:41:18,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2346584e-23 1.0000000e+00 7.7247307e-13 3.4578470e-08 1.1578566e-18], sum to 1.0000
[2019-03-24 02:41:18,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1689
[2019-03-24 02:41:18,208] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 74.66666666666667, 1.0, 2.0, 0.6034079003132248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695372.9325631983, 695372.9325631983, 159040.4963275515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2657400.0000, 
sim time next is 2658000.0000, 
raw observation next is [26.66666666666667, 75.33333333333334, 1.0, 2.0, 0.6032175095075227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695969.4004889142, 695969.4004889142, 159046.0953150608], 
processed observation next is [0.0, 0.782608695652174, 0.5432098765432101, 0.7533333333333334, 1.0, 1.0, 0.5276398922708604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24856050017461223, 0.24856050017461223, 0.3058578756058862], 
reward next is 0.6941, 
noisyNet noise sample is [array([1.5719717], dtype=float32), -0.19323826]. 
=============================================
[2019-03-24 02:41:18,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[78.67624 ]
 [78.67926 ]
 [78.646545]
 [78.62    ]
 [78.59755 ]], R is [[78.61305237]
 [78.52107239]
 [78.43054962]
 [78.34371948]
 [78.25998688]].
[2019-03-24 02:41:29,410] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1934820e-16 9.9999869e-01 1.8041924e-08 1.3452665e-06 8.3229187e-12], sum to 1.0000
[2019-03-24 02:41:29,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3319
[2019-03-24 02:41:29,425] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.5041625790298849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602380.2010683736, 602380.2010683736, 143589.4813676167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2581200.0000, 
sim time next is 2581800.0000, 
raw observation next is [27.76666666666667, 58.16666666666666, 1.0, 2.0, 0.5015112093196198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599317.7075024749, 599317.7075024749, 143175.2341570433], 
processed observation next is [1.0, 0.9130434782608695, 0.5839506172839507, 0.5816666666666666, 1.0, 1.0, 0.40656096347573784, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21404203839374103, 0.21404203839374103, 0.27533698876354484], 
reward next is 0.7247, 
noisyNet noise sample is [array([0.85723954], dtype=float32), -0.15512428]. 
=============================================
[2019-03-24 02:41:36,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2009455e-19 9.9999988e-01 1.0575395e-10 1.0318360e-07 2.6131715e-13], sum to 1.0000
[2019-03-24 02:41:36,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1952
[2019-03-24 02:41:36,345] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 97.0, 1.0, 2.0, 0.5680853121519677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663882.5722487791, 663882.5722487791, 153445.4823303308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680200.0000, 
sim time next is 2680800.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.5628325230445325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659397.9430266212, 659397.9430266212, 152636.7268356235], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.96, 1.0, 1.0, 0.4795625274339672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23549926536665045, 0.23549926536665045, 0.29353216699158363], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.5605977], dtype=float32), 0.05778987]. 
=============================================
[2019-03-24 02:41:40,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1826867e-12 9.9998975e-01 3.7495408e-08 1.0226123e-05 4.3171577e-09], sum to 1.0000
[2019-03-24 02:41:40,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9137
[2019-03-24 02:41:40,948] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.7560263346984907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872340.191238806, 872340.191238806, 187562.6686746514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.7396871155681735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 853497.5089342619, 853497.5089342619, 184320.32693379], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.6901037090097303, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30482053890509353, 0.30482053890509353, 0.3544621671803654], 
reward next is 0.6455, 
noisyNet noise sample is [array([-0.22774501], dtype=float32), 0.07812769]. 
=============================================
[2019-03-24 02:41:44,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7359546e-24 1.0000000e+00 7.2133913e-18 6.6590226e-16 2.9385700e-22], sum to 1.0000
[2019-03-24 02:41:45,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5521
[2019-03-24 02:41:45,012] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6795815737279838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774518.9902854369, 774518.9902854369, 172314.1513497765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841000.0000, 
sim time next is 2841600.0000, 
raw observation next is [28.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6778806273293413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772579.4450334242, 772579.4450334242, 171998.2318263067], 
processed observation next is [1.0, 0.9130434782608695, 0.6172839506172841, 0.7133333333333334, 1.0, 1.0, 0.6165245563444539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27592123036908006, 0.27592123036908006, 0.3307658304352052], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.3310358], dtype=float32), 0.18255049]. 
=============================================
[2019-03-24 02:41:48,645] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 02:41:48,650] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:41:48,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:41:48,652] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:41:48,655] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:41:48,655] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:41:48,656] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:41:48,658] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:41:48,656] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:41:48,659] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:41:48,661] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:41:48,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-24 02:41:48,708] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-24 02:41:48,733] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-24 02:41:48,734] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-24 02:41:48,735] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-24 02:42:15,670] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:42:15,671] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.41666666666667, 48.83333333333334, 1.0, 2.0, 0.4268194347497856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520021.7983111494, 520021.7983111494, 132231.5779829555]
[2019-03-24 02:42:15,671] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:42:15,673] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7394766e-21 1.0000000e+00 2.4212537e-14 1.8224221e-11 1.6515207e-17], sampled 0.4681990224833579
[2019-03-24 02:42:36,151] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:42:36,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.05, 78.00000000000001, 1.0, 2.0, 0.7580771767036432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864030.8390445503, 864030.8390445503, 187435.5020618106]
[2019-03-24 02:42:36,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:42:36,154] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7164361e-20 1.0000000e+00 4.1637138e-14 2.7671677e-11 3.2015351e-17], sampled 0.8357893119126516
[2019-03-24 02:42:49,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:42:49,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.33333333333334, 51.0, 1.0, 2.0, 0.5371426356812622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630767.9732386167, 630767.9732386167, 148461.1618407434]
[2019-03-24 02:42:49,793] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:42:49,795] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.15779824e-21 1.00000000e+00 2.07335183e-14 1.61477984e-11
 1.36535135e-17], sampled 0.9352938940180288
[2019-03-24 02:42:50,731] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:42:50,732] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.00234253166667, 99.38800564166667, 1.0, 2.0, 0.7705795850392124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878288.8280825533, 878288.8280825533, 189941.6350730711]
[2019-03-24 02:42:50,733] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:42:50,735] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6131624e-20 1.0000000e+00 5.5452235e-14 3.4573205e-11 4.5435691e-17], sampled 0.47331818864637853
[2019-03-24 02:43:05,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:43:05,960] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.16266757666667, 87.94526790666667, 1.0, 2.0, 0.5519109445987082, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8904491107975283, 6.911199999999999, 6.9112, 121.9257783246136, 1323086.198393724, 1323086.198393724, 273899.3613799367]
[2019-03-24 02:43:05,961] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:43:05,963] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.28504824e-17 1.00000000e+00 3.67334678e-12 8.92765972e-10
 7.73764089e-15], sampled 0.8112631326711196
[2019-03-24 02:43:05,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1323086.198393724 W.
[2019-03-24 02:43:23,656] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.808719]
[2019-03-24 02:43:23,658] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.40801720666667, 55.28546576666668, 1.0, 2.0, 0.2090052682093213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 269589.5203111654, 269589.5203111654, 81161.55769991242]
[2019-03-24 02:43:23,660] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:43:23,662] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5817084e-19 1.0000000e+00 1.9010231e-13 8.9288299e-11 2.0497144e-16], sampled 0.2609835633002371
[2019-03-24 02:43:25,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 02:43:26,404] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 02:43:26,420] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 02:43:26,545] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 02:43:26,596] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 02:43:27,612] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1350000, evaluation results [1350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 02:43:35,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5484314e-12 9.9987626e-01 5.3550755e-09 1.2374006e-04 1.9152788e-10], sum to 1.0000
[2019-03-24 02:43:35,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0844
[2019-03-24 02:43:35,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2612449.184731557 W.
[2019-03-24 02:43:35,698] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.8997370537071652, 1.0, 2.0, 0.7632331888300173, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2612449.184731557, 2612449.184731556, 487225.2660515531], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3067200.0000, 
sim time next is 3067800.0000, 
raw observation next is [31.0, 78.33333333333334, 1.0, 2.0, 0.9126691789432567, 1.0, 2.0, 0.7696992514480632, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 122.3240538471896, 2634602.383634919, 2634602.383634919, 491388.6594756285], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.7833333333333334, 1.0, 1.0, 0.8960347368372104, 1.0, 1.0, 0.7258324422000751, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8121045094949716, 0.9409294227267567, 0.9409294227267567, 0.9449781912992856], 
reward next is 0.0550, 
noisyNet noise sample is [array([-0.94045264], dtype=float32), 0.4414614]. 
=============================================
[2019-03-24 02:43:43,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.05965105e-26 1.00000000e+00 4.64119151e-19 2.26500936e-12
 2.82847281e-24], sum to 1.0000
[2019-03-24 02:43:43,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2966
[2019-03-24 02:43:43,516] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 82.0, 1.0, 2.0, 0.4837158250386353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583398.8979315119, 583398.8979315119, 140586.5683610024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3213600.0000, 
sim time next is 3214200.0000, 
raw observation next is [23.58333333333334, 79.0, 1.0, 2.0, 0.4793088518580829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579064.5907505411, 579064.5907505411, 139938.5720911919], 
processed observation next is [0.0, 0.17391304347826086, 0.4290123456790126, 0.79, 1.0, 1.0, 0.38012958554533677, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20680878241090753, 0.20680878241090753, 0.2691126386369075], 
reward next is 0.7309, 
noisyNet noise sample is [array([-1.2205563], dtype=float32), -0.55161744]. 
=============================================
[2019-03-24 02:43:52,732] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3523476e-15 9.9990976e-01 7.5850111e-11 9.0215159e-05 2.3028267e-13], sum to 1.0000
[2019-03-24 02:43:52,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1998
[2019-03-24 02:43:52,744] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333334, 93.83333333333334, 1.0, 2.0, 0.6626179293609843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755176.0042845055, 755176.0042845055, 169186.0415943195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3370200.0000, 
sim time next is 3370800.0000, 
raw observation next is [24.76666666666667, 93.66666666666667, 1.0, 2.0, 0.6582931482492995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750244.7021354008, 750244.7021354008, 168396.395099201], 
processed observation next is [1.0, 0.0, 0.4728395061728396, 0.9366666666666668, 1.0, 1.0, 0.5932061288682137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2679445364769289, 0.2679445364769289, 0.32383922134461735], 
reward next is 0.6762, 
noisyNet noise sample is [array([1.6595867], dtype=float32), -0.38174883]. 
=============================================
[2019-03-24 02:43:54,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0051986e-09 9.9905902e-01 4.2191509e-06 9.3680265e-04 4.1472831e-08], sum to 1.0000
[2019-03-24 02:43:54,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1061
[2019-03-24 02:43:54,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2115696.815070274 W.
[2019-03-24 02:43:54,252] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.75, 65.66666666666667, 1.0, 2.0, 0.6182775618077618, 1.0, 2.0, 0.6182775618077618, 1.0, 2.0, 0.984318014292385, 6.911200000000001, 6.9112, 121.94756008, 2115696.815070274, 2115696.815070274, 405424.049068826], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3409800.0000, 
sim time next is 3410400.0000, 
raw observation next is [30.0, 64.33333333333334, 1.0, 2.0, 0.895062693468861, 1.0, 2.0, 0.895062693468861, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2041805.108897663, 2041805.108897664, 384601.5311818917], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666666, 0.6433333333333334, 1.0, 1.0, 0.8750746350819774, 1.0, 1.0, 0.8750746350819774, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7292161103205939, 0.7292161103205942, 0.7396183291959455], 
reward next is 0.2604, 
noisyNet noise sample is [array([-0.76231194], dtype=float32), -0.32787266]. 
=============================================
[2019-03-24 02:43:58,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4917512e-12 9.9797958e-01 1.6942487e-07 2.0202782e-03 8.3324111e-11], sum to 1.0000
[2019-03-24 02:43:58,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6516
[2019-03-24 02:43:58,360] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6749494908050628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769237.1572659017, 769237.1572659017, 171454.1699005289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3478800.0000, 
sim time next is 3479400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7106560445945102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 809953.2707921228, 809953.2707921225, 178168.225535493], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6555429102315596, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.289269025282901, 0.2892690252829009, 0.34263120295287114], 
reward next is 0.6574, 
noisyNet noise sample is [array([-0.5580669], dtype=float32), -1.1758521]. 
=============================================
[2019-03-24 02:44:00,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2610511e-12 9.9995399e-01 2.2589752e-10 4.5955716e-05 2.4356064e-11], sum to 1.0000
[2019-03-24 02:44:00,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0840
[2019-03-24 02:44:00,199] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 76.66666666666667, 1.0, 2.0, 0.6022766756572093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687173.6962157233, 687173.6962157233, 158509.6339130908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3520200.0000, 
sim time next is 3520800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6213727776087452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 708147.7928401285, 708147.7928401281, 161793.6083784082], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5492533066770776, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2529099260143316, 0.25290992601433143, 0.3111415545738619], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.9055148], dtype=float32), 1.6074919]. 
=============================================
[2019-03-24 02:44:05,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5373514e-11 7.5844246e-01 9.7646966e-07 2.4155405e-01 2.5715462e-06], sum to 1.0000
[2019-03-24 02:44:05,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9114
[2019-03-24 02:44:05,118] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 78.83333333333333, 1.0, 2.0, 0.5260464171464401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622910.5811059331, 622910.5811059331, 146874.3977636507], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [24.7, 78.0, 1.0, 2.0, 0.2629110177338143, 1.0, 1.0, 0.2629110177338143, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 618619.3433118747, 618619.3433118751, 172729.2223441466], 
processed observation next is [1.0, 0.8695652173913043, 0.4703703703703703, 0.78, 1.0, 1.0, 0.12251311634977895, 1.0, 0.5, 0.12251311634977895, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22093547975424094, 0.2209354797542411, 0.3321715814310512], 
reward next is 0.6678, 
noisyNet noise sample is [array([-0.9214158], dtype=float32), -0.28243032]. 
=============================================
[2019-03-24 02:44:08,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0284225e-12 4.3574005e-01 7.2303159e-08 5.6425965e-01 2.2923965e-07], sum to 1.0000
[2019-03-24 02:44:08,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8984
[2019-03-24 02:44:08,327] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.03333333333333, 98.66666666666669, 1.0, 2.0, 0.5387899173767843, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637706.7951182981, 637706.7951182981, 148932.338173849], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3655200.0000, 
sim time next is 3655800.0000, 
raw observation next is [22.05, 98.5, 1.0, 2.0, 0.273407311854151, 1.0, 1.0, 0.273407311854151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642753.5886445503, 642753.5886445508, 175135.3150559224], 
processed observation next is [1.0, 0.30434782608695654, 0.37222222222222223, 0.985, 1.0, 1.0, 0.13500870458827502, 1.0, 0.5, 0.13500870458827502, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2295548530873394, 0.22955485308733956, 0.33679868279985076], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7314888], dtype=float32), -0.79727024]. 
=============================================
[2019-03-24 02:44:17,154] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.26727554e-16 5.48839052e-05 1.37976786e-08 9.99939799e-01
 5.36699872e-06], sum to 1.0000
[2019-03-24 02:44:17,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4536
[2019-03-24 02:44:17,165] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 59.33333333333334, 1.0, 2.0, 0.2850106672378877, 1.0, 2.0, 0.2850106672378877, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 658231.4706967269, 658231.4706967274, 177329.4580206164], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3829800.0000, 
sim time next is 3830400.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.2825237534712572, 1.0, 2.0, 0.2825237534712572, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653717.9184468465, 653717.9184468465, 176802.5012446015], 
processed observation next is [0.0, 0.34782608695652173, 0.6296296296296297, 0.58, 1.0, 1.0, 0.14586161127530617, 1.0, 1.0, 0.14586161127530617, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23347068515958805, 0.23347068515958805, 0.3400048100857721], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.7925455], dtype=float32), -1.663589]. 
=============================================
[2019-03-24 02:44:18,474] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 02:44:18,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:44:18,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:44:18,476] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:44:18,477] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:44:18,477] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:44:18,478] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:44:18,480] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:44:18,482] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:44:18,482] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:44:18,482] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:44:18,504] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-24 02:44:18,530] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-24 02:44:18,531] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-24 02:44:18,555] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-24 02:44:18,607] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-24 02:44:24,701] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:44:24,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.2, 35.0, 1.0, 2.0, 0.3564623520806293, 1.0, 2.0, 0.3564623520806293, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 905575.2641721091, 905575.2641721095, 197587.9503850398]
[2019-03-24 02:44:24,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:44:24,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9398714e-14 4.3550981e-04 7.1770081e-08 9.9955040e-01 1.3924755e-05], sampled 0.364061899169302
[2019-03-24 02:44:39,048] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:44:39,048] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 40.33333333333334, 1.0, 2.0, 0.1772998075635059, 1.0, 2.0, 0.1772998075635059, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441162.2589688835, 441162.2589688835, 155236.8544292344]
[2019-03-24 02:44:39,049] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:44:39,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9527677e-15 2.2499061e-04 1.7659982e-08 9.9976951e-01 5.4751686e-06], sampled 0.8274201624165055
[2019-03-24 02:45:09,259] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:45:09,260] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.665620325, 79.63046762666667, 1.0, 2.0, 0.286360037176251, 1.0, 2.0, 0.286360037176251, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657333.2884130863, 657333.2884130868, 177453.2803351226]
[2019-03-24 02:45:09,261] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:45:09,263] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.8123196e-15 2.2188731e-04 1.7193688e-08 9.9977273e-01 5.3773574e-06], sampled 0.16923281549505165
[2019-03-24 02:45:11,001] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:45:11,002] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.5808278, 88.37770760500001, 1.0, 2.0, 0.5320134380065228, 1.0, 2.0, 0.5320134380065228, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1230876.600179858, 1230876.600179858, 246312.3743646813]
[2019-03-24 02:45:11,003] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:45:11,007] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0110758e-14 3.6676397e-04 4.9957748e-08 9.9962223e-01 1.0943823e-05], sampled 0.7927717789767684
[2019-03-24 02:45:36,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:45:36,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 68.66666666666666, 1.0, 2.0, 0.3347882839441395, 1.0, 2.0, 0.3347882839441395, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 763110.610967569, 763110.6109675695, 189018.8253375743]
[2019-03-24 02:45:36,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:45:36,395] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.1466810e-16 1.6679875e-04 9.3550172e-09 9.9982965e-01 3.5858236e-06], sampled 0.9809889662871765
[2019-03-24 02:45:40,236] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:45:40,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.83333333333334, 66.0, 1.0, 2.0, 0.2848291860943274, 1.0, 2.0, 0.2848291860943274, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 654665.3177486379, 654665.3177486383, 177134.285585785]
[2019-03-24 02:45:40,238] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:45:40,242] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4288805e-15 1.8683841e-04 1.1913219e-08 9.9980897e-01 4.2121910e-06], sampled 0.14381872649827765
[2019-03-24 02:45:47,429] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7982518]
[2019-03-24 02:45:47,430] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333334, 80.33333333333333, 1.0, 2.0, 0.3141800294043727, 1.0, 2.0, 0.3141800294043727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716114.5707916353, 716114.5707916358, 183898.73244237]
[2019-03-24 02:45:47,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:45:47,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2662345e-15 1.8117984e-04 1.1158014e-08 9.9981481e-01 4.0323707e-06], sampled 0.8173693307912724
[2019-03-24 02:45:55,606] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3963 2465934155.8119 46.0000
[2019-03-24 02:45:55,862] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2097 2438815016.4056 34.0000
[2019-03-24 02:45:56,278] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.4748 2668468521.3993 68.0000
[2019-03-24 02:45:56,367] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.4420 2410683354.0442 22.0000
[2019-03-24 02:45:56,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6904.0800 2495432639.8358 48.0000
[2019-03-24 02:45:57,412] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1375000, evaluation results [1375000.0, 7522.474794537297, 2668468521.3993015, 68.0, 7122.20972767785, 2438815016.405557, 34.0, 7796.441968986809, 2410683354.044239, 22.0, 6904.0800193020605, 2495432639.835837, 48.0, 7478.396290143961, 2465934155.811905, 46.0]
[2019-03-24 02:46:10,754] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.30282295e-11 1.75734429e-04 7.21970991e-07 9.99596894e-01
 2.26664619e-04], sum to 1.0000
[2019-03-24 02:46:10,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-24 02:46:10,766] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 68.0, 1.0, 2.0, 0.6872699010506872, 1.0, 2.0, 0.6872699010506872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1568375.106803165, 1568375.106803166, 299424.4266997792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4100400.0000, 
sim time next is 4101000.0000, 
raw observation next is [27.25, 68.33333333333334, 1.0, 2.0, 0.6780357348604756, 1.0, 2.0, 0.6780357348604756, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1546292.463886331, 1546292.463886331, 295932.5498307003], 
processed observation next is [1.0, 0.4782608695652174, 0.5648148148148148, 0.6833333333333335, 1.0, 1.0, 0.6167092081672328, 1.0, 1.0, 0.6167092081672328, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5522473085308325, 0.5522473085308325, 0.5691010573667314], 
reward next is 0.4309, 
noisyNet noise sample is [array([-1.5042477], dtype=float32), 0.58665574]. 
=============================================
[2019-03-24 02:46:10,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.786613]
 [50.521065]
 [50.395607]
 [50.36219 ]
 [50.09156 ]], R is [[51.00260162]
 [50.91675949]
 [50.8315773 ]
 [50.75260162]
 [50.6916008 ]].
[2019-03-24 02:46:11,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9782097e-11 1.0166728e-03 7.1908221e-07 9.9578625e-01 3.1962628e-03], sum to 1.0000
[2019-03-24 02:46:11,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3419
[2019-03-24 02:46:11,814] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.9609000970578918, 1.0, 2.0, 0.9609000970578918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2192176.880118255, 2192176.880118255, 414726.9549580511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4114800.0000, 
sim time next is 4115400.0000, 
raw observation next is [29.0, 73.33333333333334, 1.0, 2.0, 0.8777474496087739, 1.0, 2.0, 0.8777474496087739, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2002261.52304141, 2002261.52304141, 376928.6652184406], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7333333333333334, 1.0, 1.0, 0.8544612495342547, 1.0, 1.0, 0.8544612495342547, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7150934010862178, 0.7150934010862178, 0.7248628177277704], 
reward next is 0.2751, 
noisyNet noise sample is [array([1.2113845], dtype=float32), -0.96711165]. 
=============================================
[2019-03-24 02:46:13,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9184976e-17 2.2361547e-07 1.2036283e-07 9.9999940e-01 2.3803017e-07], sum to 1.0000
[2019-03-24 02:46:13,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0388
[2019-03-24 02:46:13,313] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.225162378464615, 1.0, 2.0, 0.225162378464615, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544647.517373175, 544647.517373175, 164916.9089714811], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4131000.0000, 
sim time next is 4131600.0000, 
raw observation next is [20.9, 94.66666666666667, 1.0, 2.0, 0.224491274441892, 1.0, 2.0, 0.224491274441892, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543218.0077763861, 543218.0077763861, 164777.4748125874], 
processed observation next is [1.0, 0.8260869565217391, 0.32962962962962955, 0.9466666666666668, 1.0, 1.0, 0.07677532671653811, 1.0, 1.0, 0.07677532671653811, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19400643134870932, 0.19400643134870932, 0.3168797592549758], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.0511884], dtype=float32), -0.33894238]. 
=============================================
[2019-03-24 02:46:13,966] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3571533e-16 5.1903307e-06 5.0350876e-11 9.9999475e-01 2.2631236e-08], sum to 1.0000
[2019-03-24 02:46:13,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8518
[2019-03-24 02:46:13,977] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.7, 92.5, 1.0, 2.0, 0.2388471733350404, 1.0, 2.0, 0.2388471733350404, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572363.6398157337, 572363.6398157337, 167737.1118135717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4145400.0000, 
sim time next is 4146000.0000, 
raw observation next is [21.8, 91.0, 1.0, 2.0, 0.2364106553693766, 1.0, 2.0, 0.2364106553693766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 567381.7504105831, 567381.7504105836, 167229.0865763343], 
processed observation next is [1.0, 1.0, 0.362962962962963, 0.91, 1.0, 1.0, 0.09096506591592453, 1.0, 1.0, 0.09096506591592453, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2026363394323511, 0.20263633943235126, 0.3215943972621813], 
reward next is 0.6784, 
noisyNet noise sample is [array([1.0294212], dtype=float32), -0.17719735]. 
=============================================
[2019-03-24 02:46:14,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.30328 ]
 [71.27401 ]
 [71.237144]
 [71.21233 ]
 [71.148834]], R is [[71.2976532 ]
 [71.26210785]
 [71.22621918]
 [71.19048309]
 [71.15531158]].
[2019-03-24 02:46:14,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9916041e-14 7.2452145e-05 4.1811163e-09 9.9990165e-01 2.5839619e-05], sum to 1.0000
[2019-03-24 02:46:14,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0781
[2019-03-24 02:46:14,215] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 91.0, 1.0, 2.0, 0.2269135408323302, 1.0, 2.0, 0.2269135408323302, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 547601.203888208, 547601.2038882084, 165252.9080945302], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4149000.0000, 
sim time next is 4149600.0000, 
raw observation next is [21.33333333333334, 92.0, 1.0, 2.0, 0.2256462466305872, 1.0, 2.0, 0.2256462466305872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 544950.461208535, 544950.4612085355, 164990.9432586383], 
processed observation next is [1.0, 0.0, 0.3456790123456792, 0.92, 1.0, 1.0, 0.07815029360784188, 1.0, 1.0, 0.07815029360784188, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19462516471733393, 0.1946251647173341, 0.3172902754973813], 
reward next is 0.6827, 
noisyNet noise sample is [array([-0.76650035], dtype=float32), 0.82460207]. 
=============================================
[2019-03-24 02:46:30,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1780544e-13 1.5162788e-05 2.3085347e-09 9.9982554e-01 1.5935469e-04], sum to 1.0000
[2019-03-24 02:46:30,628] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3844
[2019-03-24 02:46:30,632] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.3677152344647214, 1.0, 2.0, 0.3677152344647214, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 838204.7694741348, 838204.7694741352, 197505.6656160125], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4463400.0000, 
sim time next is 4464000.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.3683233682523702, 1.0, 2.0, 0.3683233682523702, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 839591.7662301066, 839591.766230107, 197665.9240548745], 
processed observation next is [0.0, 0.6956521739130435, 0.6666666666666666, 0.7, 1.0, 1.0, 0.24800400982425028, 1.0, 1.0, 0.24800400982425028, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29985420222503806, 0.2998542022250382, 0.38012677702860476], 
reward next is 0.6199, 
noisyNet noise sample is [array([0.4316712], dtype=float32), 0.25949028]. 
=============================================
[2019-03-24 02:46:30,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.039494]
 [58.982292]
 [58.9277  ]
 [58.88886 ]
 [58.82211 ]], R is [[59.13798523]
 [59.16678619]
 [59.19583511]
 [59.22590256]
 [59.25892258]].
[2019-03-24 02:46:39,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8019324e-14 1.8431019e-05 4.4048775e-07 9.9996030e-01 2.0786600e-05], sum to 1.0000
[2019-03-24 02:46:39,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6343
[2019-03-24 02:46:39,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 64.66666666666667, 1.0, 2.0, 0.8672917850725548, 1.0, 2.0, 0.8672917850725548, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1978384.308809791, 1978384.308809792, 372344.7234781362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4630800.0000, 
sim time next is 4631400.0000, 
raw observation next is [29.75, 65.0, 1.0, 2.0, 0.8778107789216587, 1.0, 2.0, 0.8778107789216587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2002406.147795133, 2002406.147795133, 376955.9140842634], 
processed observation next is [1.0, 0.6086956521739131, 0.6574074074074074, 0.65, 1.0, 1.0, 0.8545366415734033, 1.0, 1.0, 0.8545366415734033, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7151450527839761, 0.7151450527839761, 0.7249152193928142], 
reward next is 0.2751, 
noisyNet noise sample is [array([0.4853676], dtype=float32), 1.8840686]. 
=============================================
[2019-03-24 02:46:42,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6936721e-14 4.0886289e-06 6.4286418e-08 9.9975592e-01 2.3986326e-04], sum to 1.0000
[2019-03-24 02:46:42,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8150
[2019-03-24 02:46:42,219] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.23333333333333, 94.33333333333334, 1.0, 2.0, 0.3127186848586859, 1.0, 2.0, 0.3127186848586859, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 723728.3317536947, 723728.3317536952, 184069.6390175658], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4681200.0000, 
sim time next is 4681800.0000, 
raw observation next is [23.35, 94.5, 1.0, 2.0, 0.3103287366255236, 1.0, 2.0, 0.3103287366255236, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716472.0278347271, 716472.0278347271, 183402.5518358232], 
processed observation next is [1.0, 0.17391304347826086, 0.42037037037037045, 0.945, 1.0, 1.0, 0.17896278169705193, 1.0, 1.0, 0.17896278169705193, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2558828670838311, 0.2558828670838311, 0.35269721506889073], 
reward next is 0.6473, 
noisyNet noise sample is [array([-0.32006416], dtype=float32), 0.95528173]. 
=============================================
[2019-03-24 02:46:44,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4787384e-15 1.2408844e-06 1.2920327e-09 9.9999380e-01 5.0168960e-06], sum to 1.0000
[2019-03-24 02:46:44,249] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7846
[2019-03-24 02:46:44,258] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333333, 92.33333333333334, 1.0, 2.0, 0.3377265110461273, 1.0, 2.0, 0.3377265110461273, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769811.3179742, 769811.3179742004, 189760.766892049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4743600.0000, 
sim time next is 4744200.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.3379914626772622, 1.0, 2.0, 0.3379914626772622, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770415.5502711849, 770415.5502711853, 189827.7732428338], 
processed observation next is [1.0, 0.9130434782608695, 0.4876543209876545, 0.9316666666666668, 1.0, 1.0, 0.21189459842531216, 1.0, 1.0, 0.21189459842531216, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27514841081113744, 0.2751484108111376, 0.3650534100823727], 
reward next is 0.6349, 
noisyNet noise sample is [array([-0.60686773], dtype=float32), 0.83820426]. 
=============================================
[2019-03-24 02:46:48,209] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 02:46:48,210] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:46:48,210] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:46:48,211] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:46:48,211] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:46:48,212] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:46:48,214] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:46:48,214] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:46:48,213] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:46:48,214] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:46:48,215] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:46:48,239] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-24 02:46:48,265] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-24 02:46:48,291] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-24 02:46:48,316] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-24 02:46:48,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-24 02:47:13,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:47:13,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.83333333333334, 77.16666666666667, 1.0, 2.0, 0.3589813008065041, 1.0, 2.0, 0.3589813008065041, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880902.4263924062, 880902.4263924062, 197678.129535507]
[2019-03-24 02:47:13,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:47:13,245] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.9331780e-12 1.2192502e-05 9.7281557e-08 9.9985528e-01 1.3245297e-04], sampled 0.3688281487686492
[2019-03-24 02:47:19,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:47:19,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.5202945525023961, 1.0, 2.0, 0.5202945525023961, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1186277.672485898, 1186277.672485898, 241730.1452440506]
[2019-03-24 02:47:19,604] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:47:19,606] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1799544e-12 8.5256424e-06 5.8064412e-08 9.9989104e-01 1.0033038e-04], sampled 0.06832161673596637
[2019-03-24 02:47:36,577] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:47:36,577] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.33333333333334, 59.00000000000001, 1.0, 2.0, 0.3908268097569775, 1.0, 2.0, 0.3908268097569775, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890918.093387384, 890918.093387384, 203687.2714897853]
[2019-03-24 02:47:36,582] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:47:36,584] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4238120e-13 3.2554603e-06 1.4492339e-08 9.9994922e-01 4.7525333e-05], sampled 0.8052409196344364
[2019-03-24 02:47:53,187] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:47:53,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 80.5, 1.0, 2.0, 0.3852189961591283, 1.0, 2.0, 0.3852189961591283, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 878127.3515113723, 878127.3515113727, 202170.1682685412]
[2019-03-24 02:47:53,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:47:53,192] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5757988e-13 4.2986212e-06 2.1654458e-08 9.9993670e-01 5.8986527e-05], sampled 0.5605573987281774
[2019-03-24 02:47:54,762] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:47:54,764] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.85953825, 78.16366709, 1.0, 2.0, 0.5239458598198363, 1.0, 2.0, 0.5239458598198363, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1194609.18678945, 1194609.18678945, 242886.5631306641]
[2019-03-24 02:47:54,764] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:47:54,767] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0987571e-12 8.3843252e-06 5.6690453e-08 9.9989259e-01 9.9045312e-05], sampled 0.3705410883172262
[2019-03-24 02:48:20,066] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:48:20,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.153088025, 82.56046568, 1.0, 2.0, 0.1896070558687775, 1.0, 2.0, 0.1896070558687775, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467881.3463604483, 467881.3463604487, 157692.2677177521]
[2019-03-24 02:48:20,069] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:48:20,071] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.6465451e-13 5.3855438e-06 2.9951003e-08 9.9992442e-01 7.0245253e-05], sampled 0.9958556458780343
[2019-03-24 02:48:22,190] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78538513]
[2019-03-24 02:48:22,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.53333333333333, 80.66666666666667, 1.0, 2.0, 0.5278344200509202, 1.0, 2.0, 0.5278344200509202, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1224772.301429021, 1224772.30142902, 245132.1156304112]
[2019-03-24 02:48:22,193] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:48:22,196] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.8622291e-12 1.4091708e-05 1.1984012e-07 9.9983764e-01 1.4819669e-04], sampled 0.7367570025575553
[2019-03-24 02:48:25,935] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6904.5090 2495501051.7154 47.0000
[2019-03-24 02:48:25,955] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.6406 2465982784.6856 46.0000
[2019-03-24 02:48:25,990] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7796.7476 2410790944.7524 22.0000
[2019-03-24 02:48:26,112] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 02:48:26,138] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.6933 2438889071.6273 34.0000
[2019-03-24 02:48:27,154] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1400000, evaluation results [1400000.0, 7523.727130323888, 2668527814.010175, 68.0, 7120.693329990657, 2438889071.6273108, 34.0, 7796.747602898168, 2410790944.7523727, 22.0, 6904.508999607442, 2495501051.715436, 47.0, 7477.640571334953, 2465982784.685571, 46.0]
[2019-03-24 02:48:28,880] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5790917e-15 4.9027130e-07 5.8255581e-11 9.9977118e-01 2.2833669e-04], sum to 1.0000
[2019-03-24 02:48:28,886] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-24 02:48:28,891] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.06666666666667, 92.33333333333333, 1.0, 2.0, 0.3551408784206393, 1.0, 2.0, 0.3551408784206393, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809526.4599810407, 809526.4599810411, 194220.3202638528], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.3547910247213145, 1.0, 2.0, 0.3547910247213145, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808728.5646687681, 808728.5646687686, 194129.7017273304], 
processed observation next is [1.0, 0.9565217391304348, 0.5216049382716051, 0.9216666666666667, 1.0, 1.0, 0.23189407704918397, 1.0, 1.0, 0.23189407704918397, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2888316302388457, 0.2888316302388459, 0.37332634947563537], 
reward next is 0.6267, 
noisyNet noise sample is [array([0.79985315], dtype=float32), 1.9038335]. 
=============================================
[2019-03-24 02:48:48,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1697203e-14 5.0799031e-08 2.7117811e-10 9.9992812e-01 7.1891729e-05], sum to 1.0000
[2019-03-24 02:48:48,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-24 02:48:48,049] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 85.5, 1.0, 2.0, 0.3590582998171796, 1.0, 2.0, 0.3590582998171796, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 818460.8003034708, 818460.8003034722, 195237.7173032775], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5171400.0000, 
sim time next is 5172000.0000, 
raw observation next is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.3571609274187566, 1.0, 2.0, 0.3571609274187566, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 814133.5094769918, 814133.5094769923, 194744.1262229546], 
processed observation next is [0.0, 0.8695652173913043, 0.5469135802469137, 0.8566666666666666, 1.0, 1.0, 0.23471538978423406, 1.0, 1.0, 0.23471538978423406, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2907619676703542, 0.2907619676703544, 0.3745079350441435], 
reward next is 0.6255, 
noisyNet noise sample is [array([0.33331135], dtype=float32), 0.40821356]. 
=============================================
[2019-03-24 02:48:48,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.343098]
 [61.358757]
 [61.391132]
 [61.393993]
 [61.394222]], R is [[61.34519958]
 [61.35628891]
 [61.36712265]
 [61.37867737]
 [61.38492203]].
[2019-03-24 02:48:48,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8940190e-16 1.4604915e-09 1.5162128e-10 9.9999917e-01 8.5284137e-07], sum to 1.0000
[2019-03-24 02:48:48,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9376
[2019-03-24 02:48:48,186] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 87.83333333333334, 1.0, 2.0, 0.3152634698999699, 1.0, 2.0, 0.3152634698999699, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718585.2280811027, 718585.2280811027, 184163.6072167538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5179800.0000, 
sim time next is 5180400.0000, 
raw observation next is [24.8, 88.0, 1.0, 2.0, 0.3117768334220885, 1.0, 2.0, 0.3117768334220885, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 710634.396380594, 710634.3963805945, 183310.5490874449], 
processed observation next is [0.0, 1.0, 0.4740740740740741, 0.88, 1.0, 1.0, 0.18068670645486729, 1.0, 1.0, 0.18068670645486729, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.253797998707355, 0.25379799870735514, 0.35252028670662483], 
reward next is 0.6475, 
noisyNet noise sample is [array([-0.21741809], dtype=float32), -0.8088741]. 
=============================================
[2019-03-24 02:49:08,816] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8475824e-11 1.2866313e-05 3.5514844e-08 1.4818014e-03 9.9850535e-01], sum to 1.0000
[2019-03-24 02:49:08,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3004
[2019-03-24 02:49:08,833] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 78.0, 1.0, 2.0, 0.5185442735182226, 1.0, 2.0, 0.5185442735182226, 1.0, 2.0, 0.8255393712489997, 6.911200000000001, 6.9112, 121.94756008, 1774078.496593936, 1774078.496593936, 352784.0271190161], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5572800.0000, 
sim time next is 5573400.0000, 
raw observation next is [28.21666666666667, 77.66666666666667, 1.0, 2.0, 0.6149873296173353, 1.0, 2.0, 0.6149873296173353, 1.0, 2.0, 0.9790798574898443, 6.9112, 6.9112, 122.1441794031513, 2104420.644986676, 2104420.644986676, 403653.3744125034], 
processed observation next is [1.0, 0.5217391304347826, 0.6006172839506173, 0.7766666666666667, 1.0, 1.0, 0.54165158287778, 1.0, 1.0, 0.54165158287778, 1.0, 1.0, 0.9738498218623054, 0.0, 0.0, 0.8109103302427954, 0.7515788017809557, 0.7515788017809557, 0.7762564892548142], 
reward next is 0.2237, 
noisyNet noise sample is [array([-0.09798374], dtype=float32), -0.7564369]. 
=============================================
[2019-03-24 02:49:17,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3665870e-09 2.1516171e-05 2.9958903e-06 2.6132091e-04 9.9971420e-01], sum to 1.0000
[2019-03-24 02:49:17,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6248
[2019-03-24 02:49:17,954] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.46666666666667, 69.0, 1.0, 2.0, 0.1802602454220642, 1.0, 2.0, 0.1802602454220642, 1.0, 2.0, 0.2875408697186796, 6.9112, 6.9112, 121.94756008, 627204.5328999695, 627204.5328999695, 214220.8374711485], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6034800.0000, 
sim time next is 6035400.0000, 
raw observation next is [26.35, 69.5, 1.0, 2.0, 0.1800330739868123, 1.0, 2.0, 0.1800330739868123, 1.0, 2.0, 0.2872107841431776, 6.911200000000001, 6.9112, 121.94756008, 626790.7406264405, 626790.74062644, 214144.8484891356], 
processed observation next is [1.0, 0.8695652173913043, 0.5314814814814816, 0.695, 1.0, 1.0, 0.023848897603347956, 1.0, 1.0, 0.023848897603347956, 1.0, 1.0, 0.10901348017897196, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22385383593801447, 0.2238538359380143, 0.41181701632526074], 
reward next is 0.5882, 
noisyNet noise sample is [array([0.7757187], dtype=float32), 0.22919834]. 
=============================================
[2019-03-24 02:49:17,963] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 02:49:17,964] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:49:17,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:49:17,965] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:49:17,965] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:49:17,967] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:49:17,967] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:49:17,967] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:49:17,968] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:49:17,971] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:49:17,971] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:49:17,997] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-24 02:49:18,022] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-24 02:49:18,048] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-24 02:49:18,086] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-24 02:49:18,108] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-24 02:49:28,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7817065]
[2019-03-24 02:49:28,886] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.23333333333333, 52.83333333333334, 1.0, 2.0, 0.3412281453560362, 1.0, 2.0, 0.3412281453560362, 1.0, 2.0, 0.5517239184877564, 6.911199999999999, 6.9112, 121.94756008, 1231610.598502911, 1231610.598502911, 271692.749833545]
[2019-03-24 02:49:28,887] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:49:28,890] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6885720e-08 2.5598647e-04 4.0419995e-06 3.3414927e-03 9.9639845e-01], sampled 0.6601000507672127
[2019-03-24 02:49:53,495] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7817065]
[2019-03-24 02:49:53,496] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.87345966666666, 94.92109162, 1.0, 2.0, 0.2307613328679652, 1.0, 2.0, 0.2307613328679652, 1.0, 2.0, 0.3673795572977367, 6.911199999999999, 6.9112, 121.94756008, 789003.3208608527, 789003.3208608532, 230906.9941952293]
[2019-03-24 02:49:53,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:49:53,500] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3137200e-10 3.7257902e-05 2.3044491e-07 9.5990754e-04 9.9900264e-01], sampled 0.775609754760769
[2019-03-24 02:50:06,202] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7817065]
[2019-03-24 02:50:06,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 68.33333333333333, 1.0, 2.0, 0.252188638000922, 1.0, 2.0, 0.252188638000922, 1.0, 2.0, 0.4014925249080134, 6.9112, 6.9112, 121.94756008, 862307.2981132355, 862307.2981132355, 238402.8546820823]
[2019-03-24 02:50:06,205] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:50:06,208] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9373670e-09 8.6131149e-05 8.0406721e-07 1.6513707e-03 9.9826175e-01], sampled 0.3130755646267409
[2019-03-24 02:50:20,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7817065]
[2019-03-24 02:50:20,957] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333333, 74.83333333333334, 1.0, 2.0, 0.2018279360817278, 1.0, 2.0, 0.2018279360817278, 1.0, 2.0, 0.3213166473190984, 6.9112, 6.9112, 121.94756008, 690031.7164205983, 690031.7164205983, 221192.6670775067]
[2019-03-24 02:50:20,957] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:50:20,959] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.0792161e-10 4.2879085e-05 2.8420104e-07 1.0514347e-03 9.9890542e-01], sampled 0.6564989006130236
[2019-03-24 02:50:49,571] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7817065]
[2019-03-24 02:50:49,572] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 47.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 366335.170939485, 366335.170939485, 170572.8159889388]
[2019-03-24 02:50:49,572] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:50:49,576] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9838404e-08 2.6955729e-04 4.3604628e-06 3.4543630e-03 9.9627173e-01], sampled 0.7910301085232346
[2019-03-24 02:50:55,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4487.2964 2939688168.0680 28.0000
[2019-03-24 02:50:56,154] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4603.9590 2893933417.9890 13.0000
[2019-03-24 02:50:56,171] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4508.8874 3106324164.3681 0.0000
[2019-03-24 02:50:56,231] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4273.2682 2918950018.6605 33.0000
[2019-03-24 02:50:56,291] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4389.9569 2874892071.8001 9.0000
[2019-03-24 02:50:57,309] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1425000, evaluation results [1425000.0, 4508.887427450716, 3106324164.3680954, 0.0, 4603.958973847953, 2893933417.988983, 13.0, 4389.956876732297, 2874892071.8000593, 9.0, 4487.296381330155, 2939688168.067997, 28.0, 4273.268245713161, 2918950018.6604543, 33.0]
[2019-03-24 02:50:57,953] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3451009e-06 6.4312413e-02 1.2439442e-03 1.9248028e-01 7.4195904e-01], sum to 1.0000
[2019-03-24 02:50:57,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5682
[2019-03-24 02:50:57,963] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.58333333333333, 82.0, 1.0, 2.0, 0.4447465494525956, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540633.4150256111, 540633.4150256115, 134823.341673878], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5734200.0000, 
sim time next is 5734800.0000, 
raw observation next is [22.8, 81.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2449832499363779, 6.911200000000001, 6.9112, 121.94756008, 548345.872041063, 548345.8720410626, 202404.9430421603], 
processed observation next is [0.0, 0.391304347826087, 0.4, 0.81, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.05622906242047237, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.1958378114432368, 0.19583781144323664, 0.3892402750810775], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6265561], dtype=float32), -0.60660374]. 
=============================================
[2019-03-24 02:50:58,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3795184e-08 7.2187677e-02 8.4243598e-04 7.0642567e-01 2.2054411e-01], sum to 1.0000
[2019-03-24 02:50:58,856] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-24 02:50:58,863] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.3, 62.0, 1.0, 2.0, 0.1707804745178385, 1.0, 2.0, 0.1707804745178385, 1.0, 2.0, 0.2729812471595725, 6.9112, 6.9112, 121.94756008, 599647.8410402142, 599647.8410402142, 211162.8665710472], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5750400.0000, 
sim time next is 5751000.0000, 
raw observation next is [27.45, 62.0, 1.0, 2.0, 0.1730150857939957, 1.0, 2.0, 0.1730150857939957, 1.0, 2.0, 0.276348420465613, 6.9112, 6.9112, 121.94756008, 605738.4303048004, 605738.4303048004, 211891.9994399965], 
processed observation next is [0.0, 0.5652173913043478, 0.5722222222222222, 0.62, 1.0, 1.0, 0.015494149754756768, 1.0, 1.0, 0.015494149754756768, 1.0, 1.0, 0.0954355255820162, 0.0, 0.0, 0.8096049824067558, 0.21633515368028586, 0.21633515368028586, 0.40748461430768557], 
reward next is 0.5925, 
noisyNet noise sample is [array([1.6045995], dtype=float32), 0.3001964]. 
=============================================
[2019-03-24 02:50:58,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[41.305725]
 [40.82301 ]
 [40.842495]
 [40.992435]
 [40.41519 ]], R is [[41.52322006]
 [41.7019043 ]
 [41.88029861]
 [42.13524628]
 [42.388237  ]].
[2019-03-24 02:51:05,228] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0331952e-15 1.8660129e-03 3.1001687e-08 9.9779993e-01 3.3398226e-04], sum to 1.0000
[2019-03-24 02:51:05,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-24 02:51:05,245] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 52.33333333333333, 1.0, 2.0, 0.1974498268406427, 1.0, 2.0, 0.1974498268406427, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484144.8105067951, 484144.8105067955, 159230.7645803722], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [26.36666666666666, 53.66666666666666, 1.0, 2.0, 0.1997985088964041, 1.0, 2.0, 0.1997985088964041, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489237.2954695782, 489237.2954695782, 159701.7905745519], 
processed observation next is [1.0, 0.782608695652174, 0.5320987654320986, 0.5366666666666666, 1.0, 1.0, 0.04737917725762393, 1.0, 1.0, 0.04737917725762393, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17472760552484934, 0.17472760552484934, 0.30711882802798446], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.0626066], dtype=float32), 0.11698456]. 
=============================================
[2019-03-24 02:51:10,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7868662e-12 1.8625500e-05 1.2070694e-07 9.9977964e-01 2.0163655e-04], sum to 1.0000
[2019-03-24 02:51:10,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1578
[2019-03-24 02:51:10,620] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.55, 79.5, 1.0, 2.0, 0.217307329988346, 1.0, 2.0, 0.217307329988346, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528138.2389495772, 528138.2389495777, 163301.7014690673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5967000.0000, 
sim time next is 5967600.0000, 
raw observation next is [22.53333333333333, 79.0, 1.0, 2.0, 0.2151731116835156, 1.0, 2.0, 0.2151731116835156, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523661.1529169891, 523661.1529169891, 162866.424185639], 
processed observation next is [1.0, 0.043478260869565216, 0.3901234567901234, 0.79, 1.0, 1.0, 0.06568227581370906, 1.0, 1.0, 0.06568227581370906, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1870218403274961, 0.1870218403274961, 0.31320466189545965], 
reward next is 0.6868, 
noisyNet noise sample is [array([-0.23537207], dtype=float32), 1.185547]. 
=============================================
[2019-03-24 02:51:22,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5160742e-11 9.5714917e-05 5.1052723e-07 9.9982423e-01 7.9657751e-05], sum to 1.0000
[2019-03-24 02:51:22,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6745
[2019-03-24 02:51:22,202] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333333, 56.33333333333333, 1.0, 2.0, 0.6815389479797987, 1.0, 2.0, 0.6815389479797987, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1554289.814941849, 1554289.814941849, 297234.2450793479], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6183600.0000, 
sim time next is 6184200.0000, 
raw observation next is [29.66666666666667, 55.66666666666666, 1.0, 2.0, 0.6829807179468106, 1.0, 2.0, 0.6829807179468106, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1557581.200640712, 1557581.200640713, 297771.1788622202], 
processed observation next is [1.0, 0.5652173913043478, 0.6543209876543211, 0.5566666666666665, 1.0, 1.0, 0.6225960927938221, 1.0, 1.0, 0.6225960927938221, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5562790002288257, 0.5562790002288261, 0.5726368824273466], 
reward next is 0.4274, 
noisyNet noise sample is [array([0.59963536], dtype=float32), 2.136836]. 
=============================================
[2019-03-24 02:51:28,570] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3524618e-14 1.4666017e-06 2.0282538e-08 9.9997449e-01 2.4094510e-05], sum to 1.0000
[2019-03-24 02:51:28,579] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2232
[2019-03-24 02:51:28,584] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 65.33333333333334, 1.0, 2.0, 0.3057860135597168, 1.0, 2.0, 0.3057860135597168, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697218.9010469536, 697218.9010469541, 181867.1333914918], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6291600.0000, 
sim time next is 6292200.0000, 
raw observation next is [28.21666666666667, 65.66666666666666, 1.0, 2.0, 0.3041554498120938, 1.0, 2.0, 0.3041554498120938, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694293.3660807632, 694293.3660807636, 181512.845639624], 
processed observation next is [0.0, 0.8260869565217391, 0.6006172839506173, 0.6566666666666666, 1.0, 1.0, 0.1716136307286831, 1.0, 1.0, 0.1716136307286831, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24796191645741542, 0.24796191645741558, 0.3490631646915846], 
reward next is 0.6509, 
noisyNet noise sample is [array([-2.1491718], dtype=float32), -0.4581965]. 
=============================================
[2019-03-24 02:51:41,120] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5696740e-12 1.5572230e-04 9.8456965e-08 9.4438195e-01 5.5462234e-02], sum to 1.0000
[2019-03-24 02:51:41,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9176
[2019-03-24 02:51:41,133] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 80.0, 1.0, 2.0, 0.7688569316918102, 1.0, 2.0, 0.7688569316918102, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1753623.565108996, 1753623.565108996, 331053.8229814055], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6526800.0000, 
sim time next is 6527400.0000, 
raw observation next is [27.51666666666667, 80.16666666666667, 1.0, 2.0, 0.8305792628339624, 1.0, 2.0, 0.8305792628339624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1894550.335875985, 1894550.335875985, 356552.4001384844], 
processed observation next is [1.0, 0.5652173913043478, 0.5746913580246914, 0.8016666666666667, 1.0, 1.0, 0.7983086462309077, 1.0, 1.0, 0.7983086462309077, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.676625119955709, 0.676625119955709, 0.6856776925740085], 
reward next is 0.3143, 
noisyNet noise sample is [array([0.5084823], dtype=float32), -0.53283143]. 
=============================================
[2019-03-24 02:51:44,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5909542e-14 3.7503494e-07 2.5303728e-09 9.7180802e-01 2.8191594e-02], sum to 1.0000
[2019-03-24 02:51:44,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7177
[2019-03-24 02:51:44,104] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 51.0, 1.0, 2.0, 0.2044253741707132, 1.0, 2.0, 0.2044253741707132, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 514073.9662023055, 514073.966202306, 161018.099863693], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6593400.0000, 
sim time next is 6594000.0000, 
raw observation next is [24.43333333333333, 51.33333333333333, 1.0, 2.0, 0.1901948282525724, 1.0, 2.0, 0.1901948282525724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 478312.4833680387, 478312.4833680392, 158027.2468615351], 
processed observation next is [1.0, 0.30434782608695654, 0.4604938271604937, 0.5133333333333333, 1.0, 1.0, 0.035946224110205226, 1.0, 1.0, 0.035946224110205226, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1708258869171567, 0.17082588691715686, 0.30389855165679824], 
reward next is 0.6961, 
noisyNet noise sample is [array([0.93081], dtype=float32), -1.5459805]. 
=============================================
[2019-03-24 02:51:44,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.056255]
 [60.106556]
 [60.22215 ]
 [60.26583 ]
 [60.31007 ]], R is [[60.18721771]
 [60.2756958 ]
 [60.36841583]
 [60.46404648]
 [60.56165314]].
[2019-03-24 02:51:44,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0286600e-13 9.4991374e-06 9.0496764e-07 9.9952376e-01 4.6578329e-04], sum to 1.0000
[2019-03-24 02:51:44,981] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-24 02:51:44,991] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.21666666666667, 39.5, 1.0, 2.0, 0.5028350056519992, 1.0, 2.0, 0.5028350056519992, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1235810.582195224, 1235810.582195224, 239748.6401281797], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6619800.0000, 
sim time next is 6620400.0000, 
raw observation next is [29.0, 37.0, 1.0, 2.0, 0.5162547513267643, 1.0, 2.0, 0.5162547513267643, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1265917.266295142, 1265917.266295142, 243965.1958667424], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.37, 1.0, 1.0, 0.42411279919852896, 1.0, 1.0, 0.42411279919852896, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.45211330939112215, 0.45211330939112215, 0.46916383820527385], 
reward next is 0.5308, 
noisyNet noise sample is [array([-0.79831016], dtype=float32), -1.4733298]. 
=============================================
[2019-03-24 02:51:47,807] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 02:51:47,808] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:51:47,809] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:51:47,810] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:51:47,811] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:51:47,812] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:51:47,813] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:51:47,813] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:51:47,810] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:51:47,817] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:51:47,814] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:51:47,840] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-24 02:51:47,867] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-24 02:51:47,867] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-24 02:51:47,868] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-24 02:51:47,937] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-24 02:51:56,123] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:51:56,124] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.805897065, 58.34301727, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 306942.1538918792, 306942.1538918792, 125460.3128428917]
[2019-03-24 02:51:56,125] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:51:56,129] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.8744791e-09 7.4862014e-04 7.6712304e-06 9.9376124e-01 5.4824655e-03], sampled 0.6527827344852626
[2019-03-24 02:51:58,369] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:51:58,370] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.9, 62.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 321676.899434873, 321676.8994348735, 138532.3528101207]
[2019-03-24 02:51:58,372] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:51:58,374] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2186503e-09 6.5697904e-04 6.2095874e-06 9.9433410e-01 5.0027305e-03], sampled 0.5825812192214542
[2019-03-24 02:52:06,789] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:52:06,790] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.06666666666667, 58.33333333333334, 1.0, 2.0, 0.1604947097142764, 1.0, 2.0, 0.1604947097142764, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 404653.077759786, 404653.0777597865, 151937.0827405162]
[2019-03-24 02:52:06,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:52:06,795] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.0400385e-10 3.0429006e-04 1.7957960e-06 9.9676019e-01 2.9337157e-03], sampled 0.023698323679473
[2019-03-24 02:52:27,693] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:52:27,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.66666666666667, 92.33333333333334, 1.0, 2.0, 0.2290252524329675, 1.0, 2.0, 0.2290252524329675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 549942.6741027446, 549942.674102745, 165611.629795487]
[2019-03-24 02:52:27,696] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:52:27,699] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.111786e-09 8.488608e-04 9.424704e-06 9.931398e-01 6.001864e-03], sampled 0.7250865274344265
[2019-03-24 02:52:33,260] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:52:33,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.5, 65.0, 1.0, 2.0, 0.4455296521701891, 1.0, 2.0, 0.4455296521701891, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015699.834065667, 1015699.834065667, 219054.8468678779]
[2019-03-24 02:52:33,262] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:52:33,264] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.6141853e-12 4.7226287e-05 9.0656386e-08 9.9912959e-01 8.2297326e-04], sampled 0.2854569919647073
[2019-03-24 02:52:43,876] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:52:43,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.41795996, 89.92391212, 1.0, 2.0, 0.2741752684589913, 1.0, 2.0, 0.2741752684589913, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639291.6190839708, 639291.6190839708, 175079.6490206655]
[2019-03-24 02:52:43,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:52:43,880] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4195389e-10 3.2907844e-04 2.0484179e-06 9.9655008e-01 3.1188258e-03], sampled 0.593785038452939
[2019-03-24 02:52:58,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:52:58,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 39.0, 1.0, 2.0, 0.3300763181253312, 1.0, 2.0, 0.3300763181253312, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757546.4863134698, 757546.4863134703, 188087.8780643939]
[2019-03-24 02:52:58,009] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:52:58,011] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4262236e-11 1.0776667e-04 3.3873471e-07 9.9845219e-01 1.4397406e-03], sampled 0.7657273353435055
[2019-03-24 02:53:09,905] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:53:09,906] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.56666666666666, 80.66666666666667, 1.0, 2.0, 0.3008833815677105, 1.0, 2.0, 0.3008833815677105, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703323.0953065077, 703323.0953065081, 181503.6139003959]
[2019-03-24 02:53:09,909] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:53:09,916] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4723441e-10 2.4366195e-04 1.2614521e-06 9.9722493e-01 2.5301182e-03], sampled 0.13448025157640497
[2019-03-24 02:53:12,856] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.76614463]
[2019-03-24 02:53:12,857] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.36364845666667, 49.06126545000001, 1.0, 2.0, 0.3119044592288816, 1.0, 2.0, 0.3119044592288816, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 710925.4293710213, 710925.4293710218, 183342.1505582278]
[2019-03-24 02:53:12,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:53:12,861] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.04001384e-10 1.50976775e-04 5.84286965e-07 9.98028934e-01
 1.81945763e-03], sampled 0.230947962633965
[2019-03-24 02:53:25,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7100.8357 2439984910.9958 34.0000
[2019-03-24 02:53:25,768] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7485.6933 2669987511.0155 68.0000
[2019-03-24 02:53:25,895] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6878.1214 2496706825.3250 47.0000
[2019-03-24 02:53:25,943] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7758.7441 2412165388.2135 22.0000
[2019-03-24 02:53:25,985] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7450.4633 2467171400.9284 46.0000
[2019-03-24 02:53:27,002] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1450000, evaluation results [1450000.0, 7485.693296091679, 2669987511.0154743, 68.0, 7100.835658627658, 2439984910.995786, 34.0, 7758.744064127351, 2412165388.213456, 22.0, 6878.121376437672, 2496706825.3249564, 47.0, 7450.4632996717855, 2467171400.9283533, 46.0]
[2019-03-24 02:53:27,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5943146e-09 3.4227245e-04 4.3544719e-06 9.9107051e-01 8.5828500e-03], sum to 1.0000
[2019-03-24 02:53:27,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1250
[2019-03-24 02:53:27,030] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 44.50000000000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 411788.6324863217, 411788.6324863221, 151762.329689279], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [22.9, 45.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 373642.7715324255, 373642.7715324259, 146212.502659783], 
processed observation next is [1.0, 0.21739130434782608, 0.4037037037037037, 0.45, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13344384697586625, 0.1334438469758664, 0.2811778897303519], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8265845], dtype=float32), -0.51060987]. 
=============================================
[2019-03-24 02:53:27,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[39.159355]
 [39.212746]
 [39.288773]
 [39.36877 ]
 [39.42106 ]], R is [[38.69528961]
 [38.30833817]
 [37.92525482]
 [37.54600143]
 [37.17054367]].
[2019-03-24 02:53:28,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9133994e-08 4.1900896e-03 1.0928395e-04 9.9089605e-01 4.8045544e-03], sum to 1.0000
[2019-03-24 02:53:28,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-24 02:53:28,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 33.0, 1.0, 2.0, 0.3147452833719392, 1.0, 2.0, 0.3147452833719392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 789493.5023644894, 789493.5023644898, 186622.9371905049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6697200.0000, 
sim time next is 6697800.0000, 
raw observation next is [28.35, 32.5, 1.0, 2.0, 0.286086595788942, 1.0, 2.0, 0.286086595788942, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719135.3385493206, 719135.3385493206, 179573.8433520409], 
processed observation next is [1.0, 0.5217391304347826, 0.6055555555555556, 0.325, 1.0, 1.0, 0.15010309022493099, 1.0, 1.0, 0.15010309022493099, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2568340494819002, 0.2568340494819002, 0.34533431413854015], 
reward next is 0.6547, 
noisyNet noise sample is [array([-0.26944292], dtype=float32), 0.63550925]. 
=============================================
[2019-03-24 02:53:34,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1846490e-13 5.4738211e-05 4.5999879e-10 9.9993956e-01 5.6857721e-06], sum to 1.0000
[2019-03-24 02:53:34,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-24 02:53:34,213] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 61.0, 1.0, 2.0, 0.2411832339487258, 1.0, 2.0, 0.2411832339487258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571601.1077584035, 571601.1077584035, 167999.436294375], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6804000.0000, 
sim time next is 6804600.0000, 
raw observation next is [26.91666666666667, 61.66666666666667, 1.0, 2.0, 0.2441695418498575, 1.0, 2.0, 0.2441695418498575, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579068.8017540153, 579068.8017540157, 168682.3089858433], 
processed observation next is [1.0, 0.782608695652174, 0.5524691358024693, 0.6166666666666667, 1.0, 1.0, 0.10020183553554465, 1.0, 1.0, 0.10020183553554465, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20681028634071974, 0.2068102863407199, 0.3243890557420063], 
reward next is 0.6756, 
noisyNet noise sample is [array([-1.6218909], dtype=float32), 3.4645584]. 
=============================================
[2019-03-24 02:53:39,190] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4105019e-16 1.2509510e-06 3.5690062e-11 9.9998248e-01 1.6387592e-05], sum to 1.0000
[2019-03-24 02:53:39,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-24 02:53:39,202] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 56.0, 1.0, 2.0, 0.2409429715211429, 1.0, 2.0, 0.2409429715211429, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575874.042553491, 575874.0425534914, 168144.9752857222], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6892200.0000, 
sim time next is 6892800.0000, 
raw observation next is [27.36666666666667, 56.33333333333334, 1.0, 2.0, 0.2387499323952306, 1.0, 2.0, 0.2387499323952306, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571250.183167658, 571250.1831676585, 167680.9616914215], 
processed observation next is [0.0, 0.782608695652174, 0.569135802469136, 0.5633333333333335, 1.0, 1.0, 0.09374991951813166, 1.0, 1.0, 0.09374991951813166, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20401792255987788, 0.20401792255987805, 0.32246338786811823], 
reward next is 0.6775, 
noisyNet noise sample is [array([1.4214399], dtype=float32), -0.047475953]. 
=============================================
[2019-03-24 02:53:41,981] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1143952e-16 2.1639248e-06 1.2821268e-10 9.9999785e-01 3.3061333e-08], sum to 1.0000
[2019-03-24 02:53:41,988] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5512
[2019-03-24 02:53:41,993] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 65.0, 1.0, 2.0, 0.2482944239062974, 1.0, 2.0, 0.2482944239062974, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 588282.6674694567, 588282.6674694571, 169584.2671106654], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6948000.0000, 
sim time next is 6948600.0000, 
raw observation next is [26.66666666666666, 63.83333333333334, 1.0, 2.0, 0.2500806715867583, 1.0, 2.0, 0.2500806715867583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 591878.6501604292, 591878.6501604295, 169960.0365582654], 
processed observation next is [0.0, 0.43478260869565216, 0.5432098765432096, 0.6383333333333334, 1.0, 1.0, 0.10723889474614082, 1.0, 1.0, 0.10723889474614082, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2113852322001533, 0.2113852322001534, 0.32684622415051034], 
reward next is 0.6732, 
noisyNet noise sample is [array([-1.0614396], dtype=float32), 0.04638504]. 
=============================================
[2019-03-24 02:53:55,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0252804e-17 6.9319533e-08 2.5833097e-12 9.9999988e-01 5.1613430e-08], sum to 1.0000
[2019-03-24 02:53:55,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5260
[2019-03-24 02:53:55,085] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.1846051184237715, 1.0, 2.0, 0.1846051184237715, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459060.1125163296, 459060.11251633, 156748.0641947114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7164600.0000, 
sim time next is 7165200.0000, 
raw observation next is [19.8, 89.0, 1.0, 2.0, 0.1835178729668063, 1.0, 2.0, 0.1835178729668063, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456370.3491415891, 456370.3491415896, 156521.1892602118], 
processed observation next is [1.0, 0.9565217391304348, 0.2888888888888889, 0.89, 1.0, 1.0, 0.027997467817626544, 1.0, 1.0, 0.027997467817626544, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1629894104077104, 0.16298941040771056, 0.30100228703886883], 
reward next is 0.6990, 
noisyNet noise sample is [array([-0.21569082], dtype=float32), -1.6483929]. 
=============================================
[2019-03-24 02:54:01,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6428633e-15 8.2944986e-08 5.4862847e-11 9.9999976e-01 1.5187732e-07], sum to 1.0000
[2019-03-24 02:54:01,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3265
[2019-03-24 02:54:01,184] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 66.16666666666667, 1.0, 2.0, 0.3797811931894985, 1.0, 2.0, 0.3797811931894985, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 902119.0386983474, 902119.0386983479, 202308.2187166336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7305000.0000, 
sim time next is 7305600.0000, 
raw observation next is [26.0, 65.33333333333334, 1.0, 2.0, 0.5478542807365193, 1.0, 2.0, 0.5478542807365193, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1293990.855750725, 1293990.855750725, 252608.7160072541], 
processed observation next is [1.0, 0.5652173913043478, 0.5185185185185185, 0.6533333333333334, 1.0, 1.0, 0.4617312865910944, 1.0, 1.0, 0.4617312865910944, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46213959133954463, 0.46213959133954463, 0.4857859923216425], 
reward next is 0.5142, 
noisyNet noise sample is [array([-0.9923434], dtype=float32), 1.2122892]. 
=============================================
[2019-03-24 02:54:03,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.35402344e-17 1.27108120e-08 4.10583442e-11 1.00000000e+00
 1.16395391e-08], sum to 1.0000
[2019-03-24 02:54:03,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4802
[2019-03-24 02:54:03,505] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 65.0, 1.0, 2.0, 0.5667172667874161, 1.0, 2.0, 0.5667172667874161, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1309902.358518068, 1309902.358518068, 257639.4662284973], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7653600.0000, 
sim time next is 7654200.0000, 
raw observation next is [26.95, 65.16666666666667, 1.0, 2.0, 0.4725357144962432, 1.0, 2.0, 0.4725357144962432, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1097089.451422337, 1097089.451422336, 227945.6784756548], 
processed observation next is [1.0, 0.6086956521739131, 0.5537037037037037, 0.6516666666666667, 1.0, 1.0, 0.3720663267812419, 1.0, 1.0, 0.3720663267812419, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3918176612222632, 0.39181766122226286, 0.43835707399164386], 
reward next is 0.5616, 
noisyNet noise sample is [array([0.25677526], dtype=float32), 0.46207085]. 
=============================================
[2019-03-24 02:54:07,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5325866e-15 2.3477684e-09 2.0503658e-10 1.0000000e+00 4.4441211e-09], sum to 1.0000
[2019-03-24 02:54:07,059] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8671
[2019-03-24 02:54:07,065] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.1, 91.0, 1.0, 2.0, 0.1950349263728123, 1.0, 2.0, 0.1950349263728123, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 481221.1279958171, 481221.1279958175, 158818.2643248668], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7416000.0000, 
sim time next is 7416600.0000, 
raw observation next is [20.11666666666667, 90.83333333333334, 1.0, 2.0, 0.1942408698942686, 1.0, 2.0, 0.1942408698942686, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479372.6391445661, 479372.6391445666, 158655.882502016], 
processed observation next is [1.0, 0.8695652173913043, 0.30061728395061743, 0.9083333333333334, 1.0, 1.0, 0.04076294035031974, 1.0, 1.0, 0.04076294035031974, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17120451398020217, 0.17120451398020237, 0.3051074663500308], 
reward next is 0.6949, 
noisyNet noise sample is [array([-1.8281085], dtype=float32), -2.1443934]. 
=============================================
[2019-03-24 02:54:17,638] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 02:54:17,640] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:54:17,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:54:17,642] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:54:17,645] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:54:17,645] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:54:17,645] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:54:17,647] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:54:17,648] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:54:17,650] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:54:17,651] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:54:17,671] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-24 02:54:17,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-24 02:54:17,699] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-24 02:54:17,749] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-24 02:54:17,781] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-24 02:55:02,325] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7908568]
[2019-03-24 02:55:02,326] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.778779555, 104.13754928, 1.0, 2.0, 0.4303400257977281, 1.0, 2.0, 0.4303400257977281, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 981048.9931884847, 981048.9931884852, 214682.0652857027]
[2019-03-24 02:55:02,327] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:55:02,329] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.7391287e-18 3.0566638e-09 3.3540753e-12 1.0000000e+00 4.4639918e-09], sampled 0.3917707988969974
[2019-03-24 02:55:11,215] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7908568]
[2019-03-24 02:55:11,217] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.13333333333334, 86.0, 1.0, 2.0, 0.4646795552565948, 1.0, 2.0, 0.4646795552565948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1074011.242056203, 1074011.242056204, 225367.388280406]
[2019-03-24 02:55:11,218] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:55:11,219] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.712374e-18 3.897211e-09 4.649111e-12 1.000000e+00 5.634303e-09], sampled 0.09335257169015565
[2019-03-24 02:55:48,642] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.7908568]
[2019-03-24 02:55:48,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 47.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 362320.685908658, 362320.6859086584, 145219.7709882351]
[2019-03-24 02:55:48,645] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:55:48,650] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8520301e-17 6.0333907e-09 8.3648487e-12 1.0000000e+00 8.5653848e-09], sampled 0.5489056907563606
[2019-03-24 02:55:55,308] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 02:55:55,617] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 02:55:55,757] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 02:55:55,775] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 02:55:56,079] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 02:55:57,098] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1475000, evaluation results [1475000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 02:55:59,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:55:59,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:59,973] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-24 02:56:00,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2425874e-14 2.4728291e-08 2.5014827e-11 1.0000000e+00 1.2638505e-08], sum to 1.0000
[2019-03-24 02:56:00,475] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7320
[2019-03-24 02:56:00,480] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 65.83333333333333, 1.0, 2.0, 0.5115659601692487, 1.0, 2.0, 0.5115659601692487, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1197182.199080382, 1197182.199080383, 240404.0853657681], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7656600.0000, 
sim time next is 7657200.0000, 
raw observation next is [26.2, 66.0, 1.0, 2.0, 0.5389424045505999, 1.0, 2.0, 0.5389424045505999, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1263171.731718409, 1263171.73171841, 249274.7896461941], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.66, 1.0, 1.0, 0.4511219101792856, 1.0, 1.0, 0.4511219101792856, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45113276132800323, 0.45113276132800356, 0.47937459547345024], 
reward next is 0.5206, 
noisyNet noise sample is [array([-0.25284302], dtype=float32), 0.70636475]. 
=============================================
[2019-03-24 02:56:05,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3564541e-16 2.4908533e-07 4.9580905e-11 9.9999976e-01 5.4553958e-08], sum to 1.0000
[2019-03-24 02:56:05,450] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-24 02:56:05,455] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333334, 46.0, 1.0, 2.0, 0.6229239491956022, 1.0, 2.0, 0.6229239491956022, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1471609.438195808, 1471609.438195808, 278378.0758449709], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7741200.0000, 
sim time next is 7741800.0000, 
raw observation next is [29.5, 46.5, 1.0, 2.0, 0.6293567022825001, 1.0, 2.0, 0.6293567022825001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1484686.083948816, 1484686.083948816, 280588.5627015592], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.465, 1.0, 1.0, 0.5587579789077382, 1.0, 1.0, 0.5587579789077382, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.53024502998172, 0.53024502998172, 0.5395933898106908], 
reward next is 0.4604, 
noisyNet noise sample is [array([-2.1550524], dtype=float32), 0.8121498]. 
=============================================
[2019-03-24 02:56:07,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1374180e-16 2.9392704e-06 1.5815961e-11 9.9999368e-01 3.3182146e-06], sum to 1.0000
[2019-03-24 02:56:07,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-24 02:56:07,944] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 39.33333333333334, 1.0, 2.0, 0.4816176597041266, 1.0, 2.0, 0.4816176597041266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1172088.116497661, 1172088.116497661, 232754.3155968135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7818000.0000, 
sim time next is 7818600.0000, 
raw observation next is [29.3, 39.16666666666666, 1.0, 2.0, 0.4937210087299133, 1.0, 2.0, 0.4937210087299133, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1200045.543383123, 1200045.543383123, 236479.1551341402], 
processed observation next is [1.0, 0.4782608695652174, 0.6407407407407407, 0.39166666666666655, 1.0, 1.0, 0.3972869151546587, 1.0, 1.0, 0.3972869151546587, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.42858769406540104, 0.42858769406540104, 0.4547676060271927], 
reward next is 0.5452, 
noisyNet noise sample is [array([0.5162977], dtype=float32), -0.3539354]. 
=============================================
[2019-03-24 02:56:09,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8766765e-16 1.0623053e-08 6.3866157e-10 9.9999964e-01 3.5984394e-07], sum to 1.0000
[2019-03-24 02:56:09,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6739
[2019-03-24 02:56:09,756] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.13333333333333, 14.83333333333333, 1.0, 2.0, 0.1821088438357075, 1.0, 2.0, 0.1821088438357075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467721.2826356747, 467721.2826356751, 156439.0520561853], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 159000.0000, 
sim time next is 159600.0000, 
raw observation next is [32.06666666666667, 14.66666666666667, 1.0, 2.0, 0.1816413855506194, 1.0, 2.0, 0.1816413855506194, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466861.6118118825, 466861.6118118829, 156341.70635641], 
processed observation next is [1.0, 0.8695652173913043, 0.74320987654321, 0.1466666666666667, 1.0, 1.0, 0.025763554226927853, 1.0, 1.0, 0.025763554226927853, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1667362899328152, 0.1667362899328153, 0.30065712760848073], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.6276691], dtype=float32), -0.55301505]. 
=============================================
[2019-03-24 02:56:15,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:15,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:15,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-24 02:56:15,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:15,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:15,916] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-24 02:56:16,221] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,221] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-24 02:56:16,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,264] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,272] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-24 02:56:16,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-24 02:56:16,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,506] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-24 02:56:16,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-24 02:56:16,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-24 02:56:16,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-24 02:56:16,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-24 02:56:16,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-24 02:56:16,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-24 02:56:16,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:56:16,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:16,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-24 02:56:16,817] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-24 02:56:16,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-24 02:56:24,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4970585e-14 4.2980741e-06 7.9630396e-08 9.9998772e-01 7.9230367e-06], sum to 1.0000
[2019-03-24 02:56:24,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1625
[2019-03-24 02:56:24,762] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 50.66666666666667, 1.0, 2.0, 0.5968083544458141, 1.0, 2.0, 0.5968083544458141, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1404847.06406925, 1404847.06406925, 268981.7055469255], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 123600.0000, 
sim time next is 124200.0000, 
raw observation next is [29.25, 49.5, 1.0, 2.0, 0.6087970904546587, 1.0, 2.0, 0.6087970904546587, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1428704.213310021, 1428704.213310021, 272976.7915457432], 
processed observation next is [1.0, 0.43478260869565216, 0.6388888888888888, 0.495, 1.0, 1.0, 0.5342822505412603, 1.0, 1.0, 0.5342822505412603, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5102515047535789, 0.5102515047535789, 0.5249553683571985], 
reward next is 0.4750, 
noisyNet noise sample is [array([0.67227924], dtype=float32), -1.0217314]. 
=============================================
[2019-03-24 02:56:26,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7406316e-17 3.2875256e-09 5.1102274e-09 1.0000000e+00 3.4713739e-08], sum to 1.0000
[2019-03-24 02:56:26,517] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-24 02:56:26,523] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 14.5, 1.0, 2.0, 0.1816884175204382, 1.0, 2.0, 0.1816884175204382, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467321.3374159841, 467321.3374159846, 156349.4490595902], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 160200.0000, 
sim time next is 160800.0000, 
raw observation next is [31.93333333333334, 14.33333333333333, 1.0, 2.0, 0.1818195843265601, 1.0, 2.0, 0.1818195843265601, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467989.592787864, 467989.592787864, 156374.1055150606], 
processed observation next is [1.0, 0.8695652173913043, 0.7382716049382719, 0.1433333333333333, 1.0, 1.0, 0.025975695626857247, 1.0, 1.0, 0.025975695626857247, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16713914028138, 0.16713914028138, 0.30071943368280885], 
reward next is 0.6993, 
noisyNet noise sample is [array([-0.02692044], dtype=float32), 0.2701493]. 
=============================================
[2019-03-24 02:56:31,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2288612e-12 7.4671075e-04 9.9166840e-08 9.9922097e-01 3.2145599e-05], sum to 1.0000
[2019-03-24 02:56:31,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-24 02:56:31,561] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 40.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389618.7878034788, 389618.7878034792, 148923.71359383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 253800.0000, 
sim time next is 254400.0000, 
raw observation next is [24.36666666666667, 41.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385329.735224455, 385329.7352244555, 148257.978002312], 
processed observation next is [0.0, 0.9565217391304348, 0.4580246913580248, 0.4166666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1376177625801625, 0.13761776258016267, 0.28511149615829234], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7179713], dtype=float32), 0.4133247]. 
=============================================
[2019-03-24 02:56:32,340] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9209327e-07 3.2185072e-01 5.9382466e-05 6.6742206e-01 1.0667642e-02], sum to 1.0000
[2019-03-24 02:56:32,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-24 02:56:32,357] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 46.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 360692.2969646686, 360692.296964669, 144317.5521041608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 259800.0000, 
sim time next is 260400.0000, 
raw observation next is [22.46666666666667, 46.66666666666667, 1.0, 2.0, 0.2778677107430196, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358386.6725553446, 358386.6725553446, 104281.032222675], 
processed observation next is [0.0, 0.0, 0.3876543209876544, 0.46666666666666673, 1.0, 1.0, 0.1403187032654995, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12799524019833736, 0.12799524019833736, 0.2005404465820673], 
reward next is 0.7995, 
noisyNet noise sample is [array([-0.36869976], dtype=float32), -0.58432776]. 
=============================================
[2019-03-24 02:56:32,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4470251e-06 4.7290817e-01 2.7302158e-04 5.1144636e-01 1.5369986e-02], sum to 1.0000
[2019-03-24 02:56:32,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2283
[2019-03-24 02:56:32,495] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 49.66666666666667, 1.0, 2.0, 0.263493076940944, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339887.2556789272, 339887.2556789272, 95457.72872154201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 265800.0000, 
sim time next is 266400.0000, 
raw observation next is [20.9, 50.0, 1.0, 2.0, 0.262818821898978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339017.3225872531, 339017.3225872531, 96147.20557739971], 
processed observation next is [0.0, 0.08695652173913043, 0.32962962962962955, 0.5, 1.0, 1.0, 0.12240335940354521, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12107761520973326, 0.12107761520973326, 0.18489847226423023], 
reward next is 0.8151, 
noisyNet noise sample is [array([0.2047191], dtype=float32), 0.3252584]. 
=============================================
[2019-03-24 02:56:32,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9513781e-07 4.8777810e-01 3.7882966e-04 5.0163406e-01 1.0208456e-02], sum to 1.0000
[2019-03-24 02:56:32,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-24 02:56:32,674] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.06666666666667, 51.83333333333334, 1.0, 2.0, 0.2506065348820112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 323261.0333711182, 323261.0333711182, 91670.6863740644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 273000.0000, 
sim time next is 273600.0000, 
raw observation next is [20.0, 52.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 322120.4242055321, 322120.4242055326, 123601.987657455], 
processed observation next is [0.0, 0.17391304347826086, 0.2962962962962963, 0.52, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1150430086448329, 0.11504300864483306, 0.23769613011049037], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1128196], dtype=float32), 0.56840414]. 
=============================================
[2019-03-24 02:56:34,815] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6926667e-18 9.9989486e-01 1.3604389e-12 1.0512559e-04 4.1266586e-09], sum to 1.0000
[2019-03-24 02:56:34,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5443
[2019-03-24 02:56:34,825] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 31.5, 1.0, 2.0, 0.3243412143686988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 416170.7388659971, 416170.7388659976, 118635.9524410141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 307800.0000, 
sim time next is 308400.0000, 
raw observation next is [27.53333333333333, 31.66666666666666, 1.0, 2.0, 0.3255146501780785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 417308.4994851525, 417308.4994851521, 118787.1440004978], 
processed observation next is [0.0, 0.5652173913043478, 0.5753086419753086, 0.3166666666666666, 1.0, 1.0, 0.19704125021199823, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1490387498161259, 0.14903874981612575, 0.2284368153855727], 
reward next is 0.7716, 
noisyNet noise sample is [array([0.03431391], dtype=float32), 0.33136123]. 
=============================================
[2019-03-24 02:56:40,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5815106e-11 1.5629898e-01 3.1325760e-06 8.3069479e-01 1.3003054e-02], sum to 1.0000
[2019-03-24 02:56:40,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0657
[2019-03-24 02:56:40,736] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 31.66666666666667, 1.0, 2.0, 0.4337221278631698, 1.0, 1.0, 0.4337221278631698, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1064506.18244311, 1064506.18244311, 218599.0509383288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478200.0000, 
sim time next is 478800.0000, 
raw observation next is [31.0, 31.0, 1.0, 2.0, 0.9145294637076202, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.11359720575038, 6.9112, 121.925249151176, 1237940.728878631, 1134295.94397644, 224661.1124696361], 
processed observation next is [1.0, 0.5652173913043478, 0.7037037037037037, 0.31, 1.0, 1.0, 0.8982493615566908, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02023972057503798, 0.0, 0.8094568610410952, 0.44212168888522535, 0.4051056942773, 0.4320406009031464], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0652785], dtype=float32), -0.94058806]. 
=============================================
[2019-03-24 02:56:40,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.11415775e-14 9.91178811e-01 9.29042585e-07 8.72813910e-03
 9.20225575e-05], sum to 1.0000
[2019-03-24 02:56:40,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0996
[2019-03-24 02:56:40,953] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 30.33333333333333, 1.0, 2.0, 0.3444499728828344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436908.1712566337, 436908.1712566337, 121229.1996963634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412800.0000, 
sim time next is 413400.0000, 
raw observation next is [29.15, 30.66666666666667, 1.0, 2.0, 0.3421916411982355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434223.5511164907, 434223.5511164907, 120934.2497635966], 
processed observation next is [1.0, 0.782608695652174, 0.6351851851851852, 0.3066666666666667, 1.0, 1.0, 0.21689481095028032, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15507983968446096, 0.15507983968446096, 0.23256586492999345], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.35572493], dtype=float32), -0.2229978]. 
=============================================
[2019-03-24 02:56:49,195] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 02:56:49,197] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:56:49,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:49,200] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:56:49,201] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:56:49,201] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:49,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:56:49,202] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:49,203] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:49,210] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:56:49,211] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:56:49,230] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-24 02:56:49,255] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-24 02:56:49,256] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-24 02:56:49,303] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-24 02:56:49,304] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-24 02:56:53,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78834784]
[2019-03-24 02:56:53,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.02343064833333, 38.86332346333334, 1.0, 2.0, 0.3882796106037726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487948.6591585346, 487948.6591585346, 127108.9410713763]
[2019-03-24 02:56:53,209] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:56:53,212] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7574782e-09 9.3050361e-01 7.9502602e-04 5.6407224e-02 1.2294179e-02], sampled 0.016429594413712723
[2019-03-24 02:57:05,497] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78834784]
[2019-03-24 02:57:05,500] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 31.0, 1.0, 2.0, 0.2300072597795891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 296684.5879877693, 296684.5879877693, 80693.72243515246]
[2019-03-24 02:57:05,502] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:57:05,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7304429e-10 9.4727647e-01 3.6039986e-04 4.4209871e-02 8.1531117e-03], sampled 0.07546175423731594
[2019-03-24 02:57:25,303] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78834784]
[2019-03-24 02:57:25,304] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.5609315043546175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 654426.4412846892, 654426.4412846888, 152200.8263547159]
[2019-03-24 02:57:25,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:57:25,306] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0142612e-10 9.5050257e-01 3.0022813e-04 4.1782446e-02 7.4147019e-03], sampled 0.254180349343204
[2019-03-24 02:57:32,393] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.78834784]
[2019-03-24 02:57:32,394] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.38574837, 52.30207718, 1.0, 2.0, 0.5195231167849822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615998.1608997729, 615998.1608997729, 145857.3091395915]
[2019-03-24 02:57:32,395] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:57:32,399] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0726721e-10 9.4353229e-01 4.3861315e-04 4.6996295e-02 9.0327896e-03], sampled 0.911343188125482
[2019-03-24 02:58:28,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7529.7888 2463363681.9710 709.0000
[2019-03-24 02:58:28,997] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8335.6447 2140958233.1482 397.0000
[2019-03-24 02:58:29,047] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8114.3567 2215107045.7801 547.0000
[2019-03-24 02:58:29,195] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8050.9705 2264925593.0798 523.0000
[2019-03-24 02:58:29,242] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8150.2015 2191287567.1361 472.0000
[2019-03-24 02:58:30,259] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1500000, evaluation results [1500000.0, 7529.788750296735, 2463363681.971016, 709.0, 8150.201541791855, 2191287567.136081, 472.0, 8335.644727426163, 2140958233.1482105, 397.0, 8050.970539243935, 2264925593.0797777, 523.0, 8114.356681123524, 2215107045.7801065, 547.0]
[2019-03-24 02:58:30,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2085291e-08 9.1409034e-01 3.5451360e-03 5.5988409e-02 2.6376054e-02], sum to 1.0000
[2019-03-24 02:58:30,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4986
[2019-03-24 02:58:30,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1611751.349955381 W.
[2019-03-24 02:58:30,339] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 32.0, 1.0, 2.0, 0.7415018692281766, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9583726768087419, 6.9112, 6.9112, 121.9260426156618, 1611751.349955381, 1611751.349955381, 315002.7028271357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 576000.0000, 
sim time next is 576600.0000, 
raw observation next is [31.8, 31.66666666666667, 1.0, 2.0, 0.6175961636901546, 1.0, 1.0, 0.6175961636901546, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1488134.488487712, 1488134.488487712, 277604.1272213949], 
processed observation next is [1.0, 0.6956521739130435, 0.7333333333333334, 0.3166666666666667, 1.0, 1.0, 0.5447573377263745, 1.0, 0.5, 0.5447573377263745, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5314766030313257, 0.5314766030313257, 0.5338540908103748], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47762525], dtype=float32), -0.87657326]. 
=============================================
[2019-03-24 02:58:31,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9476777e-13 8.9796013e-01 9.9690733e-05 9.4013780e-02 7.9263784e-03], sum to 1.0000
[2019-03-24 02:58:31,642] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8459
[2019-03-24 02:58:31,646] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 62.5, 1.0, 2.0, 0.3834577661740866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488085.1728230429, 488085.1728230434, 126503.8905535328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 617400.0000, 
sim time next is 618000.0000, 
raw observation next is [21.76666666666667, 63.33333333333333, 1.0, 2.0, 0.3762194486746953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479118.1205071408, 479118.1205071408, 125507.7592222114], 
processed observation next is [1.0, 0.13043478260869565, 0.3617283950617285, 0.6333333333333333, 1.0, 1.0, 0.25740410556511345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.171113614466836, 0.171113614466836, 0.24136107542732962], 
reward next is 0.7586, 
noisyNet noise sample is [array([-1.4367387], dtype=float32), 1.1204475]. 
=============================================
[2019-03-24 02:58:31,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[58.223747]
 [58.39452 ]
 [58.64007 ]
 [59.03021 ]
 [59.129   ]], R is [[58.21220398]
 [58.38680267]
 [58.55644989]
 [58.71442413]
 [58.88669586]].
[2019-03-24 02:58:32,898] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0839108e-12 9.9321014e-01 1.4776392e-04 6.4597339e-03 1.8235204e-04], sum to 1.0000
[2019-03-24 02:58:32,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1489
[2019-03-24 02:58:32,908] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 71.0, 1.0, 2.0, 0.3005439443253635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384020.1455242097, 384020.1455242097, 115643.7780385059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 622800.0000, 
sim time next is 623400.0000, 
raw observation next is [20.58333333333334, 70.0, 1.0, 2.0, 0.3420175202503838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 436627.382288394, 436627.3822883936, 120925.3866494345], 
processed observation next is [1.0, 0.21739130434782608, 0.3179012345679015, 0.7, 1.0, 1.0, 0.21668752410759975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15593835081728355, 0.15593835081728344, 0.23254882047968173], 
reward next is 0.7675, 
noisyNet noise sample is [array([-0.26551166], dtype=float32), -1.4150063]. 
=============================================
[2019-03-24 02:58:36,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9756219e-15 9.7884631e-01 1.9703998e-06 1.0369653e-02 1.0782075e-02], sum to 1.0000
[2019-03-24 02:58:36,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6044
[2019-03-24 02:58:36,313] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.11666666666667, 31.66666666666667, 1.0, 2.0, 0.3472202209935242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439815.1522518914, 439815.1522518914, 121588.7619775265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 684600.0000, 
sim time next is 685200.0000, 
raw observation next is [28.93333333333333, 32.33333333333334, 1.0, 2.0, 0.3448009377372245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436713.2941379446, 436713.2941379446, 121269.7656937525], 
processed observation next is [1.0, 0.9565217391304348, 0.6271604938271603, 0.3233333333333334, 1.0, 1.0, 0.22000111635383868, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1559690336206945, 0.1559690336206945, 0.23321108787260098], 
reward next is 0.7668, 
noisyNet noise sample is [array([-0.9656679], dtype=float32), 0.766439]. 
=============================================
[2019-03-24 02:58:39,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0348207e-15 9.9485540e-01 7.3469969e-06 8.5287311e-06 5.1286472e-03], sum to 1.0000
[2019-03-24 02:58:39,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2605
[2019-03-24 02:58:39,211] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 58.0, 1.0, 2.0, 0.3120308511521739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396570.7243281645, 396570.7243281645, 117067.42074699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.58, 1.0, 1.0, 0.18342182099366253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14246955213933976, 0.14246955213933957, 0.22562094760006463], 
reward next is 0.7744, 
noisyNet noise sample is [array([-0.31291592], dtype=float32), -0.40814543]. 
=============================================
[2019-03-24 02:58:39,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5641211e-10 9.9749595e-01 1.1866112e-04 4.0358860e-05 2.3449864e-03], sum to 1.0000
[2019-03-24 02:58:39,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1967
[2019-03-24 02:58:39,298] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 71.5, 1.0, 2.0, 0.72469825551307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 913748.8102798593, 913748.8102798593, 184041.8600737409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1181400.0000, 
sim time next is 1182000.0000, 
raw observation next is [21.4, 72.0, 1.0, 2.0, 0.7284715281137755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918174.6589767487, 918174.6589767487, 184789.8545355403], 
processed observation next is [1.0, 0.6956521739130435, 0.3481481481481481, 0.72, 1.0, 1.0, 0.676751819183066, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32791952106312455, 0.32791952106312455, 0.35536510487603906], 
reward next is 0.6446, 
noisyNet noise sample is [array([-2.506319], dtype=float32), 0.03897373]. 
=============================================
[2019-03-24 02:58:39,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[43.50531 ]
 [43.711174]
 [43.571976]
 [43.551685]
 [43.50832 ]], R is [[43.75606918]
 [43.96458054]
 [44.20281601]
 [44.43499756]
 [44.66636658]].
[2019-03-24 02:58:40,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0899873e-17 9.7745025e-01 1.0674532e-07 4.1673702e-06 2.2545433e-02], sum to 1.0000
[2019-03-24 02:58:40,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8026
[2019-03-24 02:58:40,260] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 33.5, 1.0, 2.0, 0.3325496463682084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422591.8204035962, 422591.8204035957, 119683.3786277826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 768600.0000, 
sim time next is 769200.0000, 
raw observation next is [28.03333333333333, 34.0, 1.0, 2.0, 0.3313891716782503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421216.9992084493, 421216.9992084493, 119534.0558521074], 
processed observation next is [1.0, 0.9130434782608695, 0.5938271604938271, 0.34, 1.0, 1.0, 0.20403472818839324, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1504346425744462, 0.1504346425744462, 0.22987318433097575], 
reward next is 0.7701, 
noisyNet noise sample is [array([0.4909374], dtype=float32), 1.2619753]. 
=============================================
[2019-03-24 02:58:40,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9106916e-18 8.4425110e-01 2.2641470e-04 1.0232710e-05 1.5551221e-01], sum to 1.0000
[2019-03-24 02:58:40,287] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8238
[2019-03-24 02:58:40,291] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.28333333333333, 27.33333333333333, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2024810764062261, 6.911199999999999, 6.9112, 121.94756008, 448114.7747440111, 448114.7747440116, 184364.24878358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 760200.0000, 
sim time next is 760800.0000, 
raw observation next is [30.16666666666667, 27.66666666666667, 1.0, 2.0, 0.3508544797793473, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443831.0484708367, 443831.0484708367, 122062.7261778005], 
processed observation next is [1.0, 0.8260869565217391, 0.6728395061728397, 0.2766666666666667, 1.0, 1.0, 0.2272077140230325, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15851108873958455, 0.15851108873958455, 0.2347360118803856], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9174611], dtype=float32), -1.7348785]. 
=============================================
[2019-03-24 02:58:44,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9725206e-17 9.9869210e-01 4.0307937e-06 3.2611759e-05 1.2712338e-03], sum to 1.0000
[2019-03-24 02:58:44,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4763
[2019-03-24 02:58:44,926] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 53.00000000000001, 1.0, 2.0, 0.3985863299672306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 494015.3705500816, 494015.3705500816, 128423.6358026004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 858000.0000, 
sim time next is 858600.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.3995729640818796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 495048.2821542382, 495048.2821542377, 128558.2251800131], 
processed observation next is [0.0, 0.9565217391304348, 0.5185185185185185, 0.54, 1.0, 1.0, 0.2852059096212852, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17680295791222794, 0.17680295791222775, 0.24722735611540983], 
reward next is 0.7528, 
noisyNet noise sample is [array([0.42034328], dtype=float32), -0.24141835]. 
=============================================
[2019-03-24 02:59:05,026] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4497299e-19 9.9999988e-01 1.1260424e-08 9.7890172e-08 1.3380223e-08], sum to 1.0000
[2019-03-24 02:59:05,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4057
[2019-03-24 02:59:05,043] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.45, 90.0, 1.0, 2.0, 0.3602773335239595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 457823.5562529002, 457823.5562528997, 123338.356799169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1233000.0000, 
sim time next is 1233600.0000, 
raw observation next is [18.53333333333333, 89.66666666666666, 1.0, 2.0, 0.3323726224638787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422164.3434182294, 422164.3434182298, 119659.1480143898], 
processed observation next is [1.0, 0.2608695652173913, 0.24197530864197525, 0.8966666666666666, 1.0, 1.0, 0.20520550293318895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1507729797922248, 0.15077297979222493, 0.23011374618151884], 
reward next is 0.7699, 
noisyNet noise sample is [array([-0.44328433], dtype=float32), -0.33726555]. 
=============================================
[2019-03-24 02:59:06,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0099136e-16 9.9999845e-01 6.7489714e-07 1.6910673e-07 6.6974468e-07], sum to 1.0000
[2019-03-24 02:59:06,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3154
[2019-03-24 02:59:06,839] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 55.33333333333333, 1.0, 2.0, 0.3568088374056348, 1.0, 1.0, 0.3568088374056348, 1.0, 2.0, 0.574871432907333, 6.9112, 6.9112, 121.94756008, 1279619.721304858, 1279619.721304858, 278290.9562895066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1266000.0000, 
sim time next is 1266600.0000, 
raw observation next is [26.28333333333333, 55.16666666666667, 1.0, 2.0, 0.9835932669388465, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.471412680361989, 6.9112, 121.9237052942766, 1487562.777637035, 1200689.313518233, 240530.9800156389], 
processed observation next is [1.0, 0.6521739130434783, 0.5290123456790122, 0.5516666666666667, 1.0, 1.0, 0.9804681749271983, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05602126803619889, 0.0, 0.8094466114367812, 0.5312724205846553, 0.4288176119707975, 0.4625595769531517], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17752765], dtype=float32), 1.772004]. 
=============================================
[2019-03-24 02:59:11,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9153413e-14 9.9999166e-01 3.3835872e-07 7.6298365e-06 3.1086637e-07], sum to 1.0000
[2019-03-24 02:59:11,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2439
[2019-03-24 02:59:11,733] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1407093.931662458 W.
[2019-03-24 02:59:11,737] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 33.0, 1.0, 2.0, 0.577889684139215, 1.0, 1.0, 0.577889684139215, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1407093.931662458, 1407093.931662458, 264206.971281638], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1346400.0000, 
sim time next is 1347000.0000, 
raw observation next is [30.71666666666667, 32.83333333333334, 1.0, 2.0, 0.4588589337365227, 1.0, 2.0, 0.4588589337365227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1118785.988859834, 1118785.988859834, 225866.3914888439], 
processed observation next is [1.0, 0.6086956521739131, 0.69320987654321, 0.3283333333333334, 1.0, 1.0, 0.35578444492443184, 1.0, 1.0, 0.35578444492443184, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.39956642459279784, 0.39956642459279784, 0.43435844517085365], 
reward next is 0.5656, 
noisyNet noise sample is [array([0.68840647], dtype=float32), -0.094833724]. 
=============================================
[2019-03-24 02:59:11,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[52.069756]
 [52.19129 ]
 [51.003754]
 [50.693314]
 [49.99321 ]], R is [[53.38143158]
 [53.33952713]
 [53.28033066]
 [52.74752808]
 [52.22005463]].
[2019-03-24 02:59:20,818] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 02:59:20,819] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:59:20,820] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:59:20,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:59:20,822] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:59:20,822] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:59:20,824] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:59:20,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:59:20,825] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:59:20,826] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:59:20,826] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:59:20,850] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-24 02:59:20,879] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-24 02:59:20,905] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-24 02:59:20,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-24 02:59:20,906] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-24 02:59:58,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.80452865]
[2019-03-24 02:59:58,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.329632595, 82.246275585, 1.0, 2.0, 0.631406209213203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719587.7650526756, 719587.7650526756, 163563.9920406585]
[2019-03-24 02:59:58,158] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:59:58,161] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2351549e-19 9.9999774e-01 6.1402358e-07 1.3492431e-06 4.1603215e-07], sampled 0.35178317546153837
[2019-03-24 02:59:59,571] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.80452865]
[2019-03-24 02:59:59,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 98.66666666666666, 1.0, 2.0, 0.5928792599395037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685741.3057570759, 685741.3057570759, 157343.1154256288]
[2019-03-24 02:59:59,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:59:59,576] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.038827e-19 9.999968e-01 8.226587e-07 1.767780e-06 5.577477e-07], sampled 0.5483258275948423
[2019-03-24 03:00:06,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.80452865]
[2019-03-24 03:00:06,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.08333333333334, 70.66666666666667, 1.0, 2.0, 0.8786015161423841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1001490.182569208, 1001490.182569208, 212729.2014025654]
[2019-03-24 03:00:06,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:00:06,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.3990804e-19 9.9999595e-01 1.0993515e-06 2.3100197e-06 7.4587655e-07], sampled 0.1791881334513663
[2019-03-24 03:00:44,195] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.80452865]
[2019-03-24 03:00:44,197] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.24402775666667, 77.82364240333334, 1.0, 2.0, 0.4377436010809923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533263.6486503965, 533263.6486503965, 133825.1342935663]
[2019-03-24 03:00:44,198] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:00:44,202] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3968419e-19 9.9999714e-01 7.6136655e-07 1.6458273e-06 5.1618338e-07], sampled 0.7365570306379243
[2019-03-24 03:00:53,965] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.80452865]
[2019-03-24 03:00:53,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.24256856, 87.75699984666667, 1.0, 2.0, 0.5545025874385837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659115.0626982064, 659115.0626982064, 151633.9331086947]
[2019-03-24 03:00:53,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:00:53,971] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1767154e-18 9.9999416e-01 1.5578173e-06 3.1902148e-06 1.0578311e-06], sampled 0.6117155769115494
[2019-03-24 03:00:58,171] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 03:00:58,443] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 03:00:58,646] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 03:00:58,679] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 03:00:58,714] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 03:00:59,729] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1525000, evaluation results [1525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 03:01:02,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9560187e-12 9.7399604e-01 1.1410001e-02 7.6589417e-03 6.9350698e-03], sum to 1.0000
[2019-03-24 03:01:02,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9424
[2019-03-24 03:01:02,074] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 81.0, 1.0, 2.0, 0.5529794776723003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693007.2282176848, 693007.2282176848, 152408.6362023544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1567800.0000, 
sim time next is 1568400.0000, 
raw observation next is [20.6, 81.66666666666666, 1.0, 2.0, 0.5391412434204399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675781.8813749254, 675781.8813749254, 150097.2289894031], 
processed observation next is [1.0, 0.13043478260869565, 0.3185185185185186, 0.8166666666666665, 1.0, 1.0, 0.4513586231195713, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2413506719196162, 0.2413506719196162, 0.28864851728731367], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.20690578], dtype=float32), 1.7507756]. 
=============================================
[2019-03-24 03:01:06,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.75654991e-09 1.01684406e-01 5.79598062e-02 7.36985207e-01
 1.03370555e-01], sum to 1.0000
[2019-03-24 03:01:06,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2032
[2019-03-24 03:01:06,020] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.73333333333333, 45.33333333333333, 1.0, 2.0, 0.1794185423303393, 1.0, 2.0, 0.1794185423303393, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446624.3826787747, 446624.3826787751, 155680.2433201936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1622400.0000, 
sim time next is 1623000.0000, 
raw observation next is [26.61666666666667, 45.66666666666667, 1.0, 2.0, 0.1783768137762507, 1.0, 2.0, 0.1783768137762507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 444261.5706635289, 444261.5706635293, 155470.4686666279], 
processed observation next is [1.0, 0.782608695652174, 0.5413580246913582, 0.4566666666666667, 1.0, 1.0, 0.021877159257441305, 1.0, 1.0, 0.021877159257441305, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15866484666554603, 0.15866484666554617, 0.29898167051274593], 
reward next is 0.7010, 
noisyNet noise sample is [array([1.7681535], dtype=float32), -1.4003707]. 
=============================================
[2019-03-24 03:01:06,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[47.820114]
 [47.97728 ]
 [48.240124]
 [48.619286]
 [48.38947 ]], R is [[48.38705063]
 [48.6037941 ]
 [48.81742477]
 [49.0282402 ]
 [48.53796005]].
[2019-03-24 03:01:09,495] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5651875e-13 9.9392253e-01 4.2044790e-03 1.7039422e-03 1.6902934e-04], sum to 1.0000
[2019-03-24 03:01:09,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1911
[2019-03-24 03:01:09,507] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.5103437165712202, 1.0, 1.0, 0.5103437165712202, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9258349573733, 1239825.376271211, 1239825.376271211, 241721.8427924417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1697400.0000, 
sim time next is 1698000.0000, 
raw observation next is [23.53333333333333, 69.0, 1.0, 2.0, 0.9475199754501321, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.277070840153002, 6.9112, 121.9244909346602, 1351985.094740633, 1164628.907819971, 232116.9842065426], 
processed observation next is [1.0, 0.6521739130434783, 0.4271604938271604, 0.69, 1.0, 1.0, 0.9375237802977763, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03658708401530024, 0.0, 0.8094518272719198, 0.48285181955022605, 0.41593889564998965, 0.4463788157818127], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4537147], dtype=float32), -0.3214268]. 
=============================================
[2019-03-24 03:01:09,533] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[54.300602]
 [53.553673]
 [53.122124]
 [52.694237]
 [53.138496]], R is [[53.69740677]
 [53.16043472]
 [52.62882996]
 [52.58070755]
 [52.05490112]].
[2019-03-24 03:01:13,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1258677e-11 9.8673254e-01 1.1534069e-02 1.3883642e-03 3.4503266e-04], sum to 1.0000
[2019-03-24 03:01:13,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1884
[2019-03-24 03:01:13,269] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666667, 69.66666666666667, 1.0, 2.0, 0.9094446885591668, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.967851699579131, 6.9112, 121.9258413040637, 1136263.557955272, 1107252.872198811, 222849.4695940732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1764600.0000, 
sim time next is 1765200.0000, 
raw observation next is [24.23333333333333, 69.33333333333334, 1.0, 2.0, 0.8433821968857625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260085010142, 1030961.76999635, 1030961.76999635, 208147.1832067278], 
processed observation next is [1.0, 0.43478260869565216, 0.45308641975308633, 0.6933333333333335, 1.0, 1.0, 0.8135502343878126, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094619023343526, 0.3682006321415536, 0.3682006321415536, 0.40028304462832265], 
reward next is 0.5997, 
noisyNet noise sample is [array([-0.48105648], dtype=float32), -0.2763615]. 
=============================================
[2019-03-24 03:01:19,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8495911e-16 9.9998307e-01 1.1448226e-05 1.1224340e-06 4.4010035e-06], sum to 1.0000
[2019-03-24 03:01:19,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1910
[2019-03-24 03:01:19,503] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 91.0, 1.0, 2.0, 0.4175281592850133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513084.4444113069, 513084.4444113069, 131012.5083858221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [20.91666666666667, 91.0, 1.0, 2.0, 0.4166828704638791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512174.6824490363, 512174.6824490363, 130894.4136458111], 
processed observation next is [1.0, 0.9130434782608695, 0.3302469135802471, 0.91, 1.0, 1.0, 0.30557484579033223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1829195294460844, 0.1829195294460844, 0.25172002624194445], 
reward next is 0.7483, 
noisyNet noise sample is [array([1.5777436], dtype=float32), -0.8302696]. 
=============================================
[2019-03-24 03:01:19,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.71444 ]
 [65.701645]
 [65.72275 ]
 [65.63248 ]
 [65.400055]], R is [[65.86733246]
 [65.95671082]
 [66.0447998 ]
 [66.13143158]
 [66.21652985]].
[2019-03-24 03:01:23,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2496445e-13 9.9957055e-01 2.0703977e-04 3.5584894e-06 2.1877562e-04], sum to 1.0000
[2019-03-24 03:01:23,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3086
[2019-03-24 03:01:23,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1541161.066951582 W.
[2019-03-24 03:01:23,590] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.3, 61.83333333333334, 1.0, 2.0, 0.4467644469074517, 1.0, 1.0, 0.4467644469074517, 1.0, 1.0, 0.711703983457984, 6.911199999999999, 6.9112, 121.94756008, 1541161.066951582, 1541161.066951582, 318251.9413192748], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1951800.0000, 
sim time next is 1952400.0000, 
raw observation next is [27.4, 61.66666666666667, 1.0, 2.0, 0.4105311201700227, 1.0, 2.0, 0.4105311201700227, 1.0, 2.0, 0.6537008801306999, 6.911199999999999, 6.9112, 121.94756008, 1409021.032659555, 1409021.032659555, 301758.4967532413], 
processed observation next is [1.0, 0.6086956521739131, 0.5703703703703703, 0.6166666666666667, 1.0, 1.0, 0.2982513335357413, 1.0, 1.0, 0.2982513335357413, 1.0, 1.0, 0.5671261001633748, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5032217973784125, 0.5032217973784125, 0.5803048014485409], 
reward next is 0.4197, 
noisyNet noise sample is [array([0.4212905], dtype=float32), -0.2901354]. 
=============================================
[2019-03-24 03:01:25,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2331311e-18 9.9965274e-01 6.3723505e-06 6.9623759e-08 3.4081715e-04], sum to 1.0000
[2019-03-24 03:01:25,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-24 03:01:25,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 63.83333333333334, 1.0, 2.0, 0.377332190612282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471155.3520282395, 471155.3520282395, 125545.7294421976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416200.0000, 
sim time next is 2416800.0000, 
raw observation next is [23.4, 63.66666666666667, 1.0, 2.0, 0.3706777872824489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463800.1068928704, 463800.1068928704, 124654.8530707611], 
processed observation next is [1.0, 1.0, 0.42222222222222217, 0.6366666666666667, 1.0, 1.0, 0.25080688962196296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1656428953188823, 0.1656428953188823, 0.2397208712899252], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.22955295], dtype=float32), 0.46604553]. 
=============================================
[2019-03-24 03:01:31,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8390966e-18 9.9998558e-01 1.3570849e-07 9.2293213e-09 1.4277807e-05], sum to 1.0000
[2019-03-24 03:01:31,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1010
[2019-03-24 03:01:31,570] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 77.0, 1.0, 2.0, 0.5398349738647489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633485.9029488236, 633485.9029488236, 148881.8168247118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2109600.0000, 
sim time next is 2110200.0000, 
raw observation next is [25.83333333333334, 76.16666666666667, 1.0, 2.0, 0.5447324819581881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637897.5769164736, 637897.5769164736, 149626.9681292682], 
processed observation next is [0.0, 0.43478260869565216, 0.5123456790123458, 0.7616666666666667, 1.0, 1.0, 0.4580148594740335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22782056318445484, 0.22782056318445484, 0.28774416947936193], 
reward next is 0.7123, 
noisyNet noise sample is [array([1.6858207], dtype=float32), -0.048946343]. 
=============================================
[2019-03-24 03:01:35,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7563286e-14 9.9994314e-01 6.6800290e-08 2.3367971e-07 5.6461391e-05], sum to 1.0000
[2019-03-24 03:01:35,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9117
[2019-03-24 03:01:35,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 89.0, 1.0, 2.0, 0.5795769780254836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675968.0399159917, 675968.0399159917, 155328.545371715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2184600.0000, 
sim time next is 2185200.0000, 
raw observation next is [24.2, 89.0, 1.0, 2.0, 0.5831626457778776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679689.02173559, 679689.02173559, 155918.3325903324], 
processed observation next is [1.0, 0.30434782608695654, 0.45185185185185184, 0.89, 1.0, 1.0, 0.5037650544974733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24274607919128213, 0.24274607919128213, 0.29984294728910077], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.45148385], dtype=float32), 0.33075753]. 
=============================================
[2019-03-24 03:01:41,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7570644e-08 9.9987817e-01 4.3728698e-05 3.1485641e-05 4.6608486e-05], sum to 1.0000
[2019-03-24 03:01:41,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1600
[2019-03-24 03:01:41,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1344034.217177475 W.
[2019-03-24 03:01:41,965] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.6, 86.0, 1.0, 2.0, 0.9863786395597449, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.265674160919845, 6.9112, 121.9246576566081, 1344034.217177475, 1162513.82616076, 239471.9020823801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2287200.0000, 
sim time next is 2287800.0000, 
raw observation next is [23.7, 85.5, 1.0, 2.0, 0.5189586781123803, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8298207278170493, 6.911200000000001, 6.9112, 121.9258291575075, 1216865.144496789, 1216865.144496788, 262975.9003717615], 
processed observation next is [1.0, 0.4782608695652174, 0.4333333333333333, 0.855, 1.0, 1.0, 0.42733175965759557, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7872759097713117, 8.881784197001253e-17, 0.0, 0.8094607116799721, 0.4345946944631389, 0.4345946944631386, 0.5057228853303106], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54632366], dtype=float32), -1.6558762]. 
=============================================
[2019-03-24 03:01:50,375] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 03:01:50,375] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:01:50,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:01:50,378] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:01:50,379] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:01:50,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:01:50,386] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:01:50,386] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:01:50,387] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:01:50,388] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:01:50,389] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:01:50,414] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-24 03:01:50,439] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-24 03:01:50,467] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-24 03:01:50,494] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-24 03:01:50,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-24 03:02:14,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8118963]
[2019-03-24 03:02:14,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.36666666666667, 71.66666666666667, 1.0, 2.0, 0.7432895008906316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 927439.0028354987, 927439.0028354987, 187603.3106292585]
[2019-03-24 03:02:14,680] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:02:14,682] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0129892e-13 8.1647319e-01 7.7056140e-02 9.7503304e-02 8.9674210e-03], sampled 0.8727463824141243
[2019-03-24 03:02:39,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8118963]
[2019-03-24 03:02:39,082] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 87.66666666666667, 1.0, 2.0, 0.6651108114436063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758018.5104808949, 758018.5104808949, 169643.6539471497]
[2019-03-24 03:02:39,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:02:39,086] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0708024e-14 8.5563141e-01 5.9428230e-02 7.9542719e-02 5.3975908e-03], sampled 0.09138762030184677
[2019-03-24 03:02:59,618] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8118963]
[2019-03-24 03:02:59,621] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.26041852, 86.79359230666667, 1.0, 2.0, 0.274248016033391, 1.0, 1.0, 0.274248016033391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 636188.0512606205, 636188.0512606209, 174944.8709841747]
[2019-03-24 03:02:59,621] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:02:59,624] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4986649e-14 8.4679705e-01 6.3381985e-02 8.3747163e-02 6.0737133e-03], sampled 0.3107651768257169
[2019-03-24 03:03:27,863] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.8251 2176165047.8502 384.0000
[2019-03-24 03:03:28,291] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7193.5523 2297523086.9447 485.0000
[2019-03-24 03:03:28,340] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7327.0006 2222387340.6916 423.0000
[2019-03-24 03:03:28,370] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7347.4322 2247680331.5456 503.0000
[2019-03-24 03:03:28,418] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6794.3102 2492353434.1611 657.0000
[2019-03-24 03:03:29,435] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1550000, evaluation results [1550000.0, 6794.310217919535, 2492353434.1611223, 657.0, 7327.000576183339, 2222387340.691642, 423.0, 7491.825052277974, 2176165047.8501525, 384.0, 7193.552251191529, 2297523086.9447303, 485.0, 7347.432173568363, 2247680331.5456433, 503.0]
[2019-03-24 03:03:30,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7906162e-11 4.4954952e-02 9.1531688e-01 3.3005770e-02 6.7223907e-03], sum to 1.0000
[2019-03-24 03:03:30,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5545
[2019-03-24 03:03:30,268] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.3, 23.0, 1.0, 2.0, 0.9409464049058416, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.275192631273648, 6.9112, 121.9245154499396, 1350674.771576056, 1164280.345755426, 230785.2333794558], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2466000.0000, 
sim time next is 2466600.0000, 
raw observation next is [34.41666666666666, 23.0, 1.0, 2.0, 0.4781450494710801, 0.0, 2.0, 0.0, 1.0, 1.0, 0.784257575232104, 6.9112, 6.9112, 121.925823425663, 1172517.231054314, 1172517.231054314, 246376.3023446549], 
processed observation next is [1.0, 0.5652173913043478, 0.8302469135802466, 0.23, 1.0, 1.0, 0.3787441065131906, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7303219690401299, 0.0, 0.0, 0.8094606736264854, 0.4187561539479693, 0.4187561539479693, 0.47380058143202863], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00133103], dtype=float32), 0.39942953]. 
=============================================
[2019-03-24 03:03:30,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6150460e-10 7.6486015e-01 1.8152108e-02 1.9313222e-01 2.3855560e-02], sum to 1.0000
[2019-03-24 03:03:30,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2393
[2019-03-24 03:03:30,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1546810.73939124 W.
[2019-03-24 03:03:30,451] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.34999999999999, 23.83333333333333, 1.0, 2.0, 0.4325695908809493, 1.0, 2.0, 0.4325695908809493, 1.0, 2.0, 0.6958873664832882, 6.9112, 6.9112, 121.94756008, 1546810.73939124, 1546810.73939124, 311428.2581724388], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2476200.0000, 
sim time next is 2476800.0000, 
raw observation next is [34.3, 24.0, 1.0, 2.0, 0.6895186223449666, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9578982146377298, 6.911199999999999, 6.9112, 121.9260426156618, 1550148.645664693, 1550148.645664693, 304895.3764916802], 
processed observation next is [1.0, 0.6956521739130435, 0.8259259259259258, 0.24, 1.0, 1.0, 0.6303793123154364, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9473727682971622, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5536245163088189, 0.5536245163088189, 0.5863372624840004], 
reward next is 0.4137, 
noisyNet noise sample is [array([0.8101443], dtype=float32), -0.5907729]. 
=============================================
[2019-03-24 03:03:32,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2858037e-14 9.9810600e-01 3.2255161e-04 1.3125831e-03 2.5882773e-04], sum to 1.0000
[2019-03-24 03:03:32,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-24 03:03:32,130] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 37.0, 1.0, 2.0, 0.3653591442066215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 456820.7471540273, 456820.7471540269, 123929.0353113917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2494800.0000, 
sim time next is 2495400.0000, 
raw observation next is [28.93333333333334, 37.66666666666667, 1.0, 2.0, 0.3692432181205175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461555.644439016, 461555.644439016, 124452.3000614472], 
processed observation next is [1.0, 0.9130434782608695, 0.6271604938271608, 0.3766666666666667, 1.0, 1.0, 0.2490990691910923, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16484130158536286, 0.16484130158536286, 0.23933134627201383], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.7546912], dtype=float32), -0.01928549]. 
=============================================
[2019-03-24 03:03:33,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3389550e-15 9.9984384e-01 6.6525454e-06 8.5935091e-05 6.3559390e-05], sum to 1.0000
[2019-03-24 03:03:33,573] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3767
[2019-03-24 03:03:33,582] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 90.66666666666667, 1.0, 2.0, 0.7462953603057716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855976.7169773228, 855976.7169773228, 185367.3148086843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2956200.0000, 
sim time next is 2956800.0000, 
raw observation next is [24.8, 91.33333333333334, 1.0, 2.0, 0.7188889488578898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822027.8832399973, 822027.8832399973, 179884.6718005804], 
processed observation next is [1.0, 0.21739130434782608, 0.4740740740740741, 0.9133333333333334, 1.0, 1.0, 0.665343986735583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2935813868714276, 0.2935813868714276, 0.34593206115496233], 
reward next is 0.6541, 
noisyNet noise sample is [array([0.43802968], dtype=float32), 0.3622658]. 
=============================================
[2019-03-24 03:03:42,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4780807e-18 9.9996829e-01 7.5587341e-06 2.3922776e-05 2.2469081e-07], sum to 1.0000
[2019-03-24 03:03:42,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5959
[2019-03-24 03:03:42,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.5, 1.0, 2.0, 0.434410473710774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 530637.4257788231, 530637.4257788226, 133377.9715855906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2703000.0000, 
sim time next is 2703600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4455684782249427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541989.1735080916, 541989.1735080916, 134957.3624120711], 
processed observation next is [0.0, 0.30434782608695654, 0.4444444444444444, 0.74, 1.0, 1.0, 0.3399624740773127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19356756196717556, 0.19356756196717556, 0.25953338925398284], 
reward next is 0.7405, 
noisyNet noise sample is [array([0.1237674], dtype=float32), -0.20233217]. 
=============================================
[2019-03-24 03:03:42,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.5090344e-20 1.0000000e+00 3.4868470e-09 1.3694001e-08 2.2290552e-09], sum to 1.0000
[2019-03-24 03:03:42,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6138
[2019-03-24 03:03:42,792] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.5410766011584892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636314.5079477953, 636314.5079477953, 149141.7241181529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2714400.0000, 
sim time next is 2715000.0000, 
raw observation next is [28.08333333333334, 61.83333333333334, 1.0, 2.0, 0.5440901591678886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639303.133515033, 639303.133515033, 149612.4696474667], 
processed observation next is [0.0, 0.43478260869565216, 0.5956790123456792, 0.6183333333333334, 1.0, 1.0, 0.45725018948558166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22832254768394036, 0.22832254768394036, 0.2877162877835898], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.13097657], dtype=float32), -0.24856305]. 
=============================================
[2019-03-24 03:03:42,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.65268 ]
 [70.582924]
 [70.52517 ]
 [70.490036]
 [70.440384]], R is [[70.69509125]
 [70.70133209]
 [70.70773315]
 [70.71433258]
 [70.72122192]].
[2019-03-24 03:03:44,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3359710e-21 1.0000000e+00 1.1875409e-11 6.5957506e-10 2.1604814e-10], sum to 1.0000
[2019-03-24 03:03:44,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4904
[2019-03-24 03:03:44,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 56.0, 1.0, 2.0, 0.6148286752558585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702341.1321619293, 702341.1321619293, 160729.3108956975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2727600.0000, 
sim time next is 2728200.0000, 
raw observation next is [30.75, 57.0, 1.0, 2.0, 0.6256299210206616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713001.7047462807, 713001.7047462807, 162541.9234581148], 
processed observation next is [0.0, 0.5652173913043478, 0.6944444444444444, 0.57, 1.0, 1.0, 0.5543213345484067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25464346598081455, 0.25464346598081455, 0.3125806220348361], 
reward next is 0.6874, 
noisyNet noise sample is [array([-0.08754271], dtype=float32), -0.58404756]. 
=============================================
[2019-03-24 03:03:44,328] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6919595e-17 1.0000000e+00 2.4115812e-09 1.6864773e-08 9.1163095e-09], sum to 1.0000
[2019-03-24 03:03:44,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1872
[2019-03-24 03:03:44,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1787955.531145647 W.
[2019-03-24 03:03:44,351] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.31666666666667, 41.16666666666667, 1.0, 2.0, 0.9146018800740455, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9741136642452808, 6.911200000000001, 6.9112, 121.9260426156618, 1787955.531145647, 1787955.531145646, 356039.8272308088], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3147000.0000, 
sim time next is 3147600.0000, 
raw observation next is [31.63333333333333, 39.33333333333334, 1.0, 2.0, 0.8639226149381575, 0.0, 2.0, 0.0, 1.0, 2.0, 0.970971416042624, 6.911199999999999, 6.9112, 121.9260426156618, 1733207.771050065, 1733207.771050065, 344320.2842138614], 
processed observation next is [1.0, 0.43478260869565216, 0.7271604938271603, 0.3933333333333334, 1.0, 1.0, 0.838003113021616, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9637142700532799, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6190027753750232, 0.6190027753750232, 0.6621543927189643], 
reward next is 0.3378, 
noisyNet noise sample is [array([-0.45539755], dtype=float32), -0.70689344]. 
=============================================
[2019-03-24 03:03:46,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8190585e-15 1.0000000e+00 2.3301435e-08 5.2467719e-09 4.7459592e-10], sum to 1.0000
[2019-03-24 03:03:46,779] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-24 03:03:46,782] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 91.33333333333334, 1.0, 2.0, 0.6111316019097041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703627.3806190728, 703627.3806190728, 160353.1665769893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2770800.0000, 
sim time next is 2771400.0000, 
raw observation next is [24.58333333333333, 90.66666666666666, 1.0, 2.0, 0.611718368558175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703871.1012615735, 703871.1012615735, 160434.9362433691], 
processed observation next is [1.0, 0.043478260869565216, 0.46604938271604923, 0.9066666666666666, 1.0, 1.0, 0.5377599625692558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2513825361648477, 0.2513825361648477, 0.3085287235449406], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.61534715], dtype=float32), 0.29194883]. 
=============================================
[2019-03-24 03:03:50,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6466501e-28 1.0000000e+00 1.0950569e-20 2.8781652e-20 1.7890083e-22], sum to 1.0000
[2019-03-24 03:03:50,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6418
[2019-03-24 03:03:50,122] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666667, 95.16666666666667, 1.0, 2.0, 0.5605270226976412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658503.4988920342, 658503.4988920342, 152327.845949012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2850600.0000, 
sim time next is 2851200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5432516795696873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 642307.2862264647, 642307.2862264642, 149637.1260960784], 
processed observation next is [1.0, 0.0, 0.37037037037037035, 1.0, 1.0, 1.0, 0.456251999487723, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22939545936659453, 0.22939545936659436, 0.28776370403092], 
reward next is 0.7122, 
noisyNet noise sample is [array([0.45283556], dtype=float32), 0.47413248]. 
=============================================
[2019-03-24 03:03:56,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0918871e-20 1.0000000e+00 6.5397267e-15 6.5996292e-13 9.4943117e-14], sum to 1.0000
[2019-03-24 03:03:56,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-24 03:03:56,071] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 89.0, 1.0, 2.0, 0.6598484439921382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752018.113839408, 752018.113839408, 168679.8826275056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2933400.0000, 
sim time next is 2934000.0000, 
raw observation next is [25.3, 89.0, 1.0, 2.0, 0.6507398556777464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741632.1879140491, 741632.1879140491, 167025.783518373], 
processed observation next is [1.0, 1.0, 0.49259259259259264, 0.89, 1.0, 1.0, 0.584214113902079, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26486863854073184, 0.26486863854073184, 0.321203429843025], 
reward next is 0.6788, 
noisyNet noise sample is [array([-1.8145555], dtype=float32), -1.4373404]. 
=============================================
[2019-03-24 03:03:56,103] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.664543]
 [56.509083]
 [56.368946]
 [56.2617  ]
 [56.19003 ]], R is [[57.02493286]
 [57.13030243]
 [57.23161697]
 [57.32957458]
 [57.42493057]].
[2019-03-24 03:03:59,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.90700455e-17 9.99881387e-01 2.72769090e-12 7.56348371e-08
 1.18496755e-04], sum to 1.0000
[2019-03-24 03:03:59,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3750
[2019-03-24 03:03:59,379] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6700423593875182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763641.7339361912, 763641.7339361907, 170548.7111947747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3013200.0000, 
sim time next is 3013800.0000, 
raw observation next is [24.83333333333334, 95.0, 1.0, 2.0, 0.6697633206911303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763323.5574954136, 763323.5574954136, 170497.1716030522], 
processed observation next is [1.0, 0.9130434782608695, 0.47530864197530887, 0.95, 1.0, 1.0, 0.6068610960608694, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.272615556248362, 0.272615556248362, 0.3278791761597158], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.48494226], dtype=float32), -0.7953481]. 
=============================================
[2019-03-24 03:04:00,245] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3875108e-21 9.9998844e-01 6.8227902e-12 2.6468359e-07 1.1379917e-05], sum to 1.0000
[2019-03-24 03:04:00,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5218
[2019-03-24 03:04:00,263] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 98.66666666666667, 1.0, 2.0, 0.646047255370496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 736281.5784411214, 736281.578441121, 166179.1417801662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018000.0000, 
sim time next is 3018600.0000, 
raw observation next is [23.95, 98.0, 1.0, 2.0, 0.639598982957802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730282.1543846015, 730282.1543846015, 165090.690027191], 
processed observation next is [1.0, 0.9565217391304348, 0.4425925925925926, 0.98, 1.0, 1.0, 0.5709511701878596, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2608150551373577, 0.2608150551373577, 0.31748209620613654], 
reward next is 0.6825, 
noisyNet noise sample is [array([1.6576074], dtype=float32), 0.5809916]. 
=============================================
[2019-03-24 03:04:04,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0641472e-24 1.0000000e+00 4.8462792e-18 1.2262960e-12 2.4272293e-09], sum to 1.0000
[2019-03-24 03:04:04,226] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9263
[2019-03-24 03:04:04,232] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666666, 62.16666666666666, 1.0, 2.0, 0.5679403015571299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661731.3759892818, 661731.3759892818, 153334.2411957794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3107400.0000, 
sim time next is 3108000.0000, 
raw observation next is [28.33333333333334, 61.33333333333334, 1.0, 2.0, 0.5607430041104352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656200.9401330429, 656200.9401330429, 152255.5915831457], 
processed observation next is [1.0, 1.0, 0.6049382716049385, 0.6133333333333334, 1.0, 1.0, 0.47707500489337523, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23435747861894388, 0.23435747861894388, 0.2927992145829725], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.7785656], dtype=float32), -0.069387004]. 
=============================================
[2019-03-24 03:04:04,249] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.0688 ]
 [77.89937]
 [77.73047]
 [77.67435]
 [77.61359]], R is [[78.15692902]
 [78.08048248]
 [78.00350952]
 [77.92825317]
 [77.85452271]].
[2019-03-24 03:04:08,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7475089e-26 1.0000000e+00 3.7273583e-24 1.8084223e-19 6.4915870e-21], sum to 1.0000
[2019-03-24 03:04:08,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-24 03:04:08,785] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.4, 53.0, 1.0, 2.0, 0.5832825844651521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668966.2982240412, 668966.2982240412, 155436.1572540672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180600.0000, 
sim time next is 3181200.0000, 
raw observation next is [30.86666666666667, 58.0, 1.0, 2.0, 0.61220063289616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697689.9967348226, 697689.9967348226, 160190.0366392704], 
processed observation next is [1.0, 0.8260869565217391, 0.6987654320987656, 0.58, 1.0, 1.0, 0.5383340867811428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24917499883386524, 0.24917499883386524, 0.3080577627678277], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.40087545], dtype=float32), -0.097282164]. 
=============================================
[2019-03-24 03:04:10,137] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3807175e-26 1.0000000e+00 5.2837212e-23 3.7950305e-19 1.2414823e-20], sum to 1.0000
[2019-03-24 03:04:10,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1526
[2019-03-24 03:04:10,148] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 58.33333333333334, 1.0, 2.0, 0.6157414133320024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706157.5011715004, 706157.5011715004, 161025.0634570064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259200.0000, 
sim time next is 3259800.0000, 
raw observation next is [30.25, 56.0, 1.0, 2.0, 0.6064319214239654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698631.9362909428, 698631.9362909428, 159554.2818894814], 
processed observation next is [0.0, 0.7391304347826086, 0.6759259259259259, 0.56, 1.0, 1.0, 0.5314665731237683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24951140581819387, 0.24951140581819387, 0.30683515747977197], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.9480159], dtype=float32), -0.66118014]. 
=============================================
[2019-03-24 03:04:12,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2094814e-18 1.0000000e+00 8.2648995e-17 1.4544213e-13 2.8837336e-15], sum to 1.0000
[2019-03-24 03:04:12,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3689
[2019-03-24 03:04:12,717] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1537982.917408826 W.
[2019-03-24 03:04:12,724] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 90.0, 1.0, 2.0, 0.722062129671954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260424732544, 1537982.917408826, 1537982.917408826, 321271.1473871272], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3677400.0000, 
sim time next is 3678000.0000, 
raw observation next is [25.33333333333333, 88.66666666666666, 1.0, 2.0, 0.6774143457323526, 1.0, 1.0, 0.6774143457323526, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156184, 1544873.927166829, 1544873.927166829, 295703.0056750661], 
processed observation next is [1.0, 0.5652173913043478, 0.49382716049382697, 0.8866666666666666, 1.0, 1.0, 0.6159694592051816, 1.0, 0.5, 0.6159694592051816, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288198478, 0.5517406882738675, 0.5517406882738675, 0.568659626298204], 
reward next is 0.4313, 
noisyNet noise sample is [array([-1.0666829], dtype=float32), -0.08388916]. 
=============================================
[2019-03-24 03:04:12,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[45.43745 ]
 [45.552105]
 [46.58395 ]
 [47.474033]
 [47.275555]], R is [[44.07340622]
 [44.01484299]
 [43.97045135]
 [43.53074646]
 [43.09543991]].
[2019-03-24 03:04:15,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1431463e-25 1.0000000e+00 1.0758026e-22 1.6374429e-18 3.3011817e-19], sum to 1.0000
[2019-03-24 03:04:15,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6804
[2019-03-24 03:04:15,417] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 94.33333333333334, 1.0, 2.0, 0.8163253053881283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 930460.3961532767, 930460.3961532762, 199331.8564211188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3725400.0000, 
sim time next is 3726000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.8131925117447162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 926887.4293711026, 926887.4293711035, 198676.6147320091], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.777610133029424, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.33103122477539376, 0.3310312247753941, 0.38207041294617133], 
reward next is 0.6179, 
noisyNet noise sample is [array([0.4548957], dtype=float32), -1.8307427]. 
=============================================
[2019-03-24 03:04:15,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[60.093582]
 [60.10243 ]
 [59.882877]
 [59.48923 ]
 [60.006786]], R is [[60.00456619]
 [60.02119064]
 [60.02880478]
 [59.42851639]
 [59.35524368]].
[2019-03-24 03:04:20,137] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 03:04:20,139] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:04:20,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:04:20,141] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:04:20,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:04:20,142] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:04:20,145] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:04:20,146] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:04:20,147] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:04:20,150] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:04:20,152] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:04:20,184] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-24 03:04:20,185] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-24 03:04:20,211] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-24 03:04:20,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-24 03:04:20,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-24 03:04:40,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:04:40,180] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.07462439, 60.39433728, 1.0, 2.0, 0.29238887666311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373799.1632465015, 373799.1632465015, 114642.0584694839]
[2019-03-24 03:04:40,181] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:04:40,183] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.67468693e-20 1.00000000e+00 6.29809115e-18 4.86695753e-13
 1.02121714e-13], sampled 0.548642893401106
[2019-03-24 03:04:55,088] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:04:55,089] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 78.0, 1.0, 2.0, 0.537642247684299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635339.1946563706, 635339.1946563706, 148705.3111686533]
[2019-03-24 03:04:55,090] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:04:55,093] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.1678660e-19 1.0000000e+00 1.4685575e-16 4.5481327e-12 1.1051478e-12], sampled 0.12850644512738285
[2019-03-24 03:04:56,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:04:56,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 55.0, 1.0, 2.0, 0.7237396351805613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824873.0050525749, 824873.0050525749, 180690.0773306894]
[2019-03-24 03:04:56,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:04:56,144] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8408600e-21 1.0000000e+00 2.5115610e-18 2.5348896e-13 5.1194139e-14], sampled 0.0821270729607333
[2019-03-24 03:04:58,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:04:58,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 82.33333333333333, 1.0, 2.0, 0.6048018995297049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691473.904850229, 691473.904850229, 159015.4215690209]
[2019-03-24 03:04:58,482] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:04:58,485] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3395699e-19 1.0000000e+00 1.0800906e-16 3.6566050e-12 8.7625713e-13], sampled 0.9531822513858892
[2019-03-24 03:05:24,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:05:24,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333333, 61.0, 1.0, 2.0, 1.013351461171071, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1870486.012758226, 1870486.012758227, 382563.2162498545]
[2019-03-24 03:05:24,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:05:24,340] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6829141e-15 1.0000000e+00 1.4659571e-13 6.1197203e-10 2.0213904e-10], sampled 0.6120726072398074
[2019-03-24 03:05:24,342] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1870486.012758226 W.
[2019-03-24 03:05:32,321] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:05:32,323] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.33333333333334, 67.66666666666667, 1.0, 2.0, 0.6363519198164292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725226.8548872591, 725226.8548872591, 164446.1489369785]
[2019-03-24 03:05:32,325] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:05:32,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7602465e-20 1.0000000e+00 6.5844995e-18 5.0218824e-13 1.0646580e-13], sampled 0.29953314215002425
[2019-03-24 03:05:33,176] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:05:33,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.541492318143407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638056.0030124191, 638056.0030124191, 149261.2018680338]
[2019-03-24 03:05:33,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:05:33,182] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9822360e-18 1.0000000e+00 4.0720696e-16 9.3793610e-12 2.3974885e-12], sampled 0.33189683196635644
[2019-03-24 03:05:46,670] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:05:46,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 63.0, 1.0, 2.0, 0.7235415673308246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904680.890374803, 904680.890374803, 183683.554116752]
[2019-03-24 03:05:46,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:05:46,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7374121e-17 1.0000000e+00 7.6733562e-15 7.5363167e-11 2.1946202e-11], sampled 0.5692631583821227
[2019-03-24 03:05:52,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8128988]
[2019-03-24 03:05:52,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.30188589, 62.60484208, 1.0, 2.0, 0.5892372370151734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676190.5654962214, 676190.5654962214, 156467.1278948576]
[2019-03-24 03:05:52,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:05:52,659] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7938663e-20 1.0000000e+00 2.6811736e-17 1.3607505e-12 3.0601227e-13], sampled 0.27557649579519916
[2019-03-24 03:05:57,604] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 03:05:57,682] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 03:05:57,690] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 03:05:57,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 03:05:57,972] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 03:05:58,989] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1575000, evaluation results [1575000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 03:06:01,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4680029e-20 1.0000000e+00 8.5963739e-15 1.2526662e-09 2.7345082e-10], sum to 1.0000
[2019-03-24 03:06:01,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7838
[2019-03-24 03:06:01,286] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 76.83333333333334, 1.0, 2.0, 0.6854779792226079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781242.5471933756, 781242.5471933756, 173414.9334864499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.6864459153535231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782346.2716394485, 782346.271639448, 173595.877333841], 
processed observation next is [1.0, 0.8260869565217391, 0.5925925925925926, 0.79, 1.0, 1.0, 0.6267213278018131, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27940938272837446, 0.2794093827283743, 0.33383822564200194], 
reward next is 0.6662, 
noisyNet noise sample is [array([-1.942761], dtype=float32), 0.97878164]. 
=============================================
[2019-03-24 03:06:01,310] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.398705]
 [59.79449 ]
 [60.189716]
 [59.95037 ]
 [59.43702 ]], R is [[59.58574677]
 [59.65640259]
 [59.72673035]
 [59.7964325 ]
 [59.86458969]].
[2019-03-24 03:06:13,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2784268e-24 8.8782363e-06 8.6707203e-17 2.1188218e-09 9.9999118e-01], sum to 1.0000
[2019-03-24 03:06:13,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9001
[2019-03-24 03:06:13,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.5, 100.0, 1.0, 2.0, 0.3635724846463511, 1.0, 2.0, 0.3635724846463511, 1.0, 2.0, 0.5788192362861716, 6.911200000000001, 6.9112, 121.94756008, 1243470.485721821, 1243470.485721821, 281492.8035209113], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3666600.0000, 
sim time next is 3667200.0000, 
raw observation next is [22.66666666666666, 100.0, 1.0, 2.0, 0.3478377948606859, 1.0, 2.0, 0.3478377948606859, 1.0, 2.0, 0.5537690977043217, 6.9112, 6.9112, 121.94756008, 1189613.793693247, 1189613.793693247, 274986.8680488006], 
processed observation next is [1.0, 0.43478260869565216, 0.3950617283950615, 1.0, 1.0, 1.0, 0.2236164224531975, 1.0, 1.0, 0.2236164224531975, 1.0, 1.0, 0.44221137213040207, 0.0, 0.0, 0.8096049824067558, 0.42486206917615965, 0.42486206917615965, 0.5288209000938473], 
reward next is 0.4712, 
noisyNet noise sample is [array([0.47996423], dtype=float32), -0.4926762]. 
=============================================
[2019-03-24 03:06:13,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2969743e-24 9.2621658e-06 8.8188253e-17 2.1693525e-09 9.9999070e-01], sum to 1.0000
[2019-03-24 03:06:13,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9050
[2019-03-24 03:06:13,624] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.66666666666666, 100.0, 1.0, 2.0, 0.3478377948606859, 1.0, 2.0, 0.3478377948606859, 1.0, 2.0, 0.5537690977043217, 6.9112, 6.9112, 121.94756008, 1189613.793693247, 1189613.793693247, 274986.8680488006], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3667200.0000, 
sim time next is 3667800.0000, 
raw observation next is [22.83333333333334, 100.0, 1.0, 2.0, 0.3514505607493765, 1.0, 2.0, 0.3514505607493765, 1.0, 2.0, 0.5595207386586879, 6.9112, 6.9112, 121.94756008, 1201979.233012133, 1201979.233012133, 276468.4986955382], 
processed observation next is [1.0, 0.43478260869565216, 0.4012345679012348, 1.0, 1.0, 1.0, 0.2279173342254482, 1.0, 1.0, 0.2279173342254482, 1.0, 1.0, 0.44940092332335985, 0.0, 0.0, 0.8096049824067558, 0.4292782975043332, 0.4292782975043332, 0.531670189799112], 
reward next is 0.4683, 
noisyNet noise sample is [array([0.47996423], dtype=float32), -0.4926762]. 
=============================================
[2019-03-24 03:06:29,364] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5706750e-17 9.9999762e-01 4.8105373e-17 3.6697583e-09 2.3982036e-06], sum to 1.0000
[2019-03-24 03:06:29,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1573
[2019-03-24 03:06:29,378] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.23333333333333, 68.66666666666666, 1.0, 2.0, 0.744711336896346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848788.4693564284, 848788.4693564284, 184784.1994265957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3951600.0000, 
sim time next is 3952200.0000, 
raw observation next is [30.06666666666667, 69.83333333333334, 1.0, 2.0, 0.7511916441545003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856178.5573983099, 856178.5573983104, 186064.8920458225], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6983333333333335, 1.0, 1.0, 0.7037995763744052, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3057780562136821, 0.30577805621368226, 0.3578171000881202], 
reward next is 0.6422, 
noisyNet noise sample is [array([-0.35967878], dtype=float32), -1.2104739]. 
=============================================
[2019-03-24 03:06:35,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7390012e-26 1.0000000e+00 4.6432136e-25 1.9450784e-15 1.6875919e-14], sum to 1.0000
[2019-03-24 03:06:35,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7844
[2019-03-24 03:06:35,083] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.76666666666667, 88.0, 1.0, 2.0, 0.6696268144005512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763167.9049898001, 763167.9049897996, 170471.9979647383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4044000.0000, 
sim time next is 4044600.0000, 
raw observation next is [25.65, 87.5, 1.0, 2.0, 0.6602631718150633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752491.0041280902, 752491.0041280902, 168755.6051544013], 
processed observation next is [1.0, 0.8260869565217391, 0.5055555555555555, 0.875, 1.0, 1.0, 0.5955513950179325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2687467871886037, 0.2687467871886037, 0.3245300099123102], 
reward next is 0.6755, 
noisyNet noise sample is [array([0.51377714], dtype=float32), -0.17317061]. 
=============================================
[2019-03-24 03:06:36,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3009327e-19 1.0000000e+00 3.5328532e-19 2.8147610e-12 7.9739777e-11], sum to 1.0000
[2019-03-24 03:06:36,677] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3168
[2019-03-24 03:06:36,682] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 97.66666666666666, 1.0, 2.0, 0.4457470319325644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548340.6811479942, 548340.6811479942, 135154.6661254478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4081200.0000, 
sim time next is 4081800.0000, 
raw observation next is [20.05, 98.83333333333334, 1.0, 2.0, 0.4400594076592049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540687.1621580696, 540687.1621580696, 134294.2707969082], 
processed observation next is [1.0, 0.21739130434782608, 0.29814814814814816, 0.9883333333333334, 1.0, 1.0, 0.3334040567371487, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19310255791359626, 0.19310255791359626, 0.25825821307097735], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.87690145], dtype=float32), -0.8718221]. 
=============================================
[2019-03-24 03:06:37,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6286749e-19 1.0000000e+00 2.1939606e-17 2.1611109e-11 2.7619540e-10], sum to 1.0000
[2019-03-24 03:06:37,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8613
[2019-03-24 03:06:37,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1951575.233007929 W.
[2019-03-24 03:06:37,139] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 67.0, 1.0, 2.0, 0.8555519453411623, 1.0, 1.0, 0.8555519453411623, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9259852821566, 1951575.233007929, 1951575.23300793, 367243.4938236342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [28.86666666666667, 66.0, 1.0, 2.0, 0.8547902651032443, 1.0, 2.0, 0.8547902651032443, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260425981794, 1949835.888190801, 1949835.8881908, 366914.0243753603], 
processed observation next is [1.0, 0.5652173913043478, 0.6246913580246916, 0.66, 1.0, 1.0, 0.8271312679800528, 1.0, 1.0, 0.8271312679800528, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.809462128704071, 0.6963699600681432, 0.6963699600681429, 0.705603893029539], 
reward next is 0.2944, 
noisyNet noise sample is [array([0.04259601], dtype=float32), -0.10666276]. 
=============================================
[2019-03-24 03:06:37,155] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[52.731483]
 [53.21952 ]
 [53.741577]
 [54.36261 ]
 [54.129494]], R is [[53.17402267]
 [52.9360466 ]
 [52.40668488]
 [52.22115326]
 [52.09174728]].
[2019-03-24 03:06:39,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1161147e-19 1.0000000e+00 1.0230369e-19 6.6660219e-13 2.9059830e-09], sum to 1.0000
[2019-03-24 03:06:39,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9339
[2019-03-24 03:06:39,021] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 93.33333333333334, 1.0, 2.0, 0.447803855806111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 546488.3635835422, 546488.3635835417, 135341.5085122862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4130400.0000, 
sim time next is 4131000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4461552995468771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544647.517373175, 544647.517373175, 135101.2398889874], 
processed observation next is [1.0, 0.8260869565217391, 0.3333333333333333, 0.94, 1.0, 1.0, 0.34066107088913944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19451697049041966, 0.19451697049041966, 0.2598100767095911], 
reward next is 0.7402, 
noisyNet noise sample is [array([-1.8040588], dtype=float32), -0.26285842]. 
=============================================
[2019-03-24 03:06:39,043] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.080566]
 [58.884323]
 [59.189655]
 [59.197388]
 [59.444057]], R is [[59.1714592 ]
 [59.31947327]
 [59.46556091]
 [59.60989761]
 [59.75257111]].
[2019-03-24 03:06:49,663] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:06:49,663] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:06:49,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:06:49,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:06:49,665] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:06:49,666] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:06:49,666] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:06:49,666] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:06:49,666] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:06:49,667] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:06:49,668] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:06:49,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-24 03:06:49,719] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-24 03:06:49,719] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-24 03:06:49,721] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-24 03:06:49,721] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-24 03:06:53,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:06:53,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.70917745333333, 7.301095467, 1.0, 2.0, 0.3631778481442828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468512.7720716024, 468512.7720716024, 108130.9614153712]
[2019-03-24 03:06:53,023] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:06:53,025] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4252266e-15 9.7728568e-01 9.3902002e-13 9.0580534e-07 2.2713320e-02], sampled 0.372979022364641
[2019-03-24 03:06:54,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:06:54,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.23333333333333, 25.33333333333334, 1.0, 2.0, 0.3345046850930342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426632.1289461748, 426632.1289461748, 119944.5922776786]
[2019-03-24 03:06:54,826] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:06:54,829] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4570381e-14 9.7181904e-01 6.3228919e-12 2.2855077e-06 2.8178608e-02], sampled 0.042290454576614955
[2019-03-24 03:07:17,347] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:07:17,349] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.003866335, 72.015136875, 1.0, 2.0, 0.499847267317044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592784.6903834336, 592784.6903834336, 142744.0446173944]
[2019-03-24 03:07:17,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:07:17,353] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5115032e-14 9.7064048e-01 8.5148225e-12 2.6428431e-06 2.9356906e-02], sampled 0.6444734721922681
[2019-03-24 03:07:21,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:07:21,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.83333333333334, 66.66666666666666, 1.0, 2.0, 0.8142432159683227, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425566079, 941732.6193536882, 941732.6193536882, 199606.1137920824]
[2019-03-24 03:07:21,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:07:21,482] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3503662e-12 9.5547044e-01 3.6157380e-10 1.6139529e-05 4.4513386e-02], sampled 0.28155226791603505
[2019-03-24 03:08:22,999] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:08:23,002] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.33097595, 72.01290835, 1.0, 2.0, 0.7701253599980575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890925.0250365356, 890925.0250365356, 190514.498618101]
[2019-03-24 03:08:23,003] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:08:23,007] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1580749e-12 9.5005012e-01 5.9960137e-10 2.0989368e-05 4.9928974e-02], sampled 0.5526297500440632
[2019-03-24 03:08:26,747] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8239179]
[2019-03-24 03:08:26,749] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 91.0, 1.0, 2.0, 0.3802450087603695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473297.5539177789, 473297.5539177785, 125916.745709748]
[2019-03-24 03:08:26,750] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:08:26,755] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9626026e-13 9.6571958e-01 3.5047857e-11 5.2417922e-06 3.4275204e-02], sampled 0.9202851934391778
[2019-03-24 03:08:26,830] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8178.7302 2271722267.7925 537.0000
[2019-03-24 03:08:26,984] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8320.7676 2216656876.5847 556.0000
[2019-03-24 03:08:27,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7722.9870 2467160262.0834 716.0000
[2019-03-24 03:08:27,290] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8377.3881 2193153204.3606 477.0000
[2019-03-24 03:08:27,310] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8487.5331 2145734738.6592 417.0000
[2019-03-24 03:08:28,326] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1600000, evaluation results [1600000.0, 7722.987022265713, 2467160262.083372, 716.0, 8377.388144810264, 2193153204.360588, 477.0, 8487.533119007738, 2145734738.6592233, 417.0, 8178.730226021879, 2271722267.792516, 537.0, 8320.7675877422, 2216656876.5847054, 556.0]
[2019-03-24 03:08:29,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5986549e-19 9.9999881e-01 1.4745742e-15 6.7331618e-10 1.1386966e-06], sum to 1.0000
[2019-03-24 03:08:29,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2121
[2019-03-24 03:08:29,886] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4964911970287312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596025.6133641055, 596025.6133641055, 142483.2914756472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4409400.0000, 
sim time next is 4410000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4955116253734915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594850.0473400932, 594850.0473400932, 142329.7924478032], 
processed observation next is [0.0, 0.043478260869565216, 0.37037037037037035, 0.94, 1.0, 1.0, 0.399418601635109, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2124464454786047, 0.2124464454786047, 0.27371113932269847], 
reward next is 0.7263, 
noisyNet noise sample is [array([-1.440646], dtype=float32), -2.6870198]. 
=============================================
[2019-03-24 03:08:29,903] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.70103]
 [64.50156]
 [64.59467]
 [64.82401]
 [64.82205]], R is [[64.98126221]
 [65.05744171]
 [65.13265228]
 [65.2071228 ]
 [65.28085327]].
[2019-03-24 03:08:32,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9192819e-23 9.9999917e-01 5.3080862e-21 1.6698315e-12 8.9112149e-07], sum to 1.0000
[2019-03-24 03:08:32,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9761
[2019-03-24 03:08:32,032] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 60.16666666666667, 1.0, 2.0, 0.6482728068548976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738819.1981456872, 738819.1981456872, 166584.3366366579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4385400.0000, 
sim time next is 4386000.0000, 
raw observation next is [31.0, 61.33333333333334, 1.0, 2.0, 0.657978958631706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749886.4508041452, 749886.4508041452, 168343.7523593836], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6133333333333334, 1.0, 1.0, 0.5928320936091738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.267816589572909, 0.267816589572909, 0.32373798530650694], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.42699033], dtype=float32), 1.7438307]. 
=============================================
[2019-03-24 03:08:32,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.76935 ]
 [74.81747 ]
 [75.743996]
 [75.80333 ]
 [75.18624 ]], R is [[74.94177246]
 [74.87199402]
 [74.80763245]
 [74.74653625]
 [74.68820953]].
[2019-03-24 03:08:43,539] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6403106e-12 9.9885964e-01 7.5343117e-12 1.2151801e-06 1.1391294e-03], sum to 1.0000
[2019-03-24 03:08:43,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6555
[2019-03-24 03:08:43,555] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1557206.347233102 W.
[2019-03-24 03:08:43,567] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 76.33333333333334, 1.0, 2.0, 0.455211092374425, 1.0, 1.0, 0.455211092374425, 1.0, 2.0, 0.7247108842503629, 6.9112, 6.9112, 121.94756008, 1557206.347233102, 1557206.347233102, 322111.428427474], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4616400.0000, 
sim time next is 4617000.0000, 
raw observation next is [26.5, 75.0, 1.0, 2.0, 0.7569597737209175, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1577816.560712965, 1577816.560712964, 327837.6428822326], 
processed observation next is [1.0, 0.43478260869565216, 0.5370370370370371, 0.75, 1.0, 1.0, 0.7106663972868066, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5635059145403446, 0.5635059145403443, 0.6304570055427551], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0576955], dtype=float32), 0.52482146]. 
=============================================
[2019-03-24 03:08:43,580] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[41.29894 ]
 [40.9201  ]
 [40.604366]
 [40.44947 ]
 [40.196743]], R is [[41.20085144]
 [41.16939926]
 [41.13495255]
 [40.72360229]
 [40.74322128]].
[2019-03-24 03:08:47,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1975172e-13 9.9179989e-01 7.6205192e-10 6.9025799e-04 7.5098309e-03], sum to 1.0000
[2019-03-24 03:08:47,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7488
[2019-03-24 03:08:47,112] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 90.0, 1.0, 2.0, 0.6759956020675899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775775.8204027005, 775775.8204027005, 171915.6602318032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4694400.0000, 
sim time next is 4695000.0000, 
raw observation next is [24.5, 91.66666666666666, 1.0, 2.0, 0.6907739763866322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793403.6421962213, 793403.6421962213, 174710.4131463836], 
processed observation next is [1.0, 0.34782608695652173, 0.46296296296296297, 0.9166666666666665, 1.0, 1.0, 0.6318737814126574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2833584436415076, 0.2833584436415076, 0.3359815637430454], 
reward next is 0.6640, 
noisyNet noise sample is [array([0.8646827], dtype=float32), 0.10195995]. 
=============================================
[2019-03-24 03:08:47,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[47.576733]
 [47.376392]
 [47.811344]
 [48.441586]
 [48.702915]], R is [[47.78401947]
 [47.97557068]
 [48.13823318]
 [48.3070488 ]
 [48.48921204]].
[2019-03-24 03:08:47,891] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7972936e-13 9.9928612e-01 1.4453400e-11 1.5123811e-05 6.9882465e-04], sum to 1.0000
[2019-03-24 03:08:47,898] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1453
[2019-03-24 03:08:47,900] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.9711197013388596, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.044732426534023, 6.9112, 121.9255682623666, 1189898.21589233, 1121517.944548554, 234632.1842756725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4698000.0000, 
sim time next is 4698600.0000, 
raw observation next is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 1.000200402690305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.248293033052172, 6.9112, 121.9245716473572, 1331908.961070047, 1159289.28169723, 241833.0706518946], 
processed observation next is [1.0, 0.391304347826087, 0.4135802469135804, 0.9900000000000001, 1.0, 1.0, 1.0002385746313156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.033709303305217195, 0.0, 0.8094523631202926, 0.47568177181073107, 0.41403188632043925, 0.46506359740748965], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.91093296], dtype=float32), 0.24292062]. 
=============================================
[2019-03-24 03:08:49,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4171192e-15 9.9985337e-01 2.8745664e-13 3.0392521e-06 1.4365805e-04], sum to 1.0000
[2019-03-24 03:08:49,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-24 03:08:49,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 77.0, 1.0, 2.0, 0.8149825819141473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928929.0112915155, 928929.0112915155, 199061.9221054429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5137200.0000, 
sim time next is 5137800.0000, 
raw observation next is [29.71666666666667, 76.83333333333334, 1.0, 2.0, 0.7752070475503627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883566.1433703455, 883566.1433703455, 190878.2766606199], 
processed observation next is [0.0, 0.4782608695652174, 0.6561728395061729, 0.7683333333333334, 1.0, 1.0, 0.7323893423218604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31555933691798055, 0.31555933691798055, 0.36707360896273056], 
reward next is 0.6329, 
noisyNet noise sample is [array([1.5070367], dtype=float32), 0.38724235]. 
=============================================
[2019-03-24 03:08:52,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0720265e-14 9.9990726e-01 7.5607901e-13 5.8371366e-05 3.4304543e-05], sum to 1.0000
[2019-03-24 03:08:52,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2229
[2019-03-24 03:08:52,742] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 93.66666666666667, 1.0, 2.0, 0.7081441622599788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818363.4643809105, 818363.4643809105, 178252.7265370066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4778400.0000, 
sim time next is 4779000.0000, 
raw observation next is [23.95, 93.5, 1.0, 2.0, 0.7403494323221568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856215.0477920956, 856215.0477920956, 184546.8872942495], 
processed observation next is [1.0, 0.30434782608695654, 0.4425925925925926, 0.935, 1.0, 1.0, 0.6908921813359009, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.305791088497177, 0.305791088497177, 0.354897860181249], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.15473448], dtype=float32), -0.75875205]. 
=============================================
[2019-03-24 03:08:52,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[49.273373]
 [49.609787]
 [49.524246]
 [49.55813 ]
 [49.70121 ]], R is [[49.15447998]
 [49.32014465]
 [49.5073204 ]
 [49.68875885]
 [49.85499954]].
[2019-03-24 03:08:54,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3463181e-12 1.2523812e-01 1.4404098e-09 8.0561731e-03 8.6670572e-01], sum to 1.0000
[2019-03-24 03:08:54,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-24 03:08:54,171] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3779727835554563, 1.0, 2.0, 0.3779727835554563, 1.0, 2.0, 0.6017449811344608, 6.9112, 6.9112, 121.94756008, 1292763.143022754, 1292763.143022754, 287567.4909521962], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4798200.0000, 
sim time next is 4798800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4015306449654771, 1.0, 2.0, 0.4015306449654771, 1.0, 2.0, 0.6392498637251974, 6.911199999999999, 6.9112, 121.94756008, 1373409.251652482, 1373409.251652482, 297753.2906562742], 
processed observation next is [1.0, 0.5652173913043478, 0.5185185185185185, 0.89, 1.0, 1.0, 0.2875364821017584, 1.0, 1.0, 0.2875364821017584, 1.0, 1.0, 0.5490623296564967, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4905033041616007, 0.4905033041616007, 0.5726024820312965], 
reward next is 0.4274, 
noisyNet noise sample is [array([-0.5848437], dtype=float32), -0.9315421]. 
=============================================
[2019-03-24 03:08:54,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6741774e-10 1.0821285e-02 1.8752252e-07 4.3820599e-03 9.8479652e-01], sum to 1.0000
[2019-03-24 03:08:54,839] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4152
[2019-03-24 03:08:54,845] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.4840403707440655, 1.0, 2.0, 0.4840403707440655, 1.0, 2.0, 0.7706080343188787, 6.911199999999999, 6.9112, 121.94756008, 1655922.035066041, 1655922.035066041, 335824.9365647383], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.4666974723247772, 1.0, 2.0, 0.4666974723247772, 1.0, 2.0, 0.7429975752166021, 6.9112, 6.9112, 121.94756008, 1596538.26190256, 1596538.26190256, 327530.4329566882], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.3651160384818776, 1.0, 1.0, 0.3651160384818776, 1.0, 1.0, 0.6787469690207526, 0.0, 0.0, 0.8096049824067558, 0.5701922363937715, 0.5701922363937715, 0.6298662172244004], 
reward next is 0.3701, 
noisyNet noise sample is [array([0.4609011], dtype=float32), 0.9297271]. 
=============================================
[2019-03-24 03:08:59,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3168520e-11 3.8051015e-01 1.8417398e-09 4.3147698e-04 6.1905837e-01], sum to 1.0000
[2019-03-24 03:08:59,015] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2706
[2019-03-24 03:08:59,029] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2495698.150688888 W.
[2019-03-24 03:08:59,036] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 69.83333333333333, 1.0, 2.0, 0.831614106130374, 1.0, 2.0, 0.7291717150416216, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2495698.150688888, 2495698.150688888, 466479.4760046424], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4899000.0000, 
sim time next is 4899600.0000, 
raw observation next is [31.6, 66.0, 1.0, 2.0, 0.9749398076368948, 1.0, 2.0, 0.9749398076368948, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156593, 2224246.672280203, 2224246.672280203, 421346.3312233757], 
processed observation next is [1.0, 0.7391304347826086, 0.725925925925926, 0.66, 1.0, 1.0, 0.9701664376629701, 1.0, 1.0, 0.9701664376629701, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201194, 0.794373811528644, 0.794373811528644, 0.8102814061987994], 
reward next is 0.1897, 
noisyNet noise sample is [array([-0.92019475], dtype=float32), -1.4280263]. 
=============================================
[2019-03-24 03:09:02,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7509174e-20 9.9999988e-01 2.0028799e-18 2.9600666e-09 8.5491649e-08], sum to 1.0000
[2019-03-24 03:09:02,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-24 03:09:02,289] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 95.83333333333334, 1.0, 2.0, 0.5464709681112783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 643545.1405330295, 643545.1405330291, 150063.4656331555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5008200.0000, 
sim time next is 5008800.0000, 
raw observation next is [22.86666666666667, 96.66666666666667, 1.0, 2.0, 0.5514981608369448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647756.5249170227, 647756.5249170227, 150822.3816147843], 
processed observation next is [1.0, 1.0, 0.4024691358024693, 0.9666666666666667, 1.0, 1.0, 0.4660692390916009, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23134161604179382, 0.23134161604179382, 0.29004304156689287], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.4325672], dtype=float32), 0.7933266]. 
=============================================
[2019-03-24 03:09:08,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0507403e-20 1.0000000e+00 9.6991554e-20 1.7844750e-08 5.2184251e-10], sum to 1.0000
[2019-03-24 03:09:08,183] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9336
[2019-03-24 03:09:08,189] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666666, 1.0, 2.0, 0.8097259321267786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 922933.7974344882, 922933.7974344877, 197965.5497719024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5057400.0000, 
sim time next is 5058000.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.8044925200286213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 916965.1327728557, 916965.1327728557, 196877.2175481095], 
processed observation next is [0.0, 0.5652173913043478, 0.6666666666666666, 0.75, 1.0, 1.0, 0.7672530000340729, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32748754741887703, 0.32748754741887703, 0.3786100337463644], 
reward next is 0.6214, 
noisyNet noise sample is [array([-0.8212583], dtype=float32), -0.18099098]. 
=============================================
[2019-03-24 03:09:08,209] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.957184]
 [64.93897 ]
 [64.94187 ]
 [64.96302 ]
 [65.03002 ]], R is [[64.93628693]
 [64.90621948]
 [64.8744812 ]
 [64.84118652]
 [64.80927277]].
[2019-03-24 03:09:14,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2874232e-16 9.9999964e-01 1.9665620e-14 3.6836090e-07 2.3641840e-08], sum to 1.0000
[2019-03-24 03:09:14,776] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8256
[2019-03-24 03:09:14,779] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 90.0, 1.0, 2.0, 0.6277761451416136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719901.7097885847, 719901.7097885847, 163142.3549948393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181600.0000, 
sim time next is 5182200.0000, 
raw observation next is [24.9, 91.0, 1.0, 2.0, 0.6373573477747546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728166.0717597627, 728166.0717597627, 164712.6451915106], 
processed observation next is [0.0, 1.0, 0.47777777777777775, 0.91, 1.0, 1.0, 0.5682825568747079, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2600593113427724, 0.2600593113427724, 0.31675508690675114], 
reward next is 0.6832, 
noisyNet noise sample is [array([0.39682496], dtype=float32), -0.8899377]. 
=============================================
[2019-03-24 03:09:17,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9642830e-15 9.9971610e-01 3.0109514e-13 2.8388551e-04 3.7891144e-08], sum to 1.0000
[2019-03-24 03:09:17,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5206
[2019-03-24 03:09:17,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2173910.949824077 W.
[2019-03-24 03:09:17,598] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.53333333333333, 70.0, 1.0, 2.0, 0.9529033004908813, 1.0, 2.0, 0.9529033004908813, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2173910.949824077, 2173910.949824077, 410987.6490923853], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5244000.0000, 
sim time next is 5244600.0000, 
raw observation next is [29.66666666666667, 69.0, 1.0, 2.0, 0.6555971974141168, 1.0, 2.0, 0.641163260683493, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2194106.067391843, 2194106.067391843, 417521.4097903732], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.69, 1.0, 1.0, 0.5899966635882343, 1.0, 1.0, 0.5728134055755869, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7836093097828011, 0.7836093097828011, 0.80292578805841], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11707361], dtype=float32), 0.09592292]. 
=============================================
[2019-03-24 03:09:18,961] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 03:09:18,963] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:09:18,964] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:09:18,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:09:18,965] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:09:18,967] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:09:18,968] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:09:18,972] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:09:18,974] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:09:18,976] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:09:18,976] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:09:18,994] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-24 03:09:19,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-24 03:09:19,024] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-24 03:09:19,025] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-24 03:09:19,073] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-24 03:09:42,635] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.83582073]
[2019-03-24 03:09:42,636] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.06666666666667, 63.00000000000001, 1.0, 2.0, 0.3821244494072881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 490234.7212313517, 490234.7212313522, 126325.3451205579]
[2019-03-24 03:09:42,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:09:42,639] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9530731e-19 9.9994171e-01 2.2226994e-18 5.8310339e-05 1.7070718e-11], sampled 0.37957736538347286
[2019-03-24 03:09:57,972] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.83582073]
[2019-03-24 03:09:57,973] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.40482506, 95.49514950666668, 1.0, 2.0, 0.5545290321909557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 647412.1267058932, 647412.1267058927, 151158.1417057798]
[2019-03-24 03:09:57,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:09:57,976] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5685666e-20 9.9996829e-01 1.5924102e-19 3.1658394e-05 3.4115850e-12], sampled 0.5797499186862005
[2019-03-24 03:10:12,426] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.83582073]
[2019-03-24 03:10:12,427] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 75.66666666666667, 1.0, 2.0, 0.7551112393621061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860648.4654809982, 860648.4654809982, 186845.36271571]
[2019-03-24 03:10:12,428] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:10:12,431] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6981682e-21 9.9998057e-01 1.8275961e-20 1.9468152e-05 9.3819473e-13], sampled 0.6941448394480626
[2019-03-24 03:10:54,403] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.83582073]
[2019-03-24 03:10:54,404] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.72040693, 65.26823559333334, 1.0, 2.0, 0.353193480292798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 443863.7862537509, 443863.7862537505, 122337.0924640706]
[2019-03-24 03:10:54,406] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:10:54,410] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5315430e-20 9.9996805e-01 1.5797703e-19 3.1943768e-05 3.4683506e-12], sampled 0.2770241301647087
[2019-03-24 03:10:56,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 03:10:56,722] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.1750 2170624013.2338 493.0000
[2019-03-24 03:10:56,725] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.7081 2195020925.5756 572.0000
[2019-03-24 03:10:56,749] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.83582073]
[2019-03-24 03:10:56,749] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.1, 53.0, 1.0, 2.0, 0.501184028333193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596109.928829205, 596109.928829205, 143019.2513685624]
[2019-03-24 03:10:56,750] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:10:56,751] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9586987e-20 9.9996674e-01 1.8424187e-19 3.3298398e-05 3.8675447e-12], sampled 0.3879206736199259
[2019-03-24 03:10:56,845] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.3389 2445376775.4760 746.0000
[2019-03-24 03:10:56,876] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 03:10:57,893] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1625000, evaluation results [1625000.0, 8098.338869298483, 2445376775.476003, 746.0, 8771.174986492491, 2170624013.233768, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8700.708141389396, 2195020925.5755677, 572.0]
[2019-03-24 03:10:59,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4879663e-16 9.9967718e-01 1.2572281e-16 3.2281206e-04 1.6479448e-10], sum to 1.0000
[2019-03-24 03:10:59,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0385
[2019-03-24 03:10:59,200] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 84.5, 1.0, 2.0, 0.7290319679811303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848400.0330399806, 848400.0330399806, 182576.9569712107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5283000.0000, 
sim time next is 5283600.0000, 
raw observation next is [24.76666666666667, 84.66666666666667, 1.0, 2.0, 0.6970417687490876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812201.6480906843, 812201.6480906843, 176450.0751754079], 
processed observation next is [1.0, 0.13043478260869565, 0.4728395061728396, 0.8466666666666667, 1.0, 1.0, 0.6393354389870091, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2900720171752444, 0.2900720171752444, 0.3393270676450152], 
reward next is 0.6607, 
noisyNet noise sample is [array([-0.5706101], dtype=float32), 0.6603412]. 
=============================================
[2019-03-24 03:11:13,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.72392414e-14 1.18875905e-04 9.11661155e-14 9.99835372e-01
 4.57356473e-05], sum to 1.0000
[2019-03-24 03:11:13,806] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3513
[2019-03-24 03:11:13,814] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666666, 81.66666666666667, 1.0, 2.0, 0.70158185426784, 1.0, 2.0, 0.70158185426784, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1600043.872245193, 1600043.872245193, 304763.8755756249], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5564400.0000, 
sim time next is 5565000.0000, 
raw observation next is [26.23333333333333, 81.33333333333333, 1.0, 2.0, 0.7030022256718109, 1.0, 2.0, 0.7030022256718109, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1603286.110812653, 1603286.110812654, 305302.7180874578], 
processed observation next is [1.0, 0.391304347826087, 0.5271604938271603, 0.8133333333333332, 1.0, 1.0, 0.6464312210378701, 1.0, 1.0, 0.6464312210378701, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5726021824330904, 0.5726021824330907, 0.5871206117066496], 
reward next is 0.4129, 
noisyNet noise sample is [array([1.93933], dtype=float32), -0.4181665]. 
=============================================
[2019-03-24 03:11:13,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[52.20586 ]
 [52.316532]
 [52.562748]
 [52.72346 ]
 [53.321148]], R is [[52.07348633]
 [51.96666718]
 [51.86395264]
 [51.77365112]
 [51.67123795]].
[2019-03-24 03:11:20,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0333259e-20 3.1503168e-04 2.5490713e-19 9.9968457e-01 3.8114959e-07], sum to 1.0000
[2019-03-24 03:11:20,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-24 03:11:20,587] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 87.0, 1.0, 2.0, 0.3672225233637348, 1.0, 2.0, 0.3672225233637348, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837081.0240200228, 837081.0240200228, 197375.8858764311], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5689800.0000, 
sim time next is 5690400.0000, 
raw observation next is [26.96666666666667, 87.33333333333334, 1.0, 2.0, 0.3667583445486528, 1.0, 2.0, 0.3667583445486528, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836022.3547721525, 836022.3547721525, 197253.5516621232], 
processed observation next is [0.0, 0.8695652173913043, 0.554320987654321, 0.8733333333333334, 1.0, 1.0, 0.24614088636744383, 1.0, 1.0, 0.24614088636744383, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2985794124186259, 0.2985794124186259, 0.3793337531963908], 
reward next is 0.6207, 
noisyNet noise sample is [array([-0.89412534], dtype=float32), 0.7443068]. 
=============================================
[2019-03-24 03:11:30,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2950088e-16 3.0097610e-04 4.1967353e-15 9.9968326e-01 1.5765734e-05], sum to 1.0000
[2019-03-24 03:11:30,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0428
[2019-03-24 03:11:30,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.18333333333333, 82.16666666666667, 1.0, 2.0, 0.1955571962610823, 1.0, 2.0, 0.1955571962610823, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482511.3769824877, 482511.3769824877, 158927.3505095409], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5875800.0000, 
sim time next is 5876400.0000, 
raw observation next is [21.06666666666667, 82.33333333333334, 1.0, 2.0, 0.1936676040040486, 1.0, 2.0, 0.1936676040040486, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478482.7583151663, 478482.7583151663, 158551.5390181603], 
processed observation next is [1.0, 0.0, 0.3358024691358026, 0.8233333333333335, 1.0, 1.0, 0.040080480957200695, 1.0, 1.0, 0.040080480957200695, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17088669939827367, 0.17088669939827367, 0.30490680580415447], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.8967639], dtype=float32), -0.06028455]. 
=============================================
[2019-03-24 03:11:31,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5067507e-15 1.8462932e-03 1.0386383e-12 9.9813098e-01 2.2777269e-05], sum to 1.0000
[2019-03-24 03:11:31,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7778
[2019-03-24 03:11:31,982] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.63333333333333, 82.33333333333334, 1.0, 2.0, 0.160336927150755, 1.0, 2.0, 0.160336927150755, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404007.8221229297, 404007.8221229297, 151901.0961063356], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5895600.0000, 
sim time next is 5896200.0000, 
raw observation next is [19.81666666666667, 81.66666666666666, 1.0, 2.0, 0.1619529134775377, 1.0, 2.0, 0.1619529134775377, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407597.4392806791, 407597.4392806791, 152217.3487142595], 
processed observation next is [1.0, 0.21739130434782608, 0.2895061728395063, 0.8166666666666665, 1.0, 1.0, 0.0023248969970686957, 1.0, 1.0, 0.0023248969970686957, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14557051402881396, 0.14557051402881396, 0.29272567060434523], 
reward next is 0.7073, 
noisyNet noise sample is [array([0.3823422], dtype=float32), 1.3193188]. 
=============================================
[2019-03-24 03:11:34,198] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8060416e-20 7.3217683e-07 4.0150838e-18 9.9999928e-01 6.3314061e-09], sum to 1.0000
[2019-03-24 03:11:34,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0857
[2019-03-24 03:11:34,212] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.86666666666667, 55.66666666666667, 1.0, 2.0, 0.2369721403978756, 1.0, 2.0, 0.2369721403978756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 564075.4774919626, 564075.4774919631, 167168.0361118791], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5940600.0000, 
sim time next is 5941200.0000, 
raw observation next is [27.73333333333333, 56.33333333333334, 1.0, 2.0, 0.2394443953479585, 1.0, 2.0, 0.2394443953479585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569902.0110335622, 569902.0110335627, 167714.2175996852], 
processed observation next is [1.0, 0.782608695652174, 0.5827160493827159, 0.5633333333333335, 1.0, 1.0, 0.09457666112852202, 1.0, 1.0, 0.09457666112852202, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20353643251198653, 0.2035364325119867, 0.3225273415378561], 
reward next is 0.6775, 
noisyNet noise sample is [array([1.3590354], dtype=float32), -1.7053152]. 
=============================================
[2019-03-24 03:11:34,548] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5649159e-17 3.2922603e-07 1.8286868e-16 9.9999905e-01 6.0087342e-07], sum to 1.0000
[2019-03-24 03:11:34,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0020
[2019-03-24 03:11:34,563] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 81.0, 1.0, 2.0, 0.2437651840795404, 1.0, 2.0, 0.2437651840795404, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 581344.6071777345, 581344.607177735, 168725.1975171441], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5955600.0000, 
sim time next is 5956200.0000, 
raw observation next is [23.3, 82.5, 1.0, 2.0, 0.2437215441117457, 1.0, 2.0, 0.2437215441117457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581141.2121369696, 581141.2121369696, 168711.4155875601], 
processed observation next is [1.0, 0.9565217391304348, 0.41851851851851857, 0.825, 1.0, 1.0, 0.09966850489493537, 1.0, 1.0, 0.09966850489493537, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20755043290606057, 0.20755043290606057, 0.3244450299760771], 
reward next is 0.6756, 
noisyNet noise sample is [array([1.0559757], dtype=float32), 0.90593976]. 
=============================================
[2019-03-24 03:11:48,422] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 03:11:48,423] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:11:48,424] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:11:48,424] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:11:48,424] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:11:48,425] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:11:48,426] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:11:48,426] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:11:48,427] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:11:48,428] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:11:48,429] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:11:48,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-24 03:11:48,481] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-24 03:11:48,516] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-24 03:11:48,517] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-24 03:11:48,517] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-24 03:11:52,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:11:52,598] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.75942571666667, 25.26033839, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408450.5337518534, 408450.5337518539, 151298.7022840512]
[2019-03-24 03:11:52,600] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:11:52,604] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4658282e-19 8.0965071e-07 1.1882339e-17 9.9999905e-01 9.8747464e-08], sampled 0.9910444956133404
[2019-03-24 03:11:58,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:11:58,136] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.1, 22.0, 1.0, 2.0, 0.2882410364039161, 1.0, 2.0, 0.2882410364039161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 723653.6764345105, 723653.676434511, 180081.052571994]
[2019-03-24 03:11:58,138] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:11:58,141] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.05385305e-19 7.25600273e-07 8.83347417e-18 9.99999166e-01
 8.73766908e-08], sampled 0.7743034805500315
[2019-03-24 03:12:02,729] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:02,730] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.5, 43.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 289683.4339551345, 289683.4339551349, 111882.3480435105]
[2019-03-24 03:12:02,732] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:12:02,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2244831e-18 1.6362682e-06 7.9956714e-17 9.9999809e-01 2.1664661e-07], sampled 0.9675830453755792
[2019-03-24 03:12:17,017] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:17,017] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.8, 82.5, 1.0, 2.0, 0.1769467601124864, 1.0, 2.0, 0.1769467601124864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439161.4044477688, 439161.4044477692, 155133.3624383839]
[2019-03-24 03:12:17,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:12:17,021] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0939376e-19 7.3480902e-07 9.1365747e-18 9.9999917e-01 8.8617178e-08], sampled 0.36338421692082334
[2019-03-24 03:12:27,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:27,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.24269782666667, 93.49936385, 1.0, 2.0, 0.2653800449192157, 1.0, 2.0, 0.2653800449192157, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 640013.3171456838, 640013.3171456843, 173916.274744976]
[2019-03-24 03:12:27,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:12:27,273] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3508995e-19 9.4691069e-07 1.8161650e-17 9.9999893e-01 1.1761606e-07], sampled 0.44975033671884446
[2019-03-24 03:12:28,302] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:28,304] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.93333333333333, 86.33333333333334, 1.0, 2.0, 0.4432804520210176, 1.0, 2.0, 0.4432804520210176, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1010568.820584138, 1010568.820584138, 218398.2603747615]
[2019-03-24 03:12:28,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:12:28,308] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.7384849e-19 1.1043153e-06 2.7547490e-17 9.9999881e-01 1.3964360e-07], sampled 0.717787247306819
[2019-03-24 03:12:48,835] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:48,836] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.218851369650549, 1.0, 2.0, 0.218851369650549, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529557.8525042261, 529557.8525042266, 163552.4684689191]
[2019-03-24 03:12:48,838] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:12:48,840] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4586369e-19 1.1703494e-06 3.2270840e-17 9.9999869e-01 1.4905198e-07], sampled 0.8428736488644654
[2019-03-24 03:12:52,571] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:12:52,573] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.53333333333333, 67.33333333333333, 1.0, 2.0, 0.2622067277243229, 1.0, 2.0, 0.2622067277243229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615151.2687781508, 615151.2687781508, 172487.6495621293]
[2019-03-24 03:12:52,573] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:12:52,575] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.4076639e-20 5.8165227e-07 4.8517137e-18 9.9999928e-01 6.8256895e-08], sampled 0.6833807972589936
[2019-03-24 03:13:10,842] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.84596926]
[2019-03-24 03:13:10,843] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.12723707333334, 74.90188101833333, 1.0, 2.0, 0.1616868382240585, 1.0, 2.0, 0.1616868382240585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408874.0530684207, 408874.0530684211, 152196.0909057026]
[2019-03-24 03:13:10,846] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:13:10,848] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8405220e-19 1.1138643e-06 2.8226807e-17 9.9999881e-01 1.4106578e-07], sampled 0.43612946403633057
[2019-03-24 03:13:25,822] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 03:13:26,239] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 03:13:26,253] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 03:13:26,288] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 03:13:26,348] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 03:13:27,366] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1650000, evaluation results [1650000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 03:13:29,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0092568e-20 1.6977529e-06 2.1868116e-18 9.9999833e-01 5.0300159e-08], sum to 1.0000
[2019-03-24 03:13:29,695] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9753
[2019-03-24 03:13:29,700] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 87.0, 1.0, 2.0, 0.2456992644107768, 1.0, 2.0, 0.2456992644107768, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583938.0493559403, 583938.0493559408, 169076.7151053914], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6242400.0000, 
sim time next is 6243000.0000, 
raw observation next is [23.01666666666667, 86.66666666666667, 1.0, 2.0, 0.2475215148964277, 1.0, 2.0, 0.2475215148964277, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 587479.1023305178, 587479.1023305183, 169453.4979878024], 
processed observation next is [0.0, 0.2608695652173913, 0.40802469135802477, 0.8666666666666667, 1.0, 1.0, 0.10419227963860442, 1.0, 1.0, 0.10419227963860442, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2098139651180421, 0.20981396511804226, 0.3258721115150046], 
reward next is 0.6741, 
noisyNet noise sample is [array([-0.21758913], dtype=float32), -1.0038849]. 
=============================================
[2019-03-24 03:13:29,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.046646]
 [69.09272 ]
 [69.13443 ]
 [69.18708 ]
 [69.23759 ]], R is [[68.9466629 ]
 [68.93204498]
 [68.91819763]
 [68.90507507]
 [68.89258575]].
[2019-03-24 03:13:29,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2253031e-21 1.2691028e-06 5.0448075e-18 9.9999857e-01 1.2138312e-07], sum to 1.0000
[2019-03-24 03:13:30,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6133
[2019-03-24 03:13:30,008] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 73.66666666666667, 1.0, 2.0, 0.3073176195899294, 1.0, 2.0, 0.3073176195899294, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700465.8457143344, 700465.8457143349, 182225.9640167718], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6261600.0000, 
sim time next is 6262200.0000, 
raw observation next is [27.3, 73.0, 1.0, 2.0, 0.3087005648724462, 1.0, 2.0, 0.3087005648724462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703619.425102945, 703619.4251029454, 182561.6647446608], 
processed observation next is [0.0, 0.4782608695652174, 0.5666666666666667, 0.73, 1.0, 1.0, 0.17702448199100737, 1.0, 1.0, 0.17702448199100737, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25129265182248034, 0.2512926518224805, 0.3510801245089631], 
reward next is 0.6489, 
noisyNet noise sample is [array([0.36259025], dtype=float32), -0.12361518]. 
=============================================
[2019-03-24 03:13:31,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8103996e-19 8.4081009e-08 4.5720622e-18 9.9999976e-01 6.5235156e-08], sum to 1.0000
[2019-03-24 03:13:31,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0047
[2019-03-24 03:13:31,871] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 64.0, 1.0, 2.0, 0.3105489516091156, 1.0, 2.0, 0.3105489516091156, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707834.3874762824, 707834.3874762824, 183011.2991894675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.68333333333333, 64.33333333333334, 1.0, 2.0, 0.3081334365307339, 1.0, 2.0, 0.3081334365307339, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 702326.1805748445, 702326.1805748449, 182423.8255650784], 
processed observation next is [0.0, 0.8260869565217391, 0.6179012345679011, 0.6433333333333334, 1.0, 1.0, 0.17634932920325463, 1.0, 1.0, 0.17634932920325463, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25083077877673016, 0.2508307787767303, 0.35081504916361234], 
reward next is 0.6492, 
noisyNet noise sample is [array([0.33812207], dtype=float32), 1.1567967]. 
=============================================
[2019-03-24 03:13:35,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6767682e-18 1.2308401e-07 1.4243405e-17 9.9999976e-01 8.3818733e-08], sum to 1.0000
[2019-03-24 03:13:35,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9106
[2019-03-24 03:13:35,355] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 87.0, 1.0, 2.0, 0.3327478642426582, 1.0, 2.0, 0.3327478642426582, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758457.4126759564, 758457.4126759568, 188505.0311545099], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6400800.0000, 
sim time next is 6401400.0000, 
raw observation next is [25.65, 87.33333333333333, 1.0, 2.0, 0.6813543477795798, 1.0, 2.0, 0.6813543477795798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 123.3915659551321, 1553849.671105727, 1553849.671105728, 297387.464496188], 
processed observation next is [1.0, 0.08695652173913043, 0.5055555555555555, 0.8733333333333333, 1.0, 1.0, 0.6206599378328331, 1.0, 1.0, 0.6206599378328331, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8191916797573598, 0.5549463111091882, 0.5549463111091886, 0.5718989701849769], 
reward next is 0.4281, 
noisyNet noise sample is [array([0.47764194], dtype=float32), -1.2381943]. 
=============================================
[2019-03-24 03:13:39,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9469363e-13 2.4175572e-05 5.2933192e-12 9.9990952e-01 6.6216278e-05], sum to 1.0000
[2019-03-24 03:13:39,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8710
[2019-03-24 03:13:39,536] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.46666666666667, 73.66666666666667, 1.0, 2.0, 0.9784305716533519, 1.0, 2.0, 0.9784305716533519, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2232220.525188464, 2232220.525188464, 423001.8731130089], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6433800.0000, 
sim time next is 6434400.0000, 
raw observation next is [29.63333333333333, 72.33333333333334, 1.0, 2.0, 0.9808540064179181, 1.0, 2.0, 0.9808540064179181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2237756.350142545, 2237756.350142546, 424154.0858134306], 
processed observation next is [1.0, 0.4782608695652174, 0.6530864197530862, 0.7233333333333334, 1.0, 1.0, 0.9772071504975215, 1.0, 1.0, 0.9772071504975215, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7991986964794804, 0.7991986964794807, 0.8156809342565973], 
reward next is 0.1843, 
noisyNet noise sample is [array([-1.8568869], dtype=float32), -1.3068479]. 
=============================================
[2019-03-24 03:13:43,122] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.31267356e-14 4.73639545e-07 9.25209562e-13 9.99873400e-01
 1.26115759e-04], sum to 1.0000
[2019-03-24 03:13:43,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7703
[2019-03-24 03:13:43,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 85.0, 1.0, 2.0, 0.5005887755595957, 1.0, 2.0, 0.5005887755595957, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1141314.80366155, 1141314.80366155, 235565.0753518108], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6496200.0000, 
sim time next is 6496800.0000, 
raw observation next is [26.36666666666667, 85.33333333333333, 1.0, 2.0, 0.4616734042471081, 1.0, 2.0, 0.4616734042471081, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1052528.960900099, 1052528.960900099, 223784.6116160912], 
processed observation next is [1.0, 0.17391304347826086, 0.5320987654320989, 0.8533333333333333, 1.0, 1.0, 0.3591350050560811, 1.0, 1.0, 0.3591350050560811, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37590320032146396, 0.37590320032146396, 0.43035502233863693], 
reward next is 0.5696, 
noisyNet noise sample is [array([1.5873846], dtype=float32), -0.6596935]. 
=============================================
[2019-03-24 03:13:46,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9383007e-17 1.7743648e-06 1.9336542e-15 9.9990773e-01 9.0506583e-05], sum to 1.0000
[2019-03-24 03:13:46,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5165
[2019-03-24 03:13:46,948] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666666, 79.5, 1.0, 2.0, 0.3094924886945524, 1.0, 2.0, 0.3094924886945524, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 705425.2830446151, 705425.2830446155, 182754.1147922666], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6563400.0000, 
sim time next is 6564000.0000, 
raw observation next is [26.13333333333333, 78.0, 1.0, 2.0, 0.3048064462154608, 1.0, 2.0, 0.3048064462154608, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695471.4963159392, 695471.4963159397, 181654.6803238869], 
processed observation next is [1.0, 1.0, 0.5234567901234567, 0.78, 1.0, 1.0, 0.17238862644697717, 1.0, 1.0, 0.17238862644697717, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24838267725569257, 0.24838267725569274, 0.3493359236997825], 
reward next is 0.6507, 
noisyNet noise sample is [array([1.3971372], dtype=float32), 0.17950992]. 
=============================================
[2019-03-24 03:13:46,963] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.32265 ]
 [68.25227 ]
 [68.161446]
 [68.13356 ]
 [68.09262 ]], R is [[68.32919312]
 [68.29445648]
 [68.25738525]
 [68.21941376]
 [68.18051147]].
[2019-03-24 03:13:54,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1108478e-22 2.1138280e-08 6.9747563e-18 1.0000000e+00 1.8590425e-08], sum to 1.0000
[2019-03-24 03:13:54,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6825
[2019-03-24 03:13:54,203] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.95, 30.66666666666667, 1.0, 2.0, 0.2789537561337243, 1.0, 2.0, 0.2789537561337243, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700956.751567791, 700956.7515677914, 177854.0202618612], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6700200.0000, 
sim time next is 6700800.0000, 
raw observation next is [29.1, 30.33333333333334, 1.0, 2.0, 0.3632386792481884, 1.0, 2.0, 0.3632386792481884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 911614.2323371965, 911614.2323371968, 199268.1013938914], 
processed observation next is [1.0, 0.5652173913043478, 0.6333333333333334, 0.3033333333333334, 1.0, 1.0, 0.24195080862879575, 1.0, 1.0, 0.24195080862879575, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32557651154899875, 0.32557651154899886, 0.383207887295945], 
reward next is 0.6168, 
noisyNet noise sample is [array([1.4374367], dtype=float32), -1.6426992]. 
=============================================
[2019-03-24 03:13:57,185] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5131376e-14 8.9297873e-06 1.4489774e-13 9.9996161e-01 2.9391889e-05], sum to 1.0000
[2019-03-24 03:13:57,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1183
[2019-03-24 03:13:57,201] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.25, 84.0, 1.0, 2.0, 0.1715733126926948, 1.0, 2.0, 0.1715733126926948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437197.6729404959, 437197.6729404964, 154243.6617886342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6755400.0000, 
sim time next is 6756000.0000, 
raw observation next is [18.16666666666667, 84.33333333333334, 1.0, 2.0, 0.1674412397439993, 1.0, 2.0, 0.1674412397439993, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 426913.1180678604, 426913.11806786, 153399.1591480076], 
processed observation next is [1.0, 0.17391304347826086, 0.22839506172839524, 0.8433333333333334, 1.0, 1.0, 0.008858618742856305, 1.0, 1.0, 0.008858618742856305, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1524689707385216, 0.15246897073852145, 0.2949983829769377], 
reward next is 0.7050, 
noisyNet noise sample is [array([0.00534064], dtype=float32), -1.5754527]. 
=============================================
[2019-03-24 03:13:57,234] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.531773]
 [56.564655]
 [56.546917]
 [56.935345]
 [56.880775]], R is [[56.58975983]
 [56.7272377 ]
 [56.86166   ]
 [56.98922348]
 [57.12640381]].
[2019-03-24 03:14:13,328] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8779816e-18 3.6445855e-09 5.6311243e-16 1.0000000e+00 1.9731401e-08], sum to 1.0000
[2019-03-24 03:14:13,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1188
[2019-03-24 03:14:13,342] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.15, 72.16666666666667, 1.0, 2.0, 0.5852919571691828, 1.0, 2.0, 0.5852919571691828, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1367489.646209453, 1367489.646209453, 264570.2861159547], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7056600.0000, 
sim time next is 7057200.0000, 
raw observation next is [24.9, 73.33333333333334, 1.0, 2.0, 0.4867500118533912, 1.0, 2.0, 0.4867500118533912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1142531.110675815, 1142531.110675815, 232809.1891270965], 
processed observation next is [1.0, 0.6956521739130435, 0.47777777777777775, 0.7333333333333334, 1.0, 1.0, 0.3889881093492752, 1.0, 1.0, 0.3889881093492752, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4080468252413625, 0.4080468252413625, 0.4477099790905702], 
reward next is 0.5523, 
noisyNet noise sample is [array([-0.3444155], dtype=float32), 0.24584907]. 
=============================================
[2019-03-24 03:14:14,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1818819e-17 4.2046105e-07 1.8342636e-15 9.9999940e-01 7.4778185e-08], sum to 1.0000
[2019-03-24 03:14:14,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5842
[2019-03-24 03:14:14,806] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 62.5, 1.0, 2.0, 0.4038495301788082, 1.0, 2.0, 0.4038495301788082, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 993269.3125143673, 993269.3125143677, 210057.2063264441], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7133400.0000, 
sim time next is 7134000.0000, 
raw observation next is [23.83333333333334, 61.66666666666667, 1.0, 2.0, 0.4004111240458725, 1.0, 2.0, 0.4004111240458725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 985163.7345249748, 985163.7345249753, 209096.6927417065], 
processed observation next is [1.0, 0.5652173913043478, 0.43827160493827183, 0.6166666666666667, 1.0, 1.0, 0.28620371910222914, 1.0, 1.0, 0.28620371910222914, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3518441909017767, 0.3518441909017769, 0.40210902450328173], 
reward next is 0.5979, 
noisyNet noise sample is [array([-1.8065517], dtype=float32), 1.8606638]. 
=============================================
[2019-03-24 03:14:14,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.70257 ]
 [64.67641 ]
 [65.01372 ]
 [65.14709 ]
 [65.163605]], R is [[64.74907684]
 [64.69763184]
 [64.65522766]
 [64.65574646]
 [64.68546295]].
[2019-03-24 03:14:17,878] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 03:14:17,879] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:14:17,879] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:14:17,880] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:14:17,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:14:17,881] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:14:17,881] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:14:17,882] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:14:17,883] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:14:17,886] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:14:17,885] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:14:17,913] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-24 03:14:17,943] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-24 03:14:17,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-24 03:14:17,971] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-24 03:14:17,995] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-24 03:14:49,414] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8599479]
[2019-03-24 03:14:49,415] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.46585978666666, 82.31805056333334, 1.0, 2.0, 0.6082235449317398, 1.0, 2.0, 0.6082235449317398, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1386938.302918941, 1386938.302918941, 270881.9517475543]
[2019-03-24 03:14:49,417] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:14:49,420] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3057085e-18 9.3662024e-08 5.0644862e-16 9.9999976e-01 7.8063891e-08], sampled 0.23652964483124206
[2019-03-24 03:15:07,969] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8599479]
[2019-03-24 03:15:07,970] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 77.33333333333333, 1.0, 2.0, 0.3369638238046985, 1.0, 2.0, 0.3369638238046985, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768071.983299047, 768071.9832990475, 189568.0173873626]
[2019-03-24 03:15:07,971] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:15:07,974] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4076255e-19 2.6139610e-08 3.2389279e-17 1.0000000e+00 2.2025491e-08], sampled 0.35042358365029846
[2019-03-24 03:15:29,913] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8599479]
[2019-03-24 03:15:29,914] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.2, 63.0, 1.0, 2.0, 0.2160336717617466, 1.0, 2.0, 0.2160336717617466, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 524656.1705694982, 524656.1705694987, 163013.6007555132]
[2019-03-24 03:15:29,915] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:15:29,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.5684417e-19 4.6192536e-08 1.1045660e-16 1.0000000e+00 3.8734765e-08], sampled 0.426604373065647
[2019-03-24 03:15:41,699] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8599479]
[2019-03-24 03:15:41,701] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666666, 71.33333333333333, 1.0, 2.0, 0.302568339325602, 1.0, 2.0, 0.302568339325602, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689635.9915327687, 689635.9915327687, 181078.3004735031]
[2019-03-24 03:15:41,702] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:15:41,704] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0800566e-18 4.8593549e-08 1.2302832e-16 1.0000000e+00 4.0650090e-08], sampled 0.9240643303280706
[2019-03-24 03:15:44,427] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8599479]
[2019-03-24 03:15:44,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.45, 76.5, 1.0, 2.0, 0.1837525926716292, 1.0, 2.0, 0.1837525926716292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 456691.2044678655, 456691.2044678659, 156563.1289343265]
[2019-03-24 03:15:44,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:15:44,430] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0156840e-18 7.4189209e-08 3.0648953e-16 9.9999976e-01 6.1942607e-08], sampled 0.22165666938535145
[2019-03-24 03:15:54,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 03:15:55,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 03:15:55,168] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 03:15:55,379] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 03:15:55,551] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 03:15:56,568] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1675000, evaluation results [1675000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 03:16:00,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2707715e-21 3.6217314e-09 2.4576711e-18 1.0000000e+00 9.0740288e-10], sum to 1.0000
[2019-03-24 03:16:00,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9167
[2019-03-24 03:16:00,412] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.4, 76.0, 1.0, 2.0, 0.3901071846078397, 1.0, 2.0, 0.3901071846078397, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 950234.4622952867, 950234.4622952872, 205944.5068006843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7210800.0000, 
sim time next is 7211400.0000, 
raw observation next is [22.5, 75.5, 1.0, 2.0, 0.4075269179645301, 1.0, 2.0, 0.4075269179645301, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 992486.0661581827, 992486.0661581832, 210820.2371103972], 
processed observation next is [1.0, 0.4782608695652174, 0.3888888888888889, 0.755, 1.0, 1.0, 0.29467490233872634, 1.0, 1.0, 0.29467490233872634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3544593093422081, 0.35445930934220826, 0.40542353290461], 
reward next is 0.5946, 
noisyNet noise sample is [array([0.45291683], dtype=float32), -0.6428817]. 
=============================================
[2019-03-24 03:16:00,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4361918e-22 9.1150010e-10 2.1996977e-20 1.0000000e+00 1.5240192e-10], sum to 1.0000
[2019-03-24 03:16:00,785] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4286
[2019-03-24 03:16:00,792] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 70.0, 1.0, 2.0, 0.4101082338483363, 1.0, 2.0, 0.4101082338483363, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 993253.0242332458, 993253.0242332462, 211380.053089829], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7219800.0000, 
sim time next is 7220400.0000, 
raw observation next is [23.83333333333334, 69.66666666666667, 1.0, 2.0, 0.4158840958374466, 1.0, 2.0, 0.4158840958374466, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1006019.558463629, 1006019.55846363, 212985.310929853], 
processed observation next is [1.0, 0.5652173913043478, 0.43827160493827183, 0.6966666666666668, 1.0, 1.0, 0.30462392361600793, 1.0, 1.0, 0.30462392361600793, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35929269945129605, 0.35929269945129644, 0.4095871364035635], 
reward next is 0.5904, 
noisyNet noise sample is [array([-0.78410256], dtype=float32), -0.4170049]. 
=============================================
[2019-03-24 03:16:07,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1579950e-16 5.9883241e-08 6.3720384e-14 9.9999976e-01 1.0493331e-07], sum to 1.0000
[2019-03-24 03:16:07,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-24 03:16:07,533] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.88333333333334, 92.83333333333333, 1.0, 2.0, 0.3537646926918191, 1.0, 2.0, 0.3537646926918191, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855621.5031138723, 855621.5031138723, 195913.6818416871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7391400.0000, 
sim time next is 7392000.0000, 
raw observation next is [20.96666666666667, 92.66666666666667, 1.0, 2.0, 0.4112136055955682, 1.0, 2.0, 0.4112136055955682, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 991793.8625786415, 991793.862578642, 211557.5820919013], 
processed observation next is [1.0, 0.5652173913043478, 0.3320987654320988, 0.9266666666666667, 1.0, 1.0, 0.29906381618520017, 1.0, 1.0, 0.29906381618520017, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35421209377808627, 0.35421209377808643, 0.4068415040228871], 
reward next is 0.5932, 
noisyNet noise sample is [array([1.1378719], dtype=float32), -1.3631688]. 
=============================================
[2019-03-24 03:16:07,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.044376]
 [58.077766]
 [58.13601 ]
 [58.095467]
 [58.11354 ]], R is [[57.91991043]
 [57.96395493]
 [58.02388763]
 [58.09917068]
 [58.17556381]].
[2019-03-24 03:16:10,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3075537e-20 6.3006091e-08 7.2229517e-16 9.9999976e-01 1.0975082e-07], sum to 1.0000
[2019-03-24 03:16:10,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1570
[2019-03-24 03:16:10,088] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.200690191158536, 1.0, 2.0, 0.200690191158536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493101.2248821048, 493101.2248821052, 159942.3461913209], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7412400.0000, 
sim time next is 7413000.0000, 
raw observation next is [20.43333333333334, 90.16666666666667, 1.0, 2.0, 0.1998012045195272, 1.0, 2.0, 0.1998012045195272, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491275.7146416724, 491275.7146416729, 159766.3668758885], 
processed observation next is [1.0, 0.8260869565217391, 0.31234567901234594, 0.9016666666666667, 1.0, 1.0, 0.04738238633277048, 1.0, 1.0, 0.04738238633277048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17545561237202587, 0.17545561237202603, 0.30724301322286246], 
reward next is 0.6928, 
noisyNet noise sample is [array([-0.48557004], dtype=float32), 0.65541613]. 
=============================================
[2019-03-24 03:16:10,105] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.14837 ]
 [69.12326 ]
 [69.09915 ]
 [69.10961 ]
 [69.034904]], R is [[69.13231659]
 [69.13341522]
 [69.13374329]
 [69.13311768]
 [69.13187408]].
[2019-03-24 03:16:19,221] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:19,222] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:19,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-24 03:16:25,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4063631e-15 8.8502198e-08 9.8067028e-14 9.9999976e-01 6.9735400e-08], sum to 1.0000
[2019-03-24 03:16:25,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-24 03:16:25,245] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.6, 78.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 394446.156916309, 394446.1569163094, 150240.3578716399], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7689600.0000, 
sim time next is 7690200.0000, 
raw observation next is [19.61666666666667, 76.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 386751.1128531465, 386751.112853147, 148994.1192372206], 
processed observation next is [1.0, 0.0, 0.28209876543209894, 0.765, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1381253974475523, 0.13812539744755248, 0.2865271523792704], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9682561], dtype=float32), 1.6631036]. 
=============================================
[2019-03-24 03:16:30,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0957497e-17 2.3917332e-06 2.3996330e-14 9.9999678e-01 8.2271987e-07], sum to 1.0000
[2019-03-24 03:16:30,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2317
[2019-03-24 03:16:30,205] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 40.0, 1.0, 2.0, 0.4813991044992913, 1.0, 2.0, 0.4813991044992913, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1173685.257297507, 1173685.257297507, 232751.2425449426], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7815600.0000, 
sim time next is 7816200.0000, 
raw observation next is [28.9, 39.83333333333334, 1.0, 2.0, 0.4381320208758776, 1.0, 2.0, 0.4381320208758776, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1068825.45254686, 1068825.45254686, 219709.7473846215], 
processed observation next is [1.0, 0.4782608695652174, 0.6259259259259259, 0.39833333333333343, 1.0, 1.0, 0.33110954866175907, 1.0, 1.0, 0.33110954866175907, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3817233759095929, 0.3817233759095929, 0.42251874497042596], 
reward next is 0.5775, 
noisyNet noise sample is [array([0.47471628], dtype=float32), 0.26730067]. 
=============================================
[2019-03-24 03:16:38,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:38,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:38,231] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-24 03:16:39,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0087082e-19 1.2259427e-08 7.8555549e-17 9.9999988e-01 1.4383573e-07], sum to 1.0000
[2019-03-24 03:16:39,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-24 03:16:39,455] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 60.5, 1.0, 2.0, 0.2478811701603523, 1.0, 2.0, 0.2478811701603523, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 589316.7897664433, 589316.7897664438, 169575.1485744912], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7933800.0000, 
sim time next is 7934400.0000, 
raw observation next is [26.8, 61.0, 1.0, 2.0, 0.2459121791292723, 1.0, 2.0, 0.2459121791292723, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585345.829749269, 585345.8297492694, 169161.5312115273], 
processed observation next is [1.0, 0.8695652173913043, 0.5481481481481482, 0.61, 1.0, 1.0, 0.10227640372532416, 1.0, 1.0, 0.10227640372532416, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20905208205331033, 0.2090520820533105, 0.3253106369452448], 
reward next is 0.6747, 
noisyNet noise sample is [array([0.5089765], dtype=float32), 0.27291182]. 
=============================================
[2019-03-24 03:16:39,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:39,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:39,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-24 03:16:40,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-24 03:16:40,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,300] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-24 03:16:40,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,322] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,339] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-24 03:16:40,361] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-24 03:16:40,404] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,406] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-24 03:16:40,454] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,458] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,467] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-24 03:16:40,468] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-24 03:16:40,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,534] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,546] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-24 03:16:40,578] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-24 03:16:40,613] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-24 03:16:40,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-24 03:16:40,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-24 03:16:40,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:16:40,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:40,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-24 03:16:42,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3162475e-16 6.0239216e-08 1.5978834e-15 9.9999857e-01 1.3693905e-06], sum to 1.0000
[2019-03-24 03:16:42,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8713
[2019-03-24 03:16:42,230] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.6, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 344191.5410248217, 344191.5410248222, 142072.6639570549], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7200.0000, 
sim time next is 7800.0000, 
raw observation next is [18.55, 75.16666666666667, 1.0, 2.0, 0.1861436614213657, 1.0, 2.0, 0.1861436614213657, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 478061.1256676101, 478061.1256676106, 157269.4624383989], 
processed observation next is [1.0, 0.08695652173913043, 0.2425925925925926, 0.7516666666666667, 1.0, 1.0, 0.031123406454006793, 1.0, 1.0, 0.031123406454006793, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17073611630986074, 0.17073611630986094, 0.3024412739199979], 
reward next is 0.6976, 
noisyNet noise sample is [array([-1.3945824], dtype=float32), 2.1681545]. 
=============================================
[2019-03-24 03:16:45,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1389629e-15 1.8190491e-06 2.7005368e-12 9.9999499e-01 3.1857846e-06], sum to 1.0000
[2019-03-24 03:16:45,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-24 03:16:45,180] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 36.83333333333334, 1.0, 2.0, 0.6059535597778999, 1.0, 2.0, 0.6059535597778999, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1465399.252876255, 1465399.252876256, 273660.0696970102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [30.0, 37.0, 1.0, 2.0, 0.6148425903258832, 1.0, 2.0, 0.6148425903258832, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1486019.685195649, 1486019.685195649, 276780.5247266053], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.37, 1.0, 1.0, 0.54147927419748, 1.0, 1.0, 0.54147927419748, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5307213161413032, 0.5307213161413032, 0.5322702398588564], 
reward next is 0.4677, 
noisyNet noise sample is [array([0.66016245], dtype=float32), 0.32932553]. 
=============================================
[2019-03-24 03:16:45,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.331474]
 [56.24211 ]
 [56.339256]
 [56.231827]
 [56.07183 ]], R is [[56.34076691]
 [56.251091  ]
 [56.17230988]
 [56.13107681]
 [56.08394623]].
[2019-03-24 03:16:48,599] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 03:16:48,602] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:16:48,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:48,603] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:16:48,604] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:48,604] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:16:48,604] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:48,605] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:16:48,605] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:16:48,607] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:48,607] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:16:48,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-24 03:16:48,657] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-24 03:16:48,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-24 03:16:48,696] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-24 03:16:48,725] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-24 03:16:57,896] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8733311]
[2019-03-24 03:16:57,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.01666666666667, 43.5, 1.0, 2.0, 0.1821471225744006, 1.0, 2.0, 0.1821471225744006, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453936.9561147278, 453936.9561147283, 156260.8094896852]
[2019-03-24 03:16:57,898] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:16:57,901] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0571101e-17 5.5153839e-07 7.3285240e-15 9.9999857e-01 8.6519458e-07], sampled 0.47314121939006815
[2019-03-24 03:17:44,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8733311]
[2019-03-24 03:17:44,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.51302673666667, 83.54985378666667, 1.0, 2.0, 0.4631263995807767, 1.0, 2.0, 0.4631263995807767, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1055843.800659188, 1055843.800659188, 224217.7740074949]
[2019-03-24 03:17:44,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:17:44,915] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8158883e-17 3.4565463e-07 2.5548244e-15 9.9999905e-01 5.5121740e-07], sampled 0.16328544943572632
[2019-03-24 03:17:49,725] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8733311]
[2019-03-24 03:17:49,727] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.22298677333333, 94.83688091500001, 1.0, 2.0, 0.2631986391139977, 1.0, 2.0, 0.2631986391139977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620135.0031500281, 620135.0031500281, 172831.6084757759]
[2019-03-24 03:17:49,727] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:17:49,729] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8181618e-17 3.4511675e-07 2.5619193e-15 9.9999905e-01 5.5273921e-07], sampled 0.611291643275879
[2019-03-24 03:17:50,263] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8733311]
[2019-03-24 03:17:50,264] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333334, 67.33333333333333, 1.0, 2.0, 0.3218224641640096, 1.0, 2.0, 0.3218224641640096, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750387.3198336216, 750387.3198336221, 186574.5499722122]
[2019-03-24 03:17:50,266] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:17:50,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6100112e-17 4.9697695e-07 5.7632507e-15 9.9999869e-01 7.7958805e-07], sampled 0.004733514753349488
[2019-03-24 03:18:12,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8733311]
[2019-03-24 03:18:12,768] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.89059074333333, 68.85302314, 1.0, 2.0, 0.3044506772867613, 1.0, 2.0, 0.3044506772867613, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693928.2963832759, 693928.2963832759, 181532.1302926126]
[2019-03-24 03:18:12,769] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:18:12,771] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3887709e-17 3.8504777e-07 3.2429088e-15 9.9999905e-01 6.0968830e-07], sampled 0.5502592442813228
[2019-03-24 03:18:25,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-03-24 03:18:26,074] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-03-24 03:18:26,283] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-03-24 03:18:26,335] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-03-24 03:18:26,353] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7121.4359 2438848915.3615 34.0000
[2019-03-24 03:18:27,371] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1700000, evaluation results [1700000.0, 7523.727130323888, 2668527814.010175, 68.0, 7121.435945869477, 2438848915.3614798, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-03-24 03:18:27,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6913133e-14 2.4693888e-06 1.1841286e-12 9.9999166e-01 5.7853190e-06], sum to 1.0000
[2019-03-24 03:18:27,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9542
[2019-03-24 03:18:27,826] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 48.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 350528.4930086173, 350528.4930086177, 135190.1846412239], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 263400.0000, 
sim time next is 264000.0000, 
raw observation next is [21.5, 48.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347259.913176196, 347259.9131761965, 133676.8408395369], 
processed observation next is [0.0, 0.043478260869565216, 0.35185185185185186, 0.4866666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12402139756292714, 0.12402139756292732, 0.25707084776834016], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.6969311], dtype=float32), -0.3717201]. 
=============================================
[2019-03-24 03:18:27,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[49.56669 ]
 [49.535255]
 [49.4717  ]
 [49.511448]
 [49.430515]], R is [[49.01398468]
 [48.52384567]
 [48.03860855]
 [47.55822372]
 [47.0826416 ]].
[2019-03-24 03:18:35,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0222176e-24 9.9999988e-01 6.4445585e-21 8.5591672e-08 1.0354971e-11], sum to 1.0000
[2019-03-24 03:18:35,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7587
[2019-03-24 03:18:35,748] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666666, 50.66666666666667, 1.0, 2.0, 0.257986190803827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332782.2246281187, 332782.2246281187, 94260.93457939157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 268800.0000, 
sim time next is 269400.0000, 
raw observation next is [20.48333333333333, 50.83333333333333, 1.0, 2.0, 0.2571165758668353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331660.2461021968, 331660.2461021968, 93852.90949045497], 
processed observation next is [0.0, 0.08695652173913043, 0.31419753086419744, 0.5083333333333333, 1.0, 1.0, 0.115614971270042, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11845008789364171, 0.11845008789364171, 0.1804863644047211], 
reward next is 0.8195, 
noisyNet noise sample is [array([-0.2824393], dtype=float32), -0.72686553]. 
=============================================
[2019-03-24 03:18:41,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2069335e-14 9.9846601e-01 1.9202066e-13 1.5274198e-03 6.5580825e-06], sum to 1.0000
[2019-03-24 03:18:41,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5050
[2019-03-24 03:18:41,802] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 31.0, 1.0, 2.0, 0.8231829761799393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260420563576, 1052807.635387705, 1052807.635387705, 204647.6956838324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 382800.0000, 
sim time next is 383400.0000, 
raw observation next is [27.95, 30.5, 1.0, 2.0, 0.825086479965565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154913, 1055009.078818609, 1055009.078818609, 205060.5286455875], 
processed observation next is [1.0, 0.43478260869565216, 0.5907407407407407, 0.305, 1.0, 1.0, 0.7917696190066249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128819004, 0.37678895672093177, 0.37678895672093177, 0.3943471704722837], 
reward next is 0.6057, 
noisyNet noise sample is [array([-0.9021873], dtype=float32), -1.0561086]. 
=============================================
[2019-03-24 03:18:46,782] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8226417e-11 9.8846310e-01 2.4119546e-09 1.0141257e-02 1.3956842e-03], sum to 1.0000
[2019-03-24 03:18:46,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7662
[2019-03-24 03:18:46,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1450996.116858498 W.
[2019-03-24 03:18:46,798] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 38.0, 1.0, 2.0, 0.9560595324983454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.418996338605633, 6.9112, 121.92379758647, 1450996.116858498, 1190963.793244622, 234593.218196394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 471600.0000, 
sim time next is 472200.0000, 
raw observation next is [29.16666666666667, 37.5, 1.0, 2.0, 0.533098787861409, 1.0, 1.0, 0.533098787861409, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257367849396, 1304761.669834211, 1304761.669834211, 249374.542547973], 
processed observation next is [1.0, 0.4782608695652174, 0.6358024691358026, 0.375, 1.0, 1.0, 0.4441652236445345, 1.0, 0.5, 0.4441652236445345, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809460098422182, 0.46598631065507534, 0.46598631065507534, 0.47956642797687116], 
reward next is 0.5204, 
noisyNet noise sample is [array([1.3512564], dtype=float32), -0.1872833]. 
=============================================
[2019-03-24 03:18:48,815] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6178959e-13 9.4490033e-01 1.6142011e-09 4.8832066e-02 6.2675932e-03], sum to 1.0000
[2019-03-24 03:18:48,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-24 03:18:48,832] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 58.0, 1.0, 2.0, 0.3143918569470784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400044.3823367539, 400044.3823367539, 117367.4629770729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 517800.0000, 
sim time next is 518400.0000, 
raw observation next is [22.6, 59.0, 1.0, 2.0, 0.3161306310778658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402241.7789574796, 402241.7789574796, 117586.9293508268], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.59, 1.0, 1.0, 0.18586979890222122, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14365777819909986, 0.14365777819909986, 0.22612871029005155], 
reward next is 0.7739, 
noisyNet noise sample is [array([-0.18032746], dtype=float32), 0.24335192]. 
=============================================
[2019-03-24 03:18:54,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3899816e-17 9.9941576e-01 2.2072760e-14 1.3726746e-04 4.4705989e-04], sum to 1.0000
[2019-03-24 03:18:54,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9872
[2019-03-24 03:18:54,018] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 69.0, 1.0, 2.0, 0.3058617502214956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390520.3274004331, 390520.3274004331, 116303.3695461298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 621600.0000, 
sim time next is 622200.0000, 
raw observation next is [20.48333333333333, 70.0, 1.0, 2.0, 0.3036157730619155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387795.8045169485, 387795.8045169485, 116024.2434678706], 
processed observation next is [1.0, 0.17391304347826086, 0.31419753086419744, 0.7, 1.0, 1.0, 0.17097115840704227, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1384985016131959, 0.1384985016131959, 0.2231235451305204], 
reward next is 0.7769, 
noisyNet noise sample is [array([-0.74827254], dtype=float32), 0.53145415]. 
=============================================
[2019-03-24 03:19:01,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0447181e-14 9.8974508e-01 2.4093047e-12 7.6945835e-05 1.0178008e-02], sum to 1.0000
[2019-03-24 03:19:01,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6733
[2019-03-24 03:19:01,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1321126.813064582 W.
[2019-03-24 03:19:01,561] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.05, 23.5, 1.0, 2.0, 0.5321857607807435, 1.0, 1.0, 0.5321857607807435, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257255978865, 1321126.813064582, 1321126.813064582, 249554.5909572064], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 747000.0000, 
sim time next is 747600.0000, 
raw observation next is [32.03333333333333, 23.66666666666667, 1.0, 2.0, 0.4950165744921581, 1.0, 2.0, 0.4950165744921581, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425189936, 1226642.622006096, 1226642.622006096, 237527.718971161], 
processed observation next is [1.0, 0.6521739130434783, 0.7419753086419753, 0.23666666666666672, 1.0, 1.0, 0.3988292553478072, 1.0, 1.0, 0.3988292553478072, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621281783596, 0.43808665071646286, 0.43808665071646286, 0.4567840749445404], 
reward next is 0.5432, 
noisyNet noise sample is [array([0.40696305], dtype=float32), -0.17371252]. 
=============================================
[2019-03-24 03:19:06,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6219098e-19 9.9986744e-01 1.3545427e-15 5.3057551e-07 1.3208298e-04], sum to 1.0000
[2019-03-24 03:19:06,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9648
[2019-03-24 03:19:06,703] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 42.66666666666667, 1.0, 2.0, 0.3838255448646262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477681.2104617027, 477681.2104617027, 126408.8324135307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 850800.0000, 
sim time next is 851400.0000, 
raw observation next is [27.9, 43.5, 1.0, 2.0, 0.3846687101003035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478558.591754847, 478558.591754847, 126521.8508273086], 
processed observation next is [0.0, 0.8695652173913043, 0.5888888888888888, 0.435, 1.0, 1.0, 0.26746275011940895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1709137827695882, 0.1709137827695882, 0.24331125159097808], 
reward next is 0.7567, 
noisyNet noise sample is [array([-2.5271127], dtype=float32), 0.23962632]. 
=============================================
[2019-03-24 03:19:08,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1656660e-19 9.9685514e-01 6.6103633e-15 1.5789158e-08 3.1447769e-03], sum to 1.0000
[2019-03-24 03:19:08,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2542
[2019-03-24 03:19:08,442] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 66.0, 1.0, 2.0, 0.3291722579744827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 417600.3411074098, 417600.3411074094, 119242.4737166924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 889200.0000, 
sim time next is 889800.0000, 
raw observation next is [21.86666666666667, 66.0, 1.0, 2.0, 0.3303232949409688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418778.3653628051, 418778.3653628051, 119388.4028939759], 
processed observation next is [0.0, 0.30434782608695654, 0.36543209876543226, 0.66, 1.0, 1.0, 0.20276582731067713, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14956370191528753, 0.14956370191528753, 0.2295930824884152], 
reward next is 0.7704, 
noisyNet noise sample is [array([-0.4368899], dtype=float32), -0.76295614]. 
=============================================
[2019-03-24 03:19:11,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8214631e-17 9.8314756e-01 1.4696600e-15 3.2485693e-07 1.6852112e-02], sum to 1.0000
[2019-03-24 03:19:11,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-24 03:19:11,798] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 52.0, 1.0, 2.0, 0.2806136897662384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360203.8783045574, 360203.8783045574, 113212.6598573232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 950400.0000, 
sim time next is 951000.0000, 
raw observation next is [22.66666666666667, 52.33333333333334, 1.0, 2.0, 0.2794794698908552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 358913.9781439044, 358913.978143904, 113075.8060431384], 
processed observation next is [1.0, 0.0, 0.39506172839506193, 0.5233333333333334, 1.0, 1.0, 0.14223746415578, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12818356362282302, 0.12818356362282285, 0.21745347315988153], 
reward next is 0.7825, 
noisyNet noise sample is [array([0.4113337], dtype=float32), -1.2621082]. 
=============================================
[2019-03-24 03:19:11,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.92943 ]
 [70.00581 ]
 [70.00432 ]
 [70.001144]
 [70.00678 ]], R is [[67.1407547 ]
 [67.25162506]
 [67.36109924]
 [67.46908569]
 [67.57551575]].
[2019-03-24 03:19:13,757] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.48217824e-18 9.98494387e-01 1.33827114e-14 2.43427803e-06
 1.50326442e-03], sum to 1.0000
[2019-03-24 03:19:13,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1404
[2019-03-24 03:19:13,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.63333333333333, 60.66666666666667, 1.0, 2.0, 0.2588584172150412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 333907.5741308543, 333907.5741308543, 109453.434273958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 969600.0000, 
sim time next is 970200.0000, 
raw observation next is [20.75, 60.5, 1.0, 2.0, 0.2595513449419527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334777.3806723494, 334777.3806723494, 110710.4662628514], 
processed observation next is [1.0, 0.21739130434782608, 0.32407407407407407, 0.605, 1.0, 1.0, 0.11851350588327703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1195633502401248, 0.1195633502401248, 0.21290474281317578], 
reward next is 0.7871, 
noisyNet noise sample is [array([0.6827231], dtype=float32), 0.84073204]. 
=============================================
[2019-03-24 03:19:18,095] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 03:19:18,096] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:19:18,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:19:18,097] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:19:18,098] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:19:18,099] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:19:18,099] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:19:18,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:19:18,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:19:18,103] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:19:18,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:19:18,122] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-24 03:19:18,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-24 03:19:18,178] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-24 03:19:18,203] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-24 03:19:18,229] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-24 03:19:21,776] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:19:21,777] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.7, 58.66666666666667, 1.0, 2.0, 0.200257397126566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 258304.0082678586, 258304.0082678586, 79386.00625827405]
[2019-03-24 03:19:21,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:19:21,780] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1818221e-16 9.9824762e-01 2.8028101e-13 4.9424493e-06 1.7473844e-03], sampled 0.8580308817135298
[2019-03-24 03:19:22,446] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:19:22,448] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.044555105, 16.32836720166667, 1.0, 2.0, 0.3797912688161127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484640.5727978591, 484640.5727978591, 126003.3238122302]
[2019-03-24 03:19:22,450] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:19:22,451] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2457434e-17 9.9867475e-01 7.5232463e-14 2.8614238e-06 1.3224733e-03], sampled 0.6176480321694859
[2019-03-24 03:19:49,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:19:49,554] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.05, 93.5, 1.0, 2.0, 0.5645773458920944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8988255216607067, 6.911199999999999, 6.9112, 121.9260426155196, 1287327.795663696, 1287327.795663696, 280330.0015333394]
[2019-03-24 03:19:49,554] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:19:49,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.3760810e-17 9.9829620e-01 2.3439738e-13 4.5920260e-06 1.6991949e-03], sampled 0.957725721585013
[2019-03-24 03:19:53,174] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:19:53,175] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.8, 68.66666666666666, 1.0, 2.0, 0.4961326148595575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593335.7063064502, 593335.7063064502, 142346.8051741119]
[2019-03-24 03:19:53,175] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:19:53,180] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9637838e-17 9.9870849e-01 6.7556732e-14 2.7355957e-06 1.2888140e-03], sampled 0.3711124507046726
[2019-03-24 03:20:11,425] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:20:11,425] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.01678957, 71.586852005, 1.0, 2.0, 0.6753571284320199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1484675.100583609, 1484675.100583609, 312813.6968271265]
[2019-03-24 03:20:11,426] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:20:11,428] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.8601877e-17 9.9860877e-01 9.1400879e-14 3.1035820e-06 1.3881408e-03], sampled 0.5188748400069075
[2019-03-24 03:20:11,429] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1484675.100583609 W.
[2019-03-24 03:20:15,145] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:20:15,146] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.6, 73.0, 1.0, 2.0, 0.5199128243368164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615886.4046508353, 615886.4046508353, 145897.4481998864]
[2019-03-24 03:20:15,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:20:15,150] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4605197e-17 9.9857724e-01 1.0587763e-13 3.2975756e-06 1.4194152e-03], sampled 0.9660118632034498
[2019-03-24 03:20:16,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:20:16,131] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.93333333333333, 91.33333333333334, 1.0, 2.0, 0.5723535764105495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 666811.4479311422, 666811.4479311417, 154073.9943535046]
[2019-03-24 03:20:16,132] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:20:16,134] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5111574e-17 9.9857402e-01 1.0709571e-13 3.3131309e-06 1.4226618e-03], sampled 0.42354534841722913
[2019-03-24 03:20:22,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:20:22,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.89149301833334, 111.6767336833333, 1.0, 2.0, 0.7612603492916421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867660.965654233, 867660.965654233, 188065.2258558968]
[2019-03-24 03:20:22,529] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:20:22,531] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.0120638e-17 9.9843651e-01 1.6408130e-13 3.9563179e-06 1.5595624e-03], sampled 0.291320194480852
[2019-03-24 03:20:32,495] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8811221]
[2019-03-24 03:20:32,497] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.05, 84.5, 1.0, 2.0, 0.5732673125018093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665502.1582458576, 665502.1582458576, 154121.8983167696]
[2019-03-24 03:20:32,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:20:32,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.6092209e-17 9.9845040e-01 1.5548313e-13 3.8695148e-06 1.5456066e-03], sampled 0.20126087763956757
[2019-03-24 03:20:55,553] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8569.1250 2249575043.5577 553.0000
[2019-03-24 03:20:55,869] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8914.1088 2121123760.0216 432.0000
[2019-03-24 03:20:55,889] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8758.1502 2171507149.0712 493.0000
[2019-03-24 03:20:55,929] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8677.9005 2196331540.7263 572.0000
[2019-03-24 03:20:56,127] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8084.3168 2446260774.0921 747.0000
[2019-03-24 03:20:57,146] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1725000, evaluation results [1725000.0, 8084.316790067984, 2446260774.0920677, 747.0, 8758.150211583488, 2171507149.071195, 493.0, 8914.10878190506, 2121123760.02159, 432.0, 8569.124998731857, 2249575043.5576825, 553.0, 8677.90045287514, 2196331540.72626, 572.0]
[2019-03-24 03:20:58,874] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0132706e-17 9.7446150e-01 1.2501945e-13 9.4906118e-06 2.5528979e-02], sum to 1.0000
[2019-03-24 03:20:58,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8452
[2019-03-24 03:20:58,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1372791.41857167 W.
[2019-03-24 03:20:58,900] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.56666666666666, 43.33333333333334, 1.0, 2.0, 0.9291596236339765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.306895039924113, 6.9112, 121.924287327403, 1372791.41857167, 1170163.10845638, 228460.8397811123], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1093200.0000, 
sim time next is 1093800.0000, 
raw observation next is [26.53333333333333, 43.66666666666667, 1.0, 2.0, 0.5076140196498093, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8439419166155215, 6.911200000000001, 6.9112, 121.9258043018699, 1260536.774936948, 1260536.774936947, 255347.774218956], 
processed observation next is [1.0, 0.6521739130434783, 0.5382716049382715, 0.4366666666666667, 1.0, 1.0, 0.4138262138688206, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.804927395769402, 8.881784197001253e-17, 0.0, 0.8094605466643866, 0.45019170533462427, 0.45019170533462394, 0.4910534119595308], 
reward next is 0.5089, 
noisyNet noise sample is [array([-1.6403244], dtype=float32), -0.1597229]. 
=============================================
[2019-03-24 03:21:03,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5565015e-15 9.9914503e-01 2.3213315e-12 3.3051179e-05 8.2196784e-04], sum to 1.0000
[2019-03-24 03:21:03,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7854
[2019-03-24 03:21:03,028] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 66.83333333333334, 1.0, 2.0, 0.5678287166299141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727826.5450798428, 727826.5450798428, 155072.1664190622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156200.0000, 
sim time next is 1156800.0000, 
raw observation next is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
processed observation next is [1.0, 0.391304347826087, 0.3160493827160493, 0.6666666666666667, 1.0, 1.0, 0.45218318234064925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24701145839495767, 0.24701145839495767, 0.28912518868606674], 
reward next is 0.7109, 
noisyNet noise sample is [array([-1.3367058], dtype=float32), -0.63551545]. 
=============================================
[2019-03-24 03:21:06,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3924011e-18 9.9847239e-01 1.7146759e-14 2.1826179e-06 1.5254526e-03], sum to 1.0000
[2019-03-24 03:21:06,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1991
[2019-03-24 03:21:06,372] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 81.33333333333334, 1.0, 2.0, 0.3780729086734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470710.6046117082, 470710.6046117082, 125620.9818334616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1732800.0000, 
sim time next is 1733400.0000, 
raw observation next is [21.2, 81.5, 1.0, 2.0, 0.3775878932256209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470176.5149414508, 470176.5149414508, 125555.9012396932], 
processed observation next is [1.0, 0.043478260869565216, 0.34074074074074073, 0.815, 1.0, 1.0, 0.2590332062209773, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.167920183907661, 0.167920183907661, 0.24145365623017923], 
reward next is 0.7585, 
noisyNet noise sample is [array([0.27315512], dtype=float32), 0.2439869]. 
=============================================
[2019-03-24 03:21:07,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9289676e-20 9.9998593e-01 1.7320856e-13 4.9553137e-07 1.3530407e-05], sum to 1.0000
[2019-03-24 03:21:07,334] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8810
[2019-03-24 03:21:07,345] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 79.83333333333333, 1.0, 2.0, 0.7094311882170682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892798.8648029665, 892798.8648029665, 180997.4508890707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242600.0000, 
sim time next is 1243200.0000, 
raw observation next is [20.7, 78.66666666666667, 1.0, 2.0, 0.6267874899404308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788290.6235061765, 788290.6235061765, 165368.7629179218], 
processed observation next is [1.0, 0.391304347826087, 0.3222222222222222, 0.7866666666666667, 1.0, 1.0, 0.555699392786227, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28153236553792016, 0.28153236553792016, 0.3180168517652342], 
reward next is 0.6820, 
noisyNet noise sample is [array([0.81570625], dtype=float32), 0.5298901]. 
=============================================
[2019-03-24 03:21:11,660] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0215868e-17 9.9999964e-01 6.9942438e-14 6.2067961e-08 2.2009199e-07], sum to 1.0000
[2019-03-24 03:21:11,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-24 03:21:11,673] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 59.66666666666667, 1.0, 2.0, 0.7424941947886787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260355361619, 922470.3533909888, 922470.3533909888, 187354.6959933391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1329600.0000, 
sim time next is 1330200.0000, 
raw observation next is [24.85, 58.0, 1.0, 2.0, 0.7821532043430101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426135031, 972478.5767956843, 972478.5767956843, 195517.3543359928], 
processed observation next is [1.0, 0.391304347826087, 0.475925925925926, 0.58, 1.0, 1.0, 0.7406585765988215, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288058044, 0.3473137774270301, 0.3473137774270301, 0.3759949121846015], 
reward next is 0.6240, 
noisyNet noise sample is [array([-0.92384255], dtype=float32), -1.531683]. 
=============================================
[2019-03-24 03:21:18,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0828207e-20 9.9999154e-01 4.3518568e-16 4.1427146e-08 8.4339808e-06], sum to 1.0000
[2019-03-24 03:21:18,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7695
[2019-03-24 03:21:18,635] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.40000000000001, 25.66666666666667, 1.0, 2.0, 0.3807647349732278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476910.4753062477, 476910.4753062477, 126043.2660267754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1448400.0000, 
sim time next is 1449000.0000, 
raw observation next is [32.25, 26.0, 1.0, 2.0, 0.3789287462809612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474734.4962608797, 474734.4962608792, 125792.7743504222], 
processed observation next is [0.0, 0.782608695652174, 0.75, 0.26, 1.0, 1.0, 0.2606294598582871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1695480343788856, 0.16954803437888544, 0.24190918144311963], 
reward next is 0.7581, 
noisyNet noise sample is [array([-0.2531146], dtype=float32), 0.9159561]. 
=============================================
[2019-03-24 03:21:18,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[80.10075]
 [80.13161]
 [80.19466]
 [80.19172]
 [80.19362]], R is [[80.01780701]
 [79.97523499]
 [79.93139648]
 [79.88912201]
 [79.84682465]].
[2019-03-24 03:21:23,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4795944e-17 9.9953938e-01 4.4582345e-13 2.5931488e-06 4.5799944e-04], sum to 1.0000
[2019-03-24 03:21:23,060] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9143
[2019-03-24 03:21:23,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 79.0, 1.0, 2.0, 0.4910760330590257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592050.1420405145, 592050.1420405145, 141722.7921592199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540800.0000, 
sim time next is 1541400.0000, 
raw observation next is [23.68333333333333, 78.33333333333334, 1.0, 2.0, 0.4890602735796402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590755.2144132018, 590755.2144132018, 141446.1947255953], 
processed observation next is [0.0, 0.8695652173913043, 0.4327160493827159, 0.7833333333333334, 1.0, 1.0, 0.3917384209281431, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21098400514757207, 0.21098400514757207, 0.2720119129338371], 
reward next is 0.7280, 
noisyNet noise sample is [array([-1.1907948], dtype=float32), 0.015503881]. 
=============================================
[2019-03-24 03:21:25,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6376938e-15 9.9523073e-01 2.4848715e-10 2.3290444e-04 4.5362976e-03], sum to 1.0000
[2019-03-24 03:21:25,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6300
[2019-03-24 03:21:25,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1349204.096665359 W.
[2019-03-24 03:21:25,116] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.26666666666667, 55.33333333333334, 1.0, 2.0, 0.9353217940746833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.273084312511627, 6.9112, 121.9244482286624, 1349204.096665359, 1163889.407137885, 229627.0632720523], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1592400.0000, 
sim time next is 1593000.0000, 
raw observation next is [25.4, 55.0, 1.0, 2.0, 0.3386376975568861, 1.0, 1.0, 0.3386376975568861, 1.0, 1.0, 0.5509540181948123, 6.9112, 6.9112, 121.94756008, 1233672.329087962, 1233672.329087962, 270282.7157106861], 
processed observation next is [1.0, 0.43478260869565216, 0.49629629629629624, 0.55, 1.0, 1.0, 0.21266392566295966, 1.0, 0.5, 0.21266392566295966, 1.0, 0.5, 0.4386925227435153, 0.0, 0.0, 0.8096049824067558, 0.44059726038855784, 0.44059726038855784, 0.519774453289781], 
reward next is 0.4802, 
noisyNet noise sample is [array([-0.13304104], dtype=float32), -1.2011855]. 
=============================================
[2019-03-24 03:21:25,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.06922 ]
 [62.438072]
 [62.296085]
 [62.193493]
 [61.547928]], R is [[62.64032745]
 [62.01392365]
 [61.39378357]
 [60.77984619]
 [60.17204666]].
[2019-03-24 03:21:28,902] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6190503e-16 9.9431831e-01 9.2332469e-10 1.5196741e-03 4.1619674e-03], sum to 1.0000
[2019-03-24 03:21:28,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-24 03:21:28,907] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 66.0, 1.0, 2.0, 0.3142578712587937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399041.7897404566, 399041.7897404566, 117345.1993184392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1648800.0000, 
sim time next is 1649400.0000, 
raw observation next is [21.48333333333333, 67.16666666666667, 1.0, 2.0, 0.5130906042522863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 651514.3627255817, 651514.3627255813, 145938.5653514462], 
processed observation next is [1.0, 0.08695652173913043, 0.3512345679012345, 0.6716666666666667, 1.0, 1.0, 0.4203459574431979, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23268370097342206, 0.2326837009734219, 0.2806510872143196], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.8314315], dtype=float32), 0.9132652]. 
=============================================
[2019-03-24 03:21:31,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1306667e-11 9.5524544e-01 6.0681714e-08 4.3212520e-03 4.0433154e-02], sum to 1.0000
[2019-03-24 03:21:31,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3056
[2019-03-24 03:21:31,422] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 69.0, 1.0, 2.0, 0.8983096293272892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.997841907601161, 6.9112, 121.9256611192311, 1157186.000843938, 1112817.739011347, 220882.1909832927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1694400.0000, 
sim time next is 1695000.0000, 
raw observation next is [23.35, 69.0, 1.0, 2.0, 0.9168433206906356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.117978036315361, 6.9112, 121.925071392979, 1240997.340644417, 1135109.347915365, 225145.8265301012], 
processed observation next is [1.0, 0.6086956521739131, 0.42037037037037045, 0.69, 1.0, 1.0, 0.9010039532031375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02067780363153613, 0.0, 0.8094556809115226, 0.4432133359444347, 0.4053961956840589, 0.4329727433271177], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8642779], dtype=float32), 0.75869906]. 
=============================================
[2019-03-24 03:21:31,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[51.551453]
 [52.070133]
 [52.20741 ]
 [51.939438]
 [52.647373]], R is [[50.56609726]
 [50.20245361]
 [49.70042801]
 [49.78488922]
 [49.87378311]].
[2019-03-24 03:21:33,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4704193e-14 9.9172169e-01 4.9137287e-07 1.6021273e-03 6.6756522e-03], sum to 1.0000
[2019-03-24 03:21:33,633] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6583
[2019-03-24 03:21:33,639] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 87.33333333333333, 1.0, 2.0, 0.3918526065444452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489935.8632362558, 489935.8632362558, 127566.3584517511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1743000.0000, 
sim time next is 1743600.0000, 
raw observation next is [20.06666666666667, 87.66666666666667, 1.0, 2.0, 0.3727222105462671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 466161.2484356069, 466161.2484356064, 124929.7546281163], 
processed observation next is [1.0, 0.17391304347826086, 0.29876543209876555, 0.8766666666666667, 1.0, 1.0, 0.25324072684079413, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16648616015557388, 0.16648616015557371, 0.24024952813099287], 
reward next is 0.7598, 
noisyNet noise sample is [array([0.32986274], dtype=float32), 0.075599656]. 
=============================================
[2019-03-24 03:21:46,343] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0741619e-12 6.9162780e-01 2.9751519e-04 1.7220590e-02 2.9085410e-01], sum to 1.0000
[2019-03-24 03:21:46,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6504
[2019-03-24 03:21:46,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1539516.330416323 W.
[2019-03-24 03:21:46,368] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 58.0, 1.0, 2.0, 0.6749783328892908, 1.0, 2.0, 0.6749783328892908, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1539516.330416323, 1539516.330416323, 294810.3295962561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [28.75, 59.16666666666667, 1.0, 2.0, 0.3512701701253741, 1.0, 2.0, 0.3512701701253741, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807348.5000094738, 807348.5000094742, 193540.3890344128], 
processed observation next is [1.0, 0.7391304347826086, 0.6203703703703703, 0.5916666666666667, 1.0, 1.0, 0.2277025834825882, 1.0, 1.0, 0.2277025834825882, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2883387500033835, 0.28833875000338366, 0.37219305583540924], 
reward next is 0.6278, 
noisyNet noise sample is [array([1.0196996], dtype=float32), -1.4342967]. 
=============================================
[2019-03-24 03:21:47,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6421747e-13 9.9319613e-01 8.9171552e-04 5.8641948e-04 5.3257658e-03], sum to 1.0000
[2019-03-24 03:21:47,354] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2371
[2019-03-24 03:21:47,359] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.3629255962178805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 454934.7871474361, 454934.7871474356, 123620.8794279519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1987200.0000, 
sim time next is 1987800.0000, 
raw observation next is [19.5, 91.00000000000001, 1.0, 2.0, 0.3634319201879735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 455564.3234768051, 455564.3234768047, 123688.9470067443], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.9100000000000001, 1.0, 1.0, 0.2421808573666351, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16270154409885898, 0.1627015440988588, 0.23786335962835442], 
reward next is 0.7621, 
noisyNet noise sample is [array([-0.94605356], dtype=float32), 0.69218904]. 
=============================================
[2019-03-24 03:21:47,691] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:21:47,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:21:47,694] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:21:47,696] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:21:47,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:21:47,696] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:21:47,697] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:21:47,697] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:21:47,701] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:21:47,698] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:21:47,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:21:47,722] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-24 03:21:47,749] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-24 03:21:47,750] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-24 03:21:47,751] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-24 03:21:47,828] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-24 03:22:01,330] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:01,330] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.9, 43.5, 1.0, 2.0, 0.2477600405354411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 319588.5336963733, 319588.5336963729, 88794.9726130993]
[2019-03-24 03:22:01,331] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:22:01,333] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.2974636e-16 9.9663866e-01 5.4908065e-05 3.5963481e-04 2.9468113e-03], sampled 0.3566425337027549
[2019-03-24 03:22:13,686] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:13,686] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.85, 87.0, 1.0, 2.0, 0.3869607042337463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479672.3830206306, 479672.3830206311, 126802.1387610369]
[2019-03-24 03:22:13,686] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:22:13,692] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2989934e-17 9.9776125e-01 2.8444761e-05 2.1454807e-04 1.9957412e-03], sampled 0.8473238268214468
[2019-03-24 03:22:22,170] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:22,171] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.9, 52.0, 1.0, 2.0, 0.3725748806741226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469644.5156403034, 469644.5156403034, 124965.8400426955]
[2019-03-24 03:22:22,175] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:22:22,179] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9741617e-16 9.9733233e-01 3.7794292e-05 2.6820356e-04 2.3616785e-03], sampled 0.06145846795736443
[2019-03-24 03:22:22,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:22,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.0934392, 36.16192574, 1.0, 2.0, 0.3195741182658896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406721.929693488, 406721.929693488, 118023.2829830082]
[2019-03-24 03:22:22,997] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:23,000] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9434128e-16 9.9666792e-01 5.4135617e-05 3.5565137e-04 2.9222502e-03], sampled 0.7182632470784589
[2019-03-24 03:22:27,702] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:27,702] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.95, 78.83333333333334, 1.0, 2.0, 0.6823570459195953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777683.8000875487, 777683.8000875487, 172827.8662334082]
[2019-03-24 03:22:27,702] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:22:27,705] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7877341e-16 9.9687934e-01 4.8688700e-05 3.2724338e-04 2.7446826e-03], sampled 0.06169105209937453
[2019-03-24 03:22:36,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:36,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.06666666666667, 78.66666666666666, 1.0, 2.0, 0.6701388720831819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 790934.1995188108, 790934.1995188104, 171835.9354542774]
[2019-03-24 03:22:36,908] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:22:36,911] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5957926e-16 9.9743038e-01 3.5567118e-05 2.5571132e-04 2.2782958e-03], sampled 0.39975225522382507
[2019-03-24 03:22:43,263] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:43,264] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.08333333333333, 83.16666666666667, 1.0, 2.0, 0.9058360529712366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032554.889008045, 1032554.889008045, 218792.1145501329]
[2019-03-24 03:22:43,266] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:22:43,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.5192884e-16 9.9679834e-01 5.0725946e-05 3.3795988e-04 2.8130629e-03], sampled 0.04986974256796839
[2019-03-24 03:22:44,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:44,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 68.16666666666666, 1.0, 2.0, 0.9399940890719616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156495, 1786739.419325208, 1786739.419325209, 365742.5060408577]
[2019-03-24 03:22:44,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:22:44,173] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.77972625e-15 9.94988739e-01 1.03916034e-04 5.95725491e-04
 4.31167800e-03], sampled 0.13959448954906595
[2019-03-24 03:22:44,176] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1786739.419325208 W.
[2019-03-24 03:22:46,571] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:46,572] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.90216224, 103.8957360166667, 1.0, 2.0, 0.5782215782039232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673557.7703953587, 673557.7703953587, 155062.1407226003]
[2019-03-24 03:22:46,573] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:46,575] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8838550e-17 9.9791390e-01 2.5361580e-05 1.9606146e-04 1.8646943e-03], sampled 0.04343070416588912
[2019-03-24 03:22:53,980] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:53,982] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.20396103, 71.65242992, 1.0, 2.0, 0.7830608976314355, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260425404219, 1607606.960346539, 1607606.96034654, 332893.4220297185]
[2019-03-24 03:22:53,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:53,985] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8212319e-17 9.9784720e-01 2.6678024e-05 2.0401245e-04 1.9221216e-03], sampled 0.9156455335629816
[2019-03-24 03:22:53,986] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1607606.960346539 W.
[2019-03-24 03:22:54,342] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:22:54,344] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.80465657, 81.87850973, 1.0, 2.0, 0.590780458033768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681115.1891010861, 681115.1891010861, 156880.9066709505]
[2019-03-24 03:22:54,344] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:54,348] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.9025839e-17 9.9799454e-01 2.3787419e-05 1.8643853e-04 1.7952486e-03], sampled 0.5449808350205667
[2019-03-24 03:23:18,140] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.8909586]
[2019-03-24 03:23:18,143] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.66666666666667, 63.0, 1.0, 2.0, 0.2487795950041965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 320903.943897596, 320903.943897596, 100554.4321287242]
[2019-03-24 03:23:18,144] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:23:18,146] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4855261e-17 9.9780744e-01 2.7500086e-05 2.0893100e-04 1.9561781e-03], sampled 0.7886597196940964
[2019-03-24 03:23:24,912] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8740.7205 2172250324.9774 492.0000
[2019-03-24 03:23:25,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8545.7033 2250749586.9601 552.0000
[2019-03-24 03:23:25,461] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8067.0380 2447076482.5030 747.0000
[2019-03-24 03:23:25,477] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8879.7212 2122787772.5927 428.0000
[2019-03-24 03:23:25,627] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8671.9675 2196690086.0642 570.0000
[2019-03-24 03:23:26,644] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1750000, evaluation results [1750000.0, 8067.037981669392, 2447076482.502974, 747.0, 8740.720493231554, 2172250324.9774137, 492.0, 8879.721187597117, 2122787772.5927224, 428.0, 8545.703286477614, 2250749586.9600573, 552.0, 8671.96745726935, 2196690086.0642314, 570.0]
[2019-03-24 03:23:32,653] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0991492e-17 9.9983370e-01 8.6692000e-07 1.0641742e-06 1.6433393e-04], sum to 1.0000
[2019-03-24 03:23:32,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0003
[2019-03-24 03:23:32,664] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 86.0, 1.0, 2.0, 0.4845037058286363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580496.6879193167, 580496.6879193167, 140576.4924067212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2103600.0000, 
sim time next is 2104200.0000, 
raw observation next is [23.4, 85.0, 1.0, 2.0, 0.4887164205530263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584527.3868111529, 584527.3868111534, 141193.0129309034], 
processed observation next is [0.0, 0.34782608695652173, 0.42222222222222217, 0.85, 1.0, 1.0, 0.39132907208693607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20875978100398318, 0.20875978100398335, 0.27152502486712193], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.37832463], dtype=float32), 1.1243305]. 
=============================================
[2019-03-24 03:23:40,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3468630e-15 9.9999142e-01 7.5815274e-06 1.4561105e-07 8.0785753e-07], sum to 1.0000
[2019-03-24 03:23:40,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8762
[2019-03-24 03:23:40,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1419642.428855143 W.
[2019-03-24 03:23:40,788] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.93333333333333, 37.0, 1.0, 2.0, 0.5895373128875029, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9535753774994408, 6.911199999999999, 6.9112, 121.9260426156618, 1419642.428855143, 1419642.428855143, 287752.4523655929], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2388000.0000, 
sim time next is 2388600.0000, 
raw observation next is [30.9, 37.0, 1.0, 2.0, 0.3846932879313104, 1.0, 1.0, 0.3846932879313104, 1.0, 2.0, 0.6178044296859753, 6.911199999999999, 6.9112, 121.94756008, 1370123.44667252, 1370123.446672521, 290252.8247527188], 
processed observation next is [1.0, 0.6521739130434783, 0.7, 0.37, 1.0, 1.0, 0.2674920094420362, 1.0, 0.5, 0.2674920094420362, 1.0, 1.0, 0.5222555371074691, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4893298023830428, 0.48932980238304324, 0.5581785091398438], 
reward next is 0.4418, 
noisyNet noise sample is [array([-0.18567117], dtype=float32), -0.32844782]. 
=============================================
[2019-03-24 03:23:44,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1819464e-21 1.0000000e+00 3.8641326e-09 4.0192347e-09 1.9225398e-10], sum to 1.0000
[2019-03-24 03:23:44,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8187
[2019-03-24 03:23:44,804] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 89.16666666666666, 1.0, 2.0, 0.4617359917306657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559722.6546571284, 559722.6546571284, 137319.2513683642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [21.9, 90.0, 1.0, 2.0, 0.4624445150913689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 560829.967364177, 560829.9673641765, 137434.1147027519], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.9, 1.0, 1.0, 0.3600529941563916, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2002964169157775, 0.20029641691577732, 0.264296374428369], 
reward next is 0.7357, 
noisyNet noise sample is [array([0.29059675], dtype=float32), 0.25910032]. 
=============================================
[2019-03-24 03:23:44,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2355462e-22 1.0000000e+00 3.9324846e-09 8.6642316e-10 6.7940306e-11], sum to 1.0000
[2019-03-24 03:23:44,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2637
[2019-03-24 03:23:44,893] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 87.5, 1.0, 2.0, 0.4637369753140788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561675.1328872836, 561675.1328872836, 137607.0020323604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2327400.0000, 
sim time next is 2328000.0000, 
raw observation next is [22.16666666666666, 88.33333333333334, 1.0, 2.0, 0.4619771256219356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 559774.63105754, 559774.6310575395, 137348.1302403738], 
processed observation next is [1.0, 0.9565217391304348, 0.376543209876543, 0.8833333333333334, 1.0, 1.0, 0.3594965781213519, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19991951109197856, 0.1999195110919784, 0.26413101969302655], 
reward next is 0.7359, 
noisyNet noise sample is [array([-1.5622349], dtype=float32), 0.8981279]. 
=============================================
[2019-03-24 03:23:44,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.002304]
 [75.96296 ]
 [75.92559 ]
 [75.86195 ]
 [75.754265]], R is [[76.02600098]
 [76.00111389]
 [75.97613525]
 [75.95129395]
 [75.9265213 ]].
[2019-03-24 03:23:46,343] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2615817e-17 9.9999118e-01 8.7691633e-06 2.8906957e-08 5.9212059e-08], sum to 1.0000
[2019-03-24 03:23:46,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8621
[2019-03-24 03:23:46,362] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 82.0, 1.0, 2.0, 0.4712318390193455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571972.70555177, 571972.7055517705, 138784.7537613345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2353200.0000, 
sim time next is 2353800.0000, 
raw observation next is [23.18333333333334, 78.5, 1.0, 2.0, 0.4642730774203732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565036.7862206021, 565036.7862206021, 137771.5882055326], 
processed observation next is [1.0, 0.21739130434782608, 0.4141975308641978, 0.785, 1.0, 1.0, 0.3622298540718729, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20179885222164362, 0.20179885222164362, 0.26494536193371654], 
reward next is 0.7351, 
noisyNet noise sample is [array([0.7380919], dtype=float32), 1.206222]. 
=============================================
[2019-03-24 03:23:47,798] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1607731e-15 5.2040058e-01 4.7417730e-01 4.1391645e-03 1.2829938e-03], sum to 1.0000
[2019-03-24 03:23:47,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-24 03:23:47,810] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1402371.148025629 W.
[2019-03-24 03:23:47,813] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.78333333333333, 37.16666666666667, 1.0, 2.0, 0.5855840704712283, 1.0, 2.0, 0.5855840704712283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1402371.148025629, 1402371.148025629, 266059.5681747879], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2391000.0000, 
sim time next is 2391600.0000, 
raw observation next is [30.76666666666667, 37.33333333333334, 1.0, 2.0, 0.6009750592871745, 1.0, 2.0, 0.6009750592871745, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1439768.479085771, 1439768.479085772, 271426.1093324034], 
processed observation next is [1.0, 0.6956521739130435, 0.6950617283950619, 0.3733333333333334, 1.0, 1.0, 0.5249703086752078, 1.0, 1.0, 0.5249703086752078, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5142030282449181, 0.5142030282449186, 0.5219732871776989], 
reward next is 0.4780, 
noisyNet noise sample is [array([0.67489976], dtype=float32), -0.007143789]. 
=============================================
[2019-03-24 03:23:49,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2169555e-16 9.9972957e-01 9.8497279e-05 1.9747797e-05 1.5224803e-04], sum to 1.0000
[2019-03-24 03:23:49,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1257
[2019-03-24 03:23:49,893] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 63.0, 1.0, 2.0, 0.3326110680575716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421277.0515240226, 421277.0515240231, 119680.0266302358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421000.0000, 
sim time next is 2421600.0000, 
raw observation next is [22.26666666666667, 63.0, 1.0, 2.0, 0.3274255406751896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 415265.6291910117, 415265.6291910112, 119016.7509266103], 
processed observation next is [1.0, 0.0, 0.38024691358024704, 0.63, 1.0, 1.0, 0.19931611985141617, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14830915328250419, 0.148309153282504, 0.22887836716655827], 
reward next is 0.7711, 
noisyNet noise sample is [array([-0.4491127], dtype=float32), 1.9377195]. 
=============================================
[2019-03-24 03:23:49,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7734969e-14 9.9855381e-01 3.1352596e-04 5.1776029e-04 6.1487022e-04], sum to 1.0000
[2019-03-24 03:23:49,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-24 03:23:49,931] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.23333333333333, 75.66666666666667, 1.0, 2.0, 0.2861664024577431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 367364.7699542817, 367364.7699542813, 113882.4203866468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2438400.0000, 
sim time next is 2439000.0000, 
raw observation next is [19.8, 73.0, 1.0, 2.0, 0.2849989462339041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365203.2071224242, 365203.2071224242, 113743.0675277358], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.73, 1.0, 1.0, 0.1488082693260763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13042971682943721, 0.13042971682943721, 0.21873666832256883], 
reward next is 0.7813, 
noisyNet noise sample is [array([0.86613697], dtype=float32), -0.3172479]. 
=============================================
[2019-03-24 03:23:49,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.033325]
 [57.99613 ]
 [58.178333]
 [58.503803]
 [58.557808]], R is [[58.18091583]
 [58.38010025]
 [58.57209015]
 [58.76340485]
 [58.95814896]].
[2019-03-24 03:24:00,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0469453e-15 9.9997365e-01 2.5790589e-05 5.9602161e-08 6.4142137e-07], sum to 1.0000
[2019-03-24 03:24:00,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3654
[2019-03-24 03:24:00,625] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 93.83333333333334, 1.0, 2.0, 0.4792956759790421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577379.6385442168, 577379.6385442168, 139881.5812359693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2623800.0000, 
sim time next is 2624400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4869563442388586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 585031.455666031, 585031.4556660305, 141012.1254792261], 
processed observation next is [0.0, 0.391304347826087, 0.37037037037037035, 0.94, 1.0, 1.0, 0.3892337431414983, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20893980559501107, 0.2089398055950109, 0.2711771643831271], 
reward next is 0.7288, 
noisyNet noise sample is [array([-0.1205664], dtype=float32), -0.7286874]. 
=============================================
[2019-03-24 03:24:02,575] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9400489e-17 9.9998975e-01 9.9082936e-06 6.5290394e-08 2.5036150e-07], sum to 1.0000
[2019-03-24 03:24:02,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4841
[2019-03-24 03:24:02,591] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 86.66666666666666, 1.0, 2.0, 0.571763745039895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668196.9893764633, 668196.9893764633, 154065.3249149621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2666400.0000, 
sim time next is 2667000.0000, 
raw observation next is [24.18333333333333, 87.83333333333334, 1.0, 2.0, 0.5696167563854587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666001.9788128743, 666001.9788128743, 153717.3379478166], 
processed observation next is [0.0, 0.8695652173913043, 0.45123456790123445, 0.8783333333333334, 1.0, 1.0, 0.48763899569697466, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23785784957602654, 0.23785784957602654, 0.29561026528426265], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.01395544], dtype=float32), 0.7274974]. 
=============================================
[2019-03-24 03:24:02,614] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.29504 ]
 [68.277916]
 [68.274376]
 [68.26515 ]
 [68.26343 ]], R is [[68.34120941]
 [68.36151886]
 [68.38201904]
 [68.40275574]
 [68.42318726]].
[2019-03-24 03:24:17,345] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 03:24:17,346] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:24:17,347] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:24:17,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:24:17,348] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:24:17,348] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:24:17,349] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:24:17,353] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:24:17,355] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:24:17,357] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:24:17,354] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:24:17,374] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-24 03:24:17,402] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-24 03:24:17,403] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-24 03:24:17,449] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-24 03:24:17,450] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-24 03:24:48,104] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.897408]
[2019-03-24 03:24:48,106] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.60237043666667, 99.00142048666667, 1.0, 2.0, 0.7560967272933461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 861772.3204484624, 861772.3204484619, 187044.5489754903]
[2019-03-24 03:24:48,107] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:24:48,110] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5483183e-20 1.0000000e+00 8.0118552e-09 5.9191458e-12 1.1580022e-11], sampled 0.050826409499431624
[2019-03-24 03:25:36,291] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.897408]
[2019-03-24 03:25:36,292] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.7, 86.66666666666667, 1.0, 2.0, 0.5087701777367966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602700.3067909487, 602700.3067909487, 144123.4386988789]
[2019-03-24 03:25:36,293] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:25:36,295] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9668545e-21 1.0000000e+00 4.0203774e-09 2.3160263e-12 4.5853256e-12], sampled 0.3632843842279826
[2019-03-24 03:25:54,321] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 03:25:54,949] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 03:25:55,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 03:25:55,157] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 03:25:55,234] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 03:25:56,252] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1775000, evaluation results [1775000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 03:26:03,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.5936312e-13 9.9997485e-01 2.5158872e-05 3.0202120e-08 3.5402916e-08], sum to 1.0000
[2019-03-24 03:26:03,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8613
[2019-03-24 03:26:03,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1537986.589325583 W.
[2019-03-24 03:26:03,152] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 90.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.643339952622799, 6.9112, 121.9236774668536, 1537986.589325583, 1163072.768460028, 245582.2042433732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3054000.0000, 
sim time next is 3054600.0000, 
raw observation next is [25.8, 90.0, 1.0, 2.0, 0.4567871523278004, 1.0, 1.0, 0.4567871523278004, 1.0, 1.0, 0.7272200230248258, 6.9112, 6.9112, 121.94756008, 1562603.303407346, 1562603.303407346, 322850.6632243454], 
processed observation next is [1.0, 0.34782608695652173, 0.5111111111111112, 0.9, 1.0, 1.0, 0.35331803848547666, 1.0, 0.5, 0.35331803848547666, 1.0, 0.5, 0.6590250287810323, 0.0, 0.0, 0.8096049824067558, 0.5580726083597664, 0.5580726083597664, 0.6208666600468181], 
reward next is 0.3791, 
noisyNet noise sample is [array([-1.2115022], dtype=float32), 0.97724366]. 
=============================================
[2019-03-24 03:26:03,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5253652e-13 9.9999690e-01 3.1112738e-06 2.5687867e-09 6.5316605e-09], sum to 1.0000
[2019-03-24 03:26:03,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9686
[2019-03-24 03:26:03,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2363069.960564345 W.
[2019-03-24 03:26:03,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.65, 71.0, 1.0, 2.0, 0.7542162021252881, 1.0, 2.0, 0.6904727630390786, 1.0, 2.0, 0.9977734948820727, 6.911199999999997, 6.9112, 121.94756008, 2363069.960564345, 2363069.960564347, 444126.6218113452], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3072600.0000, 
sim time next is 3073200.0000, 
raw observation next is [31.86666666666667, 69.66666666666667, 1.0, 2.0, 0.7848896778998261, 1.0, 2.0, 0.7058095009263478, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2415629.331594158, 2415629.331594158, 452830.3335953561], 
processed observation next is [1.0, 0.5652173913043478, 0.7358024691358026, 0.6966666666666668, 1.0, 1.0, 0.7439162832140787, 1.0, 1.0, 0.6497732153885092, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8627247612836279, 0.8627247612836279, 0.870827564606454], 
reward next is 0.1292, 
noisyNet noise sample is [array([-0.14258134], dtype=float32), -2.3263154]. 
=============================================
[2019-03-24 03:26:04,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7154368e-15 1.0000000e+00 4.7409223e-09 1.5185055e-11 2.0833496e-10], sum to 1.0000
[2019-03-24 03:26:04,367] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7981
[2019-03-24 03:26:04,372] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.7802245056365771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889288.2639093208, 889288.2639093208, 191893.5421107759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3092400.0000, 
sim time next is 3093000.0000, 
raw observation next is [28.66666666666667, 79.66666666666667, 1.0, 2.0, 0.7725724500337684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 880561.5544982904, 880561.55449829, 190342.6209424391], 
processed observation next is [1.0, 0.8260869565217391, 0.6172839506172841, 0.7966666666666667, 1.0, 1.0, 0.7292529167068671, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31448626946367514, 0.314486269463675, 0.3660435018123829], 
reward next is 0.6340, 
noisyNet noise sample is [array([0.25317478], dtype=float32), 0.1231907]. 
=============================================
[2019-03-24 03:26:04,390] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[48.12248 ]
 [48.610733]
 [48.562912]
 [49.232033]
 [49.13481 ]], R is [[48.4114418 ]
 [48.55830002]
 [48.70398712]
 [48.84915924]
 [48.9953804 ]].
[2019-03-24 03:26:05,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.21688212e-25 1.00000000e+00 1.47097070e-13 5.95000651e-18
 1.06868466e-16], sum to 1.0000
[2019-03-24 03:26:05,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7522
[2019-03-24 03:26:05,411] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.5, 1.0, 2.0, 0.684653335386235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780302.218261713, 780302.218261713, 173257.5557887942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3097800.0000, 
sim time next is 3098400.0000, 
raw observation next is [28.33333333333334, 71.66666666666667, 1.0, 2.0, 0.6746076505158625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768847.3679039475, 768847.3679039475, 171390.8821504652], 
processed observation next is [1.0, 0.8695652173913043, 0.6049382716049385, 0.7166666666666667, 1.0, 1.0, 0.6126281553760268, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27458834567998125, 0.27458834567998125, 0.3295978502893561], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.0780969], dtype=float32), 1.810254]. 
=============================================
[2019-03-24 03:26:20,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3054648e-13 9.9999988e-01 6.9002276e-08 3.5399665e-09 4.7924692e-10], sum to 1.0000
[2019-03-24 03:26:20,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2064
[2019-03-24 03:26:20,456] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 95.0, 1.0, 2.0, 0.6501909115890347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765902.3546756374, 765902.3546756374, 168089.2948455675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388200.0000, 
sim time next is 3388800.0000, 
raw observation next is [22.93333333333333, 96.0, 1.0, 2.0, 0.625019625369211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734227.102072507, 734227.102072507, 163457.5180483424], 
processed observation next is [1.0, 0.21739130434782608, 0.40493827160493817, 0.96, 1.0, 1.0, 0.5535947921062035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26222396502589534, 0.26222396502589534, 0.31434138086219693], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.8940814], dtype=float32), 0.4811657]. 
=============================================
[2019-03-24 03:26:24,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5256492e-12 9.9994648e-01 4.2163902e-05 9.5527857e-06 1.8267158e-06], sum to 1.0000
[2019-03-24 03:26:24,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5913
[2019-03-24 03:26:24,969] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7279124184573589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829631.4554496525, 829631.4554496525, 181491.0226340366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469200.0000, 
sim time next is 3469800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9595190935], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6624566883424349, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2916342286225599, 0.2916342286225599, 0.34476915292133364], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.26710874], dtype=float32), 0.09194214]. 
=============================================
[2019-03-24 03:26:26,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5653514e-14 9.9970180e-01 2.9673704e-04 1.0081210e-06 4.2840728e-07], sum to 1.0000
[2019-03-24 03:26:26,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-24 03:26:26,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1724904.414664414 W.
[2019-03-24 03:26:26,152] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 77.0, 1.0, 2.0, 0.5041850736805009, 1.0, 1.0, 0.5041850736805009, 1.0, 2.0, 0.802679057460856, 6.9112, 6.9112, 121.94756008, 1724904.414664414, 1724904.414664414, 345647.8748685881], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3495600.0000, 
sim time next is 3496200.0000, 
raw observation next is [27.75, 75.83333333333334, 1.0, 2.0, 0.7713390007970071, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426117224, 1594228.362993028, 1594228.362993028, 330608.7380695266], 
processed observation next is [1.0, 0.4782608695652174, 0.5833333333333334, 0.7583333333333334, 1.0, 1.0, 0.7277845247583418, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621287939824, 0.56936727249751, 0.56936727249751, 0.6357860347490897], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.387854], dtype=float32), -0.18392015]. 
=============================================
[2019-03-24 03:26:32,320] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7055345e-09 9.9990749e-01 7.6914548e-05 1.3560128e-05 2.0094890e-06], sum to 1.0000
[2019-03-24 03:26:32,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4323
[2019-03-24 03:26:32,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1406540.802240581 W.
[2019-03-24 03:26:32,339] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.13333333333333, 83.66666666666667, 1.0, 2.0, 0.9784070054464278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.355273408700319, 6.9112, 121.9244651632993, 1406540.802240581, 1179138.468274656, 238702.4461324576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4090800.0000, 
sim time next is 4091400.0000, 
raw observation next is [23.35, 83.5, 1.0, 2.0, 0.588953135877533, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9440400246872908, 6.911200000000001, 6.9112, 121.9257752023137, 1391632.624882045, 1391632.624882044, 288541.9424414755], 
processed observation next is [1.0, 0.34782608695652173, 0.42037037037037045, 0.835, 1.0, 1.0, 0.5106584950923011, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9300500308591133, 8.881784197001253e-17, 0.0, 0.8094603534735948, 0.49701165174358747, 0.49701165174358714, 0.5548883508489914], 
reward next is 0.4451, 
noisyNet noise sample is [array([-0.31627646], dtype=float32), 0.7875831]. 
=============================================
[2019-03-24 03:26:33,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3461903e-18 9.9999976e-01 2.3069011e-07 1.3943001e-09 5.8941817e-11], sum to 1.0000
[2019-03-24 03:26:33,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0431
[2019-03-24 03:26:33,956] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 88.0, 1.0, 2.0, 0.5457005767406324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641986.4578980857, 641986.4578980857, 149909.4450543516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.5352603653976642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632176.4500010482, 632176.4500010482, 148302.9018014316], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.85, 1.0, 1.0, 0.4467385302353145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22577730357180292, 0.22577730357180292, 0.28519788807967617], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.648633], dtype=float32), -0.04789756]. 
=============================================
[2019-03-24 03:26:34,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3916078e-18 9.9999976e-01 1.8013482e-07 1.4803149e-09 2.6834798e-10], sum to 1.0000
[2019-03-24 03:26:34,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0675
[2019-03-24 03:26:34,865] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 99.16666666666667, 1.0, 2.0, 0.6303125583935705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732785.4333435268, 732785.4333435268, 164064.5705338401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3639000.0000, 
sim time next is 3639600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.6168861117122553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716167.1224770615, 716167.1224770615, 161637.5028450152], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5439120377526848, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25577397231323623, 0.25577397231323623, 0.31084135162502924], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.6183612], dtype=float32), 1.6905583]. 
=============================================
[2019-03-24 03:26:37,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.85728927e-12 8.76572073e-01 1.22828715e-01 3.80720128e-04
 2.18498069e-04], sum to 1.0000
[2019-03-24 03:26:37,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-24 03:26:37,318] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 89.16666666666667, 1.0, 2.0, 0.7136999304661727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813424.3079552135, 813424.3079552135, 178757.4554551122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.7178856394877438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818197.4270262625, 818197.4270262625, 179560.9438940752], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.8933333333333334, 1.0, 1.0, 0.6641495708187426, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29221336679509374, 0.29221336679509374, 0.34530950748860617], 
reward next is 0.6547, 
noisyNet noise sample is [array([0.15649025], dtype=float32), 0.71010953]. 
=============================================
[2019-03-24 03:26:40,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5060826e-11 2.9714061e-02 9.6946788e-01 1.5614614e-04 6.6181662e-04], sum to 1.0000
[2019-03-24 03:26:41,007] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6411
[2019-03-24 03:26:41,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2049580.702203102 W.
[2019-03-24 03:26:41,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.53333333333333, 82.66666666666666, 1.0, 2.0, 0.8984673600974288, 1.0, 2.0, 0.8984673600974288, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.926042615612, 2049580.702203102, 2049580.702203101, 386123.9661705779], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3753600.0000, 
sim time next is 3754200.0000, 
raw observation next is [28.91666666666667, 79.83333333333333, 1.0, 2.0, 0.8969233748682023, 1.0, 2.0, 0.8969233748682023, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2046054.533245349, 2046054.533245349, 385433.6429735402], 
processed observation next is [1.0, 0.43478260869565216, 0.6265432098765434, 0.7983333333333333, 1.0, 1.0, 0.8772897319859551, 1.0, 1.0, 0.8772897319859551, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7307337618733389, 0.7307337618733389, 0.741218544179885], 
reward next is 0.2588, 
noisyNet noise sample is [array([0.54167783], dtype=float32), -0.16517672]. 
=============================================
[2019-03-24 03:26:41,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0109270e-13 8.1580982e-04 9.9906462e-01 5.8506871e-06 1.1379021e-04], sum to 1.0000
[2019-03-24 03:26:41,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-24 03:26:41,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2590506.750798859 W.
[2019-03-24 03:26:41,659] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.53333333333333, 66.33333333333333, 1.0, 2.0, 0.8869345641499128, 1.0, 2.0, 0.756831944051391, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2590506.750798859, 2590506.750798859, 483249.9084043227], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3764400.0000, 
sim time next is 3765000.0000, 
raw observation next is [32.66666666666666, 65.16666666666667, 1.0, 2.0, 0.8919223008427977, 1.0, 2.0, 0.7593258123978334, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2599055.264838574, 2599055.264838574, 484794.4592461415], 
processed observation next is [1.0, 0.5652173913043478, 0.7654320987654317, 0.6516666666666667, 1.0, 1.0, 0.871336072431902, 1.0, 1.0, 0.7134831099974207, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.9282340231566336, 0.9282340231566336, 0.9322970370118105], 
reward next is 0.0677, 
noisyNet noise sample is [array([0.1422721], dtype=float32), 0.8798436]. 
=============================================
[2019-03-24 03:26:41,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[42.773636]
 [42.44669 ]
 [41.95052 ]
 [43.097954]
 [43.154526]], R is [[42.64798355]
 [42.29217911]
 [41.86925888]
 [41.45056534]
 [41.03606033]].
[2019-03-24 03:26:47,106] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 03:26:47,106] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:26:47,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:26:47,108] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:26:47,109] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:26:47,109] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:26:47,110] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:26:47,110] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:26:47,111] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:26:47,116] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:26:47,116] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:26:47,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-24 03:26:47,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-24 03:26:47,195] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-24 03:26:47,197] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-24 03:26:47,218] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-24 03:26:56,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:26:56,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.4, 73.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2177628652556813, 6.911199999999999, 6.9112, 121.9260426156618, 310960.256547148, 310960.2565471485, 128678.9246702851]
[2019-03-24 03:26:56,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:26:56,280] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9357273e-14 5.4010766e-04 9.9939954e-01 5.1888247e-08 6.0310915e-05], sampled 0.3037302225211841
[2019-03-24 03:26:59,368] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:26:59,369] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 20.5, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2665161342924093, 6.911199999999999, 6.9112, 121.9260426156618, 380596.053909162, 380596.0539091625, 131777.4587417247]
[2019-03-24 03:26:59,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:26:59,376] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0771972e-14 4.8511050e-04 9.9946433e-01 3.8065860e-08 5.0551600e-05], sampled 0.5907994822705771
[2019-03-24 03:27:07,226] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:27:07,227] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.55, 43.83333333333334, 1.0, 2.0, 0.1674548325561593, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2829374575944478, 6.9112, 6.9112, 121.9260426156618, 420337.4604644533, 420337.4604644533, 159340.8634791261]
[2019-03-24 03:27:07,228] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:27:07,230] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7413825e-15 3.9846043e-04 9.9956232e-01 2.4699512e-08 3.9233375e-05], sampled 0.2780244652310483
[2019-03-24 03:27:30,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:27:30,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.33333333333334, 61.33333333333334, 1.0, 2.0, 0.2826697456846525, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4509632231498053, 6.9112, 6.9112, 121.9260426156618, 656200.9401330429, 656200.9401330429, 190379.2937143189]
[2019-03-24 03:27:30,061] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:27:30,063] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4736441e-15 2.9212143e-04 9.9968064e-01 1.3349114e-08 2.7239608e-05], sampled 0.16500506386404945
[2019-03-24 03:28:06,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:28:06,666] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333334, 91.66666666666667, 1.0, 2.0, 0.270087192707451, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4314382121801387, 6.911199999999999, 6.9112, 121.9260426156618, 630655.1050345508, 630655.1050345511, 186999.1547402749]
[2019-03-24 03:28:06,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:28:06,670] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9874807e-15 4.7130766e-04 9.9947935e-01 3.6588514e-08 4.9309499e-05], sampled 0.19990282704909468
[2019-03-24 03:28:07,130] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:28:07,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.58460819166667, 98.35565465666666, 1.0, 2.0, 0.44299150497521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7052569031466343, 6.911199999999999, 6.9112, 121.9260426156618, 1009909.659332275, 1009909.659332276, 237742.1886960391]
[2019-03-24 03:28:07,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:28:07,135] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.202797e-14 6.237329e-04 9.993056e-01 6.761539e-08 7.068346e-05], sampled 0.2040907858175547
[2019-03-24 03:28:12,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.89964134]
[2019-03-24 03:28:12,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.85939344333333, 79.65270826666666, 1.0, 2.0, 0.2582662751551097, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4131301729672227, 6.911199999999999, 6.9112, 121.9260426156618, 606155.044779682, 606155.0447796824, 183875.156981578]
[2019-03-24 03:28:12,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:28:12,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6896373e-15 3.4104768e-04 9.9962604e-01 1.8329979e-08 3.2845859e-05], sampled 0.7849297783390456
[2019-03-24 03:28:24,390] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6811.4753 2600626580.8673 61.0000
[2019-03-24 03:28:24,829] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6578.4858 2661621419.3757 111.0000
[2019-03-24 03:28:24,852] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7489.0172 2565886368.5647 47.0000
[2019-03-24 03:28:24,867] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.7684 2623880762.9586 97.0000
[2019-03-24 03:28:25,163] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.4956 2831247500.0602 210.0000
[2019-03-24 03:28:26,182] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1800000, evaluation results [1800000.0, 7157.495565853047, 2831247500.0602026, 210.0, 6811.475347051017, 2600626580.8672895, 61.0, 7489.01721646626, 2565886368.56472, 47.0, 6578.485752361746, 2661621419.375741, 111.0, 7162.768394127867, 2623880762.9585886, 97.0]
[2019-03-24 03:28:26,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1499070e-15 1.6589158e-05 9.9998307e-01 1.3098669e-09 3.3849298e-07], sum to 1.0000
[2019-03-24 03:28:27,008] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3047
[2019-03-24 03:28:27,011] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 76.5, 1.0, 2.0, 0.3613308155341424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5752504260534691, 6.911200000000001, 6.9112, 121.9260426156618, 823643.7034764289, 823643.7034764284, 212471.2931937572], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3877800.0000, 
sim time next is 3878400.0000, 
raw observation next is [28.66666666666667, 79.0, 1.0, 2.0, 0.3676919557760625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5853775684864805, 6.911199999999999, 6.9112, 121.9260426156618, 838151.6768225243, 838151.6768225248, 214344.3645433584], 
processed observation next is [0.0, 0.9130434782608695, 0.6172839506172841, 0.79, 1.0, 1.0, 0.24725232830483632, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4817219606081006, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29933988457947297, 0.29933988457947314, 0.41220070104491996], 
reward next is 0.5878, 
noisyNet noise sample is [array([0.64214575], dtype=float32), 0.28965303]. 
=============================================
[2019-03-24 03:28:32,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8015511e-11 7.8413874e-04 9.9890208e-01 3.4040875e-07 3.1339939e-04], sum to 1.0000
[2019-03-24 03:28:32,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9323
[2019-03-24 03:28:32,513] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.75, 91.83333333333333, 1.0, 2.0, 0.4579453708979668, 0.0, 2.0, 0.0, 1.0, 2.0, 0.729063944709076, 6.911199999999999, 6.9112, 121.9260426156618, 1044023.952269422, 1044023.952269422, 242655.2873580499], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3991800.0000, 
sim time next is 3992400.0000, 
raw observation next is [24.7, 92.0, 1.0, 2.0, 0.4423149943221458, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7041798761545423, 6.911199999999999, 6.9112, 121.9260426156618, 1008366.369741378, 1008366.369741378, 237516.901820726], 
processed observation next is [1.0, 0.21739130434782608, 0.4703703703703703, 0.92, 1.0, 1.0, 0.3360892789549355, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6302248451931777, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36013084633620646, 0.36013084633620646, 0.4567632727321654], 
reward next is 0.5432, 
noisyNet noise sample is [array([0.4242168], dtype=float32), -1.0441506]. 
=============================================
[2019-03-24 03:28:32,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8359047e-18 1.2440796e-04 9.9987495e-01 5.4126915e-11 5.7921153e-07], sum to 1.0000
[2019-03-24 03:28:32,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3391
[2019-03-24 03:28:32,913] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.86666666666667, 94.0, 1.0, 2.0, 0.8769242023161402, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1714743.550811899, 1714743.5508119, 352027.0253473591], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4009200.0000, 
sim time next is 4009800.0000, 
raw observation next is [24.93333333333334, 94.0, 1.0, 2.0, 0.9084311585708654, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1750708.811724968, 1750708.811724969, 358792.5241955228], 
processed observation next is [1.0, 0.391304347826087, 0.47901234567901263, 0.94, 1.0, 1.0, 0.8909894744891255, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6252531470446314, 0.6252531470446318, 0.6899856234529285], 
reward next is 0.3100, 
noisyNet noise sample is [array([-0.8535156], dtype=float32), -0.6119759]. 
=============================================
[2019-03-24 03:28:33,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1986289e-12 9.9235796e-04 9.9884582e-01 5.4146653e-07 1.6123035e-04], sum to 1.0000
[2019-03-24 03:28:33,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5028
[2019-03-24 03:28:33,710] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.38333333333333, 94.00000000000001, 1.0, 2.0, 0.4549642887846534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7243179648976147, 6.911199999999999, 6.9112, 121.9260426156618, 1037223.080737654, 1037223.080737654, 241667.4405245313], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4000200.0000, 
sim time next is 4000800.0000, 
raw observation next is [24.36666666666667, 94.0, 1.0, 2.0, 0.4465500857686817, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7109222796647267, 6.911199999999999, 6.9112, 121.9260426156618, 1018027.721175262, 1018027.721175262, 238899.2461001678], 
processed observation next is [1.0, 0.30434782608695654, 0.4580246913580248, 0.94, 1.0, 1.0, 0.3411310544865258, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6386528495809082, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.363581328991165, 0.363581328991165, 0.45942162711570733], 
reward next is 0.5406, 
noisyNet noise sample is [array([-0.74127394], dtype=float32), 0.51394486]. 
=============================================
[2019-03-24 03:28:35,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3506550e-17 7.0993505e-05 9.9992573e-01 1.1196087e-09 3.2516357e-06], sum to 1.0000
[2019-03-24 03:28:35,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4896
[2019-03-24 03:28:35,526] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.15, 90.0, 1.0, 2.0, 0.3197118151650494, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5089916220296589, 6.9112, 6.9112, 121.9260426156618, 728729.2342632931, 728729.2342632931, 200617.0377976445], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4048200.0000, 
sim time next is 4048800.0000, 
raw observation next is [25.1, 91.33333333333334, 1.0, 2.0, 0.3227906252249091, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5138931879147991, 6.9112, 6.9112, 121.9260426156618, 735750.231082868, 735750.231082868, 201470.1592701281], 
processed observation next is [1.0, 0.8695652173913043, 0.4851851851851852, 0.9133333333333334, 1.0, 1.0, 0.193798363362987, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39236648489349885, 0.0, 0.0, 0.8094621288201359, 0.2627679396724528, 0.2627679396724528, 0.38744261398101554], 
reward next is 0.6126, 
noisyNet noise sample is [array([-0.6813293], dtype=float32), 1.0484928]. 
=============================================
[2019-03-24 03:28:40,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3955641e-18 2.8361887e-06 9.9999714e-01 3.1009032e-12 1.1694627e-08], sum to 1.0000
[2019-03-24 03:28:40,969] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9305
[2019-03-24 03:28:40,971] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.2336189289704446, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3811474667843859, 6.911200000000001, 6.9112, 121.9260426156618, 569168.3402524664, 569168.3402524659, 176347.0896267568], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4159800.0000, 
sim time next is 4160400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.2315808253113692, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3778548588756463, 6.911199999999999, 6.9112, 121.9260426156618, 564260.9055934986, 564260.9055934991, 175854.2696227278], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.08521526822782047, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.22231857359455784, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20152175199767808, 0.20152175199767824, 0.33818128773601497], 
reward next is 0.6618, 
noisyNet noise sample is [array([1.2113237], dtype=float32), -0.049509034]. 
=============================================
[2019-03-24 03:28:43,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8530459e-15 5.3783701e-06 9.9999440e-01 5.8781102e-10 2.4081848e-07], sum to 1.0000
[2019-03-24 03:28:43,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-24 03:28:43,879] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.3, 27.0, 1.0, 2.0, 0.7357730625397271, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9614232098624225, 6.911199999999999, 6.9112, 121.9260426156618, 1597480.452890824, 1597480.452890824, 315422.168752586], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4197600.0000, 
sim time next is 4198200.0000, 
raw observation next is [34.26666666666667, 27.66666666666666, 1.0, 2.0, 0.7393767120503267, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9619301352912436, 6.911199999999999, 6.9112, 121.9260426156618, 1600776.81625145, 1600776.816251451, 316322.8728292946], 
processed observation next is [1.0, 0.6086956521739131, 0.8246913580246916, 0.2766666666666666, 1.0, 1.0, 0.6897341810122937, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9524126691140544, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5717060058040893, 0.5717060058040896, 0.6083132169794127], 
reward next is 0.3917, 
noisyNet noise sample is [array([1.0265312], dtype=float32), 0.5022458]. 
=============================================
[2019-03-24 03:28:51,560] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2954565e-15 7.1112404e-06 9.9999166e-01 4.9670143e-11 1.2483358e-06], sum to 1.0000
[2019-03-24 03:28:51,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1609
[2019-03-24 03:28:51,572] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 89.0, 1.0, 2.0, 0.3219957938006485, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147996262421214, 6.9112, 6.9112, 121.9260426156618, 754401.1072823419, 754401.1072823419, 200736.6442541974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [23.66666666666667, 89.0, 1.0, 2.0, 0.3230958249183882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5161205665447313, 6.911199999999999, 6.9112, 121.9260426156618, 754528.3044038875, 754528.304403888, 201126.0586691232], 
processed observation next is [1.0, 0.2608695652173913, 0.43209876543209896, 0.89, 1.0, 1.0, 0.1941616963314145, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.395150708180914, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2694743944299598, 0.26947439442995996, 0.38678088205600614], 
reward next is 0.6132, 
noisyNet noise sample is [array([0.35950035], dtype=float32), 0.8252423]. 
=============================================
[2019-03-24 03:28:51,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.286892]
 [49.37336 ]
 [49.438843]
 [49.582523]
 [49.731426]], R is [[49.29611969]
 [49.4171257 ]
 [49.53992081]
 [49.65374756]
 [49.79869843]].
[2019-03-24 03:28:53,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7869925e-09 7.9242000e-03 9.8157102e-01 2.6273210e-06 1.0502176e-02], sum to 1.0000
[2019-03-24 03:28:53,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0400
[2019-03-24 03:28:53,612] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2294760.814274424 W.
[2019-03-24 03:28:53,617] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666666, 49.0, 1.0, 2.0, 0.7143485108942876, 1.0, 2.0, 0.6705389174235785, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2294760.814274424, 2294760.814274424, 433118.016133018], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4380600.0000, 
sim time next is 4381200.0000, 
raw observation next is [32.6, 49.0, 1.0, 2.0, 0.716292434060561, 1.0, 2.0, 0.6715108790067151, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2298091.403434017, 2298091.403434017, 433646.8198126544], 
processed observation next is [1.0, 0.7391304347826086, 0.7629629629629631, 0.49, 1.0, 1.0, 0.662252897691144, 1.0, 1.0, 0.6089415226270418, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8207469297978632, 0.8207469297978632, 0.8339361919474123], 
reward next is 0.1661, 
noisyNet noise sample is [array([-0.38852212], dtype=float32), 0.8853062]. 
=============================================
[2019-03-24 03:28:56,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7398359e-18 1.8704635e-05 9.9982125e-01 4.2330176e-12 1.6011645e-04], sum to 1.0000
[2019-03-24 03:28:56,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7837
[2019-03-24 03:28:56,796] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 74.33333333333333, 1.0, 2.0, 0.3131154838751197, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4984900477885787, 6.9112, 6.9112, 121.9260426156618, 713687.0089832434, 713687.0089832434, 198802.0770499757], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4448400.0000, 
sim time next is 4449000.0000, 
raw observation next is [27.3, 74.16666666666667, 1.0, 2.0, 0.3144661192876488, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5006403033524495, 6.9112, 6.9112, 121.9260426156618, 716766.9639965609, 716766.9639965609, 199172.3208069344], 
processed observation next is [0.0, 0.4782608695652174, 0.5666666666666667, 0.7416666666666667, 1.0, 1.0, 0.18388823724720094, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3758003791905618, 0.0, 0.0, 0.8094621288201359, 0.2559882014273432, 0.2559882014273432, 0.38302369385948926], 
reward next is 0.6170, 
noisyNet noise sample is [array([1.8573157], dtype=float32), -0.43416533]. 
=============================================
[2019-03-24 03:28:56,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.46432 ]
 [69.47747 ]
 [69.50002 ]
 [69.51992 ]
 [69.548775]], R is [[69.38480377]
 [69.30864716]
 [69.23394012]
 [69.16081238]
 [69.08938599]].
[2019-03-24 03:28:58,258] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2921912e-13 1.3707469e-04 9.9931228e-01 1.6798160e-09 5.5065664e-04], sum to 1.0000
[2019-03-24 03:28:58,264] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3236
[2019-03-24 03:28:58,268] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 79.0, 1.0, 2.0, 0.3660133491013881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5827051719919959, 6.911199999999999, 6.9112, 121.9260426156618, 834323.2200308705, 834323.220030871, 213848.218847584], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4473000.0000, 
sim time next is 4473600.0000, 
raw observation next is [28.33333333333333, 80.66666666666667, 1.0, 2.0, 0.3716877207619723, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5917389564770295, 6.911199999999999, 6.9112, 121.9260426156618, 847265.034337681, 847265.0343376815, 215528.6169161925], 
processed observation next is [0.0, 0.782608695652174, 0.6049382716049381, 0.8066666666666668, 1.0, 1.0, 0.25200919138330036, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48967369559628676, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30259465512060035, 0.3025946551206005, 0.4144781094542163], 
reward next is 0.5855, 
noisyNet noise sample is [array([0.21007888], dtype=float32), -0.593156]. 
=============================================
[2019-03-24 03:29:04,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2175131e-16 4.0353111e-06 9.9991143e-01 1.1299491e-11 8.4510211e-05], sum to 1.0000
[2019-03-24 03:29:04,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7453
[2019-03-24 03:29:04,537] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.58333333333333, 96.66666666666666, 1.0, 2.0, 0.272524176935247, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4355383567027461, 6.911199999999999, 6.9112, 121.9260426156618, 637540.6649169078, 637540.6649169081, 187578.7891054031], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4576200.0000, 
sim time next is 4576800.0000, 
raw observation next is [22.26666666666667, 97.33333333333333, 1.0, 2.0, 0.2671961050871854, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4275883914629286, 6.9112, 6.9112, 121.9260426156618, 627963.8071123932, 627963.8071123932, 186095.9661312797], 
processed observation next is [0.0, 1.0, 0.38024691358024704, 0.9733333333333333, 1.0, 1.0, 0.12761441081807784, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2844854893286607, 0.0, 0.0, 0.8094621288201359, 0.22427278825442615, 0.22427278825442615, 0.3578768579447687], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.24507141], dtype=float32), -0.4604054]. 
=============================================
[2019-03-24 03:29:11,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7995353e-10 3.6715495e-04 9.9557859e-01 1.3382267e-07 4.0540867e-03], sum to 1.0000
[2019-03-24 03:29:11,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1088
[2019-03-24 03:29:11,713] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.76666666666667, 83.66666666666666, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.014496895078949, 6.9112, 121.9257115121342, 1931029.258785453, 1878132.159581573, 383765.0932806683], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4718400.0000, 
sim time next is 4719000.0000, 
raw observation next is [27.38333333333333, 86.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.773516822783618, 6.9112, 121.9226312281013, 2320111.910395156, 1878540.979253809, 381039.0356836312], 
processed observation next is [1.0, 0.6086956521739131, 0.569753086419753, 0.8633333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0862316822783618, 0.0, 0.8094394807543273, 0.8286113965696986, 0.6709074925906461, 0.7327673763146754], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3299011], dtype=float32), -0.6758387]. 
=============================================
[2019-03-24 03:29:11,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.85941 ]
 [42.10435 ]
 [41.887238]
 [41.427612]
 [41.702015]], R is [[41.72260666]
 [41.30538177]
 [41.22190475]
 [40.80968475]
 [40.40158844]].
[2019-03-24 03:29:16,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1826169e-10 1.7763417e-04 9.6901399e-01 1.5922157e-06 3.0806668e-02], sum to 1.0000
[2019-03-24 03:29:16,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3296
[2019-03-24 03:29:16,168] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.9, 93.5, 1.0, 2.0, 0.6248701954905804, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9948137018225217, 6.911199999999999, 6.9112, 121.9260426156618, 1424933.141106324, 1424933.141106325, 303658.5105252005], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4782600.0000, 
sim time next is 4783200.0000, 
raw observation next is [23.9, 93.66666666666667, 1.0, 2.0, 0.6266416283846016, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9976338806813451, 6.9112, 6.9112, 121.9260426156618, 1428976.426159174, 1428976.426159174, 304366.1554316496], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.9366666666666668, 1.0, 1.0, 0.5555257480769066, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9970423508516812, 0.0, 0.0, 0.8094621288201359, 0.5103487236282764, 0.5103487236282764, 0.5853195296762492], 
reward next is 0.4147, 
noisyNet noise sample is [array([-1.9356358], dtype=float32), -0.7189812]. 
=============================================
[2019-03-24 03:29:16,907] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 03:29:16,909] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:29:16,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:29:16,913] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:29:16,914] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:29:16,915] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:29:16,916] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:29:16,916] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:29:16,915] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:29:16,916] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:29:16,918] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:29:16,942] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-24 03:29:16,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-24 03:29:16,996] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-24 03:29:16,997] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-24 03:29:17,019] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-24 03:29:23,967] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:29:23,968] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 88.0, 1.0, 2.0, 0.1634097058124975, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2917974590442921, 6.9112, 6.9112, 121.9260426156618, 420172.5439037764, 420172.5439037764, 155816.4286511781]
[2019-03-24 03:29:23,970] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:29:23,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2403910e-12 2.9706518e-05 9.9490297e-01 1.3630967e-07 5.0670896e-03], sampled 0.7888817144753766
[2019-03-24 03:29:24,878] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:29:24,878] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 83.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2185923412048937, 6.9112, 6.9112, 121.9260426156618, 312144.9697508212, 312144.9697508212, 137437.6439642386]
[2019-03-24 03:29:24,879] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:29:24,882] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0377259e-12 3.5745328e-05 9.9439186e-01 1.8081985e-07 5.5722105e-03], sampled 0.45417937720457935
[2019-03-24 03:30:03,666] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:03,667] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.18719983, 55.79287568, 1.0, 2.0, 0.4712836770783156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7502989625464968, 6.9112, 6.9112, 121.9260426156618, 1074453.946211645, 1074453.946211645, 247123.852447402]
[2019-03-24 03:30:03,668] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:30:03,670] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6590252e-12 3.3070133e-05 9.9460465e-01 1.6106924e-07 5.3621819e-03], sampled 0.13731698668638315
[2019-03-24 03:30:06,634] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:06,635] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 75.0, 1.0, 2.0, 0.4680557828542863, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7451600498166663, 6.911199999999999, 6.9112, 121.9260426156618, 1067089.721787298, 1067089.721787299, 246044.8655794523]
[2019-03-24 03:30:06,635] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:30:06,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4829033e-13 1.3413857e-05 9.9660289e-01 4.0800774e-08 3.3836525e-03], sampled 0.7521453949602
[2019-03-24 03:30:10,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:10,832] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.93333333333334, 88.66666666666666, 1.0, 2.0, 0.6535047965421128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1459734.718154518, 1459734.718154518, 308986.5954730729]
[2019-03-24 03:30:10,833] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:30:10,836] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.0347933e-12 5.6634217e-05 9.9287307e-01 3.6673572e-07 7.0698829e-03], sampled 0.7727038400050789
[2019-03-24 03:30:12,441] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:12,441] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [36.8271977, 44.23677380000001, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 6.976860936473859, 6.9112, 124.2805417978172, 2361441.804861777, 2327168.222470099, 443417.4987853145]
[2019-03-24 03:30:12,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:30:12,445] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5401273e-11 8.9991823e-05 9.9078947e-01 7.6917280e-07 9.1198664e-03], sampled 0.759346230021753
[2019-03-24 03:30:12,446] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2361441.804861777 W.
[2019-03-24 03:30:15,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:15,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.137269825, 97.92645127666667, 1.0, 2.0, 0.4808516758370932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7655315281784356, 6.9112, 6.9112, 121.9260426156618, 1096283.110244318, 1096283.110244318, 250378.7013009877]
[2019-03-24 03:30:15,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:30:15,481] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.00076379e-13 1.50039805e-05 9.96402383e-01 4.83740479e-08
 3.58257815e-03], sampled 0.6101898498276415
[2019-03-24 03:30:19,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:19,468] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.7, 92.5, 1.0, 2.0, 0.2041539883424779, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3339995389956504, 6.9112, 6.9112, 121.9260426156618, 498997.0069687191, 498997.0069687191, 169288.243151787]
[2019-03-24 03:30:19,468] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:30:19,471] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4622497e-13 1.8433208e-05 9.9600726e-01 6.6007097e-08 3.9742878e-03], sampled 0.04223122845755334
[2019-03-24 03:30:24,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:24,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.6, 66.0, 1.0, 2.0, 0.8150706480102655, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9919305206420631, 6.9112, 6.9112, 121.9260426156618, 1650008.532461637, 1650008.532461637, 338316.127281495]
[2019-03-24 03:30:24,811] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:30:24,813] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.1067934e-11 1.0933272e-04 9.8999947e-01 1.0000635e-06 9.8902313e-03], sampled 0.4424660555968676
[2019-03-24 03:30:32,008] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:32,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.9627973, 85.99856317333334, 1.0, 2.0, 0.2197037910903423, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3572452971192093, 6.911199999999999, 6.9112, 121.9260426156618, 532933.5821119567, 532933.5821119571, 173280.7519225488]
[2019-03-24 03:30:32,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:30:32,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.5653733e-13 2.5853589e-05 9.9524927e-01 1.1050100e-07 4.7247000e-03], sampled 0.729451309431813
[2019-03-24 03:30:33,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:33,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.62129236666667, 87.85794785666667, 1.0, 2.0, 0.2813459163225427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4492808703011632, 6.9112, 6.9112, 121.9260426156618, 656086.4850409405, 656086.4850409405, 189936.1278411361]
[2019-03-24 03:30:33,180] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:30:33,182] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5660526e-13 1.8636103e-05 9.9598420e-01 6.7129072e-08 3.9970390e-03], sampled 0.8972317940502932
[2019-03-24 03:30:37,063] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:37,064] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.41666666666667, 92.5, 1.0, 2.0, 0.2424359990462834, 0.0, 2.0, 0.0, 1.0, 2.0, 0.389455532137844, 6.911199999999999, 6.9112, 121.9260426156618, 575731.3918130584, 575731.3918130589, 179601.1688427925]
[2019-03-24 03:30:37,065] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:30:37,068] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.7885824e-13 1.9063862e-05 9.9593771e-01 6.9478759e-08 4.0432182e-03], sampled 0.16700674743313793
[2019-03-24 03:30:44,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.9083154]
[2019-03-24 03:30:44,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.70566282, 86.47348619, 1.0, 2.0, 0.2569331076964493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4116123960162354, 6.911199999999999, 6.9112, 121.9260426156618, 605843.1390088213, 605843.1390088218, 183411.1969385416]
[2019-03-24 03:30:44,810] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:30:44,813] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8720249e-13 2.2459333e-05 9.9558252e-01 8.9124221e-08 4.3949592e-03], sampled 0.10012004815638664
[2019-03-24 03:30:54,827] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6768.6792 2602085671.0142 61.0000
[2019-03-24 03:30:54,852] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7107.2922 2625309112.1028 95.0000
[2019-03-24 03:30:54,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7447.7826 2567355329.3317 47.0000
[2019-03-24 03:30:54,873] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7095.3657 2833001356.3547 207.0000
[2019-03-24 03:30:54,880] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6540.4642 2662941512.5365 109.0000
[2019-03-24 03:30:55,895] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1825000, evaluation results [1825000.0, 7095.365670084134, 2833001356.354685, 207.0, 6768.679220889065, 2602085671.01422, 61.0, 7447.78259331605, 2567355329.331739, 47.0, 6540.464249812548, 2662941512.5365376, 109.0, 7107.292179216777, 2625309112.1028323, 95.0]
[2019-03-24 03:30:56,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4693122e-11 1.6283148e-04 9.6997738e-01 6.4670789e-06 2.9853337e-02], sum to 1.0000
[2019-03-24 03:30:56,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4706
[2019-03-24 03:30:56,087] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.26666666666667, 88.16666666666667, 1.0, 2.0, 0.5134815792367757, 1.0, 1.0, 0.5134815792367757, 1.0, 2.0, 0.8174793970724944, 6.911199999999999, 6.9112, 121.94756008, 1756740.637812736, 1756740.637812736, 350255.2464782016], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4810200.0000, 
sim time next is 4810800.0000, 
raw observation next is [27.53333333333334, 87.33333333333334, 1.0, 2.0, 0.9934861965780214, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260425168345, 1847806.559247569, 1847806.559247569, 377918.8706772633], 
processed observation next is [1.0, 0.6956521739130435, 0.5753086419753088, 0.8733333333333334, 1.0, 1.0, 0.9922454721166921, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621281640254, 0.6599309140169889, 0.6599309140169889, 0.7267670589947371], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5849353], dtype=float32), -0.24678083]. 
=============================================
[2019-03-24 03:30:57,914] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8583478e-14 3.7285161e-05 9.8805326e-01 1.0398948e-07 1.1909323e-02], sum to 1.0000
[2019-03-24 03:30:57,922] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3634
[2019-03-24 03:30:57,927] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.93333333333333, 71.66666666666666, 1.0, 2.0, 0.315354480880666, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5020546039404501, 6.9112, 6.9112, 121.9260426156618, 718792.7681689922, 718792.7681689922, 199416.6725812275], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5341800.0000, 
sim time next is 5342400.0000, 
raw observation next is [27.9, 72.0, 1.0, 2.0, 0.3140323051672345, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999496571444104, 6.911199999999999, 6.9112, 121.9260426156618, 715777.7038419133, 715777.7038419137, 199053.9911320933], 
processed observation next is [1.0, 0.8695652173913043, 0.5888888888888888, 0.72, 1.0, 1.0, 0.1833717918657554, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37493707143051297, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2556348942292547, 0.2556348942292549, 0.38279613679248714], 
reward next is 0.6172, 
noisyNet noise sample is [array([1.946216], dtype=float32), 1.7033627]. 
=============================================
[2019-03-24 03:31:05,225] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1702612e-11 2.4528596e-05 9.9928904e-01 1.1611166e-07 6.8633078e-04], sum to 1.0000
[2019-03-24 03:31:05,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2611
[2019-03-24 03:31:05,241] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333334, 91.5, 1.0, 2.0, 0.5831132785491496, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9283353301239207, 6.911199999999997, 6.9112, 121.9260426156618, 1329629.407795504, 1329629.407795505, 287347.4914765538], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4975800.0000, 
sim time next is 4976400.0000, 
raw observation next is [25.46666666666667, 88.0, 1.0, 2.0, 0.7164246657170265, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1531548.272600081, 1531548.272600082, 320230.353645804], 
processed observation next is [1.0, 0.6086956521739131, 0.4987654320987655, 0.88, 1.0, 1.0, 0.6624103163297934, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5469815259286004, 0.5469815259286007, 0.6158276031650076], 
reward next is 0.3842, 
noisyNet noise sample is [array([0.9953071], dtype=float32), -1.1595498]. 
=============================================
[2019-03-24 03:31:10,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5757737e-11 8.3892854e-05 9.9553347e-01 7.9144377e-07 4.3817651e-03], sum to 1.0000
[2019-03-24 03:31:10,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2312
[2019-03-24 03:31:10,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2442343.299052583 W.
[2019-03-24 03:31:10,734] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 75.0, 1.0, 2.0, 1.02, 1.0, 1.0, 1.02, 0.0, 1.0, 0.0, 7.135796163534008, 6.9112, 121.9240865028937, 2442343.299052583, 2327331.834354641, 443049.0809161247], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5578200.0000, 
sim time next is 5578800.0000, 
raw observation next is [30.1, 74.66666666666666, 1.0, 2.0, 1.003092549115341, 1.0, 2.0, 1.003092549115341, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257000318973, 2288557.215792681, 2288557.215792682, 434823.4566586755], 
processed observation next is [1.0, 0.5652173913043478, 0.6703703703703704, 0.7466666666666666, 1.0, 1.0, 1.0036816060896918, 1.0, 1.0, 1.0036816060896918, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094598544202017, 0.8173418627831004, 0.8173418627831007, 0.8361989551128375], 
reward next is 0.1638, 
noisyNet noise sample is [array([0.9030229], dtype=float32), -0.074803285]. 
=============================================
[2019-03-24 03:31:14,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6260495e-16 3.7357538e-08 9.9999106e-01 3.2296062e-11 8.9298119e-06], sum to 1.0000
[2019-03-24 03:31:14,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-24 03:31:14,948] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 78.16666666666667, 1.0, 2.0, 0.377499065590283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6009908067059879, 6.911199999999999, 6.9112, 121.9260426156618, 860519.4764961943, 860519.4764961946, 217262.5990008477], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5165400.0000, 
sim time next is 5166000.0000, 
raw observation next is [28.5, 79.0, 1.0, 2.0, 0.375405226884959, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5976573472955463, 6.911199999999999, 6.9112, 121.9260426156618, 855743.8491085632, 855743.8491085636, 216636.0577955987], 
processed observation next is [0.0, 0.8260869565217391, 0.6111111111111112, 0.79, 1.0, 1.0, 0.2564347939106654, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49707168411943287, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3056228032530583, 0.30562280325305846, 0.4166078034530744], 
reward next is 0.5834, 
noisyNet noise sample is [array([0.7585307], dtype=float32), -0.68522793]. 
=============================================
[2019-03-24 03:31:14,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[62.035347]
 [61.99125 ]
 [61.94796 ]
 [61.933342]
 [61.88436 ]], R is [[62.04255295]
 [62.00431442]
 [61.96530533]
 [61.92676163]
 [61.89188766]].
[2019-03-24 03:31:22,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6045308e-10 2.3077325e-04 9.7134393e-01 1.2036169e-06 2.8424077e-02], sum to 1.0000
[2019-03-24 03:31:22,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0047
[2019-03-24 03:31:22,987] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.5175287710169622, 0.0, 2.0, 0.0, 1.0, 2.0, 0.827406726975403, 6.911199999999999, 6.9112, 121.9260426156618, 1212841.122198404, 1212841.122198404, 262486.5423930928], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5305800.0000, 
sim time next is 5306400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.4975774689301969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7952245936980261, 6.911199999999999, 6.9112, 121.9260426156618, 1164506.910737861, 1164506.910737861, 255526.4195002266], 
processed observation next is [1.0, 0.43478260869565216, 0.43703703703703706, 0.85, 1.0, 1.0, 0.4018779392026154, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7440307421225325, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41589532526352174, 0.41589532526352174, 0.4913969605773588], 
reward next is 0.5086, 
noisyNet noise sample is [array([-1.813881], dtype=float32), -1.8414865]. 
=============================================
[2019-03-24 03:31:24,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5849067e-14 8.7704029e-06 9.9816018e-01 2.0772026e-09 1.8309815e-03], sum to 1.0000
[2019-03-24 03:31:24,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9869
[2019-03-24 03:31:24,447] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.23333333333334, 68.66666666666667, 1.0, 2.0, 0.3032678299781029, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4828122620688308, 6.911199999999999, 6.9112, 121.9260426156618, 691231.0408281235, 691231.0408281239, 196126.2349591534], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5336400.0000, 
sim time next is 5337000.0000, 
raw observation next is [28.2, 69.0, 1.0, 2.0, 0.3057606909252237, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4867809778834603, 6.911199999999999, 6.9112, 121.9260426156618, 696915.5413460801, 696915.5413460806, 196800.0377475202], 
processed observation next is [1.0, 0.782608695652174, 0.6, 0.69, 1.0, 1.0, 0.17352463205383772, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35847622235432536, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24889840762360005, 0.24889840762360022, 0.3784616110529235], 
reward next is 0.6215, 
noisyNet noise sample is [array([-0.58065903], dtype=float32), 1.522621]. 
=============================================
[2019-03-24 03:31:24,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.696133]
 [59.681797]
 [59.57673 ]
 [59.70111 ]
 [60.039494]], R is [[59.66349411]
 [59.68969345]
 [59.7164917 ]
 [59.74343109]
 [59.77178955]].
[2019-03-24 03:31:26,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0303243e-12 2.8006400e-06 9.9923074e-01 6.9955526e-09 7.6636102e-04], sum to 1.0000
[2019-03-24 03:31:26,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9111
[2019-03-24 03:31:26,784] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.53333333333333, 91.0, 1.0, 2.0, 0.3752601266524603, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5974263429998237, 6.911199999999999, 6.9112, 121.9260426156618, 855412.90559605, 855412.9055960504, 216586.503272541], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5380800.0000, 
sim time next is 5381400.0000, 
raw observation next is [24.56666666666667, 91.0, 1.0, 2.0, 0.372691545061175, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5933370774536351, 6.9112, 6.9112, 121.9260426156618, 849554.5277904281, 849554.5277904281, 215820.7927571316], 
processed observation next is [1.0, 0.2608695652173913, 0.46543209876543223, 0.91, 1.0, 1.0, 0.25320422031092266, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4916713468170438, 0.0, 0.0, 0.8094621288201359, 0.30341233135372436, 0.30341233135372436, 0.4150399860714069], 
reward next is 0.5850, 
noisyNet noise sample is [array([-0.10401393], dtype=float32), 1.0660541]. 
=============================================
[2019-03-24 03:31:26,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2488068e-13 2.7054298e-06 9.9955541e-01 1.2544568e-09 4.4188881e-04], sum to 1.0000
[2019-03-24 03:31:26,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4973
[2019-03-24 03:31:26,908] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.1, 84.66666666666667, 1.0, 2.0, 0.1799129664303922, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3018011863260257, 6.911199999999999, 6.9112, 121.9260426156618, 449506.6802670975, 449506.680267098, 162411.9379734731], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5881800.0000, 
sim time next is 5882400.0000, 
raw observation next is [20.0, 85.0, 1.0, 2.0, 0.1790454953529435, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3006746388144066, 6.911199999999999, 6.9112, 121.9260426156618, 447672.2012988193, 447672.2012988198, 162162.7810140472], 
processed observation next is [1.0, 0.08695652173913043, 0.2962962962962963, 0.85, 1.0, 1.0, 0.022673208753504173, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1258432985180082, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1598829290352926, 0.15988292903529278, 0.3118515019500908], 
reward next is 0.6881, 
noisyNet noise sample is [array([-0.12459128], dtype=float32), 0.008169467]. 
=============================================
[2019-03-24 03:31:32,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2884459e-11 6.6387693e-06 8.9180507e-03 1.1359414e-06 9.9107414e-01], sum to 1.0000
[2019-03-24 03:31:32,487] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8958
[2019-03-24 03:31:32,490] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.55, 91.33333333333334, 1.0, 2.0, 0.3562947008511147, 1.0, 2.0, 0.3562947008511147, 1.0, 2.0, 0.5672327674632842, 6.9112, 6.9112, 121.94756008, 1218559.618728209, 1218559.618728209, 278466.5097335805], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5472600.0000, 
sim time next is 5473200.0000, 
raw observation next is [27.7, 90.66666666666667, 1.0, 2.0, 0.5092005039831464, 1.0, 2.0, 0.5092005039831464, 1.0, 2.0, 0.8106637858438293, 6.9112, 6.9112, 121.94756008, 1742079.798176423, 1742079.798176423, 348127.7159103935], 
processed observation next is [1.0, 0.34782608695652173, 0.5814814814814815, 0.9066666666666667, 1.0, 1.0, 0.41571488569422194, 1.0, 1.0, 0.41571488569422194, 1.0, 1.0, 0.7633297323047866, 0.0, 0.0, 0.8096049824067558, 0.6221713564915796, 0.6221713564915796, 0.6694763767507568], 
reward next is 0.3305, 
noisyNet noise sample is [array([-0.1062139], dtype=float32), -0.5819638]. 
=============================================
[2019-03-24 03:31:38,474] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0010103e-14 1.3617023e-07 1.2526460e-04 2.9146827e-09 9.9987459e-01], sum to 1.0000
[2019-03-24 03:31:38,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8737
[2019-03-24 03:31:38,489] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 91.0, 1.0, 2.0, 0.2009494570001678, 1.0, 2.0, 0.2009494570001678, 1.0, 2.0, 0.3199180800111887, 6.9112, 6.9112, 121.94756008, 687026.9291535531, 687026.9291535531, 220905.0472796878], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5592000.0000, 
sim time next is 5592600.0000, 
raw observation next is [25.15, 91.0, 1.0, 2.0, 0.2007069705391856, 1.0, 2.0, 0.2007069705391856, 1.0, 2.0, 0.3195320336680722, 6.9112, 6.9112, 121.94756008, 686197.5202081734, 686197.5202081734, 220825.7317163577], 
processed observation next is [1.0, 0.7391304347826086, 0.487037037037037, 0.91, 1.0, 1.0, 0.048460679213316184, 1.0, 1.0, 0.048460679213316184, 1.0, 1.0, 0.14941504208509024, 0.0, 0.0, 0.8096049824067558, 0.2450705429314905, 0.2450705429314905, 0.4246648686853033], 
reward next is 0.5753, 
noisyNet noise sample is [array([0.16690543], dtype=float32), -0.49195012]. 
=============================================
[2019-03-24 03:31:39,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4271253e-14 7.7388250e-07 2.0320460e-03 1.2490831e-09 9.9796718e-01], sum to 1.0000
[2019-03-24 03:31:39,559] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3619
[2019-03-24 03:31:39,564] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 94.0, 1.0, 2.0, 0.2251653114345049, 1.0, 2.0, 0.2251653114345049, 1.0, 2.0, 0.3584705089259733, 6.911200000000001, 6.9112, 121.94756008, 769860.181206173, 769860.1812061726, 228991.6146797505], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5605200.0000, 
sim time next is 5605800.0000, 
raw observation next is [24.98333333333333, 94.33333333333334, 1.0, 2.0, 0.2232122235390618, 1.0, 2.0, 0.2232122235390618, 1.0, 2.0, 0.3553611293887959, 6.9112, 6.9112, 121.94756008, 763179.0765891572, 763179.0765891572, 228327.2435273666], 
processed observation next is [1.0, 0.9130434782608695, 0.4808641975308641, 0.9433333333333335, 1.0, 1.0, 0.07525264707031168, 1.0, 1.0, 0.07525264707031168, 1.0, 1.0, 0.19420141173599484, 0.0, 0.0, 0.8096049824067558, 0.272563955924699, 0.272563955924699, 0.4390908529372435], 
reward next is 0.5609, 
noisyNet noise sample is [array([0.87896514], dtype=float32), -1.9437724]. 
=============================================
[2019-03-24 03:31:39,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5209282e-15 1.6528469e-08 4.4878834e-05 9.4625342e-11 9.9995506e-01], sum to 1.0000
[2019-03-24 03:31:39,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0591
[2019-03-24 03:31:39,794] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.1982317020939327, 1.0, 2.0, 0.1982317020939327, 1.0, 2.0, 0.3155913256893644, 6.9112, 6.9112, 121.94756008, 677731.0790837279, 677731.0790837279, 220017.9725932201], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5628000.0000, 
sim time next is 5628600.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.1981649431944884, 1.0, 2.0, 0.1981649431944884, 1.0, 2.0, 0.3154850433472635, 6.9112, 6.9112, 121.94756008, 677502.7373505216, 677502.7373505216, 219996.2345424152], 
processed observation next is [0.0, 0.13043478260869565, 0.42592592592592593, 0.97, 1.0, 1.0, 0.04543445618391477, 1.0, 1.0, 0.04543445618391477, 1.0, 1.0, 0.14435630418407938, 0.0, 0.0, 0.8096049824067558, 0.241965263339472, 0.241965263339472, 0.4230696818123369], 
reward next is 0.5769, 
noisyNet noise sample is [array([0.40518603], dtype=float32), 1.5984529]. 
=============================================
[2019-03-24 03:31:40,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6559820e-15 1.2729842e-07 6.3094602e-04 1.4741625e-08 9.9936897e-01], sum to 1.0000
[2019-03-24 03:31:40,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7688
[2019-03-24 03:31:40,892] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 84.66666666666667, 1.0, 2.0, 0.2286813298445788, 1.0, 2.0, 0.2286813298445788, 1.0, 2.0, 0.3640681247435363, 6.9112, 6.9112, 121.94756008, 781887.8905172204, 781887.8905172204, 230193.0160493188], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5653200.0000, 
sim time next is 5653800.0000, 
raw observation next is [26.95, 84.0, 1.0, 2.0, 0.2293241563541301, 1.0, 2.0, 0.2293241563541301, 1.0, 2.0, 0.3650915254821399, 6.911200000000001, 6.9112, 121.94756008, 784086.9126022034, 784086.912602203, 230413.4132646991], 
processed observation next is [0.0, 0.43478260869565216, 0.5537037037037037, 0.84, 1.0, 1.0, 0.08252875756444059, 1.0, 1.0, 0.08252875756444059, 1.0, 1.0, 0.20636440685267488, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.28003104021507264, 0.28003104021507247, 0.44310271781672905], 
reward next is 0.5569, 
noisyNet noise sample is [array([0.135411], dtype=float32), 0.2546918]. 
=============================================
[2019-03-24 03:31:41,159] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5687972e-16 1.0474527e-08 6.1998917e-06 2.6815450e-10 9.9999380e-01], sum to 1.0000
[2019-03-24 03:31:41,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3136
[2019-03-24 03:31:41,175] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.1987746427682298, 1.0, 2.0, 0.1987746427682298, 1.0, 2.0, 0.3164557049251887, 6.911199999999999, 6.9112, 121.94756008, 679588.1525859574, 679588.1525859579, 220194.8577588309], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.1983903952176334, 1.0, 2.0, 0.1983903952176334, 1.0, 2.0, 0.3158439703105701, 6.9112, 6.9112, 121.94756008, 678273.8723508046, 678273.8723508046, 220069.6563074412], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.04570285144956358, 1.0, 1.0, 0.04570285144956358, 1.0, 1.0, 0.1448049628882126, 0.0, 0.0, 0.8096049824067558, 0.24224066869671593, 0.24224066869671593, 0.42321087751431], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.6328513], dtype=float32), -0.36255878]. 
=============================================
[2019-03-24 03:31:42,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5838214e-13 2.2515073e-07 8.0916594e-05 1.5919181e-08 9.9991882e-01], sum to 1.0000
[2019-03-24 03:31:42,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0298
[2019-03-24 03:31:42,868] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.2396317701484172, 1.0, 2.0, 0.38150158233819, 6.9112, 6.9112, 121.94756008, 819348.719401112, 819348.719401112, 233978.9952542289], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.2409791137689406, 1.0, 2.0, 0.2409791137689406, 1.0, 2.0, 0.3836465972619816, 6.911199999999999, 6.9112, 121.94756008, 823958.0312067362, 823958.0312067367, 234449.4532205895], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.09640370686778643, 1.0, 1.0, 0.09640370686778643, 1.0, 1.0, 0.22955824657747695, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2942707254309772, 0.2942707254309774, 0.45086433311651825], 
reward next is 0.5491, 
noisyNet noise sample is [array([0.20450673], dtype=float32), -0.7394907]. 
=============================================
[2019-03-24 03:31:42,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[50.2605  ]
 [50.277496]
 [50.28148 ]
 [50.29052 ]
 [50.274223]], R is [[50.29808426]
 [50.34514618]
 [50.39413452]
 [50.44228745]
 [50.48797226]].
[2019-03-24 03:31:44,134] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9579818e-13 5.5902979e-07 5.6754227e-04 3.5868366e-09 9.9943191e-01], sum to 1.0000
[2019-03-24 03:31:44,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9821
[2019-03-24 03:31:44,143] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.3, 97.0, 1.0, 2.0, 0.1624347420993975, 1.0, 2.0, 0.1624347420993975, 1.0, 2.0, 0.260968806975009, 6.9112, 6.9112, 121.94756008, 578772.4657289751, 578772.4657289751, 208335.7585843765], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5716800.0000, 
sim time next is 5717400.0000, 
raw observation next is [21.25, 96.83333333333334, 1.0, 2.0, 0.16117348358145, 1.0, 2.0, 0.16117348358145, 1.0, 2.0, 0.2590935894547274, 6.9112, 6.9112, 121.94756008, 575041.6296299074, 575041.6296299074, 207919.9498158652], 
processed observation next is [0.0, 0.17391304347826086, 0.3425925925925926, 0.9683333333333334, 1.0, 1.0, 0.001397004263630955, 1.0, 1.0, 0.001397004263630955, 1.0, 1.0, 0.07386698681840921, 0.0, 0.0, 0.8096049824067558, 0.2053720105821098, 0.2053720105821098, 0.39984605733820233], 
reward next is 0.6002, 
noisyNet noise sample is [array([-0.49421453], dtype=float32), -1.9422493]. 
=============================================
[2019-03-24 03:31:46,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7645409e-06 8.3898511e-03 5.8712583e-02 9.1813738e-04 9.3197769e-01], sum to 1.0000
[2019-03-24 03:31:46,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5982
[2019-03-24 03:31:46,018] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.93333333333334, 85.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2355679194001225, 6.911200000000001, 6.9112, 121.94756008, 526443.2424140655, 526443.242414065, 200115.7694463487], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5732400.0000, 
sim time next is 5733000.0000, 
raw observation next is [22.15, 84.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2369210369695797, 6.911199999999999, 6.9112, 121.94756008, 529207.800971505, 529207.8009715055, 200625.2821347835], 
processed observation next is [0.0, 0.34782608695652173, 0.3759259259259259, 0.84, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.046151296211974606, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.1890027860612518, 0.18900278606125195, 0.38581785025919907], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7260212], dtype=float32), -0.7405328]. 
=============================================
[2019-03-24 03:31:46,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[22.568964]
 [22.53933 ]
 [22.50722 ]
 [22.447214]
 [22.419903]], R is [[22.36832047]
 [22.14463806]
 [21.92319107]
 [21.70395851]
 [21.4869194 ]].
[2019-03-24 03:31:46,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3439499e-07 1.9821515e-03 1.7113732e-02 8.9142013e-05 9.8081481e-01], sum to 1.0000
[2019-03-24 03:31:46,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7942
[2019-03-24 03:31:46,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 59.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2287771338332999, 6.9112, 6.9112, 121.94756008, 511846.3501746483, 511846.3501746483, 197819.1091078548], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5859000.0000, 
sim time next is 5859600.0000, 
raw observation next is [25.53333333333333, 60.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2311744394599758, 6.9112, 6.9112, 121.94756008, 517028.790043616, 517028.790043616, 198624.6534863046], 
processed observation next is [1.0, 0.8260869565217391, 0.5012345679012346, 0.6033333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.03896804932496972, 0.0, 0.0, 0.8096049824067558, 0.18465313930129143, 0.18465313930129143, 0.3819704874736627], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4117666], dtype=float32), 0.7787281]. 
=============================================
[2019-03-24 03:31:46,507] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 03:31:46,509] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:31:46,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:31:46,510] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:31:46,512] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:31:46,513] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:31:46,514] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:31:46,515] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:31:46,515] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:31:46,518] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:31:46,523] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:31:46,540] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-24 03:31:46,565] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-24 03:31:46,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-24 03:31:46,624] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-24 03:31:46,650] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-24 03:32:06,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.909001]
[2019-03-24 03:32:06,648] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.35, 32.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2205484693945052, 6.9112, 6.9112, 121.94756008, 493082.4826330137, 493082.4826330137, 195622.9114058702]
[2019-03-24 03:32:06,649] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:32:06,651] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9524404e-07 2.4667832e-03 2.7378574e-02 1.2306980e-04 9.7003132e-01], sampled 0.44108861923393183
[2019-03-24 03:33:22,068] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00645888], dtype=float32), 0.909001]
[2019-03-24 03:33:22,070] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.2, 48.83333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2139485896216184, 6.911199999999999, 6.9112, 121.94756008, 477971.6262194397, 477971.6262194401, 189912.1207530989]
[2019-03-24 03:33:22,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:33:22,074] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8640982e-06 5.8496469e-03 4.5895975e-02 4.3751096e-04 9.4781500e-01], sampled 0.3677707722946798
[2019-03-24 03:33:23,831] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4449.0137 3095091235.1895 11.0000
[2019-03-24 03:33:23,870] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4354.9053 2861444367.4200 14.0000
[2019-03-24 03:33:24,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4433.4075 2927806028.8730 32.0000
[2019-03-24 03:33:24,248] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4266.0556 2907083043.6693 36.0000
[2019-03-24 03:33:24,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4567.9605 2882670138.5452 17.0000
[2019-03-24 03:33:25,321] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1850000, evaluation results [1850000.0, 4449.0136966368445, 3095091235.1895494, 11.0, 4567.960461897523, 2882670138.545216, 17.0, 4354.905298735997, 2861444367.420005, 14.0, 4433.4074819379075, 2927806028.8730016, 32.0, 4266.0555644621245, 2907083043.669312, 36.0]
[2019-03-24 03:33:33,027] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.423710e-18 2.705924e-11 1.000000e+00 4.167009e-11 5.107155e-10], sum to 1.0000
[2019-03-24 03:33:33,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5695
[2019-03-24 03:33:33,040] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.18333333333333, 82.16666666666667, 1.0, 2.0, 0.195135600635024, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3229771256478952, 6.9112, 6.9112, 121.9260426156618, 482511.3769824877, 482511.3769824877, 166537.7435204162], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5875800.0000, 
sim time next is 5876400.0000, 
raw observation next is [21.06666666666667, 82.33333333333334, 1.0, 2.0, 0.1932550028511693, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3203474607130664, 6.911199999999999, 6.9112, 121.9260426156618, 478482.7583151659, 478482.7583151663, 166029.451634377], 
processed observation next is [1.0, 0.0, 0.3358024691358026, 0.8233333333333335, 1.0, 1.0, 0.03958928910853489, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.150434325891333, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17088669939827353, 0.17088669939827367, 0.31928740698918656], 
reward next is 0.6807, 
noisyNet noise sample is [array([0.9437807], dtype=float32), 1.0275403]. 
=============================================
[2019-03-24 03:33:33,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3264784e-12 4.6437037e-07 9.9962056e-01 6.1045718e-08 3.7897521e-04], sum to 1.0000
[2019-03-24 03:33:33,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-24 03:33:33,709] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.73333333333333, 56.33333333333334, 1.0, 2.0, 0.2520615170836698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4030817551521183, 6.911199999999999, 6.9112, 121.9260426156618, 590965.9627999014, 590965.9627999018, 182352.1391164865], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6024000.0000, 
sim time next is 6024600.0000, 
raw observation next is [28.6, 57.0, 1.0, 2.0, 0.2486347547473487, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3977779818809628, 6.911199999999999, 6.9112, 121.9260426156618, 583809.7945690874, 583809.7945690879, 181463.8100332907], 
processed observation next is [1.0, 0.7391304347826086, 0.6148148148148148, 0.57, 1.0, 1.0, 0.10551756517541512, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24722247735120348, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20850349806038837, 0.20850349806038854, 0.348968865448636], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.8652548], dtype=float32), 1.4997525]. 
=============================================
[2019-03-24 03:33:33,764] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9379740e-10 1.2697095e-05 9.9695396e-01 2.1736653e-06 3.0311283e-03], sum to 1.0000
[2019-03-24 03:33:33,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7425
[2019-03-24 03:33:33,784] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.6, 60.33333333333334, 1.0, 2.0, 0.4372759977106159, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7098133197296197, 6.911200000000001, 6.9112, 121.9260426156618, 1058525.100032181, 1058525.10003218, 233820.9060971636], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5912400.0000, 
sim time next is 5913000.0000, 
raw observation next is [25.85, 59.5, 1.0, 2.0, 0.4432240832598929, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7188471950886985, 6.911199999999999, 6.9112, 121.9260426156618, 1071575.147960777, 1071575.147960777, 235815.3485412946], 
processed observation next is [1.0, 0.43478260869565216, 0.5129629629629631, 0.595, 1.0, 1.0, 0.3371715276903487, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6485589938608732, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3827054099859918, 0.3827054099859918, 0.453491054887105], 
reward next is 0.5465, 
noisyNet noise sample is [array([0.02614751], dtype=float32), -0.49710843]. 
=============================================
[2019-03-24 03:33:33,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[39.95177 ]
 [40.288998]
 [40.923325]
 [41.591965]
 [42.603424]], R is [[39.91691589]
 [40.06808853]
 [40.20928574]
 [40.317379  ]
 [40.42937851]].
[2019-03-24 03:33:37,755] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7112439e-19 3.3913788e-12 9.9999976e-01 2.9668078e-14 2.6727517e-07], sum to 1.0000
[2019-03-24 03:33:37,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-24 03:33:37,770] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.51666666666667, 78.5, 1.0, 2.0, 0.2131709764546414, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3485855398359111, 6.911199999999999, 6.9112, 121.9260426156618, 520758.8166230705, 520758.8166230709, 171385.6535759172], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5968200.0000, 
sim time next is 5968800.0000, 
raw observation next is [22.5, 78.0, 1.0, 2.0, 0.2119898738662793, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3470457738809909, 6.911199999999999, 6.9112, 121.9260426156618, 518539.7767607158, 518539.7767607163, 171039.862603414], 
processed observation next is [1.0, 0.08695652173913043, 0.3888888888888889, 0.78, 1.0, 1.0, 0.06189270698366582, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1838072173512386, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18519277741454138, 0.18519277741454154, 0.3289228126988731], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.7855922], dtype=float32), -0.70225745]. 
=============================================
[2019-03-24 03:33:46,545] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4253272e-24 2.3391681e-13 1.0000000e+00 1.0494467e-16 6.3761954e-11], sum to 1.0000
[2019-03-24 03:33:46,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-24 03:33:46,560] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.6, 90.5, 1.0, 2.0, 0.3137725694777285, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5036900141082773, 6.9112, 6.9112, 121.9260426156618, 743936.9152875397, 743936.9152875397, 198104.3388446548], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6150600.0000, 
sim time next is 6151200.0000, 
raw observation next is [22.53333333333333, 90.66666666666667, 1.0, 2.0, 0.3001975736856096, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4821238611288048, 6.9112, 6.9112, 121.9260426156618, 712542.3609507101, 712542.3609507101, 194397.223936268], 
processed observation next is [1.0, 0.17391304347826086, 0.3901234567901234, 0.9066666666666667, 1.0, 1.0, 0.16690187343524954, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35265482641100593, 0.0, 0.0, 0.8094621288201359, 0.25447941462525364, 0.25447941462525364, 0.37384081526205387], 
reward next is 0.6262, 
noisyNet noise sample is [array([-2.2237804], dtype=float32), 0.7006367]. 
=============================================
[2019-03-24 03:33:50,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2291748e-14 6.5073706e-05 4.5351654e-02 2.4302491e-09 9.5458329e-01], sum to 1.0000
[2019-03-24 03:33:51,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1404
[2019-03-24 03:33:51,016] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.35, 27.5, 1.0, 2.0, 0.3530948969938024, 1.0, 2.0, 0.3530948969938024, 1.0, 2.0, 0.5808191642275025, 6.9112, 6.9112, 121.94756008, 1302785.975362401, 1302785.975362401, 275543.2037031471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6712200.0000, 
sim time next is 6712800.0000, 
raw observation next is [30.4, 27.33333333333334, 1.0, 2.0, 0.3521347626904158, 1.0, 2.0, 0.3521347626904158, 1.0, 2.0, 0.5790680441931895, 6.9112, 6.9112, 121.94756008, 1298853.401733533, 1298853.401733533, 275164.7794707714], 
processed observation next is [1.0, 0.6956521739130435, 0.6814814814814815, 0.2733333333333334, 1.0, 1.0, 0.22873186034573312, 1.0, 1.0, 0.22873186034573312, 1.0, 1.0, 0.4738350552414868, 0.0, 0.0, 0.8096049824067558, 0.4638762149048332, 0.4638762149048332, 0.5291630374437911], 
reward next is 0.4708, 
noisyNet noise sample is [array([1.0922638], dtype=float32), -0.7981262]. 
=============================================
[2019-03-24 03:34:00,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8328783e-12 1.7403015e-06 9.9953997e-01 2.2524759e-08 4.5832436e-04], sum to 1.0000
[2019-03-24 03:34:00,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2909
[2019-03-24 03:34:00,549] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 82.5, 1.0, 2.0, 0.3412794838703627, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5433280530184497, 6.911199999999999, 6.9112, 121.9260426156618, 777914.0476021738, 777914.0476021742, 206672.0721166024], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6395400.0000, 
sim time next is 6396000.0000, 
raw observation next is [26.53333333333333, 83.0, 1.0, 2.0, 0.3396440124618191, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5407243292724631, 6.911199999999999, 6.9112, 121.9260426156618, 774184.2638142337, 774184.2638142342, 206206.3605962019], 
processed observation next is [1.0, 0.0, 0.5382716049382715, 0.83, 1.0, 1.0, 0.21386191959740367, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42590541159057876, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2764943799336549, 0.27649437993365505, 0.39655069345423444], 
reward next is 0.6034, 
noisyNet noise sample is [array([-0.19999115], dtype=float32), 0.4655807]. 
=============================================
[2019-03-24 03:34:00,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[47.351326]
 [48.146057]
 [49.735703]
 [52.005836]
 [54.852966]], R is [[46.94487   ]
 [47.07797623]
 [47.20985413]
 [47.34224701]
 [47.46931076]].
[2019-03-24 03:34:02,905] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8231412e-11 5.9185717e-05 9.8722166e-01 1.8625039e-08 1.2719189e-02], sum to 1.0000
[2019-03-24 03:34:02,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7123
[2019-03-24 03:34:02,920] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.13333333333333, 87.66666666666666, 1.0, 2.0, 0.9347733009559921, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1780779.537549894, 1780779.537549894, 364581.7380116894], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6424800.0000, 
sim time next is 6425400.0000, 
raw observation next is [26.36666666666667, 86.83333333333333, 1.0, 2.0, 0.9601142668173538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1809708.331261264, 1809708.331261265, 370263.627669021], 
processed observation next is [1.0, 0.34782608695652173, 0.5320987654320989, 0.8683333333333333, 1.0, 1.0, 0.9525169843063735, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.64632440402188, 0.6463244040218804, 0.7120454378250404], 
reward next is 0.2880, 
noisyNet noise sample is [array([0.5961699], dtype=float32), -1.0323181]. 
=============================================
[2019-03-24 03:34:06,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0846441e-10 6.5136957e-04 9.5726740e-01 1.0164612e-07 4.2081099e-02], sum to 1.0000
[2019-03-24 03:34:06,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-24 03:34:06,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2027494.30404418 W.
[2019-03-24 03:34:06,682] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.36666666666667, 84.0, 1.0, 2.0, 0.8887964035092355, 1.0, 2.0, 0.8887964035092355, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156296, 2027494.30404418, 2027494.304044179, 381813.1446160121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6513600.0000, 
sim time next is 6514200.0000, 
raw observation next is [27.5, 83.5, 1.0, 2.0, 0.9113608923674921, 1.0, 2.0, 0.9113608923674921, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2079027.624227066, 2079027.624227066, 391919.7316415262], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.835, 1.0, 1.0, 0.8944772528184429, 1.0, 1.0, 0.8944772528184429, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7425098657953807, 0.7425098657953807, 0.7536917916183197], 
reward next is 0.2463, 
noisyNet noise sample is [array([-0.7840004], dtype=float32), -0.13012137]. 
=============================================
[2019-03-24 03:34:13,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9822355e-18 6.4532017e-08 9.9949312e-01 3.9553538e-13 5.0674478e-04], sum to 1.0000
[2019-03-24 03:34:13,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0639
[2019-03-24 03:34:13,676] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 37.0, 1.0, 2.0, 0.5244556807681255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8638844211203007, 6.911200000000001, 6.9112, 121.9260426156618, 1291767.886821109, 1291767.886821109, 262033.6091776391], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6623400.0000, 
sim time next is 6624000.0000, 
raw observation next is [29.0, 37.0, 1.0, 2.0, 0.5512817743840392, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9076962715496151, 6.9112, 6.9112, 121.9260426156618, 1357352.304197225, 1357352.304197225, 271738.7787717979], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.37, 1.0, 1.0, 0.46581163617147525, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8846203394370189, 0.0, 0.0, 0.8094621288201359, 0.4847686800704375, 0.4847686800704375, 0.5225745745611498], 
reward next is 0.4774, 
noisyNet noise sample is [array([0.33843812], dtype=float32), -0.3645361]. 
=============================================
[2019-03-24 03:34:13,690] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.427597]
 [62.301258]
 [62.179314]
 [62.033813]
 [61.882046]], R is [[62.43394089]
 [62.30569077]
 [62.17761612]
 [62.04754257]
 [61.91530991]].
[2019-03-24 03:34:15,284] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6706885e-07 8.4594343e-05 9.9757534e-01 4.2316819e-06 2.3356925e-03], sum to 1.0000
[2019-03-24 03:34:15,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6789
[2019-03-24 03:34:15,297] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 49.5, 1.0, 2.0, 0.1716660014579993, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3032520685029332, 6.911199999999999, 6.9112, 121.9260426156618, 439851.6006547661, 439851.6006547666, 158036.048383923], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6678600.0000, 
sim time next is 6679200.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2718057612503559, 6.9112, 6.9112, 121.9260426156618, 394748.5963924241, 394748.5963924241, 153971.5815632521], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.08975720156294484, 0.0, 0.0, 0.8094621288201359, 0.1409816415687229, 0.1409816415687229, 0.29609919531394635], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4828134], dtype=float32), 0.48142308]. 
=============================================
[2019-03-24 03:34:16,058] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:34:16,059] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:34:16,060] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:34:16,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:34:16,060] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:34:16,062] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:34:16,063] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:34:16,064] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:34:16,064] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:34:16,066] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:34:16,067] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:34:16,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-24 03:34:16,112] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-24 03:34:16,113] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-24 03:34:16,161] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-24 03:34:16,162] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-24 03:35:52,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.92152095]
[2019-03-24 03:35:52,728] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.03548601, 45.15987117, 1.0, 2.0, 0.3427348709208203, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613742982316815, 6.911199999999999, 6.9112, 121.9260426156618, 839004.7180063397, 839004.7180063402, 204547.1313759863]
[2019-03-24 03:35:52,729] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:35:52,731] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.8909457e-10 6.2279607e-04 7.7358180e-01 6.1450471e-08 2.2579534e-01], sampled 0.9627911316506376
[2019-03-24 03:35:53,688] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5358.3593 2707264911.9273 95.0000
[2019-03-24 03:35:53,759] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6030.9955 2616065023.7465 36.0000
[2019-03-24 03:35:53,946] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 5842.8723 2670069631.6031 84.0000
[2019-03-24 03:35:53,985] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 5541.0323 2649049399.2620 56.0000
[2019-03-24 03:35:54,063] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5831.3376 2875800045.4101 174.0000
[2019-03-24 03:35:55,081] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1875000, evaluation results [1875000.0, 5831.337600118171, 2875800045.4101114, 174.0, 5541.0323403499815, 2649049399.2620473, 56.0, 6030.995544305766, 2616065023.746533, 36.0, 5358.35930544255, 2707264911.92731, 95.0, 5842.872282821933, 2670069631.6031103, 84.0]
[2019-03-24 03:35:55,883] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7197289e-09 1.6490645e-03 7.7784091e-01 3.4944168e-07 2.2050975e-01], sum to 1.0000
[2019-03-24 03:35:55,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6081
[2019-03-24 03:35:55,895] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 86.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2047927573208781, 6.9112, 6.9112, 121.94756008, 458999.1932516833, 458999.1932516833, 189004.4542225679], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7196400.0000, 
sim time next is 7197000.0000, 
raw observation next is [20.58333333333334, 85.66666666666667, 1.0, 2.0, 0.1874063644326621, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3108317219250643, 6.911199999999999, 6.9112, 121.9260426156618, 464224.0508864225, 464224.0508864229, 164702.0200849292], 
processed observation next is [1.0, 0.30434782608695654, 0.3179012345679015, 0.8566666666666667, 1.0, 1.0, 0.032626624324597724, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.13853965240633037, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16579430388800803, 0.1657943038880082, 0.3167346540094792], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6970103], dtype=float32), 0.57486606]. 
=============================================
[2019-03-24 03:35:55,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[34.2323  ]
 [33.737057]
 [33.35732 ]
 [33.76564 ]
 [33.597607]], R is [[33.61727142]
 [33.28109741]
 [33.63178635]
 [33.97978592]
 [34.32515717]].
[2019-03-24 03:35:56,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2049427e-21 5.4388147e-07 9.9728513e-01 3.5447561e-16 2.7142428e-03], sum to 1.0000
[2019-03-24 03:35:56,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1883
[2019-03-24 03:35:56,842] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.65, 31.5, 1.0, 2.0, 0.3182521670819209, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5411435300667532, 6.911199999999999, 6.9112, 121.9260426156618, 802027.8019502293, 802027.8019502298, 195265.5358111594], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6699000.0000, 
sim time next is 6699600.0000, 
raw observation next is [28.8, 31.0, 1.0, 2.0, 0.3246350308554757, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5517163411306133, 6.911199999999999, 6.9112, 121.9260426156618, 817888.5092123821, 817888.5092123826, 197030.5915382063], 
processed observation next is [1.0, 0.5652173913043478, 0.6222222222222222, 0.31, 1.0, 1.0, 0.19599408435175678, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4396454264132666, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2921030390044222, 0.29210303900442236, 0.3789049837273198], 
reward next is 0.6211, 
noisyNet noise sample is [array([-0.09896094], dtype=float32), -0.47194457]. 
=============================================
[2019-03-24 03:35:57,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3389486e-19 1.8493982e-07 9.9940646e-01 4.0657425e-16 5.9335848e-04], sum to 1.0000
[2019-03-24 03:35:57,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2651
[2019-03-24 03:35:57,446] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.2, 28.0, 1.0, 2.0, 0.4884153026651787, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8181867669280749, 6.911199999999999, 6.9112, 121.9260426156618, 1219739.739435388, 1219739.739435389, 248162.9689183615], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6710400.0000, 
sim time next is 6711000.0000, 
raw observation next is [30.25, 27.83333333333334, 1.0, 2.0, 0.501925206288738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.840754936943168, 6.911199999999999, 6.9112, 121.9260426156618, 1253439.580944587, 1253439.580944587, 252791.1156706645], 
processed observation next is [1.0, 0.6956521739130435, 0.6759259259259259, 0.2783333333333334, 1.0, 1.0, 0.40705381701040244, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8009436711789599, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44765699319449537, 0.44765699319449537, 0.48613676090512403], 
reward next is 0.5139, 
noisyNet noise sample is [array([2.2794373], dtype=float32), -1.0386058]. 
=============================================
[2019-03-24 03:35:57,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.3522  ]
 [72.8313  ]
 [72.276184]
 [71.73485 ]
 [71.1703  ]], R is [[73.38237762]
 [73.17131805]
 [72.95007324]
 [72.73291779]
 [72.52313232]].
[2019-03-24 03:36:01,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1028856e-15 3.4162053e-06 9.9948967e-01 3.6197258e-12 5.0685322e-04], sum to 1.0000
[2019-03-24 03:36:01,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0070
[2019-03-24 03:36:01,267] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.61666666666667, 81.16666666666667, 1.0, 2.0, 0.3759897005410217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6094911719036938, 6.9112, 6.9112, 121.9260426156618, 908230.2889891171, 908230.2889891171, 214997.8217883939], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7294200.0000, 
sim time next is 7294800.0000, 
raw observation next is [22.73333333333333, 80.33333333333334, 1.0, 2.0, 0.3766219205166002, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6104874864245977, 6.9112, 6.9112, 121.9260426156618, 909693.8367945339, 909693.8367945339, 215189.4579502681], 
processed observation next is [1.0, 0.43478260869565216, 0.39753086419753075, 0.8033333333333335, 1.0, 1.0, 0.2578832387102383, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5131093580307471, 0.0, 0.0, 0.8094621288201359, 0.32489065599804784, 0.32489065599804784, 0.4138258806735925], 
reward next is 0.5862, 
noisyNet noise sample is [array([0.94462895], dtype=float32), 0.6004041]. 
=============================================
[2019-03-24 03:36:04,910] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8665714e-18 6.2544906e-08 9.9997556e-01 6.2732738e-15 2.4262192e-05], sum to 1.0000
[2019-03-24 03:36:04,915] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4148
[2019-03-24 03:36:04,919] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.83333333333334, 48.16666666666666, 1.0, 2.0, 0.2663302883809254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4255260168970074, 6.911199999999999, 6.9112, 121.9260426156618, 622401.9285225354, 622401.9285225358, 186020.8206272288], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [31.0, 48.0, 1.0, 2.0, 0.269232367169279, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4299370005298844, 6.911199999999999, 6.9112, 121.9260426156618, 627828.1449778436, 627828.1449778441, 186810.9996949919], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.48, 1.0, 1.0, 0.13003853234437976, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2874212506623555, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.224224337492087, 0.22422433749208717, 0.359251922490369], 
reward next is 0.6407, 
noisyNet noise sample is [array([1.9958522], dtype=float32), -0.98952883]. 
=============================================
[2019-03-24 03:36:04,950] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.53124 ]
 [66.5248  ]
 [66.524574]
 [66.52938 ]
 [66.54087 ]], R is [[66.51322174]
 [66.49035645]
 [66.4691925 ]
 [66.44959259]
 [66.43145752]].
[2019-03-24 03:36:08,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1791741e-18 5.9121004e-07 9.9997377e-01 3.7761205e-16 2.5660393e-05], sum to 1.0000
[2019-03-24 03:36:08,678] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8084
[2019-03-24 03:36:08,681] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.21666666666667, 86.66666666666667, 1.0, 2.0, 0.2080071436812425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3413354892061745, 6.9112, 6.9112, 121.9260426156618, 510114.426958031, 510114.426958031, 169973.4896411168], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6930600.0000, 
sim time next is 6931200.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.2094643992545552, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3433798205121952, 6.911199999999999, 6.9112, 121.9260426156618, 513133.3807447142, 513133.3807447147, 170371.5741913796], 
processed observation next is [0.0, 0.21739130434782608, 0.3456790123456792, 0.8633333333333334, 1.0, 1.0, 0.058886189588756195, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.17922477564024394, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18326192169454078, 0.18326192169454097, 0.32763764267573], 
reward next is 0.6724, 
noisyNet noise sample is [array([2.2491634], dtype=float32), 0.21987882]. 
=============================================
[2019-03-24 03:36:11,795] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4045456e-19 8.7412273e-09 9.9999678e-01 6.5222373e-16 3.2742130e-06], sum to 1.0000
[2019-03-24 03:36:11,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6610
[2019-03-24 03:36:11,813] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.13333333333333, 46.66666666666667, 1.0, 2.0, 0.2501761573691433, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4018904054588364, 6.911199999999999, 6.9112, 121.9260426156618, 594122.7097011866, 594122.7097011871, 181503.3061049902], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6975600.0000, 
sim time next is 6976200.0000, 
raw observation next is [29.86666666666667, 47.33333333333333, 1.0, 2.0, 0.2480189384356277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3987145469477972, 6.911199999999999, 6.9112, 121.9260426156618, 589977.1692501822, 589977.1692501827, 180913.08859126], 
processed observation next is [0.0, 0.7391304347826086, 0.6617283950617285, 0.4733333333333333, 1.0, 1.0, 0.1047844505186044, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.24839318368474644, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21070613187506507, 0.21070613187506523, 0.34790978575242304], 
reward next is 0.6521, 
noisyNet noise sample is [array([1.1889387], dtype=float32), 0.7676907]. 
=============================================
[2019-03-24 03:36:17,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2146042e-17 4.3197858e-07 9.9992013e-01 9.6920119e-14 7.9338468e-05], sum to 1.0000
[2019-03-24 03:36:17,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3032
[2019-03-24 03:36:17,777] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.83333333333334, 84.33333333333334, 1.0, 2.0, 0.202861774899758, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3361015299285094, 6.9112, 6.9112, 121.9260426156618, 502058.3452419374, 502058.3452419374, 168211.5178216931], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7108800.0000, 
sim time next is 7109400.0000, 
raw observation next is [20.81666666666667, 84.16666666666666, 1.0, 2.0, 0.2009939643467269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3332376932812459, 6.9112, 6.9112, 121.9260426156618, 497728.3717399008, 497728.3717399008, 167748.7468053312], 
processed observation next is [1.0, 0.2608695652173913, 0.32654320987654334, 0.8416666666666666, 1.0, 1.0, 0.048802338508008206, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.16654711660155738, 0.0, 0.0, 0.8094621288201359, 0.1777601327642503, 0.1777601327642503, 0.32259374385640616], 
reward next is 0.6774, 
noisyNet noise sample is [array([-1.9988996], dtype=float32), 1.4584801]. 
=============================================
[2019-03-24 03:36:18,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4168732e-16 1.2223303e-06 9.9999559e-01 2.6410284e-14 3.2000066e-06], sum to 1.0000
[2019-03-24 03:36:18,943] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8186
[2019-03-24 03:36:18,945] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.93333333333333, 85.33333333333334, 1.0, 2.0, 0.2010722859068108, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3319954170158039, 6.9112, 6.9112, 121.9260426156618, 496111.1239663675, 496111.1239663675, 168015.441291981], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7105200.0000, 
sim time next is 7105800.0000, 
raw observation next is [20.91666666666667, 85.16666666666667, 1.0, 2.0, 0.1983600962226705, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3277557866525241, 6.9112, 6.9112, 121.9260426156618, 489743.1032359574, 489743.1032359574, 167361.2745842596], 
processed observation next is [1.0, 0.21739130434782608, 0.3302469135802471, 0.8516666666666667, 1.0, 1.0, 0.04566678121746489, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1596947333156551, 0.0, 0.0, 0.8094621288201359, 0.17490825115569908, 0.17490825115569908, 0.32184860496973], 
reward next is 0.6782, 
noisyNet noise sample is [array([-1.2895279], dtype=float32), 1.53776]. 
=============================================
[2019-03-24 03:36:21,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7633975e-20 1.1738223e-09 9.9999917e-01 8.1214346e-18 8.6181296e-07], sum to 1.0000
[2019-03-24 03:36:21,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1953
[2019-03-24 03:36:21,818] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.15, 68.5, 1.0, 2.0, 0.1932561237745932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3198043431532783, 6.911199999999999, 6.9112, 121.9260426156618, 477781.2269214432, 477781.2269214437, 166131.054951891], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7667400.0000, 
sim time next is 7668000.0000, 
raw observation next is [22.9, 69.0, 1.0, 2.0, 0.1924266490759333, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3192487400916513, 6.911199999999999, 6.9112, 121.9260426156618, 476776.890036784, 476776.8900367845, 165794.78001239], 
processed observation next is [1.0, 0.782608695652174, 0.4037037037037037, 0.69, 1.0, 1.0, 0.038603153661825346, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14906092511456406, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17027746072742286, 0.17027746072742303, 0.3188361154084423], 
reward next is 0.6812, 
noisyNet noise sample is [array([1.07768], dtype=float32), 0.32573748]. 
=============================================
[2019-03-24 03:36:21,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.41553 ]
 [71.622986]
 [71.764404]
 [71.903656]
 [71.99649 ]], R is [[71.33296204]
 [71.30015564]
 [71.26685333]
 [71.23296356]
 [71.19681549]].
[2019-03-24 03:36:32,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8494883e-20 1.4951813e-09 9.9999988e-01 6.3559222e-17 7.6507888e-08], sum to 1.0000
[2019-03-24 03:36:32,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-24 03:36:32,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.3, 96.0, 1.0, 2.0, 0.191469352419662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3180856840796537, 6.911199999999999, 6.9112, 121.9260426156618, 474928.605570259, 474928.6055702594, 165504.1958496801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7365600.0000, 
sim time next is 7366200.0000, 
raw observation next is [19.28333333333333, 96.0, 1.0, 2.0, 0.1967310744066129, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3269062639485748, 6.911199999999999, 6.9112, 121.9260426156618, 488080.5384705734, 488080.5384705738, 166659.2143688457], 
processed observation next is [1.0, 0.2608695652173913, 0.26975308641975304, 0.96, 1.0, 1.0, 0.04372746953168201, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.15863282993571848, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17431447802520478, 0.17431447802520492, 0.32049848917085716], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.11764977], dtype=float32), 0.09182723]. 
=============================================
[2019-03-24 03:36:35,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8058981e-20 3.5669606e-10 1.0000000e+00 1.2055344e-17 2.1476525e-08], sum to 1.0000
[2019-03-24 03:36:35,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7468
[2019-03-24 03:36:35,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.3, 90.0, 1.0, 2.0, 0.1931488299927148, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3193869353248802, 6.911199999999999, 6.9112, 121.9260426156618, 477198.1306143549, 477198.1306143554, 166152.2307329178], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7426800.0000, 
sim time next is 7427400.0000, 
raw observation next is [20.26666666666667, 90.16666666666667, 1.0, 2.0, 0.1928302108405615, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3188949345879298, 6.9112, 6.9112, 121.9260426156618, 476457.1854599906, 476457.1854599906, 166074.8974591313], 
processed observation next is [1.0, 1.0, 0.3061728395061729, 0.9016666666666667, 1.0, 1.0, 0.039083584334001796, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1486186682349122, 0.0, 0.0, 0.8094621288201359, 0.1701632805214252, 0.1701632805214252, 0.3193748028060217], 
reward next is 0.6806, 
noisyNet noise sample is [array([0.17294545], dtype=float32), -0.48824784]. 
=============================================
[2019-03-24 03:36:36,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5014225e-22 9.9988096e-10 1.0000000e+00 4.7608929e-17 3.0574935e-08], sum to 1.0000
[2019-03-24 03:36:36,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5381
[2019-03-24 03:36:36,483] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 66.0, 1.0, 2.0, 0.2353096591150663, 0.0, 2.0, 0.0, 1.0, 2.0, 0.38031321228774, 6.911199999999999, 6.9112, 121.9260426156618, 565577.9867282883, 565577.9867282888, 177412.1094747967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7939200.0000, 
sim time next is 7939800.0000, 
raw observation next is [25.35, 66.5, 1.0, 2.0, 0.2339663936973411, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3783747205465382, 6.9112, 6.9112, 121.9260426156618, 562929.9062828327, 562929.9062828327, 177044.3676193484], 
processed observation next is [1.0, 0.9130434782608695, 0.4944444444444445, 0.665, 1.0, 1.0, 0.08805523059207274, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.22296840068317272, 0.0, 0.0, 0.8094621288201359, 0.2010463951010117, 0.2010463951010117, 0.34046993772951617], 
reward next is 0.6595, 
noisyNet noise sample is [array([-0.7764273], dtype=float32), 0.023452545]. 
=============================================
[2019-03-24 03:36:37,992] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:36:37,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:38,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-24 03:36:45,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1401965e-20 2.9364361e-10 9.9999988e-01 5.5118477e-18 9.1123667e-08], sum to 1.0000
[2019-03-24 03:36:45,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1338
[2019-03-24 03:36:45,321] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.73333333333333, 92.0, 1.0, 2.0, 0.1822053839043633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3030803207026437, 6.911199999999999, 6.9112, 121.9260426156618, 452405.9401228778, 452405.9401228782, 163388.1432810354], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [19.8, 92.0, 1.0, 2.0, 0.1828874578512749, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3038851544481879, 6.9112, 6.9112, 121.9260426156618, 453704.0441149743, 453704.0441149743, 163600.2632712848], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.92, 1.0, 1.0, 0.0272469736324701, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1298564430602349, 0.0, 0.0, 0.8094621288201359, 0.16203715861249082, 0.16203715861249082, 0.314615890906317], 
reward next is 0.6854, 
noisyNet noise sample is [array([-1.3780602], dtype=float32), -0.38499397]. 
=============================================
[2019-03-24 03:36:45,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.83482]
 [68.9189 ]
 [68.94865]
 [69.00096]
 [69.07935]], R is [[68.79958344]
 [68.79737854]
 [68.79437256]
 [68.79203033]
 [68.78826904]].
[2019-03-24 03:36:45,937] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 03:36:45,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:36:45,944] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:36:45,949] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:45,949] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:45,951] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:36:45,950] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:36:45,952] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:45,952] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:36:45,954] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:45,955] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:36:45,969] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-24 03:36:45,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-24 03:36:46,023] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-24 03:36:46,062] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-24 03:36:46,062] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-24 03:36:50,238] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:36:50,241] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.696634305, 19.21263770166667, 1.0, 2.0, 0.1906136480911317, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3240450575230729, 6.911199999999999, 6.9112, 121.9260426156618, 480209.4521849373, 480209.4521849377, 164027.4362703793]
[2019-03-24 03:36:50,243] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:36:50,246] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2916872e-19 4.0309267e-09 9.9999988e-01 2.0882364e-16 8.1322078e-08], sampled 0.7012048605428162
[2019-03-24 03:36:59,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:36:59,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.36620730333333, 65.24620186666667, 1.0, 2.0, 0.2059661055077936, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3377610752826722, 6.911199999999999, 6.9112, 121.9260426156618, 504748.1791681925, 504748.179168193, 169549.858637842]
[2019-03-24 03:36:59,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:36:59,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4462127e-18 7.9552240e-09 9.9999988e-01 7.2928049e-16 1.4333688e-07], sampled 0.8900133264249552
[2019-03-24 03:37:21,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:37:21,210] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 70.0, 1.0, 2.0, 0.6358994520345165, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9774127082212694, 6.911199999999999, 6.9112, 121.9260426156618, 1457208.970986047, 1457208.970986047, 301993.8710878333]
[2019-03-24 03:37:21,212] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:37:21,215] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9840322e-17 3.1950819e-08 9.9999952e-01 9.4098406e-15 4.5684166e-07], sampled 0.20914834076234745
[2019-03-24 03:37:38,297] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:37:38,297] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 81.5, 1.0, 2.0, 0.4062319354934391, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6467344713560562, 6.911199999999999, 6.9112, 121.9260426156618, 926056.4133388516, 926056.4133388521, 226039.5363337184]
[2019-03-24 03:37:38,299] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:37:38,301] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.5066398e-19 3.5568801e-09 9.9999988e-01 1.6588394e-16 7.3265888e-08], sampled 0.5756746672733588
[2019-03-24 03:38:03,646] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:38:03,647] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.826288855, 79.63501555833334, 1.0, 2.0, 0.2337528404746232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3762929888743323, 6.911200000000001, 6.9112, 121.9260426156618, 557658.7229826326, 557658.7229826321, 177334.0474948707]
[2019-03-24 03:38:03,649] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:38:03,651] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4530697e-19 6.5439383e-09 9.9999988e-01 5.0918592e-16 1.2180072e-07], sampled 0.4803574960913334
[2019-03-24 03:38:05,740] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:38:05,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666667, 92.16666666666667, 1.0, 2.0, 0.263137610668761, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4205961562908154, 6.911199999999999, 6.9112, 121.9260426156618, 615898.2069495351, 615898.2069495355, 185172.8098377443]
[2019-03-24 03:38:05,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:38:05,745] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6440103e-19 4.2235531e-09 9.9999988e-01 2.2755614e-16 8.4549328e-08], sampled 0.8002345426859627
[2019-03-24 03:38:07,054] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:38:07,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 55.0, 1.0, 2.0, 0.3927315181906078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6252413673320527, 6.911199999999999, 6.9112, 121.9260426156618, 895262.550608346, 895262.5506083465, 221866.7660086946]
[2019-03-24 03:38:07,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:38:07,059] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.0436804e-19 6.4124115e-09 9.9999988e-01 4.9048877e-16 1.1975467e-07], sampled 0.8938459971129592
[2019-03-24 03:38:22,274] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:38:22,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.40339997333333, 65.40918849333335, 1.0, 2.0, 0.1705600024236004, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2885780807565896, 6.911200000000001, 6.9112, 121.9260426156618, 428489.57212795, 428489.5721279496, 159929.6035145163]
[2019-03-24 03:38:22,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:38:22,278] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2136130e-18 7.3400828e-09 9.9999988e-01 6.2886378e-16 1.3403269e-07], sampled 0.18434614623102663
[2019-03-24 03:38:23,838] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.5120 2600787981.7632 61.0000
[2019-03-24 03:38:23,904] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.9288 2661677694.6124 110.0000
[2019-03-24 03:38:24,063] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7492.5206 2565975221.9196 47.0000
[2019-03-24 03:38:24,119] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7157.8595 2831362235.9031 210.0000
[2019-03-24 03:38:24,200] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9436905]
[2019-03-24 03:38:24,201] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.85020314, 71.020764125, 1.0, 2.0, 0.1621152367201764, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2746832551700675, 6.911199999999999, 6.9112, 121.9260426156618, 407615.8183667514, 407615.8183667519, 158066.1286601731]
[2019-03-24 03:38:24,201] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:38:24,201] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.0396225e-19 5.3271401e-09 9.9999988e-01 3.4873061e-16 1.0260133e-07], sampled 0.7056887778920946
[2019-03-24 03:38:24,205] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.7684 2623880762.9586 97.0000
[2019-03-24 03:38:25,223] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1900000, evaluation results [1900000.0, 7157.859463619724, 2831362235.9030914, 210.0, 6809.511993196244, 2600787981.7632065, 61.0, 7492.520639979948, 2565975221.919632, 47.0, 6579.928819146758, 2661677694.612359, 110.0, 7162.768394127867, 2623880762.9585886, 97.0]
[2019-03-24 03:38:28,706] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1026466e-14 4.2700248e-07 9.9999547e-01 1.8454500e-12 4.0634022e-06], sum to 1.0000
[2019-03-24 03:38:28,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6200
[2019-03-24 03:38:28,725] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.61666666666667, 85.33333333333334, 1.0, 2.0, 0.1701282918024105, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2878963585640484, 6.9112, 6.9112, 121.9260426156618, 427448.1318835796, 427448.1318835796, 159828.4636664821], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7685400.0000, 
sim time next is 7686000.0000, 
raw observation next is [19.6, 86.0, 1.0, 2.0, 0.1708678642486712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2887869185368566, 6.9112, 6.9112, 121.9260426156618, 428982.3128328909, 428982.3128328909, 160052.7499189762], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.86, 1.0, 1.0, 0.012937933629370476, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11098364817107076, 0.0, 0.0, 0.8094621288201359, 0.1532079688688896, 0.1532079688688896, 0.30779374984418495], 
reward next is 0.6922, 
noisyNet noise sample is [array([-2.119044], dtype=float32), 1.7556072]. 
=============================================
[2019-03-24 03:38:28,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.134666]
 [51.12974 ]
 [51.123245]
 [51.12602 ]
 [51.13464 ]], R is [[51.36545563]
 [51.54444122]
 [51.72187042]
 [51.89769745]
 [52.07234573]].
[2019-03-24 03:38:30,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0277273e-16 1.6294291e-06 9.9998009e-01 3.0409543e-13 1.8194965e-05], sum to 1.0000
[2019-03-24 03:38:30,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6018
[2019-03-24 03:38:30,801] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.1780543305228281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3001566446395488, 6.911200000000001, 6.9112, 121.9260426156618, 446310.9620999277, 446310.9620999272, 161738.6308504389], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7714800.0000, 
sim time next is 7715400.0000, 
raw observation next is [19.08333333333334, 91.66666666666667, 1.0, 2.0, 0.1960104208825438, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3299636319227525, 6.9112, 6.9112, 121.9260426156618, 490891.8623763606, 490891.8623763606, 165754.8520950494], 
processed observation next is [1.0, 0.30434782608695654, 0.2623456790123459, 0.9166666666666667, 1.0, 1.0, 0.04286954866969501, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.16245453990344064, 0.0, 0.0, 0.8094621288201359, 0.17531852227727163, 0.17531852227727163, 0.3187593309520181], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.8850769], dtype=float32), -0.3114206]. 
=============================================
[2019-03-24 03:38:32,030] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0415745e-16 2.9427130e-07 9.9998212e-01 1.4739430e-14 1.7590151e-05], sum to 1.0000
[2019-03-24 03:38:32,037] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3975
[2019-03-24 03:38:32,044] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.86666666666667, 66.5, 1.0, 2.0, 0.2026894597688363, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3335743933154406, 6.911199999999999, 6.9112, 121.9260426156618, 498545.5111330266, 498545.5111330271, 168581.6817354642], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7762200.0000, 
sim time next is 7762800.0000, 
raw observation next is [23.73333333333333, 67.0, 1.0, 2.0, 0.2015666618685498, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3319815866079611, 6.911199999999999, 6.9112, 121.9260426156618, 496156.891892959, 496156.8918929594, 168280.2474281933], 
processed observation next is [1.0, 0.8695652173913043, 0.4345679012345678, 0.67, 1.0, 1.0, 0.04948412127208309, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1649769832599514, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17719888996177108, 0.17719888996177122, 0.3236158604388333], 
reward next is 0.6764, 
noisyNet noise sample is [array([-0.01940405], dtype=float32), 0.2845302]. 
=============================================
[2019-03-24 03:38:37,534] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:37,535] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:37,595] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-24 03:38:37,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5006381e-17 2.6511694e-07 9.9999630e-01 3.1250839e-16 3.4058753e-06], sum to 1.0000
[2019-03-24 03:38:37,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7335
[2019-03-24 03:38:37,893] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.35, 83.5, 1.0, 2.0, 0.2493258542122725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4101419858536452, 6.911199999999999, 6.9112, 121.9260426156618, 613027.3366099423, 613027.3366099427, 179600.9435026949], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7873800.0000, 
sim time next is 7874400.0000, 
raw observation next is [21.2, 84.0, 1.0, 2.0, 0.2147350129991158, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3537144384778621, 6.911199999999999, 6.9112, 121.9260426156618, 528646.5932410002, 528646.5932410007, 171280.7718248123], 
processed observation next is [1.0, 0.13043478260869565, 0.34074074074074073, 0.84, 1.0, 1.0, 0.06516072976085213, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.1921430480973276, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18880235472892865, 0.1888023547289288, 0.3293860996631006], 
reward next is 0.6706, 
noisyNet noise sample is [array([-0.13613728], dtype=float32), -0.08372859]. 
=============================================
[2019-03-24 03:38:40,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7002969e-13 1.6985310e-05 9.9969316e-01 1.1933174e-11 2.8982744e-04], sum to 1.0000
[2019-03-24 03:38:40,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-24 03:38:40,467] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 47.5, 1.0, 2.0, 0.8240883131690279, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9755027605262703, 6.911199999999999, 6.9112, 121.9260426156618, 1679736.678410997, 1679736.678410997, 337053.4484198379], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7918200.0000, 
sim time next is 7918800.0000, 
raw observation next is [30.1, 47.66666666666667, 1.0, 2.0, 0.8050840792129769, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9759293697747713, 6.9112, 6.9112, 121.9260426156618, 1656900.036132281, 1656900.036132281, 333281.1338029482], 
processed observation next is [1.0, 0.6521739130434783, 0.6703703703703704, 0.47666666666666674, 1.0, 1.0, 0.7679572371583058, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9699117122184642, 0.0, 0.0, 0.8094621288201359, 0.591750012904386, 0.591750012904386, 0.640925257313362], 
reward next is 0.3591, 
noisyNet noise sample is [array([0.965333], dtype=float32), 0.6887327]. 
=============================================
[2019-03-24 03:38:42,744] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:42,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:42,762] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-24 03:38:42,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:42,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:42,913] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-24 03:38:42,946] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:42,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:42,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-24 03:38:43,001] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,001] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-24 03:38:43,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-24 03:38:43,209] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,209] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,219] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-24 03:38:43,251] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,252] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,259] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-24 03:38:43,296] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,297] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,302] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-24 03:38:43,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-24 03:38:43,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-24 03:38:43,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-24 03:38:43,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,541] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-24 03:38:43,577] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,577] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-24 03:38:43,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:38:43,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:43,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-24 03:38:49,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6371717e-14 5.9357928e-05 9.9965692e-01 6.6261813e-13 2.8369986e-04], sum to 1.0000
[2019-03-24 03:38:49,452] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9746
[2019-03-24 03:38:49,457] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.8, 70.0, 1.0, 2.0, 0.2107457580047159, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3446967850326644, 6.9112, 6.9112, 121.9260426156618, 514965.075853052, 514965.075853052, 170812.1053504873], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 88200.0000, 
sim time next is 88800.0000, 
raw observation next is [23.7, 70.66666666666667, 1.0, 2.0, 0.2105138617182846, 0.0, 2.0, 0.0, 1.0, 2.0, 0.344301572913285, 6.911199999999999, 6.9112, 121.9260426156618, 514370.8528701339, 514370.8528701344, 170761.7733340723], 
processed observation next is [1.0, 0.0, 0.4333333333333333, 0.7066666666666667, 1.0, 1.0, 0.06013554966462452, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.18037696614160623, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1837038760250478, 0.183703876025048, 0.32838802564244673], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.37204596], dtype=float32), 1.6578503]. 
=============================================
[2019-03-24 03:38:50,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1990921e-20 7.7741919e-07 9.9997652e-01 8.6840036e-16 2.2628657e-05], sum to 1.0000
[2019-03-24 03:38:50,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4825
[2019-03-24 03:38:50,744] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.2, 77.0, 1.0, 2.0, 0.194484346172904, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3254692239393801, 6.911199999999999, 6.9112, 121.9260426156618, 485114.1888441481, 485114.1888441486, 165748.7608567236], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 103800.0000, 
sim time next is 104400.0000, 
raw observation next is [21.1, 77.0, 1.0, 2.0, 0.1888967362578821, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3167224749110987, 6.911199999999999, 6.9112, 121.9260426156618, 471806.1999414873, 471806.1999414878, 164407.4437576043], 
processed observation next is [1.0, 0.21739130434782608, 0.3370370370370371, 0.77, 1.0, 1.0, 0.03440087649747867, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14590309363887333, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16850221426481687, 0.16850221426481707, 0.316168161072316], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.36075026], dtype=float32), 0.7420138]. 
=============================================
[2019-03-24 03:38:51,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7982088e-20 5.9888366e-06 9.9992216e-01 2.0800366e-16 7.1905495e-05], sum to 1.0000
[2019-03-24 03:38:51,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2274
[2019-03-24 03:38:51,470] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.33333333333333, 27.33333333333334, 1.0, 2.0, 0.4948193385530033, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7998561128348455, 6.911199999999999, 6.9112, 121.9260426156618, 1190101.871105061, 1190101.871105061, 253368.028810885], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 132000.0000, 
sim time next is 132600.0000, 
raw observation next is [34.71666666666667, 25.66666666666666, 1.0, 2.0, 0.4988137769407283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075417340678843, 6.911199999999999, 6.9112, 121.9260426156618, 1202720.265088484, 1202720.265088485, 254601.8027145895], 
processed observation next is [1.0, 0.5217391304347826, 0.8413580246913581, 0.2566666666666666, 1.0, 1.0, 0.40334973445324807, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7594271675848554, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42954295181731567, 0.4295429518173161, 0.4896188513742106], 
reward next is 0.5104, 
noisyNet noise sample is [array([0.46542], dtype=float32), -0.47568375]. 
=============================================
[2019-03-24 03:39:00,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6269358e-04 6.3111103e-04 9.9724519e-01 1.8137851e-03 1.4717721e-04], sum to 1.0000
[2019-03-24 03:39:00,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-24 03:39:00,209] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.56666666666667, 30.33333333333334, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2746743183849897, 6.911199999999999, 6.9112, 121.9260426156618, 392249.2573626134, 392249.2573626139, 144758.8073139144], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 296400.0000, 
sim time next is 297000.0000, 
raw observation next is [25.7, 30.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2752488639747924, 6.9112, 6.9112, 121.9260426156618, 393069.9487109467, 393069.9487109467, 145231.8251533258], 
processed observation next is [0.0, 0.43478260869565216, 0.5074074074074074, 0.3, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.09406107996849052, 0.0, 0.0, 0.8094621288201359, 0.14038212453962381, 0.14038212453962381, 0.27929197144870344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5874152], dtype=float32), -0.12395275]. 
=============================================
[2019-03-24 03:39:00,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[6.6982503]
 [6.7179914]
 [6.724748 ]
 [6.7514434]
 [6.7810416]], R is [[6.60005665]
 [6.53405619]
 [6.46871567]
 [6.40402842]
 [6.33998823]].
[2019-03-24 03:39:00,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7968737e-04 5.6591822e-04 9.9309301e-01 6.1495379e-03 1.1871078e-05], sum to 1.0000
[2019-03-24 03:39:01,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9866
[2019-03-24 03:39:01,010] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333334, 32.33333333333334, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2668580741891704, 6.911199999999999, 6.9112, 121.9260426156618, 381084.4795361494, 381084.4795361499, 141492.1503266916], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 292800.0000, 
sim time next is 293400.0000, 
raw observation next is [24.95, 32.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2690780282898051, 6.911199999999999, 6.9112, 121.9260426156618, 384255.4609591934, 384255.4609591938, 142174.292120882], 
processed observation next is [0.0, 0.391304347826087, 0.47962962962962963, 0.32, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.08634753536225635, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13723409319971194, 0.13723409319971208, 0.27341210023246537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0833112], dtype=float32), 1.5480851]. 
=============================================
[2019-03-24 03:39:02,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5160839e-21 4.0931871e-09 1.0000000e+00 1.0620338e-20 5.8547636e-34], sum to 1.0000
[2019-03-24 03:39:02,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4178
[2019-03-24 03:39:02,456] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.3, 32.33333333333334, 1.0, 2.0, 0.1650341625051393, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2887060572782956, 6.911199999999999, 6.9112, 121.9260426156618, 421341.1647495348, 421341.1647495353, 157093.3744767077], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 324600.0000, 
sim time next is 325200.0000, 
raw observation next is [27.2, 32.66666666666667, 1.0, 2.0, 0.1642175108930804, 0.0, 2.0, 0.0, 1.0, 2.0, 0.287340733576423, 6.9112, 6.9112, 121.9260426156618, 419291.4868759005, 419291.4868759005, 156912.0089406072], 
processed observation next is [0.0, 0.782608695652174, 0.5629629629629629, 0.3266666666666667, 1.0, 1.0, 0.005020846301286185, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.10917591697052871, 0.0, 0.0, 0.8094621288201359, 0.14974695959853587, 0.14974695959853587, 0.3017538633473215], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.97097325], dtype=float32), -1.5050687]. 
=============================================
[2019-03-24 03:39:06,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.95903784e-16 1.07485896e-04 9.99883890e-01 1.72947594e-13
 8.54549216e-06], sum to 1.0000
[2019-03-24 03:39:06,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0956
[2019-03-24 03:39:06,696] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.8, 26.66666666666667, 1.0, 2.0, 0.518128412569208, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8655876776024128, 6.911199999999999, 6.9112, 121.9260426156618, 1291455.530107925, 1291455.530107925, 258640.1615114366], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 405600.0000, 
sim time next is 406200.0000, 
raw observation next is [30.8, 26.83333333333333, 1.0, 2.0, 0.514169438172493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8586578387706334, 6.911199999999999, 6.9112, 121.9260426156618, 1281230.631277048, 1281230.631277049, 257280.5539947524], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.2683333333333333, 1.0, 1.0, 0.4216302835386822, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8233222984632917, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45758236831323146, 0.4575823683132318, 0.4947702961437546], 
reward next is 0.5052, 
noisyNet noise sample is [array([-0.76708907], dtype=float32), -1.1808653]. 
=============================================
[2019-03-24 03:39:14,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6640946e-16 6.7731394e-03 9.9321437e-01 1.0744776e-16 1.2492717e-05], sum to 1.0000
[2019-03-24 03:39:14,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8050
[2019-03-24 03:39:14,097] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 66.0, 1.0, 2.0, 0.1722794653618153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2951868844301406, 6.911199999999999, 6.9112, 121.9260426156618, 435823.0405378758, 435823.0405378763, 159642.2215472073], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 543600.0000, 
sim time next is 544200.0000, 
raw observation next is [21.8, 65.16666666666667, 1.0, 2.0, 0.2081515321810778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3557972760650355, 6.911199999999999, 6.9112, 121.9260426156618, 525956.262576582, 525956.2625765825, 167640.3439534847], 
processed observation next is [1.0, 0.30434782608695654, 0.362962962962963, 0.6516666666666667, 1.0, 1.0, 0.05732325259652118, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.19474659508129433, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1878415223487793, 0.18784152234877946, 0.32238527683362445], 
reward next is 0.6776, 
noisyNet noise sample is [array([1.5653387], dtype=float32), -0.70853317]. 
=============================================
[2019-03-24 03:39:17,256] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 03:39:17,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:39:17,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:39:17,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:39:17,260] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:39:17,261] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:39:17,262] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:39:17,265] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:39:17,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:39:17,267] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:39:17,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5328678e-15 6.8952802e-05 9.9991333e-01 4.1216797e-15 1.7782415e-05], sum to 1.0000
[2019-03-24 03:39:17,269] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:39:17,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9459
[2019-03-24 03:39:17,275] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.53333333333333, 39.5, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2706635351577289, 6.911199999999999, 6.9112, 121.9260426156618, 399090.1843989645, 399090.184398965, 156201.2897576104], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 774600.0000, 
sim time next is 775200.0000, 
raw observation next is [26.36666666666667, 40.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2691288650520438, 6.911199999999999, 6.9112, 121.9260426156618, 396646.2641832416, 396646.2641832421, 155852.7841052539], 
processed observation next is [1.0, 1.0, 0.5320987654320989, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.08641108131505475, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14165938006544343, 0.1416593800654436, 0.29971689251010364], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6728158], dtype=float32), 0.41468045]. 
=============================================
[2019-03-24 03:39:17,290] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-24 03:39:17,318] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-24 03:39:17,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-24 03:39:17,370] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-24 03:39:17,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-24 03:39:25,745] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:39:25,746] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.246596255, 87.41603333, 1.0, 2.0, 0.2325233560905015, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3996211902052974, 6.9112, 6.9112, 121.9260426156618, 589165.050530203, 589165.050530203, 172971.4063887256]
[2019-03-24 03:39:25,749] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:39:25,753] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6612537e-16 5.1185436e-04 9.9947506e-01 6.2342870e-15 1.3155496e-05], sampled 0.6249380219742856
[2019-03-24 03:39:37,743] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:39:37,744] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.91666666666667, 33.66666666666667, 1.0, 2.0, 0.203949798943052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3326164706194281, 6.911199999999999, 6.9112, 121.9260426156618, 496628.3860992593, 496628.3860992598, 169446.1494895969]
[2019-03-24 03:39:37,746] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:39:37,750] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0629830e-15 5.4789451e-04 9.9943763e-01 8.4764933e-15 1.4464958e-05], sampled 0.8320718531527423
[2019-03-24 03:39:40,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:39:40,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.36926812666667, 35.50473793666667, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2773346196613177, 6.9112, 6.9112, 121.9260426156618, 404073.5832124557, 404073.5832124557, 155361.3144977524]
[2019-03-24 03:39:40,627] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:39:40,631] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0900477e-15 7.3361251e-04 9.9924374e-01 2.9848655e-14 2.2660432e-05], sampled 0.6394359943521661
[2019-03-24 03:39:48,788] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:39:48,790] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.36443830666666, 88.07714924333334, 1.0, 2.0, 0.2208609616020844, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3599316027977251, 6.911199999999999, 6.9112, 121.9260426156618, 537324.1905212295, 537324.1905212299, 173400.1407157586]
[2019-03-24 03:39:48,791] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:39:48,795] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.8634801e-16 5.1630952e-04 9.9947053e-01 6.3900415e-15 1.3246521e-05], sampled 0.7068702858525105
[2019-03-24 03:39:50,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:39:50,613] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666666, 67.33333333333334, 1.0, 2.0, 0.4530763560273421, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7215835824332208, 6.9112, 6.9112, 121.9260426156618, 1038996.521493492, 1038996.521493492, 240955.7350350208]
[2019-03-24 03:39:50,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:39:50,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0292868e-15 5.4970384e-04 9.9943584e-01 8.2170006e-15 1.4392676e-05], sampled 0.57213917888151
[2019-03-24 03:40:07,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:40:07,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.58333333333333, 73.33333333333333, 1.0, 2.0, 0.4015974575213603, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393562314900963, 6.9112, 6.9112, 121.9260426156618, 915485.2318514842, 915485.2318514842, 224601.2035158059]
[2019-03-24 03:40:07,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:40:07,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4156569e-16 3.5187107e-04 9.9964046e-01 1.2885630e-15 7.6267133e-06], sampled 0.42365712369651354
[2019-03-24 03:40:17,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:40:17,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.54236151333333, 88.93846781666667, 1.0, 2.0, 0.3308298975103168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5266919712139878, 6.9112, 6.9112, 121.9260426156618, 754083.4954058289, 754083.4954058289, 203715.1633089029]
[2019-03-24 03:40:17,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:40:17,238] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.18101510e-16 5.03816758e-04 9.99483228e-01 5.87207666e-15
 1.28915335e-05], sampled 0.7556685797389369
[2019-03-24 03:40:17,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:40:17,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.96666666666667, 94.33333333333334, 1.0, 2.0, 0.303677515403254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835663514602118, 6.911199999999999, 6.9112, 121.9260426156618, 694771.7099391416, 694771.7099391421, 196193.5780128552]
[2019-03-24 03:40:17,457] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:40:17,459] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.72783933e-16 4.59559320e-04 9.99529123e-01 3.97357979e-15
 1.12661255e-05], sampled 0.6873539460144292
[2019-03-24 03:40:19,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.94084716]
[2019-03-24 03:40:19,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.91450429333333, 81.97042173333335, 1.0, 2.0, 0.2181740691947375, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3537704645681765, 6.911199999999999, 6.9112, 121.9260426156618, 527116.5588275214, 527116.5588275217, 173114.8583270396]
[2019-03-24 03:40:19,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:40:19,431] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1066177e-16 4.1945057e-04 9.9957067e-01 2.6827361e-15 9.8355049e-06], sampled 0.0509585141421548
[2019-03-24 03:40:55,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6582.0503 2661460097.3904 110.0000
[2019-03-24 03:40:55,323] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7156.9266 2831206990.1030 210.0000
[2019-03-24 03:40:55,470] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7160.4776 2623551124.7899 98.0000
[2019-03-24 03:40:55,574] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7493.5596 2565863616.4034 47.0000
[2019-03-24 03:40:55,583] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6805.5435 2600533536.2516 63.0000
[2019-03-24 03:40:56,598] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1925000, evaluation results [1925000.0, 7156.926642186882, 2831206990.103011, 210.0, 6805.543494284622, 2600533536.251613, 63.0, 7493.559635136455, 2565863616.403372, 47.0, 6582.050273270917, 2661460097.3904414, 110.0, 7160.477578346198, 2623551124.7899427, 98.0]
[2019-03-24 03:40:58,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2471611e-14 4.1704392e-03 9.9566877e-01 4.0825923e-13 1.6085753e-04], sum to 1.0000
[2019-03-24 03:40:58,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6340
[2019-03-24 03:40:58,129] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 42.66666666666667, 1.0, 2.0, 0.4857470108303283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7905462846290267, 6.911199999999999, 6.9112, 121.9260426156618, 1180187.571633747, 1180187.571633748, 249627.823105286], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 639600.0000, 
sim time next is 640200.0000, 
raw observation next is [29.23333333333333, 41.83333333333334, 1.0, 2.0, 0.4703471019176056, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7649815316087898, 6.9112, 6.9112, 121.9260426156618, 1141739.578600308, 1141739.578600308, 244490.3544959743], 
processed observation next is [1.0, 0.391304347826087, 0.6382716049382715, 0.41833333333333345, 1.0, 1.0, 0.3694608356161972, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7062269145109873, 0.0, 0.0, 0.8094621288201359, 0.4077641352143957, 0.4077641352143957, 0.4701737586461044], 
reward next is 0.5298, 
noisyNet noise sample is [array([0.460645], dtype=float32), 1.589233]. 
=============================================
[2019-03-24 03:41:03,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8136189e-18 4.0067989e-05 9.9995852e-01 4.0128858e-17 1.4084012e-06], sum to 1.0000
[2019-03-24 03:41:03,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-24 03:41:03,794] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 41.0, 1.0, 2.0, 0.5634886708630863, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9204115505391953, 6.9112, 6.9112, 121.9260426156618, 1375519.608632105, 1375519.608632105, 276963.0977364499], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 734400.0000, 
sim time next is 735000.0000, 
raw observation next is [28.98333333333333, 39.33333333333334, 1.0, 2.0, 0.6270641971568134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9561504580610841, 6.911199999999999, 6.9112, 121.9260426156618, 1480710.813211406, 1480710.813211407, 292095.2730733394], 
processed observation next is [1.0, 0.5217391304347826, 0.6290123456790122, 0.3933333333333334, 1.0, 1.0, 0.5560288061390636, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9451880725763551, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.528825290432645, 0.5288252904326454, 0.5617216789871912], 
reward next is 0.4383, 
noisyNet noise sample is [array([-0.07603669], dtype=float32), 0.47985315]. 
=============================================
[2019-03-24 03:41:03,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.041794]
 [63.966118]
 [63.945522]
 [63.996975]
 [63.93331 ]], R is [[63.65362167]
 [63.48446655]
 [63.31433487]
 [63.14907455]
 [63.00008392]].
[2019-03-24 03:41:04,187] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7356056e-17 1.8272387e-05 9.9997950e-01 1.9122536e-17 2.3040236e-06], sum to 1.0000
[2019-03-24 03:41:04,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0679
[2019-03-24 03:41:04,201] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.93333333333333, 24.0, 1.0, 2.0, 0.4893519397295267, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8166837808853464, 6.9112, 6.9112, 121.9260426156618, 1218750.833798892, 1218750.833798892, 248768.8349907402], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 751200.0000, 
sim time next is 751800.0000, 
raw observation next is [31.91666666666666, 24.0, 1.0, 2.0, 0.4817465506317959, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8045526728193463, 6.911200000000001, 6.9112, 121.9260426156618, 1200419.595985467, 1200419.595985467, 246140.636036031], 
processed observation next is [1.0, 0.6956521739130435, 0.7376543209876542, 0.24, 1.0, 1.0, 0.38303160789499513, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7556908410241827, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.428721284280524, 0.428721284280524, 0.47334737699236734], 
reward next is 0.5267, 
noisyNet noise sample is [array([1.1570632], dtype=float32), -0.22125913]. 
=============================================
[2019-03-24 03:41:17,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.5317549e-15 9.9949050e-01 5.0877768e-04 1.7905955e-14 7.6192771e-07], sum to 1.0000
[2019-03-24 03:41:17,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5965
[2019-03-24 03:41:17,489] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 56.83333333333333, 1.0, 2.0, 0.9015877651787937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.091602098145234, 6.9112, 121.925370030727, 1222596.129653075, 1130214.640856231, 221942.3247172404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 987000.0000, 
sim time next is 987600.0000, 
raw observation next is [24.46666666666667, 56.66666666666667, 1.0, 2.0, 0.9186278415879201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.19905435387652, 6.9112, 121.9246436833285, 1297558.906763138, 1150153.440740962, 225866.5062155617], 
processed observation next is [1.0, 0.43478260869565216, 0.46172839506172847, 0.5666666666666668, 1.0, 1.0, 0.903128382842762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.028785435387652037, 0.0, 0.8094528413642299, 0.4634138952725493, 0.41076908597891504, 0.4343586657991571], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9958115], dtype=float32), 1.213508]. 
=============================================
[2019-03-24 03:41:17,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3765189e-14 9.9954200e-01 4.5723296e-04 3.1322839e-13 7.7530626e-07], sum to 1.0000
[2019-03-24 03:41:17,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-24 03:41:17,720] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 65.0, 1.0, 2.0, 0.601236510788263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 768020.6159507565, 768020.615950756, 160894.8669915523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1162800.0000, 
sim time next is 1163400.0000, 
raw observation next is [21.16666666666667, 65.0, 1.0, 2.0, 0.5449191596278085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695799.2911000772, 695799.2911000772, 151191.0978902326], 
processed observation next is [1.0, 0.4782608695652174, 0.33950617283950635, 0.65, 1.0, 1.0, 0.45823709479501007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24849974682145615, 0.24849974682145615, 0.2907521113273704], 
reward next is 0.7092, 
noisyNet noise sample is [array([0.6437255], dtype=float32), 0.06921758]. 
=============================================
[2019-03-24 03:41:18,237] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6241579e-11 9.9750769e-01 2.4817286e-03 6.2396879e-11 1.0540920e-05], sum to 1.0000
[2019-03-24 03:41:18,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8578
[2019-03-24 03:41:18,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 49.0, 1.0, 2.0, 0.8930499850312796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.021121983418724, 6.9112, 121.925501138983, 1173427.200800307, 1117137.570559328, 219933.7349096103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1004400.0000, 
sim time next is 1005000.0000, 
raw observation next is [26.1, 48.5, 1.0, 2.0, 0.9062610950641373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.110759554380175, 6.9112, 121.925071716797, 1235961.5681483, 1133770.053634085, 222974.8055530495], 
processed observation next is [1.0, 0.6521739130434783, 0.5222222222222223, 0.485, 1.0, 1.0, 0.8884060655525444, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.019955955438017536, 0.0, 0.8094556830613374, 0.44141484576725004, 0.4049178762978875, 0.4287977029866336], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13022587], dtype=float32), -0.14822355]. 
=============================================
[2019-03-24 03:41:18,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[34.43907 ]
 [34.443   ]
 [34.25802 ]
 [34.303352]
 [34.501198]], R is [[33.84622192]
 [33.53519821]
 [33.60748291]
 [33.46749115]
 [33.13281631]].
[2019-03-24 03:41:18,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8168991e-10 8.1379753e-01 1.8543968e-01 8.6189011e-10 7.6277001e-04], sum to 1.0000
[2019-03-24 03:41:18,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3627
[2019-03-24 03:41:18,972] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 44.33333333333334, 1.0, 2.0, 0.910903527245663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.14134425554893, 6.9112, 121.9248316805741, 1257298.708786405, 1139445.450382177, 224047.2825839743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1011000.0000, 
sim time next is 1011600.0000, 
raw observation next is [27.1, 44.0, 1.0, 2.0, 0.920506005253705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.20577719133894, 6.9112, 121.9245815471229, 1302249.031195362, 1151400.987888589, 226282.2995561083], 
processed observation next is [1.0, 0.7391304347826086, 0.5592592592592593, 0.44, 1.0, 1.0, 0.9053642919686964, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.029457719133893966, 0.0, 0.8094524288444418, 0.4650889397126293, 0.4112146385316389, 0.43515826837713134], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58344537], dtype=float32), 2.364909]. 
=============================================
[2019-03-24 03:41:19,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.46143300e-27 9.99999881e-01 1.69208434e-07 1.62268205e-24
 1.30751811e-12], sum to 1.0000
[2019-03-24 03:41:19,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9195
[2019-03-24 03:41:19,688] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 47.66666666666667, 1.0, 2.0, 0.2746775443908002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 353258.3547297292, 353258.3547297292, 112499.3150237044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1030800.0000, 
sim time next is 1031400.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.2736121594588486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 351895.3912560692, 351895.3912560692, 112372.5442238196], 
processed observation next is [1.0, 0.9565217391304348, 0.41851851851851857, 0.48, 1.0, 1.0, 0.13525257078434355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12567692544859613, 0.12567692544859613, 0.21610104658426846], 
reward next is 0.7839, 
noisyNet noise sample is [array([-0.3191457], dtype=float32), 0.43540108]. 
=============================================
[2019-03-24 03:41:23,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9713376e-21 8.3135843e-02 9.1682982e-01 9.1352883e-20 3.4356828e-05], sum to 1.0000
[2019-03-24 03:41:23,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4070
[2019-03-24 03:41:23,588] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.55, 63.0, 1.0, 2.0, 0.1686335350674345, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2862793089954332, 6.9112, 6.9112, 121.9260426156618, 424484.6168914968, 424484.6168914968, 159342.0916083677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1107000.0000, 
sim time next is 1107600.0000, 
raw observation next is [22.3, 64.33333333333333, 1.0, 2.0, 0.1694494695756651, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2878329288294669, 6.911199999999999, 6.9112, 121.9260426156618, 426681.3902147502, 426681.3902147507, 159485.0778445137], 
processed observation next is [1.0, 0.8260869565217391, 0.38148148148148153, 0.6433333333333333, 1.0, 1.0, 0.011249368542458437, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.10979116103683365, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15238621079098222, 0.1523862107909824, 0.30670207277791095], 
reward next is 0.6933, 
noisyNet noise sample is [array([-1.8685193], dtype=float32), -1.3528885]. 
=============================================
[2019-03-24 03:41:26,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3694361e-20 9.9997139e-01 2.8593373e-05 7.4833091e-21 1.1384601e-08], sum to 1.0000
[2019-03-24 03:41:26,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0468
[2019-03-24 03:41:26,330] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 73.0, 1.0, 2.0, 0.2764086051661019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355351.2188606191, 355351.2188606187, 112706.4810798483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [19.4, 72.5, 1.0, 2.0, 0.2841988721821617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 365379.4659833665, 365379.4659833661, 113641.6083534034], 
processed observation next is [1.0, 0.2608695652173913, 0.274074074074074, 0.725, 1.0, 1.0, 0.1478558002168592, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13049266642263088, 0.13049266642263077, 0.21854155452577576], 
reward next is 0.7815, 
noisyNet noise sample is [array([-0.3676455], dtype=float32), -0.6418438]. 
=============================================
[2019-03-24 03:41:43,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4405029e-23 9.9998415e-01 1.5795480e-05 7.9477616e-23 5.5335061e-09], sum to 1.0000
[2019-03-24 03:41:43,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-24 03:41:43,970] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 65.5, 1.0, 2.0, 0.3382838226446179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428217.2636750843, 428217.2636750843, 120414.2985573978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1481400.0000, 
sim time next is 1482000.0000, 
raw observation next is [22.0, 66.33333333333333, 1.0, 2.0, 0.3388910567155046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428853.0606733214, 428853.0606733214, 120492.1508044539], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.6633333333333333, 1.0, 1.0, 0.21296554370893409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15316180738332907, 0.15316180738332907, 0.2317156746239498], 
reward next is 0.7683, 
noisyNet noise sample is [array([-0.6293977], dtype=float32), -0.008409249]. 
=============================================
[2019-03-24 03:41:43,991] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[80.0767 ]
 [80.15661]
 [80.36592]
 [80.27934]
 [80.30497]], R is [[79.98936462]
 [79.957901  ]
 [79.92710114]
 [79.89717865]
 [79.86804199]].
[2019-03-24 03:41:46,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5124522e-19 9.9989998e-01 9.8762313e-05 2.0159707e-18 1.1574764e-06], sum to 1.0000
[2019-03-24 03:41:46,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9475
[2019-03-24 03:41:46,744] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.53333333333334, 36.33333333333334, 1.0, 2.0, 0.5003196066633016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 594454.5911940134, 594454.5911940129, 142859.9657322529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [33.36666666666667, 37.66666666666667, 1.0, 2.0, 0.5077270821579545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601149.620111681, 601149.620111681, 143946.1929375094], 
processed observation next is [0.0, 0.6956521739130435, 0.7913580246913581, 0.3766666666666667, 1.0, 1.0, 0.41396081209280294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21469629289702896, 0.21469629289702896, 0.27681960180290266], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.15588218], dtype=float32), -0.9878225]. 
=============================================
[2019-03-24 03:41:47,271] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 03:41:47,274] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:41:47,275] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:41:47,276] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:41:47,278] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:41:47,278] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:41:47,276] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:41:47,283] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:41:47,283] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:41:47,284] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:41:47,282] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:41:47,306] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-24 03:41:47,334] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-24 03:41:47,335] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-24 03:41:47,362] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-24 03:41:47,389] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-24 03:41:56,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:41:56,713] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 51.0, 1.0, 2.0, 0.3360650690401359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424937.752278861, 424937.752278861, 120120.6976543885]
[2019-03-24 03:41:56,715] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:41:56,718] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.15331320e-17 9.94670570e-01 5.31315710e-03 1.01489966e-16
 1.62603901e-05], sampled 0.12955301750144277
[2019-03-24 03:42:07,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:42:07,020] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.83333333333334, 46.16666666666667, 1.0, 2.0, 0.3043126813328549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 387807.9104450387, 387807.9104450392, 116108.1972403732]
[2019-03-24 03:42:07,021] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:07,024] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4497619e-18 9.9542785e-01 4.5604743e-03 3.2751416e-17 1.1638745e-05], sampled 0.04583183171946792
[2019-03-24 03:42:45,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:42:45,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.5066284776206096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608167.1048801392, 608167.1048801392, 144080.9000764503]
[2019-03-24 03:42:45,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:45,289] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4498910e-19 9.9651176e-01 3.4817567e-03 4.7709441e-18 6.5850290e-06], sampled 0.9720891941188303
[2019-03-24 03:42:57,764] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:42:57,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.93333333333333, 59.66666666666667, 1.0, 2.0, 0.9792367690154977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.016732951890203, 6.9112, 121.9252519826071, 1170366.025128774, 1116324.071771712, 235756.7413153048]
[2019-03-24 03:42:57,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:57,768] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0081497e-16 9.9290282e-01 7.0673008e-03 7.7840835e-16 2.9802395e-05], sampled 0.9017062149982344
[2019-03-24 03:43:01,205] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:01,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.83333333333334, 65.66666666666667, 1.0, 2.0, 0.4809023505365154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579693.1534985568, 579693.1534985568, 140141.4976125142]
[2019-03-24 03:43:01,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:01,208] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2805490e-18 9.9517423e-01 4.8126462e-03 4.8730854e-17 1.3133536e-05], sampled 0.6752502846182104
[2019-03-24 03:43:10,130] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:10,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.58333333333333, 89.00000000000001, 1.0, 2.0, 0.564983263488209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653229.1946857561, 653229.1946857561, 152610.9734098641]
[2019-03-24 03:43:10,132] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:43:10,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1211589e-18 9.9570966e-01 4.2801094e-03 2.0738420e-17 1.0173666e-05], sampled 0.1520007940858551
[2019-03-24 03:43:16,631] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:16,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 81.33333333333334, 1.0, 2.0, 0.4831756500701068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581656.64006911, 581656.64006911, 140466.5470305738]
[2019-03-24 03:43:16,634] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:16,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0687946e-17 9.9471962e-01 5.2644578e-03 9.4409042e-17 1.5947828e-05], sampled 0.24938145572464165
[2019-03-24 03:43:18,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:18,061] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 38.83333333333333, 1.0, 2.0, 0.8629328387543722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1069285.44895035, 1069285.44895035, 212884.3720608554]
[2019-03-24 03:43:18,063] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:43:18,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3700139e-16 9.9261367e-01 7.3538818e-03 1.0383828e-15 3.2445747e-05], sampled 0.052037771883752804
[2019-03-24 03:43:19,871] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:19,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.63586338, 68.31254721, 1.0, 2.0, 0.3023836553475107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 386038.5010240043, 386038.5010240038, 115870.5296898736]
[2019-03-24 03:43:19,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:43:19,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4183273e-18 9.9481261e-01 5.1720417e-03 8.3801939e-17 1.5375832e-05], sampled 0.5208540613670143
[2019-03-24 03:43:24,993] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.95519066]
[2019-03-24 03:43:24,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.7, 70.16666666666667, 1.0, 2.0, 0.4249207094344039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522622.9806460805, 522622.9806460805, 132091.7080624947]
[2019-03-24 03:43:24,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:24,997] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1800820e-17 9.9464744e-01 5.3361380e-03 1.0363465e-16 1.6406118e-05], sampled 0.5942922842736011
[2019-03-24 03:43:25,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8735.4887 2172114257.6189 492.0000
[2019-03-24 03:43:25,393] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8536.8067 2250488629.6339 552.0000
[2019-03-24 03:43:25,613] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8644.1637 2197387478.5966 569.0000
[2019-03-24 03:43:25,634] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8869.2168 2122800860.6503 430.0000
[2019-03-24 03:43:25,802] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8052.7640 2447420669.9928 739.0000
[2019-03-24 03:43:26,818] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1950000, evaluation results [1950000.0, 8052.7640021827365, 2447420669.992812, 739.0, 8735.488735134573, 2172114257.618917, 492.0, 8869.21684693115, 2122800860.6502788, 430.0, 8536.806652492292, 2250488629.6339355, 552.0, 8644.163703853117, 2197387478.596562, 569.0]
[2019-03-24 03:43:37,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2591690e-18 1.4795171e-04 9.9981683e-01 3.7728194e-17 3.5265395e-05], sum to 1.0000
[2019-03-24 03:43:37,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-24 03:43:37,943] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.5, 71.66666666666667, 1.0, 2.0, 0.4643776371874731, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7558145034657467, 6.911199999999999, 6.9112, 121.9260426156618, 1128321.748439509, 1128321.748439509, 242438.3677779203], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1761000.0000, 
sim time next is 1761600.0000, 
raw observation next is [23.6, 71.33333333333334, 1.0, 2.0, 0.4023354728201006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6545636371746248, 6.9112, 6.9112, 121.9260426156618, 976937.599793056, 976937.599793056, 222652.1749631861], 
processed observation next is [1.0, 0.391304347826087, 0.4296296296296297, 0.7133333333333334, 1.0, 1.0, 0.2884946105001198, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.568204546468281, 0.0, 0.0, 0.8094621288201359, 0.3489062856403772, 0.3489062856403772, 0.42817725954458863], 
reward next is 0.5718, 
noisyNet noise sample is [array([0.5968555], dtype=float32), 0.59884584]. 
=============================================
[2019-03-24 03:43:44,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8388291e-15 6.5672517e-02 9.3419755e-01 4.0504588e-12 1.2998775e-04], sum to 1.0000
[2019-03-24 03:43:44,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3103
[2019-03-24 03:43:44,139] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.81666666666667, 83.66666666666666, 1.0, 2.0, 0.3912373524181112, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6371977857881678, 6.911199999999999, 6.9112, 121.9260426156618, 951331.3442675844, 951331.3442675848, 219180.3854538154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1864200.0000, 
sim time next is 1864800.0000, 
raw observation next is [21.8, 84.0, 1.0, 2.0, 0.3762252443852022, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6126562743258688, 6.9112, 6.9112, 121.9260426156618, 914628.1381730991, 914628.1381730991, 214695.7388459195], 
processed observation next is [1.0, 0.6086956521739131, 0.362962962962963, 0.84, 1.0, 1.0, 0.25741100522047883, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5158203429073359, 0.0, 0.0, 0.8094621288201359, 0.3266529064903925, 0.3266529064903925, 0.4128764208575375], 
reward next is 0.5871, 
noisyNet noise sample is [array([-0.52206033], dtype=float32), 0.20882477]. 
=============================================
[2019-03-24 03:43:49,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3135511e-15 1.4083008e-03 9.9850309e-01 4.8283079e-12 8.8720568e-05], sum to 1.0000
[2019-03-24 03:43:49,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8263
[2019-03-24 03:43:49,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.15, 63.83333333333334, 1.0, 2.0, 0.274168596410644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.437113264233797, 6.9112, 6.9112, 121.9260426156618, 634062.479819851, 634062.479819851, 188245.2356017081], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1965000.0000, 
sim time next is 1965600.0000, 
raw observation next is [28.0, 65.0, 1.0, 2.0, 0.2780956854122994, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4432853472985018, 6.9112, 6.9112, 121.9260426156618, 642301.6875181022, 642301.6875181022, 189283.7665851668], 
processed observation next is [1.0, 0.782608695652174, 0.5925925925925926, 0.65, 1.0, 1.0, 0.1405901016813088, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3041066841231272, 0.0, 0.0, 0.8094621288201359, 0.22939345982789366, 0.22939345982789366, 0.36400724343301305], 
reward next is 0.6360, 
noisyNet noise sample is [array([-1.2034582], dtype=float32), 1.961393]. 
=============================================
[2019-03-24 03:43:58,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4618602e-17 3.5623400e-06 9.9999583e-01 2.0050075e-15 6.4980418e-07], sum to 1.0000
[2019-03-24 03:43:58,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-24 03:43:58,148] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.58333333333334, 54.33333333333334, 1.0, 2.0, 0.294769632146167, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4693830812665433, 6.911199999999999, 6.9112, 121.9260426156618, 674410.461759728, 674410.4617597285, 193805.0551119083], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2124600.0000, 
sim time next is 2125200.0000, 
raw observation next is [30.66666666666667, 53.66666666666667, 1.0, 2.0, 0.2935615524213756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4675007465091881, 6.911199999999999, 6.9112, 121.9260426156618, 672437.3516692668, 672437.3516692673, 193468.9267127318], 
processed observation next is [0.0, 0.6086956521739131, 0.6913580246913582, 0.5366666666666667, 1.0, 1.0, 0.15900184812068524, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3343759331364851, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24015619702473814, 0.2401561970247383, 0.372055628293715], 
reward next is 0.6279, 
noisyNet noise sample is [array([-0.85319096], dtype=float32), -1.338848]. 
=============================================
[2019-03-24 03:44:06,708] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0485627e-16 8.8197837e-04 9.9911660e-01 3.6546899e-13 1.3930337e-06], sum to 1.0000
[2019-03-24 03:44:06,715] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7539
[2019-03-24 03:44:06,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.9, 92.5, 1.0, 2.0, 0.3969386421801281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6390249613705079, 6.9112, 6.9112, 121.9260426156618, 947321.2004984552, 947321.2004984552, 221912.2124644619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2280600.0000, 
sim time next is 2281200.0000, 
raw observation next is [22.06666666666667, 92.0, 1.0, 2.0, 0.4024634299039992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473037523246163, 6.911199999999999, 6.9112, 121.9260426156618, 958586.8127026866, 958586.8127026871, 223696.519487863], 
processed observation next is [1.0, 0.391304347826087, 0.3728395061728396, 0.92, 1.0, 1.0, 0.2886469403619038, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5591296904057704, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34235243310810237, 0.34235243310810254, 0.4301856143997365], 
reward next is 0.5698, 
noisyNet noise sample is [array([-0.30712438], dtype=float32), -0.29106605]. 
=============================================
[2019-03-24 03:44:10,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0209766e-20 5.5611340e-06 9.9999440e-01 9.5072690e-18 3.0239079e-08], sum to 1.0000
[2019-03-24 03:44:10,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8858
[2019-03-24 03:44:10,482] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.23333333333333, 89.0, 1.0, 2.0, 0.2425366364204618, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3915443218402482, 6.911199999999999, 6.9112, 121.9260426156618, 581788.3536907032, 581788.3536907036, 179247.7506706728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2352000.0000, 
sim time next is 2352600.0000, 
raw observation next is [22.55, 85.5, 1.0, 2.0, 0.2391809633431625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3866578753727997, 6.9112, 6.9112, 121.9260426156618, 575107.6568329857, 575107.6568329857, 178330.752045351], 
processed observation next is [1.0, 0.21739130434782608, 0.3907407407407408, 0.855, 1.0, 1.0, 0.09426305159900297, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.23332234421599962, 0.0, 0.0, 0.8094621288201359, 0.2053955917260663, 0.2053955917260663, 0.3429437539333673], 
reward next is 0.6571, 
noisyNet noise sample is [array([-2.417261], dtype=float32), -1.0435916]. 
=============================================
[2019-03-24 03:44:15,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6202152e-16 1.1095398e-03 9.9888307e-01 1.7353178e-13 7.3695060e-06], sum to 1.0000
[2019-03-24 03:44:15,919] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7240
[2019-03-24 03:44:15,925] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.65, 28.16666666666667, 1.0, 2.0, 0.5372355044657842, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8852248133692924, 6.9112, 6.9112, 121.9260426156618, 1323691.217368432, 1323691.217368432, 266575.4803051224], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2455800.0000, 
sim time next is 2456400.0000, 
raw observation next is [31.9, 27.33333333333334, 1.0, 2.0, 0.5327291283300661, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8779498992653951, 6.911199999999999, 6.9112, 121.9260426156618, 1312794.834120858, 1312794.834120859, 264941.8363388332], 
processed observation next is [1.0, 0.43478260869565216, 0.7370370370370369, 0.2733333333333334, 1.0, 1.0, 0.44372515277388824, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8474373740817439, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46885529790030644, 0.4688552979003068, 0.509503531420833], 
reward next is 0.4905, 
noisyNet noise sample is [array([-0.24851839], dtype=float32), -0.081103355]. 
=============================================
[2019-03-24 03:44:17,182] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 03:44:17,183] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:44:17,184] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:44:17,184] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:44:17,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:44:17,188] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:44:17,190] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:44:17,191] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:44:17,191] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:44:17,192] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:44:17,192] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:44:17,215] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-24 03:44:17,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-24 03:44:17,265] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-24 03:44:17,265] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-24 03:44:17,312] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-24 03:44:35,750] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:44:35,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.27880295, 87.51007754333332, 1.0, 2.0, 0.1708061458799013, 0.0, 2.0, 0.0, 1.0, 2.0, 0.28922620041102, 6.911199999999999, 6.9112, 121.9260426156618, 429313.6694793352, 429313.6694793357, 159939.6701510448]
[2019-03-24 03:44:35,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:44:35,755] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.49053212e-17 1.07622895e-04 9.99891162e-01 6.79501392e-15
 1.15955424e-06], sampled 0.6225097191292376
[2019-03-24 03:45:04,124] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:04,125] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.91666666666667, 61.66666666666667, 1.0, 2.0, 0.2827569403335753, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4504302337920311, 6.9112, 6.9112, 121.9260426156618, 649796.6159697763, 649796.6159697763, 190576.6765694586]
[2019-03-24 03:45:04,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:45:04,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.1300717e-18 6.9654525e-05 9.9992979e-01 1.5363997e-15 6.2861631e-07], sampled 0.9326836343190918
[2019-03-24 03:45:22,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:22,666] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 70.0, 1.0, 2.0, 0.2411082562560288, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3886291675690832, 6.911199999999999, 6.9112, 121.9260426156618, 576679.1919144675, 576679.191914468, 179017.3361763571]
[2019-03-24 03:45:22,666] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:45:22,668] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.1013381e-18 7.2209172e-05 9.9992704e-01 1.7423793e-15 6.6280359e-07], sampled 0.3351789298513074
[2019-03-24 03:45:38,757] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:38,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.09930711, 73.40444933666667, 1.0, 2.0, 0.4101093867050608, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6529074999647277, 6.911200000000001, 6.9112, 121.9260426156618, 934900.9390765537, 934900.9390765532, 227243.6954211844]
[2019-03-24 03:45:38,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:45:38,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0013002e-18 5.8239726e-05 9.9994123e-01 8.3443429e-16 4.8895095e-07], sampled 0.164594517261075
[2019-03-24 03:45:40,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:40,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.78333333333333, 49.66666666666667, 1.0, 2.0, 0.1759074158201669, 0.0, 2.0, 0.0, 1.0, 2.0, 0.299320289163951, 6.911200000000001, 6.9112, 121.9260426156618, 443377.4776359532, 443377.4776359527, 160777.6833939945]
[2019-03-24 03:45:40,524] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:45:40,528] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4491866e-16 1.5379128e-04 9.9984431e-01 2.2946297e-14 1.9144015e-06], sampled 0.1359394631579014
[2019-03-24 03:45:47,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:47,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.264499685, 78.66602291999999, 1.0, 2.0, 0.1673130240292733, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2838006429636063, 6.911199999999999, 6.9112, 121.9260426156618, 420957.4171597121, 420957.4171597125, 159105.296908915]
[2019-03-24 03:45:47,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:45:47,478] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3094148e-17 9.7134667e-05 9.9990189e-01 4.7734508e-15 1.0019119e-06], sampled 0.43556602085704477
[2019-03-24 03:45:52,519] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9651828]
[2019-03-24 03:45:52,520] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.471246055, 93.763072635, 1.0, 2.0, 0.5112176176028721, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8138750964192368, 6.911199999999999, 6.9112, 121.9260426156618, 1165566.411307902, 1165566.411307902, 260911.758563312]
[2019-03-24 03:45:52,520] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:45:52,524] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.5707547e-18 7.1044218e-05 9.9992836e-01 1.6294585e-15 6.4364292e-07], sampled 0.7642323717682097
[2019-03-24 03:45:55,494] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6579.3748 2661639446.3792 110.0000
[2019-03-24 03:45:55,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6808.9140 2600748519.4866 61.0000
[2019-03-24 03:45:55,702] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7156.8066 2831345996.4491 211.0000
[2019-03-24 03:45:55,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.2041 2623842640.6097 97.0000
[2019-03-24 03:45:55,756] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7491.3894 2565899626.2703 47.0000
[2019-03-24 03:45:56,771] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1975000, evaluation results [1975000.0, 7156.806551419947, 2831345996.449108, 211.0, 6808.91400862387, 2600748519.4866486, 61.0, 7491.389414027946, 2565899626.270307, 47.0, 6579.374828341298, 2661639446.3792276, 110.0, 7162.204054848555, 2623842640.6096983, 97.0]
[2019-03-24 03:45:58,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2617168e-17 6.2673971e-05 9.9993634e-01 5.9155095e-15 9.9632564e-07], sum to 1.0000
[2019-03-24 03:45:58,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6447
[2019-03-24 03:45:58,135] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.25, 50.0, 1.0, 2.0, 0.1896512500692879, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3150319015070572, 6.911199999999999, 6.9112, 121.9260426156618, 470376.8291250355, 470376.829125036, 165108.9358178735], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2507400.0000, 
sim time next is 2508000.0000, 
raw observation next is [26.16666666666666, 50.33333333333334, 1.0, 2.0, 0.1902287426312736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.316049062181786, 6.9112, 6.9112, 121.9260426156618, 471880.0692645998, 471880.0692645998, 165225.5984169093], 
processed observation next is [1.0, 0.0, 0.5246913580246911, 0.5033333333333334, 1.0, 1.0, 0.0359865983705638, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14506132772723251, 0.0, 0.0, 0.8094621288201359, 0.1685285961659285, 0.1685285961659285, 0.3177415354171333], 
reward next is 0.6823, 
noisyNet noise sample is [array([-0.10381437], dtype=float32), -1.6356379]. 
=============================================
[2019-03-24 03:45:58,152] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[52.933453]
 [53.40311 ]
 [53.570354]
 [54.209805]
 [55.85785 ]], R is [[52.6388588 ]
 [52.79495621]
 [52.94963074]
 [53.10241318]
 [53.2533989 ]].
[2019-03-24 03:46:02,801] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0703859e-22 2.1230392e-07 9.9999976e-01 4.9937845e-19 1.3121018e-09], sum to 1.0000
[2019-03-24 03:46:02,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7556
[2019-03-24 03:46:02,811] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.3, 87.66666666666667, 1.0, 2.0, 0.23692334001312, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3829490388027844, 6.911199999999999, 6.9112, 121.9260426156618, 569528.2011578555, 569528.2011578559, 177795.956522452], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2596800.0000, 
sim time next is 2597400.0000, 
raw observation next is [22.15, 88.5, 1.0, 2.0, 0.2361053242862538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3817919297574996, 6.911199999999999, 6.9112, 121.9260426156618, 567974.3782852221, 567974.3782852226, 177567.0968466277], 
processed observation next is [0.0, 0.043478260869565216, 0.3759259259259259, 0.885, 1.0, 1.0, 0.09060157653125453, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.22723991219687448, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2028479922447222, 0.20284799224472236, 0.3414751862435148], 
reward next is 0.6585, 
noisyNet noise sample is [array([-0.8646158], dtype=float32), 0.5534293]. 
=============================================
[2019-03-24 03:46:10,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7768051e-24 5.6424362e-08 1.0000000e+00 2.1096402e-22 7.9791616e-12], sum to 1.0000
[2019-03-24 03:46:10,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1774
[2019-03-24 03:46:10,373] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.85, 50.16666666666667, 1.0, 2.0, 0.3029485423074186, 0.0, 2.0, 0.0, 1.0, 2.0, 0.482303945698628, 6.911199999999999, 6.9112, 121.9260426156618, 690502.9683938372, 690502.9683938377, 196039.7380674798], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2736600.0000, 
sim time next is 2737200.0000, 
raw observation next is [31.7, 51.33333333333334, 1.0, 2.0, 0.3055053622851743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4863744863730284, 6.911199999999999, 6.9112, 121.9260426156618, 696333.3104685412, 696333.3104685417, 196730.7521667136], 
processed observation next is [0.0, 0.6956521739130435, 0.7296296296296296, 0.5133333333333334, 1.0, 1.0, 0.17322066938711222, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3579681079662854, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.248690468024479, 0.24869046802447917, 0.3783283695513723], 
reward next is 0.6217, 
noisyNet noise sample is [array([0.3121702], dtype=float32), 2.1448371]. 
=============================================
[2019-03-24 03:46:15,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6388910e-11 2.0661044e-04 9.9974436e-01 3.4323805e-10 4.8925071e-05], sum to 1.0000
[2019-03-24 03:46:15,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7230
[2019-03-24 03:46:15,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2806901.277900824 W.
[2019-03-24 03:46:15,501] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.9, 55.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.846796543565026, 6.9112, 121.9223802475728, 2806901.277900824, 2327806.616220855, 443048.6980128029], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2824200.0000, 
sim time next is 2824800.0000, 
raw observation next is [32.86666666666667, 54.33333333333333, 1.0, 2.0, 0.761586980942349, 1.0, 2.0, 0.6941581524476091, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2375699.596621035, 2375699.596621035, 446199.5410758594], 
processed observation next is [1.0, 0.6956521739130435, 0.7728395061728395, 0.5433333333333333, 1.0, 1.0, 0.7161749773123203, 1.0, 1.0, 0.6359025624376299, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8484641416503697, 0.8484641416503697, 0.8580760405304988], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37062833], dtype=float32), 1.6826897]. 
=============================================
[2019-03-24 03:46:31,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3066956e-15 2.9775637e-07 3.3452598e-05 1.7348544e-14 9.9996626e-01], sum to 1.0000
[2019-03-24 03:46:31,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6363
[2019-03-24 03:46:31,774] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 55.5, 1.0, 2.0, 0.254864718534619, 1.0, 2.0, 0.254864718534619, 1.0, 2.0, 0.4070387559268978, 6.911199999999999, 6.9112, 121.94756008, 892063.2978970179, 892063.2978970184, 239309.5945214528], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3137400.0000, 
sim time next is 3138000.0000, 
raw observation next is [28.86666666666667, 54.66666666666666, 1.0, 2.0, 0.2496919736166688, 1.0, 2.0, 0.2496919736166688, 1.0, 2.0, 0.3983252706030546, 6.9112, 6.9112, 121.94756008, 869286.9636303011, 869286.9636303011, 237506.7740317142], 
processed observation next is [1.0, 0.30434782608695654, 0.6246913580246916, 0.5466666666666665, 1.0, 1.0, 0.10677615906746286, 1.0, 1.0, 0.10677615906746286, 1.0, 1.0, 0.24790658825381826, 0.0, 0.0, 0.8096049824067558, 0.31045962986796466, 0.31045962986796466, 0.45674379621483496], 
reward next is 0.5433, 
noisyNet noise sample is [array([-0.5885658], dtype=float32), 1.3782499]. 
=============================================
[2019-03-24 03:46:31,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.95329 ]
 [50.965446]
 [51.088043]
 [51.132263]
 [51.086315]], R is [[51.06515503]
 [51.0942955 ]
 [51.13414383]
 [51.19145203]
 [51.26298523]].
[2019-03-24 03:46:42,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3404200e-16 1.2315537e-07 2.3196651e-05 1.4614776e-14 9.9997663e-01], sum to 1.0000
[2019-03-24 03:46:42,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0582
[2019-03-24 03:46:42,563] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.2165584113056906, 1.0, 2.0, 0.2165584113056906, 1.0, 2.0, 0.344768043613733, 6.9112, 6.9112, 121.94756008, 740418.2156249266, 740418.2156249266, 226079.8688108369], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3327000.0000, 
sim time next is 3327600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.2175144463579937, 1.0, 2.0, 0.2175144463579937, 1.0, 2.0, 0.3462900825528875, 6.9112, 6.9112, 121.94756008, 743688.5069319748, 743688.5069319748, 226401.2531968743], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.06846957899761154, 1.0, 1.0, 0.06846957899761154, 1.0, 1.0, 0.18286260319110936, 0.0, 0.0, 0.8096049824067558, 0.265603038189991, 0.265603038189991, 0.43538702537860446], 
reward next is 0.5646, 
noisyNet noise sample is [array([-0.47167006], dtype=float32), -1.0863736]. 
=============================================
[2019-03-24 03:46:47,276] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 03:46:47,277] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:46:47,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:46:47,278] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:46:47,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:46:47,281] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:46:47,281] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:46:47,282] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:46:47,281] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:46:47,283] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:46:47,287] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:46:47,303] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-24 03:46:47,325] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-24 03:46:47,354] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-24 03:46:47,355] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-24 03:46:47,397] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-24 03:46:57,766] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:46:57,768] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.083985295, 66.178321805, 1.0, 2.0, 0.2954006483779866, 1.0, 2.0, 0.2954006483779866, 1.0, 2.0, 0.4731994057176809, 6.911199999999999, 6.9112, 122.1617793552429, 1044871.995301852, 1044871.995301852, 254188.275642515]
[2019-03-24 03:46:57,769] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:46:57,771] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3344765e-13 2.9628270e-06 8.7934859e-05 5.5813097e-12 9.9990904e-01], sampled 0.6571865067915315
[2019-03-24 03:47:45,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:47:45,979] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 84.0, 1.0, 2.0, 0.3268917452143595, 1.0, 2.0, 0.3268917452143595, 1.0, 2.0, 0.5204223045021577, 6.911200000000001, 6.9112, 121.94756008, 1117925.533736353, 1117925.533736352, 266539.6826235864]
[2019-03-24 03:47:45,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:47:45,984] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.0457421e-15 5.8528167e-07 2.6373567e-05 2.1373691e-13 9.9997306e-01], sampled 0.7890826826763447
[2019-03-24 03:47:47,576] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:47:47,577] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.54876648, 88.88022479, 1.0, 2.0, 0.2046472948890033, 1.0, 2.0, 0.2046472948890033, 1.0, 2.0, 0.3258051583603871, 6.9112, 6.9112, 121.94756008, 699675.2509105526, 699675.2509105526, 222118.6618334016]
[2019-03-24 03:47:47,577] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:47:47,579] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1930703e-14 7.9134082e-07 3.2998221e-05 3.9219997e-13 9.9996626e-01], sampled 0.5390499263475315
[2019-03-24 03:48:07,641] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:48:07,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.60042149, 57.33325978000001, 1.0, 2.0, 0.3799396850230154, 1.0, 2.0, 0.3799396850230154, 1.0, 2.0, 0.6048763523283238, 6.9112, 6.9112, 121.94756008, 1299496.152224676, 1299496.152224676, 288406.1510362155]
[2019-03-24 03:48:07,643] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:48:07,644] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0734180e-13 2.0982693e-06 6.8063171e-05 2.7892163e-12 9.9992979e-01], sampled 0.23826004817112978
[2019-03-24 03:48:08,040] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:48:08,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.5, 86.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2505345654306699, 6.911199999999999, 6.9112, 121.94756008, 556671.8934106737, 556671.8934106742, 205460.0230055001]
[2019-03-24 03:48:08,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:48:08,044] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2628272e-14 8.1155468e-07 3.3632859e-05 4.1260842e-13 9.9996555e-01], sampled 0.6248043108629188
[2019-03-24 03:48:21,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.97385776]
[2019-03-24 03:48:21,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.7, 43.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 361750.0800845729, 361750.0800845729, 168864.6645530585]
[2019-03-24 03:48:21,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:48:21,391] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.1282227e-14 1.7494641e-06 5.9479906e-05 1.9352965e-12 9.9993873e-01], sampled 0.12075764530222921
[2019-03-24 03:48:27,280] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4490.0995 2940755003.8805 28.0000
[2019-03-24 03:48:27,295] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4608.5815 2894659252.5298 12.0000
[2019-03-24 03:48:27,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4275.9573 2920133254.0848 33.0000
[2019-03-24 03:48:27,338] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4510.8774 3107552039.9913 0.0000
[2019-03-24 03:48:27,387] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.1813 2875918929.5409 8.0000
[2019-03-24 03:48:28,405] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2000000, evaluation results [2000000.0, 4510.87741702582, 3107552039.9912515, 0.0, 4608.581536012648, 2894659252.529829, 12.0, 4392.181277017246, 2875918929.540856, 8.0, 4490.099507670705, 2940755003.880525, 28.0, 4275.9572757857495, 2920133254.084834, 33.0]
[2019-03-24 03:48:28,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1734452e-15 3.0289502e-07 2.4938952e-05 1.4765103e-13 9.9997473e-01], sum to 1.0000
[2019-03-24 03:48:28,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6813
[2019-03-24 03:48:28,762] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.46666666666667, 59.66666666666667, 1.0, 2.0, 0.6114906021549561, 1.0, 2.0, 0.6114906021549561, 1.0, 2.0, 0.9735129534892736, 6.9112, 6.9112, 121.94756008, 2092445.170169986, 2092445.170169986, 401671.8039234482], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3418800.0000, 
sim time next is 3419400.0000, 
raw observation next is [30.33333333333333, 59.83333333333333, 1.0, 2.0, 0.6089690084030401, 1.0, 2.0, 0.6089690084030401, 1.0, 2.0, 0.9694984941136483, 6.911200000000001, 6.9112, 121.94756008, 2083806.522128229, 2083806.522128228, 400284.0259178426], 
processed observation next is [1.0, 0.5652173913043478, 0.6790123456790121, 0.5983333333333333, 1.0, 1.0, 0.5344869147655239, 1.0, 1.0, 0.5344869147655239, 1.0, 1.0, 0.9618731176420603, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7442166150457961, 0.7442166150457957, 0.769776972918928], 
reward next is 0.2302, 
noisyNet noise sample is [array([0.30230936], dtype=float32), 0.16718534]. 
=============================================
[2019-03-24 03:48:28,945] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3274345e-15 3.8066412e-07 1.1360062e-05 3.7908451e-13 9.9998832e-01], sum to 1.0000
[2019-03-24 03:48:28,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1979
[2019-03-24 03:48:28,955] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.3, 61.5, 1.0, 2.0, 0.6514154364213288, 1.0, 2.0, 0.639072380187099, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2186942.164849267, 2186942.164849267, 416439.7328119846], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3425400.0000, 
sim time next is 3426000.0000, 
raw observation next is [31.06666666666667, 62.33333333333333, 1.0, 2.0, 0.6232883457548732, 1.0, 2.0, 0.6232883457548732, 1.0, 2.0, 0.9922953455260266, 6.911200000000001, 6.9112, 121.94756008, 2132863.7957927, 2132863.795792699, 408210.209305667], 
processed observation next is [1.0, 0.6521739130434783, 0.7061728395061729, 0.6233333333333333, 1.0, 1.0, 0.5515337449462776, 1.0, 1.0, 0.5515337449462776, 1.0, 1.0, 0.9903691819075333, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7617370699259642, 0.7617370699259639, 0.7850196332801289], 
reward next is 0.2150, 
noisyNet noise sample is [array([0.61333436], dtype=float32), -0.8034603]. 
=============================================
[2019-03-24 03:48:28,976] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[45.443157]
 [45.164814]
 [45.171215]
 [44.83916 ]
 [44.96204 ]], R is [[45.45121384]
 [45.19585419]
 [44.93948746]
 [44.71292114]
 [44.44412613]].
[2019-03-24 03:48:30,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2353233e-14 5.2951981e-07 7.5164331e-05 2.5362709e-12 9.9992430e-01], sum to 1.0000
[2019-03-24 03:48:30,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4864
[2019-03-24 03:48:30,751] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.1942675916729967, 1.0, 2.0, 0.1942675916729967, 1.0, 2.0, 0.3092803327971709, 6.9112, 6.9112, 121.94756008, 664172.3777996188, 664172.3777996188, 218731.5035216659], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3629400.0000, 
sim time next is 3630000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.1950901723540477, 1.0, 2.0, 0.1950901723540477, 1.0, 2.0, 0.3105899080309866, 6.9112, 6.9112, 121.94756008, 666985.8835808282, 666985.8835808282, 218997.7313064385], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.04177401470719962, 1.0, 1.0, 0.04177401470719962, 1.0, 1.0, 0.1382373850387332, 0.0, 0.0, 0.8096049824067558, 0.23820924413601008, 0.23820924413601008, 0.4211494832816125], 
reward next is 0.5789, 
noisyNet noise sample is [array([0.8754592], dtype=float32), -0.09651904]. 
=============================================
[2019-03-24 03:48:30,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[40.66892 ]
 [41.185867]
 [42.395325]
 [42.401703]
 [42.42042 ]], R is [[40.82048798]
 [40.99164581]
 [41.16188049]
 [41.33240128]
 [41.50318146]].
[2019-03-24 03:48:36,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8881469e-16 4.6212222e-07 1.8383391e-05 1.3666982e-14 9.9998116e-01], sum to 1.0000
[2019-03-24 03:48:36,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6693
[2019-03-24 03:48:36,985] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 94.0, 1.0, 2.0, 0.2643078533636837, 1.0, 2.0, 0.2643078533636837, 1.0, 2.0, 0.4207867104608194, 6.911199999999998, 6.9112, 121.94756008, 903770.8973776852, 903770.8973776861, 242756.0395595197], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3744000.0000, 
sim time next is 3744600.0000, 
raw observation next is [25.5, 94.00000000000001, 1.0, 2.0, 0.362598610597316, 1.0, 2.0, 0.362598610597316, 1.0, 2.0, 0.5772687970832442, 6.9112, 6.9112, 122.5299911778874, 1240132.229295961, 1240132.229295961, 281207.6547726682], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 0.9400000000000002, 1.0, 1.0, 0.24118882213966192, 1.0, 1.0, 0.24118882213966192, 1.0, 1.0, 0.4715859963540552, 0.0, 0.0, 0.8134717192110751, 0.4429043676057004, 0.4429043676057004, 0.5407839514859004], 
reward next is 0.4592, 
noisyNet noise sample is [array([-0.4696944], dtype=float32), -0.32504362]. 
=============================================
[2019-03-24 03:48:38,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2569373e-18 1.2963577e-09 3.3892178e-07 5.2498017e-17 9.9999964e-01], sum to 1.0000
[2019-03-24 03:48:38,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8161
[2019-03-24 03:48:38,519] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.190069027260957, 1.0, 2.0, 0.190069027260957, 1.0, 2.0, 0.3026561144806969, 6.9112, 6.9112, 121.94756008, 652143.7673110531, 652143.7673110531, 217385.522858728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3609000.0000, 
sim time next is 3609600.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.1905839381799107, 1.0, 2.0, 0.1905839381799107, 1.0, 2.0, 0.3034753129420676, 6.9112, 6.9112, 121.94756008, 653888.6953075031, 653888.6953075031, 217550.9301937445], 
processed observation next is [1.0, 0.782608695652174, 0.48148148148148145, 0.83, 1.0, 1.0, 0.036409450214179406, 1.0, 1.0, 0.036409450214179406, 1.0, 1.0, 0.12934414117758447, 0.0, 0.0, 0.8096049824067558, 0.23353167689553683, 0.23353167689553683, 0.4183671734495087], 
reward next is 0.5816, 
noisyNet noise sample is [array([-0.39482576], dtype=float32), -0.4304067]. 
=============================================
[2019-03-24 03:48:48,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3080448e-18 1.4165040e-07 6.1508719e-05 7.6577909e-16 9.9993837e-01], sum to 1.0000
[2019-03-24 03:48:48,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8212
[2019-03-24 03:48:48,846] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 59.0, 1.0, 2.0, 0.2212532692749316, 1.0, 2.0, 0.2212532692749316, 1.0, 2.0, 0.3522424104016141, 6.911200000000001, 6.9112, 121.94756008, 756477.9628392037, 756477.9628392032, 227663.0198886369], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3792600.0000, 
sim time next is 3793200.0000, 
raw observation next is [30.33333333333334, 59.0, 1.0, 2.0, 0.2177770285409394, 1.0, 2.0, 0.2177770285409394, 1.0, 2.0, 0.3467081219398418, 6.9112, 6.9112, 121.94756008, 744586.7193591255, 744586.7193591255, 226489.6133309758], 
processed observation next is [1.0, 0.9130434782608695, 0.6790123456790126, 0.59, 1.0, 1.0, 0.06878217683445165, 1.0, 1.0, 0.06878217683445165, 1.0, 1.0, 0.18338515242480222, 0.0, 0.0, 0.8096049824067558, 0.2659238283425448, 0.2659238283425448, 0.435556948713415], 
reward next is 0.5644, 
noisyNet noise sample is [array([0.89789605], dtype=float32), 0.15618889]. 
=============================================
[2019-03-24 03:48:49,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.317196e-17 3.632932e-07 5.043644e-05 1.128385e-15 9.999492e-01], sum to 1.0000
[2019-03-24 03:48:49,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5184
[2019-03-24 03:48:49,520] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.11666666666667, 82.0, 1.0, 2.0, 0.212276827968371, 1.0, 2.0, 0.212276827968371, 1.0, 2.0, 0.3379516234992859, 6.9112, 6.9112, 121.94756008, 725772.4543290271, 725772.4543290271, 224646.8287934972], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3805800.0000, 
sim time next is 3806400.0000, 
raw observation next is [26.23333333333333, 80.0, 1.0, 2.0, 0.2118304585228934, 1.0, 2.0, 0.2118304585228934, 1.0, 2.0, 0.3372409888048475, 6.911199999999999, 6.9112, 121.94756008, 724245.6006203077, 724245.6006203082, 224498.0199864571], 
processed observation next is [0.0, 0.043478260869565216, 0.5271604938271603, 0.8, 1.0, 1.0, 0.06170292681296832, 1.0, 1.0, 0.06170292681296832, 1.0, 1.0, 0.17155123600605934, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2586591430786813, 0.2586591430786815, 0.4317269615124175], 
reward next is 0.5683, 
noisyNet noise sample is [array([0.22606818], dtype=float32), -0.3414868]. 
=============================================
[2019-03-24 03:48:49,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9040788e-18 2.3884607e-07 5.9171966e-06 3.3388564e-16 9.9999380e-01], sum to 1.0000
[2019-03-24 03:48:49,893] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1497
[2019-03-24 03:48:49,896] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 58.5, 1.0, 2.0, 0.1964430085806185, 1.0, 2.0, 0.1964430085806185, 1.0, 2.0, 0.3127436673624872, 6.911200000000001, 6.9112, 121.94756008, 671613.0661787089, 671613.0661787085, 219436.4000576046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3832200.0000, 
sim time next is 3832800.0000, 
raw observation next is [29.66666666666667, 58.66666666666666, 1.0, 2.0, 0.1989730451996359, 1.0, 2.0, 0.1989730451996359, 1.0, 2.0, 0.3167715680575031, 6.9112, 6.9112, 121.94756008, 680266.7690993943, 680266.7690993943, 220259.5366561834], 
processed observation next is [0.0, 0.34782608695652173, 0.6543209876543211, 0.5866666666666666, 1.0, 1.0, 0.04639648238051893, 1.0, 1.0, 0.04639648238051893, 1.0, 1.0, 0.14596446007187888, 0.0, 0.0, 0.8096049824067558, 0.24295241753549798, 0.24295241753549798, 0.42357603203112193], 
reward next is 0.5764, 
noisyNet noise sample is [array([0.05481691], dtype=float32), -0.30950576]. 
=============================================
[2019-03-24 03:48:57,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5109531e-18 4.3333230e-09 1.8305545e-06 1.1828749e-15 9.9999821e-01], sum to 1.0000
[2019-03-24 03:48:57,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-24 03:48:57,386] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.2509550099603459, 1.0, 2.0, 0.2509550099603459, 1.0, 2.0, 0.3995285488909558, 6.9112, 6.9112, 121.94756008, 858086.7992624801, 858086.7992624801, 237964.3384796517], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.2537729721493308, 1.0, 2.0, 0.2537729721493308, 1.0, 2.0, 0.4040148364704412, 6.9112, 6.9112, 121.94756008, 867727.6697988128, 867727.6697988128, 238967.2826943071], 
processed observation next is [0.0, 0.9130434782608695, 0.5679012345679014, 0.8733333333333333, 1.0, 1.0, 0.11163449065396525, 1.0, 1.0, 0.11163449065396525, 1.0, 1.0, 0.2550185455880514, 0.0, 0.0, 0.8096049824067558, 0.30990273921386174, 0.30990273921386174, 0.45955246671982136], 
reward next is 0.5404, 
noisyNet noise sample is [array([-1.3290871], dtype=float32), 1.4909451]. 
=============================================
[2019-03-24 03:48:57,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[57.497772]
 [57.465065]
 [57.47998 ]
 [57.48166 ]
 [57.47544 ]], R is [[57.46860886]
 [57.43630219]
 [57.40154266]
 [57.36932755]
 [57.33375549]].
[2019-03-24 03:48:57,595] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5625151e-17 9.1314448e-08 8.5895945e-06 1.4053759e-14 9.9999130e-01], sum to 1.0000
[2019-03-24 03:48:57,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2555
[2019-03-24 03:48:57,610] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.76666666666667, 87.0, 1.0, 2.0, 0.2448082351082577, 1.0, 2.0, 0.2448082351082577, 1.0, 2.0, 0.3897426831399503, 6.9112, 6.9112, 121.94756008, 837057.7466687036, 837057.7466687036, 235792.0225319469], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3968400.0000, 
sim time next is 3969000.0000, 
raw observation next is [26.65, 86.0, 1.0, 2.0, 0.2404142565677389, 1.0, 2.0, 0.2404142565677389, 1.0, 2.0, 0.3827473262015538, 6.911200000000001, 6.9112, 121.94756008, 822025.630687538, 822025.6306875375, 234252.09601918], 
processed observation next is [0.0, 0.9565217391304348, 0.5425925925925925, 0.86, 1.0, 1.0, 0.09573125781873679, 1.0, 1.0, 0.09573125781873679, 1.0, 1.0, 0.2284341577519422, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2935805823884064, 0.29358058238840623, 0.4504848000368846], 
reward next is 0.5495, 
noisyNet noise sample is [array([0.56731194], dtype=float32), -1.0400542]. 
=============================================
[2019-03-24 03:48:57,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[52.236687]
 [52.237335]
 [52.259277]
 [52.2501  ]
 [52.237934]], R is [[52.2627182 ]
 [52.2866478 ]
 [52.30709457]
 [52.32469559]
 [52.34156036]].
[2019-03-24 03:48:58,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3889175e-14 1.5532338e-07 9.5784362e-06 2.3834754e-13 9.9999022e-01], sum to 1.0000
[2019-03-24 03:48:58,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8718
[2019-03-24 03:48:58,777] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.66666666666667, 90.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2469556221258648, 6.9112, 6.9112, 121.94756008, 550303.0952800784, 550303.0952800784, 204018.5687106771], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4148400.0000, 
sim time next is 4149000.0000, 
raw observation next is [21.5, 91.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2456604178693336, 6.9112, 6.9112, 121.94756008, 547604.2082060198, 547604.2082060198, 203581.9669720404], 
processed observation next is [1.0, 0.0, 0.35185185185185186, 0.91, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05707552233666698, 0.0, 0.0, 0.8096049824067558, 0.19557293150214994, 0.19557293150214994, 0.3915037826385392], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0654217], dtype=float32), -0.9869027]. 
=============================================
[2019-03-24 03:48:58,795] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[43.637344]
 [43.31535 ]
 [43.55568 ]
 [44.517204]
 [44.53197 ]], R is [[43.52664185]
 [43.09137726]
 [42.66046524]
 [42.23386002]
 [41.81152344]].
[2019-03-24 03:49:00,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1078650e-13 1.0842098e-06 4.1786938e-05 1.9022346e-11 9.9995708e-01], sum to 1.0000
[2019-03-24 03:49:00,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0905
[2019-03-24 03:49:00,117] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.6, 94.0, 1.0, 2.0, 0.4369762049170162, 1.0, 2.0, 0.4369762049170162, 1.0, 2.0, 0.6956803495493438, 6.911200000000001, 6.9112, 121.94756008, 1494766.761792128, 1494766.761792127, 313658.3545795695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4006800.0000, 
sim time next is 4007400.0000, 
raw observation next is [24.66666666666667, 94.00000000000001, 1.0, 2.0, 0.4519567307866141, 1.0, 2.0, 0.4519567307866141, 1.0, 2.0, 0.7195298346154104, 6.9112, 6.9112, 121.94756008, 1546062.445530677, 1546062.445530677, 320589.3455577784], 
processed observation next is [1.0, 0.391304347826087, 0.469135802469136, 0.9400000000000002, 1.0, 1.0, 0.3475675366507311, 1.0, 1.0, 0.3475675366507311, 1.0, 1.0, 0.6494122932692631, 0.0, 0.0, 0.8096049824067558, 0.5521651591180989, 0.5521651591180989, 0.6165179722264968], 
reward next is 0.3835, 
noisyNet noise sample is [array([-3.1254802], dtype=float32), 1.2424303]. 
=============================================
[2019-03-24 03:49:03,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0857836e-11 1.0638309e-05 4.5767829e-05 9.5470687e-11 9.9994361e-01], sum to 1.0000
[2019-03-24 03:49:03,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4545
[2019-03-24 03:49:03,801] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.1, 97.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2450830934397731, 6.9112, 6.9112, 121.94756008, 548343.0038544441, 548343.0038544441, 202579.7326124596], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4081200.0000, 
sim time next is 4081800.0000, 
raw observation next is [20.05, 98.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2417253859177231, 6.9112, 6.9112, 121.94756008, 540690.138067408, 540690.138067408, 201677.4992759141], 
processed observation next is [1.0, 0.21739130434782608, 0.29814814814814816, 0.9883333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05215673239715387, 0.0, 0.0, 0.8096049824067558, 0.19310362073836, 0.19310362073836, 0.3878413447613733], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.102497], dtype=float32), -0.5049144]. 
=============================================
[2019-03-24 03:49:08,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1481626e-18 1.2079653e-02 9.8792017e-01 3.2737487e-16 1.5512909e-07], sum to 1.0000
[2019-03-24 03:49:08,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3013
[2019-03-24 03:49:08,754] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.98333333333333, 99.83333333333334, 1.0, 2.0, 0.2661481008613349, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4342249511075533, 6.911199999999999, 6.9112, 121.9260426156618, 648464.8019015584, 648464.8019015589, 184343.6065826303], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4162200.0000, 
sim time next is 4162800.0000, 
raw observation next is [19.96666666666667, 99.66666666666667, 1.0, 2.0, 0.2593752959306937, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4232378208839551, 6.911199999999999, 6.9112, 121.9260426156618, 632071.5619682084, 632071.5619682089, 182633.2246121576], 
processed observation next is [1.0, 0.17391304347826086, 0.2950617283950618, 0.9966666666666667, 1.0, 1.0, 0.1183039237270163, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.27904727610494384, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22573984356007443, 0.2257398435600746, 0.35121773963876457], 
reward next is 0.6488, 
noisyNet noise sample is [array([-0.16693243], dtype=float32), -0.5372406]. 
=============================================
[2019-03-24 03:49:08,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5239572e-16 3.4743767e-02 9.6525615e-01 3.3253542e-16 9.5563166e-08], sum to 1.0000
[2019-03-24 03:49:08,863] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5122
[2019-03-24 03:49:08,871] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 95.0, 1.0, 2.0, 0.592308778727789, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9429748658848477, 6.9112, 6.9112, 121.9260426156618, 1350615.7028795, 1350615.7028795, 290878.0747381854], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.5645528846184258, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8987865785163782, 6.911199999999999, 6.9112, 121.9260426156618, 1287271.97313129, 1287271.973131291, 280320.8653211442], 
processed observation next is [1.0, 0.43478260869565216, 0.4444444444444444, 0.94, 1.0, 1.0, 0.48161057692669734, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8734832231454728, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45973999040403213, 0.4597399904040325, 0.5390785871560466], 
reward next is 0.4609, 
noisyNet noise sample is [array([1.9748377], dtype=float32), 0.27754518]. 
=============================================
[2019-03-24 03:49:09,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9030356e-11 2.2752332e-03 9.9754936e-01 4.5066412e-10 1.7545928e-04], sum to 1.0000
[2019-03-24 03:49:09,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2701
[2019-03-24 03:49:09,806] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.63333333333333, 47.16666666666667, 1.0, 2.0, 0.9543786273480561, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9946277191908636, 6.911200000000001, 6.9112, 121.9260426156618, 1806805.368314899, 1806805.368314899, 368516.5658294624], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4189800.0000, 
sim time next is 4190400.0000, 
raw observation next is [32.0, 46.0, 1.0, 2.0, 0.9764664321643435, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9961885869705687, 6.911199999999999, 6.9112, 121.9260426156618, 1830239.671844691, 1830239.671844691, 373764.9936950295], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.46, 1.0, 1.0, 0.9719838478146946, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9952357337132108, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6536570256588182, 0.6536570256588182, 0.718778834028903], 
reward next is 0.2812, 
noisyNet noise sample is [array([0.4568037], dtype=float32), -1.4127276]. 
=============================================
[2019-03-24 03:49:18,898] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:49:18,901] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:49:18,902] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:49:18,903] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:49:18,905] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:49:18,905] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:49:18,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:49:18,908] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:49:18,908] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:49:18,911] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:49:18,912] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:49:19,039] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-24 03:49:19,066] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-24 03:49:19,094] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-24 03:49:19,127] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-24 03:49:19,150] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-24 03:50:01,868] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:01,870] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 96.0, 1.0, 2.0, 0.2844991330140491, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4539834806075185, 6.9112, 6.9112, 121.9260426156618, 661204.5293118174, 661204.5293118174, 190834.1598190436]
[2019-03-24 03:50:01,871] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:50:01,872] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.7627958e-13 2.0539982e-03 9.3831247e-01 1.0374334e-11 5.9633583e-02], sampled 0.24088574655910722
[2019-03-24 03:50:29,561] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:29,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.4, 90.0, 1.0, 2.0, 0.3573157469104793, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5690309045169739, 6.911199999999999, 6.9112, 121.9260426156618, 818565.1845376892, 818565.1845376897, 211228.6412983138]
[2019-03-24 03:50:29,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:50:29,567] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6009837e-13 1.7125683e-03 9.4168591e-01 5.1308753e-12 5.6601465e-02], sampled 0.40476540704882547
[2019-03-24 03:50:30,101] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:30,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.08333333333334, 68.66666666666667, 1.0, 2.0, 0.30521157351955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4859067650901224, 6.9112, 6.9112, 121.9260426156618, 695663.3787637168, 695663.3787637168, 196653.4028530096]
[2019-03-24 03:50:30,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:50:30,105] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.7879942e-13 1.8638071e-03 9.3992102e-01 7.1606566e-12 5.8215242e-02], sampled 0.7924871012446518
[2019-03-24 03:50:37,084] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:37,085] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.66666666666667, 67.33333333333334, 1.0, 2.0, 0.4086487955324372, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6505821912497775, 6.911199999999999, 6.9112, 121.9260426156618, 931569.2962063731, 931569.2962063736, 226788.8077778579]
[2019-03-24 03:50:37,086] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:50:37,089] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2842629e-13 2.0840308e-03 9.3683332e-01 1.1251225e-11 6.1082624e-02], sampled 0.9898578518082516
[2019-03-24 03:50:46,031] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:46,032] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 74.0, 1.0, 2.0, 0.2956412612921673, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4707121369997599, 6.9112, 6.9112, 121.9260426156618, 675063.8189338614, 675063.8189338614, 194060.5473707226]
[2019-03-24 03:50:46,035] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:50:46,037] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6121094e-13 1.5494175e-03 9.4507378e-01 3.3383222e-12 5.3376835e-02], sampled 0.525301142639682
[2019-03-24 03:50:54,117] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.98380905]
[2019-03-24 03:50:54,118] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.16666666666667, 94.83333333333333, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2387126899486136, 6.911199999999999, 6.9112, 121.9260426156618, 348523.5657796933, 348523.5657796937, 149219.4513998535]
[2019-03-24 03:50:54,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:50:54,125] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8852126e-13 2.0532249e-03 9.3762654e-01 1.0592570e-11 6.0320307e-02], sampled 0.15169204441673567
[2019-03-24 03:50:57,539] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6877.2929 2583657769.7577 46.0000
[2019-03-24 03:50:57,722] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6095.9409 2677337002.8509 109.0000
[2019-03-24 03:50:57,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6328.5103 2616509876.0438 63.0000
[2019-03-24 03:50:57,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6589.6524 2640669973.4430 95.0000
[2019-03-24 03:50:58,087] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6616.4586 2846034318.2828 192.0000
[2019-03-24 03:50:59,103] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2025000, evaluation results [2025000.0, 6616.458550595872, 2846034318.2828436, 192.0, 6328.510299678049, 2616509876.0438485, 63.0, 6877.292889803579, 2583657769.7577105, 46.0, 6095.940901861473, 2677337002.850858, 109.0, 6589.652422585511, 2640669973.4430385, 95.0]
[2019-03-24 03:51:01,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3086570e-18 6.9967464e-06 5.4462982e-04 3.7513302e-15 9.9944836e-01], sum to 1.0000
[2019-03-24 03:51:01,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9069
[2019-03-24 03:51:01,718] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.78333333333333, 78.16666666666666, 1.0, 2.0, 0.182930963654913, 1.0, 2.0, 0.182930963654913, 1.0, 2.0, 0.2919404001746438, 6.911199999999999, 6.9112, 121.94756008, 638060.1860996357, 638060.1860996361, 215048.1865940137], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4402200.0000, 
sim time next is 4402800.0000, 
raw observation next is [24.5, 78.0, 1.0, 2.0, 0.1775733758974586, 1.0, 2.0, 0.1775733758974586, 1.0, 2.0, 0.2837947863753126, 6.911200000000001, 6.9112, 121.94756008, 623142.741540294, 623142.7415402936, 213293.6256955096], 
processed observation next is [1.0, 1.0, 0.46296296296296297, 0.78, 1.0, 1.0, 0.02092068559221263, 1.0, 1.0, 0.02092068559221263, 1.0, 1.0, 0.10474348296914071, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22255097912153357, 0.2225509791215334, 0.4101800494144415], 
reward next is 0.5898, 
noisyNet noise sample is [array([-0.7461443], dtype=float32), -0.051085394]. 
=============================================
[2019-03-24 03:51:10,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0493099e-17 1.4536095e-05 1.8070393e-03 7.2133495e-15 9.9817848e-01], sum to 1.0000
[2019-03-24 03:51:10,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1794
[2019-03-24 03:51:10,692] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.95, 98.0, 1.0, 2.0, 0.1761393392533283, 1.0, 2.0, 0.1761393392533283, 1.0, 2.0, 0.2814157284123264, 6.911200000000001, 6.9112, 121.94756008, 617366.2855580108, 617366.2855580103, 212857.1708916687], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4577400.0000, 
sim time next is 4578000.0000, 
raw observation next is [21.63333333333333, 98.66666666666666, 1.0, 2.0, 0.1721281492706404, 1.0, 2.0, 0.1721281492706404, 1.0, 2.0, 0.275375961975464, 6.9112, 6.9112, 121.94756008, 606237.9822475468, 606237.9822475468, 211541.0203751023], 
processed observation next is [0.0, 1.0, 0.35679012345678995, 0.9866666666666666, 1.0, 1.0, 0.014438272941238577, 1.0, 1.0, 0.014438272941238577, 1.0, 1.0, 0.09421995246932997, 0.0, 0.0, 0.8096049824067558, 0.21651356508840958, 0.21651356508840958, 0.4068096545675044], 
reward next is 0.5932, 
noisyNet noise sample is [array([-0.9279645], dtype=float32), 1.459192]. 
=============================================
[2019-03-24 03:51:10,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.75234 ]
 [53.74556 ]
 [53.75759 ]
 [53.785294]
 [53.794704]], R is [[53.81992722]
 [53.87238693]
 [53.92187119]
 [53.96859741]
 [54.01327896]].
[2019-03-24 03:51:11,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1935532e-15 3.6490958e-06 9.4550208e-04 8.9364171e-14 9.9905080e-01], sum to 1.0000
[2019-03-24 03:51:11,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0484
[2019-03-24 03:51:11,012] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.3, 99.0, 1.0, 2.0, 0.1871929652752959, 1.0, 2.0, 0.1871929652752959, 1.0, 2.0, 0.2998677137233148, 6.911200000000001, 6.9112, 121.94756008, 661995.3785384973, 661995.3785384968, 216233.9548336621], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4588200.0000, 
sim time next is 4588800.0000, 
raw observation next is [21.2, 99.33333333333333, 1.0, 2.0, 0.1731709088216605, 1.0, 2.0, 0.1731709088216605, 1.0, 2.0, 0.2776903755517405, 6.9112, 6.9112, 121.94756008, 614139.9423856403, 614139.9423856403, 211751.0867848386], 
processed observation next is [1.0, 0.08695652173913043, 0.34074074074074073, 0.9933333333333333, 1.0, 1.0, 0.015679653359119642, 1.0, 1.0, 0.015679653359119642, 1.0, 1.0, 0.09711296943967558, 0.0, 0.0, 0.8096049824067558, 0.21933569370915726, 0.21933569370915726, 0.40721362843238196], 
reward next is 0.5928, 
noisyNet noise sample is [array([0.39615858], dtype=float32), 1.357925]. 
=============================================
[2019-03-24 03:51:19,566] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3634319e-19 6.6394669e-08 1.7212700e-05 4.2329454e-18 9.9998271e-01], sum to 1.0000
[2019-03-24 03:51:19,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5037
[2019-03-24 03:51:19,582] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.46666666666667, 84.33333333333334, 1.0, 2.0, 0.2230686989473892, 1.0, 2.0, 0.2230686989473892, 1.0, 2.0, 0.3551326335645834, 6.911200000000001, 6.9112, 121.94756008, 762688.1113187153, 762688.1113187148, 228278.5057038727], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [26.35, 85.5, 1.0, 2.0, 0.223388553059011, 1.0, 2.0, 0.223388553059011, 1.0, 2.0, 0.3556418517272065, 6.9112, 6.9112, 121.94756008, 763782.2605537758, 763782.2605537758, 228387.1369613368], 
processed observation next is [1.0, 0.8695652173913043, 0.5314814814814816, 0.855, 1.0, 1.0, 0.0754625631654893, 1.0, 1.0, 0.0754625631654893, 1.0, 1.0, 0.19455231465900813, 0.0, 0.0, 0.8096049824067558, 0.27277937876920566, 0.27277937876920566, 0.4392060326179554], 
reward next is 0.5608, 
noisyNet noise sample is [array([-0.36471412], dtype=float32), 0.25728893]. 
=============================================
[2019-03-24 03:51:25,066] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6398655e-17 3.4536885e-07 1.2587369e-04 1.0463918e-13 9.9987376e-01], sum to 1.0000
[2019-03-24 03:51:25,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-24 03:51:25,079] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 93.16666666666666, 1.0, 2.0, 0.2380709663770223, 1.0, 2.0, 0.2380709663770223, 1.0, 2.0, 0.3790167319022992, 6.9112, 6.9112, 121.94756008, 814009.1872601752, 814009.1872601752, 233435.2707817011], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4830600.0000, 
sim time next is 4831200.0000, 
raw observation next is [26.0, 93.0, 1.0, 2.0, 0.2373843841555424, 1.0, 2.0, 0.2373843841555424, 1.0, 2.0, 0.3779236706452815, 6.9112, 6.9112, 121.94756008, 811660.3913880205, 811660.3913880205, 233196.5229184025], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.93, 1.0, 1.0, 0.09212426685183618, 1.0, 1.0, 0.09212426685183618, 1.0, 1.0, 0.22240458830660184, 0.0, 0.0, 0.8096049824067558, 0.2898787112100073, 0.2898787112100073, 0.4484548517661587], 
reward next is 0.5515, 
noisyNet noise sample is [array([-0.9017737], dtype=float32), 1.1074208]. 
=============================================
[2019-03-24 03:51:25,497] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3961555e-15 4.1280382e-06 7.7319310e-05 7.2226789e-13 9.9991858e-01], sum to 1.0000
[2019-03-24 03:51:25,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-24 03:51:25,510] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.86666666666667, 93.33333333333334, 1.0, 2.0, 0.373116398729114, 1.0, 2.0, 0.373116398729114, 1.0, 2.0, 0.5940134583295119, 6.911199999999999, 6.9112, 121.94756008, 1276139.236928958, 1276139.236928958, 285505.9881371551], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4868400.0000, 
sim time next is 4869000.0000, 
raw observation next is [25.9, 93.5, 1.0, 2.0, 0.4105606635486146, 1.0, 2.0, 0.4105606635486146, 1.0, 2.0, 0.6536259473967262, 6.9112, 6.9112, 121.94756008, 1404324.14989576, 1404324.14989576, 301739.1887521708], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.935, 1.0, 1.0, 0.2982865042245412, 1.0, 1.0, 0.2982865042245412, 1.0, 1.0, 0.5670324342459077, 0.0, 0.0, 0.8096049824067558, 0.5015443392484857, 0.5015443392484857, 0.5802676706772516], 
reward next is 0.4197, 
noisyNet noise sample is [array([0.08333598], dtype=float32), 0.21171145]. 
=============================================
[2019-03-24 03:51:25,524] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[44.89226 ]
 [45.48382 ]
 [45.521145]
 [45.345608]
 [45.24324 ]], R is [[44.60939026]
 [44.61424637]
 [44.69321442]
 [44.78631592]
 [44.86822891]].
[2019-03-24 03:51:29,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.3120905e-14 1.7841498e-05 2.5068452e-03 7.5990967e-12 9.9747533e-01], sum to 1.0000
[2019-03-24 03:51:29,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8467
[2019-03-24 03:51:29,058] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 90.0, 1.0, 2.0, 0.2690714173190217, 1.0, 2.0, 0.2690714173190217, 1.0, 2.0, 0.4283704594161648, 6.9112, 6.9112, 121.94756008, 920069.1430247745, 920069.1430247745, 244489.5447484641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4921200.0000, 
sim time next is 4921800.0000, 
raw observation next is [27.58333333333333, 89.0, 1.0, 2.0, 0.2651580497455334, 1.0, 2.0, 0.2651580497455334, 1.0, 2.0, 0.4221402507896871, 6.9112, 6.9112, 121.94756008, 906679.7674138856, 906679.7674138856, 243064.5054426941], 
processed observation next is [1.0, 1.0, 0.5771604938271603, 0.89, 1.0, 1.0, 0.12518815445896836, 1.0, 1.0, 0.12518815445896836, 1.0, 1.0, 0.27767531348710883, 0.0, 0.0, 0.8096049824067558, 0.3238142026478163, 0.3238142026478163, 0.46743174123595016], 
reward next is 0.5326, 
noisyNet noise sample is [array([-2.3687847], dtype=float32), 1.4682021]. 
=============================================
[2019-03-24 03:51:29,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9724525e-16 3.0200590e-07 1.4272411e-04 3.8620205e-15 9.9985695e-01], sum to 1.0000
[2019-03-24 03:51:29,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6424
[2019-03-24 03:51:29,636] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.35, 92.0, 1.0, 2.0, 0.2685159967189133, 1.0, 2.0, 0.2685159967189133, 1.0, 2.0, 0.427486211732006, 6.9112, 6.9112, 121.94756008, 918168.7872232953, 918168.7872232953, 244286.769814794], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4919400.0000, 
sim time next is 4920000.0000, 
raw observation next is [27.46666666666667, 91.33333333333334, 1.0, 2.0, 0.2687384498220372, 1.0, 2.0, 0.2687384498220372, 1.0, 2.0, 0.427840364316971, 6.9112, 6.9112, 121.94756008, 918929.9036292004, 918929.9036292004, 244367.9631196104], 
processed observation next is [1.0, 0.9565217391304348, 0.5728395061728396, 0.9133333333333334, 1.0, 1.0, 0.12945053550242525, 1.0, 1.0, 0.12945053550242525, 1.0, 1.0, 0.2848004553962137, 0.0, 0.0, 0.8096049824067558, 0.328189251296143, 0.328189251296143, 0.4699383906146354], 
reward next is 0.5301, 
noisyNet noise sample is [array([1.8882848], dtype=float32), -1.4315441]. 
=============================================
[2019-03-24 03:51:29,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.661575]
 [52.619026]
 [52.559597]
 [52.48275 ]
 [52.343803]], R is [[52.67886353]
 [52.68229294]
 [52.68525314]
 [52.68733215]
 [52.68840408]].
[2019-03-24 03:51:30,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2848550e-18 4.8391780e-07 2.1816630e-05 8.2606846e-16 9.9997771e-01], sum to 1.0000
[2019-03-24 03:51:30,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8901
[2019-03-24 03:51:30,597] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.93333333333333, 94.0, 1.0, 2.0, 0.2424128794060817, 1.0, 2.0, 0.2424128794060817, 1.0, 2.0, 0.3859291988507971, 6.911199999999999, 6.9112, 121.94756008, 828863.0263304878, 828863.0263304883, 234951.2016662145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5103600.0000, 
sim time next is 5104200.0000, 
raw observation next is [25.91666666666666, 94.0, 1.0, 2.0, 0.2425931391285098, 1.0, 2.0, 0.2425931391285098, 1.0, 2.0, 0.386216178199552, 6.9112, 6.9112, 121.94756008, 829479.7074818163, 829479.7074818163, 235014.3651152815], 
processed observation next is [0.0, 0.043478260869565216, 0.5154320987654318, 0.94, 1.0, 1.0, 0.09832516562917833, 1.0, 1.0, 0.09832516562917833, 1.0, 1.0, 0.23277022274943998, 0.0, 0.0, 0.8096049824067558, 0.2962427526720772, 0.2962427526720772, 0.45195070214477207], 
reward next is 0.5480, 
noisyNet noise sample is [array([0.77024055], dtype=float32), 1.1297984]. 
=============================================
[2019-03-24 03:51:32,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8072659e-10 9.1463582e-05 2.1677290e-03 7.3396345e-10 9.9774086e-01], sum to 1.0000
[2019-03-24 03:51:32,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1395
[2019-03-24 03:51:32,336] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 78.16666666666667, 1.0, 2.0, 0.5659901591419337, 1.0, 2.0, 0.5659901591419337, 1.0, 2.0, 0.9010747663665662, 6.911199999999999, 6.9112, 121.94756008, 1936579.493100313, 1936579.493100313, 377156.9080248009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4981800.0000, 
sim time next is 4982400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.588629362603205, 1.0, 2.0, 0.588629362603205, 1.0, 2.0, 0.9371171155842927, 6.911200000000001, 6.9112, 121.94756008, 2014128.62988215, 2014128.62988215, 389215.0973446175], 
processed observation next is [1.0, 0.6956521739130435, 0.5925925925925926, 0.79, 1.0, 1.0, 0.5102730507181011, 1.0, 1.0, 0.5102730507181011, 1.0, 1.0, 0.9213963944803657, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7193316535293394, 0.7193316535293394, 0.7484905718165721], 
reward next is 0.2515, 
noisyNet noise sample is [array([-0.05037373], dtype=float32), -1.8074908]. 
=============================================
[2019-03-24 03:51:32,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3066662e-11 1.4992150e-04 1.9638641e-03 1.6519444e-10 9.9788624e-01], sum to 1.0000
[2019-03-24 03:51:32,790] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7849
[2019-03-24 03:51:32,795] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.73333333333333, 81.0, 1.0, 2.0, 0.4724818976304616, 1.0, 2.0, 0.4724818976304616, 1.0, 2.0, 0.7522065686888322, 6.911199999999999, 6.9112, 121.94756008, 1616344.258851386, 1616344.258851387, 330286.96868904], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4977600.0000, 
sim time next is 4978200.0000, 
raw observation next is [27.36666666666667, 77.5, 1.0, 2.0, 0.4885903405817174, 1.0, 2.0, 0.4885903405817174, 1.0, 2.0, 0.7778517344825929, 6.9112, 6.9112, 121.94756008, 1671502.228439095, 1671502.228439095, 338024.3352168941], 
processed observation next is [1.0, 0.6086956521739131, 0.569135802469136, 0.775, 1.0, 1.0, 0.39117897688299696, 1.0, 1.0, 0.39117897688299696, 1.0, 1.0, 0.7223146681032411, 0.0, 0.0, 0.8096049824067558, 0.5969650815853911, 0.5969650815853911, 0.6500467984940271], 
reward next is 0.3500, 
noisyNet noise sample is [array([-0.24564666], dtype=float32), -0.024424667]. 
=============================================
[2019-03-24 03:51:37,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2957155e-16 1.0504752e-06 3.4415719e-04 2.0361823e-15 9.9965477e-01], sum to 1.0000
[2019-03-24 03:51:37,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4531
[2019-03-24 03:51:37,197] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333333, 82.33333333333334, 1.0, 2.0, 0.2712396976840887, 1.0, 2.0, 0.2712396976840887, 1.0, 2.0, 0.4318224323733128, 6.911199999999999, 6.9112, 121.94756008, 927487.8977829638, 927487.8977829642, 245282.796076341], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [28.8, 82.0, 1.0, 2.0, 0.2692124613631705, 1.0, 2.0, 0.2692124613631705, 1.0, 2.0, 0.4285950061279333, 6.9112, 6.9112, 121.94756008, 920551.7219643234, 920551.7219643234, 244541.0650204371], 
processed observation next is [0.0, 0.8695652173913043, 0.6222222222222222, 0.82, 1.0, 1.0, 0.13001483495615537, 1.0, 1.0, 0.13001483495615537, 1.0, 1.0, 0.28574375765991655, 0.0, 0.0, 0.8096049824067558, 0.3287684721301155, 0.3287684721301155, 0.47027127888545595], 
reward next is 0.5297, 
noisyNet noise sample is [array([-0.07203344], dtype=float32), 1.0992076]. 
=============================================
[2019-03-24 03:51:46,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6988336e-11 4.2095430e-06 1.6918452e-04 1.1433968e-10 9.9982661e-01], sum to 1.0000
[2019-03-24 03:51:46,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0640
[2019-03-24 03:51:46,538] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.41666666666667, 68.16666666666667, 1.0, 2.0, 0.6143294648081016, 1.0, 2.0, 0.6143294648081016, 1.0, 2.0, 0.9780325152883833, 6.911199999999999, 6.9112, 121.94756008, 2102170.839667814, 2102170.839667815, 403238.2863386812], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5235000.0000, 
sim time next is 5235600.0000, 
raw observation next is [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.6211901435290652, 1.0, 2.0, 0.6211901435290652, 1.0, 2.0, 0.9889549392488642, 6.9112, 6.9112, 121.94756008, 2125675.300185118, 2125675.300185118, 407041.8974432159], 
processed observation next is [1.0, 0.6086956521739131, 0.6419753086419755, 0.6933333333333335, 1.0, 1.0, 0.5490358851536491, 1.0, 1.0, 0.5490358851536491, 1.0, 1.0, 0.9861936740610802, 0.0, 0.0, 0.8096049824067558, 0.7591697500661135, 0.7591697500661135, 0.7827728796984921], 
reward next is 0.2172, 
noisyNet noise sample is [array([1.4600176], dtype=float32), -0.02727231]. 
=============================================
[2019-03-24 03:51:49,611] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 03:51:49,613] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:51:49,613] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:51:49,614] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:49,614] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:49,615] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:51:49,615] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:51:49,615] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:49,616] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:51:49,616] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:49,617] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:49,641] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-24 03:51:49,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-24 03:51:49,692] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-24 03:51:49,692] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-24 03:51:49,716] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-24 03:51:56,594] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:51:56,595] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.8, 74.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 350260.0380501198, 350260.0380501198, 166948.3981733044]
[2019-03-24 03:51:56,597] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:51:56,600] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2807738e-18 1.5917186e-08 5.5840593e-07 2.8976023e-16 9.9999940e-01], sampled 0.5511721913312493
[2019-03-24 03:52:01,158] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:52:01,159] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.75975773333333, 20.58842613, 1.0, 2.0, 0.3314088907951948, 1.0, 2.0, 0.3314088907951948, 1.0, 2.0, 0.5393895639484632, 6.9112, 6.9112, 121.94756008, 1207903.44976985, 1207903.44976985, 267348.6356579615]
[2019-03-24 03:52:01,160] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:52:01,163] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.2384170e-18 2.1267800e-08 7.0822426e-07 5.1982888e-16 9.9999928e-01], sampled 0.8797460781340669
[2019-03-24 03:52:16,364] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:52:16,364] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.16666666666667, 90.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2331974086134021, 6.911199999999999, 6.9112, 121.94756008, 521374.2317933571, 521374.2317933576, 199310.8582862098]
[2019-03-24 03:52:16,365] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:52:16,367] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7212078e-18 1.6599909e-08 5.7842465e-07 3.1624137e-16 9.9999940e-01], sampled 0.9514411617258028
[2019-03-24 03:52:23,203] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:52:23,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.714521855, 98.41055660500001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2379476165683734, 6.9112, 6.9112, 121.94756008, 530869.9837533607, 530869.9837533607, 201162.9242080214]
[2019-03-24 03:52:23,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:52:23,209] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0818086e-18 8.6459915e-09 3.3875665e-07 8.4869796e-17 9.9999964e-01], sampled 0.5213884412937291
[2019-03-24 03:52:33,944] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:52:33,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.1, 52.66666666666667, 1.0, 2.0, 0.4913797357497756, 1.0, 2.0, 0.4913797357497756, 1.0, 2.0, 0.7822925424344, 6.911200000000001, 6.9112, 121.94756008, 1681053.924133173, 1681053.924133173, 339378.2506423513]
[2019-03-24 03:52:33,947] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:52:33,949] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.14283555e-17 2.45820644e-08 7.97580469e-07 6.96244936e-16
 9.99999166e-01], sampled 0.19848827600050123
[2019-03-24 03:52:40,375] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:52:40,377] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.03197888, 106.2554658, 1.0, 2.0, 0.2454796607422003, 1.0, 2.0, 0.2454796607422003, 1.0, 2.0, 0.3908116146159932, 6.9112, 6.9112, 121.94756008, 839354.767919291, 839354.767919291, 236028.2824684813]
[2019-03-24 03:52:40,379] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:52:40,386] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4840254e-18 9.9459907e-09 3.7997455e-07 1.1254535e-16 9.9999964e-01], sampled 0.8477743261931839
[2019-03-24 03:53:00,688] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:53:00,688] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.16666666666666, 80.16666666666667, 1.0, 2.0, 0.5421932043630487, 1.0, 2.0, 0.5421932043630487, 1.0, 2.0, 0.8631892393458707, 6.9112, 6.9112, 121.94756008, 1855071.810744067, 1855071.810744067, 364780.3041788157]
[2019-03-24 03:53:00,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:53:00,692] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4656181e-17 4.0257149e-08 1.1937944e-06 1.8743327e-15 9.9999881e-01], sampled 0.18276070184666415
[2019-03-24 03:53:14,417] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:53:14,418] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 37.5, 1.0, 2.0, 0.2684080754092221, 1.0, 2.0, 0.2684080754092221, 1.0, 2.0, 0.439549754181111, 6.911200000000001, 6.9112, 121.94756008, 985470.1989174592, 985470.1989174588, 242854.0270316332]
[2019-03-24 03:53:14,419] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:53:14,422] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1939272e-17 2.5075320e-08 8.1045039e-07 7.2396086e-16 9.9999917e-01], sampled 0.2700742085374108
[2019-03-24 03:53:20,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:53:20,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 60.0, 1.0, 2.0, 0.2319254340519414, 1.0, 2.0, 0.2319254340519414, 1.0, 2.0, 0.3696926644765781, 6.9112, 6.9112, 121.94756008, 803623.7010614894, 803623.7010614894, 231312.838982046]
[2019-03-24 03:53:20,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:53:20,990] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.9960418e-19 7.1260526e-09 2.8914170e-07 5.7515013e-17 9.9999976e-01], sampled 0.3908925412517218
[2019-03-24 03:53:21,659] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:53:21,660] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.83333333333334, 88.0, 1.0, 2.0, 0.6651538112642086, 1.0, 2.0, 0.6459415676085389, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 125.4178771165802, 2210402.312547082, 2210402.312547082, 421005.6571744797]
[2019-03-24 03:53:21,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:53:21,664] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1816731e-17 3.2807399e-08 1.0090776e-06 1.2398891e-15 9.9999893e-01], sampled 0.5201150886676361
[2019-03-24 03:53:24,167] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 0.9966027]
[2019-03-24 03:53:24,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.07841392333334, 62.43241048, 1.0, 2.0, 0.1639191138506336, 1.0, 2.0, 0.1639191138506336, 1.0, 2.0, 0.2630300640279449, 6.9112, 6.9112, 121.94756008, 582325.3886034747, 582325.3886034747, 208853.8934434084]
[2019-03-24 03:53:24,169] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:53:24,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7859983e-19 4.7357060e-09 2.0692264e-07 2.5281915e-17 9.9999976e-01], sampled 0.7590922932312294
[2019-03-24 03:53:28,370] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.1813 2875918929.5409 8.0000
[2019-03-24 03:53:28,843] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4489.4114 2940779206.0371 28.0000
[2019-03-24 03:53:29,031] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.0871 2894700717.8337 12.0000
[2019-03-24 03:53:29,111] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4510.8774 3107552039.9913 0.0000
[2019-03-24 03:53:29,123] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4275.9573 2920152679.8633 33.0000
[2019-03-24 03:53:30,140] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2050000, evaluation results [2050000.0, 4510.87741702582, 3107552039.9912515, 0.0, 4609.087071503921, 2894700717.8336563, 12.0, 4392.181277017246, 2875918929.540856, 8.0, 4489.411365254514, 2940779206.037067, 28.0, 4275.9572757857495, 2920152679.8633223, 33.0]
[2019-03-24 03:53:30,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8996239e-14 1.6110820e-06 9.4813149e-06 6.5040126e-12 9.9998891e-01], sum to 1.0000
[2019-03-24 03:53:30,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-24 03:53:30,949] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.3511235584608446, 1.0, 2.0, 0.3511235584608446, 1.0, 2.0, 0.5594434537125565, 6.9112, 6.9112, 121.94756008, 1212845.056647518, 1212845.056647518, 276384.582112268], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5305800.0000, 
sim time next is 5306400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.3376508492938935, 1.0, 2.0, 0.3376508492938935, 1.0, 2.0, 0.5378856164284913, 6.9112, 6.9112, 121.94756008, 1164508.655570065, 1164508.655570065, 270890.9405703784], 
processed observation next is [1.0, 0.43478260869565216, 0.43703703703703706, 0.85, 1.0, 1.0, 0.21148910630225418, 1.0, 1.0, 0.21148910630225418, 1.0, 1.0, 0.4223570205356141, 0.0, 0.0, 0.8096049824067558, 0.4158959484178803, 0.4158959484178803, 0.5209441164814969], 
reward next is 0.4791, 
noisyNet noise sample is [array([-0.03616499], dtype=float32), 0.120477095]. 
=============================================
[2019-03-24 03:53:32,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0024225e-16 4.4912518e-08 5.0431947e-07 5.8732045e-15 9.9999940e-01], sum to 1.0000
[2019-03-24 03:53:32,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5998
[2019-03-24 03:53:32,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.23333333333334, 68.66666666666667, 1.0, 2.0, 0.2021794914967133, 1.0, 2.0, 0.2021794914967133, 1.0, 2.0, 0.3218763349891159, 6.9112, 6.9112, 121.94756008, 691234.19483477, 691234.19483477, 221307.8896660051], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5336400.0000, 
sim time next is 5337000.0000, 
raw observation next is [28.2, 69.0, 1.0, 2.0, 0.2038414100505557, 1.0, 2.0, 0.2038414100505557, 1.0, 2.0, 0.3245221634517416, 6.9112, 6.9112, 121.94756008, 696918.7329680707, 696918.7329680707, 221853.5215425008], 
processed observation next is [1.0, 0.782608695652174, 0.6, 0.69, 1.0, 1.0, 0.052192154822090116, 1.0, 1.0, 0.052192154822090116, 1.0, 1.0, 0.155652704314677, 0.0, 0.0, 0.8096049824067558, 0.24889954748859666, 0.24889954748859666, 0.4266413875817323], 
reward next is 0.5734, 
noisyNet noise sample is [array([-0.92053086], dtype=float32), 0.22615536]. 
=============================================
[2019-03-24 03:53:32,134] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[48.110687]
 [48.149128]
 [48.094875]
 [48.093605]
 [48.154793]], R is [[48.0261116 ]
 [48.12026215]
 [48.21416855]
 [48.3074646 ]
 [48.40119934]].
[2019-03-24 03:53:34,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1045028e-16 3.2047012e-08 3.7942488e-07 2.7764870e-15 9.9999964e-01], sum to 1.0000
[2019-03-24 03:53:34,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-24 03:53:34,669] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.43333333333333, 91.00000000000001, 1.0, 2.0, 0.2868405069125433, 1.0, 2.0, 0.2868405069125433, 1.0, 2.0, 0.4566594287478979, 6.9112, 6.9112, 121.94756008, 980868.0648504586, 980868.0648504586, 251067.5742445572], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5379000.0000, 
sim time next is 5379600.0000, 
raw observation next is [24.46666666666667, 91.0, 1.0, 2.0, 0.2209904433549586, 1.0, 2.0, 0.2209904433549586, 1.0, 2.0, 0.3518239829773745, 6.9112, 6.9112, 121.94756008, 755578.9027189281, 755578.9027189281, 227574.0666731588], 
processed observation next is [1.0, 0.2608695652173913, 0.46172839506172847, 0.91, 1.0, 1.0, 0.072607670660665, 1.0, 1.0, 0.072607670660665, 1.0, 1.0, 0.1897799787217181, 0.0, 0.0, 0.8096049824067558, 0.2698496081139029, 0.2698496081139029, 0.4376424359099208], 
reward next is 0.5624, 
noisyNet noise sample is [array([1.540193], dtype=float32), 0.6104116]. 
=============================================
[2019-03-24 03:53:37,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7428494e-18 3.4155512e-10 1.0025129e-08 1.6206970e-16 1.0000000e+00], sum to 1.0000
[2019-03-24 03:53:37,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3100
[2019-03-24 03:53:37,905] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.7, 92.0, 1.0, 2.0, 0.2482529845440405, 1.0, 2.0, 0.2482529845440405, 1.0, 2.0, 0.3952268364293735, 6.911199999999999, 6.9112, 121.94756008, 848842.6878815256, 848842.6878815261, 237006.822825979], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5446800.0000, 
sim time next is 5447400.0000, 
raw observation next is [26.63333333333333, 92.16666666666667, 1.0, 2.0, 0.2475836629020743, 1.0, 2.0, 0.2475836629020743, 1.0, 2.0, 0.3941612545770791, 6.911199999999999, 6.9112, 121.94756008, 846552.8362676454, 846552.8362676458, 236770.2658290619], 
processed observation next is [1.0, 0.043478260869565216, 0.5419753086419752, 0.9216666666666667, 1.0, 1.0, 0.10426626535961224, 1.0, 1.0, 0.10426626535961224, 1.0, 1.0, 0.2427015682213489, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.30234029866701617, 0.30234029866701634, 0.45532743428665745], 
reward next is 0.5447, 
noisyNet noise sample is [array([-0.5840586], dtype=float32), -0.18730573]. 
=============================================
[2019-03-24 03:53:39,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.57414810e-17 4.42046790e-08 2.14554049e-07 1.10533395e-14
 9.99999762e-01], sum to 1.0000
[2019-03-24 03:53:39,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3318
[2019-03-24 03:53:39,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 94.5, 1.0, 2.0, 0.2948027508060266, 1.0, 2.0, 0.2948027508060266, 1.0, 2.0, 0.4693355803385036, 6.911199999999999, 6.9112, 121.94756008, 1008113.335199531, 1008113.335199531, 254072.2824581752], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5463000.0000, 
sim time next is 5463600.0000, 
raw observation next is [26.36666666666667, 94.33333333333334, 1.0, 2.0, 0.3015138862879022, 1.0, 2.0, 0.3015138862879022, 1.0, 2.0, 0.4800199265920732, 6.911199999999999, 6.9112, 121.94756008, 1031078.304947575, 1031078.304947575, 256632.302446108], 
processed observation next is [1.0, 0.21739130434782608, 0.5320987654320989, 0.9433333333333335, 1.0, 1.0, 0.16846891224750263, 1.0, 1.0, 0.16846891224750263, 1.0, 1.0, 0.35002490824009147, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.36824225176699105, 0.36824225176699105, 0.4935236585502077], 
reward next is 0.5065, 
noisyNet noise sample is [array([-0.6611973], dtype=float32), -1.3708676]. 
=============================================
[2019-03-24 03:53:40,920] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1899343e-13 4.8530075e-07 1.7644868e-05 2.4206132e-11 9.9998188e-01], sum to 1.0000
[2019-03-24 03:53:40,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0806
[2019-03-24 03:53:40,932] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.7, 65.0, 1.0, 2.0, 0.8955440449304289, 1.0, 2.0, 0.7611366844416491, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2605262.646663761, 2605262.64666376, 485919.3741499584], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5494800.0000, 
sim time next is 5495400.0000, 
raw observation next is [32.35, 66.0, 1.0, 2.0, 0.9228723064367282, 1.0, 2.0, 0.7748008151947989, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2652102.509087862, 2652102.509087862, 494498.9693075407], 
processed observation next is [1.0, 0.6086956521739131, 0.7537037037037038, 0.66, 1.0, 1.0, 0.9081813171865812, 1.0, 1.0, 0.7319057323747606, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.9471794675313793, 0.9471794675313793, 0.9509595563606552], 
reward next is 0.0490, 
noisyNet noise sample is [array([3.5907507], dtype=float32), -0.44260824]. 
=============================================
[2019-03-24 03:53:49,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9649028e-17 3.6682131e-09 1.5058754e-07 4.0120891e-16 9.9999988e-01], sum to 1.0000
[2019-03-24 03:53:49,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9434
[2019-03-24 03:53:49,195] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.86666666666667, 59.66666666666667, 1.0, 2.0, 0.3895534781984358, 1.0, 2.0, 0.3895534781984358, 1.0, 2.0, 0.6201818241629782, 6.9112, 6.9112, 121.94756008, 1332406.510863199, 1332406.510863199, 292536.2223681067], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6180600.0000, 
sim time next is 6181200.0000, 
raw observation next is [29.0, 59.0, 1.0, 2.0, 0.3653131397212344, 1.0, 2.0, 0.3653131397212344, 1.0, 2.0, 0.581590415854564, 6.9112, 6.9112, 121.94756008, 1249428.632018439, 1249428.632018439, 282220.9727215528], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.59, 1.0, 1.0, 0.24442040443004098, 1.0, 1.0, 0.24442040443004098, 1.0, 1.0, 0.4769880198182049, 0.0, 0.0, 0.8096049824067558, 0.4462245114351568, 0.4462245114351568, 0.54273263984914], 
reward next is 0.4573, 
noisyNet noise sample is [array([-0.6831625], dtype=float32), 1.0755824]. 
=============================================
[2019-03-24 03:53:52,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4766283e-18 5.5657194e-09 7.5304222e-08 4.0646972e-16 9.9999988e-01], sum to 1.0000
[2019-03-24 03:53:52,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7279
[2019-03-24 03:53:52,711] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.16666666666667, 96.66666666666666, 1.0, 2.0, 0.1763061361263637, 1.0, 2.0, 0.1763061361263637, 1.0, 2.0, 0.2816824803591828, 6.9112, 6.9112, 121.94756008, 617953.4271733775, 617953.4271733775, 212909.4624532972], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5708400.0000, 
sim time next is 5709000.0000, 
raw observation next is [22.08333333333334, 96.83333333333334, 1.0, 2.0, 0.1748553617218961, 1.0, 2.0, 0.1748553617218961, 1.0, 2.0, 0.2794618630406659, 6.911199999999999, 6.9112, 121.94756008, 613691.8293474992, 613691.8293474995, 212439.0285444106], 
processed observation next is [0.0, 0.043478260869565216, 0.373456790123457, 0.9683333333333334, 1.0, 1.0, 0.017684954430828702, 1.0, 1.0, 0.017684954430828702, 1.0, 1.0, 0.09932732880083235, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.21917565333839256, 0.2191756533383927, 0.40853659335463577], 
reward next is 0.5915, 
noisyNet noise sample is [array([1.4502015], dtype=float32), -1.0318632]. 
=============================================
[2019-03-24 03:53:52,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.49333 ]
 [49.592213]
 [49.67576 ]
 [49.65486 ]
 [49.73261 ]], R is [[49.46128845]
 [49.5572319 ]
 [49.65123749]
 [49.74337769]
 [49.83385849]].
[2019-03-24 03:53:58,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7859884e-14 5.5904047e-07 7.0715185e-05 2.4149760e-13 9.9992871e-01], sum to 1.0000
[2019-03-24 03:53:58,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0760
[2019-03-24 03:53:58,480] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.81666666666667, 80.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2603378779865874, 6.9112, 6.9112, 121.94756008, 583314.362169801, 583314.362169801, 206393.3187042637], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5983800.0000, 
sim time next is 5984400.0000, 
raw observation next is [21.93333333333333, 79.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2551206785940068, 6.9112, 6.9112, 121.94756008, 571518.473607876, 571518.473607876, 204981.9231161718], 
processed observation next is [1.0, 0.2608695652173913, 0.36790123456790114, 0.7966666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.06890084824250846, 0.0, 0.0, 0.8096049824067558, 0.20411374057424142, 0.20411374057424142, 0.39419600599263804], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9286246], dtype=float32), -1.3686788]. 
=============================================
[2019-03-24 03:54:01,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6209747e-08 4.2721498e-04 9.9933249e-01 2.9200032e-07 2.3997808e-04], sum to 1.0000
[2019-03-24 03:54:01,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-24 03:54:01,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8167356e-09 2.9941826e-04 9.9969995e-01 1.0251105e-08 5.4814200e-07], sum to 1.0000
[2019-03-24 03:54:01,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.8, 85.0, 1.0, 2.0, 0.1794054297180156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3022183837557272, 6.9112, 6.9112, 121.9260426156618, 449493.3936937976, 449493.3936937976, 162070.6867853011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5884200.0000, 
sim time next is 5884800.0000, 
raw observation next is [19.73333333333333, 85.0, 1.0, 2.0, 0.1753670622374885, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2959534638160307, 6.911199999999999, 6.9112, 121.9260426156618, 439879.4352137969, 439879.4352137973, 161097.7866811133], 
processed observation next is [1.0, 0.08695652173913043, 0.28641975308641965, 0.85, 1.0, 1.0, 0.01829412171129582, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.11994182977003838, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15709979829064175, 0.1570997982906419, 0.30980343592521786], 
reward next is 0.6902, 
noisyNet noise sample is [array([-0.15555774], dtype=float32), 0.85510385]. 
=============================================
[2019-03-24 03:54:01,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7658
[2019-03-24 03:54:01,375] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.18333333333333, 73.0, 1.0, 2.0, 0.2098603003137788, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3438092860768411, 6.911199999999999, 6.9112, 121.9260426156618, 513744.5526188005, 513744.552618801, 170503.2642727756], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5867400.0000, 
sim time next is 5868000.0000, 
raw observation next is [23.0, 74.0, 1.0, 2.0, 0.2093329548585598, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3431007434100498, 6.911199999999999, 6.9112, 121.9260426156618, 512707.8581950245, 512707.8581950249, 170353.2361296191], 
processed observation next is [1.0, 0.9565217391304348, 0.4074074074074074, 0.74, 1.0, 1.0, 0.058729708164952134, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.17887592926256224, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1831099493553659, 0.18310994935536604, 0.3276023771723444], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.6094039], dtype=float32), -0.121727265]. 
=============================================
[2019-03-24 03:54:01,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[24.415537]
 [24.432604]
 [24.518908]
 [24.575722]
 [24.618437]], R is [[24.78764534]
 [25.21187782]
 [25.63166428]
 [26.04714775]
 [26.45823669]].
[2019-03-24 03:54:07,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2927216e-24 3.0434216e-10 1.0000000e+00 3.7813215e-24 6.7378183e-18], sum to 1.0000
[2019-03-24 03:54:07,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6821
[2019-03-24 03:54:07,536] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.28333333333333, 77.66666666666667, 1.0, 2.0, 0.2124988890884493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3491779401485943, 6.911199999999999, 6.9112, 121.9260426156618, 521868.143214841, 521868.1432148415, 170918.7005580423], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5986200.0000, 
sim time next is 5986800.0000, 
raw observation next is [22.4, 77.0, 1.0, 2.0, 0.2269280198888364, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3727038577721394, 6.911199999999999, 6.9112, 121.9260426156618, 557033.2995638859, 557033.2995638864, 174316.188397813], 
processed observation next is [1.0, 0.30434782608695654, 0.38518518518518513, 0.77, 1.0, 1.0, 0.07967621415337667, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2158798222151742, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19894046412995925, 0.19894046412995942, 0.33522343922656345], 
reward next is 0.6648, 
noisyNet noise sample is [array([0.41518515], dtype=float32), 0.7486746]. 
=============================================
[2019-03-24 03:54:09,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4168160e-19 9.5421406e-08 9.9999988e-01 7.9463312e-18 2.3016674e-14], sum to 1.0000
[2019-03-24 03:54:09,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8276
[2019-03-24 03:54:09,556] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.81666666666667, 54.83333333333334, 1.0, 2.0, 0.8362151265822593, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9935277417348115, 6.911200000000001, 6.9112, 121.9260426156618, 1672611.432230828, 1672611.432230828, 342879.6490767679], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6185400.0000, 
sim time next is 6186000.0000, 
raw observation next is [29.83333333333334, 54.66666666666667, 1.0, 2.0, 0.9280974534567601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9942666154258181, 6.911199999999999, 6.9112, 121.9260426156618, 1777117.508659253, 1777117.508659253, 362590.4890706287], 
processed observation next is [1.0, 0.6086956521739131, 0.6604938271604941, 0.5466666666666667, 1.0, 1.0, 0.9144017303056667, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9928332692822724, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6346848245211617, 0.6346848245211617, 0.6972894020589013], 
reward next is 0.3027, 
noisyNet noise sample is [array([-0.45906994], dtype=float32), 1.5211718]. 
=============================================
[2019-03-24 03:54:09,575] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.08267 ]
 [57.28424 ]
 [56.826202]
 [56.889233]
 [56.982418]], R is [[56.44226837]
 [56.21846008]
 [56.04571915]
 [55.86393356]
 [55.68494797]].
[2019-03-24 03:54:09,953] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7231134e-25 8.0601170e-10 1.0000000e+00 1.9593241e-23 8.1568942e-19], sum to 1.0000
[2019-03-24 03:54:09,960] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0508
[2019-03-24 03:54:09,964] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 55.66666666666667, 1.0, 2.0, 0.3543633884367883, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5658718743849543, 6.9112, 6.9112, 121.9260426156618, 826385.8833383368, 826385.8833383368, 210024.2497257207], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6023400.0000, 
sim time next is 6024000.0000, 
raw observation next is [28.73333333333333, 56.33333333333334, 1.0, 2.0, 0.2520615170836698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4030817551521183, 6.911199999999999, 6.9112, 121.9260426156618, 590965.9627999014, 590965.9627999018, 182352.1391164865], 
processed observation next is [1.0, 0.7391304347826086, 0.619753086419753, 0.5633333333333335, 1.0, 1.0, 0.10959704414722596, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.25385219394014785, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2110592724285362, 0.21105927242853637, 0.3506771906086279], 
reward next is 0.6493, 
noisyNet noise sample is [array([0.12647961], dtype=float32), 1.2354109]. 
=============================================
[2019-03-24 03:54:09,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.93456]
 [67.08198]
 [66.91113]
 [66.64971]
 [66.44511]], R is [[70.99256897]
 [70.87875366]
 [70.49742889]
 [70.11307526]
 [69.72517395]].
[2019-03-24 03:54:16,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2933187e-16 6.0307109e-05 9.9892873e-01 1.9184983e-15 1.0109954e-03], sum to 1.0000
[2019-03-24 03:54:16,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9590
[2019-03-24 03:54:16,806] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.1, 88.66666666666667, 1.0, 2.0, 0.2797272439173917, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4485399548542508, 6.911199999999999, 6.9112, 121.9260426156618, 661297.9489648854, 661297.9489648859, 189141.222672256], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6156600.0000, 
sim time next is 6157200.0000, 
raw observation next is [23.2, 88.33333333333334, 1.0, 2.0, 0.2727874529716688, 0.0, 2.0, 0.0, 1.0, 2.0, 0.43721842822648, 6.911199999999999, 6.9112, 121.9260426156618, 644107.1346706923, 644107.1346706927, 187388.8952317745], 
processed observation next is [1.0, 0.2608695652173913, 0.4148148148148148, 0.8833333333333334, 1.0, 1.0, 0.13427077734722476, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2965230352831, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23003826238239009, 0.23003826238239025, 0.3603632600611048], 
reward next is 0.6396, 
noisyNet noise sample is [array([0.5074805], dtype=float32), 0.5795048]. 
=============================================
[2019-03-24 03:54:18,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0164824e-10 3.3391330e-03 9.4271660e-01 4.9197119e-10 5.3944301e-02], sum to 1.0000
[2019-03-24 03:54:18,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3852
[2019-03-24 03:54:18,131] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 59.0, 1.0, 2.0, 0.5439228514986696, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8663927156197859, 6.9112, 6.9112, 121.9260426156618, 1249427.714080412, 1249427.714080412, 272545.4825145158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6181200.0000, 
sim time next is 6181800.0000, 
raw observation next is [29.13333333333333, 58.33333333333334, 1.0, 2.0, 0.4772171757288153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7602487596263676, 6.9112, 6.9112, 121.9260426156618, 1097597.335897674, 1097597.335897674, 248981.1787114119], 
processed observation next is [1.0, 0.5652173913043478, 0.6345679012345677, 0.5833333333333335, 1.0, 1.0, 0.3776394949152563, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7003109495329596, 0.0, 0.0, 0.8094621288201359, 0.3919990485348836, 0.3919990485348836, 0.47880995906040746], 
reward next is 0.5212, 
noisyNet noise sample is [array([0.08066226], dtype=float32), -0.3143068]. 
=============================================
[2019-03-24 03:54:20,429] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 03:54:20,433] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:54:20,434] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:54:20,435] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:54:20,437] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:54:20,438] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:54:20,436] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:54:20,440] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:54:20,440] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:54:20,439] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:54:20,443] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:54:20,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2611693e-14 7.0362239e-06 4.3807732e-04 3.7984061e-13 9.9955481e-01], sum to 1.0000
[2019-03-24 03:54:20,448] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0292
[2019-03-24 03:54:20,453] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.01666666666667, 86.66666666666667, 1.0, 2.0, 0.1660472100224204, 1.0, 2.0, 0.1660472100224204, 1.0, 2.0, 0.2660403703317746, 6.9112, 6.9112, 121.94756008, 587482.2443068186, 587482.2443068186, 209584.9582415796], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6243000.0000, 
sim time next is 6243600.0000, 
raw observation next is [23.13333333333333, 86.33333333333334, 1.0, 2.0, 0.1673615382145363, 1.0, 2.0, 0.1673615382145363, 1.0, 2.0, 0.2680164704662895, 6.9112, 6.9112, 121.94756008, 591295.0773585816, 591295.0773585816, 210014.3381890817], 
processed observation next is [0.0, 0.2608695652173913, 0.41234567901234553, 0.8633333333333334, 1.0, 1.0, 0.00876373596968608, 1.0, 1.0, 0.00876373596968608, 1.0, 1.0, 0.08502058808286188, 0.0, 0.0, 0.8096049824067558, 0.21117681334235056, 0.21117681334235056, 0.40387372728669557], 
reward next is 0.5961, 
noisyNet noise sample is [array([-0.5440779], dtype=float32), 0.04920779]. 
=============================================
[2019-03-24 03:54:20,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-24 03:54:20,492] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-24 03:54:20,521] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-24 03:54:20,545] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-24 03:54:20,567] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-24 03:54:29,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:54:29,447] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.31666666666667, 37.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2101341069434411, 6.911200000000001, 6.9112, 121.94756008, 471078.2480964444, 471078.2480964439, 191014.9889366722]
[2019-03-24 03:54:29,449] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:54:29,451] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1776463e-12 2.9987490e-04 2.8392544e-03 5.9919535e-12 9.9686086e-01], sampled 0.3509982057556962
[2019-03-24 03:54:35,157] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:54:35,158] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.2, 53.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 415018.1380696617, 415018.1380696617, 180302.1838894882]
[2019-03-24 03:54:35,159] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:54:35,161] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7911059e-12 3.0153824e-04 2.6206682e-03 9.2374650e-12 9.9707782e-01], sampled 0.5506591290404861
[2019-03-24 03:55:09,489] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:55:09,490] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.76666666666667, 61.33333333333334, 1.0, 2.0, 0.3340007019428406, 1.0, 2.0, 0.3340007019428406, 1.0, 2.0, 0.5317399951364566, 6.9112, 6.9112, 121.94756008, 1142255.323761259, 1142255.323761259, 269379.2515324269]
[2019-03-24 03:55:09,490] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:55:09,493] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.6989471e-14 4.5445591e-05 3.3103814e-04 7.8188676e-13 9.9962354e-01], sampled 0.2758765804537976
[2019-03-24 03:55:15,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:55:15,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.5, 77.33333333333333, 1.0, 2.0, 0.2019840913099268, 1.0, 2.0, 0.2019840913099268, 1.0, 2.0, 0.321565251528012, 6.9112, 6.9112, 121.94756008, 690565.8376467944, 690565.8376467944, 221243.8385462534]
[2019-03-24 03:55:15,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:55:15,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7336534e-13 7.9592392e-05 6.2594650e-04 1.3195790e-12 9.9929440e-01], sampled 0.7531213085502466
[2019-03-24 03:55:16,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:55:16,127] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.7, 67.0, 1.0, 2.0, 0.2704459956120774, 1.0, 2.0, 0.2704459956120774, 1.0, 2.0, 0.4305588328255991, 6.9112, 6.9112, 121.94756008, 924772.2438559358, 924772.2438559358, 244992.120915545]
[2019-03-24 03:55:16,128] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:55:16,130] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5410032e-14 4.9442348e-05 3.8710990e-04 5.6726580e-13 9.9956340e-01], sampled 0.9328492127530637
[2019-03-24 03:55:54,179] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0017542]
[2019-03-24 03:55:54,180] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.7, 93.16666666666666, 1.0, 2.0, 0.1923855669333191, 1.0, 2.0, 0.1923855669333191, 1.0, 2.0, 0.3117324274013201, 6.911199999999999, 6.9112, 121.94756008, 696539.7113999635, 696539.7113999639, 217296.5413747128]
[2019-03-24 03:55:54,181] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:55:54,185] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.5626549e-13 1.4649790e-04 1.1046364e-03 4.9190981e-12 9.9874890e-01], sampled 0.19722169289820868
[2019-03-24 03:56:00,439] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4517.6975 3106834686.7228 0.0000
[2019-03-24 03:56:00,700] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4281.7450 2919555236.6618 33.0000
[2019-03-24 03:56:00,936] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4488.3353 2940390024.1428 28.0000
[2019-03-24 03:56:00,975] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4394.9794 2875549845.9505 8.0000
[2019-03-24 03:56:01,012] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4614.9484 2894005596.6793 12.0000
[2019-03-24 03:56:02,027] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2075000, evaluation results [2075000.0, 4517.697473532372, 3106834686.7227607, 0.0, 4614.948402005858, 2894005596.6792793, 12.0, 4394.979391997282, 2875549845.9504833, 8.0, 4488.335283752458, 2940390024.142791, 28.0, 4281.744965684635, 2919555236.661823, 33.0]
[2019-03-24 03:56:07,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4951232e-18 2.8326758e-07 3.6706331e-06 1.4904212e-16 9.9999607e-01], sum to 1.0000
[2019-03-24 03:56:07,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9826
[2019-03-24 03:56:07,725] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 84.0, 1.0, 2.0, 0.2077610616029716, 1.0, 2.0, 0.2077610616029716, 1.0, 2.0, 0.3307623763773268, 6.911199999999999, 6.9112, 121.94756008, 710325.940006225, 710325.9400062255, 223146.5230679929], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6337200.0000, 
sim time next is 6337800.0000, 
raw observation next is [25.9, 83.0, 1.0, 2.0, 0.2091548384146054, 1.0, 2.0, 0.2091548384146054, 1.0, 2.0, 0.3329813144535896, 6.9112, 6.9112, 121.94756008, 715093.4239298801, 715093.4239298801, 223608.3700284922], 
processed observation next is [0.0, 0.34782608695652173, 0.5148148148148147, 0.83, 1.0, 1.0, 0.05851766477929213, 1.0, 1.0, 0.05851766477929213, 1.0, 1.0, 0.16622664306698695, 0.0, 0.0, 0.8096049824067558, 0.2553905085463858, 0.2553905085463858, 0.43001609620863884], 
reward next is 0.5700, 
noisyNet noise sample is [array([1.3887177], dtype=float32), -2.1045952]. 
=============================================
[2019-03-24 03:56:08,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6187291e-18 4.5035898e-07 1.0541789e-06 3.9341957e-17 9.9999845e-01], sum to 1.0000
[2019-03-24 03:56:08,695] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3454
[2019-03-24 03:56:08,704] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 55.83333333333334, 1.0, 2.0, 0.2259694479350339, 1.0, 2.0, 0.2259694479350339, 1.0, 2.0, 0.3597507204237129, 6.9112, 6.9112, 121.94756008, 772610.9806697383, 772610.9806697383, 229265.7733374496], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6365400.0000, 
sim time next is 6366000.0000, 
raw observation next is [32.0, 55.66666666666667, 1.0, 2.0, 0.2233279002449393, 1.0, 2.0, 0.2233279002449393, 1.0, 2.0, 0.3555452904718801, 6.9112, 6.9112, 121.94756008, 763574.780749435, 763574.780749435, 228366.5332004149], 
processed observation next is [0.0, 0.6956521739130435, 0.7407407407407407, 0.5566666666666668, 1.0, 1.0, 0.07539035743445154, 1.0, 1.0, 0.07539035743445154, 1.0, 1.0, 0.1944316130898501, 0.0, 0.0, 0.8096049824067558, 0.2727052788390839, 0.2727052788390839, 0.4391664100007979], 
reward next is 0.5608, 
noisyNet noise sample is [array([-0.5996749], dtype=float32), -0.92029417]. 
=============================================
[2019-03-24 03:56:08,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.361465]
 [55.387558]
 [55.385094]
 [55.39592 ]
 [55.399956]], R is [[55.35857773]
 [55.3640976 ]
 [55.36721039]
 [55.37043762]
 [55.373806  ]].
[2019-03-24 03:56:09,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0026098e-18 2.4664820e-07 1.0451120e-06 3.1242093e-16 9.9999869e-01], sum to 1.0000
[2019-03-24 03:56:09,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1323
[2019-03-24 03:56:09,068] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.23333333333333, 63.33333333333334, 1.0, 2.0, 0.2230397068437367, 1.0, 2.0, 0.2230397068437367, 1.0, 2.0, 0.3550864771913618, 6.911200000000001, 6.9112, 121.94756008, 762588.9359065711, 762588.9359065706, 228268.6620159718], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6376800.0000, 
sim time next is 6377400.0000, 
raw observation next is [30.1, 64.0, 1.0, 2.0, 0.2276980316483087, 1.0, 2.0, 0.2276980316483087, 1.0, 2.0, 0.3625026819912877, 6.9112, 6.9112, 121.94756008, 778524.1732891178, 778524.1732891178, 229856.332945515], 
processed observation next is [0.0, 0.8260869565217391, 0.6703703703703704, 0.64, 1.0, 1.0, 0.08059289481941513, 1.0, 1.0, 0.08059289481941513, 1.0, 1.0, 0.20312835248910963, 0.0, 0.0, 0.8096049824067558, 0.27804434760325636, 0.27804434760325636, 0.44203140951060577], 
reward next is 0.5580, 
noisyNet noise sample is [array([-0.2080518], dtype=float32), 0.72591656]. 
=============================================
[2019-03-24 03:56:13,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4890418e-16 3.6646511e-06 2.4394398e-05 1.5591310e-15 9.9997199e-01], sum to 1.0000
[2019-03-24 03:56:13,498] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-24 03:56:13,502] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.2296828805613691, 1.0, 2.0, 0.2296828805613691, 1.0, 2.0, 0.3656626261028961, 6.9112, 6.9112, 121.94756008, 785314.0620820982, 785314.0620820982, 230536.5046146441], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6465600.0000, 
sim time next is 6466200.0000, 
raw observation next is [30.08333333333334, 64.5, 1.0, 2.0, 0.2260487870876612, 1.0, 2.0, 0.2260487870876612, 1.0, 2.0, 0.3598770309385915, 6.911199999999999, 6.9112, 121.94756008, 772882.3854978008, 772882.3854978011, 229292.8424679279], 
processed observation next is [1.0, 0.8695652173913043, 0.6697530864197533, 0.645, 1.0, 1.0, 0.07862950843769193, 1.0, 1.0, 0.07862950843769193, 1.0, 1.0, 0.1998462886732394, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2760294233920717, 0.2760294233920718, 0.4409477739767844], 
reward next is 0.5591, 
noisyNet noise sample is [array([-0.38847536], dtype=float32), -0.07086404]. 
=============================================
[2019-03-24 03:56:17,799] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1601348e-14 9.4212646e-06 4.4887227e-05 2.5397851e-13 9.9994564e-01], sum to 1.0000
[2019-03-24 03:56:17,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-24 03:56:17,817] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.56666666666667, 80.5, 1.0, 2.0, 0.2188006536442074, 1.0, 2.0, 0.2188006536442074, 1.0, 2.0, 0.3483377664413866, 6.9112, 6.9112, 121.94756008, 748088.234261577, 748088.234261577, 226834.4362366952], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6544200.0000, 
sim time next is 6544800.0000, 
raw observation next is [27.5, 81.0, 1.0, 2.0, 0.2208755153651366, 1.0, 2.0, 0.2208755153651366, 1.0, 2.0, 0.3516410138746346, 6.9112, 6.9112, 121.94756008, 755185.76384859, 755185.76384859, 227535.1815317341], 
processed observation next is [1.0, 0.782608695652174, 0.5740740740740741, 0.81, 1.0, 1.0, 0.07247085162516263, 1.0, 1.0, 0.07247085162516263, 1.0, 1.0, 0.18955126734329322, 0.0, 0.0, 0.8096049824067558, 0.26970920137449644, 0.26970920137449644, 0.4375676567917963], 
reward next is 0.5624, 
noisyNet noise sample is [array([1.2119294], dtype=float32), -0.9848253]. 
=============================================
[2019-03-24 03:56:22,540] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0291660e-21 9.9974436e-01 5.4423458e-07 6.5922081e-20 2.5506341e-04], sum to 1.0000
[2019-03-24 03:56:22,549] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5698
[2019-03-24 03:56:22,552] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 28.66666666666666, 1.0, 2.0, 0.5201310571796212, 1.0, 2.0, 0.5201310571796212, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1293619.317187122, 1293619.317187122, 245669.8434477942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6627000.0000, 
sim time next is 6627600.0000, 
raw observation next is [29.8, 27.0, 1.0, 2.0, 0.9290581993206413, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.335266019879716, 6.9112, 121.9242290227611, 1392583.656496129, 1175427.181876071, 228514.0667929086], 
processed observation next is [1.0, 0.7391304347826086, 0.6592592592592593, 0.27, 1.0, 1.0, 0.9155454753817158, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04240660198797164, 0.0, 0.809450088449279, 0.49735130589147464, 0.41979542209859677, 0.43945012844790116], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.39004], dtype=float32), -1.2933402]. 
=============================================
[2019-03-24 03:56:22,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0364548e-19 9.9964094e-01 1.9454768e-05 4.5521693e-18 3.3961073e-04], sum to 1.0000
[2019-03-24 03:56:22,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6695
[2019-03-24 03:56:22,794] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 52.33333333333333, 1.0, 2.0, 0.3651356704358555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455760.4741943211, 455760.4741943211, 123884.6923481051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6636000.0000, 
sim time next is 6636600.0000, 
raw observation next is [25.45, 54.5, 1.0, 2.0, 0.3710558548276494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462399.5867539573, 462399.5867539573, 124671.8390541856], 
processed observation next is [1.0, 0.8260869565217391, 0.4981481481481481, 0.545, 1.0, 1.0, 0.25125697003291597, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16514270955498475, 0.16514270955498475, 0.23975353664266463], 
reward next is 0.7602, 
noisyNet noise sample is [array([1.5099909], dtype=float32), -0.6472322]. 
=============================================
[2019-03-24 03:56:22,858] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1942975e-18 9.9993587e-01 2.1200015e-06 3.5429429e-16 6.1941224e-05], sum to 1.0000
[2019-03-24 03:56:22,871] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-24 03:56:22,876] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333333, 49.16666666666667, 1.0, 2.0, 0.3135569898542157, 1.0, 1.0, 0.3135569898542157, 1.0, 1.0, 0.5180406028602506, 6.9112, 6.9112, 121.94756008, 1161629.628933146, 1161629.628933146, 259401.966011653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6616200.0000, 
sim time next is 6616800.0000, 
raw observation next is [24.3, 52.0, 1.0, 2.0, 0.8391443577719008, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425637751, 1054423.032946822, 1054423.032946822, 207940.569598117], 
processed observation next is [1.0, 0.6086956521739131, 0.4555555555555556, 0.52, 1.0, 1.0, 0.8085051878236914, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621284756622, 0.376579654623865, 0.376579654623865, 0.39988571076560964], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25721458], dtype=float32), -0.68160474]. 
=============================================
[2019-03-24 03:56:23,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4205485e-21 9.9999595e-01 4.6557329e-07 3.4965338e-18 3.5448263e-06], sum to 1.0000
[2019-03-24 03:56:23,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6331
[2019-03-24 03:56:23,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1336581.351679117 W.
[2019-03-24 03:56:23,278] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.4, 32.0, 1.0, 2.0, 0.363762313523194, 1.0, 2.0, 0.363762313523194, 1.0, 1.0, 0.5959889302213836, 6.9112, 6.9112, 121.94756008, 1336581.351679117, 1336581.351679117, 280218.3734998868], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6625800.0000, 
sim time next is 6626400.0000, 
raw observation next is [29.53333333333333, 30.33333333333334, 1.0, 2.0, 0.3606241004808982, 1.0, 2.0, 0.3606241004808982, 1.0, 2.0, 0.5917272200664344, 6.911199999999999, 6.9112, 121.94756008, 1327174.721596794, 1327174.721596794, 278817.2694832987], 
processed observation next is [1.0, 0.6956521739130435, 0.6493827160493827, 0.3033333333333334, 1.0, 1.0, 0.23883821485821216, 1.0, 1.0, 0.23883821485821216, 1.0, 1.0, 0.489659025083043, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.473990971998855, 0.473990971998855, 0.5361870566986513], 
reward next is 0.4638, 
noisyNet noise sample is [array([1.1753577], dtype=float32), 0.39637092]. 
=============================================
[2019-03-24 03:56:23,391] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5690537e-28 1.0000000e+00 6.2281613e-10 5.3791178e-25 2.4863445e-09], sum to 1.0000
[2019-03-24 03:56:23,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5966
[2019-03-24 03:56:23,401] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 37.0, 1.0, 2.0, 0.3361114017701228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422511.2215774004, 422511.2215774004, 120095.5020668873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6630000.0000, 
sim time next is 6630600.0000, 
raw observation next is [28.3, 39.5, 1.0, 2.0, 0.3385101541522106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 424090.0044470112, 424090.0044470108, 120384.8894279755], 
processed observation next is [1.0, 0.7391304347826086, 0.6037037037037037, 0.395, 1.0, 1.0, 0.21251208827644116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1514607158739326, 0.15146071587393242, 0.23150940274610673], 
reward next is 0.7685, 
noisyNet noise sample is [array([-0.17255811], dtype=float32), -0.58218694]. 
=============================================
[2019-03-24 03:56:23,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3331536e-24 1.0000000e+00 3.1130891e-09 9.7518165e-24 2.1143039e-08], sum to 1.0000
[2019-03-24 03:56:23,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4590
[2019-03-24 03:56:23,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1334289.474927863 W.
[2019-03-24 03:56:23,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 51.5, 1.0, 2.0, 0.3777043324726954, 1.0, 1.0, 0.3777043324726954, 1.0, 2.0, 0.6047440225703503, 6.911199999999999, 6.9112, 121.94756008, 1334289.474927863, 1334289.474927863, 287396.8349512642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6793800.0000, 
sim time next is 6794400.0000, 
raw observation next is [28.0, 52.00000000000001, 1.0, 2.0, 0.452280928631019, 1.0, 2.0, 0.452280928631019, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1073524.14591159, 1073524.14591159, 222883.9463452353], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.52, 1.0, 1.0, 0.3479534864654988, 1.0, 1.0, 0.3479534864654988, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3834014806827107, 0.3834014806827107, 0.42862297374083713], 
reward next is 0.5714, 
noisyNet noise sample is [array([-0.06086875], dtype=float32), 0.8173358]. 
=============================================
[2019-03-24 03:56:23,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8458745e-29 1.0000000e+00 2.3469077e-10 3.9466580e-27 4.8196607e-09], sum to 1.0000
[2019-03-24 03:56:23,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-24 03:56:23,740] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 38.5, 1.0, 2.0, 0.2911994331424243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375562.2578579417, 375562.2578579417, 114481.5650195515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6649800.0000, 
sim time next is 6650400.0000, 
raw observation next is [24.8, 39.0, 1.0, 2.0, 0.2905587837146345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374714.5512582209, 374714.5512582209, 114403.6986039948], 
processed observation next is [1.0, 1.0, 0.4740740740740741, 0.39, 1.0, 1.0, 0.15542712346980297, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1338266254493646, 0.1338266254493646, 0.22000711269999], 
reward next is 0.7800, 
noisyNet noise sample is [array([0.127581], dtype=float32), -0.011011847]. 
=============================================
[2019-03-24 03:56:42,667] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2278960e-19 9.9971110e-01 7.7373996e-05 5.0531176e-19 2.1158493e-04], sum to 1.0000
[2019-03-24 03:56:42,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2547
[2019-03-24 03:56:42,678] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 78.0, 1.0, 2.0, 0.4197682799386124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517789.1971246097, 517789.1971246097, 131384.4112793922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7004400.0000, 
sim time next is 7005000.0000, 
raw observation next is [22.28333333333333, 78.5, 1.0, 2.0, 0.4181989180339231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515949.271886863, 515949.271886863, 131160.5728911365], 
processed observation next is [1.0, 0.043478260869565216, 0.38086419753086415, 0.785, 1.0, 1.0, 0.307379664326099, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18426759710245108, 0.18426759710245108, 0.25223187094449323], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.11083388], dtype=float32), -0.64680237]. 
=============================================
[2019-03-24 03:56:42,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.79175 ]
 [68.82568 ]
 [68.97631 ]
 [68.932526]
 [68.86434 ]], R is [[68.66413879]
 [68.72483826]
 [68.78502655]
 [68.84480286]
 [68.90415192]].
[2019-03-24 03:56:52,205] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 03:56:52,207] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:56:52,208] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:52,208] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:56:52,210] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:56:52,210] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:52,210] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:56:52,213] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:52,213] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:56:52,216] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:52,219] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:52,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-24 03:56:52,260] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-24 03:56:52,289] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-24 03:56:52,290] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-24 03:56:52,310] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-24 03:56:55,898] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:56:55,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [13.78333333333333, 76.83333333333334, 1.0, 2.0, 0.1646169348798537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 212326.4385988839, 212326.4385988844, 70927.50262954747]
[2019-03-24 03:56:55,901] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:56:55,905] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1371674e-21 9.9999952e-01 3.3695352e-07 1.9540265e-20 1.5764014e-07], sampled 0.8065136194802695
[2019-03-24 03:57:23,872] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:57:23,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 72.5, 1.0, 2.0, 0.4277097249282664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521370.723804222, 521370.723804222, 132368.481736061]
[2019-03-24 03:57:23,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:57:23,875] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.0170018e-24 9.9999988e-01 6.5633415e-08 1.4233214e-22 2.8561113e-08], sampled 0.1949145687716325
[2019-03-24 03:57:25,070] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:57:25,071] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 78.0, 1.0, 2.0, 0.4747330552887505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571389.867102391, 571389.867102391, 139164.3400093435]
[2019-03-24 03:57:25,072] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:57:25,075] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8618546e-24 9.9999988e-01 6.5121412e-08 1.3888871e-22 2.8320368e-08], sampled 0.23643007807120142
[2019-03-24 03:57:29,542] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:57:29,546] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.5736494925744757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669076.2556520657, 669076.2556520657, 154325.6450120587]
[2019-03-24 03:57:29,547] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:57:29,549] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5328826e-24 1.0000000e+00 4.2751434e-08 3.9356457e-23 1.8179291e-08], sampled 0.01852952219429993
[2019-03-24 03:58:14,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:58:14,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.8, 87.0, 1.0, 2.0, 0.5908487706592408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684069.8871821173, 684069.8871821173, 157026.4030958397]
[2019-03-24 03:58:14,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:58:14,644] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1599303e-24 1.0000000e+00 4.7692033e-08 5.4412022e-23 2.0489409e-08], sampled 0.4128569871662112
[2019-03-24 03:58:25,369] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0192885]
[2019-03-24 03:58:25,370] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 94.5, 1.0, 2.0, 0.5373692153215598, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8561784868485846, 6.9112, 6.9112, 121.925849796544, 1237354.883354843, 1237354.883354843, 270104.1115214294]
[2019-03-24 03:58:25,371] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:58:25,375] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9290559e-22 9.9999964e-01 2.1791531e-07 5.4073948e-21 9.5358793e-08], sampled 0.753173411024587
[2019-03-24 03:58:32,445] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 03:58:32,581] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 03:58:32,635] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 03:58:32,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 03:58:32,725] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 03:58:33,742] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2100000, evaluation results [2100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 03:58:39,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4680255e-22 9.9999928e-01 7.1009964e-07 3.0849424e-22 3.6221383e-08], sum to 1.0000
[2019-03-24 03:58:39,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9635
[2019-03-24 03:58:39,514] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 90.5, 1.0, 2.0, 0.4859869995766307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598134.3113719842, 598134.3113719847, 141293.1505807609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7284600.0000, 
sim time next is 7285200.0000, 
raw observation next is [20.93333333333333, 90.66666666666667, 1.0, 2.0, 0.4309479307498383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529984.7951899488, 529984.7951899488, 132968.2303577335], 
processed observation next is [1.0, 0.30434782608695654, 0.3308641975308641, 0.9066666666666667, 1.0, 1.0, 0.32255706041647414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18928028399641028, 0.18928028399641028, 0.25570813530333364], 
reward next is 0.7443, 
noisyNet noise sample is [array([-0.9437407], dtype=float32), 1.674955]. 
=============================================
[2019-03-24 03:58:41,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8895248e-24 1.0000000e+00 1.0078232e-09 3.3561283e-24 3.8089112e-11], sum to 1.0000
[2019-03-24 03:58:42,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2028
[2019-03-24 03:58:42,011] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 81.33333333333334, 1.0, 2.0, 0.4312019779651935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 529046.172144441, 529046.1721444406, 132972.4374955894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7336200.0000, 
sim time next is 7336800.0000, 
raw observation next is [22.1, 82.0, 1.0, 2.0, 0.4261388258739406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523420.2866390918, 523420.2866390918, 132250.3682860626], 
processed observation next is [1.0, 0.9565217391304348, 0.3740740740740741, 0.82, 1.0, 1.0, 0.31683193556421496, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1869358166568185, 0.1869358166568185, 0.25432763131935116], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.15724348], dtype=float32), 1.2368397]. 
=============================================
[2019-03-24 03:58:44,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2736330e-24 1.0000000e+00 2.9465183e-10 7.1896885e-24 2.3309655e-12], sum to 1.0000
[2019-03-24 03:58:44,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4680
[2019-03-24 03:58:44,075] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 95.83333333333333, 1.0, 2.0, 0.4421762008961639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552510.2683927509, 552510.2683927509, 134813.6919648433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7369800.0000, 
sim time next is 7370400.0000, 
raw observation next is [19.13333333333333, 95.66666666666666, 1.0, 2.0, 0.3770672271877357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471460.9547657464, 471460.954765746, 125521.06972119], 
processed observation next is [1.0, 0.30434782608695654, 0.2641975308641974, 0.9566666666666666, 1.0, 1.0, 0.25841336569968537, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.168378912416338, 0.16837891241633787, 0.24138667254075], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.2687158], dtype=float32), 0.5979707]. 
=============================================
[2019-03-24 03:58:48,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:58:48,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:48,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-24 03:58:50,030] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2108387: loss 18.0740
[2019-03-24 03:58:50,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2108387: learning rate 0.0001
[2019-03-24 03:58:54,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2036238e-24 1.0000000e+00 1.5333994e-10 6.5460329e-25 5.9478464e-12], sum to 1.0000
[2019-03-24 03:58:54,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2371
[2019-03-24 03:58:54,313] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 64.33333333333334, 1.0, 2.0, 0.508309922728781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604120.487263188, 604120.487263188, 144126.275294563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579200.0000, 
sim time next is 7579800.0000, 
raw observation next is [26.8, 65.5, 1.0, 2.0, 0.5107267373185771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606565.3915639599, 606565.3915639599, 144493.2864185198], 
processed observation next is [0.0, 0.7391304347826086, 0.5481481481481482, 0.655, 1.0, 1.0, 0.4175318301411632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21663049698712852, 0.21663049698712852, 0.2778717046509996], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.36517897], dtype=float32), 1.4067672]. 
=============================================
[2019-03-24 03:58:57,438] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0069739e-26 1.0000000e+00 3.0280860e-12 1.2446040e-25 1.4215009e-11], sum to 1.0000
[2019-03-24 03:58:57,449] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2060
[2019-03-24 03:58:57,455] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 91.0, 1.0, 2.0, 0.3825739667965511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473949.8267218302, 473949.8267218302, 126189.540803023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7628400.0000, 
sim time next is 7629000.0000, 
raw observation next is [20.46666666666667, 91.00000000000001, 1.0, 2.0, 0.4393660787266304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543796.7407683703, 543796.7407683703, 134289.4652207541], 
processed observation next is [1.0, 0.30434782608695654, 0.31358024691358033, 0.9100000000000001, 1.0, 1.0, 0.3325786651507505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1942131217029894, 0.1942131217029894, 0.25824897157837323], 
reward next is 0.7418, 
noisyNet noise sample is [array([1.4726785], dtype=float32), 1.9762639]. 
=============================================
[2019-03-24 03:58:57,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.69912]
 [69.69404]
 [69.69591]
 [69.6776 ]
 [69.63419]], R is [[69.50291443]
 [69.56520844]
 [69.62751007]
 [69.68922424]
 [69.74975586]].
[2019-03-24 03:59:01,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0485285e-27 1.0000000e+00 1.6941217e-15 2.5968234e-29 3.3861436e-16], sum to 1.0000
[2019-03-24 03:59:01,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3380
[2019-03-24 03:59:01,526] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 92.33333333333333, 1.0, 2.0, 0.3498833908395585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 441234.9570959058, 441234.9570959054, 121919.4313748251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7713600.0000, 
sim time next is 7714200.0000, 
raw observation next is [18.93333333333333, 92.16666666666667, 1.0, 2.0, 0.3497320089801488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 440796.2055320232, 440796.2055320237, 121896.2519947719], 
processed observation next is [1.0, 0.2608695652173913, 0.25679012345679, 0.9216666666666667, 1.0, 1.0, 0.2258714392620819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15742721626143685, 0.15742721626143702, 0.2344158692207152], 
reward next is 0.7656, 
noisyNet noise sample is [array([0.01621812], dtype=float32), 0.24104677]. 
=============================================
[2019-03-24 03:59:02,772] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5262351e-17 1.0000000e+00 5.0912559e-09 5.0349160e-17 3.3359782e-10], sum to 1.0000
[2019-03-24 03:59:02,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8015
[2019-03-24 03:59:02,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 61.00000000000001, 1.0, 2.0, 0.3536866835357799, 1.0, 1.0, 0.3536866835357799, 1.0, 1.0, 0.5659831962010357, 6.911199999999999, 6.9112, 121.94756008, 1247252.558626871, 1247252.558626872, 277332.892526645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7730400.0000, 
sim time next is 7731000.0000, 
raw observation next is [26.7, 60.0, 1.0, 2.0, 0.9830351544694197, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.347179105207022, 6.9112, 121.9242141938703, 1400894.474823186, 1177637.553632472, 239529.0313597021], 
processed observation next is [1.0, 0.4782608695652174, 0.5444444444444444, 0.6, 1.0, 1.0, 0.9798037553207377, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.043597910520702235, 0.0, 0.809449990000865, 0.500319455293995, 0.4205848405830257, 0.4606327526148117], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.98771685], dtype=float32), 0.15869491]. 
=============================================
[2019-03-24 03:59:02,804] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[45.00205 ]
 [46.42956 ]
 [46.900837]
 [47.267376]
 [47.667377]], R is [[44.97419739]
 [44.9911232 ]
 [44.54121399]
 [44.09580231]
 [43.65484619]].
[2019-03-24 03:59:03,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8560012e-24 1.0000000e+00 3.6221040e-13 1.9803856e-24 8.3295165e-13], sum to 1.0000
[2019-03-24 03:59:03,062] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9874
[2019-03-24 03:59:03,066] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 92.16666666666667, 1.0, 2.0, 0.3497320089801488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 440796.2055320232, 440796.2055320237, 121896.2519947719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7714200.0000, 
sim time next is 7714800.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.3543094632323914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446310.9620999277, 446310.9620999277, 122500.4198130657], 
processed observation next is [1.0, 0.30434782608695654, 0.25925925925925924, 0.92, 1.0, 1.0, 0.23132078956237068, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15939677217854561, 0.15939677217854561, 0.23557773040974173], 
reward next is 0.7644, 
noisyNet noise sample is [array([0.994261], dtype=float32), 0.5223577]. 
=============================================
[2019-03-24 03:59:03,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7807665e-17 1.0000000e+00 2.0218272e-09 2.4512960e-17 4.4295567e-09], sum to 1.0000
[2019-03-24 03:59:03,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-24 03:59:03,507] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 65.66666666666667, 1.0, 2.0, 0.9088838366539338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946146455212061, 6.9112, 121.9258300999576, 1121121.476467588, 1103225.799112305, 222603.610592304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7728000.0000, 
sim time next is 7728600.0000, 
raw observation next is [25.73333333333333, 64.33333333333333, 1.0, 2.0, 0.9267813153159952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.050831644067149, 6.9112, 121.9253857520995, 1194153.677009001, 1122650.180331436, 226666.1772000651], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.6433333333333333, 1.0, 1.0, 0.9128348991857085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.013963164406714856, 0.0, 0.8094577679291722, 0.42648345607464316, 0.4009464929755128, 0.43589649461550983], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2381167], dtype=float32), 0.11515164]. 
=============================================
[2019-03-24 03:59:06,280] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2116426: loss 0.2404
[2019-03-24 03:59:06,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2116426: learning rate 0.0001
[2019-03-24 03:59:08,040] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:08,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:08,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-24 03:59:09,915] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2118250: loss 6.5320
[2019-03-24 03:59:09,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2118250: learning rate 0.0001
[2019-03-24 03:59:12,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5534017e-18 8.9236486e-01 4.3552712e-02 4.6567205e-14 6.4082406e-02], sum to 1.0000
[2019-03-24 03:59:12,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8805
[2019-03-24 03:59:12,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1640389.002694268 W.
[2019-03-24 03:59:12,453] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 47.33333333333334, 1.0, 2.0, 0.4757745618654601, 1.0, 1.0, 0.4757745618654601, 1.0, 2.0, 0.7578722299483093, 6.911199999999999, 6.9112, 121.94756008, 1640389.002694268, 1640389.002694269, 331934.4813412094], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7917600.0000, 
sim time next is 7918200.0000, 
raw observation next is [30.1, 47.5, 1.0, 2.0, 0.7248994781269777, 1.0, 2.0, 0.7248994781269777, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1679701.099559012, 1679701.099559012, 315031.2139372884], 
processed observation next is [1.0, 0.6521739130434783, 0.6703703703703704, 0.475, 1.0, 1.0, 0.6724993787225926, 1.0, 1.0, 0.6724993787225926, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5998932498425044, 0.5998932498425044, 0.6058292575717085], 
reward next is 0.3942, 
noisyNet noise sample is [array([-0.47514123], dtype=float32), 1.6457314]. 
=============================================
[2019-03-24 03:59:13,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4344780e-10 3.4870312e-01 9.2424534e-02 1.4925703e-08 5.5887234e-01], sum to 1.0000
[2019-03-24 03:59:13,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3421
[2019-03-24 03:59:13,829] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 69.33333333333334, 1.0, 2.0, 0.2297246124506103, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3721141764162269, 6.911199999999999, 6.9112, 121.9260426156618, 554155.1231056073, 554155.1231056078, 175913.5175456885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7942800.0000, 
sim time next is 7943400.0000, 
raw observation next is [24.5, 70.0, 1.0, 2.0, 0.4546025916033652, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552195.3456688037, 552195.3456688037, 136280.179653558], 
processed observation next is [1.0, 0.9565217391304348, 0.46296296296296297, 0.7, 1.0, 1.0, 0.35071737095638716, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19721262345314416, 0.19721262345314416, 0.2620772685645346], 
reward next is 0.7379, 
noisyNet noise sample is [array([0.07428841], dtype=float32), 0.75313354]. 
=============================================
[2019-03-24 03:59:15,119] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,120] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-24 03:59:15,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,158] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-24 03:59:15,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-24 03:59:15,308] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,308] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-24 03:59:15,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,392] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-24 03:59:15,414] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,416] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,424] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,424] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,430] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-24 03:59:15,468] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-24 03:59:15,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,507] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-24 03:59:15,589] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,589] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,592] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-24 03:59:15,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-24 03:59:15,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-24 03:59:15,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,815] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-24 03:59:15,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-24 03:59:15,903] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:59:15,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:15,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-24 03:59:17,144] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121078: loss 1.4549
[2019-03-24 03:59:17,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121078: learning rate 0.0001
[2019-03-24 03:59:17,269] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2121128: loss 8.9399
[2019-03-24 03:59:17,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2121130: learning rate 0.0001
[2019-03-24 03:59:17,406] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121195: loss 3.8207
[2019-03-24 03:59:17,408] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121195: learning rate 0.0001
[2019-03-24 03:59:17,412] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2121195: loss 0.9686
[2019-03-24 03:59:17,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2121195: learning rate 0.0001
[2019-03-24 03:59:17,455] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2121222: loss 0.0949
[2019-03-24 03:59:17,456] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2121222: learning rate 0.0001
[2019-03-24 03:59:17,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4316745e-22 9.9999976e-01 2.7585278e-07 4.1081196e-19 2.6475171e-09], sum to 1.0000
[2019-03-24 03:59:17,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7931
[2019-03-24 03:59:17,474] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 75.33333333333334, 1.0, 2.0, 0.2767966402091786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357051.8970645203, 357051.8970645203, 105203.93946089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 16800.0000, 
sim time next is 17400.0000, 
raw observation next is [18.01666666666667, 75.16666666666666, 1.0, 2.0, 0.2702366987328751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348588.0231836425, 348588.0231836425, 103811.9003358166], 
processed observation next is [1.0, 0.17391304347826086, 0.2228395061728396, 0.7516666666666666, 1.0, 1.0, 0.13123416515818465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1244957225655866, 0.1244957225655866, 0.19963826987657038], 
reward next is 0.8004, 
noisyNet noise sample is [array([-0.21517512], dtype=float32), -0.4061764]. 
=============================================
[2019-03-24 03:59:17,530] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2121263: loss 0.1631
[2019-03-24 03:59:17,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2121263: learning rate 0.0001
[2019-03-24 03:59:17,552] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121275: loss 2.7980
[2019-03-24 03:59:17,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121275: learning rate 0.0001
[2019-03-24 03:59:17,722] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2121366: loss 2.8147
[2019-03-24 03:59:17,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2121368: learning rate 0.0001
[2019-03-24 03:59:17,740] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2121380: loss 1.8422
[2019-03-24 03:59:17,741] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2121380: learning rate 0.0001
[2019-03-24 03:59:17,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2121432: loss 1.8614
[2019-03-24 03:59:17,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2121432: learning rate 0.0001
[2019-03-24 03:59:17,923] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2121477: loss 1.1271
[2019-03-24 03:59:17,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2121477: learning rate 0.0001
[2019-03-24 03:59:18,030] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2121531: loss 0.2368
[2019-03-24 03:59:18,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2121533: learning rate 0.0001
[2019-03-24 03:59:18,212] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2121620: loss 2.1439
[2019-03-24 03:59:18,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2121621: learning rate 0.0001
[2019-03-24 03:59:18,228] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2121628: loss 1.2062
[2019-03-24 03:59:18,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2121629: learning rate 0.0001
[2019-03-24 03:59:18,235] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121629: loss 2.9000
[2019-03-24 03:59:18,239] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121629: learning rate 0.0001
[2019-03-24 03:59:22,042] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2123503: loss 0.0189
[2019-03-24 03:59:22,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2123504: learning rate 0.0001
[2019-03-24 03:59:25,085] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 03:59:25,086] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:59:25,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:25,088] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:59:25,088] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:25,089] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:59:25,090] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:25,091] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:59:25,094] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:59:25,095] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:25,097] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:59:25,124] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-24 03:59:25,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-24 03:59:25,150] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-24 03:59:25,203] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-24 03:59:25,232] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-24 03:59:26,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 03:59:26,977] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 18.0, 1.0, 2.0, 0.8608142332665538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.975653644373547, 6.9112, 121.9257128736713, 1141706.776425115, 1108700.838967402, 212916.3772784828]
[2019-03-24 03:59:26,978] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:59:26,984] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7408268e-21 1.0000000e+00 1.6978137e-10 1.2297605e-19 8.7170248e-14], sampled 0.3403157891162474
[2019-03-24 03:59:27,855] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 03:59:27,857] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.8589793, 74.98914671, 1.0, 2.0, 0.5179042917726366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611795.4253810454, 611795.4253810454, 145510.0268241231]
[2019-03-24 03:59:27,858] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:59:27,862] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9127512e-25 1.0000000e+00 4.6837694e-12 1.3727010e-22 7.6684360e-16], sampled 0.9207763227963043
[2019-03-24 03:59:34,197] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 03:59:34,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.73333333333333, 30.33333333333334, 1.0, 2.0, 0.3341189275480104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422234.4465564772, 422234.4465564772, 119865.4841192068]
[2019-03-24 03:59:34,201] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:59:34,204] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.6612819e-24 1.0000000e+00 1.1360159e-11 7.6329237e-22 2.1190037e-15], sampled 0.8618670489094991
[2019-03-24 03:59:48,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 03:59:48,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4744137563976132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605450.7458527823, 605450.7458527823, 139840.4028142143]
[2019-03-24 03:59:48,385] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:59:48,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0208941e-25 1.0000000e+00 3.4226953e-12 7.4392840e-23 5.2314740e-16], sampled 0.6848187774756196
[2019-03-24 04:00:11,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 04:00:11,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.5, 74.5, 1.0, 2.0, 0.7897858661076653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900192.5604001196, 900192.5604001196, 193848.1982332603]
[2019-03-24 04:00:11,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:00:11,667] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6044138e-24 1.0000000e+00 5.6521190e-12 2.0722877e-22 7.9923054e-16], sampled 0.3420152781231528
[2019-03-24 04:00:25,088] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 04:00:25,090] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 96.0, 1.0, 2.0, 0.561909190653331, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8945777316248457, 6.9112, 6.9112, 121.9260426156618, 1281238.881499065, 1281238.881499065, 279334.8284006246]
[2019-03-24 04:00:25,090] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:00:25,093] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0879245e-20 1.0000000e+00 4.0233822e-10 6.4485005e-19 2.5535726e-13], sampled 0.6620580344415743
[2019-03-24 04:00:48,360] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 04:00:48,362] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.9, 80.0, 1.0, 2.0, 0.9709610058230689, 1.0, 2.0, 0.9709610058230689, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2215158.095365882, 2215158.095365882, 419462.7046133335]
[2019-03-24 04:00:48,362] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:00:48,365] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.45545076e-17 1.00000000e+00 1.36485765e-08 4.66797422e-16
 3.32867345e-11], sampled 0.5449358044366761
[2019-03-24 04:00:48,365] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2215158.095365882 W.
[2019-03-24 04:00:50,188] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0260797]
[2019-03-24 04:00:50,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.91666666666666, 92.33333333333333, 1.0, 2.0, 0.637129109308161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 726113.0086409807, 726113.0086409802, 164582.0411623151]
[2019-03-24 04:00:50,191] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:00:50,193] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6522891e-25 1.0000000e+00 1.9427418e-12 2.6600163e-23 2.2181896e-16], sampled 0.35231255118851
[2019-03-24 04:01:05,481] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:01:05,548] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:01:05,574] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:01:05,575] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:01:05,648] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:01:06,666] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2125000, evaluation results [2125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:01:06,682] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6640560e-23 1.0000000e+00 2.1404926e-11 1.6715715e-21 3.0282315e-15], sum to 1.0000
[2019-03-24 04:01:06,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5256
[2019-03-24 04:01:06,691] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.88333333333333, 7.666666666666667, 1.0, 2.0, 0.3950840325719338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509686.581727462, 509686.581727462, 124927.7856831401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 150600.0000, 
sim time next is 151200.0000, 
raw observation next is [35.6, 8.0, 1.0, 2.0, 0.3924157870132285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506243.2382071864, 506243.2382071864, 124188.0293138864], 
processed observation next is [1.0, 0.782608695652174, 0.8740740740740741, 0.08, 1.0, 1.0, 0.2766854607300339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18080115650256656, 0.18080115650256656, 0.2388231332959354], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.5470761], dtype=float32), 0.1531484]. 
=============================================
[2019-03-24 04:01:09,602] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8564994e-31 1.0000000e+00 2.1089949e-16 3.3077103e-27 5.5165519e-21], sum to 1.0000
[2019-03-24 04:01:09,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2383
[2019-03-24 04:01:09,619] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.61666666666667, 59.0, 1.0, 2.0, 0.2506257788732593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 323285.8617084854, 323285.8617084854, 104303.3450150214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 193800.0000, 
sim time next is 194400.0000, 
raw observation next is [20.8, 60.0, 1.0, 2.0, 0.252349274306469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 325509.4954776079, 325509.4954776079, 109296.1690660474], 
processed observation next is [0.0, 0.2608695652173913, 0.32592592592592595, 0.6, 1.0, 1.0, 0.10993961226960593, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11625339124200282, 0.11625339124200282, 0.21018494051162961], 
reward next is 0.7898, 
noisyNet noise sample is [array([0.6558845], dtype=float32), -0.24213365]. 
=============================================
[2019-03-24 04:01:10,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9358634e-32 1.0000000e+00 4.1953915e-15 3.5061049e-29 3.9888397e-20], sum to 1.0000
[2019-03-24 04:01:10,303] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3010
[2019-03-24 04:01:10,306] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 21.0, 1.0, 2.0, 0.363461416788231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 464232.3123215236, 464232.3123215231, 123777.1331548994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 217800.0000, 
sim time next is 218400.0000, 
raw observation next is [31.7, 20.0, 1.0, 2.0, 0.3648332948032827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 466548.8411511191, 466548.8411511186, 123963.1394443607], 
processed observation next is [0.0, 0.5217391304347826, 0.7296296296296296, 0.2, 1.0, 1.0, 0.24384916048009844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16662458612539968, 0.16662458612539952, 0.23839065277761673], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.2782168], dtype=float32), -0.06240268]. 
=============================================
[2019-03-24 04:01:13,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0935471e-25 1.0000000e+00 1.0598194e-10 1.6466476e-22 2.7360208e-14], sum to 1.0000
[2019-03-24 04:01:13,819] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2895
[2019-03-24 04:01:13,822] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333334, 34.66666666666667, 1.0, 2.0, 0.2854521807438539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368219.731621718, 368219.731621718, 99369.51475772266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 288600.0000, 
sim time next is 289200.0000, 
raw observation next is [24.06666666666667, 34.33333333333334, 1.0, 2.0, 0.2871816853334858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 370451.2490848569, 370451.2490848569, 99910.94583987257], 
processed observation next is [0.0, 0.34782608695652173, 0.4469135802469137, 0.34333333333333343, 1.0, 1.0, 0.15140676825414978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13230401753030602, 0.13230401753030602, 0.19213643430744726], 
reward next is 0.8079, 
noisyNet noise sample is [array([-1.2906955], dtype=float32), 1.3265455]. 
=============================================
[2019-03-24 04:01:14,306] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2128979: loss 0.0301
[2019-03-24 04:01:14,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2128979: learning rate 0.0001
[2019-03-24 04:01:14,578] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2129117: loss 0.0010
[2019-03-24 04:01:14,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2129118: learning rate 0.0001
[2019-03-24 04:01:14,639] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2129148: loss 0.0194
[2019-03-24 04:01:14,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2129148: learning rate 0.0001
[2019-03-24 04:01:14,657] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2129162: loss 0.0325
[2019-03-24 04:01:14,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2129162: learning rate 0.0001
[2019-03-24 04:01:14,697] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2129182: loss 0.1479
[2019-03-24 04:01:14,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2129183: learning rate 0.0001
[2019-03-24 04:01:14,983] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129335: loss 0.0908
[2019-03-24 04:01:14,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129335: learning rate 0.0001
[2019-03-24 04:01:15,004] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2129344: loss 0.1159
[2019-03-24 04:01:15,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2129344: learning rate 0.0001
[2019-03-24 04:01:15,039] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129360: loss 0.1546
[2019-03-24 04:01:15,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129361: learning rate 0.0001
[2019-03-24 04:01:15,082] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2129380: loss 0.1375
[2019-03-24 04:01:15,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2129380: learning rate 0.0001
[2019-03-24 04:01:15,110] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2129398: loss 0.0449
[2019-03-24 04:01:15,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2129399: learning rate 0.0001
[2019-03-24 04:01:15,167] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2129424: loss 0.0154
[2019-03-24 04:01:15,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2129425: learning rate 0.0001
[2019-03-24 04:01:15,450] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2129587: loss 0.0275
[2019-03-24 04:01:15,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2129587: learning rate 0.0001
[2019-03-24 04:01:15,461] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2129592: loss 0.0041
[2019-03-24 04:01:15,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2129593: learning rate 0.0001
[2019-03-24 04:01:15,589] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2129665: loss 0.1132
[2019-03-24 04:01:15,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2129667: learning rate 0.0001
[2019-03-24 04:01:15,699] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2129726: loss 0.0994
[2019-03-24 04:01:15,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2129726: learning rate 0.0001
[2019-03-24 04:01:18,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8446882e-18 9.9999905e-01 7.9490138e-07 9.1147564e-16 1.5497321e-07], sum to 1.0000
[2019-03-24 04:01:18,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3020
[2019-03-24 04:01:18,890] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.73333333333333, 28.33333333333334, 1.0, 2.0, 0.8619720609519015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.934334829982964, 6.9112, 121.9258814214401, 1112881.231436209, 1101034.146379936, 213192.8746299885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 386400.0000, 
sim time next is 387000.0000, 
raw observation next is [28.85, 28.0, 1.0, 2.0, 0.8754478730596226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.026412249369047, 6.9112, 121.9254880384818, 1177117.852102967, 1118119.151227171, 216224.9829519614], 
processed observation next is [1.0, 0.4782608695652174, 0.6240740740740741, 0.28, 1.0, 1.0, 0.8517236584043126, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.011521224936904684, 0.0, 0.8094584470043804, 0.4203992328939168, 0.39932826829541823, 0.41581727490761805], 
reward next is 0.0081, 
noisyNet noise sample is [array([0.21007776], dtype=float32), 0.5323232]. 
=============================================
[2019-03-24 04:01:18,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.42621 ]
 [49.360283]
 [49.096718]
 [48.690224]
 [48.527107]], R is [[48.9567337 ]
 [48.94150543]
 [49.0537529 ]
 [49.16943359]
 [49.27678299]].
[2019-03-24 04:01:19,197] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2131490: loss 0.0459
[2019-03-24 04:01:19,203] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2131492: learning rate 0.0001
[2019-03-24 04:01:20,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6140295e-19 9.9553114e-01 1.2062635e-05 1.0815126e-16 4.4567976e-03], sum to 1.0000
[2019-03-24 04:01:20,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3989
[2019-03-24 04:01:20,342] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 40.0, 1.0, 2.0, 0.3053563691523971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391159.6595948214, 391159.6595948214, 116241.0592548984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 428400.0000, 
sim time next is 429000.0000, 
raw observation next is [25.23333333333333, 41.16666666666667, 1.0, 2.0, 0.3022922856753969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 387300.2554321137, 387300.2554321132, 115860.2984827703], 
processed observation next is [1.0, 1.0, 0.49012345679012337, 0.41166666666666674, 1.0, 1.0, 0.16939557818499631, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13832151979718346, 0.1383215197971833, 0.2228082663130198], 
reward next is 0.7772, 
noisyNet noise sample is [array([-0.5253569], dtype=float32), 0.7976823]. 
=============================================
[2019-03-24 04:01:20,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.494316]
 [69.4418  ]
 [69.488815]
 [69.52572 ]
 [69.547806]], R is [[69.58158875]
 [69.66223145]
 [69.74181366]
 [69.82041168]
 [69.89800262]].
[2019-03-24 04:01:21,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.66891960e-17 9.71525609e-01 2.21995683e-03 1.31987876e-14
 2.62543913e-02], sum to 1.0000
[2019-03-24 04:01:21,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0311
[2019-03-24 04:01:21,666] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 56.66666666666667, 1.0, 2.0, 0.2810138093666689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360887.1799558203, 360887.1799558203, 113260.0487700589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 436200.0000, 
sim time next is 436800.0000, 
raw observation next is [21.66666666666667, 58.33333333333334, 1.0, 2.0, 0.2815076913923243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 361484.5634428374, 361484.5634428374, 113319.5857807358], 
processed observation next is [1.0, 0.043478260869565216, 0.3580246913580249, 0.5833333333333335, 1.0, 1.0, 0.14465201356229082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12910162980101336, 0.12910162980101336, 0.21792228034756883], 
reward next is 0.7821, 
noisyNet noise sample is [array([0.288311], dtype=float32), -0.6082696]. 
=============================================
[2019-03-24 04:01:25,775] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8690430e-11 1.8032269e-01 1.4241490e-01 3.5835407e-07 6.7726207e-01], sum to 1.0000
[2019-03-24 04:01:25,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-24 04:01:25,785] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 52.16666666666667, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2731495226646287, 6.9112, 6.9112, 121.9260426156618, 402995.4251143481, 402995.4251143481, 156742.1720548637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 514200.0000, 
sim time next is 514800.0000, 
raw observation next is [23.6, 53.0, 1.0, 2.0, 0.3140011061172236, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399175.0892156783, 399175.0892156783, 117315.5076030677], 
processed observation next is [1.0, 1.0, 0.4296296296296297, 0.53, 1.0, 1.0, 0.1833346501395519, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14256253186274223, 0.14256253186274223, 0.2256067453905148], 
reward next is 0.7744, 
noisyNet noise sample is [array([-0.24664287], dtype=float32), 0.15496527]. 
=============================================
[2019-03-24 04:01:30,212] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2136909: loss 1.6673
[2019-03-24 04:01:30,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2136910: learning rate 0.0001
[2019-03-24 04:01:30,589] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2137094: loss 5.2835
[2019-03-24 04:01:30,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2137095: learning rate 0.0001
[2019-03-24 04:01:30,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6496366e-21 9.9999928e-01 7.4775073e-07 6.0941731e-17 3.9490236e-10], sum to 1.0000
[2019-03-24 04:01:30,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6491
[2019-03-24 04:01:30,722] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333334, 48.5, 1.0, 2.0, 0.3426954274542354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432366.3658397129, 432366.3658397129, 120975.1182428139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 604200.0000, 
sim time next is 604800.0000, 
raw observation next is [25.3, 49.0, 1.0, 2.0, 0.3418503227757224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431430.1972175969, 431430.1972175969, 120865.9884941525], 
processed observation next is [1.0, 0.0, 0.49259259259259264, 0.49, 1.0, 1.0, 0.21648847949490765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1540822132919989, 0.1540822132919989, 0.23243459325798557], 
reward next is 0.7676, 
noisyNet noise sample is [array([0.150801], dtype=float32), -0.80900943]. 
=============================================
[2019-03-24 04:01:30,740] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2137164: loss 0.0089
[2019-03-24 04:01:30,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2137165: learning rate 0.0001
[2019-03-24 04:01:30,785] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2137184: loss 0.0918
[2019-03-24 04:01:30,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2137184: learning rate 0.0001
[2019-03-24 04:01:30,841] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137215: loss 0.0774
[2019-03-24 04:01:30,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137215: learning rate 0.0001
[2019-03-24 04:01:31,096] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2137343: loss 0.0395
[2019-03-24 04:01:31,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2137343: learning rate 0.0001
[2019-03-24 04:01:31,107] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137345: loss 0.0239
[2019-03-24 04:01:31,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137345: learning rate 0.0001
[2019-03-24 04:01:31,132] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2137360: loss 0.0062
[2019-03-24 04:01:31,135] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2137360: learning rate 0.0001
[2019-03-24 04:01:31,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137386: loss 0.0152
[2019-03-24 04:01:31,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137387: learning rate 0.0001
[2019-03-24 04:01:31,205] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2137397: loss 0.0069
[2019-03-24 04:01:31,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2137397: learning rate 0.0001
[2019-03-24 04:01:31,215] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2137398: loss 0.0767
[2019-03-24 04:01:31,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2137398: learning rate 0.0001
[2019-03-24 04:01:31,457] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2137517: loss 0.0216
[2019-03-24 04:01:31,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2137518: learning rate 0.0001
[2019-03-24 04:01:31,510] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2137538: loss 4.0613
[2019-03-24 04:01:31,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2137539: learning rate 0.0001
[2019-03-24 04:01:31,902] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2137737: loss 0.7183
[2019-03-24 04:01:31,904] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2137737: learning rate 0.0001
[2019-03-24 04:01:31,972] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2137768: loss 0.7164
[2019-03-24 04:01:31,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2137768: learning rate 0.0001
[2019-03-24 04:01:34,823] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0295693e-22 9.9990833e-01 1.7552073e-05 5.7177968e-15 7.4083415e-05], sum to 1.0000
[2019-03-24 04:01:34,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0409
[2019-03-24 04:01:34,836] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 62.0, 1.0, 2.0, 0.3894527635328729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483954.9489428662, 483954.9489428657, 127173.862487469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 901800.0000, 
sim time next is 902400.0000, 
raw observation next is [24.43333333333333, 61.66666666666667, 1.0, 2.0, 0.3916040999617455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486170.7539669792, 486170.7539669792, 127463.7596501716], 
processed observation next is [0.0, 0.43478260869565216, 0.4604938271604937, 0.6166666666666667, 1.0, 1.0, 0.2757191666211256, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.173632412131064, 0.173632412131064, 0.24512261471186847], 
reward next is 0.7549, 
noisyNet noise sample is [array([-0.71072537], dtype=float32), -0.068626605]. 
=============================================
[2019-03-24 04:01:35,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8439089e-20 9.9891603e-01 1.0694196e-03 1.0492303e-14 1.4483187e-05], sum to 1.0000
[2019-03-24 04:01:35,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-24 04:01:35,339] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 35.16666666666667, 1.0, 2.0, 0.3352135773565864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424763.7503991032, 424763.7503991032, 120018.9910553417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 688200.0000, 
sim time next is 688800.0000, 
raw observation next is [27.93333333333333, 35.33333333333334, 1.0, 2.0, 0.3333551984994206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422721.3811450418, 422721.3811450414, 119780.8229125952], 
processed observation next is [1.0, 1.0, 0.5901234567901233, 0.35333333333333344, 1.0, 1.0, 0.20637523630883403, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15097192183751493, 0.1509719218375148, 0.2303477363703754], 
reward next is 0.7697, 
noisyNet noise sample is [array([-1.1170995], dtype=float32), -1.3163141]. 
=============================================
[2019-03-24 04:01:35,382] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2139447: loss 0.0377
[2019-03-24 04:01:35,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2139454: learning rate 0.0001
[2019-03-24 04:01:38,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9898568e-19 1.0000000e+00 9.8600328e-09 5.3387328e-14 8.1627751e-12], sum to 1.0000
[2019-03-24 04:01:38,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0817
[2019-03-24 04:01:38,649] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.26666666666667, 37.66666666666667, 1.0, 2.0, 0.4669784598434424, 1.0, 2.0, 0.4669784598434424, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1136096.598609672, 1136096.598609672, 228250.8620226648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 735600.0000, 
sim time next is 736200.0000, 
raw observation next is [29.55, 36.0, 1.0, 2.0, 0.8310168046714836, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1029961.601161534, 1029961.601161534, 205857.5520473535], 
processed observation next is [1.0, 0.5217391304347826, 0.65, 0.36, 1.0, 1.0, 0.7988295293708139, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36784342898626216, 0.36784342898626216, 0.3958799077833721], 
reward next is 0.6041, 
noisyNet noise sample is [array([0.3874812], dtype=float32), 0.6233287]. 
=============================================
[2019-03-24 04:01:46,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2144951: loss 0.0202
[2019-03-24 04:01:46,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2144951: learning rate 0.0001
[2019-03-24 04:01:46,740] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2145051: loss 0.0115
[2019-03-24 04:01:46,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2145051: learning rate 0.0001
[2019-03-24 04:01:46,950] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145158: loss 0.1360
[2019-03-24 04:01:46,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145159: learning rate 0.0001
[2019-03-24 04:01:47,027] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2145192: loss 0.0514
[2019-03-24 04:01:47,033] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2145195: learning rate 0.0001
[2019-03-24 04:01:47,052] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2145203: loss 0.0528
[2019-03-24 04:01:47,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2145205: learning rate 0.0001
[2019-03-24 04:01:47,255] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145301: loss 0.1071
[2019-03-24 04:01:47,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145302: learning rate 0.0001
[2019-03-24 04:01:47,338] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2145344: loss 0.0634
[2019-03-24 04:01:47,339] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2145344: learning rate 0.0001
[2019-03-24 04:01:47,372] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2145357: loss 0.0156
[2019-03-24 04:01:47,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2145359: learning rate 0.0001
[2019-03-24 04:01:47,454] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2145400: loss 0.0175
[2019-03-24 04:01:47,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2145402: learning rate 0.0001
[2019-03-24 04:01:47,506] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2145424: loss 0.0272
[2019-03-24 04:01:47,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2145424: learning rate 0.0001
[2019-03-24 04:01:47,518] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2145430: loss 0.0730
[2019-03-24 04:01:47,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2145430: learning rate 0.0001
[2019-03-24 04:01:47,628] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145483: loss 0.0673
[2019-03-24 04:01:47,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145483: learning rate 0.0001
[2019-03-24 04:01:47,729] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2145529: loss 0.0555
[2019-03-24 04:01:47,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2145530: learning rate 0.0001
[2019-03-24 04:01:48,139] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2145735: loss 0.0209
[2019-03-24 04:01:48,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2145736: learning rate 0.0001
[2019-03-24 04:01:48,379] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2145853: loss 0.0022
[2019-03-24 04:01:48,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2145853: learning rate 0.0001
[2019-03-24 04:01:51,530] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2147406: loss 0.3847
[2019-03-24 04:01:51,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2147406: learning rate 0.0001
[2019-03-24 04:01:56,782] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 04:01:56,783] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:01:56,783] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:01:56,784] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:56,784] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:01:56,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:01:56,785] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:01:56,784] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:56,790] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:56,789] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:56,791] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:56,816] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-24 04:01:56,843] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-24 04:01:56,871] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-24 04:01:56,896] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-24 04:01:56,897] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-24 04:02:44,793] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.048227]
[2019-03-24 04:02:44,794] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.31971509333334, 64.11825043000002, 1.0, 2.0, 0.5568393383760125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425819599, 645771.2299051875, 645771.229905188, 151347.6946988688]
[2019-03-24 04:02:44,795] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:02:44,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3537437e-29 1.0000000e+00 3.1758367e-11 1.8450743e-20 8.3944698e-11], sampled 0.9860958232070522
[2019-03-24 04:03:20,068] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.048227]
[2019-03-24 04:03:20,070] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.00000000000001, 1.0, 2.0, 0.4643317741833048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557436.7966287141, 557436.7966287141, 137532.4892941306]
[2019-03-24 04:03:20,070] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:03:20,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0676597e-29 1.0000000e+00 9.6621600e-11 3.5834928e-20 1.3395820e-09], sampled 0.6121263230851143
[2019-03-24 04:03:29,790] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.048227]
[2019-03-24 04:03:29,792] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.96666666666667, 72.66666666666667, 1.0, 2.0, 0.9541192905336898, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.237448099729511, 6.9112, 121.9246340005565, 1324343.187967193, 1157276.931325023, 233161.3186344383]
[2019-03-24 04:03:29,793] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:03:29,795] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.5631569e-26 1.0000000e+00 1.3390302e-09 6.1249854e-18 1.0829789e-08], sampled 0.027293004102264873
[2019-03-24 04:03:29,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1324343.187967193 W.
[2019-03-24 04:03:37,159] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:03:37,350] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:03:37,512] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:03:37,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:03:37,656] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:03:38,668] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2150000, evaluation results [2150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:03:39,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3179735e-20 8.8642877e-01 3.6854464e-05 1.5558327e-14 1.1353431e-01], sum to 1.0000
[2019-03-24 04:03:39,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1275
[2019-03-24 04:03:39,562] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 45.0, 1.0, 2.0, 0.877874186952198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946589763795445, 6.9112, 121.9258060014346, 1121430.814934333, 1103308.127939501, 216579.0791627173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1096200.0000, 
sim time next is 1096800.0000, 
raw observation next is [26.36666666666667, 45.33333333333333, 1.0, 2.0, 0.7812942478226718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260213040245, 981617.0896993849, 981617.0896993849, 195543.5772053603], 
processed observation next is [1.0, 0.6956521739130435, 0.5320987654320989, 0.4533333333333333, 1.0, 1.0, 0.7396360093127045, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094619873330269, 0.3505775320354946, 0.3505775320354946, 0.37604534077953905], 
reward next is 0.6240, 
noisyNet noise sample is [array([-1.6038742], dtype=float32), -0.17341936]. 
=============================================
[2019-03-24 04:03:40,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4991571e-19 9.8825514e-01 5.5588760e-05 2.7419471e-12 1.1689241e-02], sum to 1.0000
[2019-03-24 04:03:40,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2591
[2019-03-24 04:03:40,368] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 74.0, 1.0, 2.0, 0.2761866390931678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 355117.9015901437, 355117.9015901437, 112679.6667058073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1127400.0000, 
sim time next is 1128000.0000, 
raw observation next is [19.16666666666667, 74.0, 1.0, 2.0, 0.2755964242440173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354409.694170025, 354409.694170025, 112608.9588846406], 
processed observation next is [1.0, 0.043478260869565216, 0.2654320987654323, 0.74, 1.0, 1.0, 0.13761479076668728, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12657489077500894, 0.12657489077500894, 0.21655569016277038], 
reward next is 0.7834, 
noisyNet noise sample is [array([-2.126699], dtype=float32), -0.34796628]. 
=============================================
[2019-03-24 04:03:40,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.06081 ]
 [65.58023 ]
 [65.68898 ]
 [66.184616]
 [66.539795]], R is [[65.1137085 ]
 [65.24588013]
 [65.37651062]
 [65.50550842]
 [65.63296509]].
[2019-03-24 04:03:42,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3913093e-19 9.9447763e-01 3.2164502e-05 3.3910829e-14 5.4901885e-03], sum to 1.0000
[2019-03-24 04:03:42,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-24 04:03:42,247] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156800.0000, 
sim time next is 1157400.0000, 
raw observation next is [20.6, 66.5, 1.0, 2.0, 0.5397508969684752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691292.0731469521, 691292.0731469516, 150331.4407642356], 
processed observation next is [1.0, 0.391304347826087, 0.3185185185185186, 0.665, 1.0, 1.0, 0.4520844011529467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24689002612391145, 0.24689002612391128, 0.2890989245466069], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.48199093], dtype=float32), 0.6134815]. 
=============================================
[2019-03-24 04:03:44,232] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2152924: loss 5.7175
[2019-03-24 04:03:44,237] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2152924: learning rate 0.0001
[2019-03-24 04:03:44,530] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2153077: loss 1.5179
[2019-03-24 04:03:44,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2153077: learning rate 0.0001
[2019-03-24 04:03:44,536] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153077: loss 1.9577
[2019-03-24 04:03:44,537] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153077: learning rate 0.0001
[2019-03-24 04:03:44,628] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2153130: loss 3.0665
[2019-03-24 04:03:44,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2153133: learning rate 0.0001
[2019-03-24 04:03:44,797] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2153217: loss 4.5515
[2019-03-24 04:03:44,801] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2153217: learning rate 0.0001
[2019-03-24 04:03:44,949] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2153298: loss 2.9154
[2019-03-24 04:03:44,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2153299: learning rate 0.0001
[2019-03-24 04:03:45,022] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153329: loss 2.9536
[2019-03-24 04:03:45,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153331: learning rate 0.0001
[2019-03-24 04:03:45,114] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2153381: loss 4.0087
[2019-03-24 04:03:45,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2153382: learning rate 0.0001
[2019-03-24 04:03:45,126] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2153387: loss 4.8276
[2019-03-24 04:03:45,126] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2153387: loss 5.0925
[2019-03-24 04:03:45,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2153388: learning rate 0.0001
[2019-03-24 04:03:45,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2153388: learning rate 0.0001
[2019-03-24 04:03:45,232] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2153445: loss 6.0477
[2019-03-24 04:03:45,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2153446: learning rate 0.0001
[2019-03-24 04:03:45,332] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153490: loss 5.3935
[2019-03-24 04:03:45,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153490: learning rate 0.0001
[2019-03-24 04:03:45,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2153607: loss 0.1305
[2019-03-24 04:03:45,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2153607: learning rate 0.0001
[2019-03-24 04:03:45,792] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2153727: loss 7.1968
[2019-03-24 04:03:45,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2153728: learning rate 0.0001
[2019-03-24 04:03:46,267] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2153919: loss 4.9913
[2019-03-24 04:03:46,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2153919: learning rate 0.0001
[2019-03-24 04:03:49,118] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2155449: loss 0.0370
[2019-03-24 04:03:49,119] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2155449: learning rate 0.0001
[2019-03-24 04:03:59,857] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2160768: loss 0.2345
[2019-03-24 04:03:59,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2160768: learning rate 0.0001
[2019-03-24 04:04:00,406] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161035: loss 0.0929
[2019-03-24 04:04:00,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161036: learning rate 0.0001
[2019-03-24 04:04:00,438] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2161058: loss 0.1418
[2019-03-24 04:04:00,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2161058: learning rate 0.0001
[2019-03-24 04:04:00,646] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2161162: loss 0.1254
[2019-03-24 04:04:00,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2161162: learning rate 0.0001
[2019-03-24 04:04:00,747] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2161207: loss 0.0449
[2019-03-24 04:04:00,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2161207: learning rate 0.0001
[2019-03-24 04:04:00,821] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161248: loss 0.0055
[2019-03-24 04:04:00,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161249: learning rate 0.0001
[2019-03-24 04:04:00,842] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2161260: loss 0.0011
[2019-03-24 04:04:00,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2161261: learning rate 0.0001
[2019-03-24 04:04:00,937] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2161295: loss 0.0252
[2019-03-24 04:04:00,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2161295: learning rate 0.0001
[2019-03-24 04:04:01,199] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2161431: loss 0.1305
[2019-03-24 04:04:01,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2161432: learning rate 0.0001
[2019-03-24 04:04:01,219] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2161440: loss 0.1072
[2019-03-24 04:04:01,224] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2161441: learning rate 0.0001
[2019-03-24 04:04:01,255] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161454: loss 0.1388
[2019-03-24 04:04:01,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161456: learning rate 0.0001
[2019-03-24 04:04:01,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2161552: loss 0.1706
[2019-03-24 04:04:01,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2161556: learning rate 0.0001
[2019-03-24 04:04:01,496] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161577: loss 0.0478
[2019-03-24 04:04:01,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161579: learning rate 0.0001
[2019-03-24 04:04:01,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4965400e-22 9.9999988e-01 1.1685005e-08 3.5314686e-17 6.7054543e-08], sum to 1.0000
[2019-03-24 04:04:01,645] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9375
[2019-03-24 04:04:01,649] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 54.0, 1.0, 2.0, 0.5493174414445497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650148.1797353628, 650148.1797353628, 150663.7779339637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1534200.0000, 
sim time next is 1534800.0000, 
raw observation next is [28.7, 56.0, 1.0, 2.0, 0.5298129168716542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627863.196986527, 627863.196986527, 147502.7290671], 
processed observation next is [0.0, 0.782608695652174, 0.6185185185185185, 0.56, 1.0, 1.0, 0.440253472466255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22423685606661678, 0.22423685606661678, 0.2836590943598077], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.1298685], dtype=float32), 1.2929876]. 
=============================================
[2019-03-24 04:04:01,807] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2161732: loss 0.1328
[2019-03-24 04:04:01,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2161733: learning rate 0.0001
[2019-03-24 04:04:02,396] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2162027: loss 0.1645
[2019-03-24 04:04:02,398] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2162029: learning rate 0.0001
[2019-03-24 04:04:05,466] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2163552: loss 0.9076
[2019-03-24 04:04:05,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2163552: learning rate 0.0001
[2019-03-24 04:04:06,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4871143e-15 9.9846822e-01 1.0009441e-03 1.8754585e-08 5.3089851e-04], sum to 1.0000
[2019-03-24 04:04:06,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1162
[2019-03-24 04:04:06,681] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 46.5, 1.0, 2.0, 0.354388301446085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444846.6856177954, 444846.6856177954, 122488.3301042698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1624200.0000, 
sim time next is 1624800.0000, 
raw observation next is [26.23333333333333, 47.0, 1.0, 2.0, 0.3551708154121948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445948.3592934466, 445948.3592934461, 122594.3554336894], 
processed observation next is [1.0, 0.8260869565217391, 0.5271604938271603, 0.47, 1.0, 1.0, 0.23234620882404144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15926727117623093, 0.15926727117623077, 0.23575837583401807], 
reward next is 0.7642, 
noisyNet noise sample is [array([-0.8803402], dtype=float32), -0.08119641]. 
=============================================
[2019-03-24 04:04:08,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6830458e-22 9.9999142e-01 8.5713964e-06 3.1396374e-14 5.2969931e-09], sum to 1.0000
[2019-03-24 04:04:08,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2120
[2019-03-24 04:04:08,127] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 53.5, 1.0, 2.0, 0.3359806667770659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425212.2801154738, 425212.2801154738, 120113.667291135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1633800.0000, 
sim time next is 1634400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3335838637535274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422344.1303396783, 422344.1303396778, 119804.4267117833], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.54, 1.0, 1.0, 0.20664745684943736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15083718940702798, 0.15083718940702778, 0.23039312829189096], 
reward next is 0.7696, 
noisyNet noise sample is [array([-1.4949511], dtype=float32), -0.5435439]. 
=============================================
[2019-03-24 04:04:10,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7417457e-22 9.9997437e-01 2.5595104e-05 1.8347138e-12 9.2565964e-09], sum to 1.0000
[2019-03-24 04:04:10,553] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3145
[2019-03-24 04:04:10,556] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 70.33333333333334, 1.0, 2.0, 0.7559209052192298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 941015.0794587166, 941015.0794587166, 190123.7222771626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1690800.0000, 
sim time next is 1691400.0000, 
raw observation next is [22.91666666666667, 69.66666666666666, 1.0, 2.0, 0.7526139090332702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 936001.46221054, 936001.46221054, 189428.8086850785], 
processed observation next is [1.0, 0.5652173913043478, 0.4043209876543212, 0.6966666666666665, 1.0, 1.0, 0.7054927488491312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33428623650376427, 0.33428623650376427, 0.3642861705482279], 
reward next is 0.6357, 
noisyNet noise sample is [array([-0.3571627], dtype=float32), -0.29188126]. 
=============================================
[2019-03-24 04:04:16,023] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2168774: loss 2.5155
[2019-03-24 04:04:16,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2168775: learning rate 0.0001
[2019-03-24 04:04:16,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2169035: loss 1.3183
[2019-03-24 04:04:16,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2169035: learning rate 0.0001
[2019-03-24 04:04:16,616] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169062: loss -0.2761
[2019-03-24 04:04:16,620] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169064: learning rate 0.0001
[2019-03-24 04:04:16,638] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2862026e-13 9.9738401e-01 2.2659192e-03 7.4720907e-07 3.4930606e-04], sum to 1.0000
[2019-03-24 04:04:16,646] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2936
[2019-03-24 04:04:16,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.6, 87.0, 1.0, 2.0, 0.3132636989261762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398973.90683122, 398973.90683122, 117227.2107332534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1807200.0000, 
sim time next is 1807800.0000, 
raw observation next is [18.61666666666667, 87.16666666666667, 1.0, 2.0, 0.3135322801565211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399148.0137608356, 399148.0137608361, 117260.2014232472], 
processed observation next is [1.0, 0.9565217391304348, 0.24506172839506188, 0.8716666666666667, 1.0, 1.0, 0.18277652399585848, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14255286205744128, 0.14255286205744147, 0.22550038735239847], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.89236116], dtype=float32), 0.107250474]. 
=============================================
[2019-03-24 04:04:16,773] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2169138: loss 1.5646
[2019-03-24 04:04:16,774] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2169138: learning rate 0.0001
[2019-03-24 04:04:16,823] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2169164: loss 1.2180
[2019-03-24 04:04:16,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2169165: learning rate 0.0001
[2019-03-24 04:04:16,879] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2169195: loss 1.0940
[2019-03-24 04:04:16,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2169195: learning rate 0.0001
[2019-03-24 04:04:16,954] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2169225: loss 1.0896
[2019-03-24 04:04:16,957] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2169225: learning rate 0.0001
[2019-03-24 04:04:16,995] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169251: loss 1.0234
[2019-03-24 04:04:16,998] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169251: learning rate 0.0001
[2019-03-24 04:04:17,372] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2169435: loss 0.7256
[2019-03-24 04:04:17,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2169436: learning rate 0.0001
[2019-03-24 04:04:17,390] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169440: loss 0.5090
[2019-03-24 04:04:17,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169440: learning rate 0.0001
[2019-03-24 04:04:17,393] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2169441: loss 0.5778
[2019-03-24 04:04:17,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2169442: learning rate 0.0001
[2019-03-24 04:04:17,665] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169577: loss 0.1018
[2019-03-24 04:04:17,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169579: learning rate 0.0001
[2019-03-24 04:04:17,863] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2169675: loss 0.0839
[2019-03-24 04:04:17,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2169675: learning rate 0.0001
[2019-03-24 04:04:17,994] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2169742: loss 0.0794
[2019-03-24 04:04:17,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2169742: learning rate 0.0001
[2019-03-24 04:04:18,599] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2170035: loss 0.2756
[2019-03-24 04:04:18,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2170035: learning rate 0.0001
[2019-03-24 04:04:21,739] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2171582: loss 0.0602
[2019-03-24 04:04:21,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2171582: learning rate 0.0001
[2019-03-24 04:04:23,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3250876e-17 9.9995112e-01 2.8331511e-05 2.3333593e-09 2.0556314e-05], sum to 1.0000
[2019-03-24 04:04:23,298] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6783
[2019-03-24 04:04:23,305] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.45, 90.16666666666666, 1.0, 2.0, 0.4077251963786606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505378.1535866513, 505378.1535866513, 129717.1473385541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929000.0000, 
sim time next is 1929600.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4210835306724902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521710.3443778895, 521710.3443778899, 131628.4008476031], 
processed observation next is [1.0, 0.34782608695652173, 0.3148148148148148, 0.9, 1.0, 1.0, 0.3108137269910598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18632512299210338, 0.18632512299210352, 0.2531315400915444], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.1063121], dtype=float32), 0.54429346]. 
=============================================
[2019-03-24 04:04:24,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8028167e-15 1.7511190e-01 6.8661706e-03 1.6174495e-06 8.1802028e-01], sum to 1.0000
[2019-03-24 04:04:24,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0613
[2019-03-24 04:04:24,739] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 66.66666666666667, 1.0, 2.0, 0.3294083634966229, 1.0, 2.0, 0.3294083634966229, 1.0, 2.0, 0.5256085758259363, 6.9112, 6.9112, 121.94756008, 1148317.582807009, 1148317.582807009, 267568.0801477392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1948800.0000, 
sim time next is 1949400.0000, 
raw observation next is [26.45, 65.5, 1.0, 2.0, 0.9854359887568688, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.293952573775099, 6.9112, 121.9246828113699, 1363761.770066555, 1167760.428224945, 239544.8032386375], 
processed observation next is [1.0, 0.5652173913043478, 0.5351851851851852, 0.655, 1.0, 1.0, 0.9826618913772247, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03827525737750994, 0.0, 0.8094531011337346, 0.4870577750237696, 0.4170572957946232, 0.460663083151226], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29627284], dtype=float32), -0.9585823]. 
=============================================
[2019-03-24 04:04:28,679] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 04:04:28,680] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:04:28,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:04:28,680] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:04:28,681] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:04:28,682] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:04:28,683] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:04:28,683] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:04:28,684] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:04:28,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:04:28,685] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:04:28,712] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-24 04:04:28,741] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-24 04:04:28,768] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-24 04:04:28,792] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-24 04:04:28,793] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-24 04:04:32,611] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0593725]
[2019-03-24 04:04:32,612] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.3, 17.16666666666667, 1.0, 2.0, 0.3713346382198155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476539.1457724046, 476539.1457724046, 124843.6080823142]
[2019-03-24 04:04:32,613] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:04:32,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.0635410e-24 9.9999893e-01 5.4416819e-07 1.1825263e-11 4.4425485e-07], sampled 0.6837898981488965
[2019-03-24 04:04:49,420] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0593725]
[2019-03-24 04:04:49,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.0, 28.5, 1.0, 2.0, 0.4570364515687735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551294.259652707, 551294.259652707, 136523.3860602382]
[2019-03-24 04:04:49,422] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:04:49,424] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3262285e-24 9.9999928e-01 3.9110665e-07 6.9618538e-12 3.1002554e-07], sampled 0.35364011467126943
[2019-03-24 04:04:55,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0593725]
[2019-03-24 04:04:55,345] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.83333333333334, 92.16666666666666, 1.0, 2.0, 0.3899707432273649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485562.2675422504, 485562.2675422504, 127265.516904523]
[2019-03-24 04:04:55,347] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:04:55,351] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0794679e-23 9.9999905e-01 5.4733476e-07 1.3556517e-11 3.7756786e-07], sampled 0.42728417001400965
[2019-03-24 04:05:03,505] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0593725]
[2019-03-24 04:05:03,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.26666666666667, 40.33333333333334, 1.0, 2.0, 0.3699542867771821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462322.4798551129, 462322.4798551129, 124546.5778991389]
[2019-03-24 04:05:03,508] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:05:03,511] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.3541167e-24 9.9999940e-01 3.5025695e-07 7.3826674e-12 2.0075869e-07], sampled 0.7153747925954982
[2019-03-24 04:05:18,735] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0593725]
[2019-03-24 04:05:18,736] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.75, 55.0, 1.0, 2.0, 0.9721515194350966, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9259691632604, 1823450.173061852, 1823450.173061852, 373000.6641177613]
[2019-03-24 04:05:18,737] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:05:18,740] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6609952e-19 9.9998415e-01 8.8590759e-06 1.2897476e-09 7.0039096e-06], sampled 0.11563891515940472
[2019-03-24 04:05:18,742] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1823450.173061852 W.
[2019-03-24 04:06:09,461] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:06:09,749] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:06:09,788] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:06:09,807] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:06:09,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:06:10,908] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2175000, evaluation results [2175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:06:13,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8797844e-24 9.9999499e-01 2.3851447e-07 2.7998468e-11 4.7790641e-06], sum to 1.0000
[2019-03-24 04:06:13,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5919
[2019-03-24 04:06:13,457] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 0.6026587889575423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692856.185198979, 692856.185198979, 158831.8881031575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2058600.0000, 
sim time next is 2059200.0000, 
raw observation next is [26.9, 75.0, 1.0, 2.0, 0.6013212733106752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691442.9745468321, 691442.9745468321, 158606.6605946496], 
processed observation next is [0.0, 0.8695652173913043, 0.5518518518518518, 0.75, 1.0, 1.0, 0.5253824682269943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2469439194810115, 0.2469439194810115, 0.3050128088358646], 
reward next is 0.6950, 
noisyNet noise sample is [array([1.821118], dtype=float32), -1.40185]. 
=============================================
[2019-03-24 04:06:13,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2508490e-19 9.9986017e-01 7.2047269e-06 5.8509162e-09 1.3271435e-04], sum to 1.0000
[2019-03-24 04:06:13,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1354
[2019-03-24 04:06:13,985] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 78.0, 1.0, 2.0, 0.5139342380303181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611142.825641699, 611142.8256416986, 145032.5606388845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068200.0000, 
sim time next is 2068800.0000, 
raw observation next is [24.5, 78.0, 1.0, 2.0, 0.5066610724121237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 604089.8906944225, 604089.8906944221, 143937.5748744318], 
processed observation next is [0.0, 0.9565217391304348, 0.46296296296296297, 0.78, 1.0, 1.0, 0.4126917528715758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21574638953372233, 0.21574638953372216, 0.27680302860467654], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.9724071], dtype=float32), 0.5126195]. 
=============================================
[2019-03-24 04:06:14,395] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2176803: loss 0.0094
[2019-03-24 04:06:14,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2176803: learning rate 0.0001
[2019-03-24 04:06:14,836] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2177030: loss 0.1248
[2019-03-24 04:06:14,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2177030: learning rate 0.0001
[2019-03-24 04:06:14,949] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2177088: loss 0.1030
[2019-03-24 04:06:14,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2177090: learning rate 0.0001
[2019-03-24 04:06:14,995] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2177112: loss 0.0432
[2019-03-24 04:06:14,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2177112: learning rate 0.0001
[2019-03-24 04:06:15,014] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177121: loss 0.0213
[2019-03-24 04:06:15,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177121: learning rate 0.0001
[2019-03-24 04:06:15,114] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2177174: loss 0.0227
[2019-03-24 04:06:15,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2177175: learning rate 0.0001
[2019-03-24 04:06:15,169] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2177200: loss 0.0623
[2019-03-24 04:06:15,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2177201: learning rate 0.0001
[2019-03-24 04:06:15,189] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2177208: loss 0.0447
[2019-03-24 04:06:15,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2177208: learning rate 0.0001
[2019-03-24 04:06:15,449] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2177343: loss 0.0269
[2019-03-24 04:06:15,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2177344: learning rate 0.0001
[2019-03-24 04:06:15,630] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177443: loss 0.0053
[2019-03-24 04:06:15,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177443: learning rate 0.0001
[2019-03-24 04:06:15,720] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177482: loss 0.0197
[2019-03-24 04:06:15,723] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177482: learning rate 0.0001
[2019-03-24 04:06:15,767] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2177510: loss 0.0031
[2019-03-24 04:06:15,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2177510: learning rate 0.0001
[2019-03-24 04:06:16,194] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2177731: loss 0.0232
[2019-03-24 04:06:16,197] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2177731: learning rate 0.0001
[2019-03-24 04:06:16,240] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2177755: loss 0.0027
[2019-03-24 04:06:16,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2177756: learning rate 0.0001
[2019-03-24 04:06:16,951] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2178125: loss 0.0971
[2019-03-24 04:06:16,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2178127: learning rate 0.0001
[2019-03-24 04:06:17,581] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8975080e-17 9.9886215e-01 1.3434172e-04 4.1654804e-09 1.0035670e-03], sum to 1.0000
[2019-03-24 04:06:17,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2899
[2019-03-24 04:06:17,592] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 81.0, 1.0, 2.0, 0.5693743025814705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662907.6950306101, 662907.6950306101, 153553.3460403517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158800.0000, 
sim time next is 2159400.0000, 
raw observation next is [25.28333333333333, 81.5, 1.0, 2.0, 0.5687727720824777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662337.8966197898, 662337.8966197898, 153458.1306126975], 
processed observation next is [0.0, 1.0, 0.49197530864197525, 0.815, 1.0, 1.0, 0.48663425247914005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23654924879278205, 0.23654924879278205, 0.2951117896398029], 
reward next is 0.7049, 
noisyNet noise sample is [array([-0.25375557], dtype=float32), -0.515787]. 
=============================================
[2019-03-24 04:06:19,955] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2179688: loss 0.6660
[2019-03-24 04:06:19,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2179689: learning rate 0.0001
[2019-03-24 04:06:20,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0356915e-14 9.9992776e-01 5.3724802e-06 9.5219633e-08 6.6712979e-05], sum to 1.0000
[2019-03-24 04:06:20,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-24 04:06:20,647] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 94.33333333333334, 1.0, 2.0, 0.5297134380173569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627374.44539685, 627374.44539685, 147472.2001205154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2233200.0000, 
sim time next is 2233800.0000, 
raw observation next is [22.7, 94.5, 1.0, 2.0, 0.5289745265665311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626252.462116853, 626252.462116853, 147342.8508683413], 
processed observation next is [1.0, 0.8695652173913043, 0.39629629629629626, 0.945, 1.0, 1.0, 0.43925538876967984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2236615936131618, 0.2236615936131618, 0.28335163628527177], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.38542616], dtype=float32), 1.9637964]. 
=============================================
[2019-03-24 04:06:21,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3275781e-15 9.9986911e-01 1.1769252e-04 2.3950463e-07 1.3016291e-05], sum to 1.0000
[2019-03-24 04:06:21,075] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9857
[2019-03-24 04:06:21,080] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 75.16666666666667, 1.0, 2.0, 0.3075376143696739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395790.8896638951, 395790.8896638951, 116505.5377313965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434200.0000, 
sim time next is 2434800.0000, 
raw observation next is [18.76666666666667, 76.33333333333334, 1.0, 2.0, 0.2759191550640063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355137.9412800927, 355137.9412800922, 112645.2314566344], 
processed observation next is [1.0, 0.17391304347826086, 0.2506172839506174, 0.7633333333333334, 1.0, 1.0, 0.13799899412381705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12683497902860452, 0.12683497902860436, 0.2166254451089123], 
reward next is 0.7834, 
noisyNet noise sample is [array([-0.2568561], dtype=float32), -1.1371977]. 
=============================================
[2019-03-24 04:06:21,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4181775e-18 9.9999070e-01 8.4838439e-06 1.6478568e-08 7.8932965e-07], sum to 1.0000
[2019-03-24 04:06:21,585] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1516
[2019-03-24 04:06:21,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2283627.49007687 W.
[2019-03-24 04:06:21,592] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.3, 59.0, 1.0, 2.0, 0.7078504106842685, 1.0, 1.0, 0.6672898673185689, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2283627.49007687, 2283627.490076871, 431356.2735601653], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2813400.0000, 
sim time next is 2814000.0000, 
raw observation next is [32.40000000000001, 57.66666666666667, 1.0, 2.0, 0.7045850110855042, 1.0, 2.0, 0.6656571675191867, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2278032.868471794, 2278032.868471795, 430474.4159302838], 
processed observation next is [1.0, 0.5652173913043478, 0.755555555555556, 0.5766666666666667, 1.0, 1.0, 0.6483154893875049, 1.0, 1.0, 0.6019728184752222, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8135831673113549, 0.8135831673113555, 0.8278354152505457], 
reward next is 0.1722, 
noisyNet noise sample is [array([-0.5947546], dtype=float32), 1.2188269]. 
=============================================
[2019-03-24 04:06:21,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.410378]
 [61.26869 ]
 [61.25802 ]
 [60.133873]
 [59.93254 ]], R is [[60.89982224]
 [60.29082489]
 [59.6879158 ]
 [59.40625381]
 [59.01101303]].
[2019-03-24 04:06:25,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3017852e-17 9.0558201e-01 3.9133936e-04 3.7322441e-06 9.4022907e-02], sum to 1.0000
[2019-03-24 04:06:25,234] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4314
[2019-03-24 04:06:25,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1388275.556024635 W.
[2019-03-24 04:06:25,248] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.73333333333333, 73.0, 1.0, 2.0, 0.6018958855264968, 1.0, 2.0, 0.6018958855264968, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1388275.556024635, 1388275.556024634, 269465.5911282079], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2301600.0000, 
sim time next is 2302200.0000, 
raw observation next is [25.8, 72.5, 1.0, 2.0, 0.6071062232365226, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9688600420758349, 6.911199999999999, 6.9112, 121.9260426156618, 1412262.85067799, 1412262.850677991, 296162.4571780254], 
processed observation next is [1.0, 0.6521739130434783, 0.5111111111111112, 0.725, 1.0, 1.0, 0.5322693133768126, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9610750525947936, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5043795895278536, 0.504379589527854, 0.5695431868808181], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08948047], dtype=float32), -0.16156203]. 
=============================================
[2019-03-24 04:06:25,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5271139e-17 8.7251890e-01 1.1810173e-03 6.6652556e-06 1.2629342e-01], sum to 1.0000
[2019-03-24 04:06:25,518] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2616
[2019-03-24 04:06:25,523] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 76.66666666666667, 1.0, 2.0, 0.162793723851573, 1.0, 2.0, 0.162793723851573, 1.0, 2.0, 0.2612384287592995, 6.911200000000001, 6.9112, 121.94756008, 578405.3706285914, 578405.3706285909, 208506.1228008229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2319000.0000, 
sim time next is 2319600.0000, 
raw observation next is [24.03333333333333, 77.33333333333334, 1.0, 2.0, 0.4793762758565284, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575183.7508187972, 575183.7508187972, 139814.0065741738], 
processed observation next is [1.0, 0.8695652173913043, 0.4456790123456789, 0.7733333333333334, 1.0, 1.0, 0.38020985221015285, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20542276814957042, 0.20542276814957042, 0.26887308956571887], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.36978722], dtype=float32), -1.016473]. 
=============================================
[2019-03-24 04:06:29,983] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2184794: loss 0.2768
[2019-03-24 04:06:29,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2184794: learning rate 0.0001
[2019-03-24 04:06:30,411] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2185000: loss 0.0349
[2019-03-24 04:06:30,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2185003: learning rate 0.0001
[2019-03-24 04:06:30,437] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2185013: loss 0.1309
[2019-03-24 04:06:30,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2185013: learning rate 0.0001
[2019-03-24 04:06:30,717] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2185104: loss 0.1443
[2019-03-24 04:06:30,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2185104: learning rate 0.0001
[2019-03-24 04:06:30,722] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2185104: loss 0.1019
[2019-03-24 04:06:30,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2185105: learning rate 0.0001
[2019-03-24 04:06:30,778] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2185138: loss 0.1884
[2019-03-24 04:06:30,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2185138: learning rate 0.0001
[2019-03-24 04:06:30,828] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185163: loss 0.0139
[2019-03-24 04:06:30,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185164: learning rate 0.0001
[2019-03-24 04:06:30,938] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2185215: loss 0.0690
[2019-03-24 04:06:30,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2185215: learning rate 0.0001
[2019-03-24 04:06:31,261] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2185372: loss 0.0598
[2019-03-24 04:06:31,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2185373: learning rate 0.0001
[2019-03-24 04:06:31,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185418: loss 0.2363
[2019-03-24 04:06:31,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185418: learning rate 0.0001
[2019-03-24 04:06:31,477] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2185478: loss 0.3216
[2019-03-24 04:06:31,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2185478: learning rate 0.0001
[2019-03-24 04:06:31,598] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2185535: loss 0.1787
[2019-03-24 04:06:31,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2185536: learning rate 0.0001
[2019-03-24 04:06:31,668] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185570: loss 0.1053
[2019-03-24 04:06:31,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185571: learning rate 0.0001
[2019-03-24 04:06:32,413] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2185943: loss 0.0336
[2019-03-24 04:06:32,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2185945: learning rate 0.0001
[2019-03-24 04:06:32,910] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2186182: loss 0.0151
[2019-03-24 04:06:32,912] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2186183: learning rate 0.0001
[2019-03-24 04:06:36,067] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2187739: loss 0.0932
[2019-03-24 04:06:36,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2187739: learning rate 0.0001
[2019-03-24 04:06:37,007] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5855473e-23 1.0000000e+00 8.2534291e-10 2.5607001e-08 5.3813740e-18], sum to 1.0000
[2019-03-24 04:06:37,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6203
[2019-03-24 04:06:37,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 28.0, 1.0, 2.0, 0.3801996664322777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473564.1161300126, 473564.1161300126, 125917.0778034122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2485200.0000, 
sim time next is 2485800.0000, 
raw observation next is [32.0, 28.5, 1.0, 2.0, 0.3797289328052103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473103.8559341411, 473103.8559341406, 125854.8652222343], 
processed observation next is [1.0, 0.782608695652174, 0.7407407407407407, 0.285, 1.0, 1.0, 0.2615820628633456, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16896566283362183, 0.16896566283362166, 0.24202858696583518], 
reward next is 0.7580, 
noisyNet noise sample is [array([1.3803653], dtype=float32), 0.59303117]. 
=============================================
[2019-03-24 04:06:41,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1976765e-20 9.9999654e-01 6.8964809e-08 3.3216877e-06 2.1305336e-12], sum to 1.0000
[2019-03-24 04:06:41,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2400
[2019-03-24 04:06:41,316] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.78333333333333, 85.0, 1.0, 2.0, 0.4758668808837697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574744.1121849389, 574744.1121849393, 139404.1649407136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2595000.0000, 
sim time next is 2595600.0000, 
raw observation next is [22.6, 86.0, 1.0, 2.0, 0.4740181254086375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572984.2352414648, 572984.2352414648, 139136.2188654489], 
processed observation next is [0.0, 0.043478260869565216, 0.39259259259259266, 0.86, 1.0, 1.0, 0.3738311016769494, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2046372268719517, 0.2046372268719517, 0.2675696516643248], 
reward next is 0.7324, 
noisyNet noise sample is [array([0.5077532], dtype=float32), -0.79043245]. 
=============================================
[2019-03-24 04:06:43,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2085089e-19 9.9991095e-01 1.6142359e-07 8.8917288e-05 7.4534372e-11], sum to 1.0000
[2019-03-24 04:06:43,778] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8912
[2019-03-24 04:06:43,788] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 98.0, 1.0, 2.0, 0.5394170990963583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637912.5164393192, 637912.5164393192, 149014.5529760102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2852400.0000, 
sim time next is 2853000.0000, 
raw observation next is [22.5, 97.0, 1.0, 2.0, 0.540568202211106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638698.3872514431, 638698.3872514431, 149180.0193241225], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.97, 1.0, 1.0, 0.45305738358465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2281065668755154, 0.2281065668755154, 0.2868846525463894], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.40316352], dtype=float32), 0.8532212]. 
=============================================
[2019-03-24 04:06:43,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.110336]
 [61.523388]
 [62.61329 ]
 [65.30243 ]
 [65.170204]], R is [[60.71198654]
 [60.81829834]
 [60.92368698]
 [61.02668381]
 [61.12347794]].
[2019-03-24 04:06:45,842] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6991054e-18 9.9857593e-01 2.5894490e-06 1.4214575e-03 2.9022669e-08], sum to 1.0000
[2019-03-24 04:06:45,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8421
[2019-03-24 04:06:45,855] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 89.66666666666667, 1.0, 2.0, 0.4372240712030313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536457.5241597111, 536457.5241597111, 133855.9994478117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2697600.0000, 
sim time next is 2698200.0000, 
raw observation next is [21.1, 88.0, 1.0, 2.0, 0.4261064050016795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524692.7872810364, 524692.7872810364, 132279.3457571389], 
processed observation next is [0.0, 0.21739130434782608, 0.3370370370370371, 0.88, 1.0, 1.0, 0.3167933392877137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1873902811717987, 0.1873902811717987, 0.2543833572252671], 
reward next is 0.7456, 
noisyNet noise sample is [array([1.1332071], dtype=float32), 0.598125]. 
=============================================
[2019-03-24 04:06:46,180] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2192744: loss 0.0010
[2019-03-24 04:06:46,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2192744: learning rate 0.0001
[2019-03-24 04:06:46,580] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2192942: loss 0.0849
[2019-03-24 04:06:46,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2192942: learning rate 0.0001
[2019-03-24 04:06:46,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192962: loss 0.1080
[2019-03-24 04:06:46,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192962: learning rate 0.0001
[2019-03-24 04:06:46,840] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2193072: loss 0.0650
[2019-03-24 04:06:46,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2193073: learning rate 0.0001
[2019-03-24 04:06:46,944] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193127: loss 0.0127
[2019-03-24 04:06:46,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193128: learning rate 0.0001
[2019-03-24 04:06:46,962] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2193135: loss 0.0112
[2019-03-24 04:06:46,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2193135: learning rate 0.0001
[2019-03-24 04:06:46,978] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2193142: loss 0.0027
[2019-03-24 04:06:46,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2193142: learning rate 0.0001
[2019-03-24 04:06:47,038] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2193168: loss 0.0030
[2019-03-24 04:06:47,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2193169: learning rate 0.0001
[2019-03-24 04:06:47,643] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2193466: loss 0.0034
[2019-03-24 04:06:47,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2193466: learning rate 0.0001
[2019-03-24 04:06:47,656] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193472: loss 0.0033
[2019-03-24 04:06:47,659] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193472: learning rate 0.0001
[2019-03-24 04:06:47,682] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2193484: loss 0.0063
[2019-03-24 04:06:47,685] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2193486: learning rate 0.0001
[2019-03-24 04:06:47,718] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2193504: loss 0.0023
[2019-03-24 04:06:47,720] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2193505: learning rate 0.0001
[2019-03-24 04:06:47,775] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2193534: loss 0.0006
[2019-03-24 04:06:47,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2193534: learning rate 0.0001
[2019-03-24 04:06:47,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8269154e-20 9.9999809e-01 6.8357139e-08 1.8294618e-06 1.2262112e-09], sum to 1.0000
[2019-03-24 04:06:47,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9806
[2019-03-24 04:06:48,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 52.5, 1.0, 2.0, 0.6174136587498048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705491.0459390059, 705491.0459390059, 161191.1247404644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737800.0000, 
sim time next is 2738400.0000, 
raw observation next is [31.4, 53.66666666666666, 1.0, 2.0, 0.6252470060378993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712822.3822146391, 712822.3822146391, 162487.1054610476], 
processed observation next is [0.0, 0.6956521739130435, 0.7185185185185184, 0.5366666666666666, 1.0, 1.0, 0.5538654833784515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25457942221951396, 0.25457942221951396, 0.312475202809707], 
reward next is 0.6875, 
noisyNet noise sample is [array([0.42937815], dtype=float32), 1.4443531]. 
=============================================
[2019-03-24 04:06:48,740] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2194004: loss 0.0296
[2019-03-24 04:06:48,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2194004: learning rate 0.0001
[2019-03-24 04:06:49,098] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194180: loss 0.0579
[2019-03-24 04:06:49,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194180: learning rate 0.0001
[2019-03-24 04:06:52,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6710991e-14 9.9999797e-01 1.9413861e-08 2.0599246e-06 3.8644081e-11], sum to 1.0000
[2019-03-24 04:06:52,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9365
[2019-03-24 04:06:52,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2275091.63617559 W.
[2019-03-24 04:06:52,451] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.73333333333333, 56.33333333333334, 1.0, 2.0, 0.9971979946203171, 1.0, 2.0, 0.9971979946203171, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2275091.63617559, 2275091.636175591, 431978.2006725952], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2817600.0000, 
sim time next is 2818200.0000, 
raw observation next is [32.76666666666667, 56.66666666666666, 1.0, 2.0, 0.9862351080113949, 1.0, 2.0, 0.9862351080113949, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2250048.46311502, 2250048.46311502, 426719.934194085], 
processed observation next is [1.0, 0.6086956521739131, 0.769135802469136, 0.5666666666666665, 1.0, 1.0, 0.9836132238230891, 1.0, 1.0, 0.9836132238230891, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.8035887368267929, 0.8035887368267929, 0.8206152580655481], 
reward next is 0.1794, 
noisyNet noise sample is [array([-0.9674352], dtype=float32), 0.8409524]. 
=============================================
[2019-03-24 04:06:52,755] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2195965: loss 1.3767
[2019-03-24 04:06:52,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2195965: learning rate 0.0001
[2019-03-24 04:06:55,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0984772e-19 1.0000000e+00 1.0795279e-13 1.1809301e-10 1.5178067e-16], sum to 1.0000
[2019-03-24 04:06:55,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9718
[2019-03-24 04:06:55,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2347613.30283876 W.
[2019-03-24 04:06:55,537] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 80.33333333333334, 1.0, 2.0, 0.7451954039954902, 1.0, 2.0, 0.6859623639741799, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2347613.30283876, 2347613.30283876, 441605.6433119162], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3062400.0000, 
sim time next is 3063000.0000, 
raw observation next is [29.66666666666666, 78.16666666666667, 1.0, 2.0, 0.7563412484328458, 1.0, 2.0, 0.6915352861928575, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2366711.153311532, 2366711.153311531, 444723.0537277769], 
processed observation next is [1.0, 0.43478260869565216, 0.6543209876543208, 0.7816666666666667, 1.0, 1.0, 0.7099300576581498, 1.0, 1.0, 0.6327801026105446, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8452539833255471, 0.8452539833255468, 0.8552366417841863], 
reward next is 0.1448, 
noisyNet noise sample is [array([0.29492667], dtype=float32), -0.09606113]. 
=============================================
[2019-03-24 04:06:55,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[45.968197]
 [46.555847]
 [47.443462]
 [48.097572]
 [49.018276]], R is [[45.10645294]
 [44.80614471]
 [44.52423477]
 [44.27491379]
 [43.83216476]].
[2019-03-24 04:06:55,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5930336e-29 1.0000000e+00 1.7280129e-19 5.9676065e-16 1.6130800e-23], sum to 1.0000
[2019-03-24 04:06:55,904] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2042
[2019-03-24 04:06:55,911] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5099869736391112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611960.9638264476, 611960.9638264476, 144606.0835339737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2872800.0000, 
sim time next is 2873400.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5691350708377527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683119.485250628, 683119.485250628, 154335.1069546173], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9400000000000002, 1.0, 1.0, 0.4870655605211342, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24397124473236714, 0.24397124473236714, 0.29679828260503327], 
reward next is 0.7032, 
noisyNet noise sample is [array([-1.370153], dtype=float32), 0.6832769]. 
=============================================
[2019-03-24 04:06:58,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9334878e-23 1.0000000e+00 1.9179376e-12 2.1476444e-08 1.3237686e-16], sum to 1.0000
[2019-03-24 04:06:58,367] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5747
[2019-03-24 04:06:58,370] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.6503151812899226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741147.9629925992, 741147.9629925992, 166950.1529005346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [26.0, 86.33333333333334, 1.0, 2.0, 0.6625041960020781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755046.3201919816, 755046.3201919816, 169165.7056526192], 
processed observation next is [1.0, 0.8695652173913043, 0.5185185185185185, 0.8633333333333334, 1.0, 1.0, 0.5982192809548549, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26965940006856487, 0.26965940006856487, 0.32531866471657533], 
reward next is 0.6747, 
noisyNet noise sample is [array([0.03456268], dtype=float32), 1.1128383]. 
=============================================
[2019-03-24 04:07:00,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3217169e-16 9.9978608e-01 3.8333217e-09 2.1392018e-04 4.4601242e-10], sum to 1.0000
[2019-03-24 04:07:00,579] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5084
[2019-03-24 04:07:00,585] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.8251272356298684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940499.1306660377, 940499.1306660377, 201181.6075651884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947800.0000, 
sim time next is 2948400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.795110088513358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906264.6610070218, 906264.6610070218, 194927.6578627298], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7560834387063785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3236659503596506, 0.3236659503596506, 0.3748608805052496], 
reward next is 0.6251, 
noisyNet noise sample is [array([-2.7802112], dtype=float32), -2.1072342]. 
=============================================
[2019-03-24 04:07:00,973] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 04:07:00,975] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:07:00,977] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:07:00,977] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:07:00,978] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:07:00,983] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:07:00,984] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:07:00,985] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:07:00,985] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:07:00,986] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:07:00,987] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:07:01,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-24 04:07:01,036] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-24 04:07:01,064] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-24 04:07:01,091] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-24 04:07:01,118] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-24 04:07:12,268] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:07:12,270] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.0, 14.5, 1.0, 2.0, 0.4585719381070306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579928.8967935701, 579928.8967935697, 137375.2365402503]
[2019-03-24 04:07:12,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:07:12,275] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0995416e-23 9.9995148e-01 1.9667451e-10 4.8555270e-05 3.4066947e-13], sampled 0.2501591093176009
[2019-03-24 04:07:27,999] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:07:28,001] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.83333333333334, 1.0, 2.0, 0.4028702746647256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 505296.1516952666, 505296.1516952661, 129142.637881072]
[2019-03-24 04:07:28,002] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:07:28,004] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6218416e-21 9.9993038e-01 1.0144003e-09 6.9587899e-05 4.0598518e-12], sampled 0.4975297687571809
[2019-03-24 04:07:35,600] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:07:35,601] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.54661491, 24.84922660666667, 1.0, 2.0, 0.810111480930706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 996692.7817271722, 996692.7817271722, 201151.8308546113]
[2019-03-24 04:07:35,602] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:07:35,605] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6176268e-20 9.9988353e-01 2.9034064e-09 1.1646113e-04 1.3640148e-11], sampled 0.46190879457841394
[2019-03-24 04:07:46,152] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:07:46,153] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.46666666666667, 72.0, 1.0, 2.0, 0.4442782230133793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 539236.3836923583, 539236.3836923583, 134730.0743459086]
[2019-03-24 04:07:46,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:07:46,156] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1031059e-22 9.9994361e-01 5.6921584e-10 5.6407011e-05 1.8722242e-12], sampled 0.6589897231988805
[2019-03-24 04:08:18,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:08:18,443] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 39.0, 1.0, 2.0, 0.687595605101309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800133.075657809, 800133.075657809, 174611.3172787205]
[2019-03-24 04:08:18,444] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:08:18,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4236270e-22 9.9994111e-01 5.9984950e-10 5.8937811e-05 1.9520505e-12], sampled 0.14030859751343372
[2019-03-24 04:08:24,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0665373]
[2019-03-24 04:08:24,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.46666666666667, 90.66666666666666, 1.0, 2.0, 0.483090903396025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579998.8135807815, 579998.813580781, 140400.3010940667]
[2019-03-24 04:08:24,420] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:08:24,425] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.6347528e-23 9.9995732e-01 2.9131217e-10 4.2636530e-05 8.1857313e-13], sampled 0.1380438644600418
[2019-03-24 04:08:42,241] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.9532 2248650482.1892 553.0000
[2019-03-24 04:08:42,252] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.6041 2170611768.3515 493.0000
[2019-03-24 04:08:42,301] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.3317 2194992879.6008 572.0000
[2019-03-24 04:08:42,384] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.6497 2120408890.1177 430.0000
[2019-03-24 04:08:42,490] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.4066 2445332437.7955 746.0000
[2019-03-24 04:08:43,507] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2200000, evaluation results [2200000.0, 8099.406648590744, 2445332437.7955494, 746.0, 8769.604123995272, 2170611768.3515463, 493.0, 8923.649679796057, 2120408890.117699, 430.0, 8582.953219274745, 2248650482.189233, 553.0, 8701.33170548398, 2194992879.6007586, 572.0]
[2019-03-24 04:08:44,971] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2200745: loss 4.8406
[2019-03-24 04:08:44,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2200745: learning rate 0.0001
[2019-03-24 04:08:45,373] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200953: loss 4.3600
[2019-03-24 04:08:45,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200953: learning rate 0.0001
[2019-03-24 04:08:45,430] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2200983: loss 2.9332
[2019-03-24 04:08:45,433] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2200984: learning rate 0.0001
[2019-03-24 04:08:45,500] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2201018: loss 3.1832
[2019-03-24 04:08:45,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2201019: learning rate 0.0001
[2019-03-24 04:08:45,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2201057: loss 0.9664
[2019-03-24 04:08:45,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2201057: learning rate 0.0001
[2019-03-24 04:08:45,621] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201079: loss 2.1605
[2019-03-24 04:08:45,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201079: learning rate 0.0001
[2019-03-24 04:08:45,696] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2201122: loss 1.3925
[2019-03-24 04:08:45,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2201122: learning rate 0.0001
[2019-03-24 04:08:45,862] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2201207: loss 1.0294
[2019-03-24 04:08:45,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2201207: learning rate 0.0001
[2019-03-24 04:08:46,339] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2201450: loss 0.0677
[2019-03-24 04:08:46,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2201450: learning rate 0.0001
[2019-03-24 04:08:46,413] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201494: loss 0.0630
[2019-03-24 04:08:46,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201494: learning rate 0.0001
[2019-03-24 04:08:46,424] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2201496: loss 0.4917
[2019-03-24 04:08:46,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2201497: learning rate 0.0001
[2019-03-24 04:08:46,460] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2201516: loss 0.2004
[2019-03-24 04:08:46,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2201517: learning rate 0.0001
[2019-03-24 04:08:46,545] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2201558: loss 0.4076
[2019-03-24 04:08:46,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2201559: learning rate 0.0001
[2019-03-24 04:08:47,408] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2202000: loss 5.5592
[2019-03-24 04:08:47,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2202000: learning rate 0.0001
[2019-03-24 04:08:47,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202233: loss 0.1272
[2019-03-24 04:08:47,873] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202234: learning rate 0.0001
[2019-03-24 04:08:51,076] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2203896: loss 0.0603
[2019-03-24 04:08:51,083] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2203898: learning rate 0.0001
[2019-03-24 04:08:56,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5910157e-25 9.9999940e-01 3.8448509e-14 5.7672037e-07 9.4261406e-17], sum to 1.0000
[2019-03-24 04:08:56,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1611
[2019-03-24 04:08:56,944] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4731051477948013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571240.9294934982, 571240.9294934982, 138975.7482786729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [23.5, 80.5, 1.0, 2.0, 0.4749967716696988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573053.8262096572, 573053.8262096572, 139249.8188188967], 
processed observation next is [0.0, 0.2608695652173913, 0.42592592592592593, 0.805, 1.0, 1.0, 0.3749961567496414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20466208078916331, 0.20466208078916331, 0.26778811311326284], 
reward next is 0.7322, 
noisyNet noise sample is [array([2.9604037], dtype=float32), -0.22480522]. 
=============================================
[2019-03-24 04:09:00,444] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2208736: loss 0.0381
[2019-03-24 04:09:00,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2208736: learning rate 0.0001
[2019-03-24 04:09:00,652] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208835: loss 0.0068
[2019-03-24 04:09:00,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208835: learning rate 0.0001
[2019-03-24 04:09:00,858] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208938: loss 0.0253
[2019-03-24 04:09:00,864] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208940: learning rate 0.0001
[2019-03-24 04:09:00,901] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4133508e-24 9.9999774e-01 4.6368242e-13 2.2744314e-06 6.7791636e-16], sum to 1.0000
[2019-03-24 04:09:00,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-24 04:09:00,916] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 98.83333333333334, 1.0, 2.0, 0.5141515106191352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611861.3777230855, 611861.3777230855, 145085.0516276063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5241470904250494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621525.7125061658, 621525.7125061658, 146602.531968374], 
processed observation next is [0.0, 0.2608695652173913, 0.37037037037037035, 1.0, 1.0, 1.0, 0.4335084409822016, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22197346875220209, 0.22197346875220209, 0.28192794609302696], 
reward next is 0.7181, 
noisyNet noise sample is [array([1.1038995], dtype=float32), -0.76689833]. 
=============================================
[2019-03-24 04:09:01,040] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2209027: loss 0.0042
[2019-03-24 04:09:01,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2209027: learning rate 0.0001
[2019-03-24 04:09:01,061] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209038: loss 0.0010
[2019-03-24 04:09:01,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209038: learning rate 0.0001
[2019-03-24 04:09:01,230] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2209120: loss 0.0052
[2019-03-24 04:09:01,232] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2209120: loss 0.0389
[2019-03-24 04:09:01,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2209120: learning rate 0.0001
[2019-03-24 04:09:01,236] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2209123: learning rate 0.0001
[2019-03-24 04:09:01,321] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2209159: loss 0.0201
[2019-03-24 04:09:01,325] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2209160: learning rate 0.0001
[2019-03-24 04:09:01,916] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2209452: loss 0.0031
[2019-03-24 04:09:01,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2209452: learning rate 0.0001
[2019-03-24 04:09:01,978] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2209481: loss 0.0125
[2019-03-24 04:09:01,979] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2209481: learning rate 0.0001
[2019-03-24 04:09:01,995] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2209489: loss 0.0033
[2019-03-24 04:09:01,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2209490: learning rate 0.0001
[2019-03-24 04:09:02,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2209588: loss 0.0112
[2019-03-24 04:09:02,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2209588: learning rate 0.0001
[2019-03-24 04:09:02,253] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209611: loss 0.0007
[2019-03-24 04:09:02,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209611: learning rate 0.0001
[2019-03-24 04:09:03,091] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2210033: loss 0.0583
[2019-03-24 04:09:03,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2210034: learning rate 0.0001
[2019-03-24 04:09:03,362] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2210173: loss 0.0033
[2019-03-24 04:09:03,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2210173: learning rate 0.0001
[2019-03-24 04:09:07,397] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2212092: loss 1.1151
[2019-03-24 04:09:07,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2212094: learning rate 0.0001
[2019-03-24 04:09:16,849] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2216751: loss 0.5835
[2019-03-24 04:09:16,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2216751: learning rate 0.0001
[2019-03-24 04:09:16,915] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216783: loss -5.1521
[2019-03-24 04:09:16,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216783: learning rate 0.0001
[2019-03-24 04:09:17,318] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216982: loss 0.1587
[2019-03-24 04:09:17,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216982: learning rate 0.0001
[2019-03-24 04:09:17,359] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2217003: loss -0.8062
[2019-03-24 04:09:17,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2217003: learning rate 0.0001
[2019-03-24 04:09:17,543] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2217092: loss 3.4525
[2019-03-24 04:09:17,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2217092: learning rate 0.0001
[2019-03-24 04:09:17,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2217120: loss 1.4282
[2019-03-24 04:09:17,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2217121: learning rate 0.0001
[2019-03-24 04:09:17,687] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217163: loss 5.4804
[2019-03-24 04:09:17,689] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217164: learning rate 0.0001
[2019-03-24 04:09:17,723] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2217181: loss 3.0514
[2019-03-24 04:09:17,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2217181: learning rate 0.0001
[2019-03-24 04:09:18,104] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2217369: loss 1.5839
[2019-03-24 04:09:18,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2217369: learning rate 0.0001
[2019-03-24 04:09:18,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2217443: loss 0.9304
[2019-03-24 04:09:18,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2217443: learning rate 0.0001
[2019-03-24 04:09:18,324] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2217479: loss 0.6307
[2019-03-24 04:09:18,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2217481: learning rate 0.0001
[2019-03-24 04:09:18,525] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217576: loss 0.0104
[2019-03-24 04:09:18,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217578: learning rate 0.0001
[2019-03-24 04:09:18,533] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2217579: loss 0.1912
[2019-03-24 04:09:18,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2217579: learning rate 0.0001
[2019-03-24 04:09:19,372] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2217996: loss -0.9501
[2019-03-24 04:09:19,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2217996: learning rate 0.0001
[2019-03-24 04:09:19,916] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218268: loss 0.5711
[2019-03-24 04:09:19,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218268: learning rate 0.0001
[2019-03-24 04:09:23,482] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2220026: loss 0.0513
[2019-03-24 04:09:23,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2220026: learning rate 0.0001
[2019-03-24 04:09:23,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7150403e-17 8.4757000e-02 6.3594874e-10 9.1524297e-01 5.5171909e-11], sum to 1.0000
[2019-03-24 04:09:23,944] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8563
[2019-03-24 04:09:23,948] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3333610375363617, 1.0, 1.0, 0.3333610375363617, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 759855.7577629411, 759855.7577629415, 188659.4173780268], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3728400.0000, 
sim time next is 3729000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3356688411489772, 1.0, 2.0, 0.3356688411489772, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765118.7395316652, 765118.7395316657, 189240.7534495616], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20912957279640146, 1.0, 1.0, 0.20912957279640146, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27325669268988045, 0.2732566926898806, 0.36392452586454155], 
reward next is 0.6361, 
noisyNet noise sample is [array([-1.5521307], dtype=float32), 1.0087559]. 
=============================================
[2019-03-24 04:09:23,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[52.857586]
 [53.55474 ]
 [53.61889 ]
 [53.453712]
 [53.461884]], R is [[52.69765091]
 [52.17067337]
 [52.32384872]
 [52.43675232]
 [52.53403091]].
[2019-03-24 04:09:26,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.05677695e-20 9.99874949e-01 1.02088062e-14 1.25070568e-04
 6.80616587e-14], sum to 1.0000
[2019-03-24 04:09:26,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8287
[2019-03-24 04:09:26,069] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 73.0, 1.0, 2.0, 0.7507811119254794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855710.3877736657, 855710.3877736657, 185982.4707428831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960000.0000, 
sim time next is 3960600.0000, 
raw observation next is [29.08333333333334, 74.83333333333334, 1.0, 2.0, 0.73487659111856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837573.1438920348, 837573.1438920348, 182854.5361553756], 
processed observation next is [0.0, 0.8695652173913043, 0.6327160493827163, 0.7483333333333334, 1.0, 1.0, 0.6843768941887618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2991332656757267, 0.2991332656757267, 0.35164333876033765], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.46672702], dtype=float32), -1.1107235]. 
=============================================
[2019-03-24 04:09:27,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2043685e-15 3.0982253e-01 1.2657860e-09 6.9017744e-01 4.3259174e-10], sum to 1.0000
[2019-03-24 04:09:27,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1667
[2019-03-24 04:09:27,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1330906.32956019 W.
[2019-03-24 04:09:27,450] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.3, 88.33333333333333, 1.0, 2.0, 0.5836727906184217, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9292260915602376, 6.9112, 6.9112, 121.9260426155143, 1330906.32956019, 1330906.32956019, 287561.5572763355], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [25.25, 88.66666666666667, 1.0, 2.0, 0.5347940933751534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8514096136809194, 6.9112, 6.9112, 121.9260426156618, 1219363.105566687, 1219363.105566687, 269347.7066836886], 
processed observation next is [1.0, 0.08695652173913043, 0.49074074074074076, 0.8866666666666667, 1.0, 1.0, 0.4461834444942302, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8142620171011491, 0.0, 0.0, 0.8094621288201359, 0.4354868234166739, 0.4354868234166739, 0.5179763590070935], 
reward next is 0.4820, 
noisyNet noise sample is [array([-0.6880327], dtype=float32), 1.0020355]. 
=============================================
[2019-03-24 04:09:29,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3584577e-28 1.0000000e+00 4.6180232e-18 4.2819902e-08 4.5932157e-18], sum to 1.0000
[2019-03-24 04:09:29,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3263
[2019-03-24 04:09:29,033] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.40000000000001, 69.33333333333334, 1.0, 2.0, 0.5314651858966821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628555.7402801265, 628555.7402801265, 147721.0314213549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3820800.0000, 
sim time next is 3821400.0000, 
raw observation next is [26.3, 70.5, 1.0, 2.0, 0.5341058708636126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630606.5322070637, 630606.5322070637, 148107.1498250953], 
processed observation next is [0.0, 0.21739130434782608, 0.5296296296296297, 0.705, 1.0, 1.0, 0.4453641319804912, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22521661864537992, 0.22521661864537992, 0.2848214419713371], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.1280982], dtype=float32), -2.7051864]. 
=============================================
[2019-03-24 04:09:32,450] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4327768e-20 9.9986422e-01 5.0012501e-14 1.3579943e-04 9.2716138e-14], sum to 1.0000
[2019-03-24 04:09:32,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1905
[2019-03-24 04:09:32,465] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 68.66666666666666, 1.0, 2.0, 0.7627450369550568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869354.1264120702, 869354.1264120702, 188365.6222887504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873000.0000, 
sim time next is 3873600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.7462053212910059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 850492.1903086734, 850492.190308673, 185077.3237900074], 
processed observation next is [0.0, 0.8695652173913043, 0.6629629629629629, 0.69, 1.0, 1.0, 0.697863477727388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3037472108245262, 0.30374721082452605, 0.3559179303653988], 
reward next is 0.6441, 
noisyNet noise sample is [array([-0.88171536], dtype=float32), -0.5596077]. 
=============================================
[2019-03-24 04:09:32,811] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2224651: loss 0.0453
[2019-03-24 04:09:32,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2224652: learning rate 0.0001
[2019-03-24 04:09:33,390] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224937: loss 0.0365
[2019-03-24 04:09:33,392] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224938: learning rate 0.0001
[2019-03-24 04:09:33,430] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224962: loss 0.0111
[2019-03-24 04:09:33,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224963: learning rate 0.0001
[2019-03-24 04:09:33,482] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224984: loss 0.0018
[2019-03-24 04:09:33,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224984: learning rate 0.0001
[2019-03-24 04:09:33,515] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 04:09:33,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:09:33,518] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:09:33,522] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:09:33,523] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:09:33,523] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:09:33,524] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:09:33,525] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:09:33,526] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:09:33,528] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:09:33,529] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:09:33,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-24 04:09:33,577] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-24 04:09:33,605] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-24 04:09:33,628] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-24 04:09:33,653] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-24 04:09:37,662] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:09:37,663] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.36972079, 34.38922582, 1.0, 2.0, 0.3875624195231333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 471935.2238938478, 471935.2238938482, 126664.7876167766]
[2019-03-24 04:09:37,665] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:09:37,667] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.7898755e-22 9.9999487e-01 5.3887088e-15 5.1526322e-06 1.4895910e-14], sampled 0.5452720288326509
[2019-03-24 04:10:04,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:10:04,414] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.38333333333333, 91.33333333333334, 1.0, 2.0, 0.608872249049544, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9693444500716502, 6.9112, 6.9112, 121.9260426156618, 1388418.89028164, 1388418.89028164, 297326.2474426004]
[2019-03-24 04:10:04,415] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:10:04,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6384741e-19 9.9997461e-01 4.7302152e-13 2.5392972e-05 1.0464600e-12], sampled 0.5292030191761912
[2019-03-24 04:10:04,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1388418.89028164 W.
[2019-03-24 04:10:19,540] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:10:19,542] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.73062923, 100.43958896, 1.0, 2.0, 0.5337322022657859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634725.2682910751, 634725.2682910751, 148224.5596699654]
[2019-03-24 04:10:19,543] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:10:19,546] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3227672e-22 9.9999583e-01 3.0160334e-15 4.1888047e-06 8.5630533e-15], sampled 0.3106970375972036
[2019-03-24 04:10:30,675] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:10:30,677] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.29640130666666, 67.00263947666667, 1.0, 2.0, 0.9690513668262639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.953990630760304, 6.9112, 121.9258125296967, 1126593.821996842, 1104681.235815587, 233339.4648211066]
[2019-03-24 04:10:30,679] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:10:30,682] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.0189583e-21 9.9999154e-01 2.1715141e-14 8.4729108e-06 5.6341118e-14], sampled 0.1959907980390605
[2019-03-24 04:11:05,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:11:05,881] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.78366709166667, 62.18017310333333, 1.0, 2.0, 0.4078782839998583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519448.6191734474, 519448.6191734474, 129938.8174146523]
[2019-03-24 04:11:05,881] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:11:05,884] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5650301e-21 9.9999249e-01 1.5195986e-14 7.4598602e-06 4.0071231e-14], sampled 0.3343516226473112
[2019-03-24 04:11:09,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:11:09,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.5, 54.0, 1.0, 2.0, 0.277565692398006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 356269.783737393, 356269.783737393, 112847.6379308646]
[2019-03-24 04:11:09,554] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:11:09,557] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.67905383e-21 9.99993086e-01 1.25099024e-14 6.95915651e-06
 3.32866466e-14], sampled 0.4882722891908443
[2019-03-24 04:11:14,990] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:11:15,036] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:11:15,078] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:11:15,136] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:11:15,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.072934]
[2019-03-24 04:11:15,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.76666666666667, 74.0, 1.0, 2.0, 0.4433649726138047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540459.3935880795, 540459.3935880795, 134664.6604263765]
[2019-03-24 04:11:15,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:11:15,173] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5195954e-21 9.9999392e-01 8.4794969e-15 6.0577972e-06 2.2910979e-14], sampled 0.37142047707229786
[2019-03-24 04:11:15,177] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:11:16,194] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2225000, evaluation results [2225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:11:16,401] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225111: loss 0.0094
[2019-03-24 04:11:16,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225111: learning rate 0.0001
[2019-03-24 04:11:16,445] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2225133: loss 0.0097
[2019-03-24 04:11:16,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2225134: learning rate 0.0001
[2019-03-24 04:11:16,504] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2225158: loss 0.0110
[2019-03-24 04:11:16,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2225159: learning rate 0.0001
[2019-03-24 04:11:16,612] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2225219: loss 0.0045
[2019-03-24 04:11:16,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2225219: learning rate 0.0001
[2019-03-24 04:11:16,880] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2225358: loss 0.0494
[2019-03-24 04:11:16,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2225358: learning rate 0.0001
[2019-03-24 04:11:17,058] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2225455: loss 0.1136
[2019-03-24 04:11:17,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2225455: learning rate 0.0001
[2019-03-24 04:11:17,065] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2225455: loss 0.0439
[2019-03-24 04:11:17,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2225457: learning rate 0.0001
[2019-03-24 04:11:17,130] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2225481: loss 0.0069
[2019-03-24 04:11:17,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2225481: learning rate 0.0001
[2019-03-24 04:11:17,259] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225552: loss 0.0037
[2019-03-24 04:11:17,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225552: learning rate 0.0001
[2019-03-24 04:11:18,114] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2225998: loss 0.0034
[2019-03-24 04:11:18,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2226000: learning rate 0.0001
[2019-03-24 04:11:18,506] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2226198: loss 0.0062
[2019-03-24 04:11:18,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2226201: learning rate 0.0001
[2019-03-24 04:11:21,035] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9724176e-23 1.0000000e+00 1.0527271e-15 3.1181224e-09 1.1091176e-16], sum to 1.0000
[2019-03-24 04:11:21,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-24 04:11:21,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 98.0, 1.0, 2.0, 0.569772348042185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664080.0430902912, 664080.0430902912, 153651.7259342367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4567200.0000, 
sim time next is 4567800.0000, 
raw observation next is [23.03333333333333, 99.0, 1.0, 2.0, 0.5743130027320522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668127.4514705838, 668127.4514705838, 154361.5200959739], 
processed observation next is [0.0, 0.8695652173913043, 0.4086419753086419, 0.99, 1.0, 1.0, 0.493229765157205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2386169469537799, 0.2386169469537799, 0.2968490771076421], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.04819392], dtype=float32), 1.443806]. 
=============================================
[2019-03-24 04:11:21,195] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0179444e-19 1.0000000e+00 4.7744155e-13 7.0369639e-09 1.3956707e-13], sum to 1.0000
[2019-03-24 04:11:21,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-24 04:11:21,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1839231.561336842 W.
[2019-03-24 04:11:21,212] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.4, 94.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.223145288604846, 6.9112, 121.9210542624122, 1839231.561336842, 1167425.799907351, 245823.2383288347], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4004400.0000, 
sim time next is 4005000.0000, 
raw observation next is [24.45, 94.0, 1.0, 2.0, 0.7409537169139763, 1.0, 1.0, 0.7409537169139763, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9252525815116, 1689921.192659799, 1689921.192659799, 319958.6616966114], 
processed observation next is [1.0, 0.34782608695652173, 0.4611111111111111, 0.94, 1.0, 1.0, 0.6916115677547336, 1.0, 0.5, 0.6916115677547336, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094568838149562, 0.6035432830927854, 0.6035432830927854, 0.6153051186473296], 
reward next is 0.3847, 
noisyNet noise sample is [array([0.11336231], dtype=float32), -1.3402787]. 
=============================================
[2019-03-24 04:11:21,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[47.3509  ]
 [48.466103]
 [48.253174]
 [48.098686]
 [48.141922]], R is [[47.30372238]
 [46.83068466]
 [46.99526215]
 [47.14356995]
 [47.26890182]].
[2019-03-24 04:11:22,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2842696e-16 1.0000000e+00 4.5037506e-13 3.8647904e-08 1.3083265e-12], sum to 1.0000
[2019-03-24 04:11:22,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1383
[2019-03-24 04:11:22,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1445369.978626224 W.
[2019-03-24 04:11:22,160] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.6338238305399334, 1.0, 2.0, 0.6338238305399334, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426115626, 1445369.978626224, 1445369.978626224, 279872.2975860999], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4029000.0000, 
sim time next is 4029600.0000, 
raw observation next is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9038220100502297, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156606, 1745447.367975696, 1745447.367975696, 357793.4796614411], 
processed observation next is [1.0, 0.6521739130434783, 0.5308641975308644, 0.8733333333333334, 1.0, 1.0, 0.8855023929169401, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.809462128820128, 0.62337405999132, 0.62337405999132, 0.6880643839643098], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7047371], dtype=float32), -0.68629956]. 
=============================================
[2019-03-24 04:11:22,404] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2228222: loss 4.7796
[2019-03-24 04:11:22,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2228222: learning rate 0.0001
[2019-03-24 04:11:24,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2815523e-22 1.0000000e+00 4.5223026e-16 1.1908128e-09 1.3150570e-15], sum to 1.0000
[2019-03-24 04:11:24,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0297
[2019-03-24 04:11:24,633] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.58333333333333, 95.83333333333334, 1.0, 2.0, 0.6740214617733876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.0200424077054, 825194.8811331666, 825194.8811331671, 173644.421431369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4068600.0000, 
sim time next is 4069200.0000, 
raw observation next is [20.46666666666667, 96.66666666666667, 1.0, 2.0, 0.5766104418880592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705984.8046058216, 705984.8046058216, 156053.8264380151], 
processed observation next is [1.0, 0.08695652173913043, 0.31358024691358033, 0.9666666666666667, 1.0, 1.0, 0.49596481177149904, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25213743021636487, 0.25213743021636487, 0.30010351238079824], 
reward next is 0.6999, 
noisyNet noise sample is [array([1.6536041], dtype=float32), -1.9169644]. 
=============================================
[2019-03-24 04:11:28,474] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6146527e-27 1.0000000e+00 1.9141510e-20 6.2723329e-13 7.0460941e-21], sum to 1.0000
[2019-03-24 04:11:28,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2749
[2019-03-24 04:11:28,488] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 95.33333333333333, 1.0, 2.0, 0.4456225931011391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 544351.9553416264, 544351.955341626, 135032.2466881555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4132200.0000, 
sim time next is 4132800.0000, 
raw observation next is [20.7, 96.0, 1.0, 2.0, 0.447287922467728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546568.6261681598, 546568.6261681598, 135285.012381018], 
processed observation next is [1.0, 0.8695652173913043, 0.3222222222222222, 0.96, 1.0, 1.0, 0.3420094315092001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19520308077434279, 0.19520308077434279, 0.2601634853481115], 
reward next is 0.7398, 
noisyNet noise sample is [array([2.098671], dtype=float32), -0.44437376]. 
=============================================
[2019-03-24 04:11:31,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2232716: loss 11.0114
[2019-03-24 04:11:31,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2232716: learning rate 0.0001
[2019-03-24 04:11:31,571] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232977: loss 21.8140
[2019-03-24 04:11:31,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232979: learning rate 0.0001
[2019-03-24 04:11:31,603] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232993: loss 19.7070
[2019-03-24 04:11:31,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232994: learning rate 0.0001
[2019-03-24 04:11:31,611] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232997: loss 23.3888
[2019-03-24 04:11:31,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232997: learning rate 0.0001
[2019-03-24 04:11:31,822] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233100: loss 18.6369
[2019-03-24 04:11:31,825] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233100: learning rate 0.0001
[2019-03-24 04:11:31,906] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2233144: loss 15.8788
[2019-03-24 04:11:31,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2233144: learning rate 0.0001
[2019-03-24 04:11:31,982] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2233177: loss 15.2797
[2019-03-24 04:11:31,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2233177: learning rate 0.0001
[2019-03-24 04:11:31,994] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2233184: loss 18.7085
[2019-03-24 04:11:31,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2233186: learning rate 0.0001
[2019-03-24 04:11:32,361] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2233356: loss 18.2218
[2019-03-24 04:11:32,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2233357: learning rate 0.0001
[2019-03-24 04:11:32,593] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2233470: loss 9.4522
[2019-03-24 04:11:32,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2233470: learning rate 0.0001
[2019-03-24 04:11:32,657] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2233502: loss 19.5554
[2019-03-24 04:11:32,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2233502: learning rate 0.0001
[2019-03-24 04:11:32,799] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233573: loss 13.4024
[2019-03-24 04:11:32,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233576: learning rate 0.0001
[2019-03-24 04:11:32,904] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2233622: loss 13.3041
[2019-03-24 04:11:32,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2233622: learning rate 0.0001
[2019-03-24 04:11:33,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3095596e-19 9.9999988e-01 1.2993711e-12 8.8113637e-08 7.8522453e-13], sum to 1.0000
[2019-03-24 04:11:33,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7231
[2019-03-24 04:11:33,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1703425.22641666 W.
[2019-03-24 04:11:33,574] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.05, 32.5, 1.0, 2.0, 0.7321206543025601, 1.0, 2.0, 0.7321206543025601, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1703425.22641666, 1703425.22641666, 318188.2783632932], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4203000.0000, 
sim time next is 4203600.0000, 
raw observation next is [34.03333333333333, 33.0, 1.0, 2.0, 0.4815871619811952, 1.0, 2.0, 0.4815871619811952, 1.0, 1.0, 0.7670604178285283, 6.911200000000001, 6.9112, 121.94756008, 1658886.625596344, 1658886.625596344, 334714.5522555125], 
processed observation next is [1.0, 0.6521739130434783, 0.8160493827160493, 0.33, 1.0, 1.0, 0.38284185950142285, 1.0, 1.0, 0.38284185950142285, 1.0, 0.5, 0.7088255222856604, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5924595091415514, 0.5924595091415514, 0.643681831260601], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8290908], dtype=float32), 1.5010309]. 
=============================================
[2019-03-24 04:11:33,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2234059: loss 57.2504
[2019-03-24 04:11:33,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2234060: learning rate 0.0001
[2019-03-24 04:11:34,041] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234181: loss 9.3408
[2019-03-24 04:11:34,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234181: learning rate 0.0001
[2019-03-24 04:11:37,857] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2236039: loss 0.0305
[2019-03-24 04:11:37,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2236041: learning rate 0.0001
[2019-03-24 04:11:39,429] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.78236637e-14 9.99970913e-01 7.66054720e-10 2.90713233e-05
 1.01378435e-08], sum to 1.0000
[2019-03-24 04:11:39,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4137
[2019-03-24 04:11:39,444] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.6274182071064356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 744192.3498536876, 744192.3498536871, 164181.237096995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342800.0000, 
sim time next is 4343400.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.638012403694224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754401.1072823419, 754401.1072823419, 165994.2219818962], 
processed observation next is [1.0, 0.2608695652173913, 0.42592592592592593, 0.89, 1.0, 1.0, 0.5690623853502667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2694289668865507, 0.2694289668865507, 0.3192196576574927], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.11915766], dtype=float32), -1.4681666]. 
=============================================
[2019-03-24 04:11:43,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0234990e-21 9.9966216e-01 1.4244431e-14 3.3782833e-04 2.3597463e-12], sum to 1.0000
[2019-03-24 04:11:43,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6040
[2019-03-24 04:11:43,948] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6459279808291666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736145.579386233, 736145.579386233, 166158.8144149278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4441200.0000, 
sim time next is 4441800.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6497935255344383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740553.1577802335, 740553.1577802335, 166855.7557174187], 
processed observation next is [0.0, 0.391304347826087, 0.5493827160493825, 0.7983333333333335, 1.0, 1.0, 0.5830875303981408, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2644832706357977, 0.2644832706357977, 0.3208764533027283], 
reward next is 0.6791, 
noisyNet noise sample is [array([1.4778799], dtype=float32), -0.13048187]. 
=============================================
[2019-03-24 04:11:47,393] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2240741: loss 0.0014
[2019-03-24 04:11:47,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2240742: learning rate 0.0001
[2019-03-24 04:11:47,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9678841e-25 9.9999082e-01 1.7322558e-17 9.1699958e-06 7.2724311e-16], sum to 1.0000
[2019-03-24 04:11:47,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-24 04:11:47,485] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6610341325431328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753370.0870895492, 753370.0870895492, 168895.134857551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4488600.0000, 
sim time next is 4489200.0000, 
raw observation next is [25.4, 86.0, 1.0, 2.0, 0.6448359271405296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738002.1132951621, 738002.1132951621, 166117.0462184343], 
processed observation next is [0.0, 1.0, 0.49629629629629624, 0.86, 1.0, 1.0, 0.5771856275482495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2635721833197007, 0.2635721833197007, 0.31945585811237365], 
reward next is 0.6805, 
noisyNet noise sample is [array([0.9494206], dtype=float32), -0.5754396]. 
=============================================
[2019-03-24 04:11:47,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240817: loss 0.0115
[2019-03-24 04:11:47,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240818: learning rate 0.0001
[2019-03-24 04:11:47,695] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240885: loss 0.0014
[2019-03-24 04:11:47,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240885: learning rate 0.0001
[2019-03-24 04:11:47,968] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2241021: loss 0.0004
[2019-03-24 04:11:47,970] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2241021: learning rate 0.0001
[2019-03-24 04:11:48,102] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2241085: loss 0.0192
[2019-03-24 04:11:48,103] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2241085: learning rate 0.0001
[2019-03-24 04:11:48,116] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2241090: loss 0.0285
[2019-03-24 04:11:48,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2241093: learning rate 0.0001
[2019-03-24 04:11:48,176] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241124: loss 0.0412
[2019-03-24 04:11:48,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241124: learning rate 0.0001
[2019-03-24 04:11:48,287] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2241175: loss 0.0056
[2019-03-24 04:11:48,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2241180: learning rate 0.0001
[2019-03-24 04:11:48,753] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2241406: loss 0.0012
[2019-03-24 04:11:48,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2241407: learning rate 0.0001
[2019-03-24 04:11:48,873] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241464: loss 0.0726
[2019-03-24 04:11:48,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241464: learning rate 0.0001
[2019-03-24 04:11:48,879] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2241464: loss 0.0512
[2019-03-24 04:11:48,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2241469: learning rate 0.0001
[2019-03-24 04:11:48,907] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2241479: loss 0.0678
[2019-03-24 04:11:48,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2241479: learning rate 0.0001
[2019-03-24 04:11:49,140] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2241597: loss 0.0224
[2019-03-24 04:11:49,141] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2241597: learning rate 0.0001
[2019-03-24 04:11:50,132] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2242090: loss 0.0863
[2019-03-24 04:11:50,138] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2242091: learning rate 0.0001
[2019-03-24 04:11:50,358] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2242196: loss 0.0409
[2019-03-24 04:11:50,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2242196: learning rate 0.0001
[2019-03-24 04:11:50,712] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5624597e-21 9.9894315e-01 5.4918724e-15 1.0568831e-03 6.2118230e-13], sum to 1.0000
[2019-03-24 04:11:50,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2762
[2019-03-24 04:11:50,724] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 89.0, 1.0, 2.0, 0.611442074997472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703178.980645971, 703178.980645971, 160368.5817433149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [24.2, 92.66666666666666, 1.0, 2.0, 0.6052485081550651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697663.0296351592, 697663.0296351587, 159367.6272525587], 
processed observation next is [0.0, 0.6086956521739131, 0.45185185185185184, 0.9266666666666665, 1.0, 1.0, 0.530057747803649, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24916536772684256, 0.2491653677268424, 0.3064762062549206], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.18403052], dtype=float32), 1.0274593]. 
=============================================
[2019-03-24 04:11:54,696] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2244327: loss 150.0076
[2019-03-24 04:11:54,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2244327: learning rate 0.0001
[2019-03-24 04:11:55,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.67865776e-13 9.93704259e-01 2.11214557e-09 6.29555434e-03
 1.12175535e-07], sum to 1.0000
[2019-03-24 04:11:55,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3128
[2019-03-24 04:11:55,394] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.41666666666667, 92.5, 1.0, 2.0, 0.782772985759429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426108923, 898168.7581161336, 898168.7581161336, 192714.2879160272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5212200.0000, 
sim time next is 5212800.0000, 
raw observation next is [24.5, 91.0, 1.0, 2.0, 0.8648448177416019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156604, 994833.8870689421, 994833.8870689425, 210183.5930635652], 
processed observation next is [1.0, 0.34782608695652173, 0.46296296296296297, 0.91, 1.0, 1.0, 0.839100973501907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201267, 0.35529781681033645, 0.3552978168103366, 0.4041992174299331], 
reward next is 0.5958, 
noisyNet noise sample is [array([-1.2203178], dtype=float32), -0.12804894]. 
=============================================
[2019-03-24 04:11:56,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.97346342e-15 9.85261023e-01 2.40565241e-11 1.47389965e-02
 2.89153199e-08], sum to 1.0000
[2019-03-24 04:11:56,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2531
[2019-03-24 04:11:56,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2102217.21977741 W.
[2019-03-24 04:11:56,719] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.41666666666667, 68.16666666666667, 1.0, 2.0, 0.6143430028005935, 1.0, 2.0, 0.6143430028005935, 1.0, 1.0, 0.978054068213332, 6.911199999999999, 6.9112, 121.94756008, 2102217.21977741, 2102217.21977741, 403245.7669785688], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5235000.0000, 
sim time next is 5235600.0000, 
raw observation next is [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.6211901478464211, 1.0, 2.0, 0.6211901478464211, 1.0, 2.0, 0.9889549461222354, 6.9112, 6.9112, 121.94756008, 2125675.314976433, 2125675.314976433, 407041.8998447527], 
processed observation next is [1.0, 0.6086956521739131, 0.6419753086419755, 0.6933333333333335, 1.0, 1.0, 0.5490358902933584, 1.0, 1.0, 0.5490358902933584, 1.0, 1.0, 0.9861936826527942, 0.0, 0.0, 0.8096049824067558, 0.759169755348726, 0.759169755348726, 0.7827728843168321], 
reward next is 0.2172, 
noisyNet noise sample is [array([-1.0204148], dtype=float32), -1.8184106]. 
=============================================
[2019-03-24 04:11:56,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5023589e-17 9.0580612e-01 4.4382965e-12 9.4193920e-02 2.5264486e-09], sum to 1.0000
[2019-03-24 04:11:56,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-24 04:11:56,735] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.6947271333229492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791789.2971734446, 791789.2971734442, 175148.961310586], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.3521437414677675, 1.0, 1.0, 0.3521437414677675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802691.0538926995, 802691.0538927, 193445.4431765914], 
processed observation next is [1.0, 0.8695652173913043, 0.5222222222222223, 0.92, 1.0, 1.0, 0.22874254936638988, 1.0, 0.5, 0.22874254936638988, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2866753763902498, 0.28667537639025, 0.3720104676472911], 
reward next is 0.6280, 
noisyNet noise sample is [array([1.7824696], dtype=float32), -0.29900134]. 
=============================================
[2019-03-24 04:11:57,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2492054e-15 9.9371380e-01 3.1622400e-12 6.2861838e-03 1.6908337e-09], sum to 1.0000
[2019-03-24 04:11:57,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-24 04:11:57,305] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.6135926387105207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 722834.8172535289, 722834.8172535285, 161517.7273571113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4680000.0000, 
sim time next is 4680600.0000, 
raw observation next is [23.11666666666667, 94.16666666666667, 1.0, 2.0, 0.6608941246285235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777024.1827716883, 777024.1827716883, 169992.4987213237], 
processed observation next is [1.0, 0.17391304347826086, 0.41172839506172854, 0.9416666666666668, 1.0, 1.0, 0.5963025293196708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2775086367041744, 0.2775086367041744, 0.32690865138716096], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.21122313], dtype=float32), -1.2686]. 
=============================================
[2019-03-24 04:12:02,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1383000e-16 1.1741441e-01 1.2025043e-10 8.8258559e-01 3.4509661e-08], sum to 1.0000
[2019-03-24 04:12:02,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0434
[2019-03-24 04:12:02,298] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 92.66666666666666, 1.0, 2.0, 0.301227384596341, 1.0, 2.0, 0.301227384596341, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687299.306547072, 687299.306547072, 180791.6958645745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [24.16666666666667, 92.33333333333333, 1.0, 2.0, 0.5956599946951815, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686058.1673202098, 686058.1673202098, 157684.3582354034], 
processed observation next is [1.0, 0.043478260869565216, 0.45061728395061745, 0.9233333333333333, 1.0, 1.0, 0.518642850827597, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24502077404293207, 0.24502077404293207, 0.30323915045269884], 
reward next is 0.6968, 
noisyNet noise sample is [array([0.71693677], dtype=float32), 0.8568481]. 
=============================================
[2019-03-24 04:12:03,614] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2248724: loss -18.7086
[2019-03-24 04:12:03,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2248724: learning rate 0.0001
[2019-03-24 04:12:03,731] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248778: loss -61.9954
[2019-03-24 04:12:03,735] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248778: learning rate 0.0001
[2019-03-24 04:12:03,816] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248818: loss 3.0112
[2019-03-24 04:12:03,817] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248818: learning rate 0.0001
[2019-03-24 04:12:04,192] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2249002: loss 1.2446
[2019-03-24 04:12:04,193] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2249002: learning rate 0.0001
[2019-03-24 04:12:04,352] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2249083: loss 0.4785
[2019-03-24 04:12:04,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2249083: learning rate 0.0001
[2019-03-24 04:12:04,511] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2249156: loss 0.0285
[2019-03-24 04:12:04,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2249156: learning rate 0.0001
[2019-03-24 04:12:04,521] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249158: loss 0.0545
[2019-03-24 04:12:04,524] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249161: learning rate 0.0001
[2019-03-24 04:12:04,648] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2249225: loss 0.1107
[2019-03-24 04:12:04,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2249225: learning rate 0.0001
[2019-03-24 04:12:05,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2249414: loss 0.2550
[2019-03-24 04:12:05,041] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2249414: learning rate 0.0001
[2019-03-24 04:12:05,050] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249416: loss 0.2422
[2019-03-24 04:12:05,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249416: learning rate 0.0001
[2019-03-24 04:12:05,099] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2249447: loss 0.2017
[2019-03-24 04:12:05,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2249449: learning rate 0.0001
[2019-03-24 04:12:05,139] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2249469: loss 0.1621
[2019-03-24 04:12:05,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2249469: learning rate 0.0001
[2019-03-24 04:12:05,425] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2249607: loss 0.1470
[2019-03-24 04:12:05,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2249607: learning rate 0.0001
[2019-03-24 04:12:05,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4168974e-22 1.8974167e-03 3.8460913e-16 9.9810261e-01 5.3358906e-12], sum to 1.0000
[2019-03-24 04:12:05,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-24 04:12:05,734] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.03333333333333, 93.33333333333334, 1.0, 2.0, 0.3953978578100095, 1.0, 2.0, 0.3953978578100095, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 901344.2568705445, 901344.256870545, 204931.2326146749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4821000.0000, 
sim time next is 4821600.0000, 
raw observation next is [27.06666666666667, 92.66666666666667, 1.0, 2.0, 0.3927677015988041, 1.0, 2.0, 0.3927677015988041, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 895345.0817297838, 895345.0817297843, 204214.3110662645], 
processed observation next is [1.0, 0.8260869565217391, 0.5580246913580248, 0.9266666666666667, 1.0, 1.0, 0.27710440666524294, 1.0, 1.0, 0.27710440666524294, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31976610061777994, 0.3197661006177801, 0.39271982897358554], 
reward next is 0.6073, 
noisyNet noise sample is [array([-0.58991545], dtype=float32), 0.32927626]. 
=============================================
[2019-03-24 04:12:06,242] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 04:12:06,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:12:06,245] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:12:06,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:12:06,248] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:12:06,248] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:12:06,249] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:12:06,250] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:12:06,251] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:12:06,253] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:12:06,254] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:12:06,273] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-24 04:12:06,301] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-24 04:12:06,330] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-24 04:12:06,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-24 04:12:06,354] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-24 04:12:15,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:12:15,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.9932379, 44.94591822, 1.0, 2.0, 0.2057069175107732, 1.0, 2.0, 0.2057069175107732, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 503906.3810112388, 503906.3810112393, 160955.2764346825]
[2019-03-24 04:12:15,596] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:12:15,601] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5345727e-18 1.3339313e-03 4.3193341e-14 9.9866605e-01 7.4311673e-10], sampled 0.8762122586493125
[2019-03-24 04:12:45,756] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:12:45,758] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 65.33333333333333, 1.0, 2.0, 0.3367115669422291, 1.0, 2.0, 0.3367115669422291, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 767496.7036540626, 767496.703654063, 189504.4840955097]
[2019-03-24 04:12:45,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:12:45,762] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5261450e-19 9.0910104e-04 7.4783971e-15 9.9909091e-01 2.2344564e-10], sampled 0.9539452363138189
[2019-03-24 04:12:46,448] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:12:46,450] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.1, 94.0, 1.0, 2.0, 0.3679801210725393, 1.0, 2.0, 0.3679801210725393, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 852808.6003310916, 852808.6003310916, 198234.5987612052]
[2019-03-24 04:12:46,451] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:12:46,452] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9355843e-18 1.5580041e-03 8.8349229e-14 9.9844199e-01 1.2141386e-09], sampled 0.8082764312372058
[2019-03-24 04:13:12,618] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:13:12,619] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.2, 92.0, 1.0, 2.0, 0.3003916687903526, 1.0, 2.0, 0.3003916687903526, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685721.1739788963, 685721.1739788963, 180607.3889981952]
[2019-03-24 04:13:12,620] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:13:12,624] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.7378595e-18 1.6595867e-03 1.1766231e-13 9.9834037e-01 1.4773623e-09], sampled 0.6596362912799021
[2019-03-24 04:13:38,736] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:13:38,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 75.0, 1.0, 2.0, 0.4738633119756792, 1.0, 2.0, 0.4738633119756792, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1080339.261296796, 1080339.261296796, 227420.1243382707]
[2019-03-24 04:13:38,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:13:38,741] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9165248e-19 1.1033186e-03 1.8189680e-14 9.9889660e-01 4.1099590e-10], sampled 0.7684137204212732
[2019-03-24 04:13:42,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0775399]
[2019-03-24 04:13:42,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.1, 45.0, 1.0, 2.0, 0.1829017367761376, 1.0, 2.0, 0.1829017367761376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453712.6309907248, 453712.6309907252, 156361.652477956]
[2019-03-24 04:13:42,608] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:13:42,609] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.1862226e-18 1.7235095e-03 1.3957280e-13 9.9827647e-01 1.6600912e-09], sampled 0.02267812196935204
[2019-03-24 04:13:47,801] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7113.5193 2438088446.4749 34.0000
[2019-03-24 04:13:48,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6897.8197 2494876726.5609 47.0000
[2019-03-24 04:13:48,179] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7787.9897 2410217416.7464 23.0000
[2019-03-24 04:13:48,195] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7464.9238 2465182635.6179 50.0000
[2019-03-24 04:13:48,303] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7512.5075 2668166751.1268 75.0000
[2019-03-24 04:13:49,319] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2250000, evaluation results [2250000.0, 7512.507452921957, 2668166751.126796, 75.0, 7113.519341569585, 2438088446.4749236, 34.0, 7787.989663595185, 2410217416.746351, 23.0, 6897.819657120231, 2494876726.560927, 47.0, 7464.923764657273, 2465182635.6178627, 50.0]
[2019-03-24 04:13:49,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2250054: loss 0.1059
[2019-03-24 04:13:49,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2250054: learning rate 0.0001
[2019-03-24 04:13:49,766] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2250230: loss -9.2934
[2019-03-24 04:13:49,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2250230: learning rate 0.0001
[2019-03-24 04:13:49,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4019928e-16 3.3467442e-03 5.6705850e-13 9.9665326e-01 4.8906752e-08], sum to 1.0000
[2019-03-24 04:13:50,009] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2441
[2019-03-24 04:13:50,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.26666666666667, 96.66666666666666, 1.0, 2.0, 0.3496934573194667, 1.0, 2.0, 0.3496934573194667, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797102.8703321794, 797102.8703321798, 192814.024047598], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4844400.0000, 
sim time next is 4845000.0000, 
raw observation next is [25.33333333333334, 95.83333333333334, 1.0, 2.0, 0.3489801595594969, 1.0, 2.0, 0.3489801595594969, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795476.1120403357, 795476.1120403357, 192630.6302630107], 
processed observation next is [1.0, 0.043478260869565216, 0.49382716049382736, 0.9583333333333335, 1.0, 1.0, 0.22497638042797252, 1.0, 1.0, 0.22497638042797252, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28409861144297704, 0.28409861144297704, 0.37044351973655903], 
reward next is 0.6296, 
noisyNet noise sample is [array([1.2812431], dtype=float32), -1.9827433]. 
=============================================
[2019-03-24 04:13:50,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.95654 ]
 [50.10046 ]
 [50.324966]
 [50.28443 ]
 [50.370632]], R is [[49.960186  ]
 [50.08978653]
 [50.21760559]
 [50.34371185]
 [50.46817398]].
[2019-03-24 04:13:52,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4547011e-19 5.3258082e-03 4.3193823e-15 9.9467421e-01 4.0878506e-10], sum to 1.0000
[2019-03-24 04:13:52,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0765
[2019-03-24 04:13:52,622] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.73333333333333, 88.66666666666667, 1.0, 2.0, 0.4377113239098153, 1.0, 2.0, 0.4377113239098153, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 997864.3314455437, 997864.3314455441, 216794.5160129205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4911600.0000, 
sim time next is 4912200.0000, 
raw observation next is [28.55, 90.0, 1.0, 2.0, 0.4382234229707674, 1.0, 2.0, 0.4382234229707674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999032.5408769954, 999032.5408769954, 216941.8912176396], 
processed observation next is [1.0, 0.8695652173913043, 0.612962962962963, 0.9, 1.0, 1.0, 0.331218360679485, 1.0, 1.0, 0.331218360679485, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35679733602749836, 0.35679733602749836, 0.4171959446493069], 
reward next is 0.5828, 
noisyNet noise sample is [array([2.3817282], dtype=float32), 0.5314641]. 
=============================================
[2019-03-24 04:13:53,733] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2252287: loss 0.0764
[2019-03-24 04:13:53,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2252290: learning rate 0.0001
[2019-03-24 04:13:55,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1362679e-13 2.6323391e-02 2.0373441e-09 9.7366232e-01 1.4231516e-05], sum to 1.0000
[2019-03-24 04:13:55,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5665
[2019-03-24 04:13:55,819] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 95.0, 1.0, 2.0, 0.6293428428609438, 1.0, 2.0, 0.6293428428609438, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1435141.973241387, 1435141.973241387, 278281.2874957376], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4975200.0000, 
sim time next is 4975800.0000, 
raw observation next is [24.83333333333334, 91.5, 1.0, 2.0, 0.5831132785491496, 1.0, 2.0, 0.5831132785491496, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1329629.407795504, 1329629.407795505, 262282.7721736701], 
processed observation next is [1.0, 0.6086956521739131, 0.47530864197530887, 0.915, 1.0, 1.0, 0.5037062839870828, 1.0, 1.0, 0.5037062839870828, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.4748676456412514, 0.4748676456412517, 0.5043899464878272], 
reward next is 0.4956, 
noisyNet noise sample is [array([1.3323534], dtype=float32), -0.16840234]. 
=============================================
[2019-03-24 04:13:57,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4594702e-18 1.3204743e-02 5.4276706e-13 9.8679358e-01 1.6569187e-06], sum to 1.0000
[2019-03-24 04:13:57,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9035
[2019-03-24 04:13:57,412] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.86666666666667, 99.33333333333334, 1.0, 2.0, 0.2907913843271062, 1.0, 2.0, 0.2907913843271062, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669586.300836324, 669586.3008363245, 178603.1446777029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5016000.0000, 
sim time next is 5016600.0000, 
raw observation next is [22.8, 99.0, 1.0, 2.0, 0.2875487752052412, 1.0, 2.0, 0.2875487752052412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663659.0838810424, 663659.0838810424, 177908.550106398], 
processed observation next is [0.0, 0.043478260869565216, 0.4, 0.99, 1.0, 1.0, 0.15184378000623952, 1.0, 1.0, 0.15184378000623952, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2370211013860866, 0.2370211013860866, 0.34213182712768847], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.2126989], dtype=float32), -1.0407602]. 
=============================================
[2019-03-24 04:13:57,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2637241e-22 1.0998149e-04 1.2993794e-16 9.9988997e-01 1.7981244e-09], sum to 1.0000
[2019-03-24 04:13:57,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8881
[2019-03-24 04:13:57,521] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 95.0, 1.0, 2.0, 0.3110850670281208, 1.0, 2.0, 0.3110850670281208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 709056.9207743221, 709056.9207743226, 183141.9167942982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5003400.0000, 
sim time next is 5004000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3074381263962078, 1.0, 2.0, 0.3074381263962078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700740.6411611964, 700740.6411611967, 182255.0078701213], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.94, 1.0, 1.0, 0.17552157904310456, 1.0, 1.0, 0.17552157904310456, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25026451470042727, 0.25026451470042743, 0.3504903997502333], 
reward next is 0.6495, 
noisyNet noise sample is [array([1.3123614], dtype=float32), -1.3473369]. 
=============================================
[2019-03-24 04:13:57,542] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.366425]
 [71.39756 ]
 [71.40393 ]
 [71.39043 ]
 [71.3666  ]], R is [[71.35984802]
 [71.29405212]
 [71.22724152]
 [71.1595459 ]
 [71.09126282]].
[2019-03-24 04:13:58,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0176440e-20 2.0822708e-04 6.3602291e-16 9.9979180e-01 4.4984720e-08], sum to 1.0000
[2019-03-24 04:13:58,623] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6115
[2019-03-24 04:13:58,626] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.3499913514320662, 1.0, 2.0, 0.3499913514320662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797782.2534369333, 797782.2534369337, 192890.7763976109], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.3518128742023039, 1.0, 2.0, 0.3518128742023039, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801936.4667788643, 801936.4667788643, 193360.0555875568], 
processed observation next is [0.0, 0.43478260869565216, 0.5925925925925926, 0.79, 1.0, 1.0, 0.2283486597646475, 1.0, 1.0, 0.2283486597646475, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2864058809924515, 0.2864058809924515, 0.3718462607453015], 
reward next is 0.6282, 
noisyNet noise sample is [array([-0.2580187], dtype=float32), -2.3902411]. 
=============================================
[2019-03-24 04:14:01,966] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2256570: loss 0.0981
[2019-03-24 04:14:01,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2256572: learning rate 0.0001
[2019-03-24 04:14:02,224] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256700: loss 0.0019
[2019-03-24 04:14:02,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256700: learning rate 0.0001
[2019-03-24 04:14:02,522] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2256861: loss 0.0027
[2019-03-24 04:14:02,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2256861: learning rate 0.0001
[2019-03-24 04:14:02,882] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2257055: loss 0.0291
[2019-03-24 04:14:02,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2257056: learning rate 0.0001
[2019-03-24 04:14:02,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2257064: loss 0.0048
[2019-03-24 04:14:02,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2257064: learning rate 0.0001
[2019-03-24 04:14:03,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2257193: loss 0.0059
[2019-03-24 04:14:03,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2257194: learning rate 0.0001
[2019-03-24 04:14:03,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2257197: loss 0.0056
[2019-03-24 04:14:03,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2257197: learning rate 0.0001
[2019-03-24 04:14:03,153] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2257212: loss 0.0035
[2019-03-24 04:14:03,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2257212: learning rate 0.0001
[2019-03-24 04:14:03,469] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2257397: loss 0.0383
[2019-03-24 04:14:03,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2257397: learning rate 0.0001
[2019-03-24 04:14:03,474] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257397: loss 0.0289
[2019-03-24 04:14:03,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257397: learning rate 0.0001
[2019-03-24 04:14:03,603] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257478: loss 0.0010
[2019-03-24 04:14:03,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257478: learning rate 0.0001
[2019-03-24 04:14:03,682] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257534: loss 0.0051
[2019-03-24 04:14:03,685] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257534: learning rate 0.0001
[2019-03-24 04:14:03,935] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2257674: loss 0.0201
[2019-03-24 04:14:03,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2257677: learning rate 0.0001
[2019-03-24 04:14:04,808] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2258104: loss 0.2556
[2019-03-24 04:14:04,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2258104: learning rate 0.0001
[2019-03-24 04:14:04,825] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2258112: loss 0.1940
[2019-03-24 04:14:04,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2258113: learning rate 0.0001
[2019-03-24 04:14:04,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1104707e-17 1.2386282e-04 9.4881080e-13 9.9987602e-01 1.3784678e-07], sum to 1.0000
[2019-03-24 04:14:04,988] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-24 04:14:04,993] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.56666666666667, 97.0, 1.0, 2.0, 0.249404914340683, 1.0, 2.0, 0.249404914340683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593197.7878048576, 593197.7878048581, 169929.313075698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5714400.0000, 
sim time next is 5715000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.2481805881973214, 1.0, 2.0, 0.2481805881973214, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590997.3751141588, 590997.3751141593, 169682.1765309114], 
processed observation next is [0.0, 0.13043478260869565, 0.35185185185185186, 0.97, 1.0, 1.0, 0.10497689071109689, 1.0, 1.0, 0.10497689071109689, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21107049111219958, 0.21107049111219975, 0.3263118779440604], 
reward next is 0.6737, 
noisyNet noise sample is [array([-0.66149527], dtype=float32), 1.0003246]. 
=============================================
[2019-03-24 04:14:05,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[60.031887]
 [60.115074]
 [60.069   ]
 [60.157974]
 [60.195137]], R is [[60.13694   ]
 [60.20878601]
 [60.28015137]
 [60.3502121 ]
 [60.41897583]].
[2019-03-24 04:14:09,154] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2260243: loss -11.5511
[2019-03-24 04:14:09,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2260243: learning rate 0.0001
[2019-03-24 04:14:11,853] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3619432e-19 5.2852934e-05 2.7510625e-13 9.9994695e-01 2.8549076e-07], sum to 1.0000
[2019-03-24 04:14:11,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-24 04:14:11,863] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 88.0, 1.0, 2.0, 0.3570427326611542, 1.0, 2.0, 0.3570427326611542, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813863.9463922792, 813863.9463922792, 194713.580268295], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5259600.0000, 
sim time next is 5260200.0000, 
raw observation next is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.34994616641638, 1.0, 2.0, 0.34994616641638, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797679.2035729445, 797679.203572945, 192879.1442386404], 
processed observation next is [1.0, 0.9130434782608695, 0.5376543209876544, 0.8833333333333334, 1.0, 1.0, 0.22612638859092857, 1.0, 1.0, 0.22612638859092857, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28488542984748016, 0.28488542984748033, 0.37092143122815463], 
reward next is 0.6291, 
noisyNet noise sample is [array([-0.22803265], dtype=float32), -0.40204895]. 
=============================================
[2019-03-24 04:14:13,427] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9419395e-16 1.1456169e-04 9.1548479e-12 9.9988079e-01 4.6668492e-06], sum to 1.0000
[2019-03-24 04:14:13,435] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9512
[2019-03-24 04:14:13,440] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.83333333333334, 90.33333333333334, 1.0, 2.0, 0.2726593887470708, 1.0, 2.0, 0.2726593887470708, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 642602.1694311524, 642602.1694311529, 175030.1229257421], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5294400.0000, 
sim time next is 5295000.0000, 
raw observation next is [22.71666666666667, 90.66666666666667, 1.0, 2.0, 0.268458765340186, 1.0, 2.0, 0.268458765340186, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 633686.551325436, 633686.5513254364, 174095.413916873], 
processed observation next is [1.0, 0.2608695652173913, 0.39691358024691364, 0.9066666666666667, 1.0, 1.0, 0.1291175777859357, 1.0, 1.0, 0.1291175777859357, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22631662547337, 0.22631662547337017, 0.33479887291706345], 
reward next is 0.6652, 
noisyNet noise sample is [array([-0.5306393], dtype=float32), 0.9876673]. 
=============================================
[2019-03-24 04:14:13,459] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[54.485344]
 [54.60177 ]
 [54.73352 ]
 [54.80755 ]
 [54.769505]], R is [[54.57514572]
 [54.69279861]
 [54.8061676 ]
 [54.91951752]
 [55.02780151]].
[2019-03-24 04:14:18,050] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2264607: loss 0.1741
[2019-03-24 04:14:18,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2264608: learning rate 0.0001
[2019-03-24 04:14:18,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.10216287e-15 1.02711265e-05 1.02045473e-11 9.99988317e-01
 1.40994575e-06], sum to 1.0000
[2019-03-24 04:14:18,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-24 04:14:18,316] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 75.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.054810746957778, 6.9112, 121.9254733288117, 2400818.932531552, 2327277.737680241, 443048.9671856424], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5416200.0000, 
sim time next is 5416800.0000, 
raw observation next is [29.66666666666667, 74.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.241922661758196, 6.9112, 121.9245069083664, 2496760.102229681, 2327402.672904861, 443048.9371246396], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.7433333333333334, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.03307226617581964, 0.0, 0.8094519333207175, 0.8917000365106003, 0.8312152403231647, 0.8520171867781531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7188684], dtype=float32), 0.22479038]. 
=============================================
[2019-03-24 04:14:18,333] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264746: loss 0.0734
[2019-03-24 04:14:18,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264747: learning rate 0.0001
[2019-03-24 04:14:18,690] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264922: loss 0.0480
[2019-03-24 04:14:18,692] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264923: learning rate 0.0001
[2019-03-24 04:14:18,749] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264944: loss 0.0467
[2019-03-24 04:14:18,752] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264944: learning rate 0.0001
[2019-03-24 04:14:18,932] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2265033: loss 0.0239
[2019-03-24 04:14:18,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2265033: learning rate 0.0001
[2019-03-24 04:14:19,037] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2265087: loss 0.0234
[2019-03-24 04:14:19,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2265087: learning rate 0.0001
[2019-03-24 04:14:19,108] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2265121: loss 0.0185
[2019-03-24 04:14:19,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2265121: learning rate 0.0001
[2019-03-24 04:14:19,266] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2265201: loss 0.0351
[2019-03-24 04:14:19,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2265201: learning rate 0.0001
[2019-03-24 04:14:19,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4953381e-10 8.1343293e-02 2.4167397e-07 9.1609573e-01 2.5608265e-03], sum to 1.0000
[2019-03-24 04:14:19,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9906
[2019-03-24 04:14:19,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 77.33333333333334, 1.0, 2.0, 0.8083703145828842, 1.0, 2.0, 0.8083703145828842, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1843839.460733702, 1843839.460733702, 347225.3324673338], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5397000.0000, 
sim time next is 5397600.0000, 
raw observation next is [27.66666666666667, 78.66666666666667, 1.0, 2.0, 0.8241483778949569, 1.0, 2.0, 0.8241483778949569, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1879866.057414014, 1879866.057414014, 353834.0096008328], 
processed observation next is [1.0, 0.4782608695652174, 0.580246913580247, 0.7866666666666667, 1.0, 1.0, 0.7906528308273296, 1.0, 1.0, 0.7906528308273296, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6713807347907192, 0.6713807347907192, 0.68045001846314], 
reward next is 0.3195, 
noisyNet noise sample is [array([-0.87282], dtype=float32), 0.33772743]. 
=============================================
[2019-03-24 04:14:19,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7691796e-13 8.8281225e-04 3.6480688e-10 9.9904889e-01 6.8223613e-05], sum to 1.0000
[2019-03-24 04:14:19,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5292
[2019-03-24 04:14:19,536] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.3618764685814599, 1.0, 2.0, 0.3618764685814599, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 824888.1739753722, 824888.1739753727, 195971.6786702698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5382000.0000, 
sim time next is 5382600.0000, 
raw observation next is [24.65, 91.00000000000001, 1.0, 2.0, 0.3649979689813453, 1.0, 2.0, 0.3649979689813453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832007.4164577109, 832007.4164577114, 196789.3510489978], 
processed observation next is [1.0, 0.30434782608695654, 0.46851851851851845, 0.9100000000000001, 1.0, 1.0, 0.2440452011682682, 1.0, 1.0, 0.2440452011682682, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2971455058777539, 0.29714550587775407, 0.37844105970961117], 
reward next is 0.6216, 
noisyNet noise sample is [array([-0.04661842], dtype=float32), 0.5316339]. 
=============================================
[2019-03-24 04:14:19,546] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265337: loss 0.0204
[2019-03-24 04:14:19,550] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265337: learning rate 0.0001
[2019-03-24 04:14:19,847] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2265486: loss 0.0350
[2019-03-24 04:14:19,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2265486: learning rate 0.0001
[2019-03-24 04:14:19,929] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265527: loss 0.0442
[2019-03-24 04:14:19,934] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265529: learning rate 0.0001
[2019-03-24 04:14:20,053] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2265588: loss 0.1442
[2019-03-24 04:14:20,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2265588: learning rate 0.0001
[2019-03-24 04:14:20,087] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2815743e-19 6.1353558e-04 2.5368059e-13 9.9937880e-01 7.6406577e-06], sum to 1.0000
[2019-03-24 04:14:20,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5338
[2019-03-24 04:14:20,101] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.23333333333333, 84.33333333333333, 1.0, 2.0, 0.392011466557278, 1.0, 2.0, 0.392011466557278, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 893620.1790110203, 893620.1790110208, 204008.5958830383], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [28.16666666666667, 84.66666666666667, 1.0, 2.0, 0.3916491872905277, 1.0, 2.0, 0.3916491872905277, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 892793.85463071, 892793.8546307096, 203910.1221929076], 
processed observation next is [1.0, 0.9130434782608695, 0.5987654320987656, 0.8466666666666667, 1.0, 1.0, 0.275772842012533, 1.0, 1.0, 0.275772842012533, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3188549480823964, 0.3188549480823963, 0.3921348503709762], 
reward next is 0.6079, 
noisyNet noise sample is [array([1.3662335], dtype=float32), -1.4571595]. 
=============================================
[2019-03-24 04:14:20,152] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265638: loss -11.1012
[2019-03-24 04:14:20,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265638: learning rate 0.0001
[2019-03-24 04:14:20,366] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4068388e-15 6.3193529e-03 6.5931557e-12 9.9359131e-01 8.9446447e-05], sum to 1.0000
[2019-03-24 04:14:20,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6897
[2019-03-24 04:14:20,383] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 75.0, 1.0, 2.0, 0.3614208147684624, 1.0, 2.0, 0.3614208147684624, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823848.9645240116, 823848.9645240121, 195854.8872869004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5421600.0000, 
sim time next is 5422200.0000, 
raw observation next is [29.53333333333333, 75.5, 1.0, 2.0, 0.3698856858685513, 1.0, 2.0, 0.3698856858685513, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 843155.0223874085, 843155.022387409, 198078.6660057481], 
processed observation next is [1.0, 0.782608695652174, 0.6493827160493827, 0.755, 1.0, 1.0, 0.24986391174827538, 1.0, 1.0, 0.24986391174827538, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3011267937097888, 0.30112679370978895, 0.38092051154951556], 
reward next is 0.6191, 
noisyNet noise sample is [array([-0.92977387], dtype=float32), 0.8205159]. 
=============================================
[2019-03-24 04:14:21,178] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2266138: loss 0.0495
[2019-03-24 04:14:21,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2266138: learning rate 0.0001
[2019-03-24 04:14:21,194] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2266146: loss 4.1934
[2019-03-24 04:14:21,199] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2266147: learning rate 0.0001
[2019-03-24 04:14:22,976] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3741220e-09 8.7979190e-02 3.5061123e-06 7.6937962e-01 1.4263779e-01], sum to 1.0000
[2019-03-24 04:14:22,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1599
[2019-03-24 04:14:22,987] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.96666666666667, 85.5, 1.0, 2.0, 0.9693996801580841, 1.0, 2.0, 0.9693996801580841, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2211591.662934663, 2211591.662934663, 418727.1312970734], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5478600.0000, 
sim time next is 5479200.0000, 
raw observation next is [29.1, 85.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.143019817589591, 6.9112, 121.9252995634041, 2446048.369430589, 2327336.626472342, 443049.9786613436], 
processed observation next is [1.0, 0.43478260869565216, 0.6333333333333334, 0.85, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.023181981758959136, 0.0, 0.8094571957258647, 0.8735887033680675, 0.8311916523115507, 0.852019189733353], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25663263], dtype=float32), -0.6498212]. 
=============================================
[2019-03-24 04:14:25,681] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2268346: loss 0.8417
[2019-03-24 04:14:25,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2268348: learning rate 0.0001
[2019-03-24 04:14:28,682] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7746235e-13 1.7475863e-03 6.1398331e-10 2.6222496e-04 9.9799025e-01], sum to 1.0000
[2019-03-24 04:14:28,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3847
[2019-03-24 04:14:28,695] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.4545150156532595, 1.0, 2.0, 0.4545150156532595, 1.0, 2.0, 0.7236027074406312, 6.9112, 6.9112, 121.94756008, 1554822.759941643, 1554822.759941643, 321785.3776027851], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5590800.0000, 
sim time next is 5591400.0000, 
raw observation next is [25.05, 91.00000000000001, 1.0, 2.0, 0.2488963585717273, 1.0, 2.0, 0.2488963585717273, 1.0, 2.0, 0.39625110883468, 6.9112, 6.9112, 121.94756008, 851043.7751895372, 851043.7751895372, 237234.4451009856], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.9100000000000001, 1.0, 1.0, 0.10582899829967535, 1.0, 1.0, 0.10582899829967535, 1.0, 1.0, 0.24531388604335, 0.0, 0.0, 0.8096049824067558, 0.3039442054248347, 0.3039442054248347, 0.4562200867326646], 
reward next is 0.5438, 
noisyNet noise sample is [array([0.2696689], dtype=float32), 0.3909522]. 
=============================================
[2019-03-24 04:14:32,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7140348e-19 5.9078462e-05 2.2882583e-13 5.0935811e-05 9.9988997e-01], sum to 1.0000
[2019-03-24 04:14:32,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1848
[2019-03-24 04:14:32,213] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 76.33333333333334, 1.0, 2.0, 0.2361524646196798, 1.0, 2.0, 0.2361524646196798, 1.0, 2.0, 0.3759624146233698, 6.9112, 6.9112, 121.94756008, 807446.0161189153, 807446.0161189153, 232768.8033032157], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5661600.0000, 
sim time next is 5662200.0000, 
raw observation next is [28.6, 75.66666666666666, 1.0, 2.0, 0.2360297858718567, 1.0, 2.0, 0.2360297858718567, 1.0, 2.0, 0.3757671060614676, 6.911199999999999, 6.9112, 121.94756008, 807026.3355284448, 807026.3355284453, 232726.2559673137], 
processed observation next is [0.0, 0.5217391304347826, 0.6148148148148148, 0.7566666666666666, 1.0, 1.0, 0.09051164984744844, 1.0, 1.0, 0.09051164984744844, 1.0, 1.0, 0.21970888257683452, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2882236912601589, 0.28822369126015907, 0.447550492244834], 
reward next is 0.5524, 
noisyNet noise sample is [array([-0.304452], dtype=float32), -1.1592174]. 
=============================================
[2019-03-24 04:14:34,511] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2272705: loss 0.4398
[2019-03-24 04:14:34,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2272705: learning rate 0.0001
[2019-03-24 04:14:34,586] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272747: loss 0.5278
[2019-03-24 04:14:34,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272747: learning rate 0.0001
[2019-03-24 04:14:34,900] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272900: loss 1.2558
[2019-03-24 04:14:34,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272900: learning rate 0.0001
[2019-03-24 04:14:35,054] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272975: loss 0.5633
[2019-03-24 04:14:35,057] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272975: learning rate 0.0001
[2019-03-24 04:14:35,064] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2272976: loss 0.5542
[2019-03-24 04:14:35,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2272976: learning rate 0.0001
[2019-03-24 04:14:35,113] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2273000: loss 0.7498
[2019-03-24 04:14:35,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2273000: learning rate 0.0001
[2019-03-24 04:14:35,376] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2273126: loss 0.3825
[2019-03-24 04:14:35,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2273126: learning rate 0.0001
[2019-03-24 04:14:35,650] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273266: loss 0.3485
[2019-03-24 04:14:35,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273267: learning rate 0.0001
[2019-03-24 04:14:35,682] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2273279: loss 0.2349
[2019-03-24 04:14:35,683] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2273279: learning rate 0.0001
[2019-03-24 04:14:36,076] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2273464: loss 0.0568
[2019-03-24 04:14:36,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2273464: learning rate 0.0001
[2019-03-24 04:14:36,333] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2273594: loss 0.1023
[2019-03-24 04:14:36,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2273594: learning rate 0.0001
[2019-03-24 04:14:36,342] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2273595: loss 0.2543
[2019-03-24 04:14:36,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2273597: learning rate 0.0001
[2019-03-24 04:14:36,393] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2273620: loss 9.8232
[2019-03-24 04:14:36,394] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2273620: learning rate 0.0001
[2019-03-24 04:14:37,292] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6309039e-12 9.9804592e-01 5.3749001e-09 2.1875234e-04 1.7352403e-03], sum to 1.0000
[2019-03-24 04:14:37,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3059
[2019-03-24 04:14:37,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1442051.738965714 W.
[2019-03-24 04:14:37,318] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.26666666666667, 43.66666666666667, 1.0, 2.0, 0.6047775691472536, 1.0, 2.0, 0.6047775691472536, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156422, 1442051.738965714, 1442051.738965713, 272501.9482058241], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5924400.0000, 
sim time next is 5925000.0000, 
raw observation next is [29.43333333333333, 42.83333333333333, 1.0, 2.0, 0.6122624434140779, 1.0, 2.0, 0.6122624434140779, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1462129.39506445, 1462129.39506445, 275224.4159934461], 
processed observation next is [1.0, 0.5652173913043478, 0.6456790123456789, 0.4283333333333333, 1.0, 1.0, 0.5384076707310451, 1.0, 1.0, 0.5384076707310451, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5221890696658751, 0.5221890696658751, 0.5292777230643194], 
reward next is 0.4707, 
noisyNet noise sample is [array([-0.06836417], dtype=float32), 1.2694011]. 
=============================================
[2019-03-24 04:14:37,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[45.218605]
 [44.696598]
 [44.48972 ]
 [44.234974]
 [44.81632 ]], R is [[45.31978226]
 [44.86658478]
 [44.86182785]
 [44.91509247]
 [44.46594238]].
[2019-03-24 04:14:37,413] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2274132: loss 1.1892
[2019-03-24 04:14:37,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2274132: learning rate 0.0001
[2019-03-24 04:14:37,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2274145: loss 0.4418
[2019-03-24 04:14:37,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2274145: learning rate 0.0001
[2019-03-24 04:14:38,493] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2218381e-23 9.9945956e-01 5.4940350e-17 2.6360010e-06 5.3780887e-04], sum to 1.0000
[2019-03-24 04:14:38,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3273
[2019-03-24 04:14:38,505] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 66.0, 1.0, 2.0, 0.5882103247840441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679828.2010974919, 679828.2010974919, 156519.9385316703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5761800.0000, 
sim time next is 5762400.0000, 
raw observation next is [28.23333333333333, 66.33333333333333, 1.0, 2.0, 0.592892388251535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683978.6915887696, 683978.6915887696, 157262.5276403902], 
processed observation next is [0.0, 0.6956521739130435, 0.6012345679012344, 0.6633333333333333, 1.0, 1.0, 0.5153480812518274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24427810413884626, 0.24427810413884626, 0.30242793776998117], 
reward next is 0.6976, 
noisyNet noise sample is [array([1.4655595], dtype=float32), -0.75217295]. 
=============================================
[2019-03-24 04:14:39,208] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 04:14:39,209] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:14:39,211] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:14:39,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:39,212] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:14:39,213] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:14:39,213] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:39,213] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:39,213] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:14:39,215] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:39,217] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:39,239] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-24 04:14:39,267] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-24 04:14:39,267] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-24 04:14:39,310] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-24 04:14:39,339] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-24 04:15:08,378] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0870215]
[2019-03-24 04:15:08,381] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.94520626, 79.71930363, 1.0, 2.0, 0.4545414314668695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552633.6421160003, 552633.6421160003, 136286.4592768596]
[2019-03-24 04:15:08,381] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:15:08,385] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1925497e-22 9.9998116e-01 2.4928466e-16 6.1499823e-06 1.2597962e-05], sampled 0.9722025973196041
[2019-03-24 04:15:36,513] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0870215]
[2019-03-24 04:15:36,515] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.06666666666667, 66.33333333333334, 1.0, 2.0, 0.5832934928481193, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9286222371570503, 6.911199999999999, 6.9112, 121.9260426156618, 1330040.693705613, 1330040.693705613, 287425.3186637061]
[2019-03-24 04:15:36,516] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:15:36,519] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9103251e-19 9.9991131e-01 4.3906214e-14 3.1877807e-05 5.6895035e-05], sampled 0.22303964997505588
[2019-03-24 04:15:36,520] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1330040.693705613 W.
[2019-03-24 04:15:39,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0870215]
[2019-03-24 04:15:39,108] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4525751059036009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549329.9218498548, 549329.9218498548, 135964.8912474623]
[2019-03-24 04:15:39,109] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:15:39,113] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3942965e-21 9.9996603e-01 1.7881897e-15 1.1504044e-05 2.2379490e-05], sampled 0.06770108778250772
[2019-03-24 04:15:49,550] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0870215]
[2019-03-24 04:15:49,551] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 74.0, 1.0, 2.0, 0.6075129132836754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699991.2635304794, 699991.2635304794, 159748.0961259133]
[2019-03-24 04:15:49,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:15:49,553] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9359184e-21 9.9996173e-01 2.6734549e-15 1.3075302e-05 2.5173998e-05], sampled 0.5353722006247958
[2019-03-24 04:16:02,221] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0870215]
[2019-03-24 04:16:02,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 70.0, 1.0, 2.0, 0.6465026433126587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736800.820481555, 736800.820481555, 166264.9599429699]
[2019-03-24 04:16:02,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:16:02,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.3018758e-22 9.9997568e-01 5.9225809e-16 8.0971868e-06 1.6218246e-05], sampled 0.7075815907656673
[2019-03-24 04:16:19,966] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:16:20,299] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:16:20,379] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7727 2248688335.9555 553.0000
[2019-03-24 04:16:20,445] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.8637 2195077454.7142 572.0000
[2019-03-24 04:16:20,526] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.3353 2445298699.3775 745.0000
[2019-03-24 04:16:21,542] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2275000, evaluation results [2275000.0, 8100.335323282105, 2445298699.3775454, 745.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.772682715442, 2248688335.955484, 553.0, 8699.863715089983, 2195077454.714153, 572.0]
[2019-03-24 04:16:24,324] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2276447: loss -11.7074
[2019-03-24 04:16:24,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2276447: learning rate 0.0001
[2019-03-24 04:16:28,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4503444e-13 9.1170692e-01 1.4886297e-09 7.6759771e-02 1.1533328e-02], sum to 1.0000
[2019-03-24 04:16:28,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0792
[2019-03-24 04:16:28,653] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 66.0, 1.0, 2.0, 0.9134933140203046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.074540755235944, 6.9112, 121.9253655600135, 1210693.75510823, 1127049.153677667, 224258.6799499373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5908800.0000, 
sim time next is 5909400.0000, 
raw observation next is [24.35, 65.0, 1.0, 2.0, 0.9413476595919941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.252285634251525, 6.9112, 121.9244880806547, 1334694.44851108, 1160030.344850394, 230745.1570126223], 
processed observation next is [1.0, 0.391304347826087, 0.4574074074074075, 0.65, 1.0, 1.0, 0.9301757852285644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03410856342515247, 0.0, 0.8094518083242912, 0.4766765887539571, 0.4142965517322835, 0.4437406865627352], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3959272], dtype=float32), -1.3240556]. 
=============================================
[2019-03-24 04:16:33,175] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2328088e-17 9.8452330e-01 8.3084538e-12 1.4724970e-04 1.5329473e-02], sum to 1.0000
[2019-03-24 04:16:33,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-24 04:16:33,183] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 63.33333333333333, 1.0, 2.0, 0.5003782880722163, 1.0, 1.0, 0.5003782880722163, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9256076723691, 1140834.549524774, 1140834.549524774, 235498.9465602353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6007200.0000, 
sim time next is 6007800.0000, 
raw observation next is [28.83333333333334, 62.66666666666667, 1.0, 2.0, 0.8927073388849945, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260424830337, 1025077.243328596, 1025077.243328597, 216242.8322830077], 
processed observation next is [1.0, 0.5217391304347826, 0.623456790123457, 0.6266666666666667, 1.0, 1.0, 0.8722706415297554, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621279396232, 0.3660990154744986, 0.36609901547449897, 0.4158516005442456], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21879855], dtype=float32), -0.18574814]. 
=============================================
[2019-03-24 04:16:33,199] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2280732: loss 13.8716
[2019-03-24 04:16:33,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2280733: learning rate 0.0001
[2019-03-24 04:16:33,346] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280806: loss 33.0951
[2019-03-24 04:16:33,348] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280806: learning rate 0.0001
[2019-03-24 04:16:33,406] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280835: loss 26.0898
[2019-03-24 04:16:33,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280836: learning rate 0.0001
[2019-03-24 04:16:33,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2280850: loss -2.7191
[2019-03-24 04:16:33,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2280850: learning rate 0.0001
[2019-03-24 04:16:33,544] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280906: loss 28.9622
[2019-03-24 04:16:33,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280906: learning rate 0.0001
[2019-03-24 04:16:33,737] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2281003: loss 11.1466
[2019-03-24 04:16:33,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2281003: learning rate 0.0001
[2019-03-24 04:16:33,954] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2281115: loss 70.1716
[2019-03-24 04:16:33,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2281115: learning rate 0.0001
[2019-03-24 04:16:34,075] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2281172: loss 34.4009
[2019-03-24 04:16:34,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2281173: learning rate 0.0001
[2019-03-24 04:16:34,218] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2281245: loss 14.5860
[2019-03-24 04:16:34,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2281247: learning rate 0.0001
[2019-03-24 04:16:34,643] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2281467: loss -33.0812
[2019-03-24 04:16:34,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2281468: learning rate 0.0001
[2019-03-24 04:16:34,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2647422e-17 9.1276741e-01 2.0228744e-11 5.8558220e-05 8.7174110e-02], sum to 1.0000
[2019-03-24 04:16:34,793] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7870
[2019-03-24 04:16:34,800] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1588042.312019186 W.
[2019-03-24 04:16:34,803] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 58.33333333333333, 1.0, 2.0, 0.6963241232217685, 1.0, 2.0, 0.6963241232217685, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1588042.312019186, 1588042.312019187, 302774.5930235103], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6014400.0000, 
sim time next is 6015000.0000, 
raw observation next is [29.0, 58.16666666666666, 1.0, 2.0, 0.7436448793769853, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9922518302523284, 6.9112, 6.9112, 121.9260426156618, 1567667.588825098, 1567667.588825098, 324396.4547264273], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.5816666666666666, 1.0, 1.0, 0.6948153325916492, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9903147878154106, 0.0, 0.0, 0.8094621288201359, 0.5598812817232492, 0.5598812817232492, 0.6238393360123602], 
reward next is 0.3762, 
noisyNet noise sample is [array([-2.2107992], dtype=float32), 0.23545386]. 
=============================================
[2019-03-24 04:16:34,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.95915 ]
 [63.311836]
 [63.121273]
 [63.369633]
 [62.646023]], R is [[63.64015961]
 [63.42149734]
 [63.17694092]
 [62.89670563]
 [62.61761856]].
[2019-03-24 04:16:34,848] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281574: loss 26.8643
[2019-03-24 04:16:34,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281575: learning rate 0.0001
[2019-03-24 04:16:34,912] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2281610: loss -34.8714
[2019-03-24 04:16:34,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2281611: learning rate 0.0001
[2019-03-24 04:16:35,106] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2281704: loss 10.5427
[2019-03-24 04:16:35,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2281704: learning rate 0.0001
[2019-03-24 04:16:35,771] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2282051: loss -15.6262
[2019-03-24 04:16:35,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2282051: learning rate 0.0001
[2019-03-24 04:16:35,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4025391e-18 9.9883944e-01 1.1423015e-12 7.6602873e-07 1.1598796e-03], sum to 1.0000
[2019-03-24 04:16:35,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8573
[2019-03-24 04:16:35,819] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.85, 61.0, 1.0, 2.0, 0.5208029319692287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615893.1749064892, 615893.1749064892, 145999.2320843943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6028200.0000, 
sim time next is 6028800.0000, 
raw observation next is [27.73333333333333, 61.66666666666667, 1.0, 2.0, 0.5213949765618381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616494.9881256861, 616494.9881256861, 146090.29115633], 
processed observation next is [1.0, 0.782608695652174, 0.5827160493827159, 0.6166666666666667, 1.0, 1.0, 0.43023211495456914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22017678147345932, 0.22017678147345932, 0.28094286760832693], 
reward next is 0.7191, 
noisyNet noise sample is [array([2.8355021], dtype=float32), 2.0809608]. 
=============================================
[2019-03-24 04:16:36,357] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2282342: loss 38.2499
[2019-03-24 04:16:36,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2282344: learning rate 0.0001
[2019-03-24 04:16:40,095] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2284332: loss 0.0899
[2019-03-24 04:16:40,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2284332: learning rate 0.0001
[2019-03-24 04:16:41,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3197183e-19 9.9943215e-01 2.3083171e-13 1.5750706e-08 5.6782283e-04], sum to 1.0000
[2019-03-24 04:16:41,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7439
[2019-03-24 04:16:41,852] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666667, 72.33333333333334, 1.0, 2.0, 0.6792899166113102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774186.4208586239, 774186.4208586239, 172260.0963005015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6344400.0000, 
sim time next is 6345000.0000, 
raw observation next is [28.8, 71.5, 1.0, 2.0, 0.6868950970339637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782858.4679592135, 782858.4679592131, 173677.7484185063], 
processed observation next is [0.0, 0.43478260869565216, 0.6222222222222222, 0.715, 1.0, 1.0, 0.6272560678975758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2795923099854334, 0.2795923099854332, 0.333995670035589], 
reward next is 0.6660, 
noisyNet noise sample is [array([0.9265043], dtype=float32), 0.62723446]. 
=============================================
[2019-03-24 04:16:41,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.97775]
 [64.07668]
 [64.10129]
 [64.15362]
 [64.21406]], R is [[63.94464111]
 [63.97392654]
 [64.0071106 ]
 [64.03836823]
 [64.07084656]].
[2019-03-24 04:16:47,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2950006e-20 9.9981266e-01 4.3799257e-14 3.3161061e-11 1.8731492e-04], sum to 1.0000
[2019-03-24 04:16:47,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3667
[2019-03-24 04:16:47,726] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 62.83333333333333, 1.0, 2.0, 0.646868259363808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737217.7031496238, 737217.7031496238, 166328.225769791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6275400.0000, 
sim time next is 6276000.0000, 
raw observation next is [29.8, 62.66666666666667, 1.0, 2.0, 0.6495004107501783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740218.9410213553, 740218.9410213553, 166802.8882790058], 
processed observation next is [0.0, 0.6521739130434783, 0.6592592592592593, 0.6266666666666667, 1.0, 1.0, 0.5827385842264027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2643639075076269, 0.2643639075076269, 0.32077478515193425], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.35779265], dtype=float32), -0.12754348]. 
=============================================
[2019-03-24 04:16:47,737] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.316025]
 [64.30925 ]
 [64.267624]
 [64.234634]
 [64.20597 ]], R is [[64.36281586]
 [64.39933014]
 [64.4339447 ]
 [64.46843719]
 [64.50284576]].
[2019-03-24 04:16:49,042] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2288707: loss 0.0406
[2019-03-24 04:16:49,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2288707: learning rate 0.0001
[2019-03-24 04:16:49,126] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288748: loss 0.0471
[2019-03-24 04:16:49,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288749: learning rate 0.0001
[2019-03-24 04:16:49,259] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2288816: loss 0.1481
[2019-03-24 04:16:49,259] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2288816: learning rate 0.0001
[2019-03-24 04:16:49,301] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288833: loss 0.2053
[2019-03-24 04:16:49,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288834: learning rate 0.0001
[2019-03-24 04:16:49,404] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288887: loss 0.1067
[2019-03-24 04:16:49,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288888: learning rate 0.0001
[2019-03-24 04:16:49,696] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2289028: loss 0.0368
[2019-03-24 04:16:49,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2289028: learning rate 0.0001
[2019-03-24 04:16:49,713] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2289035: loss 0.0374
[2019-03-24 04:16:49,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2289036: learning rate 0.0001
[2019-03-24 04:16:50,119] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2289237: loss 0.0397
[2019-03-24 04:16:50,121] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2289238: learning rate 0.0001
[2019-03-24 04:16:50,280] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289317: loss 0.0253
[2019-03-24 04:16:50,285] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289318: learning rate 0.0001
[2019-03-24 04:16:50,682] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2289514: loss 0.0307
[2019-03-24 04:16:50,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2289515: learning rate 0.0001
[2019-03-24 04:16:50,839] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2289594: loss 0.0279
[2019-03-24 04:16:50,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2289594: learning rate 0.0001
[2019-03-24 04:16:50,898] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289620: loss 0.0416
[2019-03-24 04:16:50,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289621: learning rate 0.0001
[2019-03-24 04:16:51,196] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2289766: loss 0.0573
[2019-03-24 04:16:51,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2289766: learning rate 0.0001
[2019-03-24 04:16:51,891] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2290112: loss 0.1349
[2019-03-24 04:16:51,892] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2290112: learning rate 0.0001
[2019-03-24 04:16:52,035] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2290185: loss 0.0329
[2019-03-24 04:16:52,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2290185: learning rate 0.0001
[2019-03-24 04:16:56,568] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2292395: loss 10.4377
[2019-03-24 04:16:56,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2292395: learning rate 0.0001
[2019-03-24 04:17:00,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5218515e-17 5.3511958e-06 1.1205193e-09 1.6561383e-04 9.9982905e-01], sum to 1.0000
[2019-03-24 04:17:00,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4016
[2019-03-24 04:17:00,032] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.43333333333333, 88.33333333333334, 1.0, 2.0, 0.3576015709757516, 1.0, 2.0, 0.3576015709757516, 1.0, 2.0, 0.5693133472634948, 6.9112, 6.9112, 121.94756008, 1223032.798280388, 1223032.798280388, 279007.7735568641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [26.56666666666667, 87.66666666666667, 1.0, 2.0, 0.4981027679748853, 1.0, 2.0, 0.4981027679748853, 1.0, 2.0, 0.7929958286906484, 6.9112, 6.9112, 121.94756008, 1704075.950286792, 1704075.950286792, 342658.8251128503], 
processed observation next is [1.0, 0.34782608695652173, 0.5395061728395063, 0.8766666666666667, 1.0, 1.0, 0.4025032952081967, 1.0, 1.0, 0.4025032952081967, 1.0, 1.0, 0.7412447858633106, 0.0, 0.0, 0.8096049824067558, 0.6085985536738543, 0.6085985536738543, 0.6589592790631736], 
reward next is 0.3410, 
noisyNet noise sample is [array([1.21072], dtype=float32), 0.23752649]. 
=============================================
[2019-03-24 04:17:00,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.590755]
 [63.58094 ]
 [63.327877]
 [62.608562]
 [62.701977]], R is [[63.67776108]
 [63.50443268]
 [63.3760376 ]
 [63.26733017]
 [63.15642548]].
[2019-03-24 04:17:00,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4183487e-13 1.0872464e-04 3.8625302e-08 8.1494618e-03 9.9174178e-01], sum to 1.0000
[2019-03-24 04:17:00,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5757
[2019-03-24 04:17:00,097] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.7, 87.0, 1.0, 2.0, 0.5345127764304978, 1.0, 2.0, 0.5345127764304978, 1.0, 2.0, 0.8509617479431745, 6.911199999999999, 6.9112, 121.94756008, 1828766.927995542, 1828766.927995542, 360851.1090996724], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6510600.0000, 
sim time next is 6511200.0000, 
raw observation next is [26.83333333333334, 86.33333333333334, 1.0, 2.0, 0.5524506952786351, 1.0, 2.0, 0.5524506952786351, 1.0, 2.0, 0.8795194989466409, 6.911199999999999, 6.9112, 121.94756008, 1890204.146683592, 1890204.146683593, 370077.627421917], 
processed observation next is [1.0, 0.34782608695652173, 0.5493827160493829, 0.8633333333333334, 1.0, 1.0, 0.4672032086650418, 1.0, 1.0, 0.4672032086650418, 1.0, 1.0, 0.8493993736833011, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6750729095298542, 0.6750729095298547, 0.711687745042148], 
reward next is 0.2883, 
noisyNet noise sample is [array([0.46244037], dtype=float32), 2.1087348]. 
=============================================
[2019-03-24 04:17:02,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9908546e-13 5.2164856e-02 1.8496275e-08 2.0706266e-05 9.4781446e-01], sum to 1.0000
[2019-03-24 04:17:02,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6157
[2019-03-24 04:17:02,183] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333333, 79.33333333333334, 1.0, 2.0, 0.5097452063809267, 1.0, 2.0, 0.5097452063809267, 1.0, 1.0, 0.8115309698008142, 6.9112, 6.9112, 121.94756008, 1743945.156023633, 1743945.156023633, 348397.8606785219], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6536400.0000, 
sim time next is 6537000.0000, 
raw observation next is [27.56666666666667, 79.16666666666667, 1.0, 2.0, 0.5179582225092956, 1.0, 2.0, 0.5179582225092956, 1.0, 2.0, 0.8246063589564389, 6.911200000000001, 6.9112, 121.94756008, 1772071.471036771, 1772071.471036771, 352490.5881157854], 
processed observation next is [1.0, 0.6521739130434783, 0.5765432098765433, 0.7916666666666667, 1.0, 1.0, 0.4261407410824947, 1.0, 1.0, 0.4261407410824947, 1.0, 1.0, 0.7807579486955485, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6328826682274182, 0.6328826682274182, 0.6778665156072796], 
reward next is 0.3221, 
noisyNet noise sample is [array([-0.10016312], dtype=float32), 0.38767427]. 
=============================================
[2019-03-24 04:17:02,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[43.913982]
 [43.872017]
 [43.843174]
 [43.924328]
 [43.717304]], R is [[43.79582596]
 [43.35786819]
 [43.32218552]
 [43.24686432]
 [43.18045044]].
[2019-03-24 04:17:05,444] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2296801: loss -19.9395
[2019-03-24 04:17:05,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2296801: learning rate 0.0001
[2019-03-24 04:17:05,491] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2296822: loss 0.5694
[2019-03-24 04:17:05,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2296822: learning rate 0.0001
[2019-03-24 04:17:05,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296889: loss 10.7995
[2019-03-24 04:17:05,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296890: learning rate 0.0001
[2019-03-24 04:17:05,636] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296893: loss -9.2435
[2019-03-24 04:17:05,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296893: learning rate 0.0001
[2019-03-24 04:17:05,712] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296925: loss 8.9852
[2019-03-24 04:17:05,713] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296926: learning rate 0.0001
[2019-03-24 04:17:05,831] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2296988: loss 0.9595
[2019-03-24 04:17:05,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2296989: learning rate 0.0001
[2019-03-24 04:17:06,036] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2297085: loss -15.4850
[2019-03-24 04:17:06,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2297085: learning rate 0.0001
[2019-03-24 04:17:06,218] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2297173: loss 38.9350
[2019-03-24 04:17:06,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2297173: learning rate 0.0001
[2019-03-24 04:17:06,526] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2297326: loss -0.8434
[2019-03-24 04:17:06,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2297326: learning rate 0.0001
[2019-03-24 04:17:06,845] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2297487: loss 0.9615
[2019-03-24 04:17:06,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2297487: learning rate 0.0001
[2019-03-24 04:17:07,055] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297588: loss -0.9076
[2019-03-24 04:17:07,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297588: learning rate 0.0001
[2019-03-24 04:17:07,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297621: loss -30.8281
[2019-03-24 04:17:07,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297624: learning rate 0.0001
[2019-03-24 04:17:07,223] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2297669: loss -43.8165
[2019-03-24 04:17:07,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2297670: learning rate 0.0001
[2019-03-24 04:17:07,982] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2298042: loss -5.5502
[2019-03-24 04:17:07,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2298044: learning rate 0.0001
[2019-03-24 04:17:08,041] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2298067: loss 0.3106
[2019-03-24 04:17:08,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2298067: learning rate 0.0001
[2019-03-24 04:17:11,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2164884e-23 1.0000000e+00 2.1742197e-20 1.3078457e-11 1.0663922e-08], sum to 1.0000
[2019-03-24 04:17:11,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-24 04:17:11,507] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 54.66666666666667, 1.0, 2.0, 0.4828680465283668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580873.9321538435, 580873.9321538435, 140404.9077172731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6889800.0000, 
sim time next is 6890400.0000, 
raw observation next is [27.9, 55.0, 1.0, 2.0, 0.4809355447515657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 578971.3012254849, 578971.3012254846, 140121.0225739165], 
processed observation next is [0.0, 0.782608695652174, 0.5888888888888888, 0.55, 1.0, 1.0, 0.3820661247042449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20677546472338748, 0.20677546472338734, 0.26946350494983945], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.14150706], dtype=float32), -2.910612]. 
=============================================
[2019-03-24 04:17:11,931] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 04:17:11,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:17:11,935] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:17:11,935] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:17:11,935] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:17:11,938] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:17:11,939] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:17:11,940] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:17:11,941] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:17:11,941] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:17:11,941] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:17:11,966] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-24 04:17:11,990] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-24 04:17:12,019] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-24 04:17:12,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-24 04:17:12,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-24 04:17:50,177] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0950366]
[2019-03-24 04:17:50,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.7171569, 89.0363421, 1.0, 2.0, 0.6462077012691161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1451406.618680252, 1451406.618680252, 307720.3813660158]
[2019-03-24 04:17:50,180] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:17:50,185] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0485225e-18 9.9999738e-01 1.3155015e-13 4.3402761e-07 2.2044201e-06], sampled 0.9594684833957634
[2019-03-24 04:17:50,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1451406.618680252 W.
[2019-03-24 04:18:16,875] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.0950366]
[2019-03-24 04:18:16,876] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 80.0, 1.0, 2.0, 0.6052667812655813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690085.9574600197, 690085.9574600197, 159000.5330337183]
[2019-03-24 04:18:16,877] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:18:16,883] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1993523e-20 9.9999857e-01 2.0838023e-15 1.5587824e-08 1.4315725e-06], sampled 0.913434376149612
[2019-03-24 04:18:53,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:18:54,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:18:54,241] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:18:54,311] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:18:54,349] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:18:55,364] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2300000, evaluation results [2300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:18:56,062] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2300363: loss 3.1242
[2019-03-24 04:18:56,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2300364: learning rate 0.0001
[2019-03-24 04:18:57,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8318962e-21 9.9992931e-01 5.2443791e-13 7.0685426e-05 1.9767825e-08], sum to 1.0000
[2019-03-24 04:18:57,264] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4885
[2019-03-24 04:18:57,273] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 76.66666666666666, 1.0, 2.0, 0.3284262198456777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 416940.4669942584, 416940.4669942579, 119148.6061000303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6741600.0000, 
sim time next is 6742200.0000, 
raw observation next is [20.08333333333334, 76.83333333333334, 1.0, 2.0, 0.3246628507504152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412427.0253203516, 412427.0253203516, 118667.8220082094], 
processed observation next is [1.0, 0.0, 0.29938271604938294, 0.7683333333333334, 1.0, 1.0, 0.19602720327430379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14729536618583985, 0.14729536618583985, 0.22820735001578732], 
reward next is 0.7718, 
noisyNet noise sample is [array([-1.071403], dtype=float32), -1.2236477]. 
=============================================
[2019-03-24 04:19:04,467] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2304732: loss 0.9580
[2019-03-24 04:19:04,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2304736: learning rate 0.0001
[2019-03-24 04:19:04,518] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304753: loss 0.6085
[2019-03-24 04:19:04,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304753: learning rate 0.0001
[2019-03-24 04:19:04,674] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304834: loss 0.1992
[2019-03-24 04:19:04,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304835: learning rate 0.0001
[2019-03-24 04:19:04,759] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2304884: loss 0.3301
[2019-03-24 04:19:04,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2304885: learning rate 0.0001
[2019-03-24 04:19:04,964] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304987: loss 0.5537
[2019-03-24 04:19:04,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304988: learning rate 0.0001
[2019-03-24 04:19:04,990] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304998: loss 0.4795
[2019-03-24 04:19:04,993] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304999: learning rate 0.0001
[2019-03-24 04:19:05,238] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2305129: loss 0.0908
[2019-03-24 04:19:05,242] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2305129: learning rate 0.0001
[2019-03-24 04:19:05,416] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2305217: loss 0.0246
[2019-03-24 04:19:05,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2305223: learning rate 0.0001
[2019-03-24 04:19:05,677] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2305349: loss 0.0542
[2019-03-24 04:19:05,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2305349: learning rate 0.0001
[2019-03-24 04:19:05,908] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2305470: loss 0.0605
[2019-03-24 04:19:05,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2305472: learning rate 0.0001
[2019-03-24 04:19:05,974] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2305501: loss 0.0534
[2019-03-24 04:19:05,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2305501: learning rate 0.0001
[2019-03-24 04:19:06,087] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305558: loss 0.0521
[2019-03-24 04:19:06,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305558: learning rate 0.0001
[2019-03-24 04:19:06,404] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2305723: loss 0.0271
[2019-03-24 04:19:06,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2305724: learning rate 0.0001
[2019-03-24 04:19:07,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2306113: loss 0.0452
[2019-03-24 04:19:07,146] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2306113: learning rate 0.0001
[2019-03-24 04:19:07,170] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2306122: loss 0.0031
[2019-03-24 04:19:07,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2306122: learning rate 0.0001
[2019-03-24 04:19:11,545] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2308390: loss 0.4800
[2019-03-24 04:19:11,548] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2308390: learning rate 0.0001
[2019-03-24 04:19:13,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3868946e-27 1.0000000e+00 8.0653354e-20 3.4513262e-14 1.8342423e-09], sum to 1.0000
[2019-03-24 04:19:13,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7560
[2019-03-24 04:19:13,608] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 82.0, 1.0, 2.0, 0.4880548297176215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586260.8401901739, 586260.8401901739, 141179.3599002453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7078800.0000, 
sim time next is 7079400.0000, 
raw observation next is [23.55, 82.0, 1.0, 2.0, 0.488089745275712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586136.9490772858, 586136.9490772858, 141179.0365940426], 
processed observation next is [1.0, 0.9565217391304348, 0.4277777777777778, 0.82, 1.0, 1.0, 0.39058303009013334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2093346246704592, 0.2093346246704592, 0.2714981472962358], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.8981938], dtype=float32), 1.0498779]. 
=============================================
[2019-03-24 04:19:19,917] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312630: loss 1.1137
[2019-03-24 04:19:19,919] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312630: learning rate 0.0001
[2019-03-24 04:19:20,211] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2312779: loss 1.4028
[2019-03-24 04:19:20,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2312779: learning rate 0.0001
[2019-03-24 04:19:20,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312838: loss 0.6704
[2019-03-24 04:19:20,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312838: learning rate 0.0001
[2019-03-24 04:19:20,365] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2312856: loss 0.2604
[2019-03-24 04:19:20,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2312858: learning rate 0.0001
[2019-03-24 04:19:20,454] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312899: loss 0.1238
[2019-03-24 04:19:20,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312899: learning rate 0.0001
[2019-03-24 04:19:20,728] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2313032: loss 0.0114
[2019-03-24 04:19:20,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2313033: learning rate 0.0001
[2019-03-24 04:19:21,063] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2313194: loss 0.0121
[2019-03-24 04:19:21,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2313195: learning rate 0.0001
[2019-03-24 04:19:21,085] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2313206: loss 0.0046
[2019-03-24 04:19:21,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2313206: learning rate 0.0001
[2019-03-24 04:19:21,488] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313407: loss 0.0242
[2019-03-24 04:19:21,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313407: learning rate 0.0001
[2019-03-24 04:19:21,539] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2313432: loss 0.0031
[2019-03-24 04:19:21,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2313432: learning rate 0.0001
[2019-03-24 04:19:21,719] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313517: loss 0.0093
[2019-03-24 04:19:21,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313517: learning rate 0.0001
[2019-03-24 04:19:21,848] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313578: loss 0.0231
[2019-03-24 04:19:21,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313578: learning rate 0.0001
[2019-03-24 04:19:22,272] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2313789: loss 0.0058
[2019-03-24 04:19:22,276] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2313790: learning rate 0.0001
[2019-03-24 04:19:22,960] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2314122: loss 0.0225
[2019-03-24 04:19:22,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2314122: learning rate 0.0001
[2019-03-24 04:19:23,047] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2314167: loss 0.7859
[2019-03-24 04:19:23,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2314167: learning rate 0.0001
[2019-03-24 04:19:25,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.07292498e-23 1.00000000e+00 1.03464366e-16 2.58657375e-12
 5.61320920e-11], sum to 1.0000
[2019-03-24 04:19:25,710] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0723
[2019-03-24 04:19:25,714] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 77.0, 1.0, 2.0, 0.7241256019119819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883705.0942532007, 883705.0942532007, 183240.983387063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297200.0000, 
sim time next is 7297800.0000, 
raw observation next is [23.4, 76.16666666666667, 1.0, 2.0, 0.7713333635002403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940537.447827064, 940537.447827064, 192751.9676062395], 
processed observation next is [1.0, 0.4782608695652174, 0.42222222222222217, 0.7616666666666667, 1.0, 1.0, 0.7277778136907622, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3359062313668086, 0.3359062313668086, 0.3706768607812298], 
reward next is 0.6293, 
noisyNet noise sample is [array([0.2547783], dtype=float32), 1.0567995]. 
=============================================
[2019-03-24 04:19:27,328] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2316267: loss 0.0016
[2019-03-24 04:19:27,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2316267: learning rate 0.0001
[2019-03-24 04:19:27,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.51413644e-21 1.00000000e+00 1.04327915e-17 1.52479700e-12
 2.91152134e-08], sum to 1.0000
[2019-03-24 04:19:27,696] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5461
[2019-03-24 04:19:27,702] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 72.83333333333333, 1.0, 2.0, 0.868022465709464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053397.361253308, 1053397.361253308, 213336.4285134923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7300200.0000, 
sim time next is 7300800.0000, 
raw observation next is [24.4, 72.0, 1.0, 2.0, 0.8995668985157994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260096732844, 1090489.992009619, 1090489.992009619, 220415.0882639873], 
processed observation next is [1.0, 0.5217391304347826, 0.4592592592592592, 0.72, 1.0, 1.0, 0.8804367839473802, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094619101170076, 0.3894607114320068, 0.3894607114320068, 0.42387516973843714], 
reward next is 0.5761, 
noisyNet noise sample is [array([-1.2807639], dtype=float32), -2.4327645]. 
=============================================
[2019-03-24 04:19:31,121] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7727556e-25 1.0000000e+00 3.4382949e-19 4.9215016e-13 3.0836284e-10], sum to 1.0000
[2019-03-24 04:19:31,127] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0342
[2019-03-24 04:19:31,133] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.46666666666667, 96.0, 1.0, 2.0, 0.3998339668052119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 497543.354459396, 497543.3544593956, 128641.4528955546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7362600.0000, 
sim time next is 7363200.0000, 
raw observation next is [19.43333333333334, 96.0, 1.0, 2.0, 0.3801747026952166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473289.9328516799, 473289.9328516804, 125908.7704752989], 
processed observation next is [1.0, 0.21739130434782608, 0.2753086419753089, 0.96, 1.0, 1.0, 0.2621127413038293, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16903211887559996, 0.16903211887560013, 0.24213225091403634], 
reward next is 0.7579, 
noisyNet noise sample is [array([0.903458], dtype=float32), -1.9716398]. 
=============================================
[2019-03-24 04:19:31,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:19:31,603] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:31,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 04:19:35,892] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320546: loss 0.0399
[2019-03-24 04:19:35,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320547: learning rate 0.0001
[2019-03-24 04:19:36,189] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2320687: loss 0.0137
[2019-03-24 04:19:36,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2320687: learning rate 0.0001
[2019-03-24 04:19:36,295] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320736: loss 0.0047
[2019-03-24 04:19:36,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320737: learning rate 0.0001
[2019-03-24 04:19:36,476] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2320827: loss 0.0508
[2019-03-24 04:19:36,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2320827: learning rate 0.0001
[2019-03-24 04:19:36,504] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320841: loss 0.0510
[2019-03-24 04:19:36,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320842: learning rate 0.0001
[2019-03-24 04:19:36,542] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2320866: loss 0.0497
[2019-03-24 04:19:36,545] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2320868: learning rate 0.0001
[2019-03-24 04:19:37,017] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2321095: loss 0.0107
[2019-03-24 04:19:37,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2321095: learning rate 0.0001
[2019-03-24 04:19:37,077] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321126: loss 0.0333
[2019-03-24 04:19:37,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321127: learning rate 0.0001
[2019-03-24 04:19:37,541] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2321355: loss 0.1011
[2019-03-24 04:19:37,544] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2321357: learning rate 0.0001
[2019-03-24 04:19:37,557] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2321363: loss 0.1159
[2019-03-24 04:19:37,560] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2321364: learning rate 0.0001
[2019-03-24 04:19:37,706] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321435: loss 0.1396
[2019-03-24 04:19:37,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321435: learning rate 0.0001
[2019-03-24 04:19:37,908] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321539: loss 0.0124
[2019-03-24 04:19:37,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321539: learning rate 0.0001
[2019-03-24 04:19:38,077] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2321621: loss 0.0203
[2019-03-24 04:19:38,080] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2321622: learning rate 0.0001
[2019-03-24 04:19:38,904] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322028: loss 0.0089
[2019-03-24 04:19:38,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322028: learning rate 0.0001
[2019-03-24 04:19:41,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.692801e-28 1.000000e+00 5.004321e-23 2.538718e-16 3.135284e-14], sum to 1.0000
[2019-03-24 04:19:41,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1560
[2019-03-24 04:19:41,340] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 87.5, 1.0, 2.0, 0.4886856536334924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585999.4374593544, 585999.4374593544, 141241.6238457599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7601400.0000, 
sim time next is 7602000.0000, 
raw observation next is [22.73333333333333, 87.33333333333334, 1.0, 2.0, 0.4833168640661272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580955.5179806432, 580955.5179806427, 140458.4487482972], 
processed observation next is [0.0, 1.0, 0.39753086419753075, 0.8733333333333334, 1.0, 1.0, 0.3849010286501515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20748411356451543, 0.20748411356451527, 0.2701124014390331], 
reward next is 0.7299, 
noisyNet noise sample is [array([0.25122607], dtype=float32), -2.6694522]. 
=============================================
[2019-03-24 04:19:41,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.5397  ]
 [79.48864 ]
 [79.43868 ]
 [79.39426 ]
 [79.292366]], R is [[79.52617645]
 [79.45929718]
 [79.39152527]
 [79.32275391]
 [79.25332642]].
[2019-03-24 04:19:43,641] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2324365: loss 0.1438
[2019-03-24 04:19:43,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2324366: learning rate 0.0001
[2019-03-24 04:19:44,945] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 04:19:44,946] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:19:44,948] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:44,947] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:19:44,949] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:19:44,950] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:44,951] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:44,954] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:19:44,957] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:44,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:19:44,960] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:44,989] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 04:19:45,016] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 04:19:45,044] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 04:19:45,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 04:19:45,069] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 04:19:50,010] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:19:50,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.40156485, 30.5001757, 1.0, 2.0, 0.3286332586236575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419715.7861557849, 419715.7861557849, 119187.5861666395]
[2019-03-24 04:19:50,013] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:19:50,017] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1631489e-22 1.0000000e+00 2.5887811e-15 1.0419644e-10 1.6774776e-09], sampled 0.38331602318894364
[2019-03-24 04:20:00,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:20:00,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.7, 51.33333333333333, 1.0, 2.0, 0.2405638261832157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 310304.176021231, 310304.176021231, 100860.2805512545]
[2019-03-24 04:20:00,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:20:00,412] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.2889061e-22 1.0000000e+00 9.4611717e-15 2.5121991e-10 3.5372674e-09], sampled 0.5492728400903444
[2019-03-24 04:20:42,491] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:20:42,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.11905186666667, 97.44952596333334, 1.0, 2.0, 0.7073415991735401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156592, 840812.3094213776, 840812.3094213776, 179140.6308217106]
[2019-03-24 04:20:42,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:20:42,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.6052412e-22 1.0000000e+00 8.2819824e-15 2.3107337e-10 3.2546645e-09], sampled 0.6006088849847443
[2019-03-24 04:20:45,425] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:20:45,427] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.9025850648024475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1075973.542462795, 1075973.542462795, 220383.4531101884]
[2019-03-24 04:20:45,428] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:20:45,431] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0520144e-19 1.0000000e+00 7.8975471e-13 5.3426885e-09 4.4360949e-08], sampled 0.5784593241068385
[2019-03-24 04:20:52,233] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:20:52,234] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.33333333333333, 98.0, 1.0, 2.0, 0.427640681558345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 523602.9796786039, 523602.9796786035, 132424.1291452353]
[2019-03-24 04:20:52,234] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:20:52,237] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.0123231e-23 1.0000000e+00 2.1825017e-15 9.3094824e-11 1.5209274e-09], sampled 0.5313156830587759
[2019-03-24 04:21:13,202] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1099235]
[2019-03-24 04:21:13,205] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.6, 88.0, 1.0, 2.0, 0.434822665971102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531666.1974201335, 531666.1974201335, 133452.7044467096]
[2019-03-24 04:21:13,205] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:21:13,207] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4673322e-22 1.0000000e+00 4.3990309e-15 1.5113404e-10 2.2468163e-09], sampled 0.906097166900288
[2019-03-24 04:21:27,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:21:27,362] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:21:27,479] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:21:27,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:21:27,548] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:21:28,565] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2325000, evaluation results [2325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:21:31,464] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0791168e-12 8.7559491e-01 5.6390385e-05 1.2389653e-01 4.5215036e-04], sum to 1.0000
[2019-03-24 04:21:31,472] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1516
[2019-03-24 04:21:31,483] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 72.5, 1.0, 2.0, 0.7871738515299701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 965850.895104605, 965850.895104605, 196226.0771405207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725000.0000, 
sim time next is 7725600.0000, 
raw observation next is [23.9, 71.0, 1.0, 2.0, 0.8053739235765902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 986216.6657253351, 986216.6657253351, 200004.1040123279], 
processed observation next is [1.0, 0.43478260869565216, 0.4407407407407407, 0.71, 1.0, 1.0, 0.7683022899721312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35222023775904826, 0.35222023775904826, 0.38462327694678444], 
reward next is 0.6154, 
noisyNet noise sample is [array([0.31083158], dtype=float32), -2.2381592]. 
=============================================
[2019-03-24 04:21:34,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5473648e-17 9.9990880e-01 5.8931908e-09 6.9145099e-05 2.2026710e-05], sum to 1.0000
[2019-03-24 04:21:34,394] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0585
[2019-03-24 04:21:34,401] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 61.83333333333334, 1.0, 2.0, 0.4285376007989104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524728.4590188278, 524728.4590188278, 132555.2912960467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7758600.0000, 
sim time next is 7759200.0000, 
raw observation next is [25.13333333333334, 62.66666666666667, 1.0, 2.0, 0.4234745542457529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519500.0332944028, 519500.0332944028, 131846.7886880423], 
processed observation next is [1.0, 0.8260869565217391, 0.48641975308642, 0.6266666666666667, 1.0, 1.0, 0.31366018362589637, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18553572617657244, 0.18553572617657244, 0.25355151670777365], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.01850985], dtype=float32), 0.070580415]. 
=============================================
[2019-03-24 04:21:35,381] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328542: loss 9.0775
[2019-03-24 04:21:35,384] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328543: learning rate 0.0001
[2019-03-24 04:21:35,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:35,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:35,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2328569: loss 2.6942
[2019-03-24 04:21:35,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2328570: learning rate 0.0001
[2019-03-24 04:21:35,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 04:21:35,615] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328638: loss 0.0648
[2019-03-24 04:21:35,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328639: learning rate 0.0001
[2019-03-24 04:21:35,861] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328771: loss 1.4650
[2019-03-24 04:21:35,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328771: learning rate 0.0001
[2019-03-24 04:21:35,894] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2328783: loss -0.2071
[2019-03-24 04:21:35,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2328784: learning rate 0.0001
[2019-03-24 04:21:36,033] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328862: loss -2.9160
[2019-03-24 04:21:36,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328862: learning rate 0.0001
[2019-03-24 04:21:36,290] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2329000: loss 0.1818
[2019-03-24 04:21:36,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2329000: learning rate 0.0001
[2019-03-24 04:21:36,364] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2329030: loss 0.0844
[2019-03-24 04:21:36,365] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2329030: learning rate 0.0001
[2019-03-24 04:21:36,639] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329190: loss 0.1156
[2019-03-24 04:21:36,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329190: learning rate 0.0001
[2019-03-24 04:21:36,725] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2329242: loss -2.4724
[2019-03-24 04:21:36,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2329242: learning rate 0.0001
[2019-03-24 04:21:36,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2329296: loss 0.1015
[2019-03-24 04:21:36,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2329297: learning rate 0.0001
[2019-03-24 04:21:37,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2329501: loss 0.0870
[2019-03-24 04:21:37,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2329502: learning rate 0.0001
[2019-03-24 04:21:37,394] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2329604: loss 0.0276
[2019-03-24 04:21:37,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2329605: learning rate 0.0001
[2019-03-24 04:21:38,067] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2329955: loss 3.3875
[2019-03-24 04:21:38,069] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2329955: learning rate 0.0001
[2019-03-24 04:21:38,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6112872e-19 9.9999988e-01 5.4777429e-11 1.1071146e-07 2.3020782e-08], sum to 1.0000
[2019-03-24 04:21:38,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-24 04:21:38,500] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 81.5, 1.0, 2.0, 0.4622265990830175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569771.0289623564, 569771.0289623569, 137659.948129333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7871400.0000, 
sim time next is 7872000.0000, 
raw observation next is [21.76666666666667, 82.0, 1.0, 2.0, 0.4352782107784142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537133.1372789744, 537133.1372789744, 133648.4304211277], 
processed observation next is [1.0, 0.08695652173913043, 0.3617283950617285, 0.82, 1.0, 1.0, 0.32771215568858836, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19183326331391942, 0.19183326331391942, 0.2570162123483225], 
reward next is 0.7430, 
noisyNet noise sample is [array([-0.62470186], dtype=float32), 1.4960145]. 
=============================================
[2019-03-24 04:21:38,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.90587 ]
 [65.812706]
 [65.99793 ]
 [67.3412  ]
 [67.559784]], R is [[66.10294342]
 [66.17718506]
 [66.23330688]
 [66.24406433]
 [66.32975769]].
[2019-03-24 04:21:39,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3073038e-18 9.9997973e-01 1.5076160e-10 1.7776982e-05 2.4541885e-06], sum to 1.0000
[2019-03-24 04:21:39,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-24 04:21:39,659] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 66.0, 1.0, 2.0, 0.4300614185187756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 527106.5209327815, 527106.5209327815, 132791.4337810584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7853400.0000, 
sim time next is 7854000.0000, 
raw observation next is [24.56666666666667, 66.33333333333333, 1.0, 2.0, 0.4285047899572014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525404.3844410321, 525404.3844410321, 132570.1177782814], 
processed observation next is [1.0, 0.9130434782608695, 0.46543209876543223, 0.6633333333333333, 1.0, 1.0, 0.3196485594728588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1876444230146543, 0.1876444230146543, 0.2549425341890027], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.31595832], dtype=float32), 0.91864645]. 
=============================================
[2019-03-24 04:21:39,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.671688]
 [62.81138 ]
 [62.966705]
 [63.141396]
 [63.355198]], R is [[62.58663177]
 [62.70539856]
 [62.82228851]
 [62.93717194]
 [63.05049133]].
[2019-03-24 04:21:43,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 04:21:43,443] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,446] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 04:21:43,506] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 04:21:43,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 04:21:43,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 04:21:43,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:43,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 04:21:43,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:43,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 04:21:44,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 04:21:44,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 04:21:44,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 04:21:44,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 04:21:44,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 04:21:44,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 04:21:44,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:21:44,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:44,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 04:21:56,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3997411e-24 1.0000000e+00 7.2916064e-17 6.3055960e-09 1.2658817e-12], sum to 1.0000
[2019-03-24 04:21:56,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4783
[2019-03-24 04:21:56,328] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 60.0, 1.0, 2.0, 0.252349274306469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 325509.4954776079, 325509.4954776079, 109296.1690660474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 194400.0000, 
sim time next is 195000.0000, 
raw observation next is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.279734927], 
processed observation next is [0.0, 0.2608695652173913, 0.33271604938271593, 0.6066666666666666, 1.0, 1.0, 0.11320710577291582, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11735791027761876, 0.11735791027761876, 0.21191976872101345], 
reward next is 0.7881, 
noisyNet noise sample is [array([-0.03393283], dtype=float32), 0.09037475]. 
=============================================
[2019-03-24 04:21:56,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.89424]
 [71.93925]
 [71.98602]
 [72.05366]
 [72.14215]], R is [[71.88832092]
 [71.95925903]
 [72.03908539]
 [72.12568665]
 [72.21753693]].
[2019-03-24 04:22:05,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4722461e-16 2.3765968e-02 6.2788985e-08 9.7623378e-01 8.0930171e-08], sum to 1.0000
[2019-03-24 04:22:05,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3726
[2019-03-24 04:22:05,241] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.96666666666667, 62.16666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 335111.3726342435, 335111.3726342439, 128335.9998197068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [18.8, 63.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 328934.1278841695, 328934.12788417, 126797.9817824821], 
processed observation next is [1.0, 0.17391304347826086, 0.2518518518518519, 0.63, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11747647424434626, 0.11747647424434642, 0.2438422726586194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05255246], dtype=float32), -0.059533324]. 
=============================================
[2019-03-24 04:22:05,255] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.725727]
 [59.43349 ]
 [59.39552 ]
 [59.89592 ]
 [60.029583]], R is [[59.192379  ]
 [58.60045624]
 [58.01445389]
 [57.43431091]
 [57.66770554]].
[2019-03-24 04:22:10,629] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0494126e-16 6.8170494e-01 5.0651886e-07 3.1799877e-01 2.9568508e-04], sum to 1.0000
[2019-03-24 04:22:10,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6269
[2019-03-24 04:22:10,648] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 33.66666666666667, 1.0, 2.0, 0.4832324012023797, 1.0, 1.0, 0.4832324012023797, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425203191, 1179318.074819262, 1179318.074819262, 233353.9374764173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 476400.0000, 
sim time next is 477000.0000, 
raw observation next is [30.5, 33.0, 1.0, 2.0, 0.8921373230115057, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.954046023381665, 6.9112, 121.9257416904023, 1126632.685052473, 1104691.745699438, 219455.8390104211], 
processed observation next is [1.0, 0.5217391304347826, 0.6851851851851852, 0.33, 1.0, 1.0, 0.8715920512041735, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.004284602338166544, 0.0, 0.8094601309893531, 0.40236881609016895, 0.39453276632122786, 0.4220304596354252], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3355675], dtype=float32), 1.5934318]. 
=============================================
[2019-03-24 04:22:10,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.732048]
 [62.214565]
 [62.218895]
 [62.356163]
 [62.673405]], R is [[62.22744751]
 [61.60517502]
 [61.42715836]
 [60.8128891 ]
 [60.64826202]].
[2019-03-24 04:22:11,732] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4745906e-19 1.0000000e+00 2.7017594e-13 1.1204658e-08 1.0198873e-10], sum to 1.0000
[2019-03-24 04:22:11,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-24 04:22:11,744] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 36.0, 1.0, 2.0, 0.3445331327707435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432678.9477112515, 432678.9477112515, 121188.7617148745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 502800.0000, 
sim time next is 503400.0000, 
raw observation next is [28.63333333333333, 37.0, 1.0, 2.0, 0.3425224900286017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430013.8258013516, 430013.8258013516, 120922.9308615607], 
processed observation next is [1.0, 0.8260869565217391, 0.6160493827160493, 0.37, 1.0, 1.0, 0.2172886786054782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15357636635762556, 0.15357636635762556, 0.23254409781069366], 
reward next is 0.7675, 
noisyNet noise sample is [array([-1.5890144], dtype=float32), 0.17917787]. 
=============================================
[2019-03-24 04:22:14,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5375405e-15 1.3143817e-02 3.7500922e-07 9.8685491e-01 9.5127353e-07], sum to 1.0000
[2019-03-24 04:22:14,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4983
[2019-03-24 04:22:14,712] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 39.33333333333333, 1.0, 2.0, 0.5751525329971515, 1.0, 1.0, 0.5751525329971515, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257400476376, 1392074.111081388, 1392074.111081388, 262998.6535426623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 550200.0000, 
sim time next is 550800.0000, 
raw observation next is [30.6, 35.0, 1.0, 2.0, 0.58269184282305, 1.0, 2.0, 0.58269184282305, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425233998, 1409291.566920798, 1409291.566920798, 265552.9759534433], 
processed observation next is [1.0, 0.391304347826087, 0.688888888888889, 0.35, 1.0, 1.0, 0.5032045747893452, 1.0, 1.0, 0.5032045747893452, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621282076122, 0.5033184167574278, 0.5033184167574278, 0.5106787999104679], 
reward next is 0.4893, 
noisyNet noise sample is [array([1.6931317], dtype=float32), -0.7576825]. 
=============================================
[2019-03-24 04:22:15,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7567847e-15 2.1959953e-03 2.1165587e-07 9.9780053e-01 3.2317541e-06], sum to 1.0000
[2019-03-24 04:22:15,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2953
[2019-03-24 04:22:15,775] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 34.66666666666667, 1.0, 2.0, 0.5482098697776936, 1.0, 2.0, 0.5482098697776936, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1325509.599167394, 1325509.599167394, 253866.5102908076], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 569400.0000, 
sim time next is 570000.0000, 
raw observation next is [30.8, 34.33333333333334, 1.0, 2.0, 0.58176471556247, 1.0, 2.0, 0.58176471556247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1406779.402715213, 1406779.402715213, 265224.5251340658], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.34333333333333343, 1.0, 1.0, 0.5021008518600834, 1.0, 1.0, 0.5021008518600834, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5024212152554332, 0.5024212152554332, 0.5100471637193573], 
reward next is 0.4900, 
noisyNet noise sample is [array([-1.2311772], dtype=float32), 0.806018]. 
=============================================
[2019-03-24 04:22:15,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[49.38474 ]
 [49.041576]
 [48.833363]
 [48.77131 ]
 [48.75223 ]], R is [[49.34899521]
 [49.36730194]
 [49.35144424]
 [49.32036972]
 [49.28939819]].
[2019-03-24 04:22:19,591] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 04:22:19,592] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:22:19,593] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:22:19,593] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:22:19,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:22:19,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:22:19,596] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:22:19,597] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:22:19,597] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:22:19,598] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:22:19,595] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:22:19,627] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 04:22:19,627] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 04:22:19,628] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 04:22:19,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 04:22:19,727] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 04:22:35,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1236444]
[2019-03-24 04:22:35,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.33333333333333, 88.83333333333333, 1.0, 2.0, 0.2753997653428659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 354247.3651671052, 354247.3651671047, 112584.9369521146]
[2019-03-24 04:22:35,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:22:35,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0046855e-24 1.0000000e+00 1.8456694e-16 2.8873734e-10 1.6984315e-11], sampled 0.03254176273429177
[2019-03-24 04:23:20,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1236444]
[2019-03-24 04:23:20,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.66666666666667, 86.5, 1.0, 2.0, 0.43328055613555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530481.5574984042, 530481.5574984046, 133246.0919662903]
[2019-03-24 04:23:20,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:23:20,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.048464e-23 1.000000e+00 1.847840e-15 1.192406e-09 7.335402e-11], sampled 0.6924073952556378
[2019-03-24 04:23:35,713] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1236444]
[2019-03-24 04:23:35,714] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.430789895, 85.96868483, 1.0, 2.0, 0.6085125313834021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698688.9738625021, 698688.9738625021, 159804.6329592659]
[2019-03-24 04:23:35,714] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:23:35,719] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0790907e-22 1.0000000e+00 5.7080996e-15 4.0519557e-09 1.4357363e-10], sampled 0.45169446527905466
[2019-03-24 04:23:38,432] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1236444]
[2019-03-24 04:23:38,434] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 37.33333333333334, 1.0, 2.0, 0.7425969259485482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 871002.0582339931, 871002.0582339927, 185563.7048076994]
[2019-03-24 04:23:38,436] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:23:38,438] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.0538307e-22 1.0000000e+00 3.0429394e-14 2.3825230e-08 3.9905571e-10], sampled 0.4304459838309407
[2019-03-24 04:24:01,617] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8804.4996 2162650460.3745 442.0000
[2019-03-24 04:24:01,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8943.1239 2114269247.9818 403.0000
[2019-03-24 04:24:02,034] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8641.0963 2231250401.1743 474.0000
[2019-03-24 04:24:02,186] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8204.8527 2422742558.7312 569.0000
[2019-03-24 04:24:02,236] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8744.4860 2181829124.7703 504.0000
[2019-03-24 04:24:03,250] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2350000, evaluation results [2350000.0, 8204.852694730425, 2422742558.7311563, 569.0, 8804.499641200733, 2162650460.374527, 442.0, 8943.12385279568, 2114269247.9818003, 403.0, 8641.096327006924, 2231250401.174313, 474.0, 8744.485955538765, 2181829124.770301, 504.0]
[2019-03-24 04:24:03,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7498712e-15 9.4752902e-01 2.2097755e-07 5.2453753e-02 1.7065566e-05], sum to 1.0000
[2019-03-24 04:24:03,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-24 04:24:03,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1516502.002323612 W.
[2019-03-24 04:24:03,753] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.65, 38.5, 1.0, 2.0, 0.6683427438547855, 0.0, 1.0, 0.0, 1.0, 1.0, 0.961420290255282, 6.911199999999999, 6.9112, 121.9260426156618, 1516502.002323612, 1516502.002323612, 302908.3292115522], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 642600.0000, 
sim time next is 643200.0000, 
raw observation next is [31.0, 37.66666666666667, 1.0, 2.0, 0.6069770589420467, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9614379447699117, 6.9112, 6.9112, 121.9260426156618, 1442776.486180794, 1442776.486180794, 292225.2275533213], 
processed observation next is [1.0, 0.43478260869565216, 0.7037037037037037, 0.3766666666666667, 1.0, 1.0, 0.5321155463595794, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9517974309623897, 0.0, 0.0, 0.8094621288201359, 0.5152773164931407, 0.5152773164931407, 0.5619715914486948], 
reward next is 0.4380, 
noisyNet noise sample is [array([-1.9480062], dtype=float32), 1.3391637]. 
=============================================
[2019-03-24 04:24:08,198] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6528771e-23 3.2800489e-08 9.6879900e-12 1.0000000e+00 1.9116548e-13], sum to 1.0000
[2019-03-24 04:24:08,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6543
[2019-03-24 04:24:08,214] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 28.33333333333334, 1.0, 2.0, 0.4970947259005415, 1.0, 2.0, 0.4970947259005415, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426089676, 1226876.655332915, 1226876.655332915, 238065.2656452468], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [31.3, 27.0, 1.0, 2.0, 0.519935822447054, 1.0, 2.0, 0.519935822447054, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156598, 1282951.748789474, 1282951.748789474, 245367.3837316438], 
processed observation next is [1.0, 0.5652173913043478, 0.7148148148148148, 0.27, 1.0, 1.0, 0.42849502672268336, 1.0, 1.0, 0.42849502672268336, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201226, 0.4581970531390978, 0.4581970531390978, 0.4718603533300842], 
reward next is 0.5281, 
noisyNet noise sample is [array([-0.10583079], dtype=float32), -0.11457646]. 
=============================================
[2019-03-24 04:24:18,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2002374e-23 1.0000000e+00 3.2097437e-15 7.1104136e-09 3.4818724e-11], sum to 1.0000
[2019-03-24 04:24:18,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6165
[2019-03-24 04:24:18,583] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 51.66666666666666, 1.0, 2.0, 0.370520688703766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463343.5782282517, 463343.5782282521, 124629.0723544001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 934800.0000, 
sim time next is 935400.0000, 
raw observation next is [25.46666666666667, 52.33333333333334, 1.0, 2.0, 0.3692141146161365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461885.0981395594, 461885.0981395594, 124454.7929737234], 
processed observation next is [0.0, 0.8260869565217391, 0.4987654320987655, 0.5233333333333334, 1.0, 1.0, 0.24906442216206728, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16495896362127122, 0.16495896362127122, 0.23933614033408346], 
reward next is 0.7607, 
noisyNet noise sample is [array([1.0276338], dtype=float32), 0.4982861]. 
=============================================
[2019-03-24 04:24:22,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2052815e-23 1.0000000e+00 1.8386792e-14 6.0613004e-10 9.2793535e-13], sum to 1.0000
[2019-03-24 04:24:22,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-24 04:24:22,714] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 65.0, 1.0, 2.0, 0.3054436633195223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389668.3233718913, 389668.3233718913, 116250.322039522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1018800.0000, 
sim time next is 1019400.0000, 
raw observation next is [21.78333333333333, 61.50000000000001, 1.0, 2.0, 0.3031692156227609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387102.0610127111, 387102.0610127111, 115968.5174777741], 
processed observation next is [1.0, 0.8260869565217391, 0.3623456790123456, 0.6150000000000001, 1.0, 1.0, 0.17043954240804868, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13825073607596824, 0.13825073607596824, 0.2230163797649502], 
reward next is 0.7770, 
noisyNet noise sample is [array([0.9654352], dtype=float32), -0.5830496]. 
=============================================
[2019-03-24 04:24:28,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0314920e-23 1.0000000e+00 3.1536317e-17 2.4670072e-11 5.6499466e-14], sum to 1.0000
[2019-03-24 04:24:28,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6792
[2019-03-24 04:24:29,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1452857.08538273 W.
[2019-03-24 04:24:29,011] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.91666666666666, 29.66666666666666, 1.0, 2.0, 0.3973412855011765, 1.0, 1.0, 0.3973412855011765, 1.0, 1.0, 0.6482411258380905, 6.911200000000001, 6.9112, 121.94756008, 1452857.08538273, 1452857.08538273, 294859.1648401367], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1354200.0000, 
sim time next is 1354800.0000, 
raw observation next is [30.93333333333333, 29.33333333333334, 1.0, 2.0, 0.5193240726104593, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8553941811420672, 6.911200000000001, 6.9112, 121.9260425337623, 1279063.478395216, 1279063.478395215, 260220.2101214187], 
processed observation next is [1.0, 0.6956521739130435, 0.7012345679012344, 0.2933333333333334, 1.0, 1.0, 0.42776675310768963, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8192427264275839, 8.881784197001253e-17, 0.0, 0.8094621282764084, 0.4568083851411485, 0.4568083851411482, 0.5004234810027283], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.6929736], dtype=float32), -0.75368077]. 
=============================================
[2019-03-24 04:24:30,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0522226e-24 9.9999833e-01 3.0525028e-14 1.6775077e-06 5.1990677e-12], sum to 1.0000
[2019-03-24 04:24:30,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5175
[2019-03-24 04:24:30,756] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 66.16666666666666, 1.0, 2.0, 0.575601061600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736614.315736784, 736614.315736784, 156409.8775002486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1158600.0000, 
sim time next is 1159200.0000, 
raw observation next is [20.8, 66.0, 1.0, 2.0, 0.5233380732814308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669519.1609489569, 669519.1609489569, 147625.0388340205], 
processed observation next is [1.0, 0.43478260869565216, 0.32592592592592595, 0.66, 1.0, 1.0, 0.43254532533503665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23911398605319886, 0.23911398605319886, 0.2838943054500394], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.16599494], dtype=float32), -0.10805487]. 
=============================================
[2019-03-24 04:24:33,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0034925e-26 1.0000000e+00 7.6054145e-18 2.7684968e-12 1.6453348e-15], sum to 1.0000
[2019-03-24 04:24:33,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9175
[2019-03-24 04:24:33,166] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 91.33333333333334, 1.0, 2.0, 0.3508413887758287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441932.1160951412, 441932.1160951412, 122039.6724717666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1203600.0000, 
sim time next is 1204200.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.3507902226908692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441811.3669400915, 441811.3669400915, 122032.1425691338], 
processed observation next is [1.0, 0.9565217391304348, 0.25925925925925924, 0.92, 1.0, 1.0, 0.22713121748912998, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15778977390717552, 0.15778977390717552, 0.23467719724833422], 
reward next is 0.7653, 
noisyNet noise sample is [array([0.408551], dtype=float32), -0.473218]. 
=============================================
[2019-03-24 04:24:34,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5481616e-24 1.0000000e+00 3.1133869e-16 2.6031354e-11 2.0527154e-12], sum to 1.0000
[2019-03-24 04:24:34,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5719
[2019-03-24 04:24:34,301] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 74.0, 1.0, 2.0, 0.6915228865664614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868073.2946939792, 868073.2946939792, 177474.1859402438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1245600.0000, 
sim time next is 1246200.0000, 
raw observation next is [21.7, 73.0, 1.0, 2.0, 0.6096614364567849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764912.7889781232, 764912.7889781232, 162255.0322729647], 
processed observation next is [1.0, 0.43478260869565216, 0.3592592592592592, 0.73, 1.0, 1.0, 0.5353112338771249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2731831389207583, 0.2731831389207583, 0.3120289082172398], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.85209394], dtype=float32), -0.20448576]. 
=============================================
[2019-03-24 04:24:42,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4178897e-25 1.0000000e+00 2.8644330e-18 7.8620997e-15 2.6205861e-15], sum to 1.0000
[2019-03-24 04:24:42,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6122
[2019-03-24 04:24:42,055] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 62.33333333333334, 1.0, 2.0, 0.3567125890707269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447839.8186637912, 447839.8186637912, 122799.2689491714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1376400.0000, 
sim time next is 1377000.0000, 
raw observation next is [23.15, 63.5, 1.0, 2.0, 0.3563243196673936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 447465.9499623749, 447465.9499623745, 122749.1923845047], 
processed observation next is [1.0, 0.9565217391304348, 0.4129629629629629, 0.635, 1.0, 1.0, 0.23371942817546856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15980926784370533, 0.1598092678437052, 0.23605613920097057], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.50632954], dtype=float32), -0.12383805]. 
=============================================
[2019-03-24 04:24:42,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.455795]
 [72.54151 ]
 [72.61488 ]
 [72.60946 ]
 [72.64589 ]], R is [[72.41023254]
 [72.44998169]
 [72.48908234]
 [72.52741241]
 [72.56469727]].
[2019-03-24 04:24:43,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0014619e-29 1.0000000e+00 6.1148645e-22 2.2128640e-17 2.2676417e-16], sum to 1.0000
[2019-03-24 04:24:43,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5436
[2019-03-24 04:24:43,429] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 26.5, 1.0, 2.0, 0.364471563955482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458767.6832045785, 458767.6832045785, 123857.7040088144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [31.7, 26.33333333333334, 1.0, 2.0, 0.3663490734150568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460774.7643392621, 460774.7643392621, 124106.3328404302], 
processed observation next is [0.0, 0.4782608695652174, 0.7296296296296296, 0.2633333333333334, 1.0, 1.0, 0.24565365882744858, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16456241583545075, 0.16456241583545075, 0.238666024693135], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.57231236], dtype=float32), -1.1477364]. 
=============================================
[2019-03-24 04:24:50,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1625127e-22 1.0000000e+00 2.1275559e-16 9.3131134e-13 3.7022421e-12], sum to 1.0000
[2019-03-24 04:24:50,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9493
[2019-03-24 04:24:50,813] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 67.5, 1.0, 2.0, 0.4163875744128235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516003.2330807519, 516003.2330807514, 130953.5173396881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1549800.0000, 
sim time next is 1550400.0000, 
raw observation next is [23.53333333333333, 66.66666666666666, 1.0, 2.0, 0.4107015315999783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509926.3337581342, 509926.3337581342, 130159.9861910687], 
processed observation next is [0.0, 0.9565217391304348, 0.4271604938271604, 0.6666666666666665, 1.0, 1.0, 0.2984542042856885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18211654777076222, 0.18211654777076222, 0.2503076657520552], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.7618432], dtype=float32), 0.6125643]. 
=============================================
[2019-03-24 04:24:52,804] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:24:52,808] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:24:52,809] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:24:52,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:52,810] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:52,811] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:24:52,811] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:24:52,811] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:52,809] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:24:52,814] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:52,814] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:52,842] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 04:24:52,868] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 04:24:52,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 04:24:52,918] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 04:24:52,920] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 04:25:24,798] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:25:24,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.57681162666667, 93.90993569666668, 1.0, 2.0, 0.3705073762905927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463211.6216127011, 463211.6216127011, 124625.9212981816]
[2019-03-24 04:25:24,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:25:24,803] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6287280e-25 1.0000000e+00 1.5041620e-18 1.1681650e-14 1.0317951e-14], sampled 0.8887378882276424
[2019-03-24 04:25:30,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:25:30,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.79248096166667, 91.01250491666667, 1.0, 2.0, 0.3620080984547731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 453789.9723490967, 453789.9723490963, 123498.5523924826]
[2019-03-24 04:25:30,689] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:25:30,691] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4122548e-26 1.0000000e+00 4.8991586e-19 4.8724236e-15 4.3742819e-15], sampled 0.1346544271845621
[2019-03-24 04:25:38,574] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:25:38,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.7, 86.66666666666667, 1.0, 2.0, 0.6298077793920835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717765.2472772538, 717765.2472772538, 163280.6492397466]
[2019-03-24 04:25:38,577] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:25:38,579] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5606306e-26 1.0000000e+00 5.0412915e-19 4.9775154e-15 4.4672662e-15], sampled 0.07748046443346068
[2019-03-24 04:25:41,319] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:25:41,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.90132580666667, 101.6893198066667, 1.0, 2.0, 0.549279301855376, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8744705373317395, 6.911200000000001, 6.9112, 122.0180669975528, 1252416.489340427, 1252416.489340427, 274670.2083107648]
[2019-03-24 04:25:41,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:25:41,324] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.8479060e-25 1.0000000e+00 2.8951704e-18 1.9823231e-14 1.7200005e-14], sampled 0.9191717875332475
[2019-03-24 04:25:57,898] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:25:57,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.5, 91.66666666666666, 1.0, 2.0, 0.7486957638735345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860684.1721775916, 860684.1721775916, 185941.8765622077]
[2019-03-24 04:25:57,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:25:57,902] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.8402193e-25 1.0000000e+00 4.4083979e-18 2.7598632e-14 2.3764839e-14], sampled 0.6225872891399501
[2019-03-24 04:26:00,020] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:26:00,023] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.90457032, 91.47704840333333, 1.0, 2.0, 0.6445340429823628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734556.18726389, 734556.18726389, 165907.148551781]
[2019-03-24 04:26:00,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:26:00,028] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3113383e-25 1.0000000e+00 1.4706134e-18 1.2207475e-14 1.0455318e-14], sampled 0.8647602627279675
[2019-03-24 04:26:06,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:26:06,616] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.6, 84.33333333333333, 1.0, 2.0, 0.6610493035521319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753387.3857441129, 753387.3857441129, 168901.4338479758]
[2019-03-24 04:26:06,616] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:26:06,619] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7021977e-25 1.0000000e+00 1.7367635e-18 1.3759571e-14 1.1805021e-14], sampled 0.5469591227841775
[2019-03-24 04:26:13,500] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:26:13,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.33333333333334, 82.0, 1.0, 2.0, 0.5466538143181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645393.4690919819, 645393.4690919819, 150159.0944603384]
[2019-03-24 04:26:13,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:26:13,504] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3232225e-25 1.0000000e+00 2.0511827e-18 1.5272461e-14 1.3231617e-14], sampled 0.901693783971983
[2019-03-24 04:26:24,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:26:24,163] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 99.0, 1.0, 2.0, 0.5163533018473067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610918.2167827147, 610918.2167827147, 145298.7837937367]
[2019-03-24 04:26:24,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:26:24,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9568955e-26 1.0000000e+00 5.4384944e-19 5.2806999e-15 4.7352144e-15], sampled 0.7594508048484984
[2019-03-24 04:26:27,468] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1338357]
[2019-03-24 04:26:27,468] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.33333333333333, 98.0, 1.0, 2.0, 0.7164537848794775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816564.6268236398, 816564.6268236398, 179278.4917971028]
[2019-03-24 04:26:27,469] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:26:27,471] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4129877e-25 1.0000000e+00 2.0825149e-18 1.5369919e-14 1.3383579e-14], sampled 0.808352481650133
[2019-03-24 04:26:35,705] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:26:35,713] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:26:35,793] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:26:35,826] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:26:35,899] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:26:36,917] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2375000, evaluation results [2375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:26:43,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9715989e-22 1.0000000e+00 6.1191799e-15 2.0732019e-10 2.4459547e-12], sum to 1.0000
[2019-03-24 04:26:43,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8767
[2019-03-24 04:26:43,286] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.55, 71.0, 1.0, 2.0, 0.7974239120940976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 993762.9779615635, 993762.977961563, 198781.1045709923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1690200.0000, 
sim time next is 1690800.0000, 
raw observation next is [22.73333333333333, 70.33333333333334, 1.0, 2.0, 0.7559209052192298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 941015.0794587166, 941015.0794587166, 190123.7222771626], 
processed observation next is [1.0, 0.5652173913043478, 0.39753086419753075, 0.7033333333333335, 1.0, 1.0, 0.7094296490705116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33607681409239876, 0.33607681409239876, 0.3656225428406973], 
reward next is 0.6344, 
noisyNet noise sample is [array([1.2653543], dtype=float32), 1.2196678]. 
=============================================
[2019-03-24 04:26:46,344] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0945204e-19 1.0000000e+00 2.6206836e-13 9.9665831e-12 3.7672726e-11], sum to 1.0000
[2019-03-24 04:26:46,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6502
[2019-03-24 04:26:46,356] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 73.33333333333334, 1.0, 2.0, 0.6755980175936769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834509.6416264253, 834509.6416264253, 174132.31540632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1758000.0000, 
sim time next is 1758600.0000, 
raw observation next is [23.05, 73.0, 1.0, 2.0, 0.7506458070916131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926070.9052026729, 926070.9052026729, 188842.2717063745], 
processed observation next is [1.0, 0.34782608695652173, 0.40925925925925927, 0.73, 1.0, 1.0, 0.7031497703471584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3307396090009546, 0.3307396090009546, 0.363158214819951], 
reward next is 0.6368, 
noisyNet noise sample is [array([0.5198458], dtype=float32), -1.8648958]. 
=============================================
[2019-03-24 04:26:56,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00512216e-13 6.02272004e-02 9.82119236e-05 9.37755466e-01
 1.91913045e-03], sum to 1.0000
[2019-03-24 04:26:56,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6730
[2019-03-24 04:26:56,774] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.7, 64.33333333333333, 1.0, 2.0, 0.5564959440627281, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8909694885743916, 6.911199999999999, 6.9112, 121.9257516585687, 1310402.148672789, 1310402.14867279, 276449.5675564797], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1950000.0000, 
sim time next is 1950600.0000, 
raw observation next is [26.95, 63.16666666666667, 1.0, 2.0, 0.5450579458523651, 1.0, 1.0, 0.5450579458523651, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260425269404, 1273140.027139963, 1273140.027139964, 251085.9896569796], 
processed observation next is [1.0, 0.5652173913043478, 0.5537037037037037, 0.6316666666666667, 1.0, 1.0, 0.45840231649091084, 1.0, 0.5, 0.45840231649091084, 0.0, 0.5, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621282311182, 0.45469286683570104, 0.4546928668357014, 0.48285767241726846], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9408665], dtype=float32), 0.89302075]. 
=============================================
[2019-03-24 04:26:57,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9969082e-19 9.9993837e-01 2.7333122e-10 1.4842237e-06 6.0141829e-05], sum to 1.0000
[2019-03-24 04:26:57,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2485
[2019-03-24 04:26:57,121] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 84.33333333333334, 1.0, 2.0, 0.502483169565479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601442.6010756982, 601442.6010756982, 143362.7858336034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1977600.0000, 
sim time next is 1978200.0000, 
raw observation next is [22.95, 85.0, 1.0, 2.0, 0.4885861261821066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587764.7994742529, 587764.7994742529, 141291.2779019344], 
processed observation next is [1.0, 0.9130434782608695, 0.4055555555555555, 0.85, 1.0, 1.0, 0.3911739597406031, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20991599981223316, 0.20991599981223316, 0.27171399596525847], 
reward next is 0.7283, 
noisyNet noise sample is [array([-0.29897904], dtype=float32), 1.0868932]. 
=============================================
[2019-03-24 04:26:59,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.135496e-21 9.999994e-01 7.408721e-12 8.585596e-09 6.071558e-07], sum to 1.0000
[2019-03-24 04:26:59,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1620
[2019-03-24 04:26:59,225] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333334, 68.66666666666667, 1.0, 2.0, 0.4300229350445351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524263.1166849273, 524263.1166849273, 132707.2884209015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2024400.0000, 
sim time next is 2025000.0000, 
raw observation next is [24.85, 68.0, 1.0, 2.0, 0.4343936267295858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528742.4676384603, 528742.4676384603, 133320.6969751974], 
processed observation next is [0.0, 0.43478260869565216, 0.475925925925926, 0.68, 1.0, 1.0, 0.32665907943998307, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1888365955851644, 0.1888365955851644, 0.2563859557215335], 
reward next is 0.7436, 
noisyNet noise sample is [array([-0.37667358], dtype=float32), -0.20181845]. 
=============================================
[2019-03-24 04:26:59,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.90151 ]
 [70.9296  ]
 [70.98555 ]
 [71.001625]
 [71.01363 ]], R is [[70.92045593]
 [70.95604706]
 [70.99237823]
 [71.02934265]
 [71.06686401]].
[2019-03-24 04:27:14,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4208613e-19 1.0000000e+00 5.4714757e-12 7.0546631e-09 5.2000462e-09], sum to 1.0000
[2019-03-24 04:27:14,779] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2440
[2019-03-24 04:27:14,783] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 70.5, 1.0, 2.0, 0.4947689862956668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 592101.8856008622, 592101.8856008617, 142147.8584755699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2311800.0000, 
sim time next is 2312400.0000, 
raw observation next is [25.4, 71.0, 1.0, 2.0, 0.4920682788052282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589056.2479019145, 589056.2479019145, 141732.9096779655], 
processed observation next is [1.0, 0.782608695652174, 0.49629629629629624, 0.71, 1.0, 1.0, 0.39531937953003354, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2103772313935409, 0.2103772313935409, 0.2725632878422414], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.05131136], dtype=float32), -0.3812693]. 
=============================================
[2019-03-24 04:27:15,398] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0934013e-18 9.9999905e-01 6.3308966e-13 7.9656638e-07 1.3408487e-07], sum to 1.0000
[2019-03-24 04:27:15,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3894
[2019-03-24 04:27:15,405] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333333, 81.5, 1.0, 2.0, 0.8416317031882107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 993303.6020376427, 993303.6020376427, 206383.9300058914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2292600.0000, 
sim time next is 2293200.0000, 
raw observation next is [24.7, 81.0, 1.0, 2.0, 0.9729283893670103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.184247515626899, 6.9112, 121.9250713073673, 1287228.386358834, 1147404.767543775, 236275.1779550868], 
processed observation next is [1.0, 0.5652173913043478, 0.4703703703703703, 0.81, 1.0, 1.0, 0.9677718921035837, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.027304751562689855, 0.0, 0.80945568034315, 0.4597244236995836, 0.40978741697991966, 0.4543753422213208], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2572361], dtype=float32), 0.43110362]. 
=============================================
[2019-03-24 04:27:17,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6157268e-19 1.0000000e+00 4.7465719e-15 3.7779818e-10 1.9294690e-09], sum to 1.0000
[2019-03-24 04:27:17,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3350
[2019-03-24 04:27:17,762] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 52.00000000000001, 1.0, 2.0, 0.4326295783340272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537490.3124129922, 537490.3124129922, 133342.1547014512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2359200.0000, 
sim time next is 2359800.0000, 
raw observation next is [26.45, 49.5, 1.0, 2.0, 0.442753522545723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551330.5886220585, 551330.5886220585, 134863.0475841378], 
processed observation next is [1.0, 0.30434782608695654, 0.5351851851851852, 0.495, 1.0, 1.0, 0.3366113363639559, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1969037816507352, 0.1969037816507352, 0.2593520145848804], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.34989738], dtype=float32), 0.5053552]. 
=============================================
[2019-03-24 04:27:19,746] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3231276e-20 1.0000000e+00 1.2889876e-14 2.7968587e-09 1.5115112e-09], sum to 1.0000
[2019-03-24 04:27:19,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3324
[2019-03-24 04:27:19,758] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.53333333333333, 40.5, 1.0, 2.0, 0.402309573809574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495646.9097925081, 495646.9097925081, 128877.7522946564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398200.0000, 
sim time next is 2398800.0000, 
raw observation next is [29.36666666666667, 41.0, 1.0, 2.0, 0.4043665549887017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.2374046114, 498394.2374046114, 129173.7418401486], 
processed observation next is [1.0, 0.782608695652174, 0.64320987654321, 0.41, 1.0, 1.0, 0.29091256546274014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17799794193021837, 0.17799794193021837, 0.24841104200028577], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.14420447], dtype=float32), 0.10019115]. 
=============================================
[2019-03-24 04:27:23,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7835388e-19 1.0047364e-05 1.5086611e-10 9.9998999e-01 4.6146873e-09], sum to 1.0000
[2019-03-24 04:27:23,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7773
[2019-03-24 04:27:23,151] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666667, 45.33333333333334, 1.0, 2.0, 0.2284123966847445, 1.0, 2.0, 0.2284123966847445, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 565370.2354881595, 565370.2354881599, 166029.8280474466], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2446800.0000, 
sim time next is 2447400.0000, 
raw observation next is [27.73333333333333, 43.66666666666666, 1.0, 2.0, 0.232092454836199, 1.0, 2.0, 0.232092454836199, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573317.1574458887, 573317.1574458887, 166813.8150437049], 
processed observation next is [1.0, 0.30434782608695654, 0.5827160493827159, 0.4366666666666666, 1.0, 1.0, 0.085824350995475, 1.0, 1.0, 0.085824350995475, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20475612765924597, 0.20475612765924597, 0.320795798160971], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.9243044], dtype=float32), -1.1350945]. 
=============================================
[2019-03-24 04:27:25,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.89246374e-24 1.00000000e+00 1.04748524e-19 1.16499106e-12
 6.34324667e-12], sum to 1.0000
[2019-03-24 04:27:25,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-24 04:27:25,113] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.93333333333334, 37.66666666666667, 1.0, 2.0, 0.3692432181204938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461555.644439016, 461555.644439016, 124452.3000614445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2495400.0000, 
sim time next is 2496000.0000, 
raw observation next is [28.76666666666667, 38.33333333333334, 1.0, 2.0, 0.3708376259951037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463494.3185337581, 463494.3185337581, 124667.792553744], 
processed observation next is [1.0, 0.9130434782608695, 0.6209876543209878, 0.3833333333333334, 1.0, 1.0, 0.2509971738036949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1655336851906279, 0.1655336851906279, 0.23974575491104616], 
reward next is 0.7603, 
noisyNet noise sample is [array([-1.65288], dtype=float32), 1.0099547]. 
=============================================
[2019-03-24 04:27:25,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.51848 ]
 [74.67339 ]
 [74.66923 ]
 [74.88062 ]
 [74.819725]], R is [[74.47994232]
 [74.49581146]
 [74.51252747]
 [74.53013611]
 [74.54858398]].
[2019-03-24 04:27:26,323] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 04:27:26,325] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:27:26,326] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:27:26,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:27:26,327] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:27:26,327] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:27:26,330] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:27:26,331] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:27:26,332] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:27:26,332] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:27:26,335] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:27:26,355] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 04:27:26,382] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 04:27:26,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 04:27:26,431] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 04:27:26,431] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 04:27:43,445] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:27:43,446] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666667, 45.0, 1.0, 2.0, 0.2822497952237636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363547.2752348861, 363547.2752348861, 113401.5887868677]
[2019-03-24 04:27:43,447] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:27:43,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6893821e-22 1.0000000e+00 5.1378086e-16 4.0076258e-11 2.7133663e-11], sampled 0.24380041624300697
[2019-03-24 04:27:56,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:27:56,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.25, 85.5, 1.0, 2.0, 0.3561017542418503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445904.8143466953, 445904.8143466953, 122698.8562349302]
[2019-03-24 04:27:56,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:27:56,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.7245201e-23 1.0000000e+00 2.3149704e-16 2.3448974e-11 1.5923790e-11], sampled 0.2931846383256679
[2019-03-24 04:28:43,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:28:43,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.8669947, 90.33158008666666, 1.0, 2.0, 0.5523382549585523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646028.2298064205, 646028.2298064205, 150846.1213355978]
[2019-03-24 04:28:43,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:28:43,761] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.0112553e-23 1.0000000e+00 1.5632774e-16 1.8010288e-11 1.2248286e-11], sampled 0.43947495605159925
[2019-03-24 04:28:46,945] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:28:46,946] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.817653665, 67.03776104166667, 1.0, 2.0, 0.430697816696659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533745.0345808042, 533745.0345808042, 133030.3520923608]
[2019-03-24 04:28:46,947] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:28:46,950] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6603616e-22 1.0000000e+00 6.3910584e-16 4.6406705e-11 3.1397891e-11], sampled 0.6760597552508085
[2019-03-24 04:29:00,611] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:29:00,612] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 70.0, 1.0, 2.0, 0.7571467659431877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 938403.9917707295, 938403.9917707295, 190277.0499963884]
[2019-03-24 04:29:00,614] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:29:00,615] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3562442e-20 1.0000000e+00 8.3927557e-15 2.6823596e-10 1.6856909e-10], sampled 0.9777561365216898
[2019-03-24 04:29:02,913] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:29:02,914] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.26666666666667, 71.33333333333334, 1.0, 2.0, 0.2753681162210822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 354910.9965906402, 354910.9965906398, 112575.4045382544]
[2019-03-24 04:29:02,915] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:29:02,917] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0048956e-22 1.0000000e+00 5.5570761e-16 4.2234126e-11 2.8587124e-11], sampled 0.5997752620175745
[2019-03-24 04:29:04,161] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1443675]
[2019-03-24 04:29:04,163] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.53536750166667, 72.49541690833333, 1.0, 2.0, 0.6059856635976142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690603.9617850028, 690603.9617850028, 159108.9124557004]
[2019-03-24 04:29:04,164] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:29:04,168] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7447218e-22 1.0000000e+00 3.7817409e-16 3.2613974e-11 2.2107151e-11], sampled 0.8139498140883954
[2019-03-24 04:29:09,522] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8741.6163 2186370738.3703 521.0000
[2019-03-24 04:29:09,681] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8791.4126 2165695856.1021 473.0000
[2019-03-24 04:29:09,708] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8936.8030 2116670957.5376 416.0000
[2019-03-24 04:29:09,743] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8171.2791 2428368783.9657 627.0000
[2019-03-24 04:29:09,747] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8622.6395 2236473553.3925 509.0000
[2019-03-24 04:29:10,764] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2400000, evaluation results [2400000.0, 8171.27906385977, 2428368783.9657207, 627.0, 8791.412558812961, 2165695856.102142, 473.0, 8936.802991930725, 2116670957.5376213, 416.0, 8622.639546030083, 2236473553.3924823, 509.0, 8741.616275430628, 2186370738.37025, 521.0]
[2019-03-24 04:29:13,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5785559e-18 1.0000000e+00 2.4108324e-12 2.0106487e-08 2.7397302e-09], sum to 1.0000
[2019-03-24 04:29:13,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2214
[2019-03-24 04:29:13,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1732360.524722921 W.
[2019-03-24 04:29:13,086] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.6, 30.0, 1.0, 2.0, 0.7306967349060255, 1.0, 1.0, 0.7306967349060255, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156248, 1732360.524722921, 1732360.524722922, 319075.1381941566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2554800.0000, 
sim time next is 2555400.0000, 
raw observation next is [33.7, 30.0, 1.0, 2.0, 0.8785942984726836, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9652779961525219, 6.911199999999999, 6.9112, 121.9260426156618, 1760592.456073817, 1760592.456073817, 345907.5834290902], 
processed observation next is [1.0, 0.5652173913043478, 0.8037037037037038, 0.3, 1.0, 1.0, 0.8554694029436709, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9565974951906522, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6287830200263632, 0.6287830200263632, 0.6652068912097888], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6575336], dtype=float32), -0.380204]. 
=============================================
[2019-03-24 04:29:13,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7080140e-23 1.0000000e+00 2.3439556e-17 2.3586133e-12 8.4145793e-13], sum to 1.0000
[2019-03-24 04:29:13,709] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-24 04:29:13,717] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 93.16666666666667, 1.0, 2.0, 0.602058610235636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708639.8387568385, 708639.8387568385, 159469.4931400312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2783400.0000, 
sim time next is 2784000.0000, 
raw observation next is [23.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5919033845115177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695883.2625586883, 695883.2625586883, 157674.5175870403], 
processed observation next is [1.0, 0.21739130434782608, 0.4197530864197533, 0.9233333333333335, 1.0, 1.0, 0.5141706958470449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24852973662810296, 0.24852973662810296, 0.30322022612892363], 
reward next is 0.6968, 
noisyNet noise sample is [array([0.9910895], dtype=float32), 1.8233643]. 
=============================================
[2019-03-24 04:29:13,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.644337]
 [63.122555]
 [63.062653]
 [63.09023 ]
 [62.688232]], R is [[63.70719147]
 [63.76345062]
 [63.82341766]
 [63.87456131]
 [63.91978836]].
[2019-03-24 04:29:18,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8411490e-23 1.0000000e+00 2.9070592e-16 1.5623692e-11 1.6624149e-13], sum to 1.0000
[2019-03-24 04:29:18,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2561
[2019-03-24 04:29:18,090] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 76.66666666666667, 1.0, 2.0, 0.5955955626364241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688882.8743650052, 688882.8743650052, 157810.0457502649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2659200.0000, 
sim time next is 2659800.0000, 
raw observation next is [26.16666666666667, 77.33333333333333, 1.0, 2.0, 0.5915847291854271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685114.0522935295, 685114.052293529, 157161.2581270841], 
processed observation next is [0.0, 0.782608695652174, 0.5246913580246916, 0.7733333333333333, 1.0, 1.0, 0.5137913442683656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24468359010483196, 0.2446835901048318, 0.30223318870593097], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.13762216], dtype=float32), -1.2908175]. 
=============================================
[2019-03-24 04:29:18,611] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5395463e-23 1.0000000e+00 3.6743028e-18 3.5702428e-13 2.4984487e-12], sum to 1.0000
[2019-03-24 04:29:18,617] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9809
[2019-03-24 04:29:18,625] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 79.33333333333334, 1.0, 2.0, 0.5823288604521352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676645.0392815848, 676645.0392815848, 155683.5998139509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661600.0000, 
sim time next is 2662200.0000, 
raw observation next is [25.55, 80.0, 1.0, 2.0, 0.5797547851444929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674328.236541025, 674328.2365410255, 155276.5833222739], 
processed observation next is [0.0, 0.8260869565217391, 0.5018518518518519, 0.8, 1.0, 1.0, 0.49970807755296764, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24083151305036607, 0.24083151305036624, 0.2986088140812959], 
reward next is 0.7014, 
noisyNet noise sample is [array([0.21165878], dtype=float32), -0.40804827]. 
=============================================
[2019-03-24 04:29:20,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4946383e-26 1.0000000e+00 1.5096041e-20 1.3283023e-14 1.3509583e-14], sum to 1.0000
[2019-03-24 04:29:20,798] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6308
[2019-03-24 04:29:20,801] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 92.66666666666666, 1.0, 2.0, 0.5109196523147407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611514.9687537698, 611514.9687537698, 144698.8087238302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3289200.0000, 
sim time next is 3289800.0000, 
raw observation next is [22.08333333333333, 92.33333333333333, 1.0, 2.0, 0.4999507040368711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 600775.8536863801, 600775.8536863796, 143047.2407411883], 
processed observation next is [0.0, 0.043478260869565216, 0.3734567901234566, 0.9233333333333333, 1.0, 1.0, 0.40470321909151324, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2145628048879929, 0.21456280488799273, 0.27509084757920826], 
reward next is 0.7249, 
noisyNet noise sample is [array([0.18838176], dtype=float32), -0.1492731]. 
=============================================
[2019-03-24 04:29:21,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3682165e-28 1.0000000e+00 9.6832487e-22 1.4456849e-16 1.3179534e-17], sum to 1.0000
[2019-03-24 04:29:21,053] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1496
[2019-03-24 04:29:21,059] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.5524707414923744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 646913.2783311197, 646913.2783311193, 150899.117735362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2719200.0000, 
sim time next is 2719800.0000, 
raw observation next is [29.25, 56.5, 1.0, 2.0, 0.54992011293115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644544.5848432257, 644544.5848432252, 150504.2166778472], 
processed observation next is [0.0, 0.4782608695652174, 0.6388888888888888, 0.565, 1.0, 1.0, 0.46419061063232137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2301944945868663, 0.23019449458686614, 0.2894311859189369], 
reward next is 0.7106, 
noisyNet noise sample is [array([-0.5935576], dtype=float32), 0.38540438]. 
=============================================
[2019-03-24 04:29:22,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0442557e-24 1.0000000e+00 6.8975521e-17 2.6953962e-14 3.1317935e-14], sum to 1.0000
[2019-03-24 04:29:22,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2919
[2019-03-24 04:29:22,277] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.85, 47.66666666666667, 1.0, 2.0, 0.5870128893235095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680031.3316031272, 680031.3316031272, 156388.4744500551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2742600.0000, 
sim time next is 2743200.0000, 
raw observation next is [32.0, 46.0, 1.0, 2.0, 0.5754489280620674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669702.5566871561, 669702.5566871561, 154564.2673742427], 
processed observation next is [0.0, 0.782608695652174, 0.7407407407407407, 0.46, 1.0, 1.0, 0.49458205721674686, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23917948453112717, 0.23917948453112717, 0.29723897571969754], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.14989607], dtype=float32), -1.2248847]. 
=============================================
[2019-03-24 04:29:22,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0520087e-22 1.0000000e+00 9.7213574e-17 5.7889416e-14 2.1084351e-13], sum to 1.0000
[2019-03-24 04:29:22,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3145
[2019-03-24 04:29:22,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 91.33333333333334, 1.0, 2.0, 0.8376127333392666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156304, 954739.2551394841, 954739.2551394836, 203828.6192894512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947200.0000, 
sim time next is 2947800.0000, 
raw observation next is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.8251272356265952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 940499.1306623045, 940499.130662304, 201181.6077146318], 
processed observation next is [1.0, 0.08695652173913043, 0.4845679012345681, 0.9266666666666667, 1.0, 1.0, 0.7918181376507085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33589254666510876, 0.3358925466651086, 0.38688770714352266], 
reward next is 0.6131, 
noisyNet noise sample is [array([-0.67020625], dtype=float32), 0.49237186]. 
=============================================
[2019-03-24 04:29:26,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00079555e-19 1.00000000e+00 2.41561557e-15 1.04633333e-11
 8.60486855e-12], sum to 1.0000
[2019-03-24 04:29:26,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9639
[2019-03-24 04:29:26,180] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 72.66666666666666, 1.0, 2.0, 0.675620528236558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770002.3199971274, 770002.3199971274, 171579.0629061543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2842800.0000, 
sim time next is 2843400.0000, 
raw observation next is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.6741603278348285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768337.3007012532, 768337.3007012532, 171308.7787005906], 
processed observation next is [1.0, 0.9130434782608695, 0.5987654320987656, 0.7333333333333334, 1.0, 1.0, 0.6120956283747958, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2744061788218762, 0.2744061788218762, 0.32943995903959733], 
reward next is 0.6706, 
noisyNet noise sample is [array([0.9312392], dtype=float32), -0.29646012]. 
=============================================
[2019-03-24 04:29:32,699] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4485698e-19 1.0000000e+00 2.0354429e-13 2.3942509e-10 8.9579705e-10], sum to 1.0000
[2019-03-24 04:29:32,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1579
[2019-03-24 04:29:32,712] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.764176001203987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870986.02369769, 870986.02369769, 188645.5451731574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949600.0000, 
sim time next is 2950200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7663132779779147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873423.4189212293, 873423.4189212293, 189074.2470928747], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7218015214022794, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31193693532901046, 0.31193693532901046, 0.36360432133245135], 
reward next is 0.6364, 
noisyNet noise sample is [array([-0.43303096], dtype=float32), 0.2671286]. 
=============================================
[2019-03-24 04:29:33,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3235793e-15 9.3914656e-05 3.0338203e-08 9.9990046e-01 5.5673668e-06], sum to 1.0000
[2019-03-24 04:29:33,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9156
[2019-03-24 04:29:33,801] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 90.66666666666666, 1.0, 2.0, 0.6969909531675894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798129.9592200142, 798129.9592200142, 175762.5962305657], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2955000.0000, 
sim time next is 2955600.0000, 
raw observation next is [24.7, 90.0, 1.0, 2.0, 0.3495355989322554, 1.0, 1.0, 0.3495355989322554, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796742.8556693759, 796742.8556693759, 192772.2248435431], 
processed observation next is [1.0, 0.21739130434782608, 0.4703703703703703, 0.9, 1.0, 1.0, 0.22563761777649452, 1.0, 0.5, 0.22563761777649452, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28455101988191994, 0.28455101988191994, 0.37071581700681366], 
reward next is 0.6293, 
noisyNet noise sample is [array([-2.0377598], dtype=float32), -0.4911927]. 
=============================================
[2019-03-24 04:29:36,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9074110e-21 9.9999416e-01 8.3947207e-12 1.5545641e-06 4.2391121e-06], sum to 1.0000
[2019-03-24 04:29:36,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1137
[2019-03-24 04:29:36,726] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 96.66666666666666, 1.0, 2.0, 0.6232751822885878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 714885.505488679, 714885.5054886786, 162353.4496918514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3019800.0000, 
sim time next is 3020400.0000, 
raw observation next is [23.9, 96.0, 1.0, 2.0, 0.6149240732896577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706894.3493659113, 706894.3493659113, 160963.3721268146], 
processed observation next is [1.0, 1.0, 0.4407407407407407, 0.96, 1.0, 1.0, 0.541576277725783, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25246226763068264, 0.25246226763068264, 0.30954494639772034], 
reward next is 0.6905, 
noisyNet noise sample is [array([-0.23609807], dtype=float32), -1.3113501]. 
=============================================
[2019-03-24 04:29:37,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6007202e-18 6.2091869e-09 2.7569187e-09 1.0000000e+00 1.3668506e-08], sum to 1.0000
[2019-03-24 04:29:37,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5192
[2019-03-24 04:29:37,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 93.5, 1.0, 2.0, 0.4045201290498001, 1.0, 2.0, 0.4045201290498001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922151.7890415391, 922151.7890415395, 207434.1552049681], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [24.93333333333333, 93.66666666666667, 1.0, 2.0, 0.3946332111978919, 1.0, 2.0, 0.3946332111978919, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 899600.1545005179, 899600.1545005183, 204720.6244639671], 
processed observation next is [1.0, 0.08695652173913043, 0.47901234567901224, 0.9366666666666668, 1.0, 1.0, 0.2793252514260618, 1.0, 1.0, 0.2793252514260618, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3212857694644707, 0.32128576946447085, 0.39369350858455215], 
reward next is 0.6063, 
noisyNet noise sample is [array([0.23859598], dtype=float32), -0.8622472]. 
=============================================
[2019-03-24 04:29:38,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7719145e-13 9.4428424e-06 5.3331740e-07 9.9998462e-01 5.4560364e-06], sum to 1.0000
[2019-03-24 04:29:38,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1033
[2019-03-24 04:29:38,833] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.303736001481118, 1.0, 2.0, 0.303736001481118, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692646.7188702509, 692646.7188702513, 181377.0268632046], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3027600.0000, 
sim time next is 3028200.0000, 
raw observation next is [24.13333333333333, 93.83333333333334, 1.0, 2.0, 0.305616719370178, 1.0, 2.0, 0.305616719370178, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 696587.2401468799, 696587.2401468804, 181813.9067041778], 
processed observation next is [1.0, 0.043478260869565216, 0.44938271604938257, 0.9383333333333335, 1.0, 1.0, 0.17335323734544997, 1.0, 1.0, 0.17335323734544997, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24878115719531427, 0.24878115719531443, 0.349642128277265], 
reward next is 0.6504, 
noisyNet noise sample is [array([0.2891362], dtype=float32), 1.154697]. 
=============================================
[2019-03-24 04:29:52,970] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3363951e-20 1.0000000e+00 8.6671020e-15 2.6354384e-11 1.9579258e-09], sum to 1.0000
[2019-03-24 04:29:52,977] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0535
[2019-03-24 04:29:52,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7385263505095606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841735.2292184276, 841735.2292184276, 183567.4584407163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888000.0000, 
sim time next is 3888600.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.727174067774228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828789.4720911101, 828789.4720911101, 181354.0673766652], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.9400000000000002, 1.0, 1.0, 0.6752072235407476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2959962400325393, 0.2959962400325393, 0.3487578218782023], 
reward next is 0.6512, 
noisyNet noise sample is [array([-0.41135126], dtype=float32), 0.56052846]. 
=============================================
[2019-03-24 04:29:53,776] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6178612e-24 1.0000000e+00 5.3271465e-18 8.9905425e-14 5.1903843e-13], sum to 1.0000
[2019-03-24 04:29:53,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4033
[2019-03-24 04:29:53,786] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 78.83333333333334, 1.0, 2.0, 0.6508786466934139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741790.4411517085, 741790.4411517085, 167051.9533119324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3330600.0000, 
sim time next is 3331200.0000, 
raw observation next is [27.03333333333334, 78.66666666666667, 1.0, 2.0, 0.6565299177079419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748234.1996471302, 748234.1996471302, 168076.2590798209], 
processed observation next is [0.0, 0.5652173913043478, 0.5567901234567904, 0.7866666666666667, 1.0, 1.0, 0.591107044890407, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26722649987397507, 0.26722649987397507, 0.32322357515350175], 
reward next is 0.6768, 
noisyNet noise sample is [array([1.1984302], dtype=float32), 0.35637122]. 
=============================================
[2019-03-24 04:30:00,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4325858e-11 4.4459919e-03 7.1263180e-06 9.9526876e-01 2.7805954e-04], sum to 1.0000
[2019-03-24 04:30:00,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1188
[2019-03-24 04:30:00,028] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 91.33333333333334, 1.0, 2.0, 0.4076829675285613, 1.0, 2.0, 0.4076829675285613, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929366.227734174, 929366.227734174, 208309.3688080436], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3482400.0000, 
sim time next is 3483000.0000, 
raw observation next is [25.25, 90.0, 1.0, 2.0, 0.4008063085374758, 1.0, 2.0, 0.4008063085374758, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 913680.6463050997, 913680.6463050997, 206410.7924959125], 
processed observation next is [1.0, 0.30434782608695654, 0.49074074074074076, 0.9, 1.0, 1.0, 0.2866741768303283, 1.0, 1.0, 0.2866741768303283, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3263145165375356, 0.3263145165375356, 0.39694383172290865], 
reward next is 0.6031, 
noisyNet noise sample is [array([0.7374671], dtype=float32), -0.8059598]. 
=============================================
[2019-03-24 04:30:00,038] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[41.857815]
 [42.09333 ]
 [42.22667 ]
 [42.425377]
 [42.69256 ]], R is [[41.75252914]
 [41.93440628]
 [42.08914185]
 [42.29333878]
 [41.8704071 ]].
[2019-03-24 04:30:00,316] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:30:00,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:30:00,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:30:00,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:30:00,328] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:30:00,328] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:30:00,329] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:30:00,330] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:30:00,331] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:30:00,332] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:30:00,333] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:30:00,348] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 04:30:00,348] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 04:30:00,400] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 04:30:00,431] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 04:30:00,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 04:30:57,242] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1475362]
[2019-03-24 04:30:57,243] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.18511839666667, 61.99571624666667, 1.0, 2.0, 0.4649236317406708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563073.9499168096, 563073.9499168096, 137785.5379396835]
[2019-03-24 04:30:57,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:30:57,247] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.07630035e-20 1.00000000e+00 5.77974880e-15 2.97586782e-12
 2.46482612e-10], sampled 0.9346398567532547
[2019-03-24 04:30:59,127] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1475362]
[2019-03-24 04:30:59,128] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.00253269333333, 40.42609870166666, 1.0, 2.0, 0.3140764504804964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399097.4707021421, 399097.4707021421, 117323.116850408]
[2019-03-24 04:30:59,130] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:30:59,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1512350e-20 1.0000000e+00 9.4595835e-15 4.3901358e-12 3.3821262e-10], sampled 0.11509616878873574
[2019-03-24 04:31:11,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1475362]
[2019-03-24 04:31:11,153] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.93333333333333, 94.0, 1.0, 2.0, 0.7272356518183154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 828859.6998505639, 828859.6998505634, 181365.6366810458]
[2019-03-24 04:31:11,154] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:31:11,156] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6385964e-21 1.0000000e+00 1.5166557e-15 1.0327452e-12 1.0445194e-10], sampled 0.37990495404191127
[2019-03-24 04:31:13,843] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1475362]
[2019-03-24 04:31:13,844] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.83009175166667, 63.91236847833333, 1.0, 2.0, 0.4817273364263165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582568.3704584523, 582568.3704584523, 140330.2368660249]
[2019-03-24 04:31:13,845] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:31:13,849] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9225080e-20 1.0000000e+00 8.7334128e-15 4.1183576e-12 3.2127531e-10], sampled 0.30112494764484043
[2019-03-24 04:31:34,540] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1475362]
[2019-03-24 04:31:34,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 83.0, 1.0, 2.0, 0.6750076082421739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769303.4267086353, 769303.4267086353, 171467.1288587985]
[2019-03-24 04:31:34,543] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:31:34,544] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0204118e-21 1.0000000e+00 2.3422778e-15 1.4566319e-12 1.3804760e-10], sampled 0.8328476201735973
[2019-03-24 04:31:43,503] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8925.4371 2120255440.5418 430.0000
[2019-03-24 04:31:43,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8772.9336 2170515695.7300 493.0000
[2019-03-24 04:31:43,829] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8102.5259 2444480712.1541 736.0000
[2019-03-24 04:31:43,903] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8702.5338 2194921431.6764 569.0000
[2019-03-24 04:31:43,905] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.3994 2248597285.2145 552.0000
[2019-03-24 04:31:44,919] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2425000, evaluation results [2425000.0, 8102.525900105427, 2444480712.154136, 736.0, 8772.933564828863, 2170515695.729964, 493.0, 8925.437062153755, 2120255440.5418317, 430.0, 8584.399365979354, 2248597285.21453, 552.0, 8702.53380219986, 2194921431.676359, 569.0]
[2019-03-24 04:31:52,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4823320e-19 1.0000000e+00 6.7288040e-14 8.7665797e-10 1.3057714e-08], sum to 1.0000
[2019-03-24 04:31:52,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-24 04:31:52,016] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 80.33333333333334, 1.0, 2.0, 0.4775752086375843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578896.8999329745, 578896.8999329748, 139733.3187501242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [23.16666666666666, 78.16666666666667, 1.0, 2.0, 0.4587310381878363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558442.2371080577, 558442.2371080577, 136938.0111734343], 
processed observation next is [1.0, 0.17391304347826086, 0.41358024691358003, 0.7816666666666667, 1.0, 1.0, 0.35563218831885274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1994436561100206, 0.1994436561100206, 0.2633423291796813], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.8050419], dtype=float32), -0.8547668]. 
=============================================
[2019-03-24 04:31:52,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4934538e-23 1.0000000e+00 4.5913813e-16 3.4209460e-12 9.7723815e-11], sum to 1.0000
[2019-03-24 04:31:52,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-24 04:31:52,341] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 81.66666666666666, 1.0, 2.0, 0.5459476284224258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637941.6087005262, 637941.6087005262, 149767.1745134834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3606000.0000, 
sim time next is 3606600.0000, 
raw observation next is [25.05, 82.33333333333334, 1.0, 2.0, 0.5505292077743604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642702.2026959194, 642702.2026959194, 150495.0892651649], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.8233333333333335, 1.0, 1.0, 0.46491572354090527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22953650096282838, 0.22953650096282838, 0.2894136332022402], 
reward next is 0.7106, 
noisyNet noise sample is [array([-1.0169969], dtype=float32), -0.971732]. 
=============================================
[2019-03-24 04:31:58,552] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8807108e-14 1.3941608e-04 6.4621560e-08 9.9976379e-01 9.6670585e-05], sum to 1.0000
[2019-03-24 04:31:58,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9081
[2019-03-24 04:31:58,566] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 93.33333333333334, 1.0, 2.0, 0.340683915327628, 1.0, 2.0, 0.340683915327628, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 776555.8182133212, 776555.8182133216, 190510.5866643012], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3703800.0000, 
sim time next is 3704400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3367029147329618, 1.0, 2.0, 0.3367029147329618, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 767476.9720285478, 767476.9720285482, 189501.8582548975], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2103606127773355, 1.0, 1.0, 0.2103606127773355, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2740989185816242, 0.2740989185816244, 0.36442665049018746], 
reward next is 0.6356, 
noisyNet noise sample is [array([0.33817124], dtype=float32), 0.23389165]. 
=============================================
[2019-03-24 04:32:01,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8946704e-21 1.0000000e+00 3.7922397e-14 4.9906159e-11 4.1257646e-08], sum to 1.0000
[2019-03-24 04:32:01,877] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5412
[2019-03-24 04:32:01,884] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333333, 65.33333333333333, 1.0, 2.0, 0.7660361041603999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 873107.3236535977, 873107.3236535973, 189025.0263298375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789600.0000, 
sim time next is 3790200.0000, 
raw observation next is [30.91666666666667, 62.16666666666667, 1.0, 2.0, 0.7302134273261128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832255.4329175486, 832255.4329175486, 181942.9546675509], 
processed observation next is [1.0, 0.8695652173913043, 0.7006172839506175, 0.6216666666666667, 1.0, 1.0, 0.6788255087215629, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2972340831848388, 0.2972340831848388, 0.34989029743759786], 
reward next is 0.6501, 
noisyNet noise sample is [array([-1.3180755], dtype=float32), -0.20520815]. 
=============================================
[2019-03-24 04:32:11,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9805993e-22 1.0000000e+00 1.9861890e-16 2.9373296e-12 5.2815065e-11], sum to 1.0000
[2019-03-24 04:32:11,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-24 04:32:11,860] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 99.5, 1.0, 2.0, 0.5149247527170431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632461.3365437427, 632461.3365437427, 145846.359955911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4163400.0000, 
sim time next is 4164000.0000, 
raw observation next is [19.93333333333333, 99.33333333333334, 1.0, 2.0, 0.463869074802444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570093.1560501129, 570093.1560501129, 137866.0050434916], 
processed observation next is [1.0, 0.17391304347826086, 0.293827160493827, 0.9933333333333334, 1.0, 1.0, 0.36174889857433806, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20360469858932603, 0.20360469858932603, 0.2651269327759454], 
reward next is 0.7349, 
noisyNet noise sample is [array([0.14086877], dtype=float32), -0.07262504]. 
=============================================
[2019-03-24 04:32:11,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.393707]
 [61.627613]
 [61.795055]
 [61.85997 ]
 [61.930626]], R is [[61.529953  ]
 [61.63417816]
 [61.73739243]
 [61.83535004]
 [61.95629501]].
[2019-03-24 04:32:17,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3134896e-14 3.2390264e-04 3.4131497e-07 9.9889332e-01 7.8251195e-04], sum to 1.0000
[2019-03-24 04:32:17,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6677
[2019-03-24 04:32:17,550] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.2700628235368466, 1.0, 1.0, 0.2700628235368466, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653149.4059390601, 653149.4059390601, 175072.7721337791], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4083600.0000, 
sim time next is 4084200.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.2726859644352195, 1.0, 2.0, 0.2726859644352195, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656780.2870240242, 656780.2870240242, 175592.8122312883], 
processed observation next is [1.0, 0.2608695652173913, 0.3148148148148148, 1.0, 1.0, 1.0, 0.13414995766097557, 1.0, 1.0, 0.13414995766097557, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23456438822286577, 0.23456438822286577, 0.3376784850601698], 
reward next is 0.6623, 
noisyNet noise sample is [array([-0.03745773], dtype=float32), -0.7100101]. 
=============================================
[2019-03-24 04:32:22,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5889728e-20 1.0000000e+00 2.6170095e-15 3.5665965e-12 4.5569049e-11], sum to 1.0000
[2019-03-24 04:32:22,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7844
[2019-03-24 04:32:22,171] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 79.0, 1.0, 2.0, 0.5486227766390327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654975.9358547623, 654975.9358547623, 150765.7998863334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4175400.0000, 
sim time next is 4176000.0000, 
raw observation next is [24.8, 76.0, 1.0, 2.0, 0.5474205992365633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653269.297231357, 653269.297231357, 150556.6118653028], 
processed observation next is [1.0, 0.34782608695652173, 0.4740740740740741, 0.76, 1.0, 1.0, 0.4612149990911467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2333104632969132, 0.2333104632969132, 0.28953194589481307], 
reward next is 0.7105, 
noisyNet noise sample is [array([0.9871206], dtype=float32), 0.65573317]. 
=============================================
[2019-03-24 04:32:22,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[55.712532]
 [56.04052 ]
 [56.4064  ]
 [56.6634  ]
 [56.95015 ]], R is [[55.60686874]
 [55.76086426]
 [55.91617584]
 [56.07266998]
 [56.22848511]].
[2019-03-24 04:32:23,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0885034e-24 1.0000000e+00 4.2100340e-20 2.8344156e-15 5.5919410e-12], sum to 1.0000
[2019-03-24 04:32:23,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0347
[2019-03-24 04:32:23,137] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 38.0, 1.0, 2.0, 0.4980537959157358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591835.9661471162, 591835.9661471162, 142507.3056689177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4215600.0000, 
sim time next is 4216200.0000, 
raw observation next is [32.46666666666667, 39.16666666666667, 1.0, 2.0, 0.4975649744867003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592393.9910788463, 592393.9910788463, 142473.5489220034], 
processed observation next is [1.0, 0.8260869565217391, 0.7580246913580247, 0.3916666666666667, 1.0, 1.0, 0.4018630648651194, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21156928252815937, 0.21156928252815937, 0.2739875940807758], 
reward next is 0.7260, 
noisyNet noise sample is [array([1.8402563], dtype=float32), -0.9011633]. 
=============================================
[2019-03-24 04:32:25,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1378998e-20 9.4254736e-11 8.7595098e-10 1.0000000e+00 3.9761559e-08], sum to 1.0000
[2019-03-24 04:32:25,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8362
[2019-03-24 04:32:25,609] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 71.33333333333334, 1.0, 2.0, 0.246399750188177, 1.0, 1.0, 0.246399750188177, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585866.8464131264, 585866.8464131268, 169244.9341771497], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4234200.0000, 
sim time next is 4234800.0000, 
raw observation next is [25.33333333333334, 68.66666666666667, 1.0, 2.0, 0.2427833363237279, 1.0, 2.0, 0.2427833363237279, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578923.3638459995, 578923.3638459999, 168502.1972389029], 
processed observation next is [1.0, 0.0, 0.49382716049382736, 0.6866666666666668, 1.0, 1.0, 0.09855159086158083, 1.0, 1.0, 0.09855159086158083, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2067583442307141, 0.20675834423071426, 0.32404268699789024], 
reward next is 0.6760, 
noisyNet noise sample is [array([0.3760607], dtype=float32), -0.22287372]. 
=============================================
[2019-03-24 04:32:27,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9666063e-23 1.9771424e-14 1.5589868e-12 1.0000000e+00 1.2026919e-12], sum to 1.0000
[2019-03-24 04:32:27,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8381
[2019-03-24 04:32:27,203] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 93.16666666666666, 1.0, 2.0, 0.3571050943800163, 1.0, 2.0, 0.3571050943800163, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814006.1728010392, 814006.1728010392, 194729.8877128685], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4830600.0000, 
sim time next is 4831200.0000, 
raw observation next is [26.0, 93.0, 1.0, 2.0, 0.3560752225239711, 1.0, 2.0, 0.3560752225239711, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 811657.3798652637, 811657.3798652642, 194462.5481523516], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.93, 1.0, 1.0, 0.23342288395710847, 1.0, 1.0, 0.23342288395710847, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2898776356661656, 0.28987763566616576, 0.37396643875452235], 
reward next is 0.6260, 
noisyNet noise sample is [array([-0.00401781], dtype=float32), 1.5376103]. 
=============================================
[2019-03-24 04:32:31,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1859857e-14 9.9044168e-01 1.2926973e-06 4.8376196e-03 4.7193230e-03], sum to 1.0000
[2019-03-24 04:32:31,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2814
[2019-03-24 04:32:31,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 92.66666666666667, 1.0, 2.0, 0.6013967991244716, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712736.7414226364, 712736.7414226364, 159552.0601044114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335600.0000, 
sim time next is 4336200.0000, 
raw observation next is [22.4, 92.0, 1.0, 2.0, 0.574708540695147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686933.279913732, 686933.279913732, 155178.4048280661], 
processed observation next is [1.0, 0.17391304347826086, 0.38518518518518513, 0.92, 1.0, 1.0, 0.4937006436846988, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24533331425490426, 0.24533331425490426, 0.2984200092847425], 
reward next is 0.7016, 
noisyNet noise sample is [array([1.3190538], dtype=float32), 0.3942917]. 
=============================================
[2019-03-24 04:32:33,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2770758e-20 1.0000000e+00 4.5494292e-14 1.4851433e-12 2.2081750e-10], sum to 1.0000
[2019-03-24 04:32:33,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9932
[2019-03-24 04:32:33,183] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 94.5, 1.0, 2.0, 0.6028433258252563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695553.1391525086, 695553.1391525086, 158982.056730945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555800.0000, 
sim time next is 4556400.0000, 
raw observation next is [23.96666666666667, 94.33333333333334, 1.0, 2.0, 0.6021050489605116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694771.7099391416, 694771.7099391416, 158857.5231299318], 
processed observation next is [0.0, 0.7391304347826086, 0.4432098765432099, 0.9433333333333335, 1.0, 1.0, 0.5263155344767996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24813275354969344, 0.24813275354969344, 0.3054952367883304], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.10926065], dtype=float32), 0.07727798]. 
=============================================
[2019-03-24 04:32:34,335] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 04:32:34,336] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:32:34,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:34,338] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:32:34,340] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:32:34,342] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:34,342] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:34,341] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:32:34,343] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:32:34,347] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:34,348] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:34,368] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 04:32:34,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 04:32:34,423] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 04:32:34,424] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 04:32:34,484] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 04:32:44,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:32:44,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 29.0, 1.0, 2.0, 0.3355649711696782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427960.8053917392, 427960.8053917388, 120081.9263551685]
[2019-03-24 04:32:44,487] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:32:44,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.6188243e-22 1.0000000e+00 6.9210694e-15 1.2579870e-12 8.5699807e-12], sampled 0.21888948968513622
[2019-03-24 04:32:48,689] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:32:48,690] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 28.0, 1.0, 2.0, 0.2561219227495225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 330376.9451365118, 330376.9451365118, 87875.06519846046]
[2019-03-24 04:32:48,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:32:48,696] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.0933722e-22 1.0000000e+00 8.3134454e-15 1.4627375e-12 9.8365942e-12], sampled 0.44999357821244246
[2019-03-24 04:33:19,012] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:33:19,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 66.0, 1.0, 2.0, 0.6809818047533353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776115.6412461522, 776115.6412461522, 172575.7537386225]
[2019-03-24 04:33:19,014] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:33:19,019] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.3648600e-22 1.0000000e+00 8.5594306e-15 1.4981224e-12 1.0055295e-11], sampled 0.4521586721684482
[2019-03-24 04:33:22,920] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:33:22,921] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.06666666666667, 82.33333333333334, 1.0, 2.0, 0.8465725636923219, 1.0, 1.0, 0.8465725636923219, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 122.3944193166585, 1954048.601632746, 1954048.601632747, 364669.2854694326]
[2019-03-24 04:33:22,923] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:33:22,925] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7857805e-10 4.2369094e-02 2.4201878e-04 9.4925177e-01 8.1370696e-03], sampled 0.8611212691218697
[2019-03-24 04:33:38,029] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:33:38,031] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.41795996, 89.92391212, 1.0, 2.0, 0.5421571522095869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639291.6190839708, 639291.6190839708, 149388.2544843854]
[2019-03-24 04:33:38,033] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:33:38,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3175522e-22 1.0000000e+00 4.3811788e-15 8.6347368e-13 6.0774320e-12], sampled 0.808601124466944
[2019-03-24 04:33:39,719] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:33:39,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.0676271, 121.5930805, 1.0, 2.0, 0.826778670348597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 975926.1155277825, 975926.115527782, 203193.9780992415]
[2019-03-24 04:33:39,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:33:39,724] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.7122410e-22 1.0000000e+00 9.7184757e-15 1.6629484e-12 1.1064538e-11], sampled 0.26213680104781534
[2019-03-24 04:34:03,867] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.153681]
[2019-03-24 04:34:03,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.18361999, 31.73993514, 1.0, 2.0, 0.5337879682114777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663047.2719845542, 663047.2719845542, 149095.4640484547]
[2019-03-24 04:34:03,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:34:03,876] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1866970e-21 1.0000000e+00 1.2935342e-14 2.1045268e-12 1.3714760e-11], sampled 0.832622877617502
[2019-03-24 04:34:18,088] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8601.1505 2240702476.0137 524.0000
[2019-03-24 04:34:18,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8785.8551 2165907378.1561 479.0000
[2019-03-24 04:34:18,435] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8725.6950 2189546965.0734 535.0000
[2019-03-24 04:34:18,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8932.3174 2117814945.2214 422.0000
[2019-03-24 04:34:18,715] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8141.4079 2432128868.2875 665.0000
[2019-03-24 04:34:19,733] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2450000, evaluation results [2450000.0, 8141.407894311036, 2432128868.287498, 665.0, 8785.855071773043, 2165907378.156098, 479.0, 8932.317422412929, 2117814945.221399, 422.0, 8601.150548629148, 2240702476.0137353, 524.0, 8725.694986682733, 2189546965.0733943, 535.0]
[2019-03-24 04:34:20,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2468751e-18 1.0000000e+00 8.7803263e-12 6.8029131e-11 4.6435082e-09], sum to 1.0000
[2019-03-24 04:34:20,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5747
[2019-03-24 04:34:20,180] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 98.66666666666666, 1.0, 2.0, 0.4849242220009499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582765.0997817398, 582765.0997817398, 140703.1147698614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4585200.0000, 
sim time next is 4585800.0000, 
raw observation next is [21.5, 98.33333333333334, 1.0, 2.0, 0.4874084800531061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 585111.6153674611, 585111.6153674606, 141066.1124226172], 
processed observation next is [1.0, 0.043478260869565216, 0.35185185185185186, 0.9833333333333334, 1.0, 1.0, 0.38977200006322155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20896843405980753, 0.20896843405980736, 0.27128098542811], 
reward next is 0.7287, 
noisyNet noise sample is [array([-2.1248806], dtype=float32), 1.2107087]. 
=============================================
[2019-03-24 04:34:24,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9611701e-24 1.0000000e+00 2.9371078e-18 6.1833243e-14 3.2911544e-15], sum to 1.0000
[2019-03-24 04:34:24,410] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3667
[2019-03-24 04:34:24,414] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7034178820199884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801699.4333667646, 801699.4333667646, 176792.2746753431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4483200.0000, 
sim time next is 4483800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.70774869391627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 806637.943608253, 806637.9436082535, 177616.2081375977], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6520817784717501, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28808497986009035, 0.2880849798600905, 0.34156963103384175], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.3970838], dtype=float32), 0.40832224]. 
=============================================
[2019-03-24 04:34:30,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2113541e-21 1.0000000e+00 6.6959066e-16 3.8100933e-12 4.2923317e-13], sum to 1.0000
[2019-03-24 04:34:30,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6169
[2019-03-24 04:34:30,591] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 99.5, 1.0, 2.0, 0.4915601988732447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363577, 141759.4939517889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4599000.0000, 
sim time next is 4599600.0000, 
raw observation next is [21.13333333333333, 99.66666666666666, 1.0, 2.0, 0.4839474435163825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582815.624805106, 582815.624805106, 140593.5783564216], 
processed observation next is [1.0, 0.21739130434782608, 0.33827160493827146, 0.9966666666666666, 1.0, 1.0, 0.38565171847188395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.208148437430395, 0.208148437430395, 0.27037226607004156], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.00961356], dtype=float32), 0.39210954]. 
=============================================
[2019-03-24 04:34:40,425] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5641890e-10 9.8901373e-01 9.2929831e-06 1.4134186e-04 1.0835616e-02], sum to 1.0000
[2019-03-24 04:34:40,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2766
[2019-03-24 04:34:40,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1683600.940965464 W.
[2019-03-24 04:34:40,453] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.93333333333333, 94.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.909165702853711, 6.9112, 121.9220998689019, 1683600.940965464, 1172569.829791374, 246122.6757939397], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [23.95, 94.0, 1.0, 2.0, 0.394012735206266, 1.0, 1.0, 0.394012735206266, 1.0, 1.0, 0.6272811065473057, 6.911200000000001, 6.9112, 121.94756008, 1347672.115106073, 1347672.115106073, 294469.3136343561], 
processed observation next is [1.0, 0.391304347826087, 0.4425925925925926, 0.94, 1.0, 1.0, 0.2785865895312691, 1.0, 0.5, 0.2785865895312691, 1.0, 0.5, 0.5341013831841321, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.48131146968074034, 0.48131146968074034, 0.5662871416045309], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.84687746], dtype=float32), -0.496377]. 
=============================================
[2019-03-24 04:34:40,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2847771e-10 9.8908794e-01 5.1120337e-06 2.5412806e-03 8.3657093e-03], sum to 1.0000
[2019-03-24 04:34:40,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8039
[2019-03-24 04:34:40,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1633678.522638455 W.
[2019-03-24 04:34:40,666] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333333, 89.33333333333334, 1.0, 2.0, 0.7163163909244801, 1.0, 2.0, 0.7163163909244801, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426154755, 1633678.522638455, 1633678.522638454, 310387.7392606378], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4790400.0000, 
sim time next is 4791000.0000, 
raw observation next is [25.66666666666667, 88.16666666666666, 1.0, 2.0, 0.484331761569616, 1.0, 2.0, 0.484331761569616, 1.0, 1.0, 0.7710719380030918, 6.911199999999999, 6.9112, 121.94756008, 1656919.819342717, 1656919.819342717, 335965.4543894586], 
processed observation next is [1.0, 0.43478260869565216, 0.506172839506173, 0.8816666666666666, 1.0, 1.0, 0.38610923996382857, 1.0, 1.0, 0.38610923996382857, 1.0, 0.5, 0.7138399225038646, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5917570783366847, 0.5917570783366847, 0.6460874122874204], 
reward next is 0.3539, 
noisyNet noise sample is [array([-1.6120397], dtype=float32), -0.13984437]. 
=============================================
[2019-03-24 04:34:40,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[37.799644]
 [37.6523  ]
 [36.930553]
 [36.236427]
 [37.42084 ]], R is [[37.89086533]
 [37.91505432]
 [37.53590393]
 [37.16054535]
 [36.78894043]].
[2019-03-24 04:34:41,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9961743e-17 1.0000000e+00 1.7400396e-14 3.8577123e-12 2.1972306e-10], sum to 1.0000
[2019-03-24 04:34:41,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0264
[2019-03-24 04:34:41,272] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6603334510250911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752571.1394989771, 752571.1394989771, 168772.4737162357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4989600.0000, 
sim time next is 4990200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6683032867126416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761658.7424722443, 761658.7424722438, 170231.5408240278], 
processed observation next is [1.0, 0.782608695652174, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.6051229603721924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.272020979454373, 0.2720209794543728, 0.327368347738515], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.4857731], dtype=float32), -0.016520947]. 
=============================================
[2019-03-24 04:34:41,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2501222e-17 1.0000000e+00 9.6017398e-14 2.0546710e-11 1.0285026e-09], sum to 1.0000
[2019-03-24 04:34:41,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-24 04:34:41,398] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 89.0, 1.0, 2.0, 0.7232023825731452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824260.3490012272, 824260.3490012272, 180591.2806499973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4815000.0000, 
sim time next is 4815600.0000, 
raw observation next is [27.53333333333333, 90.66666666666667, 1.0, 2.0, 0.7341817904459649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836780.814856677, 836780.814856677, 182723.9011782148], 
processed observation next is [1.0, 0.7391304347826086, 0.5753086419753086, 0.9066666666666667, 1.0, 1.0, 0.6835497505309106, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2988502910202418, 0.2988502910202418, 0.35139211765041306], 
reward next is 0.6486, 
noisyNet noise sample is [array([-1.405572], dtype=float32), -0.7554172]. 
=============================================
[2019-03-24 04:34:42,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4814012e-18 1.0000000e+00 2.4091797e-14 1.3191438e-12 8.8223658e-11], sum to 1.0000
[2019-03-24 04:34:42,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5229
[2019-03-24 04:34:42,020] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.83333333333334, 1.0, 2.0, 0.7226465308894803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823626.4840073199, 823626.4840073199, 180477.4257197227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [26.0, 93.66666666666667, 1.0, 2.0, 0.7196813860710795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820245.1924964526, 820245.1924964526, 179905.1764628701], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9366666666666668, 1.0, 1.0, 0.6662873643703326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29294471160587593, 0.29294471160587593, 0.3459714931978271], 
reward next is 0.6540, 
noisyNet noise sample is [array([1.0063534], dtype=float32), 0.03407653]. 
=============================================
[2019-03-24 04:34:42,930] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8574013e-26 1.0000000e+00 3.6869317e-22 5.3090503e-18 6.1717123e-16], sum to 1.0000
[2019-03-24 04:34:42,938] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9506
[2019-03-24 04:34:42,945] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.709582049442629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808728.5646687681, 808728.5646687681, 177967.2701681992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834200.0000, 
sim time next is 4834800.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.7099768805747595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809178.8012085373, 809178.8012085373, 178042.6388841437], 
processed observation next is [1.0, 1.0, 0.5222222222222223, 0.92, 1.0, 1.0, 0.6547343816366185, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28899242900304906, 0.28899242900304906, 0.3423896901618148], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.18483868], dtype=float32), 0.44292074]. 
=============================================
[2019-03-24 04:34:53,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3893212e-23 1.0000000e+00 2.0232894e-20 1.6285787e-14 3.6092248e-15], sum to 1.0000
[2019-03-24 04:34:53,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3501
[2019-03-24 04:34:53,992] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 75.0, 1.0, 2.0, 0.718121539625911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 818466.4335783541, 818466.4335783536, 179608.0771422134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5052000.0000, 
sim time next is 5052600.0000, 
raw observation next is [29.55, 76.0, 1.0, 2.0, 0.7485074046721707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 853117.4645624782, 853117.4645624782, 185536.6868303977], 
processed observation next is [0.0, 0.4782608695652174, 0.65, 0.76, 1.0, 1.0, 0.7006040531811556, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30468480877231363, 0.30468480877231363, 0.3568013208276879], 
reward next is 0.6432, 
noisyNet noise sample is [array([0.43813595], dtype=float32), -0.4695163]. 
=============================================
[2019-03-24 04:34:55,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7613044e-27 1.0000000e+00 2.2602766e-22 1.1148957e-15 1.8829903e-17], sum to 1.0000
[2019-03-24 04:34:55,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0538
[2019-03-24 04:34:55,417] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 88.0, 1.0, 2.0, 0.7140854653223083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813863.9463922792, 813863.9463922792, 178828.5491492015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259600.0000, 
sim time next is 5260200.0000, 
raw observation next is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.6998923328327609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797679.2035729453, 797679.2035729453, 176124.6613501184], 
processed observation next is [1.0, 0.9130434782608695, 0.5376543209876544, 0.8833333333333334, 1.0, 1.0, 0.6427289676580487, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2848854298474805, 0.2848854298474805, 0.33870127182715076], 
reward next is 0.6613, 
noisyNet noise sample is [array([0.06755999], dtype=float32), 0.8243992]. 
=============================================
[2019-03-24 04:34:59,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0918173e-27 1.0000000e+00 4.4769548e-23 5.9145035e-17 4.6740787e-19], sum to 1.0000
[2019-03-24 04:34:59,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6901
[2019-03-24 04:34:59,777] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 69.66666666666667, 1.0, 2.0, 0.6168987647281163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704465.0311161361, 704465.0311161361, 161079.0827697635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5338200.0000, 
sim time next is 5338800.0000, 
raw observation next is [28.1, 70.0, 1.0, 2.0, 0.6193106665331617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706850.760518871, 706850.760518871, 161483.2452621608], 
processed observation next is [1.0, 0.8260869565217391, 0.5962962962962963, 0.7, 1.0, 1.0, 0.5467984125394781, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25244670018531107, 0.25244670018531107, 0.3105447024272323], 
reward next is 0.6895, 
noisyNet noise sample is [array([1.3867799], dtype=float32), 1.8356516]. 
=============================================
[2019-03-24 04:35:01,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9125871e-26 1.0000000e+00 1.6189009e-21 8.8152455e-16 1.4983280e-16], sum to 1.0000
[2019-03-24 04:35:01,333] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5328
[2019-03-24 04:35:01,339] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 90.0, 1.0, 2.0, 0.6277761451416136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719901.7097885847, 719901.7097885847, 163142.3549948393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181600.0000, 
sim time next is 5182200.0000, 
raw observation next is [24.9, 91.0, 1.0, 2.0, 0.6373573477747546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728166.0717597627, 728166.0717597627, 164712.6451915106], 
processed observation next is [0.0, 1.0, 0.47777777777777775, 0.91, 1.0, 1.0, 0.5682825568747079, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2600593113427724, 0.2600593113427724, 0.31675508690675114], 
reward next is 0.6832, 
noisyNet noise sample is [array([0.7328925], dtype=float32), 1.6288517]. 
=============================================
[2019-03-24 04:35:03,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5371394e-11 2.4102397e-04 2.9435553e-08 9.9968719e-01 7.1830138e-05], sum to 1.0000
[2019-03-24 04:35:03,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-24 04:35:03,242] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 97.0, 1.0, 2.0, 0.4697257904488211, 1.0, 2.0, 0.4697257904488211, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1070899.723397896, 1070899.723397897, 226178.6273035342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5210400.0000, 
sim time next is 5211000.0000, 
raw observation next is [24.25, 95.5, 1.0, 2.0, 0.4813727668026194, 1.0, 2.0, 0.4813727668026194, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1097471.984878997, 1097471.984878997, 229681.8023041036], 
processed observation next is [1.0, 0.30434782608695654, 0.4537037037037037, 0.955, 1.0, 1.0, 0.38258662714597547, 1.0, 1.0, 0.38258662714597547, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.39195428031392754, 0.39195428031392754, 0.4416957736617377], 
reward next is 0.5583, 
noisyNet noise sample is [array([0.36592168], dtype=float32), 2.8346913]. 
=============================================
[2019-03-24 04:35:03,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[36.097397]
 [35.8311  ]
 [36.11387 ]
 [36.49468 ]
 [36.502678]], R is [[36.44400406]
 [36.64460373]
 [36.87145233]
 [37.11528397]
 [37.36015701]].
[2019-03-24 04:35:09,130] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 04:35:09,131] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:35:09,131] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:35:09,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:35:09,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:35:09,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:35:09,132] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:35:09,135] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:35:09,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:35:09,136] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:35:09,139] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:35:09,160] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 04:35:09,188] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 04:35:09,189] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 04:35:09,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 04:35:09,281] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 04:35:11,712] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:35:11,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.25, 40.0, 1.0, 2.0, 0.3967906296744635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 511888.9692251112, 511888.9692251117, 110948.7021091878]
[2019-03-24 04:35:11,714] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:35:11,719] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.8457952e-24 1.0000000e+00 2.2191330e-20 2.6470262e-14 3.2272990e-16], sampled 0.8077018650919204
[2019-03-24 04:35:22,883] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:35:22,885] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.219393725, 55.102329765, 1.0, 2.0, 0.3708710359610732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463003.6015742338, 463003.6015742338, 124662.8237918649]
[2019-03-24 04:35:22,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:35:22,889] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.8032198e-26 1.0000000e+00 2.3794996e-22 1.1921454e-15 9.8666476e-18], sampled 0.2508704406944101
[2019-03-24 04:35:48,443] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:35:48,444] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.2, 69.66666666666667, 1.0, 2.0, 0.6303051231710626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718907.9505542419, 718907.9505542419, 163397.2404168597]
[2019-03-24 04:35:48,445] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:35:48,447] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4805646e-26 1.0000000e+00 4.2301688e-22 1.7676865e-15 1.5363829e-17], sampled 0.325078242091971
[2019-03-24 04:36:02,298] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:36:02,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.53515727, 62.59961982, 1.0, 2.0, 0.4733485088468385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569631.5704228103, 569631.5704228103, 138949.5265134129]
[2019-03-24 04:36:02,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:36:02,302] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.1973612e-27 1.0000000e+00 5.7684034e-23 4.5305733e-16 3.3179492e-18], sampled 0.5676185636015884
[2019-03-24 04:36:08,515] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:36:08,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.3, 76.5, 1.0, 2.0, 0.4831757644737924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598358.6958820305, 598358.6958820305, 140944.9107247658]
[2019-03-24 04:36:08,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:36:08,522] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.8890511e-26 1.0000000e+00 4.9024042e-22 1.9526017e-15 1.7194271e-17], sampled 0.85248732875435
[2019-03-24 04:36:23,727] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1545929]
[2019-03-24 04:36:23,728] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 85.5, 1.0, 2.0, 0.6011206078010832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692156.4946030412, 692156.4946030412, 158617.119069884]
[2019-03-24 04:36:23,728] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:36:23,734] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0418194e-25 1.0000000e+00 5.6119358e-22 2.1419953e-15 1.9082120e-17], sampled 0.7455824961222746
[2019-03-24 04:36:52,917] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:36:53,090] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:36:53,188] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:36:53,278] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.6684 2120370312.8683 430.0000
[2019-03-24 04:36:53,416] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8101.3620 2445300292.5861 745.0000
[2019-03-24 04:36:54,433] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2475000, evaluation results [2475000.0, 8101.361951307083, 2445300292.5860825, 745.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.668399994049, 2120370312.8682683, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 04:36:58,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.30542695e-11 1.65126566e-02 2.56966448e-09 9.83482003e-01
 5.25990572e-06], sum to 1.0000
[2019-03-24 04:36:58,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4395
[2019-03-24 04:36:58,554] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 76.0, 1.0, 2.0, 0.8317405186022349, 1.0, 1.0, 0.8317405186022349, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259993066749, 1897201.972987438, 1897201.972987438, 357044.647366839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5396400.0000, 
sim time next is 5397000.0000, 
raw observation next is [27.83333333333334, 77.33333333333334, 1.0, 2.0, 0.8086177452157169, 1.0, 2.0, 0.8086177452157169, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426024558, 1844404.416424804, 1844404.416424804, 347328.3029887446], 
processed observation next is [1.0, 0.4782608695652174, 0.58641975308642, 0.7733333333333334, 1.0, 1.0, 0.772163982399663, 1.0, 1.0, 0.772163982399663, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621287324618, 0.6587158630088585, 0.6587158630088585, 0.6679390442091242], 
reward next is 0.3321, 
noisyNet noise sample is [array([0.20769852], dtype=float32), 2.1445656]. 
=============================================
[2019-03-24 04:36:58,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[35.84156 ]
 [35.171326]
 [35.857567]
 [35.968834]
 [35.821587]], R is [[36.30703354]
 [35.9439621 ]
 [35.58452225]
 [35.56348419]
 [35.57916641]].
[2019-03-24 04:36:59,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0048991e-29 1.0000000e+00 3.9398026e-25 6.1758104e-16 3.3731045e-19], sum to 1.0000
[2019-03-24 04:36:59,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8891
[2019-03-24 04:36:59,953] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 85.0, 1.0, 2.0, 0.781851595967815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891143.8754305083, 891143.8754305083, 192224.6056568392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5434200.0000, 
sim time next is 5434800.0000, 
raw observation next is [28.03333333333333, 85.33333333333333, 1.0, 2.0, 0.7804858316940452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 889586.2923229545, 889586.292322954, 191946.7917800127], 
processed observation next is [1.0, 0.9130434782608695, 0.5938271604938271, 0.8533333333333333, 1.0, 1.0, 0.7386736091595776, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3177093901153409, 0.3177093901153407, 0.3691284457307936], 
reward next is 0.6309, 
noisyNet noise sample is [array([-0.95535815], dtype=float32), -0.57457036]. 
=============================================
[2019-03-24 04:37:05,683] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0242039e-20 1.0000000e+00 9.8229716e-18 5.1835977e-13 7.1552744e-15], sum to 1.0000
[2019-03-24 04:37:05,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4559
[2019-03-24 04:37:05,699] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.38333333333333, 87.5, 1.0, 2.0, 0.6444664657036133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735153.4002993043, 735153.4002993043, 165929.0557760294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5554200.0000, 
sim time next is 5554800.0000, 
raw observation next is [25.4, 87.0, 1.0, 2.0, 0.6539071079498567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 746813.552183487, 746813.5521834865, 167678.3022111263], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.87, 1.0, 1.0, 0.587984652321258, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26671912577981677, 0.2667191257798166, 0.3224582734829352], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.79194814], dtype=float32), -1.3407679]. 
=============================================
[2019-03-24 04:37:08,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8256799e-31 1.0000000e+00 5.7627175e-27 5.3939083e-19 1.1417219e-23], sum to 1.0000
[2019-03-24 04:37:08,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1378
[2019-03-24 04:37:08,539] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.81666666666667, 97.66666666666667, 1.0, 2.0, 0.623688629467433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715064.8492438524, 715064.8492438524, 162411.9918681989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5611800.0000, 
sim time next is 5612400.0000, 
raw observation next is [23.7, 98.0, 1.0, 2.0, 0.6181320833556029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709895.7011676447, 709895.7011676447, 161492.7954590132], 
processed observation next is [1.0, 1.0, 0.4333333333333333, 0.98, 1.0, 1.0, 0.5453953373280986, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25353417898844455, 0.25353417898844455, 0.31056306819041], 
reward next is 0.6894, 
noisyNet noise sample is [array([0.45209715], dtype=float32), -0.062349595]. 
=============================================
[2019-03-24 04:37:11,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.22264643e-25 1.00000000e+00 1.48319734e-21 1.34309175e-17
 4.20645867e-18], sum to 1.0000
[2019-03-24 04:37:11,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3692
[2019-03-24 04:37:11,827] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 72.0, 1.0, 2.0, 0.7127121601137607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 812297.921161992, 812297.9211619915, 178566.9614500222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5666400.0000, 
sim time next is 5667000.0000, 
raw observation next is [29.48333333333333, 71.66666666666667, 1.0, 2.0, 0.7138209619893799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813562.3242678294, 813562.3242678294, 178779.5177369746], 
processed observation next is [0.0, 0.6086956521739131, 0.6475308641975308, 0.7166666666666667, 1.0, 1.0, 0.6593106690349761, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29055797295279623, 0.29055797295279623, 0.3438067648787973], 
reward next is 0.6562, 
noisyNet noise sample is [array([-0.8622614], dtype=float32), 0.8849365]. 
=============================================
[2019-03-24 04:37:11,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[61.899597]
 [61.856052]
 [61.817524]
 [61.78255 ]
 [61.757164]], R is [[61.93896484]
 [61.97617722]
 [62.01341629]
 [62.05071259]
 [62.08805847]].
[2019-03-24 04:37:12,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6749788e-30 1.0000000e+00 2.5905830e-27 1.0837338e-18 1.2409087e-21], sum to 1.0000
[2019-03-24 04:37:12,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0569
[2019-03-24 04:37:12,890] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.0, 1.0, 2.0, 0.6452064369562609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 735968.8735550363, 735968.8735550359, 166060.4287235766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5695200.0000, 
sim time next is 5695800.0000, 
raw observation next is [24.76666666666667, 90.33333333333333, 1.0, 2.0, 0.6309276897266448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722789.8126126674, 722789.8126126674, 163665.3825097377], 
processed observation next is [0.0, 0.9565217391304348, 0.4728395061728396, 0.9033333333333333, 1.0, 1.0, 0.5606282020555295, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2581392187902384, 0.2581392187902384, 0.31474112021103406], 
reward next is 0.6853, 
noisyNet noise sample is [array([2.1828253], dtype=float32), -0.33665404]. 
=============================================
[2019-03-24 04:37:18,235] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1611254e-29 1.0000000e+00 1.2189271e-23 2.2129401e-17 8.2338269e-20], sum to 1.0000
[2019-03-24 04:37:18,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7575
[2019-03-24 04:37:18,247] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 81.0, 1.0, 2.0, 0.5277349568016794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 624472.8152208704, 624472.8152208704, 147129.9801931382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5779800.0000, 
sim time next is 5780400.0000, 
raw observation next is [24.4, 81.33333333333334, 1.0, 2.0, 0.5249300165789202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621748.1479401478, 621748.1479401478, 146700.8110770863], 
processed observation next is [0.0, 0.9130434782608695, 0.4592592592592592, 0.8133333333333335, 1.0, 1.0, 0.434440495927286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2220529099786242, 0.2220529099786242, 0.28211694437901214], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.4837125], dtype=float32), -0.3005875]. 
=============================================
[2019-03-24 04:37:19,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7345266e-19 1.0000000e+00 2.7415747e-17 1.3072303e-10 5.6061628e-13], sum to 1.0000
[2019-03-24 04:37:19,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4370
[2019-03-24 04:37:19,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 51.66666666666667, 1.0, 2.0, 0.8038611481686216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002318.159794572, 1002318.159794572, 200159.3302327861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5826000.0000, 
sim time next is 5826600.0000, 
raw observation next is [25.9, 50.0, 1.0, 2.0, 0.8053030910823387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1005886.322428261, 1005886.322428261, 200504.2384916426], 
processed observation next is [1.0, 0.43478260869565216, 0.5148148148148147, 0.5, 1.0, 1.0, 0.7682179655742127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3592451151529504, 0.3592451151529504, 0.3855850740223896], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.5338008], dtype=float32), -0.074961126]. 
=============================================
[2019-03-24 04:37:21,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.15981674e-30 1.00000000e+00 1.57714095e-27 4.71176242e-19
 6.78350403e-22], sum to 1.0000
[2019-03-24 04:37:21,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2985
[2019-03-24 04:37:21,943] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 71.0, 1.0, 2.0, 0.4180151406937834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514446.9521744305, 514446.9521744301, 131102.2429836291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5866200.0000, 
sim time next is 5866800.0000, 
raw observation next is [23.36666666666667, 72.0, 1.0, 2.0, 0.4177657386318819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514354.4956425749, 514354.4956425749, 131071.8150024714], 
processed observation next is [1.0, 0.9130434782608695, 0.4209876543209878, 0.72, 1.0, 1.0, 0.3068639745617642, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18369803415806246, 0.18369803415806246, 0.2520611826970604], 
reward next is 0.7479, 
noisyNet noise sample is [array([-0.88311154], dtype=float32), -1.1261133]. 
=============================================
[2019-03-24 04:37:25,942] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0946286e-25 1.0000000e+00 3.1678982e-23 2.2268386e-15 1.4311761e-17], sum to 1.0000
[2019-03-24 04:37:25,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1694
[2019-03-24 04:37:25,965] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 59.66666666666667, 1.0, 2.0, 0.4784061307481156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575298.3605007052, 575298.3605007057, 139710.2859866318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5944200.0000, 
sim time next is 5944800.0000, 
raw observation next is [26.93333333333334, 60.33333333333334, 1.0, 2.0, 0.4787427784785689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575769.0626480659, 575769.0626480659, 139764.2841689015], 
processed observation next is [1.0, 0.8260869565217391, 0.5530864197530867, 0.6033333333333334, 1.0, 1.0, 0.379455688664963, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20563180808859494, 0.20563180808859494, 0.2687774695555798], 
reward next is 0.7312, 
noisyNet noise sample is [array([0.6484958], dtype=float32), -0.13266711]. 
=============================================
[2019-03-24 04:37:27,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9233882e-24 1.0000000e+00 1.0923492e-20 7.1242459e-13 9.3215584e-16], sum to 1.0000
[2019-03-24 04:37:27,344] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6089
[2019-03-24 04:37:27,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1493018.746489468 W.
[2019-03-24 04:37:27,359] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.13333333333334, 47.5, 1.0, 2.0, 0.6334502945000131, 1.0, 2.0, 0.6334502945000131, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1493018.746489468, 1493018.746489468, 282002.5413815589], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5932200.0000, 
sim time next is 5932800.0000, 
raw observation next is [29.1, 48.0, 1.0, 2.0, 0.4167454429666881, 1.0, 2.0, 0.4167454429666881, 1.0, 1.0, 0.6654986757385816, 6.911200000000001, 6.9112, 121.94756008, 1458497.114012398, 1458497.114012397, 304565.2654673317], 
processed observation next is [1.0, 0.6956521739130435, 0.6333333333333334, 0.48, 1.0, 1.0, 0.3056493368651049, 1.0, 1.0, 0.3056493368651049, 1.0, 0.5, 0.5818733446732269, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5208918264329994, 0.5208918264329989, 0.5857024335910225], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7832245], dtype=float32), -0.394794]. 
=============================================
[2019-03-24 04:37:29,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7801408e-19 1.0000000e+00 2.0220667e-16 4.8542685e-12 3.9960426e-13], sum to 1.0000
[2019-03-24 04:37:29,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4544
[2019-03-24 04:37:29,851] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 64.66666666666667, 1.0, 2.0, 0.3737899854919274, 1.0, 1.0, 0.3737899854919274, 1.0, 2.0, 0.5950858303931003, 6.911199999999999, 6.9112, 121.94756008, 1278444.972338377, 1278444.972338377, 285791.1394045256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6006000.0000, 
sim time next is 6006600.0000, 
raw observation next is [28.5, 64.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.65109045024996, 6.9112, 121.9231017699573, 1548036.671597089, 1169155.769206418, 245932.1777336638], 
processed observation next is [1.0, 0.5217391304347826, 0.6111111111111112, 0.64, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.073989045024996, 0.0, 0.8094426046629221, 0.5528702398561032, 0.417555631859435, 0.47294649564166114], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07203176], dtype=float32), 0.20563987]. 
=============================================
[2019-03-24 04:37:34,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3309989e-21 1.0000000e+00 1.2338774e-18 1.4695187e-12 7.3990727e-14], sum to 1.0000
[2019-03-24 04:37:34,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5589
[2019-03-24 04:37:34,599] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2029775.47104266 W.
[2019-03-24 04:37:34,603] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.4, 53.0, 1.0, 2.0, 0.593196963936662, 1.0, 2.0, 0.593196963936662, 1.0, 2.0, 0.9443888856635464, 6.9112, 6.9112, 121.94756008, 2029775.47104266, 2029775.47104266, 391681.4091883508], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6102000.0000, 
sim time next is 6102600.0000, 
raw observation next is [30.35, 53.16666666666667, 1.0, 2.0, 0.8056184232514899, 1.0, 2.0, 0.8056184232514899, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1837556.121074164, 1837556.121074164, 346080.0695375355], 
processed observation next is [1.0, 0.6521739130434783, 0.6796296296296297, 0.5316666666666667, 1.0, 1.0, 0.7685933610136785, 1.0, 1.0, 0.7685933610136785, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6562700432407729, 0.6562700432407729, 0.6655385952644913], 
reward next is 0.3345, 
noisyNet noise sample is [array([0.3948801], dtype=float32), 0.11547215]. 
=============================================
[2019-03-24 04:37:43,749] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 04:37:43,751] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:37:43,753] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:37:43,753] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:43,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:43,754] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:37:43,755] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:37:43,758] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:43,760] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:43,757] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:37:43,763] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:43,781] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 04:37:43,809] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 04:37:43,839] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 04:37:43,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 04:37:43,865] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/39/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 04:37:52,853] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1614602]
[2019-03-24 04:37:52,854] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.41666666666667, 67.0, 1.0, 2.0, 0.3437864480133992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437053.6151384575, 437053.6151384575, 121149.2683511697]
[2019-03-24 04:37:52,855] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:37:52,858] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.4018366e-29 1.0000000e+00 2.9775742e-25 7.8951213e-17 1.1968174e-20], sampled 0.02147154884623148
[2019-03-24 04:37:53,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1614602]
[2019-03-24 04:37:53,723] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.8224165, 49.94907577666667, 1.0, 2.0, 0.3229705934126436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408567.5858902519, 408567.5858902523, 118436.6538276807]
[2019-03-24 04:37:53,723] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:37:53,726] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.3708822e-30 1.0000000e+00 5.5739901e-26 2.6862002e-17 3.1545639e-21], sampled 0.5901643682997024
[2019-03-24 04:38:10,875] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1614602]
[2019-03-24 04:38:10,876] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.25, 86.0, 1.0, 2.0, 0.4857111461451438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 599133.738293029, 599133.7382930286, 141283.6879241329]
[2019-03-24 04:38:10,877] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:38:10,879] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2192605e-29 1.0000000e+00 3.4511491e-25 8.6817846e-17 1.3458850e-20], sampled 0.7563206019167172
[2019-03-24 04:38:38,519] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1614602]
[2019-03-24 04:38:38,520] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 81.5, 1.0, 2.0, 0.8124638709868782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926056.4133388516, 926056.4133388516, 198539.0607898328]
[2019-03-24 04:38:38,521] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:38:38,525] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8590780e-30 1.0000000e+00 4.4073542e-26 2.3099498e-17 2.6171015e-21], sampled 0.8408677486881084
[2019-03-24 04:39:04,972] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01210835], dtype=float32), 1.1614602]
[2019-03-24 04:39:04,973] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.43333333333333, 73.33333333333334, 1.0, 2.0, 0.466039776454759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 563414.9664360848, 563414.9664360844, 137922.6640274343]
[2019-03-24 04:39:04,974] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:39:04,976] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.004353e-30 1.000000e+00 7.524180e-26 3.258235e-17 4.005580e-21], sampled 0.16723131864687313
[2019-03-24 04:39:28,637] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 04:39:28,714] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 04:39:28,793] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 04:39:28,984] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 04:39:29,158] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 04:39:30,174] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2500000, evaluation results [2500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
