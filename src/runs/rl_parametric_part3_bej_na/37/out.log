Using TensorFlow backend.
[2019-03-23 20:02:50,128] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-23 20:02:50,128] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 20:02:50.225932: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 20:03:24,455] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 20:03:24,455] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-23 20:03:24,469] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 20:03:24,473] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 20:03:24,477] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 20:03:24,481] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 20:03:24,488] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 20:03:24,488] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:24,489] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 20:03:24,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:24,599] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 20:03:25,489] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:25,492] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 20:03:25,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:25,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 20:03:26,046] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 20:03:26,046] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:03:26,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:03:26,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,047] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:03:26,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:03:26,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,048] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:03:26,048] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,048] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,049] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,052] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 20:03:26,066] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 20:03:26,066] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 20:03:26,088] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 20:03:26,105] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 20:03:26,493] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:26,494] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 20:03:26,603] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:26,603] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 20:03:27,495] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:27,496] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 20:03:27,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:27,784] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 20:03:28,496] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:28,497] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 20:03:28,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:28,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 20:03:29,499] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:29,502] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 20:03:29,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:29,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 20:03:30,501] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:30,503] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 20:03:30,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:30,635] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 20:03:31,503] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:31,508] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 20:03:32,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:32,009] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 20:03:32,507] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:32,512] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 20:03:32,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:32,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 20:03:33,513] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:33,515] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 20:03:33,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:33,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 20:03:34,516] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:34,521] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 20:03:34,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:34,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 20:03:35,521] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:35,527] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 20:03:35,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:35,686] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 20:03:36,524] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:36,530] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 20:03:36,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:36,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 20:03:37,529] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:37,533] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 20:03:37,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:37,670] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 20:03:38,532] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:38,538] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 20:03:38,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:38,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 20:03:39,536] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 20:03:39,541] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 20:03:39,667] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:03:39,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 20:03:51,327] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:03:51,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.25, 55.5, 1.0, 2.0, 0.5295668350277551, 1.0, 2.0, 0.5295668350277551, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156388, 1276093.606617854, 1276093.606617854, 247583.6048750188]
[2019-03-23 20:03:51,329] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:03:51,331] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20034486 0.20470372 0.20047423 0.19390845 0.20056875], sampled 0.3645690587374699
[2019-03-23 20:04:07,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:07,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.87002791, 34.052644455, 1.0, 2.0, 0.3133536699167016, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 400884.0707891467, 400884.0707891462, 117242.0808044192]
[2019-03-23 20:04:07,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:04:07,864] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20400968 0.20708802 0.19466737 0.19417794 0.20005694], sampled 0.8190203936762268
[2019-03-23 20:04:37,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:37,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.15855512, 96.10689663, 1.0, 2.0, 0.2466251368492554, 1.0, 1.0, 0.2466251368492554, 1.0, 2.0, 0.3926352498839772, 6.9112, 6.9112, 121.94756008, 843273.5840837953, 843273.5840837953, 236431.9317313017]
[2019-03-23 20:04:37,445] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:04:37,447] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20349386 0.20071937 0.20232606 0.1954764  0.19798426], sampled 0.5785238070079896
[2019-03-23 20:04:39,693] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:39,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.69843986666667, 94.17306608, 1.0, 2.0, 0.1808902394399188, 1.0, 2.0, 0.1808902394399188, 1.0, 1.0, 0.2886550706675842, 6.911200000000001, 6.9112, 121.94756008, 630633.6650715503, 630633.6650715498, 214405.4288535087]
[2019-03-23 20:04:39,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:04:39,700] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20061052 0.1990095  0.20518324 0.19497427 0.2002225 ], sampled 0.03797903295418548
[2019-03-23 20:04:45,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:45,903] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 91.5, 1.0, 2.0, 0.355546831412076, 1.0, 2.0, 0.355546831412076, 1.0, 1.0, 0.5660421349599274, 6.911200000000001, 6.9112, 121.94756008, 1215999.808946277, 1215999.808946277, 278157.1929533785]
[2019-03-23 20:04:45,904] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:04:45,905] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20283468 0.20297764 0.19869076 0.19821258 0.19728442], sampled 0.46038455704737447
[2019-03-23 20:04:49,856] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:49,856] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.31231590833333, 75.59631221833334, 1.0, 2.0, 0.3451175392406978, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5494383621647602, 6.911199999999999, 6.9112, 121.9260426156618, 786667.0182667038, 786667.0182667043, 207770.463303967]
[2019-03-23 20:04:49,857] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:04:49,858] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20233865 0.20802023 0.19443643 0.19550988 0.1996948 ], sampled 0.3466085111541146
[2019-03-23 20:04:50,750] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 20:04:50,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.26898404, 91.00856543, 1.0, 2.0, 0.6897734825548256, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 786140.6635249988, 786140.6635249984, 174219.1054013793]
[2019-03-23 20:04:50,754] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:04:50,756] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20231146 0.2038328  0.20027892 0.19583721 0.19773962], sampled 0.799522106133479
[2019-03-23 20:05:19,617] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 3995.2766 2469180795.3025 251.0000
[2019-03-23 20:05:19,809] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3783.4989 2536998608.8734 320.0000
[2019-03-23 20:05:19,844] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3885.8769 2716393632.9201 429.0000
[2019-03-23 20:05:19,852] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3916.7371 2488627670.6780 312.0000
[2019-03-23 20:05:19,854] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 3998.4453 2435139465.7514 234.0000
[2019-03-23 20:05:20,892] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3885.876933697917, 2716393632.920104, 429.0, 3995.276597852072, 2469180795.302451, 251.0, 3998.445330188137, 2435139465.751397, 234.0, 3783.4988944841703, 2536998608.873417, 320.0, 3916.737114261199, 2488627670.6780148, 312.0]
[2019-03-23 20:05:24,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.21106373 0.20992026 0.19380042 0.19062571 0.19458993], sum to 1.0000
[2019-03-23 20:05:24,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2637
[2019-03-23 20:05:25,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.45, 75.5, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2601082082702449, 6.911199999999999, 6.9112, 121.9260426156618, 374044.2583001362, 374044.2583001367, 150752.6912699187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9000.0000, 
sim time next is 9600.0000, 
raw observation next is [18.4, 75.66666666666667, 1.0, 2.0, 0.3048255914320697, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 392969.4682731695, 392969.4682731699, 113660.1424923167], 
processed observation next is [1.0, 0.08695652173913043, 0.237037037037037, 0.7566666666666667, 1.0, 1.0, 0.17241141837151158, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1403462386689891, 0.14034623866898924, 0.21857719710060905], 
reward next is 0.7814, 
noisyNet noise sample is [array([0.25311238], dtype=float32), 0.3670358]. 
=============================================
[2019-03-23 20:05:27,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.00757903 0.07944673 0.2482053  0.2332738  0.4314952 ], sum to 1.0000
[2019-03-23 20:05:27,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-23 20:05:27,256] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333334, 36.66666666666667, 1.0, 2.0, 0.5602393237752398, 1.0, 2.0, 0.5602393237752398, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425246908, 1358019.417768223, 1358019.417768222, 258004.1540513023], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 49200.0000, 
sim time next is 49800.0000, 
raw observation next is [30.01666666666667, 36.33333333333333, 1.0, 2.0, 0.3770810931896948, 1.0, 2.0, 0.3770810931896948, 1.0, 1.0, 0.6093144534664126, 6.9112, 6.9112, 121.94756008, 1359693.885757341, 1359693.885757341, 286661.552935634], 
processed observation next is [1.0, 0.5652173913043478, 0.6672839506172841, 0.3633333333333333, 1.0, 1.0, 0.2584298728448748, 1.0, 1.0, 0.2584298728448748, 1.0, 0.5, 0.5116430668330156, 0.0, 0.0, 0.8096049824067558, 0.4856049591990504, 0.4856049591990504, 0.5512722171839115], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20749624], dtype=float32), -0.42191914]. 
=============================================
[2019-03-23 20:05:30,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1269161e-21 7.4270119e-14 1.0000000e+00 1.3541020e-08 1.4954322e-17], sum to 1.0000
[2019-03-23 20:05:30,436] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-23 20:05:30,606] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.3, 74.0, 1.0, 2.0, 0.2081142472795128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3446007699977607, 6.911199999999999, 6.9112, 121.9260426156618, 514799.7847577648, 514799.7847577652, 169439.382896014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 111600.0000, 
sim time next is 112200.0000, 
raw observation next is [22.4, 73.83333333333334, 1.0, 2.0, 0.2077305582244214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3436273476618399, 6.911199999999999, 6.9112, 121.9260426156618, 513406.8752364876, 513406.875236488, 169411.6919684632], 
processed observation next is [1.0, 0.30434782608695654, 0.38518518518518513, 0.7383333333333334, 1.0, 1.0, 0.0568220931243112, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.17953418457729983, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18335959829874557, 0.1833595982987457, 0.32579171532396767], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.21531336], dtype=float32), -0.77902657]. 
=============================================
[2019-03-23 20:05:31,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.03599431 0.03566026 0.7342191  0.13580294 0.05832342], sum to 1.0000
[2019-03-23 20:05:31,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4780
[2019-03-23 20:05:31,758] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.56666666666666, 30.66666666666667, 1.0, 2.0, 0.5086989942197461, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8190527565680266, 6.911199999999999, 6.9112, 121.9260426156618, 1214580.639255851, 1214580.639255851, 258586.6394029246], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 130800.0000, 
sim time next is 131400.0000, 
raw observation next is [33.95, 29.0, 1.0, 2.0, 0.4827455386975722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7791783118231623, 6.911199999999999, 6.9112, 121.9260426156618, 1158020.453999605, 1158020.453999605, 249378.3679008698], 
processed observation next is [1.0, 0.5217391304347826, 0.8129629629629631, 0.29, 1.0, 1.0, 0.38422087940187166, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7239728897789529, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4135787335712875, 0.4135787335712875, 0.4795737844247496], 
reward next is 0.5204, 
noisyNet noise sample is [array([0.5713881], dtype=float32), 0.77759385]. 
=============================================
[2019-03-23 20:05:34,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.34529823 0.17503615 0.16726175 0.22584173 0.08656222], sum to 1.0000
[2019-03-23 20:05:34,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9201
[2019-03-23 20:05:34,853] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.16666666666667, 44.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 1.0, 0.2, 6.9112, 6.9112, 121.94756008, 334725.0707237558, 334725.0707237558, 148214.0008036235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 188400.0000, 
sim time next is 189000.0000, 
raw observation next is [20.8, 46.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 329975.2542815699, 329975.2542815694, 147369.8233589908], 
processed observation next is [0.0, 0.17391304347826086, 0.32592592592592595, 0.465, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.11784830510056069, 0.11784830510056049, 0.2834035064595977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10152237], dtype=float32), 1.4239621]. 
=============================================
[2019-03-23 20:05:34,867] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[2.2308092]
 [2.1991122]
 [2.2206507]
 [2.2208874]
 [2.2343695]], R is [[2.17968607]
 [2.15788913]
 [2.13631034]
 [2.11494732]
 [2.91502738]].
[2019-03-23 20:05:38,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 20:05:38,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3788
[2019-03-23 20:05:38,410] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239918434096792, 6.911200000000001, 6.9112, 121.9260426156618, 374139.5886065595, 374139.588606559, 114517.5248218611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 256200.0000, 
sim time next is 256800.0000, 
raw observation next is [23.4, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204962167637406, 6.911200000000001, 6.9112, 121.9260426156618, 371642.8973881138, 371642.8973881133, 113480.1057446777], 
processed observation next is [0.0, 1.0, 0.42222222222222217, 0.4466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4006202709546757, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13272960621004062, 0.13272960621004046, 0.21823097258591864], 
reward next is 0.7818, 
noisyNet noise sample is [array([1.1726972], dtype=float32), -0.46004307]. 
=============================================
[2019-03-23 20:05:38,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.98279572e-01 1.14508104e-04 1.34443981e-03 2.49552628e-04
 1.20163040e-05], sum to 1.0000
[2019-03-23 20:05:38,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0076
[2019-03-23 20:05:38,723] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5280255175135138, 6.911199999999999, 6.9112, 121.9260426156618, 377022.3170129617, 377022.3170129622, 115615.3708897531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 255600.0000, 
sim time next is 256200.0000, 
raw observation next is [23.55, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239918434096792, 6.911200000000001, 6.9112, 121.9260426156618, 374139.5886065595, 374139.588606559, 114517.5248218611], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.4433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40498980426209896, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13362128164519982, 0.13362128164519962, 0.2202260092728098], 
reward next is 0.7798, 
noisyNet noise sample is [array([0.03280228], dtype=float32), -1.2954001]. 
=============================================
[2019-03-23 20:05:40,300] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7744: loss 2.2192
[2019-03-23 20:05:40,383] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7744: learning rate 0.0010
[2019-03-23 20:05:40,531] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7829: loss 0.6628
[2019-03-23 20:05:40,533] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7829: learning rate 0.0010
[2019-03-23 20:05:40,613] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7876: loss 0.4661
[2019-03-23 20:05:40,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7876: learning rate 0.0010
[2019-03-23 20:05:40,630] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7884: loss 2.5649
[2019-03-23 20:05:40,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7884: learning rate 0.0010
[2019-03-23 20:05:40,730] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7937: loss 75.6455
[2019-03-23 20:05:40,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7938: learning rate 0.0010
[2019-03-23 20:05:40,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7348401e-29 2.7990044e-20 3.7394869e-27 6.4853186e-38], sum to 1.0000
[2019-03-23 20:05:40,791] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7966: loss 19.6925
[2019-03-23 20:05:40,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7966: learning rate 0.0010
[2019-03-23 20:05:40,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0711
[2019-03-23 20:05:40,803] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.95, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.538156056579611, 6.911199999999999, 6.9112, 121.9260426156618, 384255.4609591938, 384255.4609591943, 106524.2357156481], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 293400.0000, 
sim time next is 294000.0000, 
raw observation next is [25.06666666666667, 31.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5427664894204287, 6.9112, 6.9112, 121.9260426156618, 387548.2449174188, 387548.2449174188, 107105.9544939199], 
processed observation next is [0.0, 0.391304347826087, 0.4839506172839507, 0.3166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42845811177553583, 0.0, 0.0, 0.8094621288201359, 0.1384100874705067, 0.1384100874705067, 0.20597298941138442], 
reward next is 0.7940, 
noisyNet noise sample is [array([0.04956494], dtype=float32), -0.562652]. 
=============================================
[2019-03-23 20:05:40,809] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7975: loss 4.3350
[2019-03-23 20:05:40,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7976: learning rate 0.0010
[2019-03-23 20:05:40,817] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7976: loss 2.7098
[2019-03-23 20:05:40,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7977: learning rate 0.0010
[2019-03-23 20:05:40,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[106.2311 ]
 [106.13893]
 [106.10679]
 [106.0856 ]
 [106.00466]], R is [[106.02820587]
 [105.76306915]
 [105.50164795]
 [105.24342346]
 [104.98858643]].
[2019-03-23 20:05:40,884] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8014: loss 0.0037
[2019-03-23 20:05:40,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8014: learning rate 0.0010
[2019-03-23 20:05:40,900] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8025: loss 0.0222
[2019-03-23 20:05:40,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8025: learning rate 0.0010
[2019-03-23 20:05:40,918] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8031: loss 0.3087
[2019-03-23 20:05:40,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8031: learning rate 0.0010
[2019-03-23 20:05:40,936] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8041: loss 0.2950
[2019-03-23 20:05:40,939] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8041: learning rate 0.0010
[2019-03-23 20:05:40,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8053: loss 2.2872
[2019-03-23 20:05:40,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8054: learning rate 0.0010
[2019-03-23 20:05:41,107] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8129: loss 1.8337
[2019-03-23 20:05:41,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8129: learning rate 0.0010
[2019-03-23 20:05:41,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8133: loss 0.3894
[2019-03-23 20:05:41,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8134: learning rate 0.0010
[2019-03-23 20:05:41,261] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8206: loss 1.1644
[2019-03-23 20:05:41,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8206: learning rate 0.0010
[2019-03-23 20:05:42,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5659583e-22 8.2300090e-17 1.8224252e-19 4.0164580e-29], sum to 1.0000
[2019-03-23 20:05:42,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2866
[2019-03-23 20:05:42,528] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 35.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5654946330453411, 6.9112, 6.9112, 121.9260426156618, 407263.9652991864, 407263.9652991864, 121416.0662239165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 330000.0000, 
sim time next is 330600.0000, 
raw observation next is [26.21666666666667, 35.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5635805932896951, 6.911199999999999, 6.9112, 121.9260426156618, 405679.3099143428, 405679.3099143432, 121186.0057761372], 
processed observation next is [0.0, 0.8260869565217391, 0.5265432098765432, 0.3566666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45447574161211884, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.144885467826551, 0.14488546782655112, 0.23305001110795615], 
reward next is 0.7669, 
noisyNet noise sample is [array([0.5218606], dtype=float32), 1.3179517]. 
=============================================
[2019-03-23 20:05:42,553] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.3092333e-19 2.9638065e-13 1.1569395e-16 1.4034737e-24], sum to 1.0000
[2019-03-23 20:05:42,562] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6359
[2019-03-23 20:05:42,734] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.45, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204845766123368, 6.911200000000001, 6.9112, 121.9260426156618, 371634.7554156821, 371634.7554156816, 115646.6610770056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 342600.0000, 
sim time next is 343200.0000, 
raw observation next is [23.3, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5148135357739823, 6.9112, 6.9112, 121.9260426156618, 367584.3988154322, 367584.3988154322, 114692.6635040388], 
processed observation next is [0.0, 1.0, 0.41851851851851857, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39351691971747776, 0.0, 0.0, 0.8094621288201359, 0.13128014243408292, 0.13128014243408292, 0.22056281443084386], 
reward next is 0.7794, 
noisyNet noise sample is [array([0.89124733], dtype=float32), 0.8355569]. 
=============================================
[2019-03-23 20:05:43,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 8.1236100e-33 8.2566539e-22 1.4052701e-29 0.0000000e+00], sum to 1.0000
[2019-03-23 20:05:43,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-23 20:05:43,273] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.85, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5053755599489425, 6.911199999999999, 6.9112, 121.9260426156618, 360843.946708479, 360843.9467084795, 112404.6663422766], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 345000.0000, 
sim time next is 345600.0000, 
raw observation next is [22.7, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.502543295436406, 6.9112, 6.9112, 121.9260426156618, 358821.2042698291, 358821.2042698291, 111663.2569125693], 
processed observation next is [1.0, 0.0, 0.39629629629629626, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3781791192955074, 0.0, 0.0, 0.8094621288201359, 0.12815043009636753, 0.12815043009636753, 0.21473703252417173], 
reward next is 0.7853, 
noisyNet noise sample is [array([1.0598575], dtype=float32), 0.01618411]. 
=============================================
[2019-03-23 20:05:47,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5783912e-11 1.0344231e-07 1.7420247e-02 9.8257887e-01 6.6136533e-07], sum to 1.0000
[2019-03-23 20:05:47,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7578
[2019-03-23 20:05:47,717] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.65, 39.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392287.7345594974, 392287.7345594974, 149648.9846316169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 427800.0000, 
sim time next is 428400.0000, 
raw observation next is [25.5, 40.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 391159.6595948214, 391159.6595948219, 149449.1815206387], 
processed observation next is [1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13969987842672194, 0.1396998784267221, 0.2874022721550744], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.853219], dtype=float32), 0.08460211]. 
=============================================
[2019-03-23 20:05:56,085] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15739: loss 0.0208
[2019-03-23 20:05:56,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15739: learning rate 0.0010
[2019-03-23 20:05:56,252] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15824: loss 2.9977
[2019-03-23 20:05:56,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15824: learning rate 0.0010
[2019-03-23 20:05:56,263] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15829: loss 2.8520
[2019-03-23 20:05:56,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15829: learning rate 0.0010
[2019-03-23 20:05:56,308] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15850: loss 0.4864
[2019-03-23 20:05:56,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15850: learning rate 0.0010
[2019-03-23 20:05:56,359] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15878: loss 0.0152
[2019-03-23 20:05:56,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15878: learning rate 0.0010
[2019-03-23 20:05:56,410] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15906: loss 0.0014
[2019-03-23 20:05:56,412] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15906: learning rate 0.0010
[2019-03-23 20:05:56,581] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15993: loss 0.4399
[2019-03-23 20:05:56,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15993: learning rate 0.0010
[2019-03-23 20:05:56,619] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16012: loss 0.1918
[2019-03-23 20:05:56,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16012: learning rate 0.0010
[2019-03-23 20:05:56,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16032: loss 0.1148
[2019-03-23 20:05:56,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16032: learning rate 0.0010
[2019-03-23 20:05:56,657] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16034: loss 0.0028
[2019-03-23 20:05:56,660] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16035: learning rate 0.0010
[2019-03-23 20:05:56,698] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16055: loss 0.0612
[2019-03-23 20:05:56,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16055: learning rate 0.0010
[2019-03-23 20:05:56,770] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16092: loss 3.3803
[2019-03-23 20:05:56,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16093: learning rate 0.0010
[2019-03-23 20:05:56,802] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16109: loss 1.4640
[2019-03-23 20:05:56,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16109: learning rate 0.0010
[2019-03-23 20:05:56,850] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16136: loss 1.5275
[2019-03-23 20:05:56,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16138: learning rate 0.0010
[2019-03-23 20:05:56,880] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16152: loss 0.3434
[2019-03-23 20:05:56,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16152: learning rate 0.0010
[2019-03-23 20:05:56,932] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16177: loss 0.0658
[2019-03-23 20:05:56,938] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16177: learning rate 0.0010
[2019-03-23 20:06:02,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8367982e-11 7.8136206e-13 1.5709977e-04 9.9984288e-01 1.8191621e-16], sum to 1.0000
[2019-03-23 20:06:02,778] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-23 20:06:02,784] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 54.0, 1.0, 2.0, 0.2493086005891428, 1.0, 2.0, 0.2493086005891428, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 622423.8085279465, 622423.8085279469, 170841.8807412288], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 720000.0000, 
sim time next is 720600.0000, 
raw observation next is [24.63333333333333, 53.83333333333333, 1.0, 2.0, 0.3379791566318699, 1.0, 2.0, 0.3379791566318699, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 841185.0486894961, 841185.0486894958, 192447.5099296997], 
processed observation next is [1.0, 0.34782608695652173, 0.46790123456790106, 0.5383333333333333, 1.0, 1.0, 0.2118799483712737, 1.0, 1.0, 0.2118799483712737, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30042323167482005, 0.30042323167481993, 0.3700913652494225], 
reward next is 0.6299, 
noisyNet noise sample is [array([0.44029567], dtype=float32), 0.4545704]. 
=============================================
[2019-03-23 20:06:03,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8969580e-09 1.9256674e-10 1.4752727e-06 9.9999857e-01 2.6738318e-09], sum to 1.0000
[2019-03-23 20:06:03,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8341
[2019-03-23 20:06:03,297] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 53.0, 1.0, 2.0, 0.4104599621636336, 1.0, 2.0, 0.4104599621636336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1006641.758695663, 1006641.758695664, 211855.5173096073], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 725400.0000, 
sim time next is 726000.0000, 
raw observation next is [25.83333333333334, 53.0, 1.0, 2.0, 0.4630790652952538, 1.0, 2.0, 0.4630790652952538, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1132727.432039743, 1132727.432039743, 227249.1050728451], 
processed observation next is [1.0, 0.391304347826087, 0.5123456790123458, 0.53, 1.0, 1.0, 0.36080841106577827, 1.0, 1.0, 0.36080841106577827, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4045455114427654, 0.4045455114427654, 0.4370175097554713], 
reward next is 0.5630, 
noisyNet noise sample is [array([-0.13924341], dtype=float32), 0.81874955]. 
=============================================
[2019-03-23 20:06:03,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[47.126022]
 [47.126022]
 [47.126022]
 [47.126022]
 [47.126022]], R is [[47.21773911]
 [47.33815002]
 [47.45798492]
 [47.55663681]
 [47.62371063]].
[2019-03-23 20:06:06,496] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999845e-01 4.2060063e-07 7.2487489e-07 1.2270189e-07 2.2955432e-07], sum to 1.0000
[2019-03-23 20:06:06,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-23 20:06:06,510] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5281857520989471, 6.9112, 6.9112, 121.9260426156618, 385227.3456431892, 385227.3456431892, 120258.3575394967], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 794400.0000, 
sim time next is 795000.0000, 
raw observation next is [22.66666666666667, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5296290722715871, 6.9112, 6.9112, 121.9260426156618, 386387.4712092518, 386387.4712092518, 120422.7472328161], 
processed observation next is [0.0, 0.17391304347826086, 0.39506172839506193, 0.575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4120363403394838, 0.0, 0.0, 0.8094621288201359, 0.13799552543187563, 0.13799552543187563, 0.23158220621695402], 
reward next is 0.7684, 
noisyNet noise sample is [array([0.6094816], dtype=float32), 1.2843863]. 
=============================================
[2019-03-23 20:06:06,532] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[15.175119]
 [15.175119]
 [15.175119]
 [15.175119]
 [15.175119]], R is [[15.79178619]
 [16.40260124]
 [17.00745392]
 [17.60629845]
 [17.43023491]].
[2019-03-23 20:06:10,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.5476127e-23 3.3574778e-21 3.0020918e-20 1.8990646e-22], sum to 1.0000
[2019-03-23 20:06:10,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-23 20:06:10,547] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 58.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6677569797929119, 6.911200000000001, 6.9112, 121.9260426156618, 498425.3460230645, 498425.346023064, 139603.9297654451], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 861600.0000, 
sim time next is 862200.0000, 
raw observation next is [25.05, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6642846220970419, 6.9112, 6.9112, 121.9260426156618, 495740.4223061135, 495740.4223061135, 139105.3344055066], 
processed observation next is [0.0, 1.0, 0.48333333333333334, 0.585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5803557776213023, 0.0, 0.0, 0.8094621288201359, 0.17705015082361197, 0.17705015082361197, 0.2675102584721281], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.06811408], dtype=float32), -0.6897075]. 
=============================================
[2019-03-23 20:06:11,987] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23784: loss 0.0050
[2019-03-23 20:06:11,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23785: learning rate 0.0010
[2019-03-23 20:06:11,998] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23785: loss 0.0266
[2019-03-23 20:06:12,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23786: learning rate 0.0010
[2019-03-23 20:06:12,114] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23848: loss 0.2775
[2019-03-23 20:06:12,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23850: learning rate 0.0010
[2019-03-23 20:06:12,124] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23853: loss 0.3015
[2019-03-23 20:06:12,125] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23853: learning rate 0.0010
[2019-03-23 20:06:12,165] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23874: loss 0.2982
[2019-03-23 20:06:12,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23874: learning rate 0.0010
[2019-03-23 20:06:12,228] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23906: loss 0.1341
[2019-03-23 20:06:12,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23907: learning rate 0.0010
[2019-03-23 20:06:12,242] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23914: loss 0.0995
[2019-03-23 20:06:12,243] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23914: learning rate 0.0010
[2019-03-23 20:06:12,449] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24016: loss 0.2173
[2019-03-23 20:06:12,455] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24019: learning rate 0.0010
[2019-03-23 20:06:12,486] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24033: loss 0.5161
[2019-03-23 20:06:12,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24034: learning rate 0.0010
[2019-03-23 20:06:12,539] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24059: loss 0.3105
[2019-03-23 20:06:12,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24059: learning rate 0.0010
[2019-03-23 20:06:12,554] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24068: loss 0.2285
[2019-03-23 20:06:12,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24068: learning rate 0.0010
[2019-03-23 20:06:12,558] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24068: loss 0.0372
[2019-03-23 20:06:12,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24069: learning rate 0.0010
[2019-03-23 20:06:12,666] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24121: loss 0.0725
[2019-03-23 20:06:12,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24121: learning rate 0.0010
[2019-03-23 20:06:12,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24140: loss 0.1620
[2019-03-23 20:06:12,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24140: learning rate 0.0010
[2019-03-23 20:06:12,702] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24141: loss 0.2391
[2019-03-23 20:06:12,705] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24141: learning rate 0.0010
[2019-03-23 20:06:12,791] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24183: loss 0.2367
[2019-03-23 20:06:12,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24185: learning rate 0.0010
[2019-03-23 20:06:14,427] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 20:06:14,429] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:06:14,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:06:14,432] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:06:14,433] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:06:14,434] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:06:14,436] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:06:14,435] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:06:14,442] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:06:14,442] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:06:14,445] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:06:14,452] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 20:06:14,477] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 20:06:14,478] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 20:06:14,522] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 20:06:14,524] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 20:06:26,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:06:26,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.66666666666667, 43.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4409109840984068, 6.9112, 6.9112, 121.9260426156618, 314806.053464964, 314806.053464964, 90452.46494741635]
[2019-03-23 20:06:26,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:06:26,289] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.9168943470484662
[2019-03-23 20:06:29,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:06:29,361] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 42.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4971996867582507, 6.911199999999999, 6.9112, 121.9260426156618, 355004.9440077989, 355004.9440077994, 108728.5383700084]
[2019-03-23 20:06:29,364] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:06:29,370] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.574685353099523
[2019-03-23 20:06:41,412] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:06:41,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.16382717, 77.236161595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5654027200482679, 6.9112, 6.9112, 121.9260426156618, 415178.3702460991, 415178.3702460991, 124628.4355460202]
[2019-03-23 20:06:41,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:06:41,417] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.750473994992022
[2019-03-23 20:06:46,780] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:06:46,782] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.35, 38.5, 1.0, 2.0, 0.7903330563118852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1615907.021728872, 1615907.021728872, 334316.1549885481]
[2019-03-23 20:06:46,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:06:46,787] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.4996293219868687
[2019-03-23 20:06:46,788] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1615907.021728872 W.
[2019-03-23 20:06:54,248] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:06:54,250] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 70.0, 1.0, 2.0, 0.654672818640795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746116.6703993853, 746116.6703993853, 167741.4493729082]
[2019-03-23 20:06:54,251] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:06:54,252] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.3098035380826659
[2019-03-23 20:06:54,253] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 746116.6703993853 W.
[2019-03-23 20:07:01,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:07:01,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.83731129333334, 60.58066702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8411795359442195, 6.911200000000001, 6.9112, 121.9260426156618, 621301.0046110041, 621301.0046110037, 166839.8202848553]
[2019-03-23 20:07:01,372] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:07:01,376] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.19512091966723843
[2019-03-23 20:07:38,572] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.18431824]
[2019-03-23 20:07:38,574] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.13333333333333, 61.66666666666667, 1.0, 2.0, 0.9240066365027747, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1768488.789429044, 1768488.789429044, 362203.1227760864]
[2019-03-23 20:07:38,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:07:38,579] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1644535e-17 3.2658057e-14 7.6130313e-15 7.3108199e-18], sampled 0.5254134498332618
[2019-03-23 20:07:38,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1768488.789429044 W.
[2019-03-23 20:07:59,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 20:08:00,129] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 20:08:00,132] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 20:08:00,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 20:08:00,222] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 20:08:01,237] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 25000, evaluation results [25000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 20:08:14,071] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31708: loss 0.8296
[2019-03-23 20:08:14,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31710: learning rate 0.0010
[2019-03-23 20:08:14,121] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31732: loss 1.0047
[2019-03-23 20:08:14,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31732: learning rate 0.0010
[2019-03-23 20:08:14,142] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31742: loss 0.7194
[2019-03-23 20:08:14,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31742: learning rate 0.0010
[2019-03-23 20:08:14,241] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31797: loss 0.6742
[2019-03-23 20:08:14,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31798: learning rate 0.0010
[2019-03-23 20:08:14,331] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31843: loss 0.2433
[2019-03-23 20:08:14,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31843: learning rate 0.0010
[2019-03-23 20:08:14,507] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31935: loss 0.0004
[2019-03-23 20:08:14,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31937: learning rate 0.0010
[2019-03-23 20:08:14,555] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31963: loss 0.0873
[2019-03-23 20:08:14,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31964: learning rate 0.0010
[2019-03-23 20:08:14,704] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32042: loss 0.1823
[2019-03-23 20:08:14,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32042: learning rate 0.0010
[2019-03-23 20:08:14,750] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32062: loss 0.0176
[2019-03-23 20:08:14,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32063: learning rate 0.0010
[2019-03-23 20:08:14,775] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32072: loss 0.0037
[2019-03-23 20:08:14,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32072: learning rate 0.0010
[2019-03-23 20:08:14,800] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32088: loss 0.0108
[2019-03-23 20:08:14,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32088: learning rate 0.0010
[2019-03-23 20:08:14,858] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32122: loss 0.0589
[2019-03-23 20:08:14,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32122: loss 0.1462
[2019-03-23 20:08:14,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32122: learning rate 0.0010
[2019-03-23 20:08:14,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32122: learning rate 0.0010
[2019-03-23 20:08:14,970] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32179: loss 0.1398
[2019-03-23 20:08:14,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32180: learning rate 0.0010
[2019-03-23 20:08:15,013] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32202: loss 0.0547
[2019-03-23 20:08:15,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32203: learning rate 0.0010
[2019-03-23 20:08:15,040] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32213: loss 0.0151
[2019-03-23 20:08:15,041] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32213: learning rate 0.0010
[2019-03-23 20:08:23,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.3905194e-37 4.2710915e-31 6.2411518e-31 3.6122908e-33], sum to 1.0000
[2019-03-23 20:08:23,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8178
[2019-03-23 20:08:23,743] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6164241870766446, 6.9112, 6.9112, 121.9260426156618, 458055.7255364556, 458055.7255364556, 132317.6005838489], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1373400.0000, 
sim time next is 1374000.0000, 
raw observation next is [24.26666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6141475366826205, 6.9112, 6.9112, 121.9260426156618, 456202.4737676819, 456202.4737676819, 131977.3606997681], 
processed observation next is [1.0, 0.9130434782608695, 0.4543209876543211, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5176844208532755, 0.0, 0.0, 0.8094621288201359, 0.16292945491702926, 0.16292945491702926, 0.2538026167303232], 
reward next is 0.7462, 
noisyNet noise sample is [array([-0.8320229], dtype=float32), 0.047756623]. 
=============================================
[2019-03-23 20:08:23,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.426445]
 [77.426445]
 [77.426445]
 [77.426445]
 [77.426445]], R is [[77.39838409]
 [77.36994171]
 [77.34103394]
 [77.31162262]
 [77.28197479]].
[2019-03-23 20:08:29,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 9.0840588e-28 3.1672801e-24 8.7244533e-23 1.5187504e-24], sum to 1.0000
[2019-03-23 20:08:29,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-23 20:08:29,022] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.18333333333333, 56.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5654632677659156, 6.911200000000001, 6.9112, 121.9260426156618, 414886.2359727429, 414886.2359727424, 124474.9864468944], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1475400.0000, 
sim time next is 1476000.0000, 
raw observation next is [22.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5641755147965414, 6.911200000000001, 6.9112, 121.9260426156618, 413537.1688575904, 413537.1688575899, 124175.9705020086], 
processed observation next is [0.0, 0.08695652173913043, 0.4037037037037037, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4552193934956767, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.147691846020568, 0.1476918460205678, 0.23879994327309345], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.07545648], dtype=float32), 0.4428139]. 
=============================================
[2019-03-23 20:08:29,041] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.61235]
 [69.61235]
 [69.61235]
 [69.61235]
 [69.61235]], R is [[69.6774292 ]
 [69.7412796 ]
 [69.80388641]
 [69.86509705]
 [69.92494202]].
[2019-03-23 20:08:29,197] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39643: loss 0.0615
[2019-03-23 20:08:29,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39646: learning rate 0.0010
[2019-03-23 20:08:29,453] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39784: loss 0.2709
[2019-03-23 20:08:29,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39785: learning rate 0.0010
[2019-03-23 20:08:29,496] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39804: loss 0.1156
[2019-03-23 20:08:29,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39804: learning rate 0.0010
[2019-03-23 20:08:29,549] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39833: loss 0.0666
[2019-03-23 20:08:29,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39835: learning rate 0.0010
[2019-03-23 20:08:29,600] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39857: loss 0.0002
[2019-03-23 20:08:29,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39858: learning rate 0.0010
[2019-03-23 20:08:29,623] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39867: loss 0.0317
[2019-03-23 20:08:29,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39867: learning rate 0.0010
[2019-03-23 20:08:29,668] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39890: loss 0.1021
[2019-03-23 20:08:29,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39891: learning rate 0.0010
[2019-03-23 20:08:29,723] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39919: loss 0.1456
[2019-03-23 20:08:29,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39920: learning rate 0.0010
[2019-03-23 20:08:29,895] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40008: loss 0.0173
[2019-03-23 20:08:29,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40010: learning rate 0.0010
[2019-03-23 20:08:29,988] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40057: loss 0.4684
[2019-03-23 20:08:29,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40057: learning rate 0.0010
[2019-03-23 20:08:30,065] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40099: loss 0.0871
[2019-03-23 20:08:30,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40099: learning rate 0.0010
[2019-03-23 20:08:30,082] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40107: loss 0.1122
[2019-03-23 20:08:30,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40108: learning rate 0.0010
[2019-03-23 20:08:30,178] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40158: loss 0.0338
[2019-03-23 20:08:30,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40159: learning rate 0.0010
[2019-03-23 20:08:30,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40204: loss 0.1380
[2019-03-23 20:08:30,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40204: learning rate 0.0010
[2019-03-23 20:08:30,387] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40268: loss 0.0165
[2019-03-23 20:08:30,390] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40268: learning rate 0.0010
[2019-03-23 20:08:30,411] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40280: loss 0.0014
[2019-03-23 20:08:30,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40280: learning rate 0.0010
[2019-03-23 20:08:31,041] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.8892026e-30 1.0950076e-26 1.7321342e-23 3.1883245e-24], sum to 1.0000
[2019-03-23 20:08:31,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-23 20:08:31,052] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.2, 44.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084922395419636, 6.911200000000001, 6.9112, 121.9260426156618, 665300.2775014894, 665300.2775014889, 176990.5974116302], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1530600.0000, 
sim time next is 1531200.0000, 
raw observation next is [31.7, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8790082446266918, 6.9112, 6.9112, 121.9260426156618, 644487.091841032, 644487.091841032, 172924.3218375299], 
processed observation next is [0.0, 0.7391304347826086, 0.7296296296296296, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8487603057833648, 0.0, 0.0, 0.8094621288201359, 0.23017396137179716, 0.23017396137179716, 0.3325467727644806], 
reward next is 0.6675, 
noisyNet noise sample is [array([1.1243109], dtype=float32), 0.02725936]. 
=============================================
[2019-03-23 20:08:42,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.2632221e-37 8.2804677e-37 3.0139778e-36], sum to 1.0000
[2019-03-23 20:08:42,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9741
[2019-03-23 20:08:42,344] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.61666666666667, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779184749617885, 6.911199999999999, 6.9112, 121.9260426156618, 504681.9895320423, 504681.9895320428, 139160.7549406184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1739400.0000, 
sim time next is 1740000.0000, 
raw observation next is [20.53333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6327374370074274, 6.9112, 6.9112, 121.9260426156618, 470976.8006922391, 470976.8006922391, 134552.9513218222], 
processed observation next is [1.0, 0.13043478260869565, 0.3160493827160493, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5409217962592842, 0.0, 0.0, 0.8094621288201359, 0.16820600024722823, 0.16820600024722823, 0.25875567561888885], 
reward next is 0.7412, 
noisyNet noise sample is [array([-1.2500101], dtype=float32), -0.20730168]. 
=============================================
[2019-03-23 20:08:42,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[86.80231]
 [86.80231]
 [86.80231]
 [86.80231]
 [86.80231]], R is [[86.67553711]
 [86.54116821]
 [86.41011047]
 [86.28154755]
 [86.15190887]].
[2019-03-23 20:08:42,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.7464294e-29 1.8788999e-25 6.3555963e-28 4.9110231e-26], sum to 1.0000
[2019-03-23 20:08:42,667] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6151
[2019-03-23 20:08:42,678] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333333, 88.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6129008760952974, 6.911199999999999, 6.9112, 121.9260426156618, 455632.0867023756, 455632.086702376, 132130.2122940722], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1744800.0000, 
sim time next is 1745400.0000, 
raw observation next is [19.86666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6112040483971687, 6.9112, 6.9112, 121.9260426156618, 454281.8495337709, 454281.8495337709, 131897.7267286808], 
processed observation next is [1.0, 0.17391304347826086, 0.2913580246913582, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5140050604964608, 0.0, 0.0, 0.8094621288201359, 0.16224351769063244, 0.16224351769063244, 0.25364947447823233], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.7842586], dtype=float32), -0.23921151]. 
=============================================
[2019-03-23 20:08:43,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.1343378e-30 1.9143851e-27 5.6741295e-28 3.2588325e-24], sum to 1.0000
[2019-03-23 20:08:43,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7797
[2019-03-23 20:08:43,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6498453574104774, 6.911200000000001, 6.9112, 121.9260426156618, 484634.4341276722, 484634.4341276718, 137191.5696131143], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1753200.0000, 
sim time next is 1753800.0000, 
raw observation next is [21.86666666666667, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7612405780702934, 6.911199999999999, 6.9112, 121.9260426156618, 567856.8617584346, 567856.861758435, 149212.9024103505], 
processed observation next is [1.0, 0.30434782608695654, 0.36543209876543226, 0.7816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7015507225878667, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20280602205658377, 0.20280602205658393, 0.28694788925067405], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.4279015], dtype=float32), 0.65524864]. 
=============================================
[2019-03-23 20:08:45,374] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47711: loss 2.9679
[2019-03-23 20:08:45,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47712: learning rate 0.0010
[2019-03-23 20:08:45,463] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47762: loss 2.6316
[2019-03-23 20:08:45,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47762: learning rate 0.0010
[2019-03-23 20:08:45,484] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47772: loss 2.7280
[2019-03-23 20:08:45,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47773: learning rate 0.0010
[2019-03-23 20:08:45,583] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47817: loss 2.4631
[2019-03-23 20:08:45,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47817: learning rate 0.0010
[2019-03-23 20:08:45,659] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47857: loss 2.2219
[2019-03-23 20:08:45,661] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47857: learning rate 0.0010
[2019-03-23 20:08:45,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47932: loss 1.8563
[2019-03-23 20:08:45,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47932: learning rate 0.0010
[2019-03-23 20:08:45,840] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47945: loss 1.7006
[2019-03-23 20:08:45,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47945: learning rate 0.0010
[2019-03-23 20:08:45,885] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47965: loss 1.8430
[2019-03-23 20:08:45,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47967: learning rate 0.0010
[2019-03-23 20:08:45,934] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47989: loss 1.6322
[2019-03-23 20:08:45,935] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47989: learning rate 0.0010
[2019-03-23 20:08:46,038] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48044: loss 1.0843
[2019-03-23 20:08:46,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48044: learning rate 0.0010
[2019-03-23 20:08:46,154] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48102: loss 0.7328
[2019-03-23 20:08:46,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48102: learning rate 0.0010
[2019-03-23 20:08:46,174] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48109: loss 0.6159
[2019-03-23 20:08:46,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48110: learning rate 0.0010
[2019-03-23 20:08:46,231] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48135: loss 0.2665
[2019-03-23 20:08:46,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48135: learning rate 0.0010
[2019-03-23 20:08:46,283] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48162: loss 0.2625
[2019-03-23 20:08:46,285] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48162: learning rate 0.0010
[2019-03-23 20:08:46,508] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48274: loss 0.2565
[2019-03-23 20:08:46,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48275: learning rate 0.0010
[2019-03-23 20:08:46,554] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48293: loss 0.3227
[2019-03-23 20:08:46,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48293: learning rate 0.0010
[2019-03-23 20:08:46,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.1500198e-31 1.1030428e-29 2.1104527e-30 3.6006493e-27], sum to 1.0000
[2019-03-23 20:08:46,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5099
[2019-03-23 20:08:47,011] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.33333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5635931484664252, 6.911200000000001, 6.9112, 121.9260426156618, 413727.2237268479, 413727.2237268474, 124412.4545287642], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1824000.0000, 
sim time next is 1824600.0000, 
raw observation next is [18.36666666666666, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5621861220035628, 6.9112, 6.9112, 121.9260426156618, 412881.4412708965, 412881.4412708965, 124378.965143495], 
processed observation next is [1.0, 0.08695652173913043, 0.23580246913580222, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45273265250445344, 0.0, 0.0, 0.8094621288201359, 0.14745765759674875, 0.14745765759674875, 0.23919031758364423], 
reward next is 0.7608, 
noisyNet noise sample is [array([-0.46520084], dtype=float32), 2.0183558]. 
=============================================
[2019-03-23 20:08:47,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.6444538e-33 7.4412408e-31 3.9444653e-32 5.2358915e-29], sum to 1.0000
[2019-03-23 20:08:47,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3517
[2019-03-23 20:08:47,038] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5500412051978689, 6.9112, 6.9112, 121.9260426156618, 403319.8982350342, 403319.8982350342, 123024.5208943414], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1811400.0000, 
sim time next is 1812000.0000, 
raw observation next is [18.63333333333333, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5494844583597555, 6.9112, 6.9112, 121.9260426156618, 402949.6238740566, 402949.6238740566, 122994.4267170639], 
processed observation next is [1.0, 1.0, 0.24567901234567888, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4368555729496943, 0.0, 0.0, 0.8094621288201359, 0.1439105799550202, 0.1439105799550202, 0.23652774368666135], 
reward next is 0.7635, 
noisyNet noise sample is [array([-0.00128771], dtype=float32), -0.8395107]. 
=============================================
[2019-03-23 20:08:47,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.12485]
 [66.12485]
 [66.12485]
 [66.12485]
 [66.12485]], R is [[66.2270813 ]
 [66.32822418]
 [66.42835236]
 [66.52770233]
 [66.62636566]].
[2019-03-23 20:08:47,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.1118408e-32 2.9924850e-29 9.4320086e-32 6.0589594e-27], sum to 1.0000
[2019-03-23 20:08:47,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8175
[2019-03-23 20:08:47,397] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.4, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5528600060572806, 6.9112, 6.9112, 121.9260426156618, 405644.8076287216, 405644.8076287216, 123386.4187732575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1818000.0000, 
sim time next is 1818600.0000, 
raw observation next is [18.36666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.552249030976355, 6.911199999999999, 6.9112, 121.9260426156618, 405150.0509332714, 405150.0509332719, 123312.0795723066], 
processed observation next is [1.0, 0.043478260869565216, 0.2358024691358026, 0.9116666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4403112887204437, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14469644676188265, 0.1446964467618828, 0.23713861456212806], 
reward next is 0.7629, 
noisyNet noise sample is [array([1.0977379], dtype=float32), 0.4189242]. 
=============================================
[2019-03-23 20:08:49,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.8391433e-20 4.5811264e-17 5.5893860e-18 1.1435300e-17], sum to 1.0000
[2019-03-23 20:08:49,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8884
[2019-03-23 20:08:49,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 930575.140957341 W.
[2019-03-23 20:08:49,784] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 83.0, 1.0, 2.0, 0.7566610827800532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930575.140957341, 930575.140957341, 189985.9603792665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1863000.0000, 
sim time next is 1863600.0000, 
raw observation next is [21.83333333333334, 83.33333333333334, 1.0, 2.0, 0.7670565930648131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942929.3242550552, 942929.3242550552, 192103.4212960607], 
processed observation next is [1.0, 0.5652173913043478, 0.36419753086419776, 0.8333333333333335, 1.0, 1.0, 0.7226864203152537, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33676047294823397, 0.33676047294823397, 0.36942965633857827], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.28643632], dtype=float32), -0.6014866]. 
=============================================
[2019-03-23 20:08:50,140] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 20:08:50,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:08:50,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:50,142] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:08:50,144] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:08:50,146] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:08:50,146] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:50,148] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:08:50,147] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:50,153] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:50,149] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:08:50,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 20:08:50,188] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 20:08:50,189] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 20:08:50,190] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 20:08:50,272] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 20:09:04,105] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:04,106] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.41766768166667, 48.29195707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4952869712210078, 6.9112, 6.9112, 121.9260426156618, 355334.6503461788, 355334.6503461788, 115339.2502725543]
[2019-03-23 20:09:04,107] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:09:04,110] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.5391028217278357
[2019-03-23 20:09:37,125] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:37,129] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.81873517, 93.96571484666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9969438663555108, 6.940983607918495, 6.9112, 121.9257912786994, 729514.1716749459, 714262.3338320382, 191427.0203162261]
[2019-03-23 20:09:37,130] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:09:37,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.10810720895448789
[2019-03-23 20:09:37,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 729514.1716749459 W.
[2019-03-23 20:09:39,867] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:39,867] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.66666666666666, 92.66666666666666, 1.0, 2.0, 0.7747320512969713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883024.439849641, 883024.439849641, 190773.0162492226]
[2019-03-23 20:09:39,868] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:09:39,872] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.2989970574061869
[2019-03-23 20:09:39,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 883024.439849641 W.
[2019-03-23 20:09:44,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:44,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.63194386, 81.21450027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8073943320232215, 6.911200000000001, 6.9112, 121.9260426156618, 600526.49716009, 600526.4971600896, 160815.6583165976]
[2019-03-23 20:09:44,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:09:44,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.6700405639750786
[2019-03-23 20:09:52,080] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:52,081] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.45, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8439372291287982, 6.911200000000001, 6.9112, 121.9260426156618, 621764.7312250518, 621764.7312250513, 167657.1438882271]
[2019-03-23 20:09:52,082] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:09:52,084] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.7960146569778631
[2019-03-23 20:09:56,621] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:09:56,622] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.712429115563043, 6.911200000000001, 6.9112, 121.9260426156618, 532321.048298285, 532321.0482982845, 146778.7340082719]
[2019-03-23 20:09:56,623] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:09:56,626] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.8043091529046551
[2019-03-23 20:10:01,070] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:10:01,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.66666666666667, 92.33333333333334, 1.0, 2.0, 0.8161782652675524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930292.6957894792, 930292.6957894792, 199314.5011193809]
[2019-03-23 20:10:01,073] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:10:01,077] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.8271224004914508
[2019-03-23 20:10:01,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 930292.6957894792 W.
[2019-03-23 20:10:02,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:10:02,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.30027276833333, 70.21145243, 1.0, 2.0, 0.7102488013411565, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260425513163, 1524499.155466851, 1524499.15546685, 319104.3751716547]
[2019-03-23 20:10:02,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:10:02,370] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.8359307796238481
[2019-03-23 20:10:02,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1524499.155466851 W.
[2019-03-23 20:10:28,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:10:28,272] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 88.0, 1.0, 2.0, 0.6007055967048379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684583.9129463906, 684583.9129463906, 158201.8302962691]
[2019-03-23 20:10:28,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:10:28,275] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.617878806366335
[2019-03-23 20:10:28,697] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:10:28,698] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.44462525, 59.87940717333333, 1.0, 2.0, 0.4842514660538423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609004.378849187, 609004.3788491866, 141287.891447093]
[2019-03-23 20:10:28,700] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:10:28,706] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.4611097092111668
[2019-03-23 20:10:30,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.014878702]
[2019-03-23 20:10:30,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.36666666666667, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5794319907868355, 6.911200000000001, 6.9112, 121.9260426156618, 428055.4347841204, 428055.4347841199, 127188.9997018758]
[2019-03-23 20:10:30,860] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:10:30,862] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4869038e-19 7.7505971e-18 2.1372664e-18 3.9786186e-17], sampled 0.770617965066497
[2019-03-23 20:10:35,614] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 20:10:35,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 20:10:35,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 20:10:35,897] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 20:10:35,911] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 20:10:36,925] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 50000, evaluation results [50000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 20:10:37,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2890814e-21 1.9291639e-20 1.5140102e-20 4.3890488e-19], sum to 1.0000
[2019-03-23 20:10:37,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9453
[2019-03-23 20:10:37,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1225725.225520816 W.
[2019-03-23 20:10:37,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.68333333333333, 86.16666666666667, 1.0, 2.0, 0.92666695248477, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.096087524230846, 6.9112, 121.9253858391149, 1225725.225520816, 1131046.798060341, 226941.7313518126], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1869000.0000, 
sim time next is 1869600.0000, 
raw observation next is [21.66666666666667, 86.33333333333334, 1.0, 2.0, 0.4575460199312122, 1.0, 1.0, 0.4575460199312122, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259312797234, 1103405.122938933, 1103405.122938933, 225082.9435655272], 
processed observation next is [1.0, 0.6521739130434783, 0.3580246913580249, 0.8633333333333334, 1.0, 1.0, 0.35422145229906216, 1.0, 0.5, 0.35422145229906216, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094613896652861, 0.39407325819247613, 0.39407325819247613, 0.4328518145490908], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.206935], dtype=float32), -0.40505826]. 
=============================================
[2019-03-23 20:10:37,516] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.5449911e-27 1.4984940e-23 1.2935417e-25 1.5151229e-23], sum to 1.0000
[2019-03-23 20:10:37,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2007
[2019-03-23 20:10:37,530] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6954774223351902, 6.911199999999999, 6.9112, 121.9260426156618, 519722.3093043536, 519722.3093043541, 144239.0713719013], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1888800.0000, 
sim time next is 1889400.0000, 
raw observation next is [21.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6961534145698391, 6.9112, 6.9112, 121.9260426156618, 520227.6415778245, 520227.6415778245, 144312.7932418889], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6201917682122989, 0.0, 0.0, 0.8094621288201359, 0.18579558627779447, 0.18579558627779447, 0.2775246023882479], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.90237826], dtype=float32), 1.3137449]. 
=============================================
[2019-03-23 20:10:43,613] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.5799913e-38 4.3729027e-35 6.1140715e-37 3.3204185e-33], sum to 1.0000
[2019-03-23 20:10:43,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6789
[2019-03-23 20:10:43,626] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.66666666666667, 84.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6222419442884674, 6.911200000000001, 6.9112, 121.9260426156618, 463422.161889294, 463422.1618892935, 133761.3858193632], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2011800.0000, 
sim time next is 2012400.0000, 
raw observation next is [20.8, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.622964264554887, 6.9112, 6.9112, 121.9260426156618, 464033.160248418, 464033.160248418, 133902.6624090894], 
processed observation next is [0.0, 0.30434782608695654, 0.32592592592592595, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5287053306936087, 0.0, 0.0, 0.8094621288201359, 0.16572612866014927, 0.16572612866014927, 0.2575051200174796], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.6089329], dtype=float32), -0.104680926]. 
=============================================
[2019-03-23 20:10:46,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.5791835e-26 6.7217789e-24 3.8774975e-23 7.6986570e-23], sum to 1.0000
[2019-03-23 20:10:46,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6874
[2019-03-23 20:10:46,350] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.814817245031117, 6.911199999999999, 6.9112, 121.9260426156618, 604089.8906944216, 604089.8906944221, 162696.0299672752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2068800.0000, 
sim time next is 2069400.0000, 
raw observation next is [24.35, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8040254441032839, 6.9112, 6.9112, 121.9260426156618, 596843.699152977, 596843.699152977, 161003.8590114171], 
processed observation next is [0.0, 0.9565217391304348, 0.4574074074074075, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.755031805129105, 0.0, 0.0, 0.8094621288201359, 0.21315846398320606, 0.21315846398320606, 0.30962280579118673], 
reward next is 0.6904, 
noisyNet noise sample is [array([-1.047136], dtype=float32), 0.48894474]. 
=============================================
[2019-03-23 20:10:47,887] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55718: loss 0.0095
[2019-03-23 20:10:47,892] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55719: learning rate 0.0010
[2019-03-23 20:10:47,941] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55749: loss 0.1017
[2019-03-23 20:10:47,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55750: learning rate 0.0010
[2019-03-23 20:10:47,967] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55764: loss 0.2605
[2019-03-23 20:10:47,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55764: learning rate 0.0010
[2019-03-23 20:10:47,971] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55765: loss 0.2494
[2019-03-23 20:10:47,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55765: learning rate 0.0010
[2019-03-23 20:10:48,155] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55860: loss 0.0012
[2019-03-23 20:10:48,158] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55860: loss 0.0005
[2019-03-23 20:10:48,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55860: learning rate 0.0010
[2019-03-23 20:10:48,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55860: learning rate 0.0010
[2019-03-23 20:10:48,193] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55874: loss 0.0624
[2019-03-23 20:10:48,196] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55877: learning rate 0.0010
[2019-03-23 20:10:48,348] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55955: loss 0.0628
[2019-03-23 20:10:48,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55955: learning rate 0.0010
[2019-03-23 20:10:48,454] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56013: loss 0.0055
[2019-03-23 20:10:48,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56013: learning rate 0.0010
[2019-03-23 20:10:48,661] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56122: loss 0.1755
[2019-03-23 20:10:48,665] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56122: learning rate 0.0010
[2019-03-23 20:10:48,686] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56136: loss 0.0526
[2019-03-23 20:10:48,689] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56136: learning rate 0.0010
[2019-03-23 20:10:48,710] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56147: loss 0.0272
[2019-03-23 20:10:48,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56148: learning rate 0.0010
[2019-03-23 20:10:48,751] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56169: loss 0.0084
[2019-03-23 20:10:48,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56169: learning rate 0.0010
[2019-03-23 20:10:48,861] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56225: loss 0.1057
[2019-03-23 20:10:48,863] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56225: learning rate 0.0010
[2019-03-23 20:10:48,917] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56255: loss 0.0985
[2019-03-23 20:10:48,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56255: learning rate 0.0010
[2019-03-23 20:10:48,943] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56263: loss 0.1504
[2019-03-23 20:10:48,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56263: learning rate 0.0010
[2019-03-23 20:11:03,149] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63684: loss 2.6434
[2019-03-23 20:11:03,151] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63685: learning rate 0.0010
[2019-03-23 20:11:03,204] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63717: loss 2.4550
[2019-03-23 20:11:03,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63719: learning rate 0.0010
[2019-03-23 20:11:03,229] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63732: loss 2.3431
[2019-03-23 20:11:03,232] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63733: learning rate 0.0010
[2019-03-23 20:11:03,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.0616269e-17 6.4680847e-12 4.4806633e-15 4.3258746e-16], sum to 1.0000
[2019-03-23 20:11:03,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6857
[2019-03-23 20:11:03,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1403524.873314712 W.
[2019-03-23 20:11:03,267] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.06666666666667, 37.0, 1.0, 2.0, 0.5832706184579056, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9430301002823975, 6.911199999999999, 6.9112, 121.9260426156618, 1403524.873314712, 1403524.873314713, 285407.5072545495], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2384400.0000, 
sim time next is 2385000.0000, 
raw observation next is [31.05, 37.0, 1.0, 2.0, 0.4008651051116955, 1.0, 1.0, 0.4008651051116955, 1.0, 2.0, 0.6431597049517901, 6.911200000000001, 6.9112, 121.94756008, 1424401.387910919, 1424401.387910919, 297337.1115810495], 
processed observation next is [1.0, 0.6086956521739131, 0.7055555555555556, 0.37, 1.0, 1.0, 0.28674417275201847, 1.0, 0.5, 0.28674417275201847, 1.0, 1.0, 0.5539496311897376, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5087147813967567, 0.5087147813967567, 0.5718021376558644], 
reward next is 0.4282, 
noisyNet noise sample is [array([0.00539212], dtype=float32), -0.092824414]. 
=============================================
[2019-03-23 20:11:03,284] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[30.572273]
 [30.572273]
 [30.572273]
 [30.572273]
 [30.572273]], R is [[30.69474792]
 [30.83893967]
 [30.53055   ]
 [30.72113419]
 [30.86353302]].
[2019-03-23 20:11:03,373] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63805: loss 2.4332
[2019-03-23 20:11:03,374] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63805: learning rate 0.0010
[2019-03-23 20:11:03,505] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63872: loss 2.1365
[2019-03-23 20:11:03,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63872: learning rate 0.0010
[2019-03-23 20:11:03,571] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63907: loss 1.7015
[2019-03-23 20:11:03,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63907: learning rate 0.0010
[2019-03-23 20:11:03,641] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63943: loss 1.5585
[2019-03-23 20:11:03,644] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63943: loss 1.5081
[2019-03-23 20:11:03,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63943: learning rate 0.0010
[2019-03-23 20:11:03,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63944: learning rate 0.0010
[2019-03-23 20:11:03,679] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63961: loss 1.5575
[2019-03-23 20:11:03,685] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63961: learning rate 0.0010
[2019-03-23 20:11:03,751] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63999: loss 1.6360
[2019-03-23 20:11:03,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63999: learning rate 0.0010
[2019-03-23 20:11:04,089] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64179: loss 0.5954
[2019-03-23 20:11:04,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64179: learning rate 0.0010
[2019-03-23 20:11:04,124] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64197: loss 0.3520
[2019-03-23 20:11:04,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64197: learning rate 0.0010
[2019-03-23 20:11:04,202] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64238: loss 0.0906
[2019-03-23 20:11:04,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64238: learning rate 0.0010
[2019-03-23 20:11:04,215] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64246: loss 0.2810
[2019-03-23 20:11:04,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64246: learning rate 0.0010
[2019-03-23 20:11:04,240] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64258: loss 0.0934
[2019-03-23 20:11:04,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64258: learning rate 0.0010
[2019-03-23 20:11:04,289] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64284: loss 0.0029
[2019-03-23 20:11:04,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64284: learning rate 0.0010
[2019-03-23 20:11:05,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0186667e-28 6.6411788e-19 4.0320571e-28 4.2176245e-26], sum to 1.0000
[2019-03-23 20:11:05,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4341
[2019-03-23 20:11:05,394] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6003127005395112, 6.9112, 6.9112, 121.9260426156618, 441477.4308393403, 441477.4308393403, 128047.323292474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2442600.0000, 
sim time next is 2443200.0000, 
raw observation next is [23.76666666666667, 56.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5981736303992404, 6.911200000000001, 6.9112, 121.9260426156618, 440835.028431823, 440835.0284318225, 128323.5765179178], 
processed observation next is [1.0, 0.2608695652173913, 0.43580246913580256, 0.5633333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4977170379990505, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15744108158279393, 0.15744108158279374, 0.24677610868830346], 
reward next is 0.7532, 
noisyNet noise sample is [array([1.309167], dtype=float32), -0.54841256]. 
=============================================
[2019-03-23 20:11:06,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 9.9020737e-29 9.8687135e-19 1.6602237e-26 2.1843363e-28], sum to 1.0000
[2019-03-23 20:11:06,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3901
[2019-03-23 20:11:06,445] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798166935184539, 6.9112, 6.9112, 121.9260426156618, 593195.0959225703, 593195.0959225703, 151301.935766727], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [27.16666666666667, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598200619162959, 6.911199999999999, 6.9112, 121.9260426156618, 565370.2354881595, 565370.2354881599, 147610.1193480384], 
processed observation next is [1.0, 0.30434782608695654, 0.5617283950617286, 0.4533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6997750773953698, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20191794124577123, 0.2019179412457714, 0.28386561413084305], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.13445465], dtype=float32), -1.4995742]. 
=============================================
[2019-03-23 20:11:17,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.1350592e-35 5.8232165e-29 4.0030638e-34 8.0914367e-35], sum to 1.0000
[2019-03-23 20:11:17,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2576
[2019-03-23 20:11:18,076] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.13333333333333, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9190692301048636, 6.9112, 6.9112, 121.9260426156618, 670596.7567439069, 670596.7567439069, 178884.3864261363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2677800.0000, 
sim time next is 2678400.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9249475427009672, 6.9112, 6.9112, 121.9260426156618, 674106.5959791781, 674106.5959791781, 179817.5279570494], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.906184428376209, 0.0, 0.0, 0.8094621288201359, 0.24075235570684933, 0.24075235570684933, 0.34580293837894116], 
reward next is 0.6542, 
noisyNet noise sample is [array([-0.64504373], dtype=float32), -0.9449813]. 
=============================================
[2019-03-23 20:11:18,825] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71612: loss 0.0532
[2019-03-23 20:11:18,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71612: learning rate 0.0010
[2019-03-23 20:11:18,983] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71686: loss 0.2927
[2019-03-23 20:11:18,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71688: learning rate 0.0010
[2019-03-23 20:11:19,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71703: loss 0.3011
[2019-03-23 20:11:19,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71703: learning rate 0.0010
[2019-03-23 20:11:19,031] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71713: loss 0.3076
[2019-03-23 20:11:19,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71713: learning rate 0.0010
[2019-03-23 20:11:19,208] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71800: loss 0.0122
[2019-03-23 20:11:19,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71801: learning rate 0.0010
[2019-03-23 20:11:19,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.9889589e-37 1.7793772e-30 0.0000000e+00 1.1548283e-37], sum to 1.0000
[2019-03-23 20:11:19,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0239
[2019-03-23 20:11:19,267] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6556955565435773, 6.911200000000001, 6.9112, 121.9260426156618, 488877.1281617636, 488877.1281617631, 137645.7501582399], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2700000.0000, 
sim time next is 2700600.0000, 
raw observation next is [21.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6583760138337762, 6.911200000000001, 6.9112, 121.9260426156618, 491099.8216506319, 491099.8216506314, 138186.2558069391], 
processed observation next is [0.0, 0.2608695652173913, 0.35185185185185186, 0.815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5729700172922202, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17539279344665426, 0.17539279344665407, 0.26574279962872904], 
reward next is 0.7343, 
noisyNet noise sample is [array([0.14025505], dtype=float32), 0.71179783]. 
=============================================
[2019-03-23 20:11:19,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71835: loss 0.1683
[2019-03-23 20:11:19,280] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71835: loss 0.1919
[2019-03-23 20:11:19,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71835: learning rate 0.0010
[2019-03-23 20:11:19,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71835: learning rate 0.0010
[2019-03-23 20:11:19,616] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72000: loss 0.2141
[2019-03-23 20:11:19,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72001: learning rate 0.0010
[2019-03-23 20:11:19,696] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72040: loss 0.3819
[2019-03-23 20:11:19,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72041: learning rate 0.0010
[2019-03-23 20:11:19,731] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72057: loss 0.2418
[2019-03-23 20:11:19,733] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72058: learning rate 0.0010
[2019-03-23 20:11:20,029] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72209: loss 0.0212
[2019-03-23 20:11:20,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72209: learning rate 0.0010
[2019-03-23 20:11:20,059] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72222: loss 0.0009
[2019-03-23 20:11:20,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72222: learning rate 0.0010
[2019-03-23 20:11:20,063] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72222: loss 0.0480
[2019-03-23 20:11:20,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72223: learning rate 0.0010
[2019-03-23 20:11:20,089] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72236: loss 0.0094
[2019-03-23 20:11:20,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72238: learning rate 0.0010
[2019-03-23 20:11:20,167] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72277: loss 0.0611
[2019-03-23 20:11:20,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72277: learning rate 0.0010
[2019-03-23 20:11:20,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72352: loss 0.3514
[2019-03-23 20:11:20,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72353: learning rate 0.0010
[2019-03-23 20:11:24,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.48187779e-16 1.09118274e-13 1.98931405e-15
 1.53963485e-15], sum to 1.0000
[2019-03-23 20:11:24,745] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0938
[2019-03-23 20:11:24,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 788740.7388929564 W.
[2019-03-23 20:11:24,756] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.2306845744964207, 1.0, 1.0, 0.2306845744964207, 1.0, 1.0, 0.3672573554703922, 6.911200000000001, 6.9112, 121.94756008, 788740.7388929564, 788740.7388929559, 230880.6032672877], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2790000.0000, 
sim time next is 2790600.0000, 
raw observation next is [25.31666666666667, 87.5, 1.0, 2.0, 0.3646378190540387, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5805152833587297, 6.911199999999999, 6.9112, 121.9260426156618, 831186.0149302074, 831186.0149302079, 213437.4997980909], 
processed observation next is [1.0, 0.30434782608695654, 0.49320987654321, 0.875, 1.0, 1.0, 0.24361645125480796, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4756441041984121, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2968521481893598, 0.29685214818935995, 0.41045673038094405], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.98206127], dtype=float32), 0.35133418]. 
=============================================
[2019-03-23 20:11:25,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.1417870e-15 2.5837842e-11 7.9321139e-14 3.4719128e-14], sum to 1.0000
[2019-03-23 20:11:25,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1879
[2019-03-23 20:11:25,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2442520.276962686 W.
[2019-03-23 20:11:25,021] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.8005824467391671, 1.0, 2.0, 0.7136558853460183, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2442520.276962686, 2442520.276962686, 457361.8664896766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2808000.0000, 
sim time next is 2808600.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.8691742262529406, 1.0, 2.0, 0.7479517751029049, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 122.0905244840201, 2560063.559255144, 2560063.559255144, 477835.4000709909], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.63, 1.0, 1.0, 0.8442550312535008, 1.0, 1.0, 0.6999425894082201, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8105541173769475, 0.9143084140196943, 0.9143084140196943, 0.9189142309057517], 
reward next is 0.0811, 
noisyNet noise sample is [array([-0.74039555], dtype=float32), 1.1814901]. 
=============================================
[2019-03-23 20:11:25,640] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 20:11:25,641] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:11:25,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:25,643] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:11:25,645] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:11:25,645] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:25,646] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:11:25,647] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:11:25,646] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:25,648] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:25,648] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:11:25,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 20:11:25,663] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 20:11:25,686] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 20:11:25,732] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 20:11:25,771] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 20:11:47,870] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:11:47,871] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.48903067, 89.18786181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7335671386301106, 6.9112, 6.9112, 121.9260426156618, 546989.6733079461, 546989.6733079461, 150891.2106619373]
[2019-03-23 20:11:47,872] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:11:47,874] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.4828159698002499
[2019-03-23 20:11:54,823] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:11:54,824] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.76703412, 72.51439442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7045988708198296, 6.911200000000001, 6.9112, 121.9260426156618, 526465.3230421561, 526465.3230421557, 145919.812430483]
[2019-03-23 20:11:54,826] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:11:54,828] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.20983649328914478
[2019-03-23 20:11:58,607] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:11:58,607] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.13333333333334, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7206154589374821, 6.911200000000001, 6.9112, 121.9260426156618, 537490.3124129922, 537490.3124129918, 144679.9198777069]
[2019-03-23 20:11:58,608] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:11:58,613] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.6761109369373558
[2019-03-23 20:12:06,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:12:06,398] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 92.16666666666667, 1.0, 2.0, 0.6308753873486062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718982.5254361735, 718982.5254361735, 163471.1127254312]
[2019-03-23 20:12:06,399] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:12:06,402] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.5455572041922305
[2019-03-23 20:12:06,402] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 718982.5254361735 W.
[2019-03-23 20:12:25,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:12:25,337] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.44231003, 26.84185619, 1.0, 2.0, 0.488448148935712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8012344793009196, 6.911200000000001, 6.9112, 121.9260424903872, 1197926.764450598, 1197926.764450598, 249858.5883306589]
[2019-03-23 20:12:25,340] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:12:25,344] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.5918617083374408
[2019-03-23 20:12:25,345] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1197926.764450598 W.
[2019-03-23 20:12:50,086] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.012811769]
[2019-03-23 20:12:50,088] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.43089198, 70.24196752333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7004425584570636, 6.9112, 6.9112, 121.9260426156618, 523367.1951896399, 523367.1951896399, 144266.4447725973]
[2019-03-23 20:12:50,091] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:12:50,094] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3034664e-09 1.4001802e-08 3.0715753e-11 1.9867927e-11], sampled 0.3805783668249898
[2019-03-23 20:13:10,489] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 20:13:10,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 20:13:10,789] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 20:13:10,814] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 20:13:10,853] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 20:13:11,866] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 75000, evaluation results [75000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 20:13:14,206] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.01297256 0.9130355  0.07182327 0.00091485 0.00125382], sum to 1.0000
[2019-03-23 20:13:14,212] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2743
[2019-03-23 20:13:14,215] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 98.0, 1.0, 2.0, 0.6208369557759035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736433.8401758022, 736433.8401758022, 163007.125310979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866800.0000, 
sim time next is 2867400.0000, 
raw observation next is [22.2, 97.0, 1.0, 2.0, 0.609060157948467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723242.4699466918, 723242.4699466918, 160952.9542820584], 
processed observation next is [1.0, 0.17391304347826086, 0.37777777777777777, 0.97, 1.0, 1.0, 0.5345954261291274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25830088212381846, 0.25830088212381846, 0.30952491208088156], 
reward next is 0.6905, 
noisyNet noise sample is [array([-0.6404955], dtype=float32), 1.1247432]. 
=============================================
[2019-03-23 20:13:20,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2173350e-09 1.0000000e+00 7.9318939e-16 2.8334800e-19 1.3967383e-17], sum to 1.0000
[2019-03-23 20:13:20,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-23 20:13:20,358] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333333, 86.5, 1.0, 2.0, 0.788158763910957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898780.6227630901, 898780.6227630901, 193523.26491131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2967000.0000, 
sim time next is 2967600.0000, 
raw observation next is [25.66666666666667, 87.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.952433606564314, 6.9112, 121.9223099799755, 1696368.875019027, 1163180.527546398, 245581.324300049], 
processed observation next is [1.0, 0.34782608695652173, 0.506172839506173, 0.87, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.10412336065643144, 0.0, 0.8094373480008464, 0.6058460267925097, 0.41542161698085645, 0.4722717775000942], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1335254], dtype=float32), -1.2409345]. 
=============================================
[2019-03-23 20:13:20,618] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79584: loss -6.8976
[2019-03-23 20:13:20,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79584: learning rate 0.0010
[2019-03-23 20:13:20,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4496282e-08 1.0000000e+00 5.4467359e-12 1.9994815e-12 4.6099714e-14], sum to 1.0000
[2019-03-23 20:13:20,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6487
[2019-03-23 20:13:20,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1697259.654683768 W.
[2019-03-23 20:13:20,871] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 91.5, 1.0, 2.0, 0.7441682502163462, 1.0, 2.0, 0.7441682502163462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1697259.654683768, 1697259.654683769, 321223.7271441672], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2993400.0000, 
sim time next is 2994000.0000, 
raw observation next is [25.66666666666666, 90.66666666666666, 1.0, 2.0, 0.4963253595918389, 1.0, 2.0, 0.4963253595918389, 1.0, 1.0, 0.7901661366586887, 6.9112, 6.9112, 121.94756008, 1697989.421364459, 1697989.421364459, 341789.1353282346], 
processed observation next is [1.0, 0.6521739130434783, 0.5061728395061726, 0.9066666666666666, 1.0, 1.0, 0.4003873328474272, 1.0, 1.0, 0.4003873328474272, 1.0, 0.5, 0.737707670823361, 0.0, 0.0, 0.8096049824067558, 0.6064247933444497, 0.6064247933444497, 0.6572867987081434], 
reward next is 0.3427, 
noisyNet noise sample is [array([-1.9823953], dtype=float32), -0.5185504]. 
=============================================
[2019-03-23 20:13:20,880] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79644: loss -45.1850
[2019-03-23 20:13:20,885] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79645: learning rate 0.0010
[2019-03-23 20:13:20,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[31.34352]
 [31.34352]
 [31.34352]
 [31.34352]
 [31.34352]], R is [[31.37279701]
 [31.44132996]
 [31.52826691]
 [31.21298409]
 [31.30944252]].
[2019-03-23 20:13:21,264] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79776: loss -39.8546
[2019-03-23 20:13:21,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79776: learning rate 0.0010
[2019-03-23 20:13:21,417] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79788: loss 44.4476
[2019-03-23 20:13:21,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79788: learning rate 0.0010
[2019-03-23 20:13:21,427] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79797: loss 62.2265
[2019-03-23 20:13:21,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79797: learning rate 0.0010
[2019-03-23 20:13:21,829] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79871: loss 48.8273
[2019-03-23 20:13:21,830] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79872: learning rate 0.0010
[2019-03-23 20:13:22,027] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79905: loss -7.3350
[2019-03-23 20:13:22,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79907: learning rate 0.0010
[2019-03-23 20:13:22,318] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79990: loss -6.6613
[2019-03-23 20:13:22,321] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79990: learning rate 0.0010
[2019-03-23 20:13:22,499] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80017: loss 14.1751
[2019-03-23 20:13:22,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80017: learning rate 0.0010
[2019-03-23 20:13:22,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80045: loss 25.9265
[2019-03-23 20:13:22,694] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80046: learning rate 0.0010
[2019-03-23 20:13:22,921] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80100: loss -61.0068
[2019-03-23 20:13:22,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80100: learning rate 0.0010
[2019-03-23 20:13:23,208] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80184: loss -50.3882
[2019-03-23 20:13:23,215] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80185: learning rate 0.0010
[2019-03-23 20:13:23,404] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80213: loss -56.0110
[2019-03-23 20:13:23,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80213: learning rate 0.0010
[2019-03-23 20:13:23,624] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80263: loss 12.5440
[2019-03-23 20:13:23,626] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80263: learning rate 0.0010
[2019-03-23 20:13:23,857] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80313: loss -38.8828
[2019-03-23 20:13:23,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80313: learning rate 0.0010
[2019-03-23 20:13:24,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80350: loss -54.3587
[2019-03-23 20:13:24,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80350: learning rate 0.0010
[2019-03-23 20:13:28,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3788301e-08 1.0000000e+00 5.0363042e-15 4.0184617e-16 6.1871289e-16], sum to 1.0000
[2019-03-23 20:13:28,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 20:13:28,384] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.506012336141787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602888.503701165, 602888.5037011645, 143819.2109219316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3113400.0000, 
sim time next is 3114000.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5058524108876513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602698.475924039, 602698.475924039, 143793.9451421387], 
processed observation next is [1.0, 0.043478260869565216, 0.5925925925925926, 0.58, 1.0, 1.0, 0.41172906058053726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21524945568715678, 0.21524945568715678, 0.2765268175810359], 
reward next is 0.7235, 
noisyNet noise sample is [array([1.7241621], dtype=float32), -1.5776358]. 
=============================================
[2019-03-23 20:13:28,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[30.495342]
 [30.495342]
 [30.495342]
 [30.495342]
 [30.495342]], R is [[30.91386414]
 [31.3281498 ]
 [31.73816872]
 [32.14385986]
 [32.54518127]].
[2019-03-23 20:13:37,901] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87464: loss 0.1661
[2019-03-23 20:13:37,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87464: learning rate 0.0010
[2019-03-23 20:13:38,272] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87655: loss 0.1371
[2019-03-23 20:13:38,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87655: learning rate 0.0010
[2019-03-23 20:13:38,434] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87735: loss 0.0009
[2019-03-23 20:13:38,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87735: learning rate 0.0010
[2019-03-23 20:13:38,646] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87845: loss 0.0651
[2019-03-23 20:13:38,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87846: learning rate 0.0010
[2019-03-23 20:13:38,733] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87890: loss 0.0130
[2019-03-23 20:13:38,739] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87890: learning rate 0.0010
[2019-03-23 20:13:38,822] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87935: loss 0.1167
[2019-03-23 20:13:38,824] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87935: learning rate 0.0010
[2019-03-23 20:13:38,852] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87951: loss 0.1933
[2019-03-23 20:13:38,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87951: learning rate 0.0010
[2019-03-23 20:13:38,892] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87972: loss 0.1640
[2019-03-23 20:13:38,897] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87972: learning rate 0.0010
[2019-03-23 20:13:38,915] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87980: loss 0.0354
[2019-03-23 20:13:38,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87980: learning rate 0.0010
[2019-03-23 20:13:38,927] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87986: loss 0.1177
[2019-03-23 20:13:38,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87986: learning rate 0.0010
[2019-03-23 20:13:38,936] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87990: loss 0.0770
[2019-03-23 20:13:38,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87990: learning rate 0.0010
[2019-03-23 20:13:39,266] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88164: loss 0.0042
[2019-03-23 20:13:39,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88164: learning rate 0.0010
[2019-03-23 20:13:39,338] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88201: loss 0.0390
[2019-03-23 20:13:39,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88202: learning rate 0.0010
[2019-03-23 20:13:39,458] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88259: loss 0.1307
[2019-03-23 20:13:39,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88260: learning rate 0.0010
[2019-03-23 20:13:39,579] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88321: loss 0.0395
[2019-03-23 20:13:39,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88321: learning rate 0.0010
[2019-03-23 20:13:39,817] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88452: loss 0.0403
[2019-03-23 20:13:39,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88452: learning rate 0.0010
[2019-03-23 20:13:42,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2414713e-12 1.0000000e+00 2.7472028e-20 2.1604908e-24 1.5061202e-25], sum to 1.0000
[2019-03-23 20:13:42,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4037
[2019-03-23 20:13:42,560] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6902531025586766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786687.5710085721, 786687.5710085721, 174306.2998859342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [25.86666666666667, 88.16666666666667, 1.0, 2.0, 0.6691941412814703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762674.5458464265, 762674.5458464265, 170393.0087210855], 
processed observation next is [0.0, 0.9565217391304348, 0.5135802469135804, 0.8816666666666667, 1.0, 1.0, 0.6061835015255598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27238376637372375, 0.27238376637372375, 0.3276788629251644], 
reward next is 0.6723, 
noisyNet noise sample is [array([0.24337766], dtype=float32), -0.4168472]. 
=============================================
[2019-03-23 20:13:42,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.759224]
 [56.759224]
 [56.759224]
 [56.759224]
 [56.759224]], R is [[56.86395264]
 [56.96010971]
 [57.05455399]
 [57.14743042]
 [57.23900223]].
[2019-03-23 20:13:43,235] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9454420e-15 1.0000000e+00 4.2187625e-28 5.7041162e-30 1.8822095e-30], sum to 1.0000
[2019-03-23 20:13:43,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1222
[2019-03-23 20:13:43,399] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 96.0, 1.0, 2.0, 0.625019625369211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734227.102072507, 734227.102072507, 163457.5180483424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388800.0000, 
sim time next is 3389400.0000, 
raw observation next is [22.95, 97.0, 1.0, 2.0, 0.6282935442603312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736016.1108567854, 736016.1108567854, 163953.2148142153], 
processed observation next is [1.0, 0.21739130434782608, 0.4055555555555555, 0.97, 1.0, 1.0, 0.5574923145956324, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26286289673456625, 0.26286289673456625, 0.31529464387349093], 
reward next is 0.6847, 
noisyNet noise sample is [array([1.3190185], dtype=float32), -1.4073032]. 
=============================================
[2019-03-23 20:13:52,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2610101e-20 1.0000000e+00 7.6487194e-30 1.9127023e-31 3.5333923e-34], sum to 1.0000
[2019-03-23 20:13:52,034] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0151
[2019-03-23 20:13:52,040] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 84.66666666666667, 1.0, 2.0, 0.5123284281197534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615583.6811216474, 615583.6811216474, 145007.3634543359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3558000.0000, 
sim time next is 3558600.0000, 
raw observation next is [23.1, 82.5, 1.0, 2.0, 0.4951853033610343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597636.1841620754, 597636.1841620754, 142386.3215946755], 
processed observation next is [1.0, 0.17391304347826086, 0.41111111111111115, 0.825, 1.0, 1.0, 0.3990301230488503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21344149434359835, 0.21344149434359835, 0.2738198492205298], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.3651639], dtype=float32), 0.12703946]. 
=============================================
[2019-03-23 20:13:53,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3139436e-18 1.0000000e+00 5.2409846e-30 3.9759653e-31 7.3344000e-32], sum to 1.0000
[2019-03-23 20:13:53,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4663
[2019-03-23 20:13:53,389] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 80.33333333333334, 1.0, 2.0, 0.4643222218884224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564204.5140512629, 564204.5140512629, 137752.6305562971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3561600.0000, 
sim time next is 3562200.0000, 
raw observation next is [23.1, 82.5, 1.0, 2.0, 0.4674151029483292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565568.7048263142, 565568.7048263142, 138147.5465554538], 
processed observation next is [1.0, 0.21739130434782608, 0.41111111111111115, 0.825, 1.0, 1.0, 0.36597036065277283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20198882315225508, 0.20198882315225508, 0.26566835876048805], 
reward next is 0.7343, 
noisyNet noise sample is [array([-0.36769286], dtype=float32), 0.07676187]. 
=============================================
[2019-03-23 20:13:54,128] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95558: loss -61.2093
[2019-03-23 20:13:54,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95559: learning rate 0.0010
[2019-03-23 20:13:54,471] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95726: loss -53.7949
[2019-03-23 20:13:54,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95726: loss -60.6808
[2019-03-23 20:13:54,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95726: learning rate 0.0010
[2019-03-23 20:13:54,474] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95726: learning rate 0.0010
[2019-03-23 20:13:54,579] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95776: loss -20.6940
[2019-03-23 20:13:54,580] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95777: learning rate 0.0010
[2019-03-23 20:13:54,801] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95884: loss -88.1719
[2019-03-23 20:13:54,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95884: learning rate 0.0010
[2019-03-23 20:13:54,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95969: loss -18.1284
[2019-03-23 20:13:54,972] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95969: loss -26.1566
[2019-03-23 20:13:54,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95969: learning rate 0.0010
[2019-03-23 20:13:54,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95971: learning rate 0.0010
[2019-03-23 20:13:54,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95972: loss -27.5436
[2019-03-23 20:13:54,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95972: learning rate 0.0010
[2019-03-23 20:13:55,030] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95992: loss -65.6745
[2019-03-23 20:13:55,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95992: learning rate 0.0010
[2019-03-23 20:13:55,137] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96046: loss 9.8074
[2019-03-23 20:13:55,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96048: learning rate 0.0010
[2019-03-23 20:13:55,145] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96049: loss -34.9098
[2019-03-23 20:13:55,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96050: learning rate 0.0010
[2019-03-23 20:13:55,424] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96182: loss -43.1805
[2019-03-23 20:13:55,426] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96182: learning rate 0.0010
[2019-03-23 20:13:55,508] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96226: loss -11.5798
[2019-03-23 20:13:55,510] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96227: learning rate 0.0010
[2019-03-23 20:13:55,516] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96228: loss 41.0236
[2019-03-23 20:13:55,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96228: learning rate 0.0010
[2019-03-23 20:13:55,531] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96231: loss -39.9696
[2019-03-23 20:13:55,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96231: learning rate 0.0010
[2019-03-23 20:13:56,054] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96492: loss -51.5372
[2019-03-23 20:13:56,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96492: learning rate 0.0010
[2019-03-23 20:14:03,162] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 20:14:03,162] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:14:03,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:14:03,166] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:14:03,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:14:03,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:14:03,169] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:14:03,173] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:14:03,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:14:03,174] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:14:03,176] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:14:03,187] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 20:14:03,209] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 20:14:03,212] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 20:14:03,232] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 20:14:03,261] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 20:14:06,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:14:06,289] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.55, 13.0, 1.0, 2.0, 0.3593985123188697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463635.8160297155, 463635.8160297155, 113185.8445341904]
[2019-03-23 20:14:06,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:14:06,292] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.2975653944689669
[2019-03-23 20:14:38,084] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:14:38,085] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.4, 30.0, 1.0, 2.0, 0.3745002184387501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 467032.1327561716, 467032.1327561711, 125147.3814758723]
[2019-03-23 20:14:38,088] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:14:38,092] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.02060059472394893
[2019-03-23 20:15:22,908] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:22,910] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.46666666666667, 69.5, 1.0, 2.0, 0.5879120673094949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680382.3354724268, 680382.3354724268, 156510.4482874336]
[2019-03-23 20:15:22,911] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:15:22,914] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.28077147528555924
[2019-03-23 20:15:27,555] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:27,556] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.06666666666667, 62.66666666666667, 1.0, 2.0, 0.5471350427016549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640934.2636662526, 640934.2636662526, 150030.8473904114]
[2019-03-23 20:15:27,557] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:15:27,561] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.6217581453956967
[2019-03-23 20:15:28,896] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:28,897] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.02504662, 78.51368143833332, 1.0, 2.0, 0.5398705328216075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 636584.3946739939, 636584.3946739935, 149013.5177678855]
[2019-03-23 20:15:28,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:15:28,900] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.8763945236473832
[2019-03-23 20:15:30,037] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:30,039] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.5970263276148168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 684194.3795327011, 684194.3795327006, 157754.8002986462]
[2019-03-23 20:15:30,040] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:15:30,043] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.5335485752436809
[2019-03-23 20:15:37,617] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:37,618] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.25, 79.83333333333333, 1.0, 2.0, 0.600861855935811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689285.8430337764, 689285.8430337764, 158448.7187485585]
[2019-03-23 20:15:37,618] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:15:37,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.10988066779800687
[2019-03-23 20:15:41,490] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:41,491] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.61264402333333, 94.05614228666667, 1.0, 2.0, 0.634113340815301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780279.0322248063, 780279.0322248063, 166336.5056611878]
[2019-03-23 20:15:41,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:15:41,495] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.8196725657140874
[2019-03-23 20:15:45,487] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.012307188]
[2019-03-23 20:15:45,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.9561569, 82.66891887, 1.0, 2.0, 0.3078922459086899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388831.5532785133, 388831.5532785133, 116526.1773257266]
[2019-03-23 20:15:45,489] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:15:45,490] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2431447e-14 1.0000000e+00 2.5886397e-25 6.2524869e-26 2.8648790e-27], sampled 0.25500775144729104
[2019-03-23 20:15:47,901] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:15:48,041] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:15:48,131] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:15:48,140] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:15:48,164] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:15:49,178] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 100000, evaluation results [100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:15:53,096] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.511315e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:15:53,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3089
[2019-03-23 20:15:53,108] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 67.0, 1.0, 2.0, 0.531230806994579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629400.4793801071, 629400.4793801071, 147726.8523685909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3819600.0000, 
sim time next is 3820200.0000, 
raw observation next is [26.5, 68.16666666666667, 1.0, 2.0, 0.5292703047248103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626999.795098962, 626999.795098962, 147406.4072229618], 
processed observation next is [0.0, 0.21739130434782608, 0.5370370370370371, 0.6816666666666668, 1.0, 1.0, 0.43960750562477413, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2239284982496293, 0.2239284982496293, 0.2834738600441573], 
reward next is 0.7165, 
noisyNet noise sample is [array([-0.1421317], dtype=float32), -0.37990743]. 
=============================================
[2019-03-23 20:15:56,051] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103582: loss 0.0801
[2019-03-23 20:15:56,057] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103582: learning rate 0.0010
[2019-03-23 20:15:56,165] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103637: loss 0.1107
[2019-03-23 20:15:56,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103638: learning rate 0.0010
[2019-03-23 20:15:56,310] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103712: loss 0.0241
[2019-03-23 20:15:56,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103714: learning rate 0.0010
[2019-03-23 20:15:56,435] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103775: loss 0.1625
[2019-03-23 20:15:56,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103776: learning rate 0.0010
[2019-03-23 20:15:56,625] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103875: loss 0.0396
[2019-03-23 20:15:56,627] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103876: learning rate 0.0010
[2019-03-23 20:15:56,751] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103941: loss 0.1537
[2019-03-23 20:15:56,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103943: learning rate 0.0010
[2019-03-23 20:15:56,798] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103965: loss 0.0928
[2019-03-23 20:15:56,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103965: learning rate 0.0010
[2019-03-23 20:15:56,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103990: loss 0.0864
[2019-03-23 20:15:56,839] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103990: learning rate 0.0010
[2019-03-23 20:15:56,869] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104003: loss 0.0426
[2019-03-23 20:15:56,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104004: learning rate 0.0010
[2019-03-23 20:15:56,926] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1185727e-14 1.0000000e+00 1.6885555e-28 8.6701524e-28 2.4179138e-28], sum to 1.0000
[2019-03-23 20:15:56,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5706
[2019-03-23 20:15:56,940] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 92.0, 1.0, 2.0, 0.7245762281431279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825827.014875492, 825827.014875492, 180849.1527060161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894000.0000, 
sim time next is 3894600.0000, 
raw observation next is [26.0, 91.5, 1.0, 2.0, 0.7212121118455389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821990.7478944645, 821990.7478944645, 180198.6908580048], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.915, 1.0, 1.0, 0.6681096569589748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29356812424802303, 0.29356812424802303, 0.34653594395770154], 
reward next is 0.6535, 
noisyNet noise sample is [array([-0.00552781], dtype=float32), 0.8040897]. 
=============================================
[2019-03-23 20:15:56,962] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104052: loss 0.0017
[2019-03-23 20:15:56,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104052: learning rate 0.0010
[2019-03-23 20:15:56,995] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104068: loss 0.0759
[2019-03-23 20:15:56,996] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104068: learning rate 0.0010
[2019-03-23 20:15:57,166] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104160: loss 0.0020
[2019-03-23 20:15:57,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104160: learning rate 0.0010
[2019-03-23 20:15:57,176] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104161: loss 0.0009
[2019-03-23 20:15:57,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104161: learning rate 0.0010
[2019-03-23 20:15:57,197] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104171: loss 0.0000
[2019-03-23 20:15:57,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104171: learning rate 0.0010
[2019-03-23 20:15:57,204] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104173: loss 0.0029
[2019-03-23 20:15:57,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104173: learning rate 0.0010
[2019-03-23 20:15:57,888] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104525: loss 0.1346
[2019-03-23 20:15:57,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104526: learning rate 0.0010
[2019-03-23 20:15:58,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1997244e-20 1.0000000e+00 3.4900358e-38 2.3562495e-37 2.6283857e-37], sum to 1.0000
[2019-03-23 20:15:58,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4348
[2019-03-23 20:15:58,491] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.771609890515014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879463.8202674534, 879463.8202674534, 190152.0553008922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7640533583523271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870846.159454618, 870846.159454618, 188632.9325222276], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7191111408956276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31101648551950645, 0.31101648551950645, 0.36275563946582234], 
reward next is 0.6372, 
noisyNet noise sample is [array([1.1045431], dtype=float32), 0.64974564]. 
=============================================
[2019-03-23 20:15:58,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8258069e-19 1.0000000e+00 8.5039640e-32 6.5357977e-34 1.3305557e-34], sum to 1.0000
[2019-03-23 20:15:58,928] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-23 20:15:58,932] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.7765975303168591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885151.9042056603, 885151.9042056603, 191160.1568265931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3933000.0000, 
sim time next is 3933600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8042962351058892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 916741.2722920439, 916741.2722920434, 196837.0731188326], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.767019327507011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3274075972471585, 0.32740759724715834, 0.37853283292083195], 
reward next is 0.6215, 
noisyNet noise sample is [array([-0.55543405], dtype=float32), 1.5032785]. 
=============================================
[2019-03-23 20:16:05,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6237994e-21 1.0000000e+00 3.1555355e-38 0.0000000e+00 3.2658530e-38], sum to 1.0000
[2019-03-23 20:16:05,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7260
[2019-03-23 20:16:05,767] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4411135496914033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541043.1052586475, 541043.1052586475, 134425.1228089939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4061400.0000, 
sim time next is 4062000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4380637018431857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537367.2359322021, 537367.2359322016, 133976.7358518791], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 1.0, 1.0, 0.33102821647998304, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19191686997578647, 0.1919168699757863, 0.25764756894592133], 
reward next is 0.7424, 
noisyNet noise sample is [array([0.33933178], dtype=float32), 1.4035151]. 
=============================================
[2019-03-23 20:16:05,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.67932]
 [75.67932]
 [75.67932]
 [75.67932]
 [75.67932]], R is [[75.66488647]
 [75.6497345 ]
 [75.63261414]
 [75.60902405]
 [75.5785141 ]].
[2019-03-23 20:16:09,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1836786e-16 1.0000000e+00 5.9734083e-33 1.5909382e-32 2.0076497e-29], sum to 1.0000
[2019-03-23 20:16:09,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5727
[2019-03-23 20:16:10,139] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 95.5, 1.0, 2.0, 0.4431452631645587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540810.4722571144, 540810.4722571144, 134650.1315303274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4152600.0000, 
sim time next is 4153200.0000, 
raw observation next is [20.8, 96.0, 1.0, 2.0, 0.4444954125942485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542378.9306117097, 542378.9306117097, 134847.8964016383], 
processed observation next is [1.0, 0.043478260869565216, 0.32592592592592595, 0.96, 1.0, 1.0, 0.33868501499315296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19370676093275346, 0.19370676093275346, 0.2593228776954583], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.531416], dtype=float32), 1.1513189]. 
=============================================
[2019-03-23 20:16:11,706] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111564: loss -62.2150
[2019-03-23 20:16:11,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111565: learning rate 0.0010
[2019-03-23 20:16:11,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111687: loss -105.9713
[2019-03-23 20:16:11,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111688: learning rate 0.0010
[2019-03-23 20:16:12,066] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111755: loss -8.6603
[2019-03-23 20:16:12,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111755: learning rate 0.0010
[2019-03-23 20:16:12,175] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111811: loss -15.9652
[2019-03-23 20:16:12,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111812: learning rate 0.0010
[2019-03-23 20:16:12,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111891: loss -7.0535
[2019-03-23 20:16:12,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111891: learning rate 0.0010
[2019-03-23 20:16:12,441] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111952: loss 28.0776
[2019-03-23 20:16:12,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111952: learning rate 0.0010
[2019-03-23 20:16:12,530] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111993: loss 11.3244
[2019-03-23 20:16:12,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111993: learning rate 0.0010
[2019-03-23 20:16:12,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112000: loss 16.4861
[2019-03-23 20:16:12,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112000: learning rate 0.0010
[2019-03-23 20:16:12,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112027: loss 5.3307
[2019-03-23 20:16:12,587] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112027: learning rate 0.0010
[2019-03-23 20:16:12,604] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112035: loss 2.3330
[2019-03-23 20:16:12,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112036: learning rate 0.0010
[2019-03-23 20:16:12,624] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112045: loss 9.5974
[2019-03-23 20:16:12,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112046: learning rate 0.0010
[2019-03-23 20:16:12,669] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112063: loss 23.4188
[2019-03-23 20:16:12,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112063: learning rate 0.0010
[2019-03-23 20:16:12,815] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112139: loss 21.2240
[2019-03-23 20:16:12,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112140: learning rate 0.0010
[2019-03-23 20:16:12,929] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112205: loss 7.2522
[2019-03-23 20:16:12,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112205: learning rate 0.0010
[2019-03-23 20:16:12,953] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112212: loss -3.7567
[2019-03-23 20:16:12,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112213: learning rate 0.0010
[2019-03-23 20:16:13,669] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112582: loss -41.7153
[2019-03-23 20:16:13,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112584: learning rate 0.0010
[2019-03-23 20:16:15,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4617163e-17 1.0000000e+00 9.2432490e-35 3.2371441e-35 1.5233431e-35], sum to 1.0000
[2019-03-23 20:16:15,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-23 20:16:15,412] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 75.0, 1.0, 2.0, 0.4677825963521917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578687.4934094183, 578687.4934094183, 138555.9814439075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [22.33333333333334, 76.33333333333333, 1.0, 2.0, 0.4192248271931635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518974.2246853504, 518974.2246853504, 131349.9532132567], 
processed observation next is [1.0, 0.21739130434782608, 0.38271604938271625, 0.7633333333333333, 1.0, 1.0, 0.3086009847537661, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18534793738762514, 0.18534793738762514, 0.2525960638716475], 
reward next is 0.7474, 
noisyNet noise sample is [array([-1.1417726], dtype=float32), 0.4620856]. 
=============================================
[2019-03-23 20:16:19,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2540141e-18 1.0000000e+00 1.9031079e-33 1.9156357e-33 5.7058891e-34], sum to 1.0000
[2019-03-23 20:16:19,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7753
[2019-03-23 20:16:19,065] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333334, 86.0, 1.0, 2.0, 0.9374816088746607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.948439796895838, 6.9112, 121.9256114733609, 1122722.051200847, 1103652.014168638, 227809.3800066813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4328400.0000, 
sim time next is 4329000.0000, 
raw observation next is [24.1, 88.0, 1.0, 2.0, 0.8689670110828479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260201546311, 1018183.226604028, 1018183.226604028, 212023.706102492], 
processed observation next is [1.0, 0.08695652173913043, 0.4481481481481482, 0.88, 1.0, 1.0, 0.8440083465271999, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.80946197970225, 0.36363686664429573, 0.36363686664429573, 0.40773789635094615], 
reward next is 0.5923, 
noisyNet noise sample is [array([0.0387371], dtype=float32), -1.1401821]. 
=============================================
[2019-03-23 20:16:19,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.94919]
 [60.94919]
 [60.94919]
 [60.94919]
 [60.94919]], R is [[60.93196487]
 [60.69835281]
 [60.09136963]
 [60.2065773 ]
 [60.31861877]].
[2019-03-23 20:16:19,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6272320e-18 1.0000000e+00 6.8300970e-34 1.3516224e-34 1.4452084e-34], sum to 1.0000
[2019-03-23 20:16:19,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0983
[2019-03-23 20:16:19,811] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.534485915371232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638014.7373969996, 638014.7373970001, 148437.7374722651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4341600.0000, 
sim time next is 4342200.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.6571767151382696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 781976.9507730954, 781976.9507730949, 169691.6682981087], 
processed observation next is [1.0, 0.2608695652173913, 0.4135802469135804, 0.89, 1.0, 1.0, 0.5918770418312733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2792774824189626, 0.27927748241896244, 0.32633013134251676], 
reward next is 0.6737, 
noisyNet noise sample is [array([0.7385914], dtype=float32), 1.1971701]. 
=============================================
[2019-03-23 20:16:25,740] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.54639438e-20 1.00000000e+00 1.73967433e-33 6.30856479e-36
 1.12053805e-35], sum to 1.0000
[2019-03-23 20:16:25,748] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5105
[2019-03-23 20:16:25,754] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.66666666666667, 1.0, 2.0, 0.615244172961707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707088.9030206772, 707088.9030206772, 161011.2846291801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4447200.0000, 
sim time next is 4447800.0000, 
raw observation next is [27.1, 74.5, 1.0, 2.0, 0.6193386137137085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710712.638730079, 710712.638730079, 161677.3140221527], 
processed observation next is [0.0, 0.4782608695652174, 0.5592592592592593, 0.745, 1.0, 1.0, 0.5468316829925101, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2538259424035997, 0.2538259424035997, 0.3109179115810629], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.10282382], dtype=float32), 0.033338774]. 
=============================================
[2019-03-23 20:16:26,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6010922e-22 1.0000000e+00 1.6951112e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:16:26,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2774
[2019-03-23 20:16:26,593] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 66.5, 1.0, 2.0, 0.647354711370501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737772.3657206857, 737772.3657206857, 166414.7957691248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4456200.0000, 
sim time next is 4456800.0000, 
raw observation next is [29.0, 65.0, 1.0, 2.0, 0.640980675951304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731009.9949536968, 731009.9949536968, 165295.2182767014], 
processed observation next is [0.0, 0.6086956521739131, 0.6296296296296297, 0.65, 1.0, 1.0, 0.5725960427991714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2610749981977489, 0.2610749981977489, 0.3178754197628873], 
reward next is 0.6821, 
noisyNet noise sample is [array([-1.1946121], dtype=float32), 1.0001428]. 
=============================================
[2019-03-23 20:16:27,286] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119422: loss 0.0562
[2019-03-23 20:16:27,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119423: learning rate 0.0010
[2019-03-23 20:16:27,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119649: loss 0.0768
[2019-03-23 20:16:27,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119649: learning rate 0.0010
[2019-03-23 20:16:27,926] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119743: loss 0.1766
[2019-03-23 20:16:27,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119744: learning rate 0.0010
[2019-03-23 20:16:28,035] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119802: loss 0.0016
[2019-03-23 20:16:28,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119803: learning rate 0.0010
[2019-03-23 20:16:28,058] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119810: loss 0.0017
[2019-03-23 20:16:28,061] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119810: learning rate 0.0010
[2019-03-23 20:16:28,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119899: loss 0.3032
[2019-03-23 20:16:28,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119899: learning rate 0.0010
[2019-03-23 20:16:28,295] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119923: loss 0.1202
[2019-03-23 20:16:28,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119925: learning rate 0.0010
[2019-03-23 20:16:28,440] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119994: loss 0.0007
[2019-03-23 20:16:28,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119994: learning rate 0.0010
[2019-03-23 20:16:28,518] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120035: loss 0.0231
[2019-03-23 20:16:28,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120036: learning rate 0.0010
[2019-03-23 20:16:28,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3759494e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:16:28,524] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120036: loss 0.0813
[2019-03-23 20:16:28,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120038: learning rate 0.0010
[2019-03-23 20:16:28,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9014
[2019-03-23 20:16:28,536] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 94.00000000000001, 1.0, 2.0, 0.6653498770612468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758291.105356137, 758291.105356137, 169685.964532902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4493400.0000, 
sim time next is 4494000.0000, 
raw observation next is [24.66666666666667, 94.0, 1.0, 2.0, 0.6585278009620904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 750512.2624758733, 750512.2624758729, 168438.8443565942], 
processed observation next is [0.0, 0.0, 0.469135802469136, 0.94, 1.0, 1.0, 0.5934854773358219, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2680400937413833, 0.26804009374138316, 0.32392085453191194], 
reward next is 0.6761, 
noisyNet noise sample is [array([0.7113332], dtype=float32), 0.9126044]. 
=============================================
[2019-03-23 20:16:28,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.055885]
 [79.055885]
 [79.055885]
 [79.055885]
 [79.055885]], R is [[78.94142151]
 [78.82569122]
 [78.7099762 ]
 [78.59771729]
 [78.48870087]].
[2019-03-23 20:16:28,584] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120064: loss 0.1352
[2019-03-23 20:16:28,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120064: learning rate 0.0010
[2019-03-23 20:16:28,818] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120178: loss 0.0447
[2019-03-23 20:16:28,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120179: learning rate 0.0010
[2019-03-23 20:16:28,881] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120204: loss 0.1626
[2019-03-23 20:16:28,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120204: learning rate 0.0010
[2019-03-23 20:16:28,945] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120240: loss 0.1689
[2019-03-23 20:16:28,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120240: learning rate 0.0010
[2019-03-23 20:16:29,006] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120270: loss 0.0826
[2019-03-23 20:16:29,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120271: learning rate 0.0010
[2019-03-23 20:16:29,609] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120566: loss 0.0139
[2019-03-23 20:16:29,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120566: learning rate 0.0010
[2019-03-23 20:16:34,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9908829e-17 1.0000000e+00 6.2140968e-30 4.5474554e-31 7.6026263e-34], sum to 1.0000
[2019-03-23 20:16:34,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6893
[2019-03-23 20:16:34,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1604415.693926572 W.
[2019-03-23 20:16:34,857] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.4689981250714695, 1.0, 2.0, 0.4689981250714695, 1.0, 1.0, 0.7466602893163654, 6.911200000000001, 6.9112, 121.94756008, 1604415.693926572, 1604415.693926571, 328624.5842943025], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [27.0, 71.0, 1.0, 2.0, 0.7044537840493161, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1517884.795312549, 1517884.795312549, 318035.0099961736], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.71, 1.0, 1.0, 0.6481592667253764, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5421017126116247, 0.5421017126116247, 0.61160578845418], 
reward next is 0.3884, 
noisyNet noise sample is [array([0.21528448], dtype=float32), -0.844098]. 
=============================================
[2019-03-23 20:16:37,054] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6281684e-18 1.0000000e+00 3.1498206e-32 4.1254736e-34 2.5595444e-33], sum to 1.0000
[2019-03-23 20:16:37,065] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2499
[2019-03-23 20:16:37,074] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 83.66666666666667, 1.0, 2.0, 0.6933083398135331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790171.4467828627, 790171.4467828627, 174881.0324503953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4648200.0000, 
sim time next is 4648800.0000, 
raw observation next is [26.86666666666667, 83.33333333333334, 1.0, 2.0, 0.6888160979561686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 785048.9654352954, 785048.9654352949, 174037.1369915279], 
processed observation next is [1.0, 0.8260869565217391, 0.5506172839506175, 0.8333333333333335, 1.0, 1.0, 0.6295429737573436, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28037463051260547, 0.2803746305126053, 0.3346868019067844], 
reward next is 0.6653, 
noisyNet noise sample is [array([-0.4392974], dtype=float32), -0.25621864]. 
=============================================
[2019-03-23 20:16:38,565] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7381602e-19 1.0000000e+00 1.7426273e-36 1.5148975e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 20:16:38,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-23 20:16:38,586] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.6039261973650975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701371.7237633121, 701371.7237633121, 159381.6378134763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4690800.0000, 
sim time next is 4691400.0000, 
raw observation next is [23.3, 98.33333333333334, 1.0, 2.0, 0.6545212581623552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758412.3333690261, 758412.3333690261, 168320.4048355568], 
processed observation next is [1.0, 0.30434782608695654, 0.41851851851851857, 0.9833333333333334, 1.0, 1.0, 0.5887157835266132, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27086154763179504, 0.27086154763179504, 0.32369308622222465], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.48402658], dtype=float32), 0.74049586]. 
=============================================
[2019-03-23 20:16:38,667] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 20:16:38,668] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:16:38,670] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:16:38,671] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:16:38,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:38,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:38,674] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:16:38,673] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:38,674] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:16:38,676] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:38,676] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:16:38,693] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 20:16:38,693] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 20:16:38,716] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 20:16:38,717] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 20:16:38,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 20:16:54,324] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.0033774215]
[2019-03-23 20:16:54,325] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.6, 41.66666666666667, 1.0, 2.0, 0.5456180537757015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690478.3253093347, 690478.3253093342, 151266.3065236057]
[2019-03-23 20:16:54,327] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:16:54,331] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1814851e-20 1.0000000e+00 5.0807065e-37 0.0000000e+00 0.0000000e+00], sampled 0.4282450263643949
[2019-03-23 20:17:18,804] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.0033774215]
[2019-03-23 20:17:18,808] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333333, 90.66666666666667, 1.0, 2.0, 0.5757601971761583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666605.5312374722, 666605.5312374722, 154460.8561546409]
[2019-03-23 20:17:18,810] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:17:18,814] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1814851e-20 1.0000000e+00 5.0807065e-37 0.0000000e+00 0.0000000e+00], sampled 0.14699333303060358
[2019-03-23 20:18:15,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.0033774215]
[2019-03-23 20:18:15,128] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.5852577835145056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679901.0102579503, 679901.0102579503, 156176.0434792765]
[2019-03-23 20:18:15,128] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:18:15,131] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1814851e-20 1.0000000e+00 5.0807065e-37 0.0000000e+00 0.0000000e+00], sampled 0.8184130325893106
[2019-03-23 20:18:18,481] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.0033774215]
[2019-03-23 20:18:18,482] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.03333333333333, 93.50000000000001, 1.0, 2.0, 0.2798538165580187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359262.7627724654, 359262.7627724654, 113121.3102451115]
[2019-03-23 20:18:18,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:18:18,485] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1814851e-20 1.0000000e+00 5.0807065e-37 0.0000000e+00 0.0000000e+00], sampled 0.5208249652323563
[2019-03-23 20:18:22,891] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:18:22,915] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:18:23,100] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:18:23,222] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:18:23,274] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:18:24,289] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 125000, evaluation results [125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:18:24,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1629702e-19 1.0000000e+00 1.9787057e-35 2.5210385e-38 5.1822758e-38], sum to 1.0000
[2019-03-23 20:18:24,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6611
[2019-03-23 20:18:24,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1355495.524763631 W.
[2019-03-23 20:18:24,703] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 1.005730547894984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.282102529781888, 6.9112, 121.9243737249813, 1355495.524763631, 1165562.878405626, 243170.1398581379], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4698600.0000, 
sim time next is 4699200.0000, 
raw observation next is [23.33333333333334, 98.0, 1.0, 2.0, 0.3780118966595375, 1.0, 1.0, 0.3780118966595375, 1.0, 1.0, 0.6018072504699831, 6.9112, 6.9112, 121.94756008, 1292897.032676017, 1292897.032676017, 287584.1473304011], 
processed observation next is [1.0, 0.391304347826087, 0.4197530864197533, 0.98, 1.0, 1.0, 0.2595379722137351, 1.0, 0.5, 0.2595379722137351, 1.0, 0.5, 0.5022590630874788, 0.0, 0.0, 0.8096049824067558, 0.4617489402414346, 0.4617489402414346, 0.5530464371738483], 
reward next is 0.4470, 
noisyNet noise sample is [array([-0.4845454], dtype=float32), -0.021133544]. 
=============================================
[2019-03-23 20:18:28,938] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127426: loss -68.6039
[2019-03-23 20:18:28,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127426: learning rate 0.0010
[2019-03-23 20:18:29,567] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127750: loss -60.1501
[2019-03-23 20:18:29,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127750: learning rate 0.0010
[2019-03-23 20:18:29,607] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127767: loss -67.1143
[2019-03-23 20:18:29,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127767: learning rate 0.0010
[2019-03-23 20:18:29,672] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127805: loss -42.3503
[2019-03-23 20:18:29,673] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127805: learning rate 0.0010
[2019-03-23 20:18:29,841] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127893: loss -35.4828
[2019-03-23 20:18:29,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127893: learning rate 0.0010
[2019-03-23 20:18:29,897] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127915: loss -70.7709
[2019-03-23 20:18:29,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127915: learning rate 0.0010
[2019-03-23 20:18:29,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127950: loss -58.7042
[2019-03-23 20:18:29,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127951: learning rate 0.0010
[2019-03-23 20:18:29,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127961: loss -10.7978
[2019-03-23 20:18:29,988] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127962: learning rate 0.0010
[2019-03-23 20:18:30,012] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127975: loss -43.5819
[2019-03-23 20:18:30,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127976: learning rate 0.0010
[2019-03-23 20:18:30,052] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127993: loss -39.7911
[2019-03-23 20:18:30,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127993: learning rate 0.0010
[2019-03-23 20:18:30,118] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128027: loss -20.1573
[2019-03-23 20:18:30,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128027: learning rate 0.0010
[2019-03-23 20:18:30,404] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128169: loss 3.3043
[2019-03-23 20:18:30,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128169: learning rate 0.0010
[2019-03-23 20:18:30,496] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128224: loss 18.8706
[2019-03-23 20:18:30,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128224: learning rate 0.0010
[2019-03-23 20:18:30,534] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128239: loss -22.0167
[2019-03-23 20:18:30,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128239: learning rate 0.0010
[2019-03-23 20:18:30,539] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128240: loss 1.4283
[2019-03-23 20:18:30,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128243: learning rate 0.0010
[2019-03-23 20:18:31,162] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128568: loss 7.5872
[2019-03-23 20:18:31,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128568: learning rate 0.0010
[2019-03-23 20:18:33,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3261357e-21 1.0000000e+00 8.3015595e-38 1.8818427e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 20:18:33,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6904
[2019-03-23 20:18:33,271] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333333, 93.16666666666667, 1.0, 2.0, 0.8272649980115636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942937.3008301703, 942937.3008301703, 201636.9790613338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4867800.0000, 
sim time next is 4868400.0000, 
raw observation next is [25.86666666666667, 93.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.454057462420761, 6.9112, 121.924252405975, 1440986.633656215, 1162999.17452786, 245586.4915850116], 
processed observation next is [1.0, 0.34782608695652173, 0.5135802469135804, 0.9333333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05428574624207609, 0.0, 0.8094502436895025, 0.5146380834486481, 0.4153568480456643, 0.47228171458656076], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3880963], dtype=float32), 2.1412678]. 
=============================================
[2019-03-23 20:18:37,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7565897e-21 1.0000000e+00 4.2736209e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:18:37,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1465
[2019-03-23 20:18:37,345] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 82.33333333333334, 1.0, 2.0, 0.5752440677897533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683753.2648210963, 683753.2648210963, 155125.6145180723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4945800.0000, 
sim time next is 4946400.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5537677345398572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 658111.790752446, 658111.7907524456, 151507.0661203344], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.83, 1.0, 1.0, 0.468771112547449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23503992526873074, 0.23503992526873058, 0.2913597425391046], 
reward next is 0.7086, 
noisyNet noise sample is [array([-2.0081992], dtype=float32), -1.198321]. 
=============================================
[2019-03-23 20:18:44,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135369: loss 0.0891
[2019-03-23 20:18:44,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135369: learning rate 0.0010
[2019-03-23 20:18:44,850] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135693: loss 0.1242
[2019-03-23 20:18:44,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135693: learning rate 0.0010
[2019-03-23 20:18:45,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135804: loss 0.0001
[2019-03-23 20:18:45,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135804: learning rate 0.0010
[2019-03-23 20:18:45,078] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135814: loss 0.0278
[2019-03-23 20:18:45,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135814: learning rate 0.0010
[2019-03-23 20:18:45,082] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135815: loss 0.0182
[2019-03-23 20:18:45,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135815: learning rate 0.0010
[2019-03-23 20:18:45,132] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135842: loss 0.0528
[2019-03-23 20:18:45,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135843: learning rate 0.0010
[2019-03-23 20:18:45,177] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135865: loss 0.1428
[2019-03-23 20:18:45,178] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135865: learning rate 0.0010
[2019-03-23 20:18:45,219] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135889: loss 0.0608
[2019-03-23 20:18:45,224] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135889: learning rate 0.0010
[2019-03-23 20:18:45,254] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135905: loss 0.0357
[2019-03-23 20:18:45,256] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135905: learning rate 0.0010
[2019-03-23 20:18:45,540] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136056: loss 0.0424
[2019-03-23 20:18:45,543] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136056: learning rate 0.0010
[2019-03-23 20:18:45,591] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136083: loss 0.0130
[2019-03-23 20:18:45,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136083: learning rate 0.0010
[2019-03-23 20:18:45,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.279295e-19 1.000000e+00 8.583396e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:18:45,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1475
[2019-03-23 20:18:45,623] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.7144199260309619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814245.3434556775, 814245.3434556775, 178892.6998453086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5109000.0000, 
sim time next is 5109600.0000, 
raw observation next is [25.0, 100.0, 1.0, 2.0, 0.7143755224048348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814194.7084608183, 814194.7084608183, 178884.1841718933], 
processed observation next is [0.0, 0.13043478260869565, 0.48148148148148145, 1.0, 1.0, 1.0, 0.6599708600057558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2907838244502922, 0.2907838244502922, 0.34400804648441025], 
reward next is 0.6560, 
noisyNet noise sample is [array([0.8670961], dtype=float32), -0.028166266]. 
=============================================
[2019-03-23 20:18:45,760] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136168: loss 0.0668
[2019-03-23 20:18:45,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136169: learning rate 0.0010
[2019-03-23 20:18:45,993] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136289: loss 0.1987
[2019-03-23 20:18:45,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136289: learning rate 0.0010
[2019-03-23 20:18:46,045] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136315: loss 0.2480
[2019-03-23 20:18:46,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136316: learning rate 0.0010
[2019-03-23 20:18:46,079] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136332: loss 0.1131
[2019-03-23 20:18:46,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136333: learning rate 0.0010
[2019-03-23 20:18:46,620] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136617: loss 0.1997
[2019-03-23 20:18:46,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136617: learning rate 0.0010
[2019-03-23 20:18:49,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2032266e-21 1.0000000e+00 4.7843666e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:18:49,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-23 20:18:49,300] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 84.0, 1.0, 2.0, 0.7395327964208376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842882.9564575694, 842882.9564575689, 183765.2355557225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169000.0000, 
sim time next is 5169600.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.7360319343837549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838890.6631617954, 838890.6631617954, 183079.3868782075], 
processed observation next is [0.0, 0.8695652173913043, 0.5666666666666667, 0.85, 1.0, 1.0, 0.6857523028378034, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2996038082720698, 0.2996038082720698, 0.3520757439965529], 
reward next is 0.6479, 
noisyNet noise sample is [array([-0.8962847], dtype=float32), -0.95121825]. 
=============================================
[2019-03-23 20:18:50,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2124511e-19 1.0000000e+00 2.0330744e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:18:50,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3707
[2019-03-23 20:18:50,218] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 85.5, 1.0, 2.0, 0.7181165996343591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818460.8003034717, 818460.8003034717, 179602.4803715475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5171400.0000, 
sim time next is 5172000.0000, 
raw observation next is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.714321854837514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814133.5094769928, 814133.5094769928, 178873.0137151155], 
processed observation next is [0.0, 0.8695652173913043, 0.5469135802469137, 0.8566666666666666, 1.0, 1.0, 0.6599069700446595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29076196767035456, 0.29076196767035456, 0.34398656483676054], 
reward next is 0.6560, 
noisyNet noise sample is [array([1.5453565], dtype=float32), -0.61594844]. 
=============================================
[2019-03-23 20:18:50,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.61092]
 [62.61092]
 [62.61092]
 [62.61092]
 [62.61092]], R is [[62.64081192]
 [62.66901398]
 [62.69671631]
 [62.72536469]
 [62.74603271]].
[2019-03-23 20:18:51,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1844923e-13 1.0000000e+00 2.0851237e-24 7.8618117e-27 4.1998173e-27], sum to 1.0000
[2019-03-23 20:18:51,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6283
[2019-03-23 20:18:51,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1901608.626631194 W.
[2019-03-23 20:18:51,698] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.5557803430028265, 1.0, 2.0, 0.5557803430028265, 1.0, 2.0, 0.8848204065626096, 6.911199999999999, 6.9112, 121.94756008, 1901608.626631194, 1901608.626631194, 371809.3962218447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 0.82968025646475, 1.0, 2.0, 0.82968025646475, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1892497.530804569, 1892497.530804569, 356170.8950393042], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 0.7972384005532738, 1.0, 1.0, 0.7972384005532738, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.675891975287346, 0.675891975287346, 0.6849440289217389], 
reward next is 0.3151, 
noisyNet noise sample is [array([0.9329678], dtype=float32), -0.9763455]. 
=============================================
[2019-03-23 20:18:59,933] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9277286e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:18:59,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-23 20:18:59,942] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 91.0, 1.0, 2.0, 0.7227903746608298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832297.3347077536, 832297.3347077536, 180931.5343731668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5380200.0000, 
sim time next is 5380800.0000, 
raw observation next is [24.53333333333333, 91.0, 1.0, 2.0, 0.7434264956064697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855412.90559605, 855412.90559605, 184938.7212647875], 
processed observation next is [1.0, 0.2608695652173913, 0.46419753086419746, 0.91, 1.0, 1.0, 0.6945553519124639, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3055046091414464, 0.3055046091414464, 0.3556513870476683], 
reward next is 0.6443, 
noisyNet noise sample is [array([0.23842795], dtype=float32), -0.3340707]. 
=============================================
[2019-03-23 20:19:00,025] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143374: loss -184.6416
[2019-03-23 20:19:00,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143374: learning rate 0.0010
[2019-03-23 20:19:00,908] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143801: loss -93.4032
[2019-03-23 20:19:00,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143802: learning rate 0.0010
[2019-03-23 20:19:00,936] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143817: loss -124.9813
[2019-03-23 20:19:00,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143818: learning rate 0.0010
[2019-03-23 20:19:00,941] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143818: loss -123.8211
[2019-03-23 20:19:00,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143820: learning rate 0.0010
[2019-03-23 20:19:00,982] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143838: loss -88.4155
[2019-03-23 20:19:00,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143839: learning rate 0.0010
[2019-03-23 20:19:01,021] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143856: loss -117.0783
[2019-03-23 20:19:01,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143858: learning rate 0.0010
[2019-03-23 20:19:01,043] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143869: loss -121.5348
[2019-03-23 20:19:01,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143869: learning rate 0.0010
[2019-03-23 20:19:01,149] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143919: loss -35.2003
[2019-03-23 20:19:01,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143922: learning rate 0.0010
[2019-03-23 20:19:01,229] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143959: loss -60.6855
[2019-03-23 20:19:01,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143959: learning rate 0.0010
[2019-03-23 20:19:01,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143960: loss -89.8344
[2019-03-23 20:19:01,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143962: learning rate 0.0010
[2019-03-23 20:19:01,365] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144024: loss -72.8258
[2019-03-23 20:19:01,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144025: learning rate 0.0010
[2019-03-23 20:19:01,703] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144189: loss -48.2727
[2019-03-23 20:19:01,705] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144190: learning rate 0.0010
[2019-03-23 20:19:01,784] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144229: loss -9.7329
[2019-03-23 20:19:01,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144231: learning rate 0.0010
[2019-03-23 20:19:01,847] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144258: loss -45.8981
[2019-03-23 20:19:01,850] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144258: learning rate 0.0010
[2019-03-23 20:19:01,974] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144321: loss 29.5151
[2019-03-23 20:19:01,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144321: learning rate 0.0010
[2019-03-23 20:19:02,455] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144566: loss -46.1139
[2019-03-23 20:19:02,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144566: learning rate 0.0010
[2019-03-23 20:19:04,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0083279e-20 1.0000000e+00 3.8107887e-32 8.3513362e-37 1.2221037e-36], sum to 1.0000
[2019-03-23 20:19:04,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9267
[2019-03-23 20:19:04,037] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 89.5, 1.0, 2.0, 0.7613156461045993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867724.0269273018, 867724.0269273018, 188081.4720486476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5441400.0000, 
sim time next is 5442000.0000, 
raw observation next is [27.13333333333333, 89.66666666666667, 1.0, 2.0, 0.7576138436552293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 863502.4501436652, 863502.4501436652, 187342.4055900972], 
processed observation next is [1.0, 1.0, 0.5604938271604937, 0.8966666666666667, 1.0, 1.0, 0.7114450519705111, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30839373219416616, 0.30839373219416616, 0.3602738569040331], 
reward next is 0.6397, 
noisyNet noise sample is [array([0.32260305], dtype=float32), 0.67564595]. 
=============================================
[2019-03-23 20:19:04,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.306335]
 [50.306335]
 [50.306335]
 [50.306335]
 [50.306335]], R is [[50.44299698]
 [50.57687378]
 [50.70815659]
 [50.83693695]
 [50.96316147]].
[2019-03-23 20:19:13,495] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 20:19:13,500] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:19:13,501] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:19:13,502] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:19:13,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:19:13,503] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:19:13,503] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:19:13,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:19:13,505] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:19:13,508] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:19:13,509] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:19:13,521] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 20:19:13,523] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 20:19:13,545] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 20:19:13,578] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 20:19:13,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 20:19:27,456] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.025680553]
[2019-03-23 20:19:27,458] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.81384279333333, 63.04460846666667, 1.0, 2.0, 0.3990305704726724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492065.6614629149, 492065.6614629149, 128427.6865415054]
[2019-03-23 20:19:27,459] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:19:27,463] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5023787e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6555624534066246
[2019-03-23 20:19:49,025] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.025680553]
[2019-03-23 20:19:49,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.53333333333333, 31.33333333333334, 1.0, 2.0, 0.3616185663126223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452777.9898722207, 452777.9898722207, 123436.4315503408]
[2019-03-23 20:19:49,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:19:49,032] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5023787e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8888183405547156
[2019-03-23 20:19:56,406] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.025680553]
[2019-03-23 20:19:56,407] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.51231658, 100.0747984066667, 1.0, 2.0, 0.6007611090814846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688253.7128408606, 688253.7128408606, 158386.387902819]
[2019-03-23 20:19:56,407] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:19:56,411] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5023787e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8871270969543198
[2019-03-23 20:20:53,118] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), 0.025680553]
[2019-03-23 20:20:53,120] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.93663709333333, 67.31841031666667, 1.0, 2.0, 0.5080321647257625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600331.0837951456, 600331.0837951456, 143948.4050164171]
[2019-03-23 20:20:53,121] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:20:53,123] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5023787e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7943110892938733
[2019-03-23 20:20:57,544] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:20:57,754] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:20:57,838] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:20:58,004] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:20:58,031] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:20:59,045] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 150000, evaluation results [150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:20:59,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8248109e-21 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:20:59,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6473
[2019-03-23 20:20:59,575] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 95.66666666666666, 1.0, 2.0, 0.6315028945720793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720224.5809745941, 720224.5809745941, 163607.1322121412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5642400.0000, 
sim time next is 5643000.0000, 
raw observation next is [24.4, 95.5, 1.0, 2.0, 0.6338604019379994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722386.0257502102, 722386.0257502102, 163999.3525966698], 
processed observation next is [0.0, 0.30434782608695654, 0.4592592592592592, 0.955, 1.0, 1.0, 0.5641195261166659, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25799500919650364, 0.25799500919650364, 0.3153833703782112], 
reward next is 0.6846, 
noisyNet noise sample is [array([-0.24027707], dtype=float32), 1.5108948]. 
=============================================
[2019-03-23 20:20:59,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.121284]
 [67.121284]
 [67.121284]
 [67.121284]
 [67.121284]], R is [[67.13468933]
 [67.14871216]
 [67.16364288]
 [67.17945862]
 [67.1962738 ]].
[2019-03-23 20:21:01,580] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151322: loss 0.0162
[2019-03-23 20:21:01,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151322: learning rate 0.0010
[2019-03-23 20:21:02,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2294126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:21:02,023] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5952
[2019-03-23 20:21:02,029] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.06666666666666, 77.0, 1.0, 2.0, 0.7495953158034796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854358.1113218231, 854358.1113218231, 185750.1398131133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683800.0000, 
sim time next is 5684400.0000, 
raw observation next is [28.9, 78.0, 1.0, 2.0, 0.7504136243017929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855291.3063201389, 855291.3063201389, 185912.1080206737], 
processed observation next is [0.0, 0.8260869565217391, 0.6259259259259259, 0.78, 1.0, 1.0, 0.7028733622640392, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.305461180828621, 0.305461180828621, 0.35752328465514177], 
reward next is 0.6425, 
noisyNet noise sample is [array([-0.6432046], dtype=float32), -0.16778119]. 
=============================================
[2019-03-23 20:21:02,402] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151757: loss 0.2412
[2019-03-23 20:21:02,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151758: learning rate 0.0010
[2019-03-23 20:21:02,447] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151782: loss 0.2203
[2019-03-23 20:21:02,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151783: learning rate 0.0010
[2019-03-23 20:21:02,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151784: loss 0.3256
[2019-03-23 20:21:02,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151784: learning rate 0.0010
[2019-03-23 20:21:02,475] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151797: loss 0.1638
[2019-03-23 20:21:02,477] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151797: learning rate 0.0010
[2019-03-23 20:21:02,554] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151839: loss 0.0204
[2019-03-23 20:21:02,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151839: learning rate 0.0010
[2019-03-23 20:21:02,582] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151855: loss 0.0093
[2019-03-23 20:21:02,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151855: learning rate 0.0010
[2019-03-23 20:21:02,800] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151975: loss 0.0508
[2019-03-23 20:21:02,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151975: learning rate 0.0010
[2019-03-23 20:21:02,823] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151985: loss 0.0186
[2019-03-23 20:21:02,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151985: learning rate 0.0010
[2019-03-23 20:21:02,828] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151986: loss 0.0001
[2019-03-23 20:21:02,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151986: learning rate 0.0010
[2019-03-23 20:21:02,953] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152063: loss 0.2094
[2019-03-23 20:21:02,955] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152065: learning rate 0.0010
[2019-03-23 20:21:02,979] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152075: loss 0.1877
[2019-03-23 20:21:02,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152075: learning rate 0.0010
[2019-03-23 20:21:03,314] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152269: loss 0.0338
[2019-03-23 20:21:03,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152269: learning rate 0.0010
[2019-03-23 20:21:03,388] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152310: loss 0.0012
[2019-03-23 20:21:03,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152310: learning rate 0.0010
[2019-03-23 20:21:03,476] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152354: loss 0.1862
[2019-03-23 20:21:03,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152354: learning rate 0.0010
[2019-03-23 20:21:03,883] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152570: loss 0.0527
[2019-03-23 20:21:03,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152571: learning rate 0.0010
[2019-03-23 20:21:04,658] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.14532334e-26 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 20:21:04,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0890
[2019-03-23 20:21:04,673] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 70.0, 1.0, 2.0, 0.4796224009455317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576668.5148492754, 576668.5148492754, 139894.2849463342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5742000.0000, 
sim time next is 5742600.0000, 
raw observation next is [25.41666666666667, 69.16666666666667, 1.0, 2.0, 0.4805128412681891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 577656.5506808585, 577656.5506808581, 140028.4391723539], 
processed observation next is [0.0, 0.4782608695652174, 0.49691358024691373, 0.6916666666666668, 1.0, 1.0, 0.38156290627165373, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2063059109574495, 0.20630591095744932, 0.2692854599468344], 
reward next is 0.7307, 
noisyNet noise sample is [array([0.9599775], dtype=float32), 0.32640395]. 
=============================================
[2019-03-23 20:21:07,018] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.79499e-24 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:21:07,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8129
[2019-03-23 20:21:07,032] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 80.33333333333334, 1.0, 2.0, 0.532885361868483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629364.2588961768, 629364.2588961768, 147916.6385414228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5778600.0000, 
sim time next is 5779200.0000, 
raw observation next is [24.6, 80.66666666666667, 1.0, 2.0, 0.5303833761545508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627007.4572729905, 627007.4572729905, 147534.7788786869], 
processed observation next is [0.0, 0.9130434782608695, 0.46666666666666673, 0.8066666666666668, 1.0, 1.0, 0.4409325906601795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22393123474035376, 0.22393123474035376, 0.2837207286128594], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.0438166], dtype=float32), -1.7259233]. 
=============================================
[2019-03-23 20:21:08,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0581599e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:21:08,355] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7746
[2019-03-23 20:21:08,359] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 82.16666666666667, 1.0, 2.0, 0.5567247921623961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676071.3272809503, 676071.3272809503, 152506.2074314958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5814600.0000, 
sim time next is 5815200.0000, 
raw observation next is [22.96666666666667, 81.33333333333334, 1.0, 2.0, 0.4893124894247683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594019.734441463, 594019.734441463, 141579.9782050494], 
processed observation next is [1.0, 0.30434782608695654, 0.4061728395061729, 0.8133333333333335, 1.0, 1.0, 0.39203867788662894, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21214990515766535, 0.21214990515766535, 0.27226918885586426], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.00783618], dtype=float32), 1.3461064]. 
=============================================
[2019-03-23 20:21:13,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8093992e-22 1.0000000e+00 2.4492040e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:21:13,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9351
[2019-03-23 20:21:13,875] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 64.0, 1.0, 2.0, 0.3399830176854812, 1.0, 1.0, 0.3399830176854812, 1.0, 1.0, 0.549165792229364, 6.9112, 6.9112, 121.94756008, 1225031.965527387, 1225031.965527387, 271242.8802093366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5910000.0000, 
sim time next is 5910600.0000, 
raw observation next is [24.85, 63.0, 1.0, 2.0, 0.9488677386942672, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.243442117236524, 6.9112, 121.9246310554026, 1328524.742804809, 1158389.053031267, 232178.8891509395], 
processed observation next is [1.0, 0.391304347826087, 0.475925925925926, 0.63, 1.0, 1.0, 0.9391282603503182, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03322421172365244, 0.0, 0.8094527575279341, 0.47447312243028894, 0.4137103760825953, 0.4464978637518067], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0190974], dtype=float32), -0.86182725]. 
=============================================
[2019-03-23 20:21:16,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159295: loss -56.4559
[2019-03-23 20:21:16,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159295: learning rate 0.0010
[2019-03-23 20:21:16,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4184986e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:21:16,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7322
[2019-03-23 20:21:16,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.11666666666667, 85.16666666666667, 1.0, 2.0, 0.4675507086204132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579070.6168296319, 579070.6168296319, 138535.9725546141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5980200.0000, 
sim time next is 5980800.0000, 
raw observation next is [21.23333333333333, 84.33333333333334, 1.0, 2.0, 0.4782900991712275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592215.9045278139, 592215.9045278139, 140184.4553828623], 
processed observation next is [1.0, 0.21739130434782608, 0.34197530864197523, 0.8433333333333334, 1.0, 1.0, 0.37891678472765183, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21150568018850496, 0.21150568018850496, 0.26958549112088903], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.8018082], dtype=float32), -0.29717916]. 
=============================================
[2019-03-23 20:21:17,566] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159806: loss -69.1286
[2019-03-23 20:21:17,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159807: learning rate 0.0010
[2019-03-23 20:21:17,615] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159822: loss -71.7074
[2019-03-23 20:21:17,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159822: learning rate 0.0010
[2019-03-23 20:21:17,655] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159839: loss -64.8655
[2019-03-23 20:21:17,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159839: learning rate 0.0010
[2019-03-23 20:21:17,691] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159851: loss -78.6333
[2019-03-23 20:21:17,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159851: learning rate 0.0010
[2019-03-23 20:21:17,779] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159862: loss -41.2591
[2019-03-23 20:21:17,793] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159862: learning rate 0.0010
[2019-03-23 20:21:17,878] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159879: loss -64.1495
[2019-03-23 20:21:17,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159879: learning rate 0.0010
[2019-03-23 20:21:17,942] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159907: loss -56.3121
[2019-03-23 20:21:17,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159907: learning rate 0.0010
[2019-03-23 20:21:17,994] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159925: loss -55.0499
[2019-03-23 20:21:17,996] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159925: learning rate 0.0010
[2019-03-23 20:21:18,098] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159982: loss -50.5164
[2019-03-23 20:21:18,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159982: learning rate 0.0010
[2019-03-23 20:21:18,112] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159989: loss -53.1185
[2019-03-23 20:21:18,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159989: learning rate 0.0010
[2019-03-23 20:21:18,485] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160174: loss -45.9054
[2019-03-23 20:21:18,488] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160174: learning rate 0.0010
[2019-03-23 20:21:18,620] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160251: loss -50.1134
[2019-03-23 20:21:18,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160252: learning rate 0.0010
[2019-03-23 20:21:18,688] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160282: loss -1.6687
[2019-03-23 20:21:18,691] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160283: learning rate 0.0010
[2019-03-23 20:21:18,736] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160313: loss -26.0261
[2019-03-23 20:21:18,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160313: learning rate 0.0010
[2019-03-23 20:21:18,946] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160433: loss 12.5024
[2019-03-23 20:21:18,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160433: learning rate 0.0010
[2019-03-23 20:21:28,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8049055e-11 1.0000000e+00 1.0900728e-19 1.0913579e-20 1.8736715e-21], sum to 1.0000
[2019-03-23 20:21:28,133] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5384
[2019-03-23 20:21:28,137] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.41666666666667, 55.16666666666667, 1.0, 2.0, 0.5209495744060716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611975.0662026751, 611975.0662026746, 145856.8314922964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198600.0000, 
sim time next is 6199200.0000, 
raw observation next is [29.3, 56.0, 1.0, 2.0, 0.5301682737361304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622167.1396483212, 622167.1396483212, 147312.7741678156], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.56, 1.0, 1.0, 0.4406765163525362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22220254987440044, 0.22220254987440044, 0.28329379647656844], 
reward next is 0.7167, 
noisyNet noise sample is [array([-1.4283165], dtype=float32), 2.109534]. 
=============================================
[2019-03-23 20:21:32,025] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167067: loss 0.1490
[2019-03-23 20:21:32,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167067: learning rate 0.0010
[2019-03-23 20:21:33,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167747: loss 0.0747
[2019-03-23 20:21:33,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167747: learning rate 0.0010
[2019-03-23 20:21:33,438] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167752: loss 0.0376
[2019-03-23 20:21:33,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167756: learning rate 0.0010
[2019-03-23 20:21:33,520] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167798: loss 0.3039
[2019-03-23 20:21:33,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167799: learning rate 0.0010
[2019-03-23 20:21:33,564] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167819: loss 0.0707
[2019-03-23 20:21:33,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167819: learning rate 0.0010
[2019-03-23 20:21:33,710] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167891: loss 0.0126
[2019-03-23 20:21:33,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167892: learning rate 0.0010
[2019-03-23 20:21:33,755] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167911: loss 0.1411
[2019-03-23 20:21:33,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167911: learning rate 0.0010
[2019-03-23 20:21:33,863] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167966: loss 0.0501
[2019-03-23 20:21:33,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167967: learning rate 0.0010
[2019-03-23 20:21:33,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.171015e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:21:33,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-23 20:21:33,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 76.0, 1.0, 2.0, 0.5835119477033154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678702.1267014277, 678702.1267014277, 155915.7044896122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6299400.0000, 
sim time next is 6300000.0000, 
raw observation next is [26.0, 77.0, 1.0, 2.0, 0.5820017053860035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677086.2316740965, 677086.2316740965, 155664.8936273675], 
processed observation next is [0.0, 0.9565217391304348, 0.5185185185185185, 0.77, 1.0, 1.0, 0.5023829826023851, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24181651131217735, 0.24181651131217735, 0.29935556466801444], 
reward next is 0.7006, 
noisyNet noise sample is [array([-0.34979153], dtype=float32), -1.5167953]. 
=============================================
[2019-03-23 20:21:33,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.137184]
 [66.137184]
 [66.137184]
 [66.137184]
 [66.137184]], R is [[66.17645264]
 [66.21485138]
 [66.2521286 ]
 [66.28820801]
 [66.32357025]].
[2019-03-23 20:21:33,903] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167984: loss 0.0196
[2019-03-23 20:21:33,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167985: learning rate 0.0010
[2019-03-23 20:21:33,913] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167986: loss 0.0064
[2019-03-23 20:21:33,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167987: learning rate 0.0010
[2019-03-23 20:21:34,025] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168041: loss 0.0289
[2019-03-23 20:21:34,029] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168043: learning rate 0.0010
[2019-03-23 20:21:34,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168244: loss 0.1422
[2019-03-23 20:21:34,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168244: learning rate 0.0010
[2019-03-23 20:21:34,565] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168305: loss 0.0020
[2019-03-23 20:21:34,570] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168305: learning rate 0.0010
[2019-03-23 20:21:34,715] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168380: loss 0.3395
[2019-03-23 20:21:34,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168381: learning rate 0.0010
[2019-03-23 20:21:34,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168403: loss 0.0787
[2019-03-23 20:21:34,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168403: learning rate 0.0010
[2019-03-23 20:21:35,128] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168578: loss 0.0078
[2019-03-23 20:21:35,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168578: learning rate 0.0010
[2019-03-23 20:21:35,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8936134e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:21:35,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3269
[2019-03-23 20:21:35,807] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 88.0, 1.0, 2.0, 0.5650920080577401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 661517.5791537098, 661517.5791537093, 152992.5083450952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6321600.0000, 
sim time next is 6322200.0000, 
raw observation next is [24.08333333333334, 88.00000000000001, 1.0, 2.0, 0.5648651877457146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661470.9422601978, 661470.9422601978, 152963.8911567332], 
processed observation next is [0.0, 0.17391304347826086, 0.4475308641975311, 0.8800000000000001, 1.0, 1.0, 0.4819823663639459, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23623962223578493, 0.23623962223578493, 0.2941613291475639], 
reward next is 0.7058, 
noisyNet noise sample is [array([-1.4895537], dtype=float32), -0.08239306]. 
=============================================
[2019-03-23 20:21:36,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.055124e-23 1.000000e+00 2.832318e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:21:36,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9904
[2019-03-23 20:21:36,299] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 87.0, 1.0, 2.0, 0.5695292020676505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664742.6879426173, 664742.6879426173, 153652.3557334143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [24.46666666666667, 87.0, 1.0, 2.0, 0.5729653181092249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 667934.2820802875, 667934.282080287, 154195.1838862641], 
processed observation next is [0.0, 0.2608695652173913, 0.46172839506172847, 0.87, 1.0, 1.0, 0.4916253787014582, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23854795788581695, 0.23854795788581679, 0.2965291997812771], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.00510228], dtype=float32), 2.304006]. 
=============================================
[2019-03-23 20:21:38,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.204243e-19 1.000000e+00 8.257539e-36 9.104103e-37 0.000000e+00], sum to 1.0000
[2019-03-23 20:21:38,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6376
[2019-03-23 20:21:38,837] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 80.0, 1.0, 2.0, 0.688501652681309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 784690.4063132785, 784690.406313278, 173977.442048638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6392400.0000, 
sim time next is 6393000.0000, 
raw observation next is [27.1, 80.5, 1.0, 2.0, 0.6891042682750844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785377.563608391, 785377.563608391, 174090.2286971483], 
processed observation next is [0.0, 1.0, 0.5592592592592593, 0.805, 1.0, 1.0, 0.6298860336608147, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28049198700299677, 0.28049198700299677, 0.3347889013406698], 
reward next is 0.6652, 
noisyNet noise sample is [array([0.08157705], dtype=float32), 0.0735715]. 
=============================================
[2019-03-23 20:21:38,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.204193]
 [54.204193]
 [54.204193]
 [54.204193]
 [54.204193]], R is [[54.32736206]
 [54.4495163 ]
 [54.57020187]
 [54.68941498]
 [54.80707169]].
[2019-03-23 20:21:41,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0622220e-11 1.0000000e+00 1.6977745e-18 1.1979371e-19 4.9381624e-21], sum to 1.0000
[2019-03-23 20:21:41,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4521
[2019-03-23 20:21:41,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2144719.697038464 W.
[2019-03-23 20:21:41,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.2, 54.0, 1.0, 2.0, 0.940123074671062, 1.0, 2.0, 0.940123074671062, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2144719.697038464, 2144719.697038464, 405057.3958662577], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6446400.0000, 
sim time next is 6447000.0000, 
raw observation next is [32.15000000000001, 54.0, 1.0, 2.0, 0.6146492715473215, 1.0, 2.0, 0.6146492715473215, 1.0, 1.0, 0.9785416580325998, 6.9112, 6.9112, 121.94756008, 2103266.473332601, 2103266.473332601, 403415.0271392644], 
processed observation next is [1.0, 0.6086956521739131, 0.7462962962962968, 0.54, 1.0, 1.0, 0.5412491327944303, 1.0, 1.0, 0.5412491327944303, 1.0, 0.5, 0.9731770725407498, 0.0, 0.0, 0.8096049824067558, 0.7511665976187861, 0.7511665976187861, 0.77579812911397], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0463891], dtype=float32), 0.30212468]. 
=============================================
[2019-03-23 20:21:41,817] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[22.02055]
 [22.02055]
 [22.02055]
 [22.02055]
 [22.02055]], R is [[21.80034637]
 [21.80338669]
 [21.76602173]
 [21.73547554]
 [21.51812172]].
[2019-03-23 20:21:48,221] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:21:48,222] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:21:48,223] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:48,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:21:48,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:21:48,225] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:48,225] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:21:48,226] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:21:48,228] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:48,225] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:48,229] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:21:48,243] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 20:21:48,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 20:21:48,244] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 20:21:48,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 20:21:48,267] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 20:22:18,514] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.056585036]
[2019-03-23 20:22:18,515] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.27841892666667, 52.90707130000001, 1.0, 2.0, 0.586525275282079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671596.100288858, 671596.100288858, 155932.7264510425]
[2019-03-23 20:22:18,516] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:22:18,519] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9854517e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3007644809655876
[2019-03-23 20:22:18,525] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.056585036]
[2019-03-23 20:22:18,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.56995887333333, 55.10343275, 1.0, 2.0, 0.582310673120028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 669408.9094482466, 669408.9094482461, 155345.3721878233]
[2019-03-23 20:22:18,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:22:18,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9854517e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.01344612528541822
[2019-03-23 20:23:03,126] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.056585036]
[2019-03-23 20:23:03,127] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 79.0, 1.0, 2.0, 0.7527636265427569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857971.2436677963, 857971.2436677963, 186379.3406969265]
[2019-03-23 20:23:03,128] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:23:03,131] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9854517e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.19941973170956995
[2019-03-23 20:23:09,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.056585036]
[2019-03-23 20:23:09,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.63333333333333, 70.0, 1.0, 2.0, 0.5433328819599367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638376.1656749723, 638376.1656749723, 149486.6897144428]
[2019-03-23 20:23:09,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:23:09,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9854517e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3119874218587775
[2019-03-23 20:23:32,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:23:32,420] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:23:32,430] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:23:32,673] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:23:32,691] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:23:33,705] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 175000, evaluation results [175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:23:33,769] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175039: loss 0.0010
[2019-03-23 20:23:33,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175040: learning rate 0.0010
[2019-03-23 20:23:35,066] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175716: loss 0.6065
[2019-03-23 20:23:35,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175716: learning rate 0.0010
[2019-03-23 20:23:35,132] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175750: loss 0.2276
[2019-03-23 20:23:35,134] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175750: learning rate 0.0010
[2019-03-23 20:23:35,196] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175781: loss 0.0092
[2019-03-23 20:23:35,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175782: learning rate 0.0010
[2019-03-23 20:23:35,370] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175875: loss 0.0528
[2019-03-23 20:23:35,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175875: learning rate 0.0010
[2019-03-23 20:23:35,416] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175898: loss 0.0361
[2019-03-23 20:23:35,417] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175898: learning rate 0.0010
[2019-03-23 20:23:35,431] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175903: loss 0.0023
[2019-03-23 20:23:35,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175904: loss 0.0012
[2019-03-23 20:23:35,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175904: learning rate 0.0010
[2019-03-23 20:23:35,436] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175904: learning rate 0.0010
[2019-03-23 20:23:35,456] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175914: loss 0.0143
[2019-03-23 20:23:35,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175914: learning rate 0.0010
[2019-03-23 20:23:35,580] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175984: loss 0.1621
[2019-03-23 20:23:35,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175984: learning rate 0.0010
[2019-03-23 20:23:35,634] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176005: loss 0.0796
[2019-03-23 20:23:35,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176006: learning rate 0.0010
[2019-03-23 20:23:35,985] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176193: loss 0.0696
[2019-03-23 20:23:35,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176193: learning rate 0.0010
[2019-03-23 20:23:36,209] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176313: loss 0.0115
[2019-03-23 20:23:36,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176316: learning rate 0.0010
[2019-03-23 20:23:36,319] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176365: loss 0.0556
[2019-03-23 20:23:36,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176367: learning rate 0.0010
[2019-03-23 20:23:36,472] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176447: loss 0.1976
[2019-03-23 20:23:36,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176447: learning rate 0.0010
[2019-03-23 20:23:36,836] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176634: loss 0.6312
[2019-03-23 20:23:36,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176634: learning rate 0.0010
[2019-03-23 20:23:43,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.157578e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:23:43,186] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6927
[2019-03-23 20:23:43,190] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 54.66666666666667, 1.0, 2.0, 0.3358126082457025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424588.0373353306, 424588.0373353306, 120087.6581902965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6729000.0000, 
sim time next is 6729600.0000, 
raw observation next is [23.76666666666667, 56.33333333333334, 1.0, 2.0, 0.3381966808812994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427442.6685877579, 427442.6685877574, 120396.0520851918], 
processed observation next is [1.0, 0.9130434782608695, 0.43580246913580256, 0.5633333333333335, 1.0, 1.0, 0.2121389058110707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15265809592419927, 0.15265809592419907, 0.2315308693945996], 
reward next is 0.7685, 
noisyNet noise sample is [array([0.21735759], dtype=float32), -0.6774028]. 
=============================================
[2019-03-23 20:23:46,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1093828e-22 1.0000000e+00 2.3277047e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:23:46,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4703
[2019-03-23 20:23:46,143] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 72.0, 1.0, 2.0, 0.4709568442032145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 568848.1030863775, 568848.103086377, 138654.1338251148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813600.0000, 
sim time next is 6814200.0000, 
raw observation next is [24.58333333333334, 72.5, 1.0, 2.0, 0.472693027146266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 570990.2293020121, 570990.2293020117, 138920.7494028698], 
processed observation next is [1.0, 0.8695652173913043, 0.4660493827160496, 0.725, 1.0, 1.0, 0.3722536037455548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20392508189357575, 0.20392508189357558, 0.2671552873132112], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.68112195], dtype=float32), 1.8808073]. 
=============================================
[2019-03-23 20:23:46,260] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3028317e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:23:46,268] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 20:23:46,273] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.31666666666667, 48.83333333333334, 1.0, 2.0, 0.7942375442589892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 979964.474292484, 979964.474292484, 197864.2059837536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786600.0000, 
sim time next is 6787200.0000, 
raw observation next is [27.43333333333334, 48.66666666666667, 1.0, 2.0, 0.9833408625761044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.5334761386547, 6.9112, 121.9238304231106, 1530859.177366131, 1212203.95766226, 240855.9288483658], 
processed observation next is [1.0, 0.5652173913043478, 0.5716049382716052, 0.4866666666666667, 1.0, 1.0, 0.9801676935429815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.062227613865469954, 0.0, 0.8094474421621141, 0.5467354204879039, 0.43292998487937856, 0.4631844785545496], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5800844], dtype=float32), -0.06743917]. 
=============================================
[2019-03-23 20:23:48,985] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 182976: loss 0.2562
[2019-03-23 20:23:48,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 182976: learning rate 0.0010
[2019-03-23 20:23:50,244] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183627: loss 0.1886
[2019-03-23 20:23:50,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183627: learning rate 0.0010
[2019-03-23 20:23:50,490] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183753: loss 0.1074
[2019-03-23 20:23:50,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183754: learning rate 0.0010
[2019-03-23 20:23:50,585] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183805: loss 0.1115
[2019-03-23 20:23:50,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183805: learning rate 0.0010
[2019-03-23 20:23:50,614] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183823: loss 0.0423
[2019-03-23 20:23:50,617] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183823: learning rate 0.0010
[2019-03-23 20:23:50,640] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183834: loss 0.0273
[2019-03-23 20:23:50,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183834: learning rate 0.0010
[2019-03-23 20:23:50,722] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183873: loss 0.0516
[2019-03-23 20:23:50,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183873: learning rate 0.0010
[2019-03-23 20:23:50,774] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183903: loss 0.1339
[2019-03-23 20:23:50,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183904: learning rate 0.0010
[2019-03-23 20:23:50,911] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183977: loss 0.0221
[2019-03-23 20:23:50,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183978: learning rate 0.0010
[2019-03-23 20:23:50,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184004: loss 0.0195
[2019-03-23 20:23:50,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184005: learning rate 0.0010
[2019-03-23 20:23:51,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184065: loss 0.1773
[2019-03-23 20:23:51,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184065: learning rate 0.0010
[2019-03-23 20:23:51,439] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184245: loss 0.1394
[2019-03-23 20:23:51,439] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184245: loss 0.0804
[2019-03-23 20:23:51,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184245: learning rate 0.0010
[2019-03-23 20:23:51,441] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184245: learning rate 0.0010
[2019-03-23 20:23:51,762] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.523594e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:23:51,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3377
[2019-03-23 20:23:51,775] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 59.33333333333334, 1.0, 2.0, 0.4383704275454699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535919.550871799, 535919.550871799, 133971.8442861775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [25.85, 60.0, 1.0, 2.0, 0.436948972285028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534386.5107737497, 534386.5107737492, 133768.4299294778], 
processed observation next is [0.0, 0.8695652173913043, 0.5129629629629631, 0.6, 1.0, 1.0, 0.3297011574821762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19085232527633916, 0.190852325276339, 0.2572469806336112], 
reward next is 0.7428, 
noisyNet noise sample is [array([1.8728788], dtype=float32), 0.80655044]. 
=============================================
[2019-03-23 20:23:51,811] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184439: loss 0.0000
[2019-03-23 20:23:51,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184440: learning rate 0.0010
[2019-03-23 20:23:52,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6794416e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:23:52,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6919
[2019-03-23 20:23:52,083] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 85.0, 1.0, 2.0, 0.4153009567960252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512463.4884140966, 512463.4884140966, 130746.2208117138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928200.0000, 
sim time next is 6928800.0000, 
raw observation next is [21.3, 85.66666666666667, 1.0, 2.0, 0.4142452291711953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511264.0078017961, 511264.0078017961, 130597.3503758817], 
processed observation next is [0.0, 0.17391304347826086, 0.3444444444444445, 0.8566666666666667, 1.0, 1.0, 0.3026728918704706, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18259428850064147, 0.18259428850064147, 0.2511487507228494], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.8923014], dtype=float32), -0.2888079]. 
=============================================
[2019-03-23 20:23:52,108] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184589: loss 0.0038
[2019-03-23 20:23:52,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184590: learning rate 0.0010
[2019-03-23 20:23:52,225] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184653: loss 0.1464
[2019-03-23 20:23:52,229] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184656: learning rate 0.0010
[2019-03-23 20:23:55,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.051761e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:23:55,030] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5929
[2019-03-23 20:23:55,035] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333333, 90.33333333333334, 1.0, 2.0, 0.4848526082192893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 598577.6732820419, 598577.6732820414, 141162.2826024324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7015800.0000, 
sim time next is 7016400.0000, 
raw observation next is [20.6, 91.0, 1.0, 2.0, 0.4825627817021838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595782.2469060741, 595782.2469060741, 140806.6456583215], 
processed observation next is [1.0, 0.21739130434782608, 0.3185185185185186, 0.91, 1.0, 1.0, 0.3840033115502188, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21277937389502646, 0.21277937389502646, 0.2707820108813875], 
reward next is 0.7292, 
noisyNet noise sample is [array([0.6361729], dtype=float32), 1.2877827]. 
=============================================
[2019-03-23 20:23:59,782] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.508567e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:23:59,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8578
[2019-03-23 20:23:59,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1722326.128244303 W.
[2019-03-23 20:23:59,797] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.93333333333333, 68.66666666666666, 1.0, 2.0, 0.7427207412726913, 1.0, 2.0, 0.7427207412726913, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1722326.128244303, 1722326.128244304, 322091.2971610513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7054800.0000, 
sim time next is 7055400.0000, 
raw observation next is [25.66666666666667, 69.83333333333334, 1.0, 2.0, 0.83584396276014, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9762193107988665, 6.911199999999999, 6.9112, 121.9260426156618, 1692540.094066133, 1692540.094066134, 339632.790814381], 
processed observation next is [1.0, 0.6521739130434783, 0.506172839506173, 0.6983333333333335, 1.0, 1.0, 0.8045761461430238, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.970274138498583, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6044786050236189, 0.6044786050236193, 0.653139982335348], 
reward next is 0.3469, 
noisyNet noise sample is [array([1.5343326], dtype=float32), 1.2349519]. 
=============================================
[2019-03-23 20:24:01,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.437409e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:24:01,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3726
[2019-03-23 20:24:01,369] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 82.66666666666667, 1.0, 2.0, 0.4048839931050919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500795.9928313701, 500795.9928313701, 129289.455103953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7100400.0000, 
sim time next is 7101000.0000, 
raw observation next is [21.4, 83.5, 1.0, 2.0, 0.4034444051291486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499184.0462514674, 499184.0462514674, 129089.557869442], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.835, 1.0, 1.0, 0.2898147680108912, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1782800165183812, 0.1782800165183812, 0.24824914974892692], 
reward next is 0.7518, 
noisyNet noise sample is [array([-1.2618849], dtype=float32), 0.37175483]. 
=============================================
[2019-03-23 20:24:01,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[86.74771]
 [86.74771]
 [86.74771]
 [86.74771]
 [86.74771]], R is [[86.63198853]
 [86.51703644]
 [86.40048981]
 [86.28856659]
 [86.17745972]].
[2019-03-23 20:24:04,696] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191036: loss 0.0040
[2019-03-23 20:24:04,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191038: learning rate 0.0010
[2019-03-23 20:24:05,823] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191596: loss 0.0966
[2019-03-23 20:24:05,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191597: learning rate 0.0010
[2019-03-23 20:24:06,071] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191720: loss 0.2063
[2019-03-23 20:24:06,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191720: learning rate 0.0010
[2019-03-23 20:24:06,127] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191745: loss 0.1420
[2019-03-23 20:24:06,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191745: learning rate 0.0010
[2019-03-23 20:24:06,169] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191769: loss 0.0677
[2019-03-23 20:24:06,173] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191770: learning rate 0.0010
[2019-03-23 20:24:06,211] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191787: loss 0.0086
[2019-03-23 20:24:06,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191787: learning rate 0.0010
[2019-03-23 20:24:06,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191892: loss 0.1185
[2019-03-23 20:24:06,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191892: learning rate 0.0010
[2019-03-23 20:24:06,490] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191928: loss 0.0443
[2019-03-23 20:24:06,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191928: learning rate 0.0010
[2019-03-23 20:24:06,581] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191969: loss 0.0322
[2019-03-23 20:24:06,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191969: learning rate 0.0010
[2019-03-23 20:24:06,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192018: loss 0.1567
[2019-03-23 20:24:06,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192019: learning rate 0.0010
[2019-03-23 20:24:06,740] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192045: loss 0.1142
[2019-03-23 20:24:06,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192045: learning rate 0.0010
[2019-03-23 20:24:06,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.858338e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:24:06,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3521
[2019-03-23 20:24:06,799] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 92.66666666666666, 1.0, 2.0, 0.3766445018125332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469153.8831494225, 469153.8831494225, 125429.7907497607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7174200.0000, 
sim time next is 7174800.0000, 
raw observation next is [19.8, 93.0, 1.0, 2.0, 0.3799876474232725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473066.5438075097, 473066.5438075092, 125883.322281343], 
processed observation next is [1.0, 0.043478260869565216, 0.2888888888888889, 0.93, 1.0, 1.0, 0.26189005645627683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16895233707411061, 0.16895233707411042, 0.24208331207950579], 
reward next is 0.7579, 
noisyNet noise sample is [array([-1.577366], dtype=float32), -0.09084884]. 
=============================================
[2019-03-23 20:24:06,910] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192127: loss 0.0046
[2019-03-23 20:24:06,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192127: learning rate 0.0010
[2019-03-23 20:24:07,024] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192187: loss 0.0120
[2019-03-23 20:24:07,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192187: learning rate 0.0010
[2019-03-23 20:24:07,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192527: loss 0.1986
[2019-03-23 20:24:07,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192528: learning rate 0.0010
[2019-03-23 20:24:08,111] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192725: loss 0.1337
[2019-03-23 20:24:08,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192725: learning rate 0.0010
[2019-03-23 20:24:08,151] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192742: loss 0.0876
[2019-03-23 20:24:08,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192742: learning rate 0.0010
[2019-03-23 20:24:11,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7597477e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:24:11,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6797
[2019-03-23 20:24:11,421] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 90.5, 1.0, 2.0, 0.4859869995766307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598134.3113719842, 598134.3113719847, 141293.1505807609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7284600.0000, 
sim time next is 7285200.0000, 
raw observation next is [20.93333333333333, 90.66666666666667, 1.0, 2.0, 0.4309479307498383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529984.7951899488, 529984.7951899488, 132968.2303577335], 
processed observation next is [1.0, 0.30434782608695654, 0.3308641975308641, 0.9066666666666667, 1.0, 1.0, 0.32255706041647414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18928028399641028, 0.18928028399641028, 0.25570813530333364], 
reward next is 0.7443, 
noisyNet noise sample is [array([-0.4587325], dtype=float32), 0.80674505]. 
=============================================
[2019-03-23 20:24:16,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6353109e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:24:16,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8239
[2019-03-23 20:24:16,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.11666666666666, 94.16666666666667, 1.0, 2.0, 0.7149092479694468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883661.3331055801, 883661.3331055801, 181743.9735551173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7386600.0000, 
sim time next is 7387200.0000, 
raw observation next is [20.2, 94.0, 1.0, 2.0, 0.7514131305237557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 927923.5188519647, 927923.5188519647, 189022.2260950732], 
processed observation next is [1.0, 0.5217391304347826, 0.3037037037037037, 0.94, 1.0, 1.0, 0.7040632506235187, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33140125673284454, 0.33140125673284454, 0.36350428095206383], 
reward next is 0.6365, 
noisyNet noise sample is [array([-0.20088805], dtype=float32), -1.390246]. 
=============================================
[2019-03-23 20:24:20,799] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 198990: loss 0.1121
[2019-03-23 20:24:20,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 198990: learning rate 0.0010
[2019-03-23 20:24:22,099] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199635: loss 0.2893
[2019-03-23 20:24:22,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199635: learning rate 0.0010
[2019-03-23 20:24:22,197] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199687: loss 0.0262
[2019-03-23 20:24:22,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199688: learning rate 0.0010
[2019-03-23 20:24:22,359] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199768: loss 0.0620
[2019-03-23 20:24:22,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199769: learning rate 0.0010
[2019-03-23 20:24:22,376] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199775: loss 0.0657
[2019-03-23 20:24:22,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199775: learning rate 0.0010
[2019-03-23 20:24:22,382] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199776: loss 0.0722
[2019-03-23 20:24:22,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199777: learning rate 0.0010
[2019-03-23 20:24:22,636] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199898: loss 0.0993
[2019-03-23 20:24:22,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199898: learning rate 0.0010
[2019-03-23 20:24:22,743] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199951: loss 0.3209
[2019-03-23 20:24:22,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199951: learning rate 0.0010
[2019-03-23 20:24:22,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0441484e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:24:22,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4812
[2019-03-23 20:24:22,845] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199995: loss 0.0846
[2019-03-23 20:24:22,848] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.23333333333333, 92.33333333333334, 1.0, 2.0, 0.4819870918513726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578275.2030839399, 578275.2030839399, 140215.7543794519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7508400.0000, 
sim time next is 7509000.0000, 
raw observation next is [22.16666666666667, 92.66666666666666, 1.0, 2.0, 0.4808502802286518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577167.7908125118, 577167.7908125118, 140049.5018497194], 
processed observation next is [0.0, 0.9130434782608695, 0.3765432098765434, 0.9266666666666665, 1.0, 1.0, 0.3819646193198236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20613135386161135, 0.20613135386161135, 0.26932596509561424], 
reward next is 0.7307, 
noisyNet noise sample is [array([-0.96360654], dtype=float32), -0.42299083]. 
=============================================
[2019-03-23 20:24:22,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199998: learning rate 0.0010
[2019-03-23 20:24:22,854] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 20:24:22,857] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:24:22,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:24:22,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:24:22,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:24:22,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:24:22,861] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:24:22,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:24:22,861] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:24:22,862] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:24:22,863] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:24:22,872] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 20:24:22,900] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 20:24:22,900] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 20:24:22,901] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 20:24:22,967] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 20:24:25,239] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:24:25,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.33333333333334, 50.0, 1.0, 2.0, 0.2258356243138918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 291302.6057686986, 291302.605768699, 84068.55734868783]
[2019-03-23 20:24:25,242] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:24:25,245] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.782052377494124
[2019-03-23 20:24:36,896] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:24:36,898] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.45, 34.5, 1.0, 2.0, 0.2988417333642333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385495.9584389871, 385495.9584389871, 91477.53453040782]
[2019-03-23 20:24:36,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:24:36,902] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6467417572821185
[2019-03-23 20:24:40,441] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:24:40,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.83333333333334, 61.33333333333333, 1.0, 2.0, 0.5281681448863548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 681450.9070853676, 681450.9070853671, 138847.2762676578]
[2019-03-23 20:24:40,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:24:40,445] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.15593716844956274
[2019-03-23 20:24:50,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:24:50,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.06666666666667, 97.66666666666667, 1.0, 2.0, 0.3799609923023197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474070.2226594547, 474070.2226594547, 125899.7766953698]
[2019-03-23 20:24:50,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:24:50,608] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.974931899079522
[2019-03-23 20:25:03,987] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:03,988] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.763033061282267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869682.5942395737, 869682.5942395737, 188416.601355379]
[2019-03-23 20:25:03,990] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:25:03,992] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.16842625657891896
[2019-03-23 20:25:08,883] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:08,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 89.66666666666667, 1.0, 2.0, 0.5354882124552915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633276.560643355, 633276.560643355, 148373.6255908939]
[2019-03-23 20:25:08,886] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:25:08,892] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9940895832361302
[2019-03-23 20:25:17,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:17,685] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.550321205, 70.44069354999999, 1.0, 2.0, 0.8140379880524018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 927851.6976775244, 927851.6976775244, 198868.6506425091]
[2019-03-23 20:25:17,686] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:25:17,691] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.45461364732463805
[2019-03-23 20:25:23,590] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:23,591] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.16206988666667, 58.87686087333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.79933258120735, 6.9112, 121.922632430273, 2333345.426870747, 1878554.885429595, 380948.40325427]
[2019-03-23 20:25:23,591] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:25:23,593] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.16065624481229535
[2019-03-23 20:25:23,595] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2333345.426870747 W.
[2019-03-23 20:25:27,714] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:27,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.41666666666667, 83.16666666666666, 1.0, 2.0, 0.5880906407636312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679470.0734231764, 679470.0734231764, 156489.1202844979]
[2019-03-23 20:25:27,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:25:27,718] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.1348572583069838
[2019-03-23 20:25:55,673] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:55,675] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5464059109344909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639468.382002949, 639468.382002949, 149884.9912790895]
[2019-03-23 20:25:55,676] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:25:55,681] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5875747013154098
[2019-03-23 20:25:56,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2505967]
[2019-03-23 20:25:56,959] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.70898022666667, 80.86692701, 1.0, 2.0, 0.4024885533277427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497887.3944930106, 497887.3944930106, 128951.6051770127]
[2019-03-23 20:25:56,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:25:56,961] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.130471e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2211547573171162
[2019-03-23 20:26:06,659] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:26:06,708] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:26:06,803] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:26:06,921] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:26:07,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:26:08,015] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 200000, evaluation results [200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:26:08,041] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.925415]
 [74.925415]
 [74.925415]
 [74.925415]
 [74.925415]], R is [[74.90683746]
 [74.88812256]
 [74.86921692]
 [74.85011292]
 [74.83080292]].
[2019-03-23 20:26:08,068] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200033: loss 0.0065
[2019-03-23 20:26:08,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200033: learning rate 0.0010
[2019-03-23 20:26:08,084] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200040: loss 0.0228
[2019-03-23 20:26:08,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200041: learning rate 0.0010
[2019-03-23 20:26:08,145] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200062: loss 0.0557
[2019-03-23 20:26:08,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200062: learning rate 0.0010
[2019-03-23 20:26:08,453] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200220: loss 0.1615
[2019-03-23 20:26:08,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200220: learning rate 0.0010
[2019-03-23 20:26:09,191] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200607: loss 0.0124
[2019-03-23 20:26:09,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200607: learning rate 0.0010
[2019-03-23 20:26:09,303] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200666: loss 0.1174
[2019-03-23 20:26:09,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200666: learning rate 0.0010
[2019-03-23 20:26:09,409] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200718: loss 0.0082
[2019-03-23 20:26:09,411] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200718: learning rate 0.0010
[2019-03-23 20:26:09,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2602614e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:09,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 20:26:09,778] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 95.83333333333333, 1.0, 2.0, 0.4390908062737902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534143.9402890576, 534143.9402890576, 134000.7297211656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7542600.0000, 
sim time next is 7543200.0000, 
raw observation next is [21.0, 95.66666666666666, 1.0, 2.0, 0.4392070269614659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534451.9082490135, 534451.9082490135, 134022.8302729552], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 0.9566666666666666, 1.0, 1.0, 0.33238931781126896, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1908756815175048, 0.1908756815175048, 0.2577362120633754], 
reward next is 0.7423, 
noisyNet noise sample is [array([0.12439699], dtype=float32), 1.390667]. 
=============================================
[2019-03-23 20:26:10,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.659361e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:10,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4994
[2019-03-23 20:26:10,105] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 96.0, 1.0, 2.0, 0.4375735928087751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532793.1975728913, 532793.1975728913, 133792.3974413281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7539600.0000, 
sim time next is 7540200.0000, 
raw observation next is [20.95, 96.0, 1.0, 2.0, 0.4382123090340981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533425.6217944389, 533425.6217944389, 133881.9930066861], 
processed observation next is [0.0, 0.2608695652173913, 0.33148148148148143, 0.96, 1.0, 1.0, 0.3312051298024978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19050915064087104, 0.19050915064087104, 0.25746537116670404], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.3782147], dtype=float32), 1.4217012]. 
=============================================
[2019-03-23 20:26:12,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.942958e-22 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:12,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8828
[2019-03-23 20:26:12,874] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 91.0, 1.0, 2.0, 0.4164466086863971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513448.9384911675, 513448.9384911675, 130900.2864637316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7631400.0000, 
sim time next is 7632000.0000, 
raw observation next is [20.8, 91.0, 1.0, 2.0, 0.4497881518818608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554000.2346855943, 554000.2346855948, 135774.926110511], 
processed observation next is [1.0, 0.34782608695652173, 0.32592592592592595, 0.91, 1.0, 1.0, 0.34498589509745337, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19785722667342653, 0.1978572266734267, 0.2611056271355981], 
reward next is 0.7389, 
noisyNet noise sample is [array([-0.01088793], dtype=float32), -0.6979236]. 
=============================================
[2019-03-23 20:26:12,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.47573]
 [68.47573]
 [68.47573]
 [68.47573]
 [68.47573]], R is [[68.52987671]
 [68.59284973]
 [68.65435791]
 [68.71105957]
 [68.76844025]].
[2019-03-23 20:26:13,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2002819e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:13,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4185
[2019-03-23 20:26:13,399] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 86.66666666666667, 1.0, 2.0, 0.4588384415016596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 556406.5794588375, 556406.579458837, 136888.2492776876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7604400.0000, 
sim time next is 7605000.0000, 
raw observation next is [22.2, 86.5, 1.0, 2.0, 0.4539025915212001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551506.3924314542, 551506.3924314542, 136180.6375675554], 
processed observation next is [1.0, 0.0, 0.37777777777777777, 0.865, 1.0, 1.0, 0.3498840375252383, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19696656872551935, 0.19696656872551935, 0.261885841476068], 
reward next is 0.7381, 
noisyNet noise sample is [array([1.4558492], dtype=float32), -0.23602709]. 
=============================================
[2019-03-23 20:26:13,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.5834]
 [68.5834]
 [68.5834]
 [68.5834]
 [68.5834]], R is [[68.63567352]
 [68.6860733 ]
 [68.73426056]
 [68.78022766]
 [68.82395935]].
[2019-03-23 20:26:14,383] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8693287e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:14,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1635
[2019-03-23 20:26:14,396] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.01666666666667, 90.33333333333333, 1.0, 2.0, 0.426443051409598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531412.4414922363, 531412.4414922363, 132470.5528424567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7618200.0000, 
sim time next is 7618800.0000, 
raw observation next is [19.93333333333334, 90.66666666666667, 1.0, 2.0, 0.3798674462156272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473637.0440095928, 473637.0440095928, 125880.9076258686], 
processed observation next is [1.0, 0.17391304347826086, 0.29382716049382746, 0.9066666666666667, 1.0, 1.0, 0.26174695978050855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16915608714628314, 0.16915608714628314, 0.24207866851128576], 
reward next is 0.7579, 
noisyNet noise sample is [array([1.6002561], dtype=float32), -1.0522652]. 
=============================================
[2019-03-23 20:26:18,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5632822e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:18,775] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8262
[2019-03-23 20:26:18,784] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 82.66666666666667, 1.0, 2.0, 0.3307655717257229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418815.8914944866, 418815.8914944861, 119440.6802811138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [19.66666666666667, 83.33333333333334, 1.0, 2.0, 0.3358405767585297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424924.0551804684, 424924.0551804684, 120094.4527175516], 
processed observation next is [1.0, 0.9565217391304348, 0.28395061728395077, 0.8333333333333335, 1.0, 1.0, 0.20933401995063058, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15175859113588158, 0.15175859113588158, 0.23095087061067615], 
reward next is 0.7690, 
noisyNet noise sample is [array([-0.19031413], dtype=float32), -0.34201992]. 
=============================================
[2019-03-23 20:26:21,615] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207068: loss 0.0612
[2019-03-23 20:26:21,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207069: learning rate 0.0010
[2019-03-23 20:26:22,764] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207670: loss 0.0271
[2019-03-23 20:26:22,768] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207670: learning rate 0.0010
[2019-03-23 20:26:22,871] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207729: loss 0.0019
[2019-03-23 20:26:22,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207730: learning rate 0.0010
[2019-03-23 20:26:22,905] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207746: loss 0.0320
[2019-03-23 20:26:22,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207747: learning rate 0.0010
[2019-03-23 20:26:22,916] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207751: loss 0.0242
[2019-03-23 20:26:22,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207751: learning rate 0.0010
[2019-03-23 20:26:23,107] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207849: loss 0.0326
[2019-03-23 20:26:23,108] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207849: learning rate 0.0010
[2019-03-23 20:26:23,194] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207896: loss 0.0828
[2019-03-23 20:26:23,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207896: learning rate 0.0010
[2019-03-23 20:26:23,233] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207914: loss 0.1920
[2019-03-23 20:26:23,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207914: learning rate 0.0010
[2019-03-23 20:26:23,310] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207955: loss 0.0810
[2019-03-23 20:26:23,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207956: learning rate 0.0010
[2019-03-23 20:26:23,346] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207976: loss 0.0488
[2019-03-23 20:26:23,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207976: learning rate 0.0010
[2019-03-23 20:26:23,525] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208066: loss 0.0208
[2019-03-23 20:26:23,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208066: learning rate 0.0010
[2019-03-23 20:26:23,579] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208093: loss 0.0110
[2019-03-23 20:26:23,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208094: learning rate 0.0010
[2019-03-23 20:26:23,761] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208195: loss 0.1491
[2019-03-23 20:26:23,762] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208195: learning rate 0.0010
[2019-03-23 20:26:24,392] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208514: loss 0.6129
[2019-03-23 20:26:24,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208515: learning rate 0.0010
[2019-03-23 20:26:24,523] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208583: loss 0.8857
[2019-03-23 20:26:24,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208583: learning rate 0.0010
[2019-03-23 20:26:24,686] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208667: loss 1.1082
[2019-03-23 20:26:24,691] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208668: learning rate 0.0010
[2019-03-23 20:26:27,031] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0540887e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:27,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6060
[2019-03-23 20:26:27,047] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.71666666666667, 76.66666666666667, 1.0, 2.0, 0.4167307781239784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 512945.9155069785, 512945.9155069781, 130919.6584637046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7866600.0000, 
sim time next is 7867200.0000, 
raw observation next is [22.63333333333334, 77.33333333333334, 1.0, 2.0, 0.4187023381481245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515286.7629207319, 515286.7629207314, 131201.046386016], 
processed observation next is [1.0, 0.043478260869565216, 0.39382716049382743, 0.7733333333333334, 1.0, 1.0, 0.3079789739858625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18403098675740426, 0.18403098675740406, 0.25230970458849233], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.13285136], dtype=float32), 0.14184359]. 
=============================================
[2019-03-23 20:26:29,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4754371e-13 1.0000000e+00 3.5885058e-24 4.3558619e-24 4.8205016e-26], sum to 1.0000
[2019-03-23 20:26:29,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4947
[2019-03-23 20:26:29,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1324117.755779856 W.
[2019-03-23 20:26:29,822] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 50.5, 1.0, 2.0, 0.9672067849379545, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.237125019167907, 6.9112, 121.9246555473905, 1324117.755779856, 1157216.913855296, 235653.8980975646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7907400.0000, 
sim time next is 7908000.0000, 
raw observation next is [28.86666666666667, 50.0, 1.0, 2.0, 0.5253795416263951, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8445112381082733, 6.911199999999997, 6.9112, 121.9258463493497, 1249998.97489884, 1249998.974898841, 264668.0983575127], 
processed observation next is [1.0, 0.5217391304347826, 0.6246913580246916, 0.5, 1.0, 1.0, 0.4349756447933275, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8056390476353417, -2.6645352591003756e-16, 0.0, 0.8094608258159262, 0.4464282053210143, 0.4464282053210146, 0.508977112225986], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.89793223], dtype=float32), 1.1986644]. 
=============================================
[2019-03-23 20:26:29,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[32.810223]
 [32.810223]
 [32.810223]
 [32.810223]
 [32.810223]], R is [[32.48212051]
 [32.15729904]
 [31.83572578]
 [31.51736832]
 [31.65691757]].
[2019-03-23 20:26:30,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:30,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:30,435] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 20:26:31,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,538] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 20:26:31,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 20:26:31,621] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,621] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 20:26:31,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 20:26:31,705] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,710] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 20:26:31,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,751] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 20:26:31,780] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 20:26:31,801] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,801] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,803] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 20:26:31,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,837] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 20:26:31,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 20:26:31,928] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,928] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,930] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 20:26:31,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:31,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:31,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 20:26:32,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:32,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:32,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 20:26:32,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:32,176] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:32,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 20:26:32,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:26:32,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:32,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 20:26:38,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.372382e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:38,148] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6989
[2019-03-23 20:26:38,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1719025.904039602 W.
[2019-03-23 20:26:38,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.3, 8.0, 1.0, 2.0, 0.6863581298119843, 1.0, 2.0, 0.6863581298119843, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1719025.904039602, 1719025.904039602, 304797.6680582173], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 145200.0000, 
sim time next is 145800.0000, 
raw observation next is [37.3, 7.5, 1.0, 2.0, 0.6835906719321592, 1.0, 2.0, 0.6835906719321592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1715149.386336982, 1715149.386336982, 303791.6447850414], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.075, 1.0, 1.0, 0.6233222284906657, 1.0, 1.0, 0.6233222284906657, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6125533522632078, 0.6125533522632078, 0.584214701509695], 
reward next is 0.4158, 
noisyNet noise sample is [array([1.1842831], dtype=float32), -0.4929967]. 
=============================================
[2019-03-23 20:26:39,171] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.231587e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:39,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7911
[2019-03-23 20:26:39,184] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 74.33333333333334, 1.0, 2.0, 0.4179660163344289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520461.4568880743, 520461.4568880743, 131233.9405592615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111000.0000, 
sim time next is 111600.0000, 
raw observation next is [22.3, 74.0, 1.0, 2.0, 0.4136813112113084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514799.7847577648, 514799.7847577648, 130611.1060573111], 
processed observation next is [1.0, 0.30434782608695654, 0.38148148148148153, 0.74, 1.0, 1.0, 0.3020015609658434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.183857065984916, 0.183857065984916, 0.2511752039563675], 
reward next is 0.7488, 
noisyNet noise sample is [array([-1.4789494], dtype=float32), 1.3475653]. 
=============================================
[2019-03-23 20:26:39,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.566552e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:39,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6700
[2019-03-23 20:26:39,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 74.33333333333334, 1.0, 2.0, 0.4179660163344289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520461.4568880743, 520461.4568880743, 131233.9405592615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111000.0000, 
sim time next is 111600.0000, 
raw observation next is [22.3, 74.0, 1.0, 2.0, 0.4136813112113084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514799.7847577648, 514799.7847577648, 130611.1060573111], 
processed observation next is [1.0, 0.30434782608695654, 0.38148148148148153, 0.74, 1.0, 1.0, 0.3020015609658434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.183857065984916, 0.183857065984916, 0.2511752039563675], 
reward next is 0.7488, 
noisyNet noise sample is [array([-0.70097286], dtype=float32), -0.3748743]. 
=============================================
[2019-03-23 20:26:42,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5378954e-23 1.0000000e+00 5.4494485e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:42,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7692
[2019-03-23 20:26:42,220] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.9, 14.66666666666667, 1.0, 2.0, 0.3719787301762465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478748.2410212555, 478748.2410212555, 124924.5376566399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [33.1, 13.83333333333333, 1.0, 2.0, 0.3733559869705815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979039, 125108.8648741274], 
processed observation next is [0.0, 0.5652173913043478, 0.7814814814814816, 0.1383333333333333, 1.0, 1.0, 0.25399522258402557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17178849667782298, 0.1717884966778228, 0.24059397091178344], 
reward next is 0.7594, 
noisyNet noise sample is [array([0.5798242], dtype=float32), 0.44825324]. 
=============================================
[2019-03-23 20:26:43,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8475253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:43,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9765
[2019-03-23 20:26:43,484] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.43333333333333, 49.0, 1.0, 2.0, 0.2521853358785723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 325297.9837465684, 325297.9837465684, 91360.5690397747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 189600.0000, 
sim time next is 190200.0000, 
raw observation next is [20.06666666666667, 51.5, 1.0, 2.0, 0.2485855413952107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 320653.5793688714, 320653.5793688714, 91072.13118698412], 
processed observation next is [0.0, 0.17391304347826086, 0.29876543209876555, 0.515, 1.0, 1.0, 0.1054589778514413, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11451913548888265, 0.11451913548888265, 0.1751387138211233], 
reward next is 0.8249, 
noisyNet noise sample is [array([-0.922845], dtype=float32), -1.295014]. 
=============================================
[2019-03-23 20:26:45,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.819559e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:26:45,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9784
[2019-03-23 20:26:45,748] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 25.0, 1.0, 2.0, 0.35680598770907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453685.1419650791, 453685.1419650791, 122874.8815316364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 215400.0000, 
sim time next is 216000.0000, 
raw observation next is [30.9, 24.0, 1.0, 2.0, 0.358256839531956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456020.6962624202, 456020.6962624202, 123071.810569159], 
processed observation next is [0.0, 0.5217391304347826, 0.7, 0.24, 1.0, 1.0, 0.23602004706185237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1628645343794358, 0.1628645343794358, 0.23667655878684424], 
reward next is 0.7633, 
noisyNet noise sample is [array([0.99487704], dtype=float32), 0.53955674]. 
=============================================
[2019-03-23 20:26:45,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[87.660965]
 [87.660965]
 [87.660965]
 [87.660965]
 [87.660965]], R is [[87.54766083]
 [87.4358902 ]
 [87.32561493]
 [87.21681976]
 [87.10945129]].
[2019-03-23 20:26:50,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6421893e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:50,636] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9608
[2019-03-23 20:26:50,648] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.05, 30.5, 1.0, 2.0, 0.3339844640617451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427462.48097898, 427462.48097898, 119879.4076667391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 318600.0000, 
sim time next is 319200.0000, 
raw observation next is [28.06666666666667, 30.33333333333334, 1.0, 2.0, 0.3340941402873989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427698.6664708984, 427698.666470898, 119893.5936040193], 
processed observation next is [0.0, 0.6956521739130435, 0.5950617283950619, 0.3033333333333334, 1.0, 1.0, 0.20725492891357014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15274952373960657, 0.15274952373960643, 0.23056460308465251], 
reward next is 0.7694, 
noisyNet noise sample is [array([-0.6561592], dtype=float32), -0.094351456]. 
=============================================
[2019-03-23 20:26:54,429] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3709012e-20 1.0000000e+00 4.3113192e-35 8.1840601e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:54,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2087
[2019-03-23 20:26:54,441] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 28.0, 1.0, 2.0, 0.8754478730596226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.026412249369047, 6.9112, 121.9254880384818, 1177117.852102967, 1118119.151227171, 216224.9829519614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 387000.0000, 
sim time next is 387600.0000, 
raw observation next is [28.96666666666667, 27.66666666666667, 1.0, 2.0, 0.8877907078710092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.110765867910889, 6.9112, 121.9250643399934, 1235965.991276588, 1133771.24987916, 219030.5640567846], 
processed observation next is [1.0, 0.4782608695652174, 0.6283950617283951, 0.2766666666666667, 1.0, 1.0, 0.8664175093702491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.01995658679108887, 0.0, 0.8094556340870327, 0.4414164254559243, 0.4049183035282714, 0.42121262318612424], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67455244], dtype=float32), -1.4703629]. 
=============================================
[2019-03-23 20:26:55,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2965809e-17 1.0000000e+00 1.2670883e-29 4.1852870e-31 1.4424326e-34], sum to 1.0000
[2019-03-23 20:26:55,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-23 20:26:55,106] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 25.5, 1.0, 2.0, 0.3407292388548003, 1.0, 1.0, 0.3407292388548003, 1.0, 2.0, 0.5644217368110308, 6.9112, 6.9112, 121.94756008, 1265334.552410999, 1265334.552410999, 270063.5536421695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 401400.0000, 
sim time next is 402000.0000, 
raw observation next is [30.76666666666667, 25.66666666666666, 1.0, 2.0, 0.9509237495808457, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.452990264464621, 6.9112, 121.9237837315077, 1474710.886576327, 1197270.98664016, 233621.7107065205], 
processed observation next is [1.0, 0.6521739130434783, 0.6950617283950619, 0.2566666666666666, 1.0, 1.0, 0.9415758923581496, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05417902644646207, 0.0, 0.8094471321784267, 0.5266824594915454, 0.42759678094291426, 0.4492725205894625], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5456554], dtype=float32), -0.325146]. 
=============================================
[2019-03-23 20:26:55,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[43.139206]
 [43.139206]
 [43.139206]
 [43.139206]
 [43.139206]], R is [[42.70781326]
 [42.76138306]
 [42.33377075]
 [41.91043472]
 [41.49132919]].
[2019-03-23 20:26:56,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1310109e-20 1.0000000e+00 3.2099192e-35 4.3234737e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 20:26:56,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5707
[2019-03-23 20:26:56,392] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 30.33333333333333, 1.0, 2.0, 0.3444474079134085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436908.1712566337, 436908.1712566337, 121228.8911951803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412800.0000, 
sim time next is 413400.0000, 
raw observation next is [29.15, 30.66666666666667, 1.0, 2.0, 0.3421914209569374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434223.5511164907, 434223.5511164907, 120934.2232602116], 
processed observation next is [1.0, 0.782608695652174, 0.6351851851851852, 0.3066666666666667, 1.0, 1.0, 0.2168945487582588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15507983968446096, 0.15507983968446096, 0.2325658139619454], 
reward next is 0.7674, 
noisyNet noise sample is [array([-0.02658332], dtype=float32), -0.8893899]. 
=============================================
[2019-03-23 20:26:59,736] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 20:26:59,737] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:26:59,737] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:59,739] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:26:59,739] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:59,739] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:26:59,740] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:26:59,741] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:59,742] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:59,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:26:59,745] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:26:59,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 20:26:59,781] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 20:26:59,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 20:26:59,783] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 20:26:59,835] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 20:28:16,589] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.273774]
[2019-03-23 20:28:16,591] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.06666666666667, 77.0, 1.0, 2.0, 0.8228468718049411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 937898.3286266506, 937898.3286266502, 200715.0266189278]
[2019-03-23 20:28:16,592] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:28:16,596] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9848595e-13 1.0000000e+00 2.6856694e-23 2.5593217e-24 1.0066238e-25], sampled 0.9094464723830628
[2019-03-23 20:28:20,139] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.273774]
[2019-03-23 20:28:20,150] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666666, 74.83333333333333, 1.0, 2.0, 0.6016718705876678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703289.8529536191, 703289.8529536191, 159192.7018124138]
[2019-03-23 20:28:20,152] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:28:20,155] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9848595e-13 1.0000000e+00 2.6856694e-23 2.5593217e-24 1.0066238e-25], sampled 0.8297160520169589
[2019-03-23 20:28:23,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.273774]
[2019-03-23 20:28:23,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.8, 79.66666666666667, 1.0, 2.0, 0.6657505312798977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758747.9520570256, 758747.9520570256, 169763.8054094424]
[2019-03-23 20:28:23,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:28:23,904] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9848595e-13 1.0000000e+00 2.6856694e-23 2.5593217e-24 1.0066238e-25], sampled 0.008803064591280663
[2019-03-23 20:28:33,500] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.273774]
[2019-03-23 20:28:33,501] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.86165068, 62.37370834, 1.0, 2.0, 0.6508663670239871, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156424, 1456723.495340883, 1456723.495340883, 308523.5919009724]
[2019-03-23 20:28:33,501] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:28:33,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9848595e-13 1.0000000e+00 2.6856694e-23 2.5593217e-24 1.0066238e-25], sampled 0.67136104702769
[2019-03-23 20:28:33,505] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1456723.495340883 W.
[2019-03-23 20:28:42,935] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:28:43,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:28:43,195] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:28:43,301] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:28:43,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:28:44,468] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 225000, evaluation results [225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:28:44,610] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9562832e-12 1.0000000e+00 1.9472179e-21 1.1099698e-21 7.8235888e-24], sum to 1.0000
[2019-03-23 20:28:44,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9098
[2019-03-23 20:28:44,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1333353.046498948 W.
[2019-03-23 20:28:44,623] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.5, 24.0, 1.0, 2.0, 0.3642502235148081, 1.0, 2.0, 0.3642502235148081, 1.0, 1.0, 0.5948399523330299, 6.9112, 6.9112, 121.94756008, 1333353.046498948, 1333353.046498948, 280618.1621162129], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 489600.0000, 
sim time next is 490200.0000, 
raw observation next is [32.53333333333334, 23.66666666666667, 1.0, 2.0, 0.4978460968060652, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8232568634500984, 6.911199999999999, 6.9112, 121.9260426156618, 1230633.315971483, 1230633.315971484, 252405.0619309675], 
processed observation next is [1.0, 0.6956521739130435, 0.7604938271604941, 0.23666666666666672, 1.0, 1.0, 0.4021977342929347, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7790710793126229, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43951189856124395, 0.4395118985612443, 0.48539434986724517], 
reward next is 0.5146, 
noisyNet noise sample is [array([-0.15228744], dtype=float32), 1.3533905]. 
=============================================
[2019-03-23 20:28:45,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.27149535e-20 1.00000000e+00 5.72039790e-36 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 20:28:45,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8974
[2019-03-23 20:28:45,800] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 47.16666666666666, 1.0, 2.0, 0.3335143476090035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421654.4595051919, 421654.4595051919, 119789.2496177124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [25.2, 48.0, 1.0, 2.0, 0.331816353703491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419873.7658518224, 419873.7658518224, 119573.4945579188], 
processed observation next is [1.0, 0.9565217391304348, 0.4888888888888889, 0.48, 1.0, 1.0, 0.20454327821844168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14995491637565087, 0.14995491637565087, 0.2299490279959977], 
reward next is 0.7701, 
noisyNet noise sample is [array([-0.15553991], dtype=float32), -0.8355609]. 
=============================================
[2019-03-23 20:28:47,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5423752e-22 1.0000000e+00 5.5545554e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:28:47,977] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7788
[2019-03-23 20:28:47,981] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 40.83333333333333, 1.0, 2.0, 0.9181756974307914, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.088232940157016, 6.9112, 121.925256845658, 1220246.023079095, 1129589.918944193, 225249.8674728761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553800.0000, 
sim time next is 554400.0000, 
raw observation next is [28.8, 42.0, 1.0, 2.0, 0.9401972277608552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.255508814874666, 6.9112, 121.9244693502378, 1336943.040821801, 1160628.428727749, 230531.7871538111], 
processed observation next is [1.0, 0.43478260869565216, 0.6222222222222222, 0.42, 1.0, 1.0, 0.9288062235248277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.034430881487466626, 0.0, 0.8094516839738013, 0.47747965743635745, 0.41451015311705325, 0.4433303599111752], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3847174], dtype=float32), -0.16429883]. 
=============================================
[2019-03-23 20:28:59,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1445173e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:28:59,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8668
[2019-03-23 20:28:59,354] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 44.66666666666666, 1.0, 2.0, 0.298045680332183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380038.7653004113, 380038.7653004113, 115333.4340579451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 780000.0000, 
sim time next is 780600.0000, 
raw observation next is [24.95, 45.33333333333334, 1.0, 2.0, 0.2988439798645069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 381081.9299182885, 381081.9299182885, 115431.9370505229], 
processed observation next is [0.0, 0.0, 0.47962962962962963, 0.4533333333333334, 1.0, 1.0, 0.16529045221965105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1361006892565316, 0.1361006892565316, 0.22198449432792866], 
reward next is 0.7780, 
noisyNet noise sample is [array([-0.9971298], dtype=float32), -0.10039336]. 
=============================================
[2019-03-23 20:28:59,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.155087e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:28:59,392] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9536
[2019-03-23 20:28:59,397] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 40.5, 1.0, 2.0, 0.3096715006519642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394251.8835190028, 394251.8835190028, 116775.2368598392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [26.03333333333333, 41.0, 1.0, 2.0, 0.3077377748939292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391954.3853854141, 391954.3853854141, 116534.1171507278], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.41, 1.0, 1.0, 0.1758783034451538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13998370906621932, 0.13998370906621932, 0.2241040714437073], 
reward next is 0.7759, 
noisyNet noise sample is [array([-1.4064281], dtype=float32), 0.132074]. 
=============================================
[2019-03-23 20:29:01,079] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0099778e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:01,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2944
[2019-03-23 20:29:01,091] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 54.0, 1.0, 2.0, 0.375405871865336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468079.2147791556, 468079.2147791556, 125269.6319547523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810000.0000, 
sim time next is 810600.0000, 
raw observation next is [25.8, 53.16666666666666, 1.0, 2.0, 0.3799260576840032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 472983.279061183, 472983.2790611825, 125874.8014675363], 
processed observation next is [0.0, 0.391304347826087, 0.5111111111111112, 0.5316666666666666, 1.0, 1.0, 0.26181673533809907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1689225996647082, 0.16892259966470805, 0.24206692589910825], 
reward next is 0.7579, 
noisyNet noise sample is [array([-0.31184426], dtype=float32), -0.5209937]. 
=============================================
[2019-03-23 20:29:06,611] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2793679e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:06,614] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8959
[2019-03-23 20:29:06,617] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6879587e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:06,619] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 43.33333333333334, 1.0, 2.0, 0.4018693865085279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497276.6360656028, 497276.6360656028, 128867.8858197386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 922800.0000, 
sim time next is 923400.0000, 
raw observation next is [28.35, 43.0, 1.0, 2.0, 0.3986226479395992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493803.474535409, 493803.474535409, 128422.8755190818], 
processed observation next is [0.0, 0.6956521739130435, 0.6055555555555556, 0.43, 1.0, 1.0, 0.2840745808804752, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17635838376264606, 0.17635838376264606, 0.24696706830592655], 
reward next is 0.7530, 
noisyNet noise sample is [array([-1.207211], dtype=float32), -2.037194]. 
=============================================
[2019-03-23 20:29:06,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2644
[2019-03-23 20:29:06,629] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 48.0, 1.0, 2.0, 0.4409354349407854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537783.9966420659, 537783.9966420655, 134313.9229422498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 914400.0000, 
sim time next is 915000.0000, 
raw observation next is [28.48333333333333, 47.66666666666666, 1.0, 2.0, 0.4423684203553585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 539869.2878423737, 539869.2878423732, 134535.2669954926], 
processed observation next is [0.0, 0.6086956521739131, 0.6104938271604937, 0.47666666666666657, 1.0, 1.0, 0.33615288137542676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1928104599437049, 0.19281045994370474, 0.25872166729902424], 
reward next is 0.7413, 
noisyNet noise sample is [array([1.0202087], dtype=float32), -0.59830356]. 
=============================================
[2019-03-23 20:29:06,655] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[81.83546]
 [81.83546]
 [81.83546]
 [81.83546]
 [81.83546]], R is [[81.75839233]
 [81.68251801]
 [81.60795593]
 [81.53471375]
 [81.46277618]].
[2019-03-23 20:29:09,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.30389e-26 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:29:09,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-23 20:29:09,099] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 60.33333333333334, 1.0, 2.0, 0.2745177893365329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 353894.1764660525, 353894.176466052, 112473.4190715814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 970800.0000, 
sim time next is 971400.0000, 
raw observation next is [20.98333333333333, 60.16666666666666, 1.0, 2.0, 0.2841926275513607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366104.5798217494, 366104.5798217494, 113635.5158058753], 
processed observation next is [1.0, 0.21739130434782608, 0.33271604938271593, 0.6016666666666666, 1.0, 1.0, 0.14784836613257227, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13075163565062478, 0.13075163565062478, 0.21852983808822174], 
reward next is 0.7815, 
noisyNet noise sample is [array([-0.9634717], dtype=float32), -1.5552338]. 
=============================================
[2019-03-23 20:29:13,643] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2623713e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:13,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1018
[2019-03-23 20:29:13,656] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 69.33333333333333, 1.0, 2.0, 0.3227383611528948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411730.6132241195, 411730.6132241195, 118430.8867804457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1050000.0000, 
sim time next is 1050600.0000, 
raw observation next is [20.65, 69.66666666666667, 1.0, 2.0, 0.3188921862337993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 406840.0236188314, 406840.0236188309, 117941.4175002654], 
processed observation next is [1.0, 0.13043478260869565, 0.3203703703703703, 0.6966666666666668, 1.0, 1.0, 0.18915736456404678, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14530000843529695, 0.14530000843529675, 0.22681041826974113], 
reward next is 0.7732, 
noisyNet noise sample is [array([0.340109], dtype=float32), -0.46671835]. 
=============================================
[2019-03-23 20:29:15,226] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6109862e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:15,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0116
[2019-03-23 20:29:15,235] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 41.33333333333334, 1.0, 2.0, 0.817324755401359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032011.158082032, 1032011.158082032, 203273.5978595786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1089600.0000, 
sim time next is 1090200.0000, 
raw observation next is [26.73333333333333, 41.66666666666666, 1.0, 2.0, 0.8325582518276593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050721.776336977, 1050721.776336977, 206572.7539178446], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.4166666666666666, 1.0, 1.0, 0.8006645855091182, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3752577772632061, 0.3752577772632061, 0.39725529599585496], 
reward next is 0.6027, 
noisyNet noise sample is [array([-2.7192156], dtype=float32), 2.432632]. 
=============================================
[2019-03-23 20:29:15,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.286064e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:29:15,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-23 20:29:15,499] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 40.5, 1.0, 2.0, 0.73622747813433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931436.8140817488, 931436.8140817488, 186390.1759453904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1086600.0000, 
sim time next is 1087200.0000, 
raw observation next is [26.9, 40.0, 1.0, 2.0, 0.8109689070517145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1025657.683878235, 1025657.683878235, 201927.8328582041], 
processed observation next is [1.0, 0.6086956521739131, 0.5518518518518518, 0.4, 1.0, 1.0, 0.7749629845853745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36630631567079824, 0.36630631567079824, 0.3883227554965464], 
reward next is 0.6117, 
noisyNet noise sample is [array([-0.26686293], dtype=float32), -0.27517954]. 
=============================================
[2019-03-23 20:29:19,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.389032e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:29:19,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-23 20:29:19,995] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 66.5, 1.0, 2.0, 0.5397508969684752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691292.0731469521, 691292.0731469516, 150331.4407642356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1157400.0000, 
sim time next is 1158000.0000, 
raw observation next is [20.66666666666667, 66.33333333333334, 1.0, 2.0, 0.5665471582155811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725330.0631513244, 725330.0631513244, 154853.2152854746], 
processed observation next is [1.0, 0.391304347826087, 0.3209876543209878, 0.6633333333333334, 1.0, 1.0, 0.48398471216140604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.259046451125473, 0.259046451125473, 0.29779464477975887], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.17146389], dtype=float32), -0.62205887]. 
=============================================
[2019-03-23 20:29:20,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.98513]
 [78.98513]
 [78.98513]
 [78.98513]
 [78.98513]], R is [[78.89749146]
 [78.81941986]
 [78.74210358]
 [78.65646362]
 [78.59573364]].
[2019-03-23 20:29:22,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5932368e-21 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:22,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-23 20:29:22,237] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 94.0, 1.0, 2.0, 0.3388871369528024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428115.8957466062, 428115.8957466062, 120483.7563998804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210800.0000, 
sim time next is 1211400.0000, 
raw observation next is [18.45, 94.0, 1.0, 2.0, 0.3370533766749014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426047.5908334068, 426047.5908334068, 120247.6722039335], 
processed observation next is [1.0, 0.0, 0.23888888888888887, 0.94, 1.0, 1.0, 0.2107778293748826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15215985386907385, 0.15215985386907385, 0.23124552346910288], 
reward next is 0.7688, 
noisyNet noise sample is [array([-0.8405904], dtype=float32), -0.57600504]. 
=============================================
[2019-03-23 20:29:24,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5842196e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:24,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3133
[2019-03-23 20:29:24,356] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 72.0, 1.0, 2.0, 0.6163044284917502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772841.1793009768, 772841.1793009768, 163438.1239309956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1246800.0000, 
sim time next is 1247400.0000, 
raw observation next is [22.1, 71.0, 1.0, 2.0, 0.6339870659162886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 794523.0118124159, 794523.011812415, 166635.0395659205], 
processed observation next is [1.0, 0.43478260869565216, 0.3740740740740741, 0.71, 1.0, 1.0, 0.5642703165670102, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2837582185044343, 0.28375821850443395, 0.32045199916523176], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.28177524], dtype=float32), 0.81874686]. 
=============================================
[2019-03-23 20:29:29,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4761044e-21 1.0000000e+00 2.5276662e-36 2.6559012e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 20:29:29,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4363
[2019-03-23 20:29:29,467] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 73.0, 1.0, 2.0, 0.4486497279517081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555831.9127046054, 555831.9127046054, 135682.0226251025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1325400.0000, 
sim time next is 1326000.0000, 
raw observation next is [23.03333333333333, 71.0, 1.0, 2.0, 0.6291734305718858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 779584.9200876469, 779584.9200876465, 165573.5853599243], 
processed observation next is [1.0, 0.34782608695652173, 0.4086419753086419, 0.71, 1.0, 1.0, 0.558539798299864, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27842318574558816, 0.278423185745588, 0.31841074107677747], 
reward next is 0.6816, 
noisyNet noise sample is [array([2.054493], dtype=float32), -0.3432862]. 
=============================================
[2019-03-23 20:29:29,485] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.776684]
 [55.776684]
 [55.776684]
 [55.776684]
 [55.776684]], R is [[55.90050507]
 [56.08057404]
 [56.26353073]
 [56.45555496]
 [56.64649582]].
[2019-03-23 20:29:33,945] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 20:29:33,948] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:29:33,949] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:29:33,950] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:33,950] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:33,951] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:29:33,952] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:29:33,953] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:33,953] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:33,953] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:29:33,958] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:29:33,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 20:29:33,971] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 20:29:34,024] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 20:29:34,046] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 20:29:34,047] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 20:29:45,524] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.46568948]
[2019-03-23 20:29:45,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.53333333333333, 52.0, 1.0, 2.0, 0.2994788753415976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382225.6084055145, 382225.6084055145, 115511.3413328044]
[2019-03-23 20:29:45,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:29:45,529] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.477073e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8527405613343653
[2019-03-23 20:30:29,836] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.46568948]
[2019-03-23 20:30:29,837] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.8, 68.0, 1.0, 2.0, 0.7812626891341293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890472.257433257, 890472.257433257, 192098.7377103005]
[2019-03-23 20:30:29,838] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:30:29,840] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.477073e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8449641065607196
[2019-03-23 20:30:30,239] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.46568948]
[2019-03-23 20:30:30,241] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.65020872666667, 91.93019885333334, 1.0, 2.0, 0.7808621006048706, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156159, 1605097.383659282, 1605097.383659282, 332465.0930413128]
[2019-03-23 20:30:30,242] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:30:30,246] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.477073e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.05936049690644163
[2019-03-23 20:30:30,248] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1605097.383659282 W.
[2019-03-23 20:30:37,889] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.46568948]
[2019-03-23 20:30:37,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.5813727973226286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671029.0586543378, 671029.0586543378, 155314.2755237757]
[2019-03-23 20:30:37,891] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:30:37,895] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.477073e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.17389948227090957
[2019-03-23 20:31:10,656] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.46568948]
[2019-03-23 20:31:10,657] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.9, 23.66666666666667, 1.0, 2.0, 0.3335324713883356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 430095.5100594198, 430095.5100594193, 119597.1010540999]
[2019-03-23 20:31:10,657] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:31:10,660] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.477073e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.02012622952052523
[2019-03-23 20:31:16,874] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:31:17,043] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:31:17,161] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:31:17,281] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:31:17,380] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:31:18,396] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 250000, evaluation results [250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:31:30,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4410812e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:30,132] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8356
[2019-03-23 20:31:30,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 68.33333333333334, 1.0, 2.0, 0.4213212279668661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535084.5768863673, 535084.5768863673, 131865.9304038599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650000.0000, 
sim time next is 1650600.0000, 
raw observation next is [21.05, 69.5, 1.0, 2.0, 0.3651215079834854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463991.5962578292, 463991.5962578287, 123990.9323758967], 
processed observation next is [1.0, 0.08695652173913043, 0.3351851851851852, 0.695, 1.0, 1.0, 0.24419227140891123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16571128437779614, 0.16571128437779598, 0.23844410072287825], 
reward next is 0.7616, 
noisyNet noise sample is [array([0.34288707], dtype=float32), -2.5402658]. 
=============================================
[2019-03-23 20:31:32,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1705522e-20 1.0000000e+00 7.0501037e-35 5.5869417e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:32,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8683
[2019-03-23 20:31:32,600] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 69.33333333333334, 1.0, 2.0, 0.4033772612692237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156387, 496550.167874888, 496550.1678748875, 129018.1464433779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1704000.0000, 
sim time next is 1704600.0000, 
raw observation next is [23.75, 70.0, 1.0, 2.0, 0.4007814543672993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493183.4229731849, 493183.4229731849, 128647.6651502023], 
processed observation next is [1.0, 0.7391304347826086, 0.4351851851851852, 0.7, 1.0, 1.0, 0.28664458853249913, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17613693677613745, 0.17613693677613745, 0.24739935605808136], 
reward next is 0.7526, 
noisyNet noise sample is [array([0.6748325], dtype=float32), 1.8482567]. 
=============================================
[2019-03-23 20:31:49,307] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0516602e-20 1.0000000e+00 3.0401078e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:49,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8633
[2019-03-23 20:31:49,324] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 79.0, 1.0, 2.0, 0.3718639624381854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463292.9871949694, 463292.9871949689, 124779.3544310266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2016000.0000, 
sim time next is 2016600.0000, 
raw observation next is [21.71666666666667, 78.33333333333334, 1.0, 2.0, 0.3753655707504654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467104.290209505, 467104.290209505, 125245.7956745098], 
processed observation next is [0.0, 0.34782608695652173, 0.3598765432098766, 0.7833333333333334, 1.0, 1.0, 0.2563875842267445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16682296078910894, 0.16682296078910894, 0.2408572993740573], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.45161432], dtype=float32), 1.2420878]. 
=============================================
[2019-03-23 20:31:49,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4274585e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:49,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3985
[2019-03-23 20:31:49,718] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 83.16666666666667, 1.0, 2.0, 0.373120185447367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465047.9171999443, 465047.9171999443, 124954.0982908087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2013000.0000, 
sim time next is 2013600.0000, 
raw observation next is [21.03333333333333, 82.33333333333334, 1.0, 2.0, 0.3741105527758791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466228.4825172589, 466228.4825172589, 125088.0725862518], 
processed observation next is [0.0, 0.30434782608695654, 0.3345679012345678, 0.8233333333333335, 1.0, 1.0, 0.2548935152093799, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16651017232759247, 0.16651017232759247, 0.24055398574279194], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.09884485], dtype=float32), -0.6787447]. 
=============================================
[2019-03-23 20:31:49,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.099082e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:31:49,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-23 20:31:49,863] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 65.16666666666667, 1.0, 2.0, 0.513096341967438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607365.7298621207, 607365.7298621207, 144791.9870123268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2033400.0000, 
sim time next is 2034000.0000, 
raw observation next is [27.2, 65.0, 1.0, 2.0, 0.5173563695269268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611302.7931325737, 611302.7931325737, 145427.3277859599], 
processed observation next is [0.0, 0.5652173913043478, 0.5629629629629629, 0.65, 1.0, 1.0, 0.42542424943681756, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21832242611877634, 0.21832242611877634, 0.2796679380499229], 
reward next is 0.7203, 
noisyNet noise sample is [array([0.45826015], dtype=float32), -0.0595421]. 
=============================================
[2019-03-23 20:31:49,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[76.35393]
 [76.35393]
 [76.35393]
 [76.35393]
 [76.35393]], R is [[76.31069946]
 [76.26914978]
 [76.22951508]
 [76.19213867]
 [76.15686035]].
[2019-03-23 20:31:50,887] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4520654e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:50,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8663
[2019-03-23 20:31:50,901] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 0.6026587889575423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692856.185198979, 692856.185198979, 158831.8881031575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2058600.0000, 
sim time next is 2059200.0000, 
raw observation next is [26.9, 75.0, 1.0, 2.0, 0.6013212733106752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691442.9745468321, 691442.9745468321, 158606.6605946496], 
processed observation next is [0.0, 0.8695652173913043, 0.5518518518518518, 0.75, 1.0, 1.0, 0.5253824682269943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2469439194810115, 0.2469439194810115, 0.3050128088358646], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.78615606], dtype=float32), 1.0642692]. 
=============================================
[2019-03-23 20:31:57,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8201253e-19 1.0000000e+00 3.2450075e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:31:57,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2311
[2019-03-23 20:31:57,457] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.0, 1.0, 2.0, 0.6053270175002804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707693.4592780896, 707693.4592780896, 159834.776294686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2174400.0000, 
sim time next is 2175000.0000, 
raw observation next is [23.86666666666667, 90.0, 1.0, 2.0, 0.6423109623456211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751332.9472816255, 751332.9472816255, 166425.6991358232], 
processed observation next is [1.0, 0.17391304347826086, 0.4395061728395063, 0.9, 1.0, 1.0, 0.5741797170781203, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2683331954577234, 0.2683331954577234, 0.3200494214150446], 
reward next is 0.6800, 
noisyNet noise sample is [array([1.8701897], dtype=float32), 0.39712587]. 
=============================================
[2019-03-23 20:31:57,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.961006]
 [67.961006]
 [67.961006]
 [67.961006]
 [67.961006]], R is [[67.96134949]
 [67.97436523]
 [67.98464203]
 [67.9910965 ]
 [67.99481201]].
[2019-03-23 20:32:00,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1217833e-14 1.0000000e+00 2.1895631e-24 1.6020278e-25 5.2640349e-27], sum to 1.0000
[2019-03-23 20:32:00,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4472
[2019-03-23 20:32:00,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2465603.531540358 W.
[2019-03-23 20:32:00,879] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 91.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 9.451463766424801, 6.9112, 121.9155665777656, 2465603.531540358, 1164873.206909634, 245649.6692021209], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2217600.0000, 
sim time next is 2218200.0000, 
raw observation next is [24.48333333333333, 91.83333333333334, 1.0, 2.0, 0.764342512475512, 1.0, 1.0, 0.764342512475512, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9245128971092, 1743316.965570186, 1743316.965570185, 329239.2179550165], 
processed observation next is [1.0, 0.6956521739130435, 0.4623456790123456, 0.9183333333333334, 1.0, 1.0, 0.7194553719946571, 1.0, 0.5, 0.7194553719946571, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094519730797418, 0.6226132019893521, 0.6226132019893518, 0.6331523422211855], 
reward next is 0.3668, 
noisyNet noise sample is [array([-1.793728], dtype=float32), -0.20366977]. 
=============================================
[2019-03-23 20:32:07,681] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 20:32:07,688] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:32:07,690] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:32:07,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:32:07,691] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:32:07,691] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:32:07,692] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:32:07,692] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:32:07,693] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:32:07,693] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:32:07,695] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:32:07,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 20:32:07,708] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 20:32:07,709] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 20:32:07,777] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 20:32:07,778] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 20:32:47,709] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:32:47,710] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.06726418, 94.80786113666666, 1.0, 2.0, 0.5331587678326247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648028.4004983837, 648028.4004983837, 148614.6236624964]
[2019-03-23 20:32:47,712] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:32:47,715] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.8463326369654286
[2019-03-23 20:33:12,929] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:12,931] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 60.0, 1.0, 2.0, 0.95317830352757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258129332081, 1086558.186503178, 1086558.186503178, 229614.1359096785]
[2019-03-23 20:33:12,931] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:33:12,935] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.2851801377422476
[2019-03-23 20:33:13,065] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:13,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.62822778, 102.1743653, 1.0, 2.0, 0.5912617944715128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688497.5595562301, 688497.5595562301, 157275.321342622]
[2019-03-23 20:33:13,070] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:33:13,072] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.5940728528023097
[2019-03-23 20:33:13,682] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:13,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.17420787, 68.73031067, 1.0, 2.0, 0.5714986059793851, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9098443931293777, 6.911199999999999, 6.9112, 121.9260426156618, 1303122.813875668, 1303122.813875669, 282934.6858980342]
[2019-03-23 20:33:13,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:33:13,687] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.4639896558420121
[2019-03-23 20:33:13,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1303122.813875668 W.
[2019-03-23 20:33:19,001] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:19,003] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.29813678, 81.71079489, 1.0, 2.0, 0.761399218890603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867819.3345326041, 867819.3345326041, 188097.8387061105]
[2019-03-23 20:33:19,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:33:19,007] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.7856428649216646
[2019-03-23 20:33:22,342] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:22,343] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.21776943, 77.81751622, 1.0, 2.0, 0.6083548895629297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701979.4831423447, 701979.4831423447, 159942.3764451734]
[2019-03-23 20:33:22,343] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:33:22,347] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.9709332197617718
[2019-03-23 20:33:28,692] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:28,693] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 84.0, 1.0, 2.0, 0.4812785173360991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579615.5525728362, 579615.5525728362, 140181.7917121423]
[2019-03-23 20:33:28,695] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:33:28,697] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.13688967691465848
[2019-03-23 20:33:49,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5785619]
[2019-03-23 20:33:49,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.2, 70.0, 1.0, 2.0, 0.3428224228008647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434800.6448680773, 434800.6448680773, 121015.1443465122]
[2019-03-23 20:33:49,497] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:33:49,498] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3985543e-20 1.0000000e+00 3.6101226e-36 2.5020305e-38 0.0000000e+00], sampled 0.5868666450802215
[2019-03-23 20:33:50,337] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:33:50,497] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:33:50,521] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:33:50,774] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:33:50,797] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:33:51,810] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 275000, evaluation results [275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:33:53,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9088938e-13 1.0000000e+00 5.0629626e-23 6.4818245e-25 1.8602563e-26], sum to 1.0000
[2019-03-23 20:33:53,119] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5395
[2019-03-23 20:33:53,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1583099.404264034 W.
[2019-03-23 20:33:53,132] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.96666666666667, 37.0, 1.0, 2.0, 0.7239292964975468, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9615011550873913, 6.9112, 6.9112, 121.9260426156618, 1583099.404264034, 1583099.404264034, 313199.0355367698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2387400.0000, 
sim time next is 2388000.0000, 
raw observation next is [30.93333333333333, 37.0, 1.0, 2.0, 0.5931582024656448, 1.0, 1.0, 0.5931582024656448, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419642.419058421, 1419642.419058421, 268648.097357195], 
processed observation next is [1.0, 0.6521739130434783, 0.7012345679012344, 0.37, 1.0, 1.0, 0.5156645267448152, 1.0, 0.5, 0.5156645267448152, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5070151496637217, 0.5070151496637217, 0.5166309564561442], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.81054634], dtype=float32), -0.891677]. 
=============================================
[2019-03-23 20:33:53,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[38.26096]
 [38.26096]
 [38.26096]
 [38.26096]
 [38.26096]], R is [[37.8783493 ]
 [37.89725876]
 [37.95008469]
 [38.06837463]
 [38.18202209]].
[2019-03-23 20:33:53,922] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3389426e-14 1.0000000e+00 7.9347323e-25 1.6291790e-28 1.4028659e-28], sum to 1.0000
[2019-03-23 20:33:53,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-23 20:33:53,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1542688.949901691 W.
[2019-03-23 20:33:53,949] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.83333333333334, 23.66666666666666, 1.0, 2.0, 0.6348236553040706, 1.0, 1.0, 0.6348236553040706, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1542688.949901691, 1542688.949901691, 284242.8189081777], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2463600.0000, 
sim time next is 2464200.0000, 
raw observation next is [33.95, 23.5, 1.0, 2.0, 0.6354271740504209, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9562174988562442, 6.911200000000001, 6.9112, 121.9260426156618, 1490571.201289258, 1490571.201289258, 293647.9426845766], 
processed observation next is [1.0, 0.5217391304347826, 0.8129629629629631, 0.235, 1.0, 1.0, 0.5659847310124059, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9452718735703053, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5323468576033065, 0.5323468576033065, 0.5647075820857242], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42028993], dtype=float32), 0.43855727]. 
=============================================
[2019-03-23 20:33:54,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5189292e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:33:54,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-23 20:33:54,719] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 48.0, 1.0, 2.0, 0.38504556434815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478308.411445769, 478308.411445769, 126558.959703931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2406600.0000, 
sim time next is 2407200.0000, 
raw observation next is [26.83333333333333, 49.0, 1.0, 2.0, 0.3854484863058197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478805.5961316593, 478805.5961316593, 126614.6212483078], 
processed observation next is [1.0, 0.8695652173913043, 0.5493827160493825, 0.49, 1.0, 1.0, 0.26839105512597583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17100199861844975, 0.17100199861844975, 0.24348965624674576], 
reward next is 0.7565, 
noisyNet noise sample is [array([-0.9198196], dtype=float32), -0.67076576]. 
=============================================
[2019-03-23 20:33:54,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9030912e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:33:54,820] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3235
[2019-03-23 20:33:54,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 63.0, 1.0, 2.0, 0.3411975040969739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 430964.1874114221, 430964.1874114226, 120784.6509170909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2419800.0000, 
sim time next is 2420400.0000, 
raw observation next is [22.53333333333333, 63.00000000000001, 1.0, 2.0, 0.3373014606054798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426636.2744526397, 426636.2744526397, 120282.8062576669], 
processed observation next is [1.0, 0.0, 0.3901234567901234, 0.6300000000000001, 1.0, 1.0, 0.21107316738747592, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1523700980187999, 0.1523700980187999, 0.23131308895705174], 
reward next is 0.7687, 
noisyNet noise sample is [array([0.30263302], dtype=float32), -0.79450244]. 
=============================================
[2019-03-23 20:34:04,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1341049e-20 1.0000000e+00 6.3096303e-34 4.8915881e-37 1.2299504e-38], sum to 1.0000
[2019-03-23 20:34:04,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3988
[2019-03-23 20:34:04,086] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 62.83333333333334, 1.0, 2.0, 0.5007565331675203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598890.2063113574, 598890.2063113574, 143073.6060343808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584200.0000, 
sim time next is 2584800.0000, 
raw observation next is [26.6, 64.0, 1.0, 2.0, 0.5013315521229745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599791.3945577956, 599791.3945577956, 143171.8190985648], 
processed observation next is [1.0, 0.9565217391304348, 0.5407407407407407, 0.64, 1.0, 1.0, 0.40634708586068397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21421121234206986, 0.21421121234206986, 0.27533042134339386], 
reward next is 0.7247, 
noisyNet noise sample is [array([1.1081046], dtype=float32), 0.33416328]. 
=============================================
[2019-03-23 20:34:06,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0813664e-21 1.0000000e+00 8.4331345e-36 1.1181164e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:06,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7967
[2019-03-23 20:34:06,797] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 77.0, 1.0, 2.0, 0.5424494584351575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638772.6183961874, 638772.6183961874, 149401.3071061511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2640600.0000, 
sim time next is 2641200.0000, 
raw observation next is [25.53333333333333, 76.66666666666667, 1.0, 2.0, 0.5459974442210977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641960.2780370902, 641960.2780370902, 149943.0742992861], 
processed observation next is [0.0, 0.5652173913043478, 0.5012345679012346, 0.7666666666666667, 1.0, 1.0, 0.45952076692987825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22927152787038935, 0.22927152787038935, 0.28835206596016555], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.6067888], dtype=float32), -0.6866208]. 
=============================================
[2019-03-23 20:34:08,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1229251e-19 1.0000000e+00 2.1623195e-33 2.8880197e-35 1.4470212e-37], sum to 1.0000
[2019-03-23 20:34:08,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8167
[2019-03-23 20:34:08,652] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 72.0, 1.0, 2.0, 0.6811770963657765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776338.3280064305, 776338.3280064305, 172610.7052965619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2750400.0000, 
sim time next is 2751000.0000, 
raw observation next is [28.33333333333334, 73.16666666666667, 1.0, 2.0, 0.6812687336407329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776442.820011903, 776442.820011903, 172627.4468370141], 
processed observation next is [0.0, 0.8695652173913043, 0.6049382716049385, 0.7316666666666667, 1.0, 1.0, 0.6205580162389678, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2773010071471082, 0.2773010071471082, 0.3319758593019502], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.16774486], dtype=float32), -0.21254268]. 
=============================================
[2019-03-23 20:34:08,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[59.924892]
 [59.924892]
 [59.924892]
 [59.924892]
 [59.924892]], R is [[59.99367142]
 [60.06179047]
 [60.13108826]
 [60.20194244]
 [60.2745018 ]].
[2019-03-23 20:34:20,791] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2857840e-13 1.0000000e+00 1.2395841e-21 2.7430191e-24 7.8200381e-24], sum to 1.0000
[2019-03-23 20:34:20,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7294
[2019-03-23 20:34:20,801] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6881961344592514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784342.0267900283, 784342.0267900283, 173921.7283386645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917200.0000, 
sim time next is 2917800.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.6759071409926769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770329.1356786313, 770329.1356786313, 171633.6448746658], 
processed observation next is [1.0, 0.782608695652174, 0.5370370370370371, 0.865, 1.0, 1.0, 0.6141751678484249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27511754845665404, 0.27511754845665404, 0.3300647016820496], 
reward next is 0.6699, 
noisyNet noise sample is [array([-1.1808119], dtype=float32), 0.44774318]. 
=============================================
[2019-03-23 20:34:22,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0564775e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:22,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8644
[2019-03-23 20:34:22,633] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.33333333333334, 1.0, 2.0, 0.7053744989281009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805232.3758621824, 805232.3758621824, 177226.149382306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2954400.0000, 
sim time next is 2955000.0000, 
raw observation next is [24.75, 90.66666666666666, 1.0, 2.0, 0.6969909531675891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798129.9592200142, 798129.9592200142, 175762.5962305657], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9066666666666666, 1.0, 1.0, 0.6392749442471298, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2850464140071479, 0.2850464140071479, 0.33800499275108786], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.23319983], dtype=float32), -0.061367687]. 
=============================================
[2019-03-23 20:34:22,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.44975]
 [63.44975]
 [63.44975]
 [63.44975]
 [63.44975]], R is [[63.47725296]
 [63.50165939]
 [63.52799606]
 [63.54897308]
 [63.55386734]].
[2019-03-23 20:34:28,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4358819e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:28,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-23 20:34:28,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 93.83333333333334, 1.0, 2.0, 0.7746352820079808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 882914.0805744511, 882914.0805744511, 190750.772102335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3034200.0000, 
sim time next is 3034800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7622760045413984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 868819.2341942501, 868819.2341942496, 188265.0673398155], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7169952435016648, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3102925836408036, 0.3102925836408034, 0.3620482064227221], 
reward next is 0.6380, 
noisyNet noise sample is [array([-1.0945982], dtype=float32), 0.92052954]. 
=============================================
[2019-03-23 20:34:31,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.521516e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:34:31,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5959
[2019-03-23 20:34:31,262] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.506012336141787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602888.503701165, 602888.5037011645, 143819.2109219316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3113400.0000, 
sim time next is 3114000.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5058524108876513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602698.475924039, 602698.475924039, 143793.9451421387], 
processed observation next is [1.0, 0.043478260869565216, 0.5925925925925926, 0.58, 1.0, 1.0, 0.41172906058053726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21524945568715678, 0.21524945568715678, 0.2765268175810359], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.07269251], dtype=float32), -1.3504331]. 
=============================================
[2019-03-23 20:34:31,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.05046]
 [71.05046]
 [71.05046]
 [71.05046]
 [71.05046]], R is [[71.06343079]
 [71.07622528]
 [71.08876038]
 [71.10094452]
 [71.11269379]].
[2019-03-23 20:34:32,670] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5027591e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:32,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6515
[2019-03-23 20:34:32,684] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 54.66666666666666, 1.0, 2.0, 0.5938965346771823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724643.0012521134, 724643.0012521134, 158977.4975532311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3132600.0000, 
sim time next is 3133200.0000, 
raw observation next is [27.06666666666667, 55.33333333333334, 1.0, 2.0, 0.5897382788851712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718324.1148429664, 718324.1148429664, 158214.7857595313], 
processed observation next is [1.0, 0.2608695652173913, 0.5580246913580248, 0.5533333333333335, 1.0, 1.0, 0.5115931891490133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25654432672963084, 0.25654432672963084, 0.30425920338371404], 
reward next is 0.6957, 
noisyNet noise sample is [array([0.36009634], dtype=float32), -0.23499972]. 
=============================================
[2019-03-23 20:34:39,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0709959e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:39,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4750
[2019-03-23 20:34:39,905] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 77.0, 1.0, 2.0, 0.5711014422579751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666670.673487403, 666670.673487403, 153921.0769450775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [25.9, 77.5, 1.0, 2.0, 0.5760072263651067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670948.1348651316, 670948.1348651316, 154685.572800095], 
processed observation next is [0.0, 0.8695652173913043, 0.5148148148148147, 0.775, 1.0, 1.0, 0.4952466980536984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23962433388040413, 0.23962433388040413, 0.29747225538479805], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.122229], dtype=float32), -0.9246082]. 
=============================================
[2019-03-23 20:34:40,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0132154e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:34:40,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8519
[2019-03-23 20:34:40,038] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.5970135925654511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690829.183511032, 690829.1835110316, 158068.7304943599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3272400.0000, 
sim time next is 3273000.0000, 
raw observation next is [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.6008830990830424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694454.6736476488, 694454.6736476488, 158697.4296869911], 
processed observation next is [0.0, 0.9130434782608695, 0.506172839506173, 0.8150000000000002, 1.0, 1.0, 0.5248608322417171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2480195263027317, 0.2480195263027317, 0.30518736478267516], 
reward next is 0.6948, 
noisyNet noise sample is [array([1.0327457], dtype=float32), -2.2108736]. 
=============================================
[2019-03-23 20:34:40,057] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.42752]
 [71.42752]
 [71.42752]
 [71.42752]
 [71.42752]], R is [[71.40805817]
 [71.38999939]
 [71.37446594]
 [71.36132812]
 [71.35024261]].
[2019-03-23 20:34:41,411] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 20:34:41,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:34:41,415] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:41,415] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:34:41,416] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:34:41,418] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:41,420] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:41,421] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:34:41,423] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:34:41,423] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:41,424] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:34:41,440] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 20:34:41,440] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 20:34:41,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 20:34:41,462] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 20:34:41,488] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 20:34:43,715] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5697218]
[2019-03-23 20:34:43,716] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.97494043, 88.31639151, 1.0, 2.0, 0.448886492398349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545590.8196177074, 545590.8196177079, 135437.086713348]
[2019-03-23 20:34:43,717] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:34:43,720] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.486946e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.31191074249466366
[2019-03-23 20:35:36,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5697218]
[2019-03-23 20:35:36,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.43762125333333, 104.8714304033333, 1.0, 2.0, 0.7192901948407138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 819799.1001924407, 819799.1001924402, 179837.1803508122]
[2019-03-23 20:35:36,869] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:35:36,871] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.486946e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.31029229310585815
[2019-03-23 20:36:15,675] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5697218]
[2019-03-23 20:36:15,676] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.167841595, 86.765409925, 1.0, 2.0, 0.2819914907069261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 362881.2177679533, 362881.2177679529, 113148.5470066931]
[2019-03-23 20:36:15,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:36:15,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.486946e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3983126411208613
[2019-03-23 20:36:23,753] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:36:24,321] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:36:24,325] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:36:24,412] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:36:24,685] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:36:25,699] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 300000, evaluation results [300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:36:32,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8034215e-14 1.0000000e+00 2.7268833e-21 1.4154643e-23 6.7454360e-24], sum to 1.0000
[2019-03-23 20:36:32,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3502
[2019-03-23 20:36:32,948] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 78.66666666666667, 1.0, 2.0, 0.6908975036763843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787422.3779088878, 787422.3779088878, 174427.6941693872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3439200.0000, 
sim time next is 3439800.0000, 
raw observation next is [27.45, 78.5, 1.0, 2.0, 0.6831419197516214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778578.7767991655, 778578.7767991651, 172976.1664491504], 
processed observation next is [1.0, 0.8260869565217391, 0.5722222222222222, 0.785, 1.0, 1.0, 0.6227879997043112, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2780638488568448, 0.27806384885684465, 0.3326464739406738], 
reward next is 0.6674, 
noisyNet noise sample is [array([-2.0990763], dtype=float32), -0.82279503]. 
=============================================
[2019-03-23 20:36:39,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.882588e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:36:39,357] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1542
[2019-03-23 20:36:39,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 93.66666666666667, 1.0, 2.0, 0.5806608267564172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688696.6442537673, 688696.6442537673, 155991.3025331475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3568800.0000, 
sim time next is 3569400.0000, 
raw observation next is [22.45, 93.5, 1.0, 2.0, 0.5779806286761224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688138.9564953335, 688138.9564953335, 155635.2423156492], 
processed observation next is [1.0, 0.30434782608695654, 0.387037037037037, 0.935, 1.0, 1.0, 0.49759598651919335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24576391303404765, 0.24576391303404765, 0.29929854291471], 
reward next is 0.7007, 
noisyNet noise sample is [array([-0.8054026], dtype=float32), -0.66123796]. 
=============================================
[2019-03-23 20:36:41,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9511734e-15 1.0000000e+00 3.8892027e-22 9.8822450e-25 3.3050038e-24], sum to 1.0000
[2019-03-23 20:36:41,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-23 20:36:41,455] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5301556446242681, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8443303395201175, 6.911200000000001, 6.9112, 121.9258386080348, 1215691.947810107, 1215691.947810107, 267573.751333927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3668400.0000, 
sim time next is 3669000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.9047632654538249, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425534542, 1045629.290778606, 1045629.290778606, 219305.1722351766], 
processed observation next is [1.0, 0.4782608695652174, 0.4074074074074074, 1.0, 1.0, 1.0, 0.8866229350640773, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621284071422, 0.3734390324209307, 0.3734390324209307, 0.4217407158368781], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1544725], dtype=float32), -0.85066944]. 
=============================================
[2019-03-23 20:36:41,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5654842e-14 1.0000000e+00 6.1930399e-21 1.2418208e-24 2.5663118e-24], sum to 1.0000
[2019-03-23 20:36:41,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[27.891655]
 [27.891655]
 [27.891655]
 [27.891655]
 [27.891655]], R is [[27.61273766]
 [27.33661079]
 [27.06324577]
 [27.26268387]
 [26.99005699]].
[2019-03-23 20:36:41,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-23 20:36:41,487] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 82.33333333333334, 1.0, 2.0, 0.5505292009069135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642702.2026959194, 642702.2026959194, 150495.0884836894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3606600.0000, 
sim time next is 3607200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5569951974611488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649652.8911720772, 649652.8911720772, 151538.4641220554], 
processed observation next is [1.0, 0.782608695652174, 0.48148148148148145, 0.83, 1.0, 1.0, 0.47261333031089137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23201888970431328, 0.23201888970431328, 0.29142012331164496], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.89772534], dtype=float32), -0.6527609]. 
=============================================
[2019-03-23 20:36:43,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.653615e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:36:43,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2732
[2019-03-23 20:36:43,661] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 98.83333333333333, 1.0, 2.0, 0.5738138367440835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 681210.0875008467, 681210.0875008462, 154849.6382051829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3654600.0000, 
sim time next is 3655200.0000, 
raw observation next is [22.03333333333333, 98.66666666666669, 1.0, 2.0, 0.5371180716750985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637706.7951182981, 637706.7951182981, 148737.3128619144], 
processed observation next is [1.0, 0.30434782608695654, 0.37160493827160485, 0.9866666666666668, 1.0, 1.0, 0.4489500853274982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22775242682796362, 0.22775242682796362, 0.28603329396522], 
reward next is 0.7140, 
noisyNet noise sample is [array([-1.3603365], dtype=float32), -0.967597]. 
=============================================
[2019-03-23 20:36:47,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.470364e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:36:47,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4046
[2019-03-23 20:36:47,032] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 94.00000000000001, 1.0, 2.0, 0.6696799924360773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763228.5417115594, 763228.5417115594, 170482.4166058683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3712200.0000, 
sim time next is 3712800.0000, 
raw observation next is [25.06666666666667, 94.0, 1.0, 2.0, 0.6681501539406507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761484.1318554935, 761484.1318554935, 170201.0041468944], 
processed observation next is [1.0, 1.0, 0.4839506172839507, 0.94, 1.0, 1.0, 0.6049406594531556, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2719586185198191, 0.2719586185198191, 0.3273096233594123], 
reward next is 0.6727, 
noisyNet noise sample is [array([1.5317243], dtype=float32), 0.1686999]. 
=============================================
[2019-03-23 20:36:49,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4857309e-18 1.0000000e+00 5.0118567e-27 9.0652479e-31 9.5945955e-30], sum to 1.0000
[2019-03-23 20:36:49,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5557
[2019-03-23 20:36:49,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2049624.013860629 W.
[2019-03-23 20:36:49,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.53333333333333, 82.66666666666666, 1.0, 2.0, 0.5989910042952571, 1.0, 2.0, 0.5989910042952571, 1.0, 2.0, 0.9536131866131505, 6.9112, 6.9112, 121.94756008, 2049624.013860629, 2049624.013860629, 394826.1156444636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3753600.0000, 
sim time next is 3754200.0000, 
raw observation next is [28.91666666666667, 79.83333333333333, 1.0, 2.0, 0.5979499586696801, 1.0, 2.0, 0.5979499586696801, 1.0, 2.0, 0.9519558080727429, 6.911199999999999, 6.9112, 121.94756008, 2046057.689543728, 2046057.689543729, 394259.7573853083], 
processed observation next is [1.0, 0.43478260869565216, 0.6265432098765434, 0.7983333333333333, 1.0, 1.0, 0.5213689984162859, 1.0, 1.0, 0.5213689984162859, 1.0, 1.0, 0.9399447600909285, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.73073488912276, 0.7307348891227603, 0.7581918411255928], 
reward next is 0.2418, 
noisyNet noise sample is [array([0.3178512], dtype=float32), -0.9596722]. 
=============================================
[2019-03-23 20:36:50,162] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0531502e-09 1.0000000e+00 7.3043676e-14 6.8277372e-16 2.8212658e-15], sum to 1.0000
[2019-03-23 20:36:50,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-23 20:36:50,177] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 53.0, 1.0, 2.0, 0.7009622392381677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798899.2295950548, 798899.2295950548, 176329.2823845062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3782400.0000, 
sim time next is 3783000.0000, 
raw observation next is [33.16666666666666, 54.5, 1.0, 2.0, 0.712243550101067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811763.5504387452, 811763.5504387452, 178478.4527188419], 
processed observation next is [1.0, 0.782608695652174, 0.7839506172839502, 0.545, 1.0, 1.0, 0.6574327977393655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2899155537281233, 0.2899155537281233, 0.3432277936900806], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.10346752], dtype=float32), 1.1427184]. 
=============================================
[2019-03-23 20:36:50,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[15.995456]
 [15.995456]
 [15.995456]
 [15.995456]
 [15.995456]], R is [[16.49227333]
 [16.98825645]
 [17.48605537]
 [17.98083878]
 [18.47215843]].
[2019-03-23 20:36:51,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2045424e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:36:51,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-23 20:36:51,852] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 77.33333333333333, 1.0, 2.0, 0.5730485183230508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666658.1817657753, 666658.1817657753, 154148.3600873292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3814800.0000, 
sim time next is 3815400.0000, 
raw observation next is [26.0, 78.16666666666667, 1.0, 2.0, 0.5794574409792116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672386.6430277174, 672386.6430277178, 155154.4090021297], 
processed observation next is [0.0, 0.13043478260869565, 0.5185185185185185, 0.7816666666666667, 1.0, 1.0, 0.4993540964038233, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24013808679561335, 0.24013808679561352, 0.298373863465634], 
reward next is 0.7016, 
noisyNet noise sample is [array([-0.24232635], dtype=float32), 1.3183392]. 
=============================================
[2019-03-23 20:36:56,453] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.082637e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:36:56,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7133
[2019-03-23 20:36:56,463] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 89.33333333333333, 1.0, 2.0, 0.7450674271156634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849194.5498055457, 849194.5498055457, 184854.0153885002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898200.0000, 
sim time next is 3898800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7523220758437918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857467.6995142838, 857467.6995142838, 186289.07030845], 
processed observation next is [0.0, 0.13043478260869565, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7051453283854665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3062384641122442, 0.3062384641122442, 0.3582482121316346], 
reward next is 0.6418, 
noisyNet noise sample is [array([0.66195476], dtype=float32), -0.97753674]. 
=============================================
[2019-03-23 20:37:06,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1722294e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:37:06,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9799
[2019-03-23 20:37:06,844] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4487397923208389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549149.8090784793, 549149.8090784793, 135523.2503132933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4060800.0000, 
sim time next is 4061400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4411135496914033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541043.1052586475, 541043.1052586475, 134425.1228089939], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 1.0, 1.0, 0.3346589877278611, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19322968044951697, 0.19322968044951697, 0.2585098515557575], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.38200366], dtype=float32), -1.7735289]. 
=============================================
[2019-03-23 20:37:09,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7052027e-16 1.0000000e+00 1.3077086e-22 5.2674122e-26 4.6913358e-26], sum to 1.0000
[2019-03-23 20:37:09,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3129
[2019-03-23 20:37:09,673] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 92.66666666666667, 1.0, 2.0, 0.449394207365416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548261.0274395389, 548261.0274395389, 135573.6362651458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4129800.0000, 
sim time next is 4130400.0000, 
raw observation next is [21.1, 93.33333333333334, 1.0, 2.0, 0.4478038558061107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 546488.3635835422, 546488.3635835417, 135341.5085122862], 
processed observation next is [1.0, 0.8260869565217391, 0.3370370370370371, 0.9333333333333335, 1.0, 1.0, 0.34262363786441746, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19517441556555076, 0.1951744155655506, 0.26027213175439656], 
reward next is 0.7397, 
noisyNet noise sample is [array([-0.13162531], dtype=float32), 1.643524]. 
=============================================
[2019-03-23 20:37:12,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2959154e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:37:12,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6293
[2019-03-23 20:37:12,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1612750.9071104 W.
[2019-03-23 20:37:12,496] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 68.0, 1.0, 2.0, 0.7875678116726339, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1612750.9071104, 1612750.9071104, 333772.7257209097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4181400.0000, 
sim time next is 4182000.0000, 
raw observation next is [28.33333333333334, 66.0, 1.0, 2.0, 0.8017241115957117, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1628908.331155928, 1628908.331155929, 336572.188732417], 
processed observation next is [1.0, 0.391304347826087, 0.6049382716049385, 0.66, 1.0, 1.0, 0.7639572757091806, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5817529754128314, 0.5817529754128318, 0.6472542091008019], 
reward next is 0.3527, 
noisyNet noise sample is [array([-0.49992713], dtype=float32), 3.2970958]. 
=============================================
[2019-03-23 20:37:12,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.116714]
 [63.116714]
 [63.116714]
 [63.116714]
 [63.116714]], R is [[62.83829498]
 [62.20991135]
 [61.58781433]
 [60.97193527]
 [60.76745605]].
[2019-03-23 20:37:12,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.935693e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:37:12,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-23 20:37:12,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1627070.247719578 W.
[2019-03-23 20:37:12,721] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.800113690787924, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1627070.247719578, 1627070.247719578, 336252.0549024945], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4179600.0000, 
sim time next is 4180200.0000, 
raw observation next is [27.33333333333333, 72.0, 1.0, 2.0, 0.733201891679128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1550698.08660901, 1550698.08660901, 323344.0136783869], 
processed observation next is [1.0, 0.391304347826087, 0.5679012345679011, 0.72, 1.0, 1.0, 0.6823832043799143, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5538207452175036, 0.5538207452175036, 0.6218154109199748], 
reward next is 0.3782, 
noisyNet noise sample is [array([-0.09181079], dtype=float32), 1.2330954]. 
=============================================
[2019-03-23 20:37:13,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4441134e-13 1.0000000e+00 8.6185809e-20 2.3767599e-22 2.7902813e-22], sum to 1.0000
[2019-03-23 20:37:13,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7313
[2019-03-23 20:37:13,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1703461.169176088 W.
[2019-03-23 20:37:13,619] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.05, 32.5, 1.0, 2.0, 0.7304230827548802, 1.0, 2.0, 0.7304230827548802, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1703461.169176088, 1703461.169176088, 317710.4583121942], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4203000.0000, 
sim time next is 4203600.0000, 
raw observation next is [34.03333333333333, 33.0, 1.0, 2.0, 0.4814608817927831, 1.0, 2.0, 0.4814608817927831, 1.0, 1.0, 0.7668784941959749, 6.911199999999999, 6.9112, 121.94756008, 1658886.637074433, 1658886.637074434, 334655.843275386], 
processed observation next is [1.0, 0.6521739130434783, 0.8160493827160493, 0.33, 1.0, 1.0, 0.3826915259437894, 1.0, 1.0, 0.3826915259437894, 1.0, 0.5, 0.7085981177449685, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.592459513240869, 0.5924595132408693, 0.6435689293757424], 
reward next is 0.3564, 
noisyNet noise sample is [array([0.57186633], dtype=float32), -0.070452414]. 
=============================================
[2019-03-23 20:37:15,537] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 20:37:15,539] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:37:15,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:37:15,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:37:15,541] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:37:15,541] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:37:15,543] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:37:15,543] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:37:15,545] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:37:15,545] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:37:15,547] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:37:15,563] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 20:37:15,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 20:37:15,587] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 20:37:15,612] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 20:37:15,668] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 20:37:25,898] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:37:25,899] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.41457712, 23.47794917666667, 1.0, 2.0, 0.9580723735335268, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.371761643471662, 6.9112, 121.9241158734721, 1418043.872235644, 1182198.873256478, 234774.8107630156]
[2019-03-23 20:37:25,900] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:37:25,905] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9188736347680747
[2019-03-23 20:37:25,906] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1418043.872235644 W.
[2019-03-23 20:37:38,851] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:37:38,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 33.0, 1.0, 2.0, 0.3563302843683521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446175.9249095883, 446175.9249095883, 122728.9518739265]
[2019-03-23 20:37:38,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:37:38,857] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.28382231479864917
[2019-03-23 20:37:41,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:37:41,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.43469316166667, 86.02859110166668, 1.0, 2.0, 0.2468527417767381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 318417.8526568747, 318417.8526568747, 97651.99436005446]
[2019-03-23 20:37:41,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:37:41,517] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.38817475863547746
[2019-03-23 20:37:49,024] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:37:49,025] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 78.0, 1.0, 2.0, 0.4576716195767578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 550869.2627097273, 550869.2627097269, 136578.7820946594]
[2019-03-23 20:37:49,029] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:37:49,031] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.825582000503305
[2019-03-23 20:37:51,375] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:37:51,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.56666666666666, 35.66666666666666, 1.0, 2.0, 0.5960616111020786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9573596676848485, 6.9112, 6.9112, 121.9260426156618, 1438269.288187255, 1438269.288187255, 288066.4325304895]
[2019-03-23 20:37:51,378] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:37:51,380] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.03372857644105054
[2019-03-23 20:37:51,383] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1438269.288187255 W.
[2019-03-23 20:38:05,599] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:38:05,599] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.24674443666667, 95.26920754333332, 1.0, 2.0, 0.5750045909747162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659740.1146336043, 659740.1146336043, 154052.2150505946]
[2019-03-23 20:38:05,600] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:38:05,603] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7232037313988822
[2019-03-23 20:38:39,992] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:38:39,993] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.54716713833333, 84.80397516833334, 1.0, 2.0, 0.4767192183070019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577278.0551862031, 577278.0551862031, 139583.1114491865]
[2019-03-23 20:38:39,994] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:38:39,998] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9481672239302615
[2019-03-23 20:38:48,618] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.52242416]
[2019-03-23 20:38:48,619] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.96513395, 81.21379479666666, 1.0, 2.0, 0.2905794227739235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371885.1183588838, 371885.1183588838, 114421.3016182429]
[2019-03-23 20:38:48,620] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:38:48,623] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.979923e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.03528497428102495
[2019-03-23 20:38:57,360] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:38:58,003] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:38:58,072] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:38:58,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:38:58,171] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:38:59,182] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 325000, evaluation results [325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:39:06,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4213634e-10 1.0000000e+00 6.9816574e-16 1.2209885e-16 1.8926112e-17], sum to 1.0000
[2019-03-23 20:39:06,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8659
[2019-03-23 20:39:06,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2324113.00879176 W.
[2019-03-23 20:39:06,305] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.8, 49.0, 1.0, 2.0, 1.018656673721376, 1.0, 2.0, 1.018656673721376, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258853545034, 2324113.00879176, 2324113.00879176, 442390.1063595987], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4379400.0000, 
sim time next is 4380000.0000, 
raw observation next is [32.73333333333333, 49.0, 1.0, 2.0, 0.7231612396275259, 1.0, 2.0, 0.6749452817901975, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2309860.05931102, 2309860.05931102, 435521.8781879604], 
processed observation next is [1.0, 0.6956521739130435, 0.767901234567901, 0.49, 1.0, 1.0, 0.670430047175626, 1.0, 1.0, 0.6130300973692827, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8249500211825073, 0.8249500211825073, 0.8375420734383854], 
reward next is 0.1625, 
noisyNet noise sample is [array([0.23614708], dtype=float32), 0.09474229]. 
=============================================
[2019-03-23 20:39:06,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[19.742111]
 [19.742111]
 [19.742111]
 [19.742111]
 [19.742111]], R is [[19.70715141]
 [19.65933037]
 [19.46273804]
 [19.47291756]
 [19.5175724 ]].
[2019-03-23 20:39:06,437] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6829423e-09 1.0000000e+00 2.8978642e-12 9.6612049e-14 1.0760743e-13], sum to 1.0000
[2019-03-23 20:39:06,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-23 20:39:06,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2309670.202168852 W.
[2019-03-23 20:39:06,453] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.8, 49.0, 1.0, 2.0, 0.7230504297480452, 1.0, 2.0, 0.6748898768504574, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2309670.202168852, 2309670.202168853, 435491.5481685057], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4379400.0000, 
sim time next is 4380000.0000, 
raw observation next is [32.73333333333333, 49.0, 1.0, 2.0, 1.017141546624311, 1.0, 2.0, 1.017141546624311, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259022750981, 2320651.681639754, 2320651.681639754, 441649.5786842976], 
processed observation next is [1.0, 0.6956521739130435, 0.767901234567901, 0.49, 1.0, 1.0, 1.0204066031241799, 1.0, 1.0, 1.0204066031241799, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094611971047369, 0.828804172014198, 0.828804172014198, 0.8493261128544185], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7510263], dtype=float32), -0.5213575]. 
=============================================
[2019-03-23 20:39:06,479] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[14.924061]
 [14.924061]
 [14.924061]
 [14.924061]
 [14.924061]], R is [[14.77481937]
 [14.78958797]
 [14.80412388]
 [14.86868954]
 [14.96769714]].
[2019-03-23 20:39:07,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4158791e-17 1.0000000e+00 7.3366609e-26 1.5596938e-28 3.3965761e-28], sum to 1.0000
[2019-03-23 20:39:07,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8713
[2019-03-23 20:39:07,308] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 92.66666666666667, 1.0, 2.0, 0.4940858690301305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 593121.0603713352, 593121.0603713348, 142106.0536576847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4411200.0000, 
sim time next is 4411800.0000, 
raw observation next is [22.25, 92.0, 1.0, 2.0, 0.4936631096396072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592610.6878534715, 592610.6878534715, 142039.8596730684], 
processed observation next is [0.0, 0.043478260869565216, 0.37962962962962965, 0.92, 1.0, 1.0, 0.3972179876661991, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21164667423338268, 0.21164667423338268, 0.2731535762943623], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.72063464], dtype=float32), 0.5426526]. 
=============================================
[2019-03-23 20:39:07,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7416110e-21 1.0000000e+00 7.8372077e-32 2.4064778e-34 1.9158613e-34], sum to 1.0000
[2019-03-23 20:39:07,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5944
[2019-03-23 20:39:07,504] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 75.0, 1.0, 2.0, 0.6703245511837952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763963.505862447, 763963.505862447, 170601.0224046793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4393200.0000, 
sim time next is 4393800.0000, 
raw observation next is [27.9, 76.0, 1.0, 2.0, 0.6779135218817379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772616.9537954936, 772616.9537954936, 172004.359937254], 
processed observation next is [1.0, 0.8695652173913043, 0.5888888888888888, 0.76, 1.0, 1.0, 0.6165637165258785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2759346263555334, 0.2759346263555334, 0.33077761526395], 
reward next is 0.6692, 
noisyNet noise sample is [array([1.9526402], dtype=float32), 0.08742776]. 
=============================================
[2019-03-23 20:39:10,795] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6208387e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:10,803] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3704
[2019-03-23 20:39:10,808] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 68.33333333333333, 1.0, 2.0, 0.6910765522900006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 787626.5461416054, 787626.5461416049, 174462.5655347174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4459200.0000, 
sim time next is 4459800.0000, 
raw observation next is [29.83333333333333, 69.16666666666667, 1.0, 2.0, 0.7054895257809093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804061.7656457409, 804061.7656457409, 177188.0442975709], 
processed observation next is [0.0, 0.6086956521739131, 0.6604938271604937, 0.6916666666666668, 1.0, 1.0, 0.6493922925963206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2871649163020503, 0.2871649163020503, 0.34074623903379014], 
reward next is 0.6593, 
noisyNet noise sample is [array([-1.4523212], dtype=float32), -2.0322297]. 
=============================================
[2019-03-23 20:39:12,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9993543e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:12,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2216
[2019-03-23 20:39:12,682] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6585278009620904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 750512.2624758733, 750512.2624758729, 168438.8443565942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4494000.0000, 
sim time next is 4494600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.650431328611727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741602.720296786, 741602.720296786, 166985.8492888572], 
processed observation next is [0.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.5838468197758655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2648581143917093, 0.2648581143917093, 0.3211266332478023], 
reward next is 0.6789, 
noisyNet noise sample is [array([0.9999469], dtype=float32), -0.69512683]. 
=============================================
[2019-03-23 20:39:13,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5847166e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:13,533] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2592
[2019-03-23 20:39:13,542] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5866139833721604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680798.7439094037, 680798.7439094037, 156376.8160159577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4517400.0000, 
sim time next is 4518000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5864564911323468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 680616.2007247963, 680616.2007247958, 156349.9322283302], 
processed observation next is [0.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5076862989670795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2430772145445701, 0.24307721454456993, 0.3006729465929427], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.72588736], dtype=float32), 1.5693319]. 
=============================================
[2019-03-23 20:39:13,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.73585]
 [75.73585]
 [75.73585]
 [75.73585]
 [75.73585]], R is [[75.67782593]
 [75.62032318]
 [75.5633316 ]
 [75.50683594]
 [75.4509201 ]].
[2019-03-23 20:39:33,127] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6743391e-14 1.0000000e+00 1.5339971e-20 2.0039755e-23 1.9181986e-22], sum to 1.0000
[2019-03-23 20:39:33,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1414
[2019-03-23 20:39:33,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1348509.711900244 W.
[2019-03-23 20:39:33,148] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 89.0, 1.0, 2.0, 0.5913860145301045, 1.0, 1.0, 0.5913860145301045, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1348509.711900244, 1348509.711900244, 265094.6604130954], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4884600.0000, 
sim time next is 4885200.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.725772093756543, 1.0, 2.0, 0.725772093756543, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1655263.801862797, 1655263.801862798, 314039.5518523976], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.89, 1.0, 1.0, 0.6735382068530273, 1.0, 1.0, 0.6735382068530273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5911656435224275, 0.5911656435224278, 0.6039222151007646], 
reward next is 0.3961, 
noisyNet noise sample is [array([0.16176511], dtype=float32), 1.5466601]. 
=============================================
[2019-03-23 20:39:34,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5704748e-09 1.0000000e+00 2.1762531e-12 4.1512121e-16 1.6805726e-15], sum to 1.0000
[2019-03-23 20:39:34,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2968
[2019-03-23 20:39:34,576] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 69.83333333333333, 1.0, 2.0, 0.3232689960988068, 1.0, 2.0, 0.3232689960988068, 1.0, 2.0, 0.5146547699254959, 6.9112, 6.9112, 121.94756008, 1105527.285102011, 1105527.285102011, 265103.4437392674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4900200.0000, 
sim time next is 4900800.0000, 
raw observation next is [30.73333333333333, 73.66666666666667, 1.0, 2.0, 0.7343337226192891, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 836954.0735025896, 836954.0735025892, 182756.3741777608], 
processed observation next is [1.0, 0.7391304347826086, 0.6938271604938271, 0.7366666666666667, 1.0, 1.0, 0.6837306221658204, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2989121691080677, 0.2989121691080676, 0.35145456572646305], 
reward next is 0.6485, 
noisyNet noise sample is [array([0.90904236], dtype=float32), 0.3324652]. 
=============================================
[2019-03-23 20:39:36,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.21698e-31 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:39:36,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1942
[2019-03-23 20:39:36,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 80.5, 1.0, 2.0, 0.8930843977613608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1054297.529979776, 1054297.529979776, 217768.0664475748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4955400.0000, 
sim time next is 4956000.0000, 
raw observation next is [24.83333333333333, 81.33333333333333, 1.0, 2.0, 0.9847846285574569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.242063584320197, 6.9112, 121.9247957124262, 1327562.712288008, 1158132.717594939, 238967.802774321], 
processed observation next is [1.0, 0.34782608695652173, 0.4753086419753085, 0.8133333333333332, 1.0, 1.0, 0.9818864625684011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03308635843201966, 0.0, 0.8094538506793395, 0.47412954010286, 0.4136188277124782, 0.45955346687369425], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.933393], dtype=float32), 0.19752242]. 
=============================================
[2019-03-23 20:39:36,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.578705]
 [72.578705]
 [72.578705]
 [72.578705]
 [72.578705]], R is [[71.8529129 ]
 [71.71559906]
 [71.60910034]
 [71.57180786]
 [71.54933929]].
[2019-03-23 20:39:37,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9598034e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:37,020] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4983
[2019-03-23 20:39:37,026] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1532993.026801967 W.
[2019-03-23 20:39:37,031] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.7176904350824583, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1532993.026801967, 1532993.026801967, 320464.2387668567], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4969200.0000, 
sim time next is 4969800.0000, 
raw observation next is [26.0, 86.5, 1.0, 2.0, 0.4404419733873796, 1.0, 1.0, 0.4404419733873796, 1.0, 2.0, 0.7011979658263613, 6.911199999999999, 6.9112, 121.94756008, 1506633.794294956, 1506633.794294956, 315250.8196609187], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.865, 1.0, 1.0, 0.3338594921278329, 1.0, 0.5, 0.3338594921278329, 1.0, 1.0, 0.6264974572829515, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5380834979624842, 0.5380834979624842, 0.6062515762709976], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34440568], dtype=float32), 0.13701956]. 
=============================================
[2019-03-23 20:39:39,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2668532e-18 1.0000000e+00 2.6523217e-26 9.8859200e-29 2.4471221e-30], sum to 1.0000
[2019-03-23 20:39:39,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5646
[2019-03-23 20:39:39,225] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.66666666666667, 1.0, 2.0, 0.6436288392997047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733524.0600815524, 733524.0600815524, 165744.5026566863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4996200.0000, 
sim time next is 4996800.0000, 
raw observation next is [24.8, 91.0, 1.0, 2.0, 0.6353447312838725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 726037.2080803763, 726037.2080803758, 164361.7041022851], 
processed observation next is [1.0, 0.8695652173913043, 0.4740740740740741, 0.91, 1.0, 1.0, 0.5658865848617529, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2592990028858487, 0.2592990028858485, 0.3160802001967021], 
reward next is 0.6839, 
noisyNet noise sample is [array([-1.6435705], dtype=float32), -0.5105607]. 
=============================================
[2019-03-23 20:39:45,924] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0344437e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:45,933] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5841
[2019-03-23 20:39:45,942] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 98.33333333333334, 1.0, 2.0, 0.6977447080855484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795230.249353185, 795230.249353185, 175716.8863267185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5115000.0000, 
sim time next is 5115600.0000, 
raw observation next is [24.8, 98.0, 1.0, 2.0, 0.6941141410089684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791090.3015532561, 791090.3015532556, 175031.8723416645], 
processed observation next is [0.0, 0.21739130434782608, 0.4740740740740741, 0.98, 1.0, 1.0, 0.6358501678678196, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2825322505547343, 0.28253225055473413, 0.33659975450320095], 
reward next is 0.6634, 
noisyNet noise sample is [array([0.2882169], dtype=float32), 0.82627785]. 
=============================================
[2019-03-23 20:39:46,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5069382e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:39:46,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0693
[2019-03-23 20:39:46,738] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 93.16666666666667, 1.0, 2.0, 0.784767601005829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 894469.4380812166, 894469.4380812166, 192820.997223883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5130600.0000, 
sim time next is 5131200.0000, 
raw observation next is [27.66666666666667, 92.33333333333334, 1.0, 2.0, 0.8161782652675524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930292.6957894792, 930292.6957894792, 199314.5011193809], 
processed observation next is [0.0, 0.391304347826087, 0.580246913580247, 0.9233333333333335, 1.0, 1.0, 0.781164601508991, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33224739135338544, 0.33224739135338544, 0.38329711753727097], 
reward next is 0.6167, 
noisyNet noise sample is [array([0.23073818], dtype=float32), 0.1378507]. 
=============================================
[2019-03-23 20:39:48,914] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 20:39:48,917] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:39:48,918] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:39:48,918] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:48,919] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:39:48,919] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:39:48,920] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:39:48,918] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:48,921] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:48,921] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:48,920] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:39:48,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 20:39:48,940] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 20:39:48,984] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 20:39:48,985] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 20:39:49,031] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 20:39:58,401] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.49223855]
[2019-03-23 20:39:58,402] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.8224165, 49.94907577666667, 1.0, 2.0, 0.3229705934126436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 408567.5858902519, 408567.5858902523, 118436.6538276807]
[2019-03-23 20:39:58,403] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:39:58,404] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.468152e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.19414242465176668
[2019-03-23 20:40:06,265] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.49223855]
[2019-03-23 20:40:06,267] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.733861505, 68.35514945166668, 1.0, 2.0, 0.2107956040977531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 271899.2292167598, 271899.2292167594, 86150.68951917079]
[2019-03-23 20:40:06,268] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:40:06,270] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.468152e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2641518560980748
[2019-03-23 20:40:08,401] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.49223855]
[2019-03-23 20:40:08,401] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.56666666666667, 16.66666666666667, 1.0, 2.0, 0.6742877158419096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834944.7001326082, 834944.7001326077, 173935.0199183174]
[2019-03-23 20:40:08,403] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:40:08,407] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.468152e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8341418860924855
[2019-03-23 20:40:32,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.49223855]
[2019-03-23 20:40:32,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 78.0, 1.0, 2.0, 0.5004817802780077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592282.9097158073, 592282.9097158073, 142793.8666157004]
[2019-03-23 20:40:32,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:40:32,585] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.468152e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5800693655346152
[2019-03-23 20:41:15,751] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.49223855]
[2019-03-23 20:41:15,752] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.19709629333333, 38.80139049166667, 1.0, 2.0, 0.4636133680189485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586253.7591460112, 586253.7591460112, 138141.7468253574]
[2019-03-23 20:41:15,754] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:41:15,756] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.468152e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6074272619547437
[2019-03-23 20:41:30,601] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:41:30,640] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:41:30,761] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:41:30,801] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:41:30,877] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:41:31,892] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 350000, evaluation results [350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:41:32,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.86136e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:41:32,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3190
[2019-03-23 20:41:32,378] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 74.83333333333334, 1.0, 2.0, 0.7533649400986693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 858656.9818200419, 858656.9818200424, 186497.6497993096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163000.0000, 
sim time next is 5163600.0000, 
raw observation next is [29.3, 75.66666666666667, 1.0, 2.0, 0.7473210342891746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851764.5378037539, 851764.5378037539, 185300.6135372075], 
processed observation next is [0.0, 0.782608695652174, 0.6407407407407407, 0.7566666666666667, 1.0, 1.0, 0.6991917074871127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3042016206441978, 0.3042016206441978, 0.35634733372539906], 
reward next is 0.6437, 
noisyNet noise sample is [array([-1.1407498], dtype=float32), 0.75286436]. 
=============================================
[2019-03-23 20:41:35,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6493645e-13 1.0000000e+00 3.7498729e-19 1.3996797e-21 2.7753980e-22], sum to 1.0000
[2019-03-23 20:41:35,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7840
[2019-03-23 20:41:35,846] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 69.0, 1.0, 2.0, 0.3069281411017624, 1.0, 2.0, 0.3069281411017624, 1.0, 1.0, 0.4886395965857077, 6.911200000000001, 6.9112, 121.94756008, 1049605.954146583, 1049605.954146583, 258715.9045932507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5245800.0000, 
sim time next is 5246400.0000, 
raw observation next is [29.53333333333334, 70.0, 1.0, 2.0, 0.6563150671011608, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747989.2191786662, 747989.2191786662, 168042.141303962], 
processed observation next is [1.0, 0.7391304347826086, 0.6493827160493829, 0.7, 1.0, 1.0, 0.5908512703585248, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2671390068495237, 0.2671390068495237, 0.32315796404608077], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8897069], dtype=float32), -0.97054094]. 
=============================================
[2019-03-23 20:41:38,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0704328e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:41:38,077] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1117
[2019-03-23 20:41:38,084] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.71666666666667, 90.66666666666667, 1.0, 2.0, 0.5309603477373349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 633686.5513254369, 633686.5513254364, 147858.622281754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5295000.0000, 
sim time next is 5295600.0000, 
raw observation next is [22.6, 91.0, 1.0, 2.0, 0.5637861299009295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673748.3150779454, 673748.3150779458, 153323.5518807879], 
processed observation next is [1.0, 0.30434782608695654, 0.39259259259259266, 0.91, 1.0, 1.0, 0.4806977736915827, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24062439824212334, 0.2406243982421235, 0.2948529843861306], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.32933205], dtype=float32), -1.2244755]. 
=============================================
[2019-03-23 20:41:41,685] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.772301e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:41:41,693] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1459
[2019-03-23 20:41:41,700] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 82.5, 1.0, 2.0, 0.6040886231618399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695371.5113546202, 695371.5113546202, 159121.1437398704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5358600.0000, 
sim time next is 5359200.0000, 
raw observation next is [25.63333333333333, 83.0, 1.0, 2.0, 0.6035446300374061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694652.2493718094, 694652.2493718094, 159022.449344085], 
processed observation next is [1.0, 0.0, 0.5049382716049381, 0.83, 1.0, 1.0, 0.5280293214731024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2480900890613605, 0.2480900890613605, 0.3058124025847789], 
reward next is 0.6942, 
noisyNet noise sample is [array([0.8862665], dtype=float32), -0.32455137]. 
=============================================
[2019-03-23 20:41:42,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0692835e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:41:42,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5011
[2019-03-23 20:41:42,208] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.6093309968138211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703303.1165683762, 703303.1165683762, 160122.1839640385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5378400.0000, 
sim time next is 5379000.0000, 
raw observation next is [24.43333333333333, 91.00000000000001, 1.0, 2.0, 0.8505633089901871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 980857.9594053247, 980857.9594053247, 207208.0501014718], 
processed observation next is [1.0, 0.2608695652173913, 0.4604938271604937, 0.9100000000000001, 1.0, 1.0, 0.8220991773692703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35030641407333024, 0.35030641407333024, 0.3984770194259073], 
reward next is 0.6015, 
noisyNet noise sample is [array([0.07050597], dtype=float32), 0.470605]. 
=============================================
[2019-03-23 20:41:42,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.7677]
 [62.7677]
 [62.7677]
 [62.7677]
 [62.7677]], R is [[62.74154282]
 [62.80620193]
 [62.85734177]
 [62.91509247]
 [62.98337173]].
[2019-03-23 20:41:48,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0929544e-08 1.0000000e+00 2.2969072e-12 1.6317158e-14 1.2426991e-14], sum to 1.0000
[2019-03-23 20:41:48,412] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-23 20:41:48,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2222210.637135643 W.
[2019-03-23 20:41:48,422] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.56666666666667, 71.0, 1.0, 2.0, 0.6720022604284829, 1.0, 2.0, 0.649365792190676, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2222210.637135643, 2222210.637135644, 421801.3393134643], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5498400.0000, 
sim time next is 5499000.0000, 
raw observation next is [30.2, 72.0, 1.0, 2.0, 0.9924350245905104, 1.0, 2.0, 0.9924350245905104, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2264211.214519762, 2264211.214519762, 429688.976542718], 
processed observation next is [1.0, 0.6521739130434783, 0.674074074074074, 0.72, 1.0, 1.0, 0.9909940768934647, 1.0, 1.0, 0.9909940768934647, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.8086468623284864, 0.8086468623284864, 0.8263249548898424], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40077454], dtype=float32), -1.3754133]. 
=============================================
[2019-03-23 20:41:48,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[14.833776]
 [14.833776]
 [14.833776]
 [14.833776]
 [14.833776]], R is [[14.68544102]
 [14.53858662]
 [14.61383629]
 [14.61360931]
 [14.5524435 ]].
[2019-03-23 20:41:50,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7022364e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:41:50,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2110
[2019-03-23 20:41:50,465] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 93.0, 1.0, 2.0, 0.6828738307968908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778273.0799424673, 778273.0799424673, 172926.9395340979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5536800.0000, 
sim time next is 5537400.0000, 
raw observation next is [25.48333333333333, 93.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.65872327393246, 6.9112, 123.3348791180078, 2068635.699271475, 1163407.297936741, 245797.556469041], 
processed observation next is [1.0, 0.08695652173913043, 0.4993827160493826, 0.93, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.1747523273932461, 0.0, 0.8188153381090104, 0.7387984640255267, 0.4155026064059789, 0.47268760859430964], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80803007], dtype=float32), -1.1234765]. 
=============================================
[2019-03-23 20:41:52,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0776306e-24 1.0000000e+00 6.7240967e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:41:52,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0640
[2019-03-23 20:41:52,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1573776.097261108 W.
[2019-03-23 20:41:52,440] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.8, 78.16666666666666, 1.0, 2.0, 0.7534200683841591, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1573776.097261108, 1573776.097261108, 327166.3995523934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5572200.0000, 
sim time next is 5572800.0000, 
raw observation next is [28.0, 78.0, 1.0, 2.0, 0.5185541834505566, 1.0, 1.0, 0.5185541834505566, 1.0, 2.0, 0.8255551481840194, 6.911199999999999, 6.9112, 121.94756008, 1774112.434783409, 1774112.43478341, 352788.9906767539], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.78, 1.0, 1.0, 0.4268502183935197, 1.0, 0.5, 0.4268502183935197, 1.0, 1.0, 0.7819439352300241, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6336115838512174, 0.6336115838512179, 0.6784403666860652], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6792019], dtype=float32), 0.7547658]. 
=============================================
[2019-03-23 20:41:54,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2332733e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:41:54,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8413
[2019-03-23 20:41:54,505] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 92.16666666666667, 1.0, 2.0, 0.676753817508171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771294.5755963159, 771294.5755963159, 171789.6314080244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5598600.0000, 
sim time next is 5599200.0000, 
raw observation next is [25.6, 92.33333333333334, 1.0, 2.0, 0.6818652924545818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777123.0634912108, 777123.0634912113, 172739.1697887163], 
processed observation next is [1.0, 0.8260869565217391, 0.5037037037037038, 0.9233333333333335, 1.0, 1.0, 0.6212682053030736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.277543951246861, 0.27754395124686115, 0.3321907111321467], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.9467773], dtype=float32), -1.0890902]. 
=============================================
[2019-03-23 20:41:56,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.974445e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:41:56,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3560
[2019-03-23 20:41:56,880] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 92.5, 1.0, 2.0, 0.6472536830020887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 737657.1710666067, 737657.1710666062, 166397.7861038654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646600.0000, 
sim time next is 5647200.0000, 
raw observation next is [25.2, 91.66666666666667, 1.0, 2.0, 0.6493645239895234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740063.9996104523, 740063.9996104523, 166778.6143347988], 
processed observation next is [0.0, 0.34782608695652173, 0.4888888888888889, 0.9166666666666667, 1.0, 1.0, 0.5825768142732421, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26430857128944724, 0.26430857128944724, 0.32072810448999767], 
reward next is 0.6793, 
noisyNet noise sample is [array([-1.6050979], dtype=float32), 0.79266465]. 
=============================================
[2019-03-23 20:42:07,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0470139e-19 1.0000000e+00 3.8534067e-29 5.0517667e-33 2.9400351e-32], sum to 1.0000
[2019-03-23 20:42:07,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1621
[2019-03-23 20:42:07,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1410221.009781969 W.
[2019-03-23 20:42:07,400] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.86666666666667, 45.33333333333333, 1.0, 2.0, 0.3918728714324176, 1.0, 1.0, 0.3918728714324176, 1.0, 2.0, 0.6324897549018574, 6.9112, 6.9112, 121.94756008, 1410221.009781969, 1410221.009781969, 293096.2729119684], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5842200.0000, 
sim time next is 5842800.0000, 
raw observation next is [27.9, 45.0, 1.0, 2.0, 0.3658160435411869, 1.0, 2.0, 0.3658160435411869, 1.0, 2.0, 0.5898810025419625, 6.911199999999999, 6.9112, 121.94756008, 1314091.526302466, 1314091.526302467, 282007.5242178882], 
processed observation next is [1.0, 0.6521739130434783, 0.5888888888888888, 0.45, 1.0, 1.0, 0.24501909945379394, 1.0, 1.0, 0.24501909945379394, 1.0, 1.0, 0.4873512531774531, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4693184022508807, 0.4693184022508811, 0.5423221619574773], 
reward next is 0.4577, 
noisyNet noise sample is [array([1.7953452], dtype=float32), -0.019114593]. 
=============================================
[2019-03-23 20:42:14,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1165138e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:42:14,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1804
[2019-03-23 20:42:14,346] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 86.0, 1.0, 2.0, 0.3921456714410512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485742.5287856225, 485742.5287856225, 127514.9459905666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5979600.0000, 
sim time next is 5980200.0000, 
raw observation next is [21.11666666666667, 85.16666666666667, 1.0, 2.0, 0.4675507086204132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579070.6168296319, 579070.6168296319, 138535.9725546141], 
processed observation next is [1.0, 0.21739130434782608, 0.33765432098765447, 0.8516666666666667, 1.0, 1.0, 0.36613179597668244, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20681093458201139, 0.20681093458201139, 0.26641533183579635], 
reward next is 0.7336, 
noisyNet noise sample is [array([0.63470125], dtype=float32), 1.5122133]. 
=============================================
[2019-03-23 20:42:15,874] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3538134e-23 1.0000000e+00 3.7269252e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:42:15,882] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3803
[2019-03-23 20:42:15,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1368967.281145479 W.
[2019-03-23 20:42:15,895] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.58333333333334, 69.33333333333334, 1.0, 2.0, 0.4002331475065852, 1.0, 2.0, 0.4002331475065852, 1.0, 2.0, 0.6371842055140994, 6.911199999999999, 6.9112, 121.94756008, 1368967.281145479, 1368967.281145479, 297184.2805808812], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6001800.0000, 
sim time next is 6002400.0000, 
raw observation next is [26.86666666666667, 68.66666666666667, 1.0, 2.0, 0.6566360881413269, 1.0, 2.0, 0.6566360881413269, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1502232.714430353, 1502232.714430354, 288317.0382848494], 
processed observation next is [1.0, 0.4782608695652174, 0.5506172839506175, 0.6866666666666668, 1.0, 1.0, 0.5912334382634844, 1.0, 1.0, 0.5912334382634844, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.536511683725126, 0.5365116837251265, 0.5544558428554796], 
reward next is 0.4455, 
noisyNet noise sample is [array([-0.0103204], dtype=float32), 2.5127544]. 
=============================================
[2019-03-23 20:42:17,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0651600e-25 1.0000000e+00 3.0417882e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:42:17,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1667
[2019-03-23 20:42:17,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1919258.998639755 W.
[2019-03-23 20:42:17,546] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.56666666666667, 51.33333333333333, 1.0, 2.0, 0.560933455244637, 1.0, 1.0, 0.560933455244637, 1.0, 2.0, 0.8930243290767211, 6.9112, 6.9112, 121.94756008, 1919258.998639755, 1919258.998639755, 374501.3646356037], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6099000.0000, 
sim time next is 6099600.0000, 
raw observation next is [30.53333333333333, 51.66666666666667, 1.0, 2.0, 0.5780116260185054, 1.0, 2.0, 0.5780116260185054, 1.0, 2.0, 0.9202133331459116, 6.911200000000001, 6.9112, 121.94756008, 1977757.417074438, 1977757.417074438, 383525.415163551], 
processed observation next is [1.0, 0.6086956521739131, 0.6864197530864197, 0.5166666666666667, 1.0, 1.0, 0.49763288811726836, 1.0, 1.0, 0.49763288811726836, 1.0, 1.0, 0.9002666664323894, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7063419346694422, 0.7063419346694422, 0.7375488753145212], 
reward next is 0.2625, 
noisyNet noise sample is [array([-0.50612175], dtype=float32), 2.1805696]. 
=============================================
[2019-03-23 20:42:19,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.34043e-34 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:42:19,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-23 20:42:19,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1693020.017298509 W.
[2019-03-23 20:42:19,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.6, 51.0, 1.0, 2.0, 0.7423111291127124, 1.0, 1.0, 0.7423111291127124, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1693020.017298509, 1693020.017298509, 320491.4680152591], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6080400.0000, 
sim time next is 6081000.0000, 
raw observation next is [30.38333333333334, 52.16666666666666, 1.0, 2.0, 0.741350318151376, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9942383004886249, 6.911199999999999, 6.9112, 121.9260426156618, 1563186.992367808, 1563186.992367809, 324297.2648954689], 
processed observation next is [1.0, 0.391304347826087, 0.6808641975308645, 0.5216666666666666, 1.0, 1.0, 0.6920837120849714, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.992797875610781, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5582810687027886, 0.5582810687027889, 0.6236485863374401], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9820393], dtype=float32), 1.5952188]. 
=============================================
[2019-03-23 20:42:19,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.629]
 [70.629]
 [70.629]
 [70.629]
 [70.629]], R is [[69.9227066 ]
 [69.22348022]
 [68.86675262]
 [68.54273224]
 [68.24326324]].
[2019-03-23 20:42:21,634] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 20:42:21,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:42:21,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:42:21,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:42:21,638] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:42:21,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:42:21,640] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:42:21,641] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:42:21,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:42:21,641] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:42:21,642] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:42:21,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 20:42:21,685] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 20:42:21,724] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 20:42:21,725] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 20:42:21,769] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 20:43:08,794] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5122543]
[2019-03-23 20:43:08,796] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.91141527666667, 87.03327098, 1.0, 2.0, 0.4890919966235229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588865.9358164396, 588865.9358164396, 141387.9620193687]
[2019-03-23 20:43:08,797] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:43:08,801] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1835272e-14 1.0000000e+00 7.9082435e-22 1.6149201e-24 4.6932380e-24], sampled 0.1754574490052404
[2019-03-23 20:43:21,421] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5122543]
[2019-03-23 20:43:21,422] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.93333333333333, 92.0, 1.0, 2.0, 0.5017246663322148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605062.3089398546, 605062.3089398546, 143400.1506997304]
[2019-03-23 20:43:21,424] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:43:21,426] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1835272e-14 1.0000000e+00 7.9082435e-22 1.6149201e-24 4.6932380e-24], sampled 0.38564472546364736
[2019-03-23 20:43:22,393] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5122543]
[2019-03-23 20:43:22,394] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.69458011333333, 68.63303535666667, 1.0, 2.0, 0.6316681235010498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719886.3981858672, 719886.3981858669, 163611.0710490753]
[2019-03-23 20:43:22,395] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:43:22,398] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1835272e-14 1.0000000e+00 7.9082435e-22 1.6149201e-24 4.6932380e-24], sampled 0.8307013808466439
[2019-03-23 20:43:44,771] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5122543]
[2019-03-23 20:43:44,772] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.1, 92.5, 1.0, 2.0, 0.5194636121944078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613242.7060368264, 613242.7060368264, 145742.1541205338]
[2019-03-23 20:43:44,772] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:43:44,776] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1835272e-14 1.0000000e+00 7.9082435e-22 1.6149201e-24 4.6932380e-24], sampled 0.7765923089372678
[2019-03-23 20:43:50,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.5122543]
[2019-03-23 20:43:50,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.95, 94.16666666666667, 1.0, 2.0, 0.5293338071706424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623935.6849590745, 623935.6849590745, 147291.2303414861]
[2019-03-23 20:43:50,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:43:50,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1835272e-14 1.0000000e+00 7.9082435e-22 1.6149201e-24 4.6932380e-24], sampled 0.9484455307563019
[2019-03-23 20:44:02,225] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:44:02,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:44:02,482] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:44:02,530] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:44:02,572] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:44:03,588] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 375000, evaluation results [375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:44:09,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7746797e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:09,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 20:44:09,449] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 71.33333333333334, 1.0, 2.0, 0.5148095440250734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613100.236040233, 613100.236040233, 145206.8156738478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6216000.0000, 
sim time next is 6216600.0000, 
raw observation next is [25.45, 71.66666666666666, 1.0, 2.0, 0.5097521901699522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608079.854497078, 608079.854497078, 144438.9863962015], 
processed observation next is [1.0, 0.9565217391304348, 0.4981481481481481, 0.7166666666666666, 1.0, 1.0, 0.4163716549642288, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21717137660609928, 0.21717137660609928, 0.27776728153115676], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.11633485], dtype=float32), 0.34163132]. 
=============================================
[2019-03-23 20:44:15,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.175989e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:44:15,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1699
[2019-03-23 20:44:15,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1342351.713075657 W.
[2019-03-23 20:44:15,204] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.4, 89.0, 1.0, 2.0, 1.019247768060239, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.263262033285346, 6.9112, 121.9245333181957, 1342351.713075657, 1162066.716824699, 245397.1786831787], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6404400.0000, 
sim time next is 6405000.0000, 
raw observation next is [25.33333333333334, 89.33333333333334, 1.0, 2.0, 0.593345841808459, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9446259040840609, 6.9112, 6.9112, 121.9258306100729, 1352982.563007858, 1352982.563007858, 291280.5184271962], 
processed observation next is [1.0, 0.13043478260869565, 0.49382716049382736, 0.8933333333333334, 1.0, 1.0, 0.5158879069148321, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.930782380105076, 0.0, 0.0, 0.8094607213234959, 0.4832080582170922, 0.4832080582170922, 0.5601548431292235], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7651011], dtype=float32), -1.0731347]. 
=============================================
[2019-03-23 20:44:15,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.87837]
 [66.87837]
 [66.87837]
 [66.87837]
 [66.87837]], R is [[66.2095871 ]
 [65.54749298]
 [65.34842682]
 [65.14408112]
 [64.49263763]].
[2019-03-23 20:44:16,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.586925e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:44:16,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8466
[2019-03-23 20:44:16,148] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 58.16666666666666, 1.0, 2.0, 0.6836162076554382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779119.5987870564, 779119.5987870564, 173065.386886677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6357000.0000, 
sim time next is 6357600.0000, 
raw observation next is [31.4, 58.0, 1.0, 2.0, 0.6843818843457101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 779992.6869858245, 779992.686985824, 173208.3272793795], 
processed observation next is [0.0, 0.6086956521739131, 0.7185185185185184, 0.58, 1.0, 1.0, 0.6242641480306073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2785688167806516, 0.27856881678065143, 0.3330929370757298], 
reward next is 0.6669, 
noisyNet noise sample is [array([-1.5386708], dtype=float32), -0.56692433]. 
=============================================
[2019-03-23 20:44:19,425] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1939526e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:19,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-23 20:44:19,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2040993.367666168 W.
[2019-03-23 20:44:19,453] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.13333333333333, 79.16666666666667, 1.0, 2.0, 0.5964716254778484, 1.0, 2.0, 0.5964716254778484, 1.0, 1.0, 0.949602253485396, 6.911200000000001, 6.9112, 121.94756008, 2040993.367666168, 2040993.367666168, 393456.5051220413], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6430200.0000, 
sim time next is 6430800.0000, 
raw observation next is [28.36666666666667, 78.33333333333334, 1.0, 2.0, 0.5960501269813385, 1.0, 2.0, 0.5960501269813385, 1.0, 2.0, 0.9489312141517047, 6.911200000000001, 6.9112, 121.94756008, 2039549.446707266, 2039549.446707266, 393227.6995562699], 
processed observation next is [1.0, 0.43478260869565216, 0.606172839506173, 0.7833333333333334, 1.0, 1.0, 0.519107294025403, 1.0, 1.0, 0.519107294025403, 1.0, 1.0, 0.9361640176896308, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7284105166811664, 0.7284105166811664, 0.7562071145312883], 
reward next is 0.2438, 
noisyNet noise sample is [array([-0.76012754], dtype=float32), -1.2310221]. 
=============================================
[2019-03-23 20:44:27,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5259004e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:27,135] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7327
[2019-03-23 20:44:27,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 70.33333333333333, 1.0, 2.0, 0.5281790747364933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626247.2946647964, 626247.2946647964, 147250.4459110137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [25.93333333333334, 68.66666666666667, 1.0, 2.0, 0.5130007226353195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611491.1949608658, 611491.1949608658, 144938.4371908501], 
processed observation next is [1.0, 0.0, 0.5160493827160496, 0.6866666666666668, 1.0, 1.0, 0.4202389555182375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21838971248602349, 0.21838971248602349, 0.27872776382855785], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.77231604], dtype=float32), 1.0755514]. 
=============================================
[2019-03-23 20:44:28,010] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8340072e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:28,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-23 20:44:28,022] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 57.0, 1.0, 2.0, 0.4147870532348812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511464.3713755981, 511464.3713755981, 130663.2806097992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6571800.0000, 
sim time next is 6572400.0000, 
raw observation next is [25.66666666666667, 55.33333333333333, 1.0, 2.0, 0.4016593484904655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497441.1045848861, 497441.1045848861, 128847.7229830337], 
processed observation next is [1.0, 0.043478260869565216, 0.506172839506173, 0.5533333333333332, 1.0, 1.0, 0.2876897005838875, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17765753735174503, 0.17765753735174503, 0.2477840826596802], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.0942074], dtype=float32), -1.1131625]. 
=============================================
[2019-03-23 20:44:32,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.300344e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:44:32,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-23 20:44:32,876] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 48.66666666666666, 1.0, 2.0, 0.2697357029805138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347470.480113324, 347470.480113324, 111908.8644554996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6677400.0000, 
sim time next is 6678000.0000, 
raw observation next is [23.0, 49.0, 1.0, 2.0, 0.3054024885728883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393167.5760437495, 393167.5760437495, 116238.4161354694], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.49, 1.0, 1.0, 0.1730982006820099, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14041699144419625, 0.14041699144419625, 0.22353541564513346], 
reward next is 0.7765, 
noisyNet noise sample is [array([-1.4625698], dtype=float32), -0.42299956]. 
=============================================
[2019-03-23 20:44:32,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.40642]
 [70.40642]
 [70.40642]
 [70.40642]
 [70.40642]], R is [[70.4788208 ]
 [70.55882263]
 [70.63807678]
 [70.71624756]
 [70.79325867]].
[2019-03-23 20:44:33,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.624847e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:44:33,569] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3673
[2019-03-23 20:44:33,583] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.78333333333333, 37.83333333333334, 1.0, 2.0, 0.6545198065386889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832510.5006622557, 832510.5006622557, 170579.3979445776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6691800.0000, 
sim time next is 6692400.0000, 
raw observation next is [27.0, 37.0, 1.0, 2.0, 0.7120968927433495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905593.5176126278, 905593.5176126278, 181628.7581254059], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.37, 1.0, 1.0, 0.6572582056468447, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3234262562902242, 0.3234262562902242, 0.34928607331808825], 
reward next is 0.6507, 
noisyNet noise sample is [array([0.0408683], dtype=float32), -0.5083514]. 
=============================================
[2019-03-23 20:44:33,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5881438e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:33,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0517
[2019-03-23 20:44:33,776] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 35.0, 1.0, 2.0, 0.8806273728823076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.028945682652712, 6.9112, 121.925445759016, 1178885.354332206, 1118589.335988953, 217360.7352372656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6694800.0000, 
sim time next is 6695400.0000, 
raw observation next is [27.75, 34.5, 1.0, 2.0, 0.8880464338367071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.078791103595674, 6.9112, 121.9251767705417, 1213659.395960927, 1127838.381250422, 219048.762727866], 
processed observation next is [1.0, 0.4782608695652174, 0.5833333333333334, 0.345, 1.0, 1.0, 0.8667219450436989, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.016759110359567408, 0.0, 0.809456380508954, 0.4334497842717596, 0.4027994218751507, 0.4212476206305116], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36462143], dtype=float32), -1.5872416]. 
=============================================
[2019-03-23 20:44:33,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7329293e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:33,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4504
[2019-03-23 20:44:33,799] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 40.33333333333334, 1.0, 2.0, 0.6488166198656851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825592.5691936245, 825592.5691936245, 169519.1984412937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6690000.0000, 
sim time next is 6690600.0000, 
raw observation next is [26.35, 39.5, 1.0, 2.0, 0.6477941355891093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824175.9603963154, 824175.9603963154, 169328.6032960034], 
processed observation next is [1.0, 0.43478260869565216, 0.5314814814814816, 0.395, 1.0, 1.0, 0.5807073042727491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29434855728439835, 0.29434855728439835, 0.32563192941539115], 
reward next is 0.6744, 
noisyNet noise sample is [array([0.5628301], dtype=float32), -1.4978542]. 
=============================================
[2019-03-23 20:44:40,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9934982e-24 1.0000000e+00 2.7816409e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:40,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3772
[2019-03-23 20:44:40,439] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 72.5, 1.0, 2.0, 0.472693027146266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 570990.2293020121, 570990.2293020117, 138920.7494028698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6814200.0000, 
sim time next is 6814800.0000, 
raw observation next is [24.5, 73.0, 1.0, 2.0, 0.4747483954741283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573521.5870802063, 573521.5870802058, 139236.9184631214], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.73, 1.0, 1.0, 0.37470047080253366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2048291382429308, 0.20482913824293064, 0.2677633047367719], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.8329698], dtype=float32), 0.04495928]. 
=============================================
[2019-03-23 20:44:48,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7730826e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:44:48,263] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7317
[2019-03-23 20:44:48,267] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 56.5, 1.0, 2.0, 0.5129422550479614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609092.3701589943, 609092.3701589943, 144841.5485721102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6953400.0000, 
sim time next is 6954000.0000, 
raw observation next is [28.66666666666666, 56.0, 1.0, 2.0, 0.5166993386318283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612900.6754924705, 612900.6754924705, 145415.6310619299], 
processed observation next is [0.0, 0.4782608695652174, 0.6172839506172837, 0.56, 1.0, 1.0, 0.4246420697997955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21889309839016804, 0.21889309839016804, 0.27964544434986516], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.28188178], dtype=float32), 0.5743966]. 
=============================================
[2019-03-23 20:44:48,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.853607]
 [63.853607]
 [63.853607]
 [63.853607]
 [63.853607]], R is [[63.93543243]
 [64.01753998]
 [64.09980011]
 [64.18198395]
 [64.26399231]].
[2019-03-23 20:44:53,323] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 20:44:53,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:44:53,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:53,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:44:53,328] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:44:53,329] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:53,332] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:44:53,332] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:53,333] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:53,330] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:44:53,335] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:44:53,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 20:44:53,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 20:44:53,370] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 20:44:53,417] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 20:44:53,444] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 20:44:55,816] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.55102056]
[2019-03-23 20:44:55,819] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.24285635, 36.98665395, 1.0, 2.0, 0.4715046976286091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582197.284936566, 582197.284936566, 139100.2396457115]
[2019-03-23 20:44:55,821] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:44:55,825] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2814427e-21 1.0000000e+00 1.2637163e-33 1.0881765e-37 5.7017682e-37], sampled 0.7933932336588546
[2019-03-23 20:45:23,339] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.55102056]
[2019-03-23 20:45:23,340] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.41666666666666, 48.5, 1.0, 2.0, 0.5596366888288822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651761.4318267031, 651761.4318267031, 151934.4379746965]
[2019-03-23 20:45:23,340] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:45:23,343] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2814427e-21 1.0000000e+00 1.2637163e-33 1.0881765e-37 5.7017682e-37], sampled 0.4558485312761976
[2019-03-23 20:45:41,181] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.55102056]
[2019-03-23 20:45:41,182] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.13183091000001, 70.35403847666667, 1.0, 2.0, 0.6546205985829885, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1461008.179483367, 1461008.179483368, 309175.5189564255]
[2019-03-23 20:45:41,183] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:45:41,187] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2814427e-21 1.0000000e+00 1.2637163e-33 1.0881765e-37 5.7017682e-37], sampled 0.6830001461116159
[2019-03-23 20:45:41,188] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1461008.179483367 W.
[2019-03-23 20:46:06,965] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.55102056]
[2019-03-23 20:46:06,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.69923415, 99.99155872666667, 1.0, 2.0, 0.7961690751479295, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 907472.4061832029, 907472.4061832029, 195159.4253427661]
[2019-03-23 20:46:06,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:46:06,970] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2814427e-21 1.0000000e+00 1.2637163e-33 1.0881765e-37 5.7017682e-37], sampled 0.7705721330544003
[2019-03-23 20:46:28,534] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.55102056]
[2019-03-23 20:46:28,535] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.46666666666667, 29.66666666666667, 1.0, 2.0, 0.4040379893715061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508461.1578935462, 508461.1578935462, 129333.6780033234]
[2019-03-23 20:46:28,536] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:46:28,538] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2814427e-21 1.0000000e+00 1.2637163e-33 1.0881765e-37 5.7017682e-37], sampled 0.6816967421983183
[2019-03-23 20:46:34,511] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:46:35,087] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:46:35,110] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:46:35,235] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:46:35,288] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:46:36,301] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 400000, evaluation results [400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:46:37,406] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0153517e-24 1.0000000e+00 1.4126400e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:46:37,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3904
[2019-03-23 20:46:37,420] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 81.83333333333334, 1.0, 2.0, 0.4849588231539975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583120.1167974209, 583120.1167974209, 140719.1871152882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7077000.0000, 
sim time next is 7077600.0000, 
raw observation next is [23.5, 82.0, 1.0, 2.0, 0.4864112974547585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584636.4465450408, 584636.4465450408, 140936.3698471362], 
processed observation next is [1.0, 0.9565217391304348, 0.42592592592592593, 0.82, 1.0, 1.0, 0.38858487792233154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20879873090894316, 0.20879873090894316, 0.27103148047526193], 
reward next is 0.7290, 
noisyNet noise sample is [array([-0.81499475], dtype=float32), -0.64043725]. 
=============================================
[2019-03-23 20:46:39,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7981e-34 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-23 20:46:39,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-23 20:46:39,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 76.5, 1.0, 2.0, 0.6957780401292223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860896.7339795509, 860896.7339795509, 178034.440387295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7122600.0000, 
sim time next is 7123200.0000, 
raw observation next is [22.4, 76.0, 1.0, 2.0, 0.7472884164114342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924230.9975375833, 924230.9975375833, 188221.9712616723], 
processed observation next is [1.0, 0.43478260869565216, 0.38518518518518513, 0.76, 1.0, 1.0, 0.6991528766802788, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3300824991205655, 0.3300824991205655, 0.3619653293493698], 
reward next is 0.6380, 
noisyNet noise sample is [array([-1.7615215], dtype=float32), -0.9267508]. 
=============================================
[2019-03-23 20:46:46,985] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.614979e-35 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:46:46,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0909
[2019-03-23 20:46:47,004] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.0, 1.0, 2.0, 0.4021203149889288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 497997.3881235226, 497997.3881235221, 128912.7409151211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7243200.0000, 
sim time next is 7243800.0000, 
raw observation next is [22.41666666666667, 75.33333333333333, 1.0, 2.0, 0.3988255705950949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 494164.5122600454, 494164.5122600454, 128453.9273202675], 
processed observation next is [1.0, 0.8695652173913043, 0.38580246913580263, 0.7533333333333333, 1.0, 1.0, 0.28431615547035105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17648732580715906, 0.17648732580715906, 0.2470267833082067], 
reward next is 0.7530, 
noisyNet noise sample is [array([-0.33900526], dtype=float32), -0.27308038]. 
=============================================
[2019-03-23 20:46:50,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.546792e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:46:50,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9761
[2019-03-23 20:46:50,125] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 73.66666666666667, 1.0, 2.0, 0.8591769826395732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1043815.083411236, 1043815.083411236, 211411.5303169634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [24.2, 72.83333333333333, 1.0, 2.0, 0.868022465709464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053397.361253308, 1053397.361253308, 213336.4285134923], 
processed observation next is [1.0, 0.4782608695652174, 0.45185185185185184, 0.7283333333333333, 1.0, 1.0, 0.8428838877493618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3762133433047528, 0.3762133433047528, 0.4102623625259468], 
reward next is 0.5897, 
noisyNet noise sample is [array([0.7576016], dtype=float32), 0.290869]. 
=============================================
[2019-03-23 20:46:55,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3047196e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:46:55,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4511
[2019-03-23 20:46:55,728] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.11666666666667, 90.83333333333334, 1.0, 2.0, 0.3854415079280883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479372.6391445666, 479372.6391445666, 126625.6953118571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7416600.0000, 
sim time next is 7417200.0000, 
raw observation next is [20.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3837029525168645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477238.0584808394, 477238.058480839, 126385.9320312396], 
processed observation next is [1.0, 0.8695652173913043, 0.30123456790123443, 0.9066666666666667, 1.0, 1.0, 0.26631303871055295, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17044216374315693, 0.1704421637431568, 0.24304986929084538], 
reward next is 0.7570, 
noisyNet noise sample is [array([-1.0728642], dtype=float32), -0.24316613]. 
=============================================
[2019-03-23 20:46:56,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3349222e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:46:56,068] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3146
[2019-03-23 20:46:56,073] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 91.5, 1.0, 2.0, 0.3813333368804351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474205.3848525184, 474205.3848525184, 126057.4668245171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7432200.0000, 
sim time next is 7432800.0000, 
raw observation next is [20.03333333333333, 91.66666666666666, 1.0, 2.0, 0.3806712567146405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473363.0157594518, 473363.0157594514, 125965.9703595854], 
processed observation next is [0.0, 0.0, 0.2975308641975308, 0.9166666666666665, 1.0, 1.0, 0.2627038770412387, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16905821991408992, 0.16905821991408979, 0.24224225069151037], 
reward next is 0.7578, 
noisyNet noise sample is [array([-1.3512211], dtype=float32), 0.43815362]. 
=============================================
[2019-03-23 20:46:56,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.0019604e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:46:56,452] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6421
[2019-03-23 20:46:56,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 90.33333333333334, 1.0, 2.0, 0.3835741189834583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477123.3500871169, 477123.3500871169, 126369.0806282361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7418400.0000, 
sim time next is 7419000.0000, 
raw observation next is [20.18333333333333, 90.16666666666666, 1.0, 2.0, 0.3835441661470839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477107.5915609535, 477107.5915609531, 126365.3866363147], 
processed observation next is [1.0, 0.8695652173913043, 0.3030864197530863, 0.9016666666666666, 1.0, 1.0, 0.26612400731795705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17039556841462625, 0.1703955684146261, 0.2430103589159898], 
reward next is 0.7570, 
noisyNet noise sample is [array([-0.84055084], dtype=float32), -0.07266726]. 
=============================================
[2019-03-23 20:46:56,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.94044]
 [73.94044]
 [73.94044]
 [73.94044]
 [73.94044]], R is [[73.95802307]
 [73.97542572]
 [73.99275208]
 [74.00977325]
 [74.02616882]].
[2019-03-23 20:46:58,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.464633e-34 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:46:58,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6641
[2019-03-23 20:46:58,283] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 95.83333333333333, 1.0, 2.0, 0.4390908062737902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534143.9402890576, 534143.9402890576, 134000.7297211656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7542600.0000, 
sim time next is 7543200.0000, 
raw observation next is [21.0, 95.66666666666666, 1.0, 2.0, 0.4392070269614659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534451.9082490135, 534451.9082490135, 134022.8302729552], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 0.9566666666666666, 1.0, 1.0, 0.33238931781126896, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1908756815175048, 0.1908756815175048, 0.2577362120633754], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.9003826], dtype=float32), -0.5770984]. 
=============================================
[2019-03-23 20:47:02,546] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3311707e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:02,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7586
[2019-03-23 20:47:02,560] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 92.0, 1.0, 2.0, 0.3624408378109262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452405.9401228782, 452405.9401228782, 123522.0075436594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [19.8, 92.0, 1.0, 2.0, 0.3637969287197159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453704.0441149747, 453704.0441149747, 123696.9229762139], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.92, 1.0, 1.0, 0.24261539133299515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16203715861249096, 0.16203715861249096, 0.23787869803118059], 
reward next is 0.7621, 
noisyNet noise sample is [array([-0.50636494], dtype=float32), 1.2157693]. 
=============================================
[2019-03-23 20:47:02,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.04224]
 [66.04224]
 [66.04224]
 [66.04224]
 [66.04224]], R is [[66.14393616]
 [66.24495697]
 [66.34380341]
 [66.44233704]
 [66.53826904]].
[2019-03-23 20:47:03,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2777934e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:03,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7104
[2019-03-23 20:47:03,303] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 64.0, 1.0, 2.0, 0.5563684855350272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649402.1302626427, 649402.1302626427, 151455.2884353252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7572600.0000, 
sim time next is 7573200.0000, 
raw observation next is [28.0, 63.33333333333333, 1.0, 2.0, 0.5520400656207464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645809.8496416914, 645809.8496416914, 150802.1874930103], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.6333333333333333, 1.0, 1.0, 0.4667143638342218, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23064637487203266, 0.23064637487203266, 0.2900042067173275], 
reward next is 0.7100, 
noisyNet noise sample is [array([1.499217], dtype=float32), 0.16040038]. 
=============================================
[2019-03-23 20:47:12,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.092191e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:47:12,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7557
[2019-03-23 20:47:12,542] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 50.0, 1.0, 2.0, 0.838236097925783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426146609, 1013752.774100478, 1013752.774100478, 206647.8787868513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7737000.0000, 
sim time next is 7737600.0000, 
raw observation next is [28.8, 49.00000000000001, 1.0, 2.0, 0.9796578296550028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.389041717148878, 6.9112, 121.9243302930415, 1430098.446246826, 1185404.21457912, 239191.8872992887], 
processed observation next is [1.0, 0.5652173913043478, 0.6222222222222222, 0.49000000000000005, 1.0, 1.0, 0.97578313054167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04778417171488778, 0.0, 0.8094507607786272, 0.5107494450881521, 0.42335864806397144, 0.45998439865247825], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0604444], dtype=float32), 0.20154476]. 
=============================================
[2019-03-23 20:47:13,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0637762e-22 1.0000000e+00 5.4912488e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:13,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3391
[2019-03-23 20:47:13,116] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.71666666666667, 52.83333333333334, 1.0, 2.0, 0.3233993931187326, 1.0, 2.0, 0.3233993931187326, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 758431.7708645114, 758431.7708645118, 187158.5995367487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7751400.0000, 
sim time next is 7752000.0000, 
raw observation next is [28.43333333333334, 53.66666666666667, 1.0, 2.0, 0.4660478842328974, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556590.992763874, 556590.992763874, 137687.6839601761], 
processed observation next is [1.0, 0.7391304347826086, 0.6086419753086423, 0.5366666666666667, 1.0, 1.0, 0.3643427193248779, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19878249741566928, 0.19878249741566928, 0.2647840076157233], 
reward next is 0.7352, 
noisyNet noise sample is [array([-0.59524924], dtype=float32), -1.1321406]. 
=============================================
[2019-03-23 20:47:13,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[46.652897]
 [46.652897]
 [46.652897]
 [46.652897]
 [46.652897]], R is [[46.92158508]
 [47.09244919]
 [47.01961899]
 [46.54942322]
 [46.50719833]].
[2019-03-23 20:47:16,034] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.440333e-37 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:47:16,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1626
[2019-03-23 20:47:16,047] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 63.16666666666667, 1.0, 2.0, 0.3347095296316759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426073.1871111949, 426073.1871111949, 119967.6076761675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7794600.0000, 
sim time next is 7795200.0000, 
raw observation next is [22.1, 62.33333333333334, 1.0, 2.0, 0.3206714923171368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407942.9510283774, 407942.9510283774, 118162.4584656018], 
processed observation next is [1.0, 0.21739130434782608, 0.3740740740740741, 0.6233333333333334, 1.0, 1.0, 0.19127558609182954, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14569391108156335, 0.14569391108156335, 0.22723549704923424], 
reward next is 0.7728, 
noisyNet noise sample is [array([1.315083], dtype=float32), -0.9197436]. 
=============================================
[2019-03-23 20:47:17,036] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5399297e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:17,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0920
[2019-03-23 20:47:17,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1519813.890261818 W.
[2019-03-23 20:47:17,059] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.6, 37.0, 1.0, 2.0, 0.6665278245361135, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9588251921422791, 6.9112, 6.9112, 121.9260426156618, 1519813.890261818, 1519813.890261818, 301295.8405908306], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7826400.0000, 
sim time next is 7827000.0000, 
raw observation next is [30.66666666666667, 36.83333333333334, 1.0, 2.0, 0.378228447442456, 1.0, 1.0, 0.378228447442456, 1.0, 2.0, 0.6079634946287963, 6.9112, 6.9112, 121.94756008, 1349863.956056261, 1349863.956056261, 287435.1050122002], 
processed observation next is [1.0, 0.6086956521739131, 0.6913580246913582, 0.3683333333333334, 1.0, 1.0, 0.25979577076482857, 1.0, 0.5, 0.25979577076482857, 1.0, 1.0, 0.5099543682859953, 0.0, 0.0, 0.8096049824067558, 0.4820942700200932, 0.4820942700200932, 0.5527598173311542], 
reward next is 0.4472, 
noisyNet noise sample is [array([1.5340389], dtype=float32), -2.20532]. 
=============================================
[2019-03-23 20:47:17,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[61.27331]
 [61.27331]
 [61.27331]
 [61.27331]
 [61.27331]], R is [[61.1078186 ]
 [60.91732788]
 [60.30815506]
 [59.70507431]
 [59.51277924]].
[2019-03-23 20:47:18,326] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.04045159e-19 1.00000000e+00 1.12753065e-29 3.10656194e-33
 2.17467087e-32], sum to 1.0000
[2019-03-23 20:47:18,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-23 20:47:18,341] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 61.33333333333333, 1.0, 2.0, 0.4403213347612612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536986.0094439866, 536986.0094439866, 134221.7800071026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7847400.0000, 
sim time next is 7848000.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.4413781215111436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538418.8377585381, 538418.8377585381, 134381.9536120068], 
processed observation next is [1.0, 0.8695652173913043, 0.5, 0.63, 1.0, 1.0, 0.33497395417993286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19229244205662074, 0.19229244205662074, 0.2584268338692438], 
reward next is 0.7416, 
noisyNet noise sample is [array([-0.6938609], dtype=float32), 0.73080176]. 
=============================================
[2019-03-23 20:47:18,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[35.478386]
 [35.478386]
 [35.478386]
 [35.478386]
 [35.478386]], R is [[35.86517715]
 [36.24840927]
 [36.6282196 ]
 [37.00456238]
 [37.37732697]].
[2019-03-23 20:47:20,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1606066e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:20,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4901
[2019-03-23 20:47:20,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 87.5, 1.0, 2.0, 0.396583633784572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495147.9034393002, 495147.9034393002, 128216.2464715692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7878600.0000, 
sim time next is 7879200.0000, 
raw observation next is [20.06666666666667, 88.0, 1.0, 2.0, 0.3876767349954444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484488.8662833261, 484488.8662833261, 126980.6138106732], 
processed observation next is [1.0, 0.17391304347826086, 0.29876543209876555, 0.88, 1.0, 1.0, 0.2710437321374338, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17303173795833077, 0.17303173795833077, 0.24419348809744845], 
reward next is 0.7558, 
noisyNet noise sample is [array([-1.4309654], dtype=float32), 0.6185882]. 
=============================================
[2019-03-23 20:47:21,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:21,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:21,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 20:47:22,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2942169e-19 1.0000000e+00 1.1511159e-30 2.8527650e-33 2.9210403e-33], sum to 1.0000
[2019-03-23 20:47:22,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-23 20:47:22,039] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 73.83333333333333, 1.0, 2.0, 0.3887099986312569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484560.4938643465, 484560.493864346, 127101.4624891581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890600.0000, 
sim time next is 7891200.0000, 
raw observation next is [22.3, 73.0, 1.0, 2.0, 0.3909878153811938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487350.0498356816, 487350.0498356816, 127417.6485808743], 
processed observation next is [1.0, 0.34782608695652173, 0.38148148148148153, 0.73, 1.0, 1.0, 0.27498549450142123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17405358922702915, 0.17405358922702915, 0.24503393957860442], 
reward next is 0.7550, 
noisyNet noise sample is [array([-1.1412892], dtype=float32), -0.22323143]. 
=============================================
[2019-03-23 20:47:22,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.64631552e-17 1.00000000e+00 1.39725484e-25 1.26020465e-29
 2.01847076e-28], sum to 1.0000
[2019-03-23 20:47:22,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-23 20:47:22,263] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1789573.709113431 W.
[2019-03-23 20:47:22,268] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 46.5, 1.0, 2.0, 0.9168475682052084, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9747753520584572, 6.911200000000001, 6.9112, 121.9260426156618, 1789573.709113431, 1789573.709113431, 356679.8887751187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7914600.0000, 
sim time next is 7915200.0000, 
raw observation next is [30.1, 46.66666666666667, 1.0, 2.0, 0.922567578898028, 0.0, 2.0, 0.0, 1.0, 2.0, 0.974355332762823, 6.911199999999999, 6.9112, 121.9260426156618, 1796935.561416077, 1796935.561416078, 357859.5930452832], 
processed observation next is [1.0, 0.6086956521739131, 0.6703703703703704, 0.46666666666666673, 1.0, 1.0, 0.9078185463071762, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9679441659535287, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6417627005057418, 0.6417627005057421, 0.6881915250870831], 
reward next is 0.3118, 
noisyNet noise sample is [array([1.0527422], dtype=float32), 1.726453]. 
=============================================
[2019-03-23 20:47:23,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8866249e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:47:23,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4956
[2019-03-23 20:47:23,412] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 74.0, 1.0, 2.0, 0.4433649726138047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540459.3935880795, 540459.3935880795, 134664.6604263765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7947600.0000, 
sim time next is 7948200.0000, 
raw observation next is [23.68333333333333, 74.5, 1.0, 2.0, 0.4430623294448311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540156.0115665076, 540156.0115665081, 134621.7785359266], 
processed observation next is [1.0, 1.0, 0.4327160493827159, 0.745, 1.0, 1.0, 0.33697896362479896, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19291286127375273, 0.1929128612737529, 0.2588880356460127], 
reward next is 0.7411, 
noisyNet noise sample is [array([-1.6217045], dtype=float32), 0.5808934]. 
=============================================
[2019-03-23 20:47:24,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,100] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 20:47:24,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 20:47:24,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 20:47:24,489] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,489] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,507] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,515] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 20:47:24,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,546] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 20:47:24,572] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,572] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,578] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 20:47:24,600] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 20:47:24,621] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,622] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 20:47:24,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,655] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 20:47:24,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 20:47:24,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 20:47:24,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:24,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:24,759] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 20:47:24,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 20:47:24,912] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 20:47:25,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 20:47:25,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:25,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 20:47:27,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 20:47:27,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2230
[2019-03-23 20:47:27,092] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.01666666666667, 75.16666666666666, 1.0, 2.0, 0.2702366987328751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348588.0231836425, 348588.0231836425, 103811.9003358166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 17400.0000, 
sim time next is 18000.0000, 
raw observation next is [18.0, 75.0, 1.0, 2.0, 0.26698095197961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 344387.3755884984, 344387.3755884984, 102924.2420164067], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.75, 1.0, 1.0, 0.1273582761662024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12299549128160658, 0.12299549128160658, 0.19793123464693596], 
reward next is 0.8021, 
noisyNet noise sample is [array([-1.0714558], dtype=float32), -0.5722725]. 
=============================================
[2019-03-23 20:47:27,113] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[81.12525]
 [81.12525]
 [81.12525]
 [81.12525]
 [81.12525]], R is [[81.11608124]
 [81.10528564]
 [81.09191895]
 [81.07450867]
 [81.05570221]].
[2019-03-23 20:47:27,797] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 20:47:27,798] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:47:27,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:27,799] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:47:27,800] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:27,800] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:47:27,803] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:27,804] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:47:27,805] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:47:27,805] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:27,806] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:47:27,821] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 20:47:27,822] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 20:47:27,862] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 20:47:27,887] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 20:47:27,912] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 20:47:43,702] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:47:43,703] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.957348865, 48.859629795, 1.0, 2.0, 0.5290542427696037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669836.0027196576, 669836.0027196576, 148522.8632570682]
[2019-03-23 20:47:43,706] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:47:43,709] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.653860241208638
[2019-03-23 20:47:45,046] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:47:45,047] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.8, 50.0, 1.0, 2.0, 0.8749509536513185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.086516486301653, 6.9112, 121.9252799971245, 1219048.525332907, 1129271.376275054, 214377.2171560647]
[2019-03-23 20:47:45,050] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:47:45,057] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4779643516839256
[2019-03-23 20:47:47,494] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:47:47,495] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 47.0, 1.0, 2.0, 0.312544312217856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397253.5515172242, 397253.5515172242, 117132.171796662]
[2019-03-23 20:47:47,495] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:47:47,499] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.13296394488455465
[2019-03-23 20:47:55,194] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:47:55,195] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.85, 89.5, 1.0, 2.0, 0.6940574445489933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856109.9264352293, 856109.9264352293, 177633.9631878823]
[2019-03-23 20:47:55,196] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:47:55,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5581838965865867
[2019-03-23 20:48:03,110] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:48:03,111] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333334, 76.66666666666667, 1.0, 2.0, 0.5183459486961498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622086.7611618903, 622086.7611618903, 145946.0106306783]
[2019-03-23 20:48:03,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:48:03,114] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6102744954911096
[2019-03-23 20:48:45,979] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:48:45,980] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.52605069333333, 50.427391335, 1.0, 2.0, 0.3886289718427736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615654, 488721.4893528229, 488721.4893528229, 127162.9976342322]
[2019-03-23 20:48:45,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:48:45,983] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.15632984547997753
[2019-03-23 20:49:03,674] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.59325194]
[2019-03-23 20:49:03,674] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 57.0, 1.0, 2.0, 0.3770962565614686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469463.2841492397, 469463.2841492401, 125486.5113687359]
[2019-03-23 20:49:03,675] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:49:03,677] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1206785e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5482718554572839
[2019-03-23 20:49:08,693] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:49:08,715] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:49:09,006] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:49:09,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:49:09,083] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:49:10,097] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 425000, evaluation results [425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:49:10,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9361546e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:10,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6577
[2019-03-23 20:49:10,483] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 42.33333333333334, 1.0, 2.0, 0.7310919079655676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 928420.617739008, 928420.6177390076, 185393.7790668757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 37200.0000, 
sim time next is 37800.0000, 
raw observation next is [26.2, 42.0, 1.0, 2.0, 0.7477062963883013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 948227.809551375, 948227.8095513746, 188736.6149153968], 
processed observation next is [1.0, 0.43478260869565216, 0.5259259259259259, 0.42, 1.0, 1.0, 0.6996503528432159, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33865278912549107, 0.33865278912549096, 0.3629550286834554], 
reward next is 0.6370, 
noisyNet noise sample is [array([0.90703166], dtype=float32), 0.6480776]. 
=============================================
[2019-03-23 20:49:17,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2634892e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:17,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4979
[2019-03-23 20:49:17,056] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 11.33333333333333, 1.0, 2.0, 0.3546305892362279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 457483.2047960592, 457483.2047960588, 108305.6091011549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 166800.0000, 
sim time next is 167400.0000, 
raw observation next is [31.1, 11.0, 1.0, 2.0, 0.3542594541383339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 457004.2876534775, 457004.287653477, 107593.0022403841], 
processed observation next is [1.0, 0.9565217391304348, 0.7074074074074075, 0.11, 1.0, 1.0, 0.23126125492658794, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16321581701909912, 0.16321581701909893, 0.20690961969304633], 
reward next is 0.7931, 
noisyNet noise sample is [array([-0.5961863], dtype=float32), -0.033615623]. 
=============================================
[2019-03-23 20:49:19,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.5640796e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:19,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5414
[2019-03-23 20:49:19,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1376754.190624567 W.
[2019-03-23 20:49:19,555] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.8, 26.33333333333334, 1.0, 2.0, 0.5511159209436478, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9234980162351459, 6.911200000000001, 6.9112, 121.925602273263, 1376754.190624567, 1376754.190624567, 270210.8085003177], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 404400.0000, 
sim time next is 405000.0000, 
raw observation next is [30.8, 26.5, 1.0, 2.0, 0.5324396077647338, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8895306884711075, 6.911199999999998, 6.9112, 121.9260424813873, 1327195.777443085, 1327195.777443086, 263708.9312967669], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.265, 1.0, 1.0, 0.44338048543420683, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8619133605888842, -1.7763568394002506e-16, 0.0, 0.8094621279286929, 0.473998491943959, 0.4739984919439593, 0.5071325601860902], 
reward next is 0.4929, 
noisyNet noise sample is [array([-2.0307474], dtype=float32), -0.96564263]. 
=============================================
[2019-03-23 20:49:19,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.743546]
 [75.743546]
 [75.743546]
 [75.743546]
 [75.743546]], R is [[75.47898865]
 [75.20455933]
 [74.45251465]
 [73.70799255]
 [72.97091675]].
[2019-03-23 20:49:21,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.448072e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:49:21,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0131
[2019-03-23 20:49:21,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.46666666666667, 20.66666666666667, 1.0, 2.0, 0.3678579062778196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470530.52516416, 470530.52516416, 124372.9079445012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 240000.0000, 
sim time next is 240600.0000, 
raw observation next is [31.23333333333333, 21.33333333333334, 1.0, 2.0, 0.3670157485272285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469375.2921667987, 469375.2921667991, 124258.6576345839], 
processed observation next is [0.0, 0.782608695652174, 0.7123456790123456, 0.2133333333333334, 1.0, 1.0, 0.24644731967527206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16763403291671383, 0.16763403291671394, 0.23895895698958441], 
reward next is 0.7610, 
noisyNet noise sample is [array([-0.00544203], dtype=float32), 0.4752719]. 
=============================================
[2019-03-23 20:49:26,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4390628e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:26,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5845
[2019-03-23 20:49:26,916] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 53.0, 1.0, 2.0, 0.2615382937437919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337365.170336205, 337365.170336205, 101830.890899253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [21.05, 53.5, 1.0, 2.0, 0.2599338504763279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 335295.104080551, 335295.1040805514, 101023.4111809151], 
processed observation next is [1.0, 0.043478260869565216, 0.3351851851851852, 0.535, 1.0, 1.0, 0.11896886961467605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11974825145733965, 0.11974825145733979, 0.19427579073252904], 
reward next is 0.8057, 
noisyNet noise sample is [array([0.17611586], dtype=float32), -1.1785182]. 
=============================================
[2019-03-23 20:49:28,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2926061e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:28,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7642
[2019-03-23 20:49:28,538] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.28333333333333, 37.5, 1.0, 2.0, 0.4117530727101867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 530303.3087942997, 530303.3087942993, 130488.4349187204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 375000.0000, 
sim time next is 375600.0000, 
raw observation next is [25.46666666666667, 37.0, 1.0, 2.0, 0.602439855145101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 775335.3377800498, 775335.3377800502, 161098.4624183236], 
processed observation next is [1.0, 0.34782608695652173, 0.4987654320987655, 0.37, 1.0, 1.0, 0.5267141132679773, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2769054777785892, 0.27690547777858937, 0.30980473541985304], 
reward next is 0.6902, 
noisyNet noise sample is [array([1.2919075], dtype=float32), 0.18427101]. 
=============================================
[2019-03-23 20:49:33,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5905491e-18 1.0000000e+00 6.2749620e-29 1.0078542e-31 5.9781758e-32], sum to 1.0000
[2019-03-23 20:49:33,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7602
[2019-03-23 20:49:33,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1326868.678445765 W.
[2019-03-23 20:49:33,911] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.06666666666667, 27.33333333333334, 1.0, 2.0, 0.3651176931739889, 1.0, 1.0, 0.3651176931739889, 1.0, 2.0, 0.592950584939079, 6.9112, 6.9112, 121.94756008, 1326868.678445765, 1326868.678445765, 281310.368789622], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 483600.0000, 
sim time next is 484200.0000, 
raw observation next is [32.1, 27.0, 1.0, 2.0, 0.5409909014745792, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8875385910351918, 6.911199999999999, 6.9112, 121.9260426156618, 1327083.371852669, 1327083.37185267, 268313.2309924017], 
processed observation next is [1.0, 0.6086956521739131, 0.7444444444444445, 0.27, 1.0, 1.0, 0.4535605969935466, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8594232387939899, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47395834709023893, 0.4739583470902393, 0.5159869826776956], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02890579], dtype=float32), -1.0412457]. 
=============================================
[2019-03-23 20:49:33,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2768805e-17 1.0000000e+00 3.4182570e-28 2.1281808e-31 2.5683298e-31], sum to 1.0000
[2019-03-23 20:49:33,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7261
[2019-03-23 20:49:33,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1578942.796263459 W.
[2019-03-23 20:49:33,949] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333333, 28.5, 1.0, 2.0, 0.7083846484904296, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9563631370274986, 6.9112, 6.9112, 121.9260426156618, 1578942.796263459, 1578942.796263459, 307066.4079077359], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 481800.0000, 
sim time next is 482400.0000, 
raw observation next is [32.0, 28.0, 1.0, 2.0, 0.71515551609918, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9559484715346882, 6.9112, 6.9112, 121.9260426156618, 1589896.952662192, 1589896.952662192, 307731.8832961043], 
processed observation next is [1.0, 0.6086956521739131, 0.7407407407407407, 0.28, 1.0, 1.0, 0.6608994239275953, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9449355894183603, 0.0, 0.0, 0.8094621288201359, 0.5678203402364972, 0.5678203402364972, 0.591792083261739], 
reward next is 0.4082, 
noisyNet noise sample is [array([-0.7074535], dtype=float32), -0.16511622]. 
=============================================
[2019-03-23 20:49:36,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7666773e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:36,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1991
[2019-03-23 20:49:36,501] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 76.66666666666667, 1.0, 2.0, 0.3214619013472238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410543.6573623123, 410543.6573623123, 118269.2429366312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 534000.0000, 
sim time next is 534600.0000, 
raw observation next is [19.5, 77.0, 1.0, 2.0, 0.3147604364139758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402097.0728933017, 402097.0728933017, 117419.7346747979], 
processed observation next is [1.0, 0.17391304347826086, 0.2777777777777778, 0.77, 1.0, 1.0, 0.1842386147785426, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14360609746189348, 0.14360609746189348, 0.22580718206691905], 
reward next is 0.7742, 
noisyNet noise sample is [array([-0.62936777], dtype=float32), -1.0728282]. 
=============================================
[2019-03-23 20:49:44,899] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1608325e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:44,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4557
[2019-03-23 20:49:44,914] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 35.16666666666667, 1.0, 2.0, 0.3352135773565864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424763.7503991032, 424763.7503991032, 120018.9910553417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 688200.0000, 
sim time next is 688800.0000, 
raw observation next is [27.93333333333333, 35.33333333333334, 1.0, 2.0, 0.3333551984994206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422721.3811450418, 422721.3811450414, 119780.8229125952], 
processed observation next is [1.0, 1.0, 0.5901234567901233, 0.35333333333333344, 1.0, 1.0, 0.20637523630883403, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15097192183751493, 0.1509719218375148, 0.2303477363703754], 
reward next is 0.7697, 
noisyNet noise sample is [array([-1.2125247], dtype=float32), 0.40957135]. 
=============================================
[2019-03-23 20:49:54,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9994809e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:49:54,623] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6094
[2019-03-23 20:49:54,627] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 57.0, 1.0, 2.0, 0.405357656940102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501739.6473098276, 501739.6473098276, 129364.9017676198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 860400.0000, 
sim time next is 861000.0000, 
raw observation next is [25.35, 57.5, 1.0, 2.0, 0.4045507751674626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 500957.4845463607, 500957.4845463603, 129255.4195762588], 
processed observation next is [0.0, 1.0, 0.4944444444444445, 0.575, 1.0, 1.0, 0.29113187519936023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17891338733798595, 0.17891338733798584, 0.24856811456972847], 
reward next is 0.7514, 
noisyNet noise sample is [array([1.0696725], dtype=float32), -1.526689]. 
=============================================
[2019-03-23 20:49:54,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.22261]
 [74.22261]
 [74.22261]
 [74.22261]
 [74.22261]], R is [[74.23181915]
 [74.24072266]
 [74.25019073]
 [74.26016235]
 [74.27033234]].
[2019-03-23 20:49:59,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.300133e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:49:59,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-23 20:49:59,865] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 57.33333333333333, 1.0, 2.0, 0.3022366753883002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389876.4346396258, 389876.4346396258, 114321.2201230607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 960000.0000, 
sim time next is 960600.0000, 
raw observation next is [21.05, 57.66666666666667, 1.0, 2.0, 0.2951350011505979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380713.2095367122, 380713.2095367122, 113399.8953990322], 
processed observation next is [1.0, 0.08695652173913043, 0.3351851851851852, 0.5766666666666667, 1.0, 1.0, 0.16087500136975938, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13596900340596865, 0.13596900340596865, 0.21807672192121577], 
reward next is 0.7819, 
noisyNet noise sample is [array([-0.09815963], dtype=float32), -0.6872601]. 
=============================================
[2019-03-23 20:50:00,033] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 20:50:00,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:50:00,035] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:50:00,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:50:00,036] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:50:00,036] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:50:00,037] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:50:00,037] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:50:00,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:50:00,039] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:50:00,040] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:50:00,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 20:50:00,053] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 20:50:00,107] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 20:50:00,107] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 20:50:00,108] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 20:50:20,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:50:20,159] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.16666666666666, 41.66666666666667, 1.0, 2.0, 0.3122375388945373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396730.9301693165, 396730.9301693165, 117092.6246924569]
[2019-03-23 20:50:20,160] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:50:20,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9762984623781866
[2019-03-23 20:50:25,692] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:50:25,693] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.49657594, 84.70068974, 1.0, 2.0, 0.3637750645901819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454922.9255053282, 454922.9255053282, 123717.0534500754]
[2019-03-23 20:50:25,694] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:50:25,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4830423582432839
[2019-03-23 20:50:26,892] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:50:26,894] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.291667845, 95.999325625, 1.0, 2.0, 0.3656779582821936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457028.3290186112, 457028.3290186112, 123969.048722718]
[2019-03-23 20:50:26,895] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:50:26,897] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7374164472342412
[2019-03-23 20:50:35,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:50:35,624] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.59433273, 47.92577437, 1.0, 2.0, 0.2998523093557039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 381789.2959058749, 381789.2959058753, 115553.965512276]
[2019-03-23 20:50:35,625] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:50:35,628] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.958135188894723
[2019-03-23 20:50:36,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:50:36,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 59.0, 1.0, 2.0, 0.6025496687617442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690418.4159425654, 690418.4159425654, 158701.1467675552]
[2019-03-23 20:50:36,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:50:36,481] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9740133762766966
[2019-03-23 20:51:06,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:06,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.65598758, 98.479383645, 1.0, 2.0, 0.8635565234929158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426114941, 990638.5885698865, 990638.588569887, 209757.7856390771]
[2019-03-23 20:51:06,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:51:06,600] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.037606914542941294
[2019-03-23 20:51:09,765] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:09,765] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.49550316, 69.95158115, 1.0, 2.0, 0.83414350096998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 950782.4539465883, 950782.4539465888, 203111.1177348885]
[2019-03-23 20:51:09,766] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:51:09,768] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9448477448407778
[2019-03-23 20:51:13,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:13,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.23333333333333, 84.33333333333333, 1.0, 2.0, 0.7840229331145561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 893620.1790110203, 893620.1790110199, 192666.9824748277]
[2019-03-23 20:51:13,139] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:51:13,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.013351526293737592
[2019-03-23 20:51:14,955] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:14,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.53333333333333, 36.66666666666667, 1.0, 2.0, 0.8427138958650457, 1.0, 2.0, 0.8427138958650457, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156492, 1922259.206604406, 1922259.206604406, 361719.656811016]
[2019-03-23 20:51:14,959] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:51:14,962] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7125961717024332
[2019-03-23 20:51:14,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1922259.206604406 W.
[2019-03-23 20:51:22,264] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:22,265] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 89.0, 1.0, 2.0, 0.4713114215327286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569874.2895561907, 569874.2895561903, 138727.6561805833]
[2019-03-23 20:51:22,265] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:51:22,267] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9028302005740125
[2019-03-23 20:51:36,172] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4940831]
[2019-03-23 20:51:36,173] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.45320951833333, 95.16945665666667, 1.0, 2.0, 0.4259662882961439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522329.9227868895, 522329.9227868895, 132201.515525171]
[2019-03-23 20:51:36,173] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:51:36,175] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.724645e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.347680785393387
[2019-03-23 20:51:40,850] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:51:41,035] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:51:41,141] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:51:41,213] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:51:41,219] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:51:42,234] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 450000, evaluation results [450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:51:42,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7992348e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:51:42,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-23 20:51:42,737] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 57.5, 1.0, 2.0, 0.6925667522248117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872267.0560279211, 872267.0560279211, 177721.2334631999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 984600.0000, 
sim time next is 985200.0000, 
raw observation next is [23.93333333333333, 57.33333333333334, 1.0, 2.0, 0.7590469896772275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 954890.3840004185, 954890.384000418, 190954.9248929136], 
processed observation next is [1.0, 0.391304347826087, 0.4419753086419752, 0.5733333333333335, 1.0, 1.0, 0.7131511781871755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34103228000014946, 0.3410322800001493, 0.36722100940944924], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.08631849], dtype=float32), 1.595389]. 
=============================================
[2019-03-23 20:51:45,366] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1932756e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:51:45,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4115
[2019-03-23 20:51:45,378] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 48.33333333333333, 1.0, 2.0, 0.2730648825256914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 351198.6627203493, 351198.6627203493, 112307.4794210261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1032000.0000, 
sim time next is 1032600.0000, 
raw observation next is [23.16666666666667, 48.66666666666666, 1.0, 2.0, 0.2731359895577912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 351297.3781220517, 351297.3781220517, 112315.8760047063], 
processed observation next is [1.0, 0.9565217391304348, 0.4135802469135804, 0.4866666666666666, 1.0, 1.0, 0.13468570185451337, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12546334932930417, 0.12546334932930417, 0.2159920692398198], 
reward next is 0.7840, 
noisyNet noise sample is [array([-0.16912048], dtype=float32), -0.34316456]. 
=============================================
[2019-03-23 20:51:47,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.684633e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:51:47,163] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4091
[2019-03-23 20:51:47,166] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 66.33333333333334, 1.0, 2.0, 0.3128396668062891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398544.9360669742, 398544.9360669742, 117174.3055400701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1059600.0000, 
sim time next is 1060200.0000, 
raw observation next is [21.45, 65.5, 1.0, 2.0, 0.3149502407070027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401160.20851027, 401160.20851027, 117439.9751738543], 
processed observation next is [1.0, 0.2608695652173913, 0.35, 0.655, 1.0, 1.0, 0.18446457227024135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14327150303938213, 0.14327150303938213, 0.22584610610356595], 
reward next is 0.7742, 
noisyNet noise sample is [array([2.0471659], dtype=float32), -0.122170426]. 
=============================================
[2019-03-23 20:51:51,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5887036e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:51:51,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5608
[2019-03-23 20:51:51,434] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 73.0, 1.0, 2.0, 0.2764086051661019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355351.2188606191, 355351.2188606187, 112706.4810798483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [19.4, 72.5, 1.0, 2.0, 0.2841988721821617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 365379.4659833665, 365379.4659833661, 113641.6083534034], 
processed observation next is [1.0, 0.2608695652173913, 0.274074074074074, 0.725, 1.0, 1.0, 0.1478558002168592, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13049266642263088, 0.13049266642263077, 0.21854155452577576], 
reward next is 0.7815, 
noisyNet noise sample is [array([-0.154511], dtype=float32), -1.4644613]. 
=============================================
[2019-03-23 20:52:05,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.528637e-36 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:52:05,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8527
[2019-03-23 20:52:05,989] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 34.33333333333334, 1.0, 2.0, 0.3431121560900645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 431581.6773342358, 431581.6773342353, 121012.4289902141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1415400.0000, 
sim time next is 1416000.0000, 
raw observation next is [29.33333333333334, 33.66666666666667, 1.0, 2.0, 0.343309513711952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431912.0091459317, 431912.0091459317, 121039.4663133068], 
processed observation next is [0.0, 0.391304347826087, 0.6419753086419755, 0.3366666666666667, 1.0, 1.0, 0.21822561156184764, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15425428898068988, 0.15425428898068988, 0.23276820444866692], 
reward next is 0.7672, 
noisyNet noise sample is [array([0.8809695], dtype=float32), -1.3635298]. 
=============================================
[2019-03-23 20:52:06,005] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[85.642555]
 [85.642555]
 [85.642555]
 [85.642555]
 [85.642555]], R is [[85.55335999]
 [85.46511078]
 [85.37763214]
 [85.29039764]
 [85.20386505]].
[2019-03-23 20:52:11,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1728774e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:52:11,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7925
[2019-03-23 20:52:11,578] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 47.5, 1.0, 2.0, 0.5439986196303979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638204.9573580298, 638204.9573580298, 149555.7766979248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1531800.0000, 
sim time next is 1532400.0000, 
raw observation next is [30.7, 49.0, 1.0, 2.0, 0.5401087917005557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635079.6659639785, 635079.6659639785, 148979.2710507787], 
processed observation next is [0.0, 0.7391304347826086, 0.6925925925925925, 0.49, 1.0, 1.0, 0.4525104663101853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22681416641570662, 0.22681416641570662, 0.28649859817457446], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.6040405], dtype=float32), -0.72927415]. 
=============================================
[2019-03-23 20:52:32,317] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 20:52:32,319] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:52:32,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:52:32,321] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:52:32,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:52:32,323] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:52:32,325] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:52:32,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:52:32,330] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:52:32,332] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:52:32,333] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:52:32,346] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 20:52:32,346] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 20:52:32,347] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 20:52:32,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 20:52:32,439] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 20:52:34,483] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:52:34,484] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.61894028333333, 78.457175475, 1.0, 2.0, 0.5745814869198184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660117.1142463965, 660117.1142463965, 154022.7988546464]
[2019-03-23 20:52:34,484] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:52:34,489] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.20402173502214238
[2019-03-23 20:52:44,588] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:52:44,589] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.717777885, 44.83017652, 1.0, 2.0, 0.5010614259561345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602569.7801658176, 602569.7801658176, 143236.3218146637]
[2019-03-23 20:52:44,593] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:52:44,595] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.08047066200454189
[2019-03-23 20:52:58,673] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:52:58,674] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.95, 87.66666666666667, 1.0, 2.0, 0.3860872649885289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477425.042907165, 477425.042907165, 126654.5906135804]
[2019-03-23 20:52:58,675] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:52:58,676] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.24945598513634626
[2019-03-23 20:53:08,426] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:08,427] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.76666666666667, 44.66666666666667, 1.0, 2.0, 0.6657650569151856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425983178, 758764.5149442271, 758764.5149442271, 169765.4102139756]
[2019-03-23 20:53:08,428] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:53:08,431] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.23029976131578322
[2019-03-23 20:53:24,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:24,277] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.40840461, 100.21856326, 1.0, 2.0, 0.6762990464682287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770776.0136245143, 770776.0136245143, 171710.1160561067]
[2019-03-23 20:53:24,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:53:24,281] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8325418456516267
[2019-03-23 20:53:31,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:31,780] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.88105552, 64.69178646, 1.0, 2.0, 0.7485183190900823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853129.9112835132, 853129.9112835135, 185545.3370385662]
[2019-03-23 20:53:31,782] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:53:31,785] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3462919747339239
[2019-03-23 20:53:32,663] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:32,664] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.28223992, 83.17054606, 1.0, 2.0, 0.5389428271443395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636002.3763761271, 636002.3763761271, 148882.4446067211]
[2019-03-23 20:53:32,665] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:53:32,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1416969734588669
[2019-03-23 20:53:35,487] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:35,490] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.46666666666667, 94.0, 1.0, 2.0, 0.5734449492247621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668836.6896821251, 668836.6896821251, 154290.9621920363]
[2019-03-23 20:53:35,490] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 20:53:35,494] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.24846420991704832
[2019-03-23 20:53:41,109] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:41,110] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.9388963, 75.91128557, 1.0, 2.0, 0.9373360975588647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1068486.56003828, 1068486.56003828, 225967.3840406541]
[2019-03-23 20:53:41,112] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:53:41,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7721961367169042
[2019-03-23 20:53:58,888] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:53:58,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 59.5, 1.0, 2.0, 0.606654801815206, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9658142018573694, 6.911199999999999, 6.9112, 121.9260426156618, 1383357.851530055, 1383357.851530056, 296462.8325351794]
[2019-03-23 20:53:58,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:53:58,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.17422530735694708
[2019-03-23 20:53:58,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1383357.851530055 W.
[2019-03-23 20:54:05,449] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.43185255]
[2019-03-23 20:54:05,451] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.30037543, 88.93068599, 1.0, 2.0, 0.8595793382716223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156194, 995733.5411278812, 995733.5411278812, 209394.7292383669]
[2019-03-23 20:54:05,453] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:54:05,455] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3322796e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6328578904975017
[2019-03-23 20:54:12,857] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:54:13,263] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:54:13,354] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:54:13,462] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:54:13,463] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:54:14,478] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 475000, evaluation results [475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:54:20,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4515034e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:20,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-23 20:54:20,331] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 66.0, 1.0, 2.0, 0.4666433707456217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 561474.2768503869, 561474.2768503864, 137925.819584349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2028600.0000, 
sim time next is 2029200.0000, 
raw observation next is [26.1, 66.0, 1.0, 2.0, 0.4726365363174186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 567326.6905175243, 567326.6905175238, 138791.074588555], 
processed observation next is [0.0, 0.4782608695652174, 0.5222222222222223, 0.66, 1.0, 1.0, 0.3721863527588317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2026166751848301, 0.20261667518482993, 0.26690591267029806], 
reward next is 0.7331, 
noisyNet noise sample is [array([-1.7077316], dtype=float32), 1.3216487]. 
=============================================
[2019-03-23 20:54:21,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.974403e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:54:21,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3262
[2019-03-23 20:54:21,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 64.66666666666667, 1.0, 2.0, 0.5211466575179315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614769.9499536863, 614769.9499536863, 145993.2910345082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2034600.0000, 
sim time next is 2035200.0000, 
raw observation next is [27.5, 64.33333333333334, 1.0, 2.0, 0.5250595564329001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618403.9938132049, 618403.9938132049, 146581.8996114313], 
processed observation next is [0.0, 0.5652173913043478, 0.5740740740740741, 0.6433333333333334, 1.0, 1.0, 0.43459471003916683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22085856921900177, 0.22085856921900177, 0.2818882684835217], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.00837526], dtype=float32), -0.68315554]. 
=============================================
[2019-03-23 20:54:21,515] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0047215e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:21,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5137
[2019-03-23 20:54:21,527] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 0.6026587889575423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692856.185198979, 692856.185198979, 158831.8881031575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2058600.0000, 
sim time next is 2059200.0000, 
raw observation next is [26.9, 75.0, 1.0, 2.0, 0.6013212733106752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691442.9745468321, 691442.9745468321, 158606.6605946496], 
processed observation next is [0.0, 0.8695652173913043, 0.5518518518518518, 0.75, 1.0, 1.0, 0.5253824682269943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2469439194810115, 0.2469439194810115, 0.3050128088358646], 
reward next is 0.6950, 
noisyNet noise sample is [array([2.3549867], dtype=float32), 2.6369736]. 
=============================================
[2019-03-23 20:54:28,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5135652e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:28,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 20:54:28,026] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 89.0, 1.0, 2.0, 0.6389522271495482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744835.7685452169, 744835.7685452169, 165704.2841612931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169600.0000, 
sim time next is 2170200.0000, 
raw observation next is [24.13333333333333, 89.0, 1.0, 2.0, 0.6245746367383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728599.8148983652, 728599.8148983652, 163155.0482917241], 
processed observation next is [1.0, 0.08695652173913043, 0.44938271604938257, 0.89, 1.0, 1.0, 0.5530650437361341, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.260214219606559, 0.260214219606559, 0.31375970825331556], 
reward next is 0.6862, 
noisyNet noise sample is [array([-0.8372441], dtype=float32), -0.1755312]. 
=============================================
[2019-03-23 20:54:28,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8228737e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:28,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8737
[2019-03-23 20:54:28,246] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 89.83333333333333, 1.0, 2.0, 0.705226143296477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827451.1912768594, 827451.1912768594, 178272.225411337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2178600.0000, 
sim time next is 2179200.0000, 
raw observation next is [23.8, 89.66666666666667, 1.0, 2.0, 0.6650567299520084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779819.9792611891, 779819.9792611891, 170670.9893353782], 
processed observation next is [1.0, 0.21739130434782608, 0.43703703703703706, 0.8966666666666667, 1.0, 1.0, 0.601258011847629, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27850713545042466, 0.27850713545042466, 0.32821344102957345], 
reward next is 0.6718, 
noisyNet noise sample is [array([-0.96908075], dtype=float32), 1.527089]. 
=============================================
[2019-03-23 20:54:32,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1072084e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:32,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2730
[2019-03-23 20:54:32,420] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 98.0, 1.0, 2.0, 0.5571014409257439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651388.710388164, 651388.710388164, 151626.1217789419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2248200.0000, 
sim time next is 2248800.0000, 
raw observation next is [22.93333333333333, 98.0, 1.0, 2.0, 0.5585620526580397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652647.4863142942, 652647.4863142942, 151849.4647594361], 
processed observation next is [1.0, 0.0, 0.40493827160493817, 0.98, 1.0, 1.0, 0.4744786341167139, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23308838796939077, 0.23308838796939077, 0.292018201460454], 
reward next is 0.7080, 
noisyNet noise sample is [array([-1.1314087], dtype=float32), 0.4192058]. 
=============================================
[2019-03-23 20:54:36,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.852192e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:54:36,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0351
[2019-03-23 20:54:36,653] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.98333333333333, 92.83333333333333, 1.0, 2.0, 0.4759072788202013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573097.7536010717, 573097.7536010712, 139354.1600148507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2335800.0000, 
sim time next is 2336400.0000, 
raw observation next is [22.0, 93.0, 1.0, 2.0, 0.4778314215518487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575041.7243147572, 575041.7243147572, 139636.8480113216], 
processed observation next is [1.0, 0.043478260869565216, 0.37037037037037035, 0.93, 1.0, 1.0, 0.37837073994267706, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20537204439812756, 0.20537204439812756, 0.2685324000217723], 
reward next is 0.7315, 
noisyNet noise sample is [array([1.7182575], dtype=float32), 0.36616346]. 
=============================================
[2019-03-23 20:54:42,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8736065e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:42,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8155
[2019-03-23 20:54:42,020] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 63.83333333333334, 1.0, 2.0, 0.3773304460927403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471155.3520282395, 471155.3520282395, 125545.5317773603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416200.0000, 
sim time next is 2416800.0000, 
raw observation next is [23.4, 63.66666666666667, 1.0, 2.0, 0.370677652795156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463800.1068928704, 463800.1068928704, 124654.8377980725], 
processed observation next is [1.0, 1.0, 0.42222222222222217, 0.6366666666666667, 1.0, 1.0, 0.2508067295180429, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1656428953188823, 0.1656428953188823, 0.2397208419193702], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.28100073], dtype=float32), -0.37081918]. 
=============================================
[2019-03-23 20:54:43,100] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4384987e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:43,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1962
[2019-03-23 20:54:43,116] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 68.0, 1.0, 2.0, 0.293398023764236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377019.6211152644, 377019.6211152644, 114760.9018645539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2430000.0000, 
sim time next is 2430600.0000, 
raw observation next is [19.93333333333334, 69.0, 1.0, 2.0, 0.2995793535418291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385035.8896417869, 385035.8896417873, 115520.4314902293], 
processed observation next is [1.0, 0.13043478260869565, 0.29382716049382746, 0.69, 1.0, 1.0, 0.16616589707360604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13751281772920962, 0.13751281772920973, 0.22215467594274865], 
reward next is 0.7778, 
noisyNet noise sample is [array([-0.34889802], dtype=float32), 0.56631297]. 
=============================================
[2019-03-23 20:54:51,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2968525e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:54:51,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9207
[2019-03-23 20:54:51,739] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 90.16666666666667, 1.0, 2.0, 0.4652813629431153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564415.790117749, 564415.790117749, 137868.3405930214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2598600.0000, 
sim time next is 2599200.0000, 
raw observation next is [21.7, 91.0, 1.0, 2.0, 0.4629468471086041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562003.0541269344, 562003.0541269344, 137527.5797242911], 
processed observation next is [0.0, 0.08695652173913043, 0.3592592592592592, 0.91, 1.0, 1.0, 0.36065100846262393, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20071537647390514, 0.20071537647390514, 0.264476114854406], 
reward next is 0.7355, 
noisyNet noise sample is [array([0.9840635], dtype=float32), -0.9360873]. 
=============================================
[2019-03-23 20:55:04,597] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 20:55:04,600] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:55:04,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:55:04,602] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:55:04,606] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:55:04,607] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:55:04,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:55:04,608] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:55:04,608] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:55:04,609] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:55:04,609] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:55:04,614] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 20:55:04,634] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 20:55:04,635] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 20:55:04,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 20:55:04,712] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 20:55:25,009] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:55:25,010] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.93699846, 58.39914948, 1.0, 2.0, 0.596787095969689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680116.2793129017, 680116.2793129017, 157528.2348934516]
[2019-03-23 20:55:25,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:55:25,015] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.9804491036905855
[2019-03-23 20:55:36,093] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:55:36,094] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.16666666666667, 82.66666666666667, 1.0, 2.0, 0.3745611390937459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465811.576584691, 465811.576584691, 125129.9205714681]
[2019-03-23 20:55:36,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:55:36,098] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.07035923471737693
[2019-03-23 20:55:39,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:55:39,888] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.74320522, 38.77806894, 1.0, 2.0, 0.4204747268308798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514445.7734406652, 514445.7734406652, 131376.7290771077]
[2019-03-23 20:55:39,890] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:55:39,894] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.9180944249568487
[2019-03-23 20:55:43,197] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:55:43,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666666, 75.0, 1.0, 2.0, 0.5963304972665877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689025.0771238293, 689025.0771238293, 157903.7061767972]
[2019-03-23 20:55:43,199] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:55:43,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.8442169044479249
[2019-03-23 20:55:43,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:55:43,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 74.66666666666667, 1.0, 2.0, 0.5474309798836362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643764.3342280516, 643764.3342280516, 150183.8870048559]
[2019-03-23 20:55:43,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:55:43,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.10985754479645926
[2019-03-23 20:56:33,174] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.40335763]
[2019-03-23 20:56:33,175] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.25771029666667, 45.87665696333333, 1.0, 2.0, 0.5640225522882075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 693794.7652887036, 693794.7652887031, 153992.9314416539]
[2019-03-23 20:56:33,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:56:33,182] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.1026305e-17 1.0000000e+00 2.8173782e-26 2.4684342e-29 8.5784266e-29], sampled 0.9395569979882933
[2019-03-23 20:56:46,017] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:56:46,161] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:56:46,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:56:46,409] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:56:46,423] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:56:47,437] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 500000, evaluation results [500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:56:52,046] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3094812e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:56:52,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2905
[2019-03-23 20:56:52,058] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 88.66666666666667, 1.0, 2.0, 0.5118079671209498, 1.0, 1.0, 0.5118079671209498, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257037656964, 1166913.424488652, 1166913.424488652, 239058.3406351413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2946000.0000, 
sim time next is 2946600.0000, 
raw observation next is [25.25, 90.0, 1.0, 2.0, 0.8900896827910901, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425123362, 1014593.851054915, 1014593.851054915, 215250.8225542072], 
processed observation next is [1.0, 0.08695652173913043, 0.49074074074074076, 0.9, 1.0, 1.0, 0.8691543842751073, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621281341614, 0.36235494680532676, 0.36235494680532676, 0.41394388952732153], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4876978], dtype=float32), 0.63082975]. 
=============================================
[2019-03-23 20:56:56,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4698154e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:56:56,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8198
[2019-03-23 20:56:56,729] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 92.33333333333334, 1.0, 2.0, 0.6703845166706957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 764031.8821065259, 764031.8821065264, 170611.8529750401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3012600.0000, 
sim time next is 3013200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6700423593875182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763641.7339361912, 763641.7339361907, 170548.7111947747], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6071932849851407, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27272919069149687, 0.2727291906914967, 0.3279782907591821], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.85140795], dtype=float32), -1.3498458]. 
=============================================
[2019-03-23 20:56:57,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7615013e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:56:57,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3461
[2019-03-23 20:56:57,748] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 97.0, 1.0, 2.0, 0.751228509497946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 856220.5985305964, 856220.5985305959, 186067.2622279097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3036600.0000, 
sim time next is 3037200.0000, 
raw observation next is [25.0, 98.0, 1.0, 2.0, 0.7724411847718551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880411.8552250122, 880411.8552250122, 190310.3286549849], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.98, 1.0, 1.0, 0.7290966485379227, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31443280543750435, 0.31443280543750435, 0.3659814012595864], 
reward next is 0.6340, 
noisyNet noise sample is [array([0.3356943], dtype=float32), 1.1870522]. 
=============================================
[2019-03-23 20:57:07,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2714769e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:57:07,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5231
[2019-03-23 20:57:07,351] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 76.0, 1.0, 2.0, 0.4744172613143072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574237.7074800801, 574237.7074800801, 139222.089341862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3214800.0000, 
sim time next is 3215400.0000, 
raw observation next is [23.75, 77.16666666666667, 1.0, 2.0, 0.4726120044331394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572209.2135343803, 572209.2135343803, 138950.8654830824], 
processed observation next is [0.0, 0.21739130434782608, 0.4351851851851852, 0.7716666666666667, 1.0, 1.0, 0.3721571481346898, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20436043340513582, 0.20436043340513582, 0.26721320285208155], 
reward next is 0.7328, 
noisyNet noise sample is [array([-1.4651344], dtype=float32), -0.5261183]. 
=============================================
[2019-03-23 20:57:10,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5593517e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:57:10,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-23 20:57:10,344] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 86.5, 1.0, 2.0, 0.6034844769308826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696634.2780834283, 696634.2780834283, 159109.2733272288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274200.0000, 
sim time next is 3274800.0000, 
raw observation next is [24.66666666666667, 89.0, 1.0, 2.0, 0.6045640048116646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697690.424491094, 697690.424491094, 159287.5860510836], 
processed observation next is [0.0, 0.9130434782608695, 0.469135802469136, 0.89, 1.0, 1.0, 0.5292428628710293, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24917515160396214, 0.24917515160396214, 0.3063222808674685], 
reward next is 0.6937, 
noisyNet noise sample is [array([1.564373], dtype=float32), 0.7403826]. 
=============================================
[2019-03-23 20:57:16,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.278111e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:57:16,035] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4137
[2019-03-23 20:57:16,038] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 84.33333333333333, 1.0, 2.0, 0.787847378070799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904310.8366846641, 904310.8366846641, 193769.0503875258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3397800.0000, 
sim time next is 3398400.0000, 
raw observation next is [25.8, 83.0, 1.0, 2.0, 0.7414505728593513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850319.5889179686, 850319.5889179686, 184406.0381754394], 
processed observation next is [1.0, 0.34782608695652173, 0.5111111111111112, 0.83, 1.0, 1.0, 0.6922030629277992, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3036855674707031, 0.3036855674707031, 0.35462699649122964], 
reward next is 0.6454, 
noisyNet noise sample is [array([0.7381883], dtype=float32), -0.59833163]. 
=============================================
[2019-03-23 20:57:19,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8174588e-15 1.0000000e+00 4.8507586e-24 2.0037967e-26 6.1741296e-26], sum to 1.0000
[2019-03-23 20:57:19,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5759
[2019-03-23 20:57:19,214] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 76.83333333333334, 1.0, 2.0, 0.6854779792226079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781242.5471933756, 781242.5471933756, 173414.9334864498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.6864459153535231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782346.2716394485, 782346.271639448, 173595.877333841], 
processed observation next is [1.0, 0.8260869565217391, 0.5925925925925926, 0.79, 1.0, 1.0, 0.6267213278018131, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27940938272837446, 0.2794093827283743, 0.33383822564200194], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.0750388], dtype=float32), -1.301311]. 
=============================================
[2019-03-23 20:57:19,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[30.733843]
 [30.733843]
 [30.733843]
 [30.733843]
 [30.733843]], R is [[31.09266472]
 [31.44824791]
 [31.80065918]
 [32.14962387]
 [32.49425125]].
[2019-03-23 20:57:20,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.357683e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:57:20,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6266
[2019-03-23 20:57:20,371] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 98.5, 1.0, 2.0, 0.7755633483291637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883972.4823768238, 883972.4823768238, 190937.1127467615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466200.0000, 
sim time next is 3466800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7888799241524445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899159.3681747539, 899159.3681747539, 193647.9038952479], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.7486665763719577, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3211283457766978, 0.3211283457766978, 0.37239981518316906], 
reward next is 0.6276, 
noisyNet noise sample is [array([0.03638544], dtype=float32), -0.26166287]. 
=============================================
[2019-03-23 20:57:28,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2053261e-20 1.0000000e+00 9.1788260e-31 2.1033093e-36 4.4838346e-34], sum to 1.0000
[2019-03-23 20:57:28,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5993
[2019-03-23 20:57:28,629] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 83.5, 1.0, 2.0, 0.5283848439583234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 623569.5899793094, 623569.5899793089, 147168.5574954386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3616200.0000, 
sim time next is 3616800.0000, 
raw observation next is [24.23333333333333, 85.33333333333333, 1.0, 2.0, 0.5337722919065803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628254.8205768414, 628254.8205768414, 147973.4130158077], 
processed observation next is [1.0, 0.8695652173913043, 0.45308641975308633, 0.8533333333333333, 1.0, 1.0, 0.4449670141745003, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2243767216345862, 0.2243767216345862, 0.2845642557996302], 
reward next is 0.7154, 
noisyNet noise sample is [array([1.2527555], dtype=float32), 1.167119]. 
=============================================
[2019-03-23 20:57:37,516] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 20:57:37,520] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:57:37,522] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:57:37,523] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:57:37,524] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:57:37,525] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:57:37,526] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:57:37,525] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:57:37,527] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:57:37,527] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:57:37,529] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:57:37,548] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 20:57:37,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 20:57:37,574] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 20:57:37,608] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 20:57:37,631] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 20:58:02,576] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33212984]
[2019-03-23 20:58:02,580] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.7134154964550851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 882938.224443071, 882938.224443071, 181478.6150049718]
[2019-03-23 20:58:02,580] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:58:02,583] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9256106e-11 1.0000000e+00 4.2519721e-17 5.7723336e-19 1.2181772e-18], sampled 0.5290797959429093
[2019-03-23 20:58:03,600] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33212984]
[2019-03-23 20:58:03,602] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.85160210333333, 77.52392858333334, 1.0, 2.0, 0.4001047421671073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492157.4290603893, 492157.4290603893, 128548.2269765815]
[2019-03-23 20:58:03,603] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:58:03,607] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9256106e-11 1.0000000e+00 4.2519721e-17 5.7723336e-19 1.2181772e-18], sampled 0.14303252243356146
[2019-03-23 20:58:38,913] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33212984]
[2019-03-23 20:58:38,914] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.24386913666667, 81.1950526, 1.0, 2.0, 0.6344585377006051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723068.0192949163, 723068.0192949163, 164109.778048655]
[2019-03-23 20:58:38,914] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:58:38,917] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.9256106e-11 1.0000000e+00 4.2519721e-17 5.7723336e-19 1.2181772e-18], sampled 0.8478642668260948
[2019-03-23 20:59:17,633] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 20:59:17,767] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33212984]
[2019-03-23 20:59:17,768] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.1, 61.0, 1.0, 2.0, 0.6197421033958138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752016.6327095244, 752016.6327095244, 163422.5601547482]
[2019-03-23 20:59:17,769] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:59:17,770] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9256106e-11 1.0000000e+00 4.2519721e-17 5.7723336e-19 1.2181772e-18], sampled 0.9945932803859888
[2019-03-23 20:59:17,826] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 20:59:17,890] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 20:59:17,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 20:59:17,967] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 20:59:18,982] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 525000, evaluation results [525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 20:59:26,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2654994e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:59:26,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3923
[2019-03-23 20:59:26,610] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.802424352938369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 914606.4175546059, 914606.4175546059, 196449.2284480587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3943800.0000, 
sim time next is 3944400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8109933599136352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924379.2956857367, 924379.2956857367, 198229.6124350023], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.7, 1.0, 1.0, 0.77499209513528, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33013546274490596, 0.33013546274490596, 0.38121079314423517], 
reward next is 0.6188, 
noisyNet noise sample is [array([2.1622927], dtype=float32), -0.9192211]. 
=============================================
[2019-03-23 20:59:27,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.416739e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:59:27,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4019
[2019-03-23 20:59:27,206] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8088815492633511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 921970.7823837365, 921970.7823837365, 197789.6601493584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3942600.0000, 
sim time next is 3943200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7805714610548283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889683.9480614975, 889683.9480614975, 191966.4477505636], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7387755488747956, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31774426716482057, 0.31774426716482057, 0.36916624567416073], 
reward next is 0.6308, 
noisyNet noise sample is [array([0.4031996], dtype=float32), -0.04310379]. 
=============================================
[2019-03-23 20:59:29,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1705927e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:59:29,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-23 20:59:29,550] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 87.0, 1.0, 2.0, 0.7344222655442711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837055.0450723128, 837055.0450723128, 182763.523794569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3968400.0000, 
sim time next is 3969000.0000, 
raw observation next is [26.65, 86.0, 1.0, 2.0, 0.721240298650842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822022.8906126631, 822022.8906126631, 180203.526526246], 
processed observation next is [0.0, 0.9565217391304348, 0.5425925925925925, 0.86, 1.0, 1.0, 0.6681432126795739, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29357960379023684, 0.29357960379023684, 0.3465452433197038], 
reward next is 0.6535, 
noisyNet noise sample is [array([-0.7873756], dtype=float32), -0.06886471]. 
=============================================
[2019-03-23 20:59:29,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.800022]
 [58.800022]
 [58.800022]
 [58.800022]
 [58.800022]], R is [[58.86547089]
 [58.92535019]
 [58.9792099 ]
 [59.02810287]
 [59.07556152]].
[2019-03-23 20:59:33,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7118784e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:59:33,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2279
[2019-03-23 20:59:33,631] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4380637018431857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537367.2359322021, 537367.2359322016, 133976.7358518791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4062000.0000, 
sim time next is 4062600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4358984806353341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534721.4216754317, 534721.4216754317, 133658.4226802251], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 1.0, 1.0, 0.3284505721849215, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19097193631265416, 0.19097193631265416, 0.2570354282312021], 
reward next is 0.7430, 
noisyNet noise sample is [array([0.45180693], dtype=float32), 1.3100758]. 
=============================================
[2019-03-23 20:59:41,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.04724709e-15 1.00000000e+00 1.02903156e-22 9.74961772e-25
 7.51446021e-25], sum to 1.0000
[2019-03-23 20:59:41,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1976
[2019-03-23 20:59:41,744] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333334, 40.33333333333334, 1.0, 2.0, 0.4939515597024959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589783.4892561116, 589783.4892561116, 141971.4054670813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4216800.0000, 
sim time next is 4217400.0000, 
raw observation next is [31.4, 41.5, 1.0, 2.0, 0.4871868059960392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 583472.7812161427, 583472.7812161422, 140983.1032965795], 
processed observation next is [1.0, 0.8260869565217391, 0.7185185185185184, 0.415, 1.0, 1.0, 0.3895081023762372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2083831361486224, 0.20838313614862222, 0.2711213524934221], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.87129533], dtype=float32), -0.87229145]. 
=============================================
[2019-03-23 20:59:45,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4214087e-18 1.0000000e+00 2.4720257e-28 1.5304005e-30 7.4599425e-31], sum to 1.0000
[2019-03-23 20:59:45,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8348
[2019-03-23 20:59:45,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1774004.158849038 W.
[2019-03-23 20:59:45,795] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 34.66666666666667, 1.0, 2.0, 0.7606322174034243, 1.0, 1.0, 0.7606322174034243, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1774004.158849038, 1774004.158849038, 329723.7553827837], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4283400.0000, 
sim time next is 4284000.0000, 
raw observation next is [33.6, 34.0, 1.0, 2.0, 0.761990103617548, 1.0, 2.0, 0.761990103617548, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1773352.21497239, 1773352.21497239, 330088.8989728938], 
processed observation next is [1.0, 0.6086956521739131, 0.8, 0.34, 1.0, 1.0, 0.7166548852589858, 1.0, 1.0, 0.7166548852589858, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6333400767758536, 0.6333400767758536, 0.6347863441786419], 
reward next is 0.3652, 
noisyNet noise sample is [array([-0.40464437], dtype=float32), 1.3178259]. 
=============================================
[2019-03-23 20:59:45,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[38.461876]
 [38.461876]
 [38.461876]
 [38.461876]
 [38.461876]], R is [[38.44247055]
 [38.05804443]
 [37.67746353]
 [37.3006897 ]
 [36.92768478]].
[2019-03-23 20:59:48,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.410935e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:59:48,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7725
[2019-03-23 20:59:48,032] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.88333333333333, 56.0, 1.0, 2.0, 0.5705949900436349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663273.1187100431, 663273.1187100431, 153711.5241275572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4302600.0000, 
sim time next is 4303200.0000, 
raw observation next is [29.76666666666667, 57.0, 1.0, 2.0, 0.5739478033701344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666038.0336274105, 666038.0336274105, 154225.0114542453], 
processed observation next is [1.0, 0.8260869565217391, 0.6580246913580248, 0.57, 1.0, 1.0, 0.4927950040120647, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23787072629550376, 0.23787072629550376, 0.2965865604889333], 
reward next is 0.7034, 
noisyNet noise sample is [array([1.7572168], dtype=float32), 0.48027065]. 
=============================================
[2019-03-23 20:59:49,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.63199e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 20:59:49,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5492
[2019-03-23 20:59:49,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1834947.397426764 W.
[2019-03-23 20:59:49,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8044758843923874, 1.0, 2.0, 0.8044758843923874, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1834947.397426764, 1834947.397426764, 345606.9071032207], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4352400.0000, 
sim time next is 4353000.0000, 
raw observation next is [27.16666666666666, 79.00000000000001, 1.0, 2.0, 0.5140564931354484, 1.0, 2.0, 0.5140564931354484, 1.0, 1.0, 0.8183946787228199, 6.9112, 6.9112, 121.94756008, 1758709.488724531, 1758709.488724531, 350541.7130884252], 
processed observation next is [1.0, 0.391304347826087, 0.5617283950617282, 0.7900000000000001, 1.0, 1.0, 0.4214958251612481, 1.0, 1.0, 0.4214958251612481, 1.0, 0.5, 0.7729933484035247, 0.0, 0.0, 0.8096049824067558, 0.6281105316873324, 0.6281105316873324, 0.6741186790162024], 
reward next is 0.3259, 
noisyNet noise sample is [array([-0.33332145], dtype=float32), -0.8941829]. 
=============================================
[2019-03-23 20:59:49,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.72508]
 [66.72508]
 [66.72508]
 [66.72508]
 [66.72508]], R is [[66.38370514]
 [66.05524445]
 [65.77748871]
 [65.5007782 ]
 [65.12182617]].
[2019-03-23 20:59:49,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.548711e-24 1.000000e+00 6.891624e-35 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:59:49,810] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0548
[2019-03-23 20:59:49,818] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1788549.86093687 W.
[2019-03-23 20:59:49,822] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.2, 66.0, 1.0, 2.0, 0.7841546661126201, 1.0, 1.0, 0.7841546661126201, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1788549.86093687, 1788549.86093687, 337249.9195534924], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4359600.0000, 
sim time next is 4360200.0000, 
raw observation next is [29.33333333333333, 65.33333333333333, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.448287780019483, 6.9112, 121.9242886640616, 2153398.769883185, 1878365.778661236, 382205.2294028194], 
processed observation next is [1.0, 0.4782608695652174, 0.6419753086419752, 0.6533333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.05370877800194833, 0.0, 0.8094504844054917, 0.7690709892439948, 0.6708449209504415, 0.7350100565438835], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1418931], dtype=float32), -0.61283255]. 
=============================================
[2019-03-23 20:59:50,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7021898e-19 1.0000000e+00 3.1283786e-29 4.1972738e-33 1.5568731e-32], sum to 1.0000
[2019-03-23 20:59:50,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9085
[2019-03-23 20:59:50,212] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.6487855582465132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762235.8111109334, 762235.8111109334, 167746.8049593535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4344600.0000, 
sim time next is 4345200.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.6506267184630743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761888.3875786936, 761888.3875786936, 167973.6770431093], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 0.89, 1.0, 1.0, 0.5840794267417551, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2721029955638191, 0.2721029955638191, 0.3230263020059794], 
reward next is 0.6770, 
noisyNet noise sample is [array([0.7156925], dtype=float32), 0.5485009]. 
=============================================
[2019-03-23 20:59:54,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.076078e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 20:59:54,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8094
[2019-03-23 20:59:54,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 76.33333333333334, 1.0, 2.0, 0.632328222919329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 723774.7210932643, 723774.7210932638, 163883.7900131957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444800.0000, 
sim time next is 4445400.0000, 
raw observation next is [26.83333333333334, 75.66666666666666, 1.0, 2.0, 0.6244921035614616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 716911.2848146536, 716911.2848146531, 162598.956417706], 
processed observation next is [0.0, 0.43478260869565216, 0.5493827160493829, 0.7566666666666666, 1.0, 1.0, 0.5529667899541209, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.256039744576662, 0.25603974457666184, 0.3126903008032808], 
reward next is 0.6873, 
noisyNet noise sample is [array([-0.653515], dtype=float32), -1.3702112]. 
=============================================
[2019-03-23 20:59:59,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0718536e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 20:59:59,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7547
[2019-03-23 20:59:59,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2036558.910480379 W.
[2019-03-23 20:59:59,431] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666666, 79.83333333333334, 1.0, 2.0, 0.5951771500743801, 1.0, 2.0, 0.5951771500743801, 1.0, 1.0, 0.9475414064849538, 6.911200000000001, 6.9112, 121.94756008, 2036558.910480379, 2036558.910480378, 392754.1184786238], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4726200.0000, 
sim time next is 4726800.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.617175143580761, 1.0, 2.0, 0.617175143580761, 1.0, 2.0, 0.9825629285717445, 6.911199999999999, 6.9112, 121.94756008, 2111919.966828773, 2111919.966828773, 404812.8799827058], 
processed observation next is [1.0, 0.7391304347826086, 0.6222222222222222, 0.79, 1.0, 1.0, 0.5442561233104297, 1.0, 1.0, 0.5442561233104297, 1.0, 1.0, 0.9782036607146807, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.754257131010276, 0.754257131010276, 0.7784863076590496], 
reward next is 0.2215, 
noisyNet noise sample is [array([-0.64493436], dtype=float32), 1.7223048]. 
=============================================
[2019-03-23 21:00:05,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3031174e-21 1.0000000e+00 1.4579283e-33 0.0000000e+00 1.6223807e-37], sum to 1.0000
[2019-03-23 21:00:05,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5184
[2019-03-23 21:00:05,924] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.6947271333229492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791789.2971734446, 791789.2971734442, 175148.961310586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.704287482935535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802691.0538926995, 802691.0538926995, 176958.6975358216], 
processed observation next is [1.0, 0.8695652173913043, 0.5222222222222223, 0.92, 1.0, 1.0, 0.6479612892089702, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2866753763902498, 0.2866753763902498, 0.34030518756888767], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.5711594], dtype=float32), 0.28592607]. 
=============================================
[2019-03-23 21:00:09,032] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 21:00:09,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:00:09,036] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:00:09,037] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:00:09,040] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:00:09,041] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:00:09,042] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:00:09,043] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:00:09,044] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:00:09,044] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:00:09,046] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:00:09,060] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 21:00:09,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 21:00:09,061] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 21:00:09,085] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 21:00:09,111] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 21:00:16,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:00:16,233] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.9061501, 75.93759107, 1.0, 2.0, 0.4189007988832095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538051.8498443268, 538051.8498443273, 131526.8114028494]
[2019-03-23 21:00:16,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:00:16,241] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.2883293630207585
[2019-03-23 21:00:33,859] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:00:33,861] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.0, 88.0, 1.0, 2.0, 0.3672044262264405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459425.1432761964, 459425.1432761964, 124183.5056556453]
[2019-03-23 21:00:33,862] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:00:33,864] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.09235406023011528
[2019-03-23 21:00:40,211] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:00:40,211] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 43.66666666666667, 1.0, 2.0, 0.4838813999877868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578088.184625848, 578088.1846258484, 140420.4638463241]
[2019-03-23 21:00:40,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:00:40,217] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.8374170734583624
[2019-03-23 21:00:43,229] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:00:43,230] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.5, 67.66666666666667, 1.0, 2.0, 0.6387057482220542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 744465.9789587937, 744465.9789587932, 165656.4886362249]
[2019-03-23 21:00:43,230] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:00:43,235] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.18659639469882516
[2019-03-23 21:00:44,221] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:00:44,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 44.0, 1.0, 2.0, 0.8233188867744357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 951141.9322780285, 951141.9322780285, 201466.6996905287]
[2019-03-23 21:00:44,224] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:00:44,227] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.47466164031826996
[2019-03-23 21:01:47,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32804024]
[2019-03-23 21:01:47,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.55, 43.5, 1.0, 2.0, 0.9619401017751205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.058418043169256, 6.9112, 121.9254407661932, 1199445.974745094, 1124057.550576072, 233147.8066355376]
[2019-03-23 21:01:47,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:01:47,482] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7243262e-14 1.0000000e+00 1.2905477e-21 4.9988423e-24 1.3424986e-23], sampled 0.7928694806260035
[2019-03-23 21:01:54,715] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:01:54,725] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:01:54,778] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:01:54,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:01:54,987] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:01:56,002] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 550000, evaluation results [550000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:02:00,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9621433e-14 1.0000000e+00 6.2655367e-22 3.5889593e-23 7.1379883e-23], sum to 1.0000
[2019-03-23 21:02:00,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4072
[2019-03-23 21:02:00,869] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7468900885006622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851273.0914597898, 851273.0914597898, 185214.3386002095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4825800.0000, 
sim time next is 4826400.0000, 
raw observation next is [26.4, 92.66666666666667, 1.0, 2.0, 0.742228970264539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 845957.6181469194, 845957.618146919, 184295.4680569069], 
processed observation next is [1.0, 0.8695652173913043, 0.5333333333333333, 0.9266666666666667, 1.0, 1.0, 0.6931297265054036, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3021277207667569, 0.30212772076675676, 0.35441436164789786], 
reward next is 0.6456, 
noisyNet noise sample is [array([-0.10890341], dtype=float32), -0.3246786]. 
=============================================
[2019-03-23 21:02:01,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8105754e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:02:01,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4964
[2019-03-23 21:02:01,791] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 97.33333333333333, 1.0, 2.0, 0.7078710132406543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806777.4272089533, 806777.4272089533, 177640.6275622077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4837200.0000, 
sim time next is 4837800.0000, 
raw observation next is [25.18333333333334, 98.66666666666667, 1.0, 2.0, 0.7070792773449115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805874.5926069357, 805874.5926069357, 177489.6666104037], 
processed observation next is [1.0, 1.0, 0.4882716049382719, 0.9866666666666667, 1.0, 1.0, 0.6512848539820375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.287812354502477, 0.287812354502477, 0.34132628194308406], 
reward next is 0.6587, 
noisyNet noise sample is [array([0.16701043], dtype=float32), 0.10125374]. 
=============================================
[2019-03-23 21:02:01,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1498453e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:02:01,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4518
[2019-03-23 21:02:01,870] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 92.0, 1.0, 2.0, 0.7099768805747595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809178.8012085373, 809178.8012085373, 178042.6388841437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [25.91666666666667, 93.33333333333334, 1.0, 2.0, 0.7102163936568184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 809451.9245349576, 809451.9245349572, 178088.3769715219], 
processed observation next is [1.0, 1.0, 0.5154320987654323, 0.9333333333333335, 1.0, 1.0, 0.6550195162581172, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28908997304819917, 0.289089973048199, 0.3424776480221575], 
reward next is 0.6575, 
noisyNet noise sample is [array([0.38756153], dtype=float32), 0.74932563]. 
=============================================
[2019-03-23 21:02:16,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3092976e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:02:16,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8730
[2019-03-23 21:02:16,767] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 92.33333333333334, 1.0, 2.0, 0.8161782652675524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930292.6957894792, 930292.6957894792, 199314.5011193809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5131200.0000, 
sim time next is 5131800.0000, 
raw observation next is [28.0, 91.5, 1.0, 2.0, 0.8377181083907039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954859.4400086326, 954859.4400086326, 203866.607443901], 
processed observation next is [0.0, 0.391304347826087, 0.5925925925925926, 0.915, 1.0, 1.0, 0.8068072718936952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34102122857451167, 0.34102122857451167, 0.3920511681613481], 
reward next is 0.6079, 
noisyNet noise sample is [array([-0.5388472], dtype=float32), -1.4530202]. 
=============================================
[2019-03-23 21:02:20,768] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9441838e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:02:20,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3315
[2019-03-23 21:02:20,779] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 86.83333333333333, 1.0, 2.0, 0.6728394217537006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766831.1173301353, 766831.1173301353, 171063.2179745071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5176200.0000, 
sim time next is 5176800.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.6657718352857979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758772.2439960912, 758772.2439960912, 169762.4330794841], 
processed observation next is [0.0, 0.9565217391304348, 0.5037037037037038, 0.87, 1.0, 1.0, 0.602109327721188, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2709900871414611, 0.2709900871414611, 0.3264662174605463], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.5097721], dtype=float32), -2.5242577]. 
=============================================
[2019-03-23 21:02:30,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.889649e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:02:30,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4975
[2019-03-23 21:02:30,482] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 83.0, 1.0, 2.0, 0.6035446300374061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694652.2493718094, 694652.2493718094, 159022.449344085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5359200.0000, 
sim time next is 5359800.0000, 
raw observation next is [25.56666666666667, 83.5, 1.0, 2.0, 0.6032006182659523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694169.1803942021, 694169.1803942021, 158958.7138524874], 
processed observation next is [1.0, 0.0, 0.5024691358024692, 0.835, 1.0, 1.0, 0.5276197836499432, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24791756442650076, 0.24791756442650076, 0.3056898343317065], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.63895875], dtype=float32), 1.5263917]. 
=============================================
[2019-03-23 21:02:32,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0019425e-09 1.0000000e+00 2.1932526e-14 9.9502654e-16 5.5739548e-16], sum to 1.0000
[2019-03-23 21:02:32,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6338
[2019-03-23 21:02:33,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2435092.207739254 W.
[2019-03-23 21:02:33,012] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 72.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.121653116417416, 6.9112, 121.924945786084, 2435092.207739254, 2327322.371538489, 443048.8574090758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5418000.0000, 
sim time next is 5418600.0000, 
raw observation next is [29.93333333333333, 72.5, 1.0, 2.0, 0.3318048441647352, 1.0, 2.0, 0.3318048441647352, 1.0, 1.0, 0.5282441180396178, 6.911199999999999, 6.9112, 121.94756008, 1134740.107835419, 1134740.10783542, 268499.1474911755], 
processed observation next is [1.0, 0.7391304347826086, 0.6641975308641974, 0.725, 1.0, 1.0, 0.20452957638658956, 1.0, 1.0, 0.20452957638658956, 1.0, 0.5, 0.4103051475495222, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.40526432422693537, 0.4052643242269357, 0.5163445144061067], 
reward next is 0.4837, 
noisyNet noise sample is [array([-0.3626761], dtype=float32), -1.3124422]. 
=============================================
[2019-03-23 21:02:39,547] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6419945e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:02:39,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-23 21:02:39,564] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.88333333333333, 90.16666666666667, 1.0, 2.0, 0.6887497913108003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 784973.3565493103, 784973.3565493098, 174024.7013023535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5526600.0000, 
sim time next is 5527200.0000, 
raw observation next is [25.86666666666667, 90.33333333333334, 1.0, 2.0, 0.6872504383905208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783263.6595596975, 783263.6595596975, 173744.0494788332], 
processed observation next is [1.0, 1.0, 0.5135802469135804, 0.9033333333333334, 1.0, 1.0, 0.6276790933220485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27973702127132055, 0.27973702127132055, 0.33412317207467923], 
reward next is 0.6659, 
noisyNet noise sample is [array([-0.40719956], dtype=float32), -0.17997581]. 
=============================================
[2019-03-23 21:02:46,175] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 21:02:46,177] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:02:46,177] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:02:46,177] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:02:46,178] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:02:46,179] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:02:46,180] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:02:46,180] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:02:46,179] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:02:46,183] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:02:46,184] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:02:46,198] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 21:02:46,198] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 21:02:46,198] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 21:02:46,268] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 21:02:46,269] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 21:02:53,635] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:02:53,636] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 43.0, 1.0, 2.0, 0.9379008978472226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.340227029207621, 6.9112, 121.9240586701024, 1396044.838956129, 1176348.228899416, 230439.7342788761]
[2019-03-23 21:02:53,637] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:02:53,639] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2459480174370593
[2019-03-23 21:02:53,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1396044.838956129 W.
[2019-03-23 21:02:54,499] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:02:54,500] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.11666666666667, 73.5, 1.0, 2.0, 0.3703968605895649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472470.4378310322, 472470.4378310322, 124715.391196053]
[2019-03-23 21:02:54,503] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:02:54,507] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6343571191925593
[2019-03-23 21:03:03,538] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:03,538] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.0, 19.0, 1.0, 2.0, 0.4350886992763621, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7209037117266148, 6.911200000000001, 6.9112, 121.9258653778298, 1077257.927960091, 1077257.927960091, 231449.0660398562]
[2019-03-23 21:03:03,539] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:03:03,541] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3651053557989219
[2019-03-23 21:03:13,779] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:13,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.4, 90.33333333333334, 1.0, 2.0, 0.4068115306191039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504454.3368533917, 504454.3368533917, 129591.8647321439]
[2019-03-23 21:03:13,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:13,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8706934792422859
[2019-03-23 21:03:16,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:16,414] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.75, 63.0, 1.0, 2.0, 0.5818130915801195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672335.3337058633, 672335.3337058633, 155426.1260833915]
[2019-03-23 21:03:16,414] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:16,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9597682477269911
[2019-03-23 21:03:25,964] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:25,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.2, 60.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.049621895369725, 6.9112, 121.9218573612501, 2461643.482392149, 1878689.732226544, 380043.5724283737]
[2019-03-23 21:03:25,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:25,971] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9764504014258306
[2019-03-23 21:03:25,971] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2461643.482392149 W.
[2019-03-23 21:03:39,778] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:39,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 94.0, 1.0, 2.0, 0.7382074860838717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841371.6040876328, 841371.6040876328, 183504.983435629]
[2019-03-23 21:03:39,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:39,783] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2286523582526494
[2019-03-23 21:03:47,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:47,522] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.4793053141476246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 578328.5812437377, 578328.5812437373, 139914.1190240014]
[2019-03-23 21:03:47,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:47,527] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8849211182323573
[2019-03-23 21:03:49,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.33520496]
[2019-03-23 21:03:49,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.80353660333333, 90.54092441333334, 1.0, 2.0, 0.585560900359333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710469.7437793516, 710469.7437793516, 157403.3343657684]
[2019-03-23 21:03:49,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:03:49,585] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.990917e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9863382476245364
[2019-03-23 21:04:24,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:04:24,523] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:04:24,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:04:24,722] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:04:24,922] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:04:25,937] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 575000, evaluation results [575000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:04:29,504] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1210092e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:29,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1593
[2019-03-23 21:04:29,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 95.0, 1.0, 2.0, 0.4575245076001414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556799.0029587015, 556799.0029587015, 136751.395700289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5721600.0000, 
sim time next is 5722200.0000, 
raw observation next is [21.1, 94.5, 1.0, 2.0, 0.4558469126587386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554992.8537276682, 554992.8537276682, 136506.2066013765], 
processed observation next is [0.0, 0.21739130434782608, 0.3370370370370371, 0.945, 1.0, 1.0, 0.35219870554611743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1982117334741672, 0.1982117334741672, 0.26251193577187787], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.11163], dtype=float32), -0.04749551]. 
=============================================
[2019-03-23 21:04:30,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3073407e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:30,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1047
[2019-03-23 21:04:30,425] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 83.0, 1.0, 2.0, 0.4363861488584428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533156.7657907709, 533156.7657907704, 133670.593158254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5733600.0000, 
sim time next is 5734200.0000, 
raw observation next is [22.58333333333333, 82.0, 1.0, 2.0, 0.4430735809690162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540644.6661157018, 540644.6661157018, 134637.352041851], 
processed observation next is [0.0, 0.34782608695652173, 0.3919753086419751, 0.82, 1.0, 1.0, 0.3369923582964479, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19308738075560777, 0.19308738075560777, 0.2589179846958673], 
reward next is 0.7411, 
noisyNet noise sample is [array([-1.09688], dtype=float32), 1.3187554]. 
=============================================
[2019-03-23 21:04:31,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.140956e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:04:31,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3512
[2019-03-23 21:04:31,391] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 68.5, 1.0, 2.0, 0.5953871079098836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686856.5603912566, 686856.5603912566, 157690.6950133212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5765400.0000, 
sim time next is 5766000.0000, 
raw observation next is [27.63333333333333, 69.0, 1.0, 2.0, 0.5917000262327827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683681.1761705457, 683681.1761705457, 157108.4311178991], 
processed observation next is [0.0, 0.7391304347826086, 0.5790123456790122, 0.69, 1.0, 1.0, 0.5139286026580746, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24417184863233776, 0.24417184863233776, 0.3021315983036521], 
reward next is 0.6979, 
noisyNet noise sample is [array([0.48529428], dtype=float32), 0.42436507]. 
=============================================
[2019-03-23 21:04:31,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.502182]
 [63.502182]
 [63.502182]
 [63.502182]
 [63.502182]], R is [[63.56502914]
 [63.62612534]
 [63.68550873]
 [63.74333954]
 [63.80026245]].
[2019-03-23 21:04:33,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1343906e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:33,695] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4928
[2019-03-23 21:04:33,700] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 78.83333333333333, 1.0, 2.0, 0.4834153855524796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586468.9733059745, 586468.9733059745, 140650.8318424452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817000.0000, 
sim time next is 5817600.0000, 
raw observation next is [23.5, 78.0, 1.0, 2.0, 0.5015690723484025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608338.4231012223, 608338.4231012223, 143488.0198972076], 
processed observation next is [1.0, 0.34782608695652173, 0.42592592592592593, 0.78, 1.0, 1.0, 0.4066298480338125, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2172637225361508, 0.2172637225361508, 0.27593849980232227], 
reward next is 0.7241, 
noisyNet noise sample is [array([1.2106771], dtype=float32), -0.8141716]. 
=============================================
[2019-03-23 21:04:40,488] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7580773e-19 1.0000000e+00 3.0767408e-30 1.2479988e-32 5.0355498e-32], sum to 1.0000
[2019-03-23 21:04:40,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1448
[2019-03-23 21:04:40,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1322357.922543919 W.
[2019-03-23 21:04:40,510] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.55, 42.5, 1.0, 2.0, 0.5501377501786117, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8889195299213591, 6.911199999999997, 6.9112, 121.9260426156618, 1322357.922543919, 1322357.922543921, 273092.3079126509], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5926200.0000, 
sim time next is 5926800.0000, 
raw observation next is [29.5, 43.0, 1.0, 2.0, 0.5332222579285231, 1.0, 1.0, 0.5332222579285231, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1276241.785650955, 1276241.785650955, 248468.0601334395], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.43, 1.0, 1.0, 0.4443122118196703, 1.0, 0.5, 0.4443122118196703, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.45580063773248397, 0.45580063773248397, 0.4778231925643067], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61447185], dtype=float32), 1.0885379]. 
=============================================
[2019-03-23 21:04:47,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4646228e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:47,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5649
[2019-03-23 21:04:47,109] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 89.0, 1.0, 2.0, 0.4984896812392379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596445.4925761998, 596445.4925761998, 142726.8620893711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6053400.0000, 
sim time next is 6054000.0000, 
raw observation next is [22.66666666666666, 89.66666666666667, 1.0, 2.0, 0.4978324332559956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596156.4978418098, 596156.4978418098, 142641.519422304], 
processed observation next is [1.0, 0.043478260869565216, 0.3950617283950615, 0.8966666666666667, 1.0, 1.0, 0.4021814681618995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2129130349435035, 0.2129130349435035, 0.27431061427366155], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.18373522], dtype=float32), 0.78874546]. 
=============================================
[2019-03-23 21:04:47,127] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.475136]
 [75.475136]
 [75.475136]
 [75.475136]
 [75.475136]], R is [[75.44607544]
 [75.41713715]
 [75.38824463]
 [75.35906219]
 [75.32969666]].
[2019-03-23 21:04:47,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0197553e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:47,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0961
[2019-03-23 21:04:48,002] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 88.5, 1.0, 2.0, 0.5253728961463476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628448.1993775689, 628448.1993775689, 147005.3522601151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [22.96666666666667, 88.33333333333334, 1.0, 2.0, 0.5241998220515287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626560.0570535586, 626560.0570535591, 146798.1455468492], 
processed observation next is [1.0, 0.13043478260869565, 0.4061728395061729, 0.8833333333333334, 1.0, 1.0, 0.43357121672801036, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22377144894769951, 0.22377144894769968, 0.2823041260516331], 
reward next is 0.7177, 
noisyNet noise sample is [array([-0.5013666], dtype=float32), 0.47116068]. 
=============================================
[2019-03-23 21:04:49,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4544666e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:49,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-23 21:04:49,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1745516.586503033 W.
[2019-03-23 21:04:49,057] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 62.66666666666666, 1.0, 2.0, 0.5102040782831982, 1.0, 1.0, 0.5102040782831982, 1.0, 2.0, 0.812261508813645, 6.911200000000001, 6.9112, 121.94756008, 1745516.586503033, 1745516.586503032, 348625.5626674684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6086400.0000, 
sim time next is 6087000.0000, 
raw observation next is [28.3, 63.83333333333334, 1.0, 2.0, 0.7692739643926712, 1.0, 2.0, 0.7692739643926712, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1754575.675408055, 1754575.675408055, 331220.105855362], 
processed observation next is [1.0, 0.43478260869565216, 0.6037037037037037, 0.6383333333333334, 1.0, 1.0, 0.7253261480865133, 1.0, 1.0, 0.7253261480865133, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6266341697885911, 0.6266341697885911, 0.6369617420295424], 
reward next is 0.3630, 
noisyNet noise sample is [array([-0.26228052], dtype=float32), -0.5226082]. 
=============================================
[2019-03-23 21:04:49,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[59.14805]
 [59.14805]
 [59.14805]
 [59.14805]
 [59.14805]], R is [[58.91960526]
 [58.33041   ]
 [57.74710464]
 [57.57360077]
 [57.27651978]].
[2019-03-23 21:04:56,968] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.845102e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:04:56,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-23 21:04:56,979] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 73.33333333333333, 1.0, 2.0, 0.4994065819194118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597530.7690800518, 597530.7690800518, 142870.5065206116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6219600.0000, 
sim time next is 6220200.0000, 
raw observation next is [24.96666666666667, 73.66666666666667, 1.0, 2.0, 0.4986009729511823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596714.564151352, 596714.5641513516, 142749.2572320183], 
processed observation next is [1.0, 1.0, 0.48024691358024696, 0.7366666666666667, 1.0, 1.0, 0.40309639637045513, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21311234433976858, 0.21311234433976842, 0.274517802369266], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.47865817], dtype=float32), 1.657597]. 
=============================================
[2019-03-23 21:04:57,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.940408e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:04:57,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9083
[2019-03-23 21:04:57,275] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 82.0, 1.0, 2.0, 0.5234428896076553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620369.8874552537, 620369.8874552537, 146476.4672036263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6249600.0000, 
sim time next is 6250200.0000, 
raw observation next is [24.45, 81.66666666666667, 1.0, 2.0, 0.52710024936154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 623702.0935820583, 623702.0935820579, 147026.8696770885], 
processed observation next is [0.0, 0.34782608695652173, 0.4611111111111111, 0.8166666666666668, 1.0, 1.0, 0.43702410638278566, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22275074770787798, 0.2227507477078778, 0.28274398014824714], 
reward next is 0.7173, 
noisyNet noise sample is [array([-2.0340176], dtype=float32), -1.6390688]. 
=============================================
[2019-03-23 21:04:59,748] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5429443e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:04:59,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4283
[2019-03-23 21:04:59,763] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 71.0, 1.0, 2.0, 0.5874088643644207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682800.1067577282, 682800.1067577282, 156561.3863486782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6296400.0000, 
sim time next is 6297000.0000, 
raw observation next is [26.83333333333333, 72.0, 1.0, 2.0, 0.5880175838920451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683662.2588360517, 683662.2588360517, 156672.5302765865], 
processed observation next is [0.0, 0.9130434782608695, 0.5493827160493825, 0.72, 1.0, 1.0, 0.509544742728625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24416509244144702, 0.24416509244144702, 0.30129332745497406], 
reward next is 0.6987, 
noisyNet noise sample is [array([-1.5262825], dtype=float32), 0.56103015]. 
=============================================
[2019-03-23 21:04:59,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.37572]
 [77.37572]
 [77.37572]
 [77.37572]
 [77.37572]], R is [[77.30067444]
 [77.22659302]
 [77.15271759]
 [77.07918549]
 [77.00616455]].
[2019-03-23 21:05:11,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.773358e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:05:11,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8712
[2019-03-23 21:05:11,679] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 87.83333333333334, 1.0, 2.0, 0.7847186547973828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 894413.6171797388, 894413.6171797388, 192801.0884296406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6504600.0000, 
sim time next is 6505200.0000, 
raw observation next is [26.3, 88.0, 1.0, 2.0, 0.839449372803659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 956834.0257239458, 956834.0257239458, 204223.5774305693], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.88, 1.0, 1.0, 0.808868300956737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3417264377585521, 0.3417264377585521, 0.39273764890494095], 
reward next is 0.6073, 
noisyNet noise sample is [array([0.01871324], dtype=float32), 0.20725797]. 
=============================================
[2019-03-23 21:05:12,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.883394e-23 1.000000e+00 8.490778e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:05:12,129] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2562
[2019-03-23 21:05:12,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1983742.601480934 W.
[2019-03-23 21:05:12,144] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.1, 85.0, 1.0, 2.0, 0.5797588922627226, 1.0, 1.0, 0.5797588922627226, 1.0, 2.0, 0.9229950379111943, 6.911200000000001, 6.9112, 121.94756008, 1983742.601480934, 1983742.601480933, 384457.5375660536], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6512400.0000, 
sim time next is 6513000.0000, 
raw observation next is [27.23333333333333, 84.50000000000001, 1.0, 2.0, 0.5831827968536288, 1.0, 2.0, 0.5831827968536288, 1.0, 2.0, 0.9284460055287047, 6.911200000000001, 6.9112, 121.94756008, 1995471.153806014, 1995471.153806014, 386288.8774565379], 
processed observation next is [1.0, 0.391304347826087, 0.5641975308641974, 0.8450000000000002, 1.0, 1.0, 0.5037890438733676, 1.0, 1.0, 0.5037890438733676, 1.0, 1.0, 0.9105575069108809, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7126682692164336, 0.7126682692164336, 0.7428632258779575], 
reward next is 0.2571, 
noisyNet noise sample is [array([-0.6751435], dtype=float32), 0.06612459]. 
=============================================
[2019-03-23 21:05:12,158] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[54.362865]
 [54.362865]
 [54.362865]
 [54.362865]
 [54.362865]], R is [[54.07637405]
 [53.79626846]
 [53.2583046 ]
 [52.72572327]
 [52.19846725]].
[2019-03-23 21:05:12,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6492437e-16 1.0000000e+00 2.3352432e-26 8.2968803e-29 1.2000224e-27], sum to 1.0000
[2019-03-23 21:05:12,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7393
[2019-03-23 21:05:12,654] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1740666.763193168 W.
[2019-03-23 21:05:12,663] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.56666666666667, 87.66666666666667, 1.0, 2.0, 0.8996340616422597, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9258295725462, 1740666.763193168, 1740666.763193168, 356888.4934588072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [26.7, 87.0, 1.0, 2.0, 0.9792365667660776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.926042550699, 1831538.627381148, 1831538.627381147, 374625.5172658609], 
processed observation next is [1.0, 0.34782608695652173, 0.5444444444444444, 0.87, 1.0, 1.0, 0.9752816271024733, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621283888505, 0.65412093835041, 0.6541209383504096, 0.7204336870497325], 
reward next is 0.2796, 
noisyNet noise sample is [array([1.2182434], dtype=float32), 0.41533712]. 
=============================================
[2019-03-23 21:05:16,513] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 21:05:16,515] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:05:16,515] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:05:16,516] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:05:16,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:05:16,517] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:05:16,519] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:05:16,518] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:05:16,519] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:05:16,522] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:05:16,521] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:05:16,539] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 21:05:16,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 21:05:16,540] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 21:05:16,619] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 21:05:16,645] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 21:05:25,838] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2910717]
[2019-03-23 21:05:25,842] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.66666666666666, 26.0, 1.0, 2.0, 0.4005101874713278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500197.2931162513, 500197.2931162513, 128772.1954049971]
[2019-03-23 21:05:25,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:05:25,848] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.170623e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.08227362451166265
[2019-03-23 21:05:39,718] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2910717]
[2019-03-23 21:05:39,719] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 67.0, 1.0, 2.0, 0.4076980407893612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517894.5973869919, 517894.5973869919, 129905.679601228]
[2019-03-23 21:05:39,720] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:05:39,722] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.170623e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4230777926394369
[2019-03-23 21:06:22,010] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2910717]
[2019-03-23 21:06:22,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.72433033, 109.384932, 1.0, 2.0, 0.7455713465342001, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9254928651343, 1564817.108856494, 1564817.108856494, 325694.496510572]
[2019-03-23 21:06:22,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:06:22,016] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.170623e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9289290156022568
[2019-03-23 21:06:22,016] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1564817.108856494 W.
[2019-03-23 21:06:38,888] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2910717]
[2019-03-23 21:06:38,889] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.13333333333333, 72.5, 1.0, 2.0, 0.6604074980026644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 752655.571049154, 752655.5710491536, 168782.7773892712]
[2019-03-23 21:06:38,892] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:06:38,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.170623e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.141418769790693
[2019-03-23 21:06:54,832] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:06:54,983] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:06:55,006] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:06:55,156] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:06:55,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:06:56,434] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 600000, evaluation results [600000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:07:01,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.398164e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:07:01,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-23 21:07:02,003] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 30.33333333333334, 1.0, 2.0, 0.7182078652995748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911614.2323371973, 911614.2323371973, 182822.4206928058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700800.0000, 
sim time next is 6701400.0000, 
raw observation next is [29.25, 30.0, 1.0, 2.0, 0.799248928766363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013766.533953812, 1013766.533953812, 199457.2715527619], 
processed observation next is [1.0, 0.5652173913043478, 0.6388888888888888, 0.3, 1.0, 1.0, 0.7610106294837654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3620594764120757, 0.3620594764120757, 0.38357167606300363], 
reward next is 0.6164, 
noisyNet noise sample is [array([0.5201777], dtype=float32), -1.0729711]. 
=============================================
[2019-03-23 21:07:05,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5987063e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:05,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8659
[2019-03-23 21:07:05,566] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 58.5, 1.0, 2.0, 0.7459997831276461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944073.039357731, 944073.039357731, 188368.8666361735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6769800.0000, 
sim time next is 6770400.0000, 
raw observation next is [23.33333333333334, 58.0, 1.0, 2.0, 0.7632835497382564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 964826.2721790615, 964826.2721790615, 191891.143111451], 
processed observation next is [1.0, 0.34782608695652173, 0.4197530864197533, 0.58, 1.0, 1.0, 0.7181947020693529, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34458081149252195, 0.34458081149252195, 0.3690214290604827], 
reward next is 0.6310, 
noisyNet noise sample is [array([0.13421103], dtype=float32), -0.740474]. 
=============================================
[2019-03-23 21:07:07,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6140095e-25 1.0000000e+00 2.0212035e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:07,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6376
[2019-03-23 21:07:07,645] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 58.5, 1.0, 2.0, 0.4637740042349329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554913.0006879375, 554913.0006879375, 137382.8959198511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6802200.0000, 
sim time next is 6802800.0000, 
raw observation next is [27.43333333333334, 59.33333333333333, 1.0, 2.0, 0.4683843211911041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560584.5781229235, 560584.5781229235, 138085.9698369269], 
processed observation next is [1.0, 0.7391304347826086, 0.5716049382716052, 0.5933333333333333, 1.0, 1.0, 0.3671241918941716, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2002087779010441, 0.2002087779010441, 0.2655499419940902], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.76152813], dtype=float32), 1.0486946]. 
=============================================
[2019-03-23 21:07:08,751] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.159823e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:07:08,757] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4725
[2019-03-23 21:07:08,760] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 76.0, 1.0, 2.0, 0.3929493180065292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 487916.6495157832, 487916.6495157827, 127653.0166893971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6837000.0000, 
sim time next is 6837600.0000, 
raw observation next is [22.1, 76.0, 1.0, 2.0, 0.3899290640037172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484484.0206114715, 484484.0206114715, 127238.6914447294], 
processed observation next is [0.0, 0.13043478260869565, 0.3740740740740741, 0.76, 1.0, 1.0, 0.27372507619490144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17303000736123983, 0.17303000736123983, 0.24468979123986423], 
reward next is 0.7553, 
noisyNet noise sample is [array([1.0823047], dtype=float32), -0.11651211]. 
=============================================
[2019-03-23 21:07:09,825] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4693114e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:09,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1663
[2019-03-23 21:07:09,837] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 76.0, 1.0, 2.0, 0.3787657304473463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472067.1020864274, 472067.1020864274, 125725.7767264719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840600.0000, 
sim time next is 6841200.0000, 
raw observation next is [21.83333333333334, 76.0, 1.0, 2.0, 0.3776883484977536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470924.6257695958, 470924.6257695958, 125581.892276624], 
processed observation next is [0.0, 0.17391304347826086, 0.36419753086419776, 0.76, 1.0, 1.0, 0.2591527958306591, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1681873663462842, 0.1681873663462842, 0.24150363899350769], 
reward next is 0.7585, 
noisyNet noise sample is [array([-0.8154998], dtype=float32), -1.3315243]. 
=============================================
[2019-03-23 21:07:15,056] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1257969e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:15,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9874
[2019-03-23 21:07:15,068] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 74.5, 1.0, 2.0, 0.4152814203104522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511761.0708367186, 511761.0708367186, 130726.7361765173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6917400.0000, 
sim time next is 6918000.0000, 
raw observation next is [22.9, 75.0, 1.0, 2.0, 0.4168259855270609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513497.7399163669, 513497.7399163673, 130944.3274223465], 
processed observation next is [0.0, 0.043478260869565216, 0.4037037037037037, 0.75, 1.0, 1.0, 0.30574522086554873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18339204997013103, 0.18339204997013117, 0.2518160142737433], 
reward next is 0.7482, 
noisyNet noise sample is [array([-0.40407836], dtype=float32), 1.1625499]. 
=============================================
[2019-03-23 21:07:15,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.37016]
 [79.37016]
 [79.37016]
 [79.37016]
 [79.37016]], R is [[79.32465363]
 [79.28001404]
 [79.23612976]
 [79.19283295]
 [79.15014648]].
[2019-03-23 21:07:16,036] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2958858e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:16,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4018
[2019-03-23 21:07:16,046] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666666, 44.83333333333334, 1.0, 2.0, 0.5224699979843507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619433.0178980189, 619433.0178980189, 146328.1682468381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6972600.0000, 
sim time next is 6973200.0000, 
raw observation next is [31.2, 44.0, 1.0, 2.0, 0.5148503194355282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612064.994449293, 612064.994449293, 145172.3183029748], 
processed observation next is [0.0, 0.7391304347826086, 0.7111111111111111, 0.44, 1.0, 1.0, 0.4224408564708668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185946408747475, 0.2185946408747475, 0.27917753519802846], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.12412994], dtype=float32), 0.04154055]. 
=============================================
[2019-03-23 21:07:18,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.137064e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:07:18,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5612
[2019-03-23 21:07:18,655] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 56.33333333333333, 1.0, 2.0, 0.4550790773991935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554124.751017767, 554124.7510177674, 136392.8242395249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6982800.0000, 
sim time next is 6983400.0000, 
raw observation next is [26.56666666666667, 57.16666666666667, 1.0, 2.0, 0.4519061300065996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551063.4179216876, 551063.4179216876, 135941.1237885947], 
processed observation next is [0.0, 0.8260869565217391, 0.5395061728395063, 0.5716666666666668, 1.0, 1.0, 0.3475072976269043, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19680836354345985, 0.19680836354345985, 0.2614252380549898], 
reward next is 0.7386, 
noisyNet noise sample is [array([0.32653138], dtype=float32), 0.257519]. 
=============================================
[2019-03-23 21:07:20,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.62605e-26 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:07:20,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6148
[2019-03-23 21:07:20,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1439891.728304334 W.
[2019-03-23 21:07:20,245] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.03333333333333, 68.66666666666667, 1.0, 2.0, 0.4182183420824778, 1.0, 2.0, 0.4182183420824778, 1.0, 2.0, 0.6661058023548407, 6.9112, 6.9112, 121.94756008, 1439891.728304334, 1439891.728304334, 305212.1262169198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7040400.0000, 
sim time next is 7041000.0000, 
raw observation next is [26.21666666666667, 67.83333333333333, 1.0, 2.0, 0.6294190273559046, 1.0, 2.0, 0.6294190273559046, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1459596.667094653, 1459596.667094653, 279490.7888724439], 
processed observation next is [1.0, 0.4782608695652174, 0.5265432098765432, 0.6783333333333332, 1.0, 1.0, 0.5588321754236959, 1.0, 1.0, 0.5588321754236959, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5212845239623761, 0.5212845239623761, 0.5374822862931613], 
reward next is 0.4625, 
noisyNet noise sample is [array([0.96257937], dtype=float32), 1.0245078]. 
=============================================
[2019-03-23 21:07:20,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.273335]
 [55.273335]
 [55.273335]
 [55.273335]
 [55.273335]], R is [[55.1831131 ]
 [55.04433823]
 [54.49389648]
 [54.38649368]
 [54.25111008]].
[2019-03-23 21:07:25,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.118418e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:07:25,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8712
[2019-03-23 21:07:25,635] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 66.66666666666666, 1.0, 2.0, 0.442398490181982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550392.9098621198, 550392.9098621198, 134800.3415686523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7130400.0000, 
sim time next is 7131000.0000, 
raw observation next is [23.43333333333333, 65.83333333333334, 1.0, 2.0, 0.4201769311248644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523262.9596670049, 523262.9596670049, 131554.0619825697], 
processed observation next is [1.0, 0.5217391304347826, 0.42345679012345666, 0.6583333333333334, 1.0, 1.0, 0.3097344418153148, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18687962845250175, 0.18687962845250175, 0.25298858073571096], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.08982488], dtype=float32), 0.63248765]. 
=============================================
[2019-03-23 21:07:25,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.44818]
 [66.44818]
 [66.44818]
 [66.44818]
 [66.44818]], R is [[66.53070831]
 [66.60617065]
 [66.65750122]
 [66.68986511]
 [66.64673615]].
[2019-03-23 21:07:30,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1749587e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:30,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6133
[2019-03-23 21:07:30,274] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 71.0, 1.0, 2.0, 0.4122549397799282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507119.8777894293, 507119.8777894293, 130270.3092187653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7234200.0000, 
sim time next is 7234800.0000, 
raw observation next is [23.53333333333333, 71.33333333333334, 1.0, 2.0, 0.4146392749199623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510172.9771919238, 510172.9771919238, 130614.4910130668], 
processed observation next is [1.0, 0.7391304347826086, 0.4271604938271604, 0.7133333333333334, 1.0, 1.0, 0.3031419939523361, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18220463471140136, 0.18220463471140136, 0.2511817134866669], 
reward next is 0.7488, 
noisyNet noise sample is [array([-0.31194878], dtype=float32), -0.22254434]. 
=============================================
[2019-03-23 21:07:32,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.246323e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:07:32,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9099
[2019-03-23 21:07:32,878] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.08333333333334, 76.66666666666667, 1.0, 2.0, 0.3880568060589423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481745.8387140298, 481745.8387140298, 126969.6802014052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7246200.0000, 
sim time next is 7246800.0000, 
raw observation next is [22.0, 77.0, 1.0, 2.0, 0.3868627766051802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480493.7768039011, 480493.7768039011, 126808.9920627649], 
processed observation next is [1.0, 0.9130434782608695, 0.37037037037037035, 0.77, 1.0, 1.0, 0.27007473405378596, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17160492028710755, 0.17160492028710755, 0.24386344627454787], 
reward next is 0.7561, 
noisyNet noise sample is [array([0.37553632], dtype=float32), -0.045184754]. 
=============================================
[2019-03-23 21:07:36,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2638844e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:36,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9168
[2019-03-23 21:07:36,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 84.33333333333334, 1.0, 2.0, 0.3795631430128835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473112.7410589083, 473112.7410589079, 125836.2528675191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7348800.0000, 
sim time next is 7349400.0000, 
raw observation next is [20.7, 84.0, 1.0, 2.0, 0.3763700407525273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469594.836089488, 469594.836089488, 125407.3035124976], 
processed observation next is [1.0, 0.043478260869565216, 0.3222222222222222, 0.84, 1.0, 1.0, 0.25758338184824675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16771244146053144, 0.16771244146053144, 0.24116789137018768], 
reward next is 0.7588, 
noisyNet noise sample is [array([1.3675586], dtype=float32), 0.771934]. 
=============================================
[2019-03-23 21:07:38,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7100467e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:07:38,183] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9873
[2019-03-23 21:07:38,193] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.5, 1.0, 2.0, 0.3742104515199112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468246.6175491394, 468246.6175491394, 125136.6258888526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7371000.0000, 
sim time next is 7371600.0000, 
raw observation next is [19.06666666666667, 95.33333333333333, 1.0, 2.0, 0.3800839823034168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475922.3056756972, 475922.3056756972, 125947.2367558805], 
processed observation next is [1.0, 0.30434782608695654, 0.2617283950617285, 0.9533333333333333, 1.0, 1.0, 0.26200474083740094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16997225202703473, 0.16997225202703473, 0.24220622453053942], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.5511033], dtype=float32), -1.8468053]. 
=============================================
[2019-03-23 21:07:46,690] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 21:07:46,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:07:46,693] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:07:46,693] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:07:46,695] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:07:46,698] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:07:46,698] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:07:46,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:07:46,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:07:46,703] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:07:46,705] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:07:46,722] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 21:07:46,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 21:07:46,767] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 21:07:46,789] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 21:07:46,812] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 21:08:17,387] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3403571]
[2019-03-23 21:08:17,388] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.25, 85.5, 1.0, 2.0, 0.3476412821669292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 435324.1696110572, 435324.1696110576, 121577.4686728754]
[2019-03-23 21:08:17,390] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:08:17,393] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.184781e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9620342233841268
[2019-03-23 21:08:17,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3403571]
[2019-03-23 21:08:17,862] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.33333333333334, 39.33333333333334, 1.0, 2.0, 0.4862545387620389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579871.6100503043, 579871.6100503043, 140748.914216075]
[2019-03-23 21:08:17,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:08:17,869] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.184781e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7805418062269874
[2019-03-23 21:08:39,604] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3403571]
[2019-03-23 21:08:39,604] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.21418528833333, 80.906654565, 1.0, 2.0, 0.6863125989195176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782194.2526229813, 782194.2526229813, 173568.5736314983]
[2019-03-23 21:08:39,604] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:08:39,607] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.184781e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7041803146112567
[2019-03-23 21:09:05,888] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3403571]
[2019-03-23 21:09:05,889] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 62.0, 1.0, 2.0, 0.6030275469234385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695137.4800165521, 695137.4800165521, 158983.9989776919]
[2019-03-23 21:09:05,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:09:05,892] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.184781e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7950425838400895
[2019-03-23 21:09:16,376] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3403571]
[2019-03-23 21:09:16,378] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.50385870333334, 55.64823131833333, 1.0, 2.0, 0.2389674507329427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 308244.0629736909, 308244.0629736909, 96354.09602716268]
[2019-03-23 21:09:16,379] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:09:16,383] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.184781e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.36731850633863194
[2019-03-23 21:09:25,217] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:09:25,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:09:25,687] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:09:25,749] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:09:25,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:09:26,893] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 625000, evaluation results [625000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:09:33,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5471257e-20 1.0000000e+00 5.2733646e-33 5.7925110e-36 6.5721212e-35], sum to 1.0000
[2019-03-23 21:09:33,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4850
[2019-03-23 21:09:33,485] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 68.0, 1.0, 2.0, 0.3867557176263466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479789.7150616497, 479789.7150616497, 126781.7055458143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7666800.0000, 
sim time next is 7667400.0000, 
raw observation next is [23.15, 68.5, 1.0, 2.0, 0.3843026552062534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477781.2269217097, 477781.2269217097, 126464.428328413], 
processed observation next is [1.0, 0.7391304347826086, 0.4129629629629629, 0.685, 1.0, 1.0, 0.267026970483635, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1706361524720392, 0.1706361524720392, 0.24320082370848656], 
reward next is 0.7568, 
noisyNet noise sample is [array([0.45713413], dtype=float32), -0.16568673]. 
=============================================
[2019-03-23 21:09:34,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.366465e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:09:34,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8311
[2019-03-23 21:09:34,818] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 87.0, 1.0, 2.0, 0.4028683367536679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502506.5080832604, 502506.5080832604, 129093.3776847009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7878000.0000, 
sim time next is 7878600.0000, 
raw observation next is [20.2, 87.5, 1.0, 2.0, 0.396583633784572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495147.9034393002, 495147.9034393002, 128216.2464715692], 
processed observation next is [1.0, 0.17391304347826086, 0.3037037037037037, 0.875, 1.0, 1.0, 0.2816471830768714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1768385369426072, 0.1768385369426072, 0.2465697047530177], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.12702668], dtype=float32), -0.5514378]. 
=============================================
[2019-03-23 21:09:36,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0327733e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:09:36,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6639
[2019-03-23 21:09:36,809] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.8829418887068472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1074009.642580007, 1074009.642580007, 216771.3845795502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7727400.0000, 
sim time next is 7728000.0000, 
raw observation next is [25.36666666666667, 65.66666666666667, 1.0, 2.0, 0.9088838366539338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946146455212061, 6.9112, 121.9258300999576, 1121121.476467588, 1103225.799112305, 222603.610592304], 
processed observation next is [1.0, 0.43478260869565216, 0.49506172839506185, 0.6566666666666667, 1.0, 1.0, 0.8915283769689688, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0034946455212060633, 0.0, 0.8094607179368608, 0.40040052730985287, 0.3940092139686804, 0.42808386652366154], 
reward next is 0.3972, 
noisyNet noise sample is [array([-0.7217114], dtype=float32), 0.26364765]. 
=============================================
[2019-03-23 21:09:36,828] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.723694]
 [73.723694]
 [73.723694]
 [73.723694]
 [73.723694]], R is [[73.38365173]
 [73.2329483 ]
 [73.09506989]
 [72.97103119]
 [72.85670471]].
[2019-03-23 21:09:36,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.352126e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:09:36,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4832
[2019-03-23 21:09:36,936] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 65.66666666666667, 1.0, 2.0, 0.9088838366539338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946146455212061, 6.9112, 121.9258300999576, 1121121.476467588, 1103225.799112305, 222603.610592304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7728000.0000, 
sim time next is 7728600.0000, 
raw observation next is [25.73333333333333, 64.33333333333333, 1.0, 2.0, 0.9267813153159952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.050831644067149, 6.9112, 121.9253857520995, 1194153.677009001, 1122650.180331436, 226666.1772000651], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.6433333333333333, 1.0, 1.0, 0.9128348991857085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.013963164406714856, 0.0, 0.8094577679291722, 0.42648345607464316, 0.4009464929755128, 0.43589649461550983], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5839119], dtype=float32), -1.1185987]. 
=============================================
[2019-03-23 21:09:38,074] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0902487e-23 1.0000000e+00 4.5446169e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:09:38,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8549
[2019-03-23 21:09:38,088] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 91.33333333333334, 1.0, 2.0, 0.3558324050363399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447712.3778960381, 447712.3778960381, 122696.2885626371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716000.0000, 
sim time next is 7716600.0000, 
raw observation next is [19.25, 91.0, 1.0, 2.0, 0.3516039323531087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 442178.8129270723, 442178.8129270728, 122130.9256065355], 
processed observation next is [1.0, 0.30434782608695654, 0.26851851851851855, 0.91, 1.0, 1.0, 0.22809991946798658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15792100461681152, 0.15792100461681172, 0.23486716462795287], 
reward next is 0.7651, 
noisyNet noise sample is [array([-1.1572568], dtype=float32), 0.1161469]. 
=============================================
[2019-03-23 21:09:39,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:39,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:39,705] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 21:09:44,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5226444e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:09:44,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0585
[2019-03-23 21:09:44,795] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 66.0, 1.0, 2.0, 0.4300614185187756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 527106.5209327815, 527106.5209327815, 132791.4337810584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7853400.0000, 
sim time next is 7854000.0000, 
raw observation next is [24.56666666666667, 66.33333333333333, 1.0, 2.0, 0.4285047899572014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525404.3844410321, 525404.3844410321, 132570.1177782814], 
processed observation next is [1.0, 0.9130434782608695, 0.46543209876543223, 0.6633333333333333, 1.0, 1.0, 0.3196485594728588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1876444230146543, 0.1876444230146543, 0.2549425341890027], 
reward next is 0.7451, 
noisyNet noise sample is [array([-1.166969], dtype=float32), 0.44265616]. 
=============================================
[2019-03-23 21:09:44,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.79946]
 [72.79946]
 [72.79946]
 [72.79946]
 [72.79946]], R is [[72.81652069]
 [72.83298492]
 [72.84859467]
 [72.86322021]
 [72.87728119]].
[2019-03-23 21:09:45,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.225584e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:09:45,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1956
[2019-03-23 21:09:45,808] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333333, 69.0, 1.0, 2.0, 0.8953618235441374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.970073323374022, 6.9112, 121.9257974928357, 1137813.55116423, 1107665.208169819, 220166.7982011697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7893600.0000, 
sim time next is 7894200.0000, 
raw observation next is [23.71666666666667, 68.0, 1.0, 2.0, 0.9205823602312772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.127688249434343, 6.9112, 121.9250712242287, 1247771.399185336, 1136910.949213075, 225938.7200008328], 
processed observation next is [1.0, 0.34782608695652173, 0.4339506172839507, 0.68, 1.0, 1.0, 0.9054551907515204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02164882494343434, 0.0, 0.809455679791196, 0.4456326425661914, 0.4060396247189553, 0.43449753846314], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5951674], dtype=float32), 0.112960756]. 
=============================================
[2019-03-23 21:09:48,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7984548e-22 1.0000000e+00 1.0288217e-33 1.4558579e-37 4.9883705e-37], sum to 1.0000
[2019-03-23 21:09:48,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7346
[2019-03-23 21:09:48,163] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 74.0, 1.0, 2.0, 0.4433649726138047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540459.3935880795, 540459.3935880795, 134664.6604263765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7947600.0000, 
sim time next is 7948200.0000, 
raw observation next is [23.68333333333333, 74.5, 1.0, 2.0, 0.4430623294448311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540156.0115665076, 540156.0115665081, 134621.7785359266], 
processed observation next is [1.0, 1.0, 0.4327160493827159, 0.745, 1.0, 1.0, 0.33697896362479896, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19291286127375273, 0.1929128612737529, 0.2588880356460127], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.51777065], dtype=float32), -0.2527073]. 
=============================================
[2019-03-23 21:09:49,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 21:09:49,384] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,384] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,388] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 21:09:49,435] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,436] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,439] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 21:09:49,462] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,463] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 21:09:49,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 21:09:49,582] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,584] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 21:09:49,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 21:09:49,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,698] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 21:09:49,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,744] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 21:09:49,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 21:09:49,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,847] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 21:09:49,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:49,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:49,902] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 21:09:50,017] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:50,017] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:50,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 21:09:50,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:50,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:50,094] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 21:09:50,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:09:50,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:50,181] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 21:09:52,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5887363e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:09:52,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5296
[2019-03-23 21:09:52,756] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 47.33333333333333, 1.0, 2.0, 0.4779479689805211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615493.9145732548, 615493.9145732548, 140378.4059693362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 30000.0000, 
sim time next is 30600.0000, 
raw observation next is [23.5, 47.0, 1.0, 2.0, 0.5399372112714772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694242.1632680318, 694242.1632680318, 150355.1401773632], 
processed observation next is [1.0, 0.34782608695652173, 0.42592592592592593, 0.47, 1.0, 1.0, 0.4523062038946157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24794362973858278, 0.24794362973858278, 0.2891445003410831], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.182975], dtype=float32), 0.38592312]. 
=============================================
[2019-03-23 21:09:53,867] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.739534e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:09:53,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-23 21:09:53,883] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.73333333333333, 38.33333333333334, 1.0, 2.0, 0.7143458069320526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892239.9787420412, 892239.9787420412, 181845.3103153542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 45600.0000, 
sim time next is 46200.0000, 
raw observation next is [28.91666666666667, 38.16666666666666, 1.0, 2.0, 0.7198653686825177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 897914.8041311766, 897914.8041311766, 182910.6541311807], 
processed observation next is [1.0, 0.5217391304347826, 0.6265432098765434, 0.3816666666666666, 1.0, 1.0, 0.6665063912887116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32068385861827736, 0.32068385861827736, 0.35175125794457823], 
reward next is 0.6482, 
noisyNet noise sample is [array([-0.30633128], dtype=float32), -0.57158333]. 
=============================================
[2019-03-23 21:09:54,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1835944e-18 1.0000000e+00 1.8108922e-28 3.1668702e-31 4.8133624e-30], sum to 1.0000
[2019-03-23 21:09:54,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4779
[2019-03-23 21:09:54,580] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 43.5, 1.0, 2.0, 0.4056531893557905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499842.1861612421, 499842.1861612421, 129352.5503860106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 66600.0000, 
sim time next is 67200.0000, 
raw observation next is [28.63333333333333, 44.0, 1.0, 2.0, 0.404568141005167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498484.3204522337, 498484.3204522337, 129198.3530898171], 
processed observation next is [1.0, 0.782608695652174, 0.6160493827160493, 0.44, 1.0, 1.0, 0.29115254881567504, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17803011444722633, 0.17803011444722633, 0.24845837132657134], 
reward next is 0.7515, 
noisyNet noise sample is [array([-2.0556877], dtype=float32), -0.07468079]. 
=============================================
[2019-03-23 21:10:01,077] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1818836e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:10:01,083] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-23 21:10:01,090] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 17.0, 1.0, 2.0, 0.3103439504215394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400337.3110635817, 400337.3110635817, 95489.91408410214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 180000.0000, 
sim time next is 180600.0000, 
raw observation next is [26.03333333333333, 18.5, 1.0, 2.0, 0.3070668812703095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396108.8675256517, 396108.8675256517, 95250.3162663643], 
processed observation next is [0.0, 0.08695652173913043, 0.519753086419753, 0.185, 1.0, 1.0, 0.1750796205598923, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14146745268773275, 0.14146745268773275, 0.18317368512762366], 
reward next is 0.8168, 
noisyNet noise sample is [array([-0.8088597], dtype=float32), -0.2578123]. 
=============================================
[2019-03-23 21:10:09,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.590414e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:10:09,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8270
[2019-03-23 21:10:09,228] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 37.5, 1.0, 2.0, 0.3105613204554739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398965.7200231063, 398965.7200231063, 116888.276446878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 333000.0000, 
sim time next is 333600.0000, 
raw observation next is [25.56666666666667, 38.0, 1.0, 2.0, 0.3089983855880311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396999.1533287051, 396999.1533287051, 116692.2243855212], 
processed observation next is [0.0, 0.8695652173913043, 0.5024691358024692, 0.38, 1.0, 1.0, 0.1773790304619418, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14178541190310898, 0.14178541190310898, 0.22440812381831], 
reward next is 0.7756, 
noisyNet noise sample is [array([-0.5303409], dtype=float32), -0.791388]. 
=============================================
[2019-03-23 21:10:11,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.377181e-34 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:10:11,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5188
[2019-03-23 21:10:11,111] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.95, 62.0, 1.0, 2.0, 0.2311742207469147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 298190.1345361223, 298190.1345361223, 91122.53726009889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 365400.0000, 
sim time next is 366000.0000, 
raw observation next is [19.36666666666667, 60.0, 1.0, 2.0, 0.235350587573424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 303578.2692670079, 303578.2692670079, 92471.90490485393], 
processed observation next is [1.0, 0.21739130434782608, 0.27283950617283964, 0.6, 1.0, 1.0, 0.08970308044455239, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.10842081045250282, 0.10842081045250282, 0.17783058635548832], 
reward next is 0.8222, 
noisyNet noise sample is [array([-3.5981843], dtype=float32), -1.384527]. 
=============================================
[2019-03-23 21:10:11,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[84.48353]
 [84.48353]
 [84.48353]
 [84.48353]
 [84.48353]], R is [[84.46085358]
 [84.44101715]
 [84.42295074]
 [84.40328217]
 [84.38642883]].
[2019-03-23 21:10:12,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4873796e-20 1.0000000e+00 1.3424054e-32 1.3437508e-35 9.9144408e-35], sum to 1.0000
[2019-03-23 21:10:12,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.03244170e-21 1.00000000e+00 1.18297064e-32 2.13675765e-36
 1.75990316e-36], sum to 1.0000
[2019-03-23 21:10:12,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-23 21:10:12,864] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-23 21:10:12,869] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 26.66666666666667, 1.0, 2.0, 0.3495715071603094, 1.0, 1.0, 0.3495715071603094, 1.0, 2.0, 0.5757986915650656, 6.9112, 6.9112, 121.94756008, 1291489.842836976, 1291489.842836976, 274011.455915286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 405600.0000, 
sim time next is 406200.0000, 
raw observation next is [30.8, 26.83333333333333, 1.0, 2.0, 0.9612740447361222, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.499359006094405, 6.9112, 121.9235900323299, 1507058.737809869, 1205874.816171787, 236028.1368954077], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.2683333333333333, 1.0, 1.0, 0.9538976723049074, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05881590060944051, 0.0, 0.809445846217319, 0.5382352635035247, 0.4306695772042096, 0.4539002632603994], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7677921], dtype=float32), 0.110304855]. 
=============================================
[2019-03-23 21:10:12,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1327227.353331107 W.
[2019-03-23 21:10:12,877] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.8, 26.5, 1.0, 2.0, 0.3595471601132654, 1.0, 2.0, 0.3595471601132654, 1.0, 1.0, 0.5917077470830748, 6.911200000000001, 6.9112, 121.94756008, 1327227.353331107, 1327227.353331106, 278191.0313163198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 405000.0000, 
sim time next is 405600.0000, 
raw observation next is [30.8, 26.66666666666667, 1.0, 2.0, 0.5217327280521546, 1.0, 2.0, 0.5217327280521546, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156209, 1291430.614277616, 1291430.614277616, 246049.7546855483], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.2666666666666667, 1.0, 1.0, 0.43063420006208886, 1.0, 1.0, 0.43063420006208886, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288198645, 0.46122521938486283, 0.46122521938486283, 0.473172605164516], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2169697], dtype=float32), -0.95791054]. 
=============================================
[2019-03-23 21:10:16,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5745837e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:10:16,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0414
[2019-03-23 21:10:16,653] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.51666666666667, 47.16666666666666, 1.0, 2.0, 0.8359322475745078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1055477.113075319, 1055477.113075319, 207317.6418971136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 465000.0000, 
sim time next is 465600.0000, 
raw observation next is [25.83333333333334, 46.33333333333333, 1.0, 2.0, 0.8330627348986528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050252.506727442, 1050252.506727442, 206667.0511668756], 
processed observation next is [1.0, 0.391304347826087, 0.5123456790123458, 0.46333333333333326, 1.0, 1.0, 0.8012651605936343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3750901809740864, 0.3750901809740864, 0.3974366368593762], 
reward next is 0.6026, 
noisyNet noise sample is [array([-0.33186117], dtype=float32), -0.5483174]. 
=============================================
[2019-03-23 21:10:18,848] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 21:10:18,849] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:10:18,850] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:10:18,852] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:10:18,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:10:18,856] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:10:18,857] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:10:18,855] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:10:18,858] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:10:18,859] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:10:18,859] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:10:18,871] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 21:10:18,894] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 21:10:18,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 21:10:18,922] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 21:10:18,977] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 21:10:26,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:10:26,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.12105394, 47.67047848, 1.0, 2.0, 0.5827214840263283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706563.1211643792, 706563.1211643792, 156898.4884484409]
[2019-03-23 21:10:26,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:10:26,430] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6684540509619539
[2019-03-23 21:11:02,145] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:02,146] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.11666666666667, 99.16666666666667, 1.0, 2.0, 0.9140079362516645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1060045.032145324, 1060045.032145324, 221596.4894432116]
[2019-03-23 21:11:02,147] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:11:02,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8486714232884701
[2019-03-23 21:11:10,299] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:10,300] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666666, 79.66666666666667, 1.0, 2.0, 0.6210507431763196, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9887330093473408, 6.9112, 6.9112, 121.9260426156618, 1416215.336528973, 1416215.336528973, 302139.2849704089]
[2019-03-23 21:11:10,301] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:10,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7762202977284559
[2019-03-23 21:11:10,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1416215.336528973 W.
[2019-03-23 21:11:28,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:28,189] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.13333333333333, 86.33333333333334, 1.0, 2.0, 0.5711593629146381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670940.2309405543, 670940.2309405543, 154110.7861363149]
[2019-03-23 21:11:28,189] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:28,191] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9637340236622207
[2019-03-23 21:11:34,053] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:34,055] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.11666666666667, 88.0, 1.0, 2.0, 0.4967503104690054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602675.2901447624, 602675.2901447624, 142733.6421738918]
[2019-03-23 21:11:34,055] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:34,059] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2706716987315302
[2019-03-23 21:11:35,120] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:35,121] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.66666666666666, 38.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.602620144788737, 6.9112, 121.9233358433482, 1517117.991180379, 1163056.938988257, 245581.1060188489]
[2019-03-23 21:11:35,122] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:35,124] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.49455981828140827
[2019-03-23 21:11:35,125] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1517117.991180379 W.
[2019-03-23 21:11:48,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:48,578] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.96666666666667, 85.66666666666667, 1.0, 2.0, 0.4309744432742892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534211.693767747, 534211.6937677466, 133073.0497497774]
[2019-03-23 21:11:48,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:48,582] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.10549643362143213
[2019-03-23 21:11:55,518] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.32332638]
[2019-03-23 21:11:55,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.86666666666667, 92.33333333333333, 1.0, 2.0, 0.3498833908395585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 441234.9570959058, 441234.9570959054, 121919.4313748251]
[2019-03-23 21:11:55,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:55,523] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1446268e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3033935059760179
[2019-03-23 21:11:57,473] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:11:57,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:11:57,679] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:11:57,836] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:11:57,854] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:11:58,867] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 650000, evaluation results [650000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:11:59,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6620417e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:11:59,805] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9277
[2019-03-23 21:11:59,808] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 72.66666666666667, 1.0, 2.0, 0.3378440377430728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430786.8498215469, 430786.8498215469, 120378.2433967239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 528600.0000, 
sim time next is 529200.0000, 
raw observation next is [20.2, 73.0, 1.0, 2.0, 0.332281431349273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 423802.9791165702, 423802.9791165697, 119656.5252924639], 
processed observation next is [1.0, 0.13043478260869565, 0.3037037037037037, 0.73, 1.0, 1.0, 0.20509694208246787, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1513582068273465, 0.15135820682734633, 0.23010870248550752], 
reward next is 0.7699, 
noisyNet noise sample is [array([-2.102368], dtype=float32), 1.3098005]. 
=============================================
[2019-03-23 21:12:00,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.699534e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:12:00,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0123
[2019-03-23 21:12:00,402] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 64.33333333333334, 1.0, 2.0, 0.4715555234869563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598341.9757254666, 598341.9757254666, 139379.5471130596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 544800.0000, 
sim time next is 545400.0000, 
raw observation next is [22.2, 63.5, 1.0, 2.0, 0.4987157063827352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632271.6212976923, 632271.6212976918, 143626.7660490887], 
processed observation next is [1.0, 0.30434782608695654, 0.37777777777777777, 0.635, 1.0, 1.0, 0.4032329837889705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2258112933206044, 0.22581129332060423, 0.27620531932517056], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.8881215], dtype=float32), 0.9043163]. 
=============================================
[2019-03-23 21:12:03,409] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3643645e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:03,417] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5281
[2019-03-23 21:12:03,420] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 37.0, 1.0, 2.0, 0.3799697881595382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472760.0555131718, 472760.0555131723, 125875.0243174322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 590400.0000, 
sim time next is 591000.0000, 
raw observation next is [29.31666666666667, 37.5, 1.0, 2.0, 0.3784107523819081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471075.2231353483, 471075.2231353483, 125666.16010569], 
processed observation next is [1.0, 0.8695652173913043, 0.6413580246913582, 0.375, 1.0, 1.0, 0.26001280045465247, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16824115111976726, 0.16824115111976726, 0.2416656925109423], 
reward next is 0.7583, 
noisyNet noise sample is [array([0.38993832], dtype=float32), -1.2037901]. 
=============================================
[2019-03-23 21:12:03,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.66008]
 [69.66008]
 [69.66008]
 [69.66008]
 [69.66008]], R is [[69.72180939]
 [69.78252411]
 [69.84234619]
 [69.90123749]
 [69.95915985]].
[2019-03-23 21:12:04,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3807131e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:04,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0306
[2019-03-23 21:12:04,880] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 61.66666666666667, 1.0, 2.0, 0.3954400473174092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503076.7288244056, 503076.7288244056, 128174.0530975518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 616800.0000, 
sim time next is 617400.0000, 
raw observation next is [21.95, 62.5, 1.0, 2.0, 0.3834577661018769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488085.1728230429, 488085.1728230434, 126503.8905451277], 
processed observation next is [1.0, 0.13043478260869565, 0.36851851851851847, 0.625, 1.0, 1.0, 0.266021150121282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17431613315108674, 0.17431613315108693, 0.24327671258678402], 
reward next is 0.7567, 
noisyNet noise sample is [array([-1.0357585], dtype=float32), -0.3646228]. 
=============================================
[2019-03-23 21:12:06,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7350607e-19 1.0000000e+00 1.3772698e-29 1.7457981e-32 1.1690955e-31], sum to 1.0000
[2019-03-23 21:12:06,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3742
[2019-03-23 21:12:06,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1404346.692389629 W.
[2019-03-23 21:12:06,597] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.68333333333334, 18.83333333333334, 1.0, 2.0, 0.3889962649321481, 1.0, 2.0, 0.3889962649321481, 1.0, 1.0, 0.6290036242199767, 6.9112, 6.9112, 121.94756008, 1404346.692389629, 1404346.692389629, 291744.7766355944], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 659400.0000, 
sim time next is 660000.0000, 
raw observation next is [35.66666666666667, 18.66666666666667, 1.0, 2.0, 0.3568688441018896, 1.0, 2.0, 0.3568688441018896, 1.0, 2.0, 0.5779442133113012, 6.9112, 6.9112, 121.94756008, 1291485.348047549, 1291485.348047549, 278027.13059144], 
processed observation next is [1.0, 0.6521739130434783, 0.8765432098765434, 0.1866666666666667, 1.0, 1.0, 0.2343676715498686, 1.0, 1.0, 0.2343676715498686, 1.0, 1.0, 0.47243026663912646, 0.0, 0.0, 0.8096049824067558, 0.4612447671598389, 0.4612447671598389, 0.5346675588296923], 
reward next is 0.4653, 
noisyNet noise sample is [array([0.14968531], dtype=float32), -0.8243588]. 
=============================================
[2019-03-23 21:12:06,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[38.419613]
 [38.419613]
 [38.419613]
 [38.419613]
 [38.419613]], R is [[38.50074387]
 [38.11573792]
 [38.15628052]
 [38.15096664]
 [38.15811539]].
[2019-03-23 21:12:24,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5583087e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:24,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-23 21:12:24,543] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 54.33333333333334, 1.0, 2.0, 0.7398865415808149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258779601705, 922364.12035205, 922364.12035205, 186898.6805046425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 994800.0000, 
sim time next is 995400.0000, 
raw observation next is [25.25, 54.0, 1.0, 2.0, 0.6487603303297194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425654539, 809641.9499316061, 809641.9499316061, 169291.6431242385], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.54, 1.0, 1.0, 0.5818575361068088, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621284868077, 0.2891578392612879, 0.2891578392612879, 0.3255608521619971], 
reward next is 0.6744, 
noisyNet noise sample is [array([1.1612229], dtype=float32), -0.3539143]. 
=============================================
[2019-03-23 21:12:30,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9865095e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:30,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5077
[2019-03-23 21:12:30,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 51.0, 1.0, 2.0, 0.3351694553965226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422306.2484225116, 422306.2484225116, 119986.5797259839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1101000.0000, 
sim time next is 1101600.0000, 
raw observation next is [24.8, 52.0, 1.0, 2.0, 0.3364288838102544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424119.3167940284, 424119.3167940284, 120153.0021996266], 
processed observation next is [1.0, 0.782608695652174, 0.4740740740740741, 0.52, 1.0, 1.0, 0.21003438548839806, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15147118456929584, 0.15147118456929584, 0.2310634657685127], 
reward next is 0.7689, 
noisyNet noise sample is [array([1.8199939], dtype=float32), -0.06964451]. 
=============================================
[2019-03-23 21:12:30,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.027701e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:12:30,513] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1422
[2019-03-23 21:12:30,516] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 41.66666666666666, 1.0, 2.0, 0.8325582518276593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050721.776336977, 1050721.776336977, 206572.7539178446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1090200.0000, 
sim time next is 1090800.0000, 
raw observation next is [26.7, 42.0, 1.0, 2.0, 0.8590978293620841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1083739.319574894, 1083739.319574894, 212424.8035439431], 
processed observation next is [1.0, 0.6521739130434783, 0.5444444444444444, 0.42, 1.0, 1.0, 0.8322593206691478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.38704975699103356, 0.38704975699103356, 0.40850923758450597], 
reward next is 0.5915, 
noisyNet noise sample is [array([1.5178778], dtype=float32), -0.07960662]. 
=============================================
[2019-03-23 21:12:34,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8002125e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:34,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6892
[2019-03-23 21:12:34,680] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 67.5, 1.0, 2.0, 0.7227678928463744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 912072.3880998166, 912072.3880998166, 183668.1309998129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [21.9, 68.0, 1.0, 2.0, 0.7330785276424029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 924842.8634783081, 924842.8634783076, 185724.3367977001], 
processed observation next is [1.0, 0.6521739130434783, 0.36666666666666664, 0.68, 1.0, 1.0, 0.682236342431432, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33030102267082434, 0.3303010226708242, 0.35716218614942324], 
reward next is 0.6428, 
noisyNet noise sample is [array([-0.5546287], dtype=float32), -0.28787574]. 
=============================================
[2019-03-23 21:12:43,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7423593e-21 1.0000000e+00 2.0197607e-32 2.3097713e-34 3.8669884e-34], sum to 1.0000
[2019-03-23 21:12:43,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4817
[2019-03-23 21:12:43,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1336011.400667408 W.
[2019-03-23 21:12:44,001] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 35.5, 1.0, 2.0, 0.931096486687871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.25417438090506, 6.9112, 121.9248242813817, 1336011.400667408, 1160379.617942975, 228672.6210471069], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1343400.0000, 
sim time next is 1344000.0000, 
raw observation next is [29.9, 35.0, 1.0, 2.0, 0.5668363112574752, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9322337963441208, 6.911200000000001, 6.9112, 121.925836082506, 1394092.019479352, 1394092.019479352, 277581.0393318822], 
processed observation next is [1.0, 0.5652173913043478, 0.6629629629629629, 0.35, 1.0, 1.0, 0.4843289419731848, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.915292245430151, 8.881784197001253e-17, 0.0, 0.8094607576547608, 0.49789000695691144, 0.49789000695691144, 0.5338096910228504], 
reward next is 0.4662, 
noisyNet noise sample is [array([-2.1378543], dtype=float32), 0.043451607]. 
=============================================
[2019-03-23 21:12:44,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.513123]
 [42.513123]
 [42.513123]
 [42.513123]
 [42.513123]], R is [[42.55418015]
 [42.12863922]
 [42.3348732 ]
 [42.55271912]
 [42.77224731]].
[2019-03-23 21:12:46,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4881032e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:12:46,642] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0966
[2019-03-23 21:12:46,647] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 55.0, 1.0, 2.0, 0.2734233947049491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 351274.2787665935, 351274.278766594, 112352.4743672192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [22.6, 54.0, 1.0, 2.0, 0.2791633794573393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358146.8650023618, 358146.8650023618, 113039.5256906351], 
processed observation next is [0.0, 0.2608695652173913, 0.39259259259259266, 0.54, 1.0, 1.0, 0.14186116602064205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12790959464370066, 0.12790959464370066, 0.21738370325122133], 
reward next is 0.7826, 
noisyNet noise sample is [array([-1.0313574], dtype=float32), -1.3864353]. 
=============================================
[2019-03-23 21:12:46,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.23482]
 [73.23482]
 [73.23482]
 [73.23482]
 [73.23482]], R is [[73.28507996]
 [73.33616638]
 [73.38792419]
 [73.44008636]
 [73.49253845]].
[2019-03-23 21:12:49,042] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:12:49,044] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:12:49,046] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:12:49,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:49,048] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:12:49,049] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:12:49,051] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:12:49,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:49,051] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:49,054] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:49,052] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:49,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 21:12:49,088] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 21:12:49,115] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 21:12:49,147] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 21:12:49,173] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 21:12:53,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:12:53,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.35, 51.0, 1.0, 2.0, 0.2133094338713113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 275142.3280906833, 275142.3280906837, 80148.21958116861]
[2019-03-23 21:12:53,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:12:53,481] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5683527421363969
[2019-03-23 21:13:21,815] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:13:21,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 59.0, 1.0, 2.0, 0.6472202849978748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740933.6526354429, 740933.6526354429, 166557.0439082998]
[2019-03-23 21:13:21,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:13:21,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.03241935172609145
[2019-03-23 21:13:34,385] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:13:34,386] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.58333333333333, 59.0, 1.0, 2.0, 0.6788095255979714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773638.6431324073, 773638.6431324073, 172172.9761003314]
[2019-03-23 21:13:34,387] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:13:34,392] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5475992948613199
[2019-03-23 21:13:45,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:13:45,668] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.41658628, 103.1645808, 1.0, 2.0, 0.4961284785687686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593871.8465595191, 593871.8465595191, 142365.5812836809]
[2019-03-23 21:13:45,669] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:13:45,675] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9554038390266206
[2019-03-23 21:13:58,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:13:58,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.058620715, 81.84128442, 1.0, 2.0, 0.7063361215558023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805027.1559823756, 805027.1559823756, 177345.8684526179]
[2019-03-23 21:13:58,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:13:58,291] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8495643795241395
[2019-03-23 21:14:27,640] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:14:27,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.26328924]
[2019-03-23 21:14:27,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.41086123, 54.69220096, 1.0, 2.0, 0.6981546311745719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836266.9043049425, 836266.9043049425, 177620.840283756]
[2019-03-23 21:14:27,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:14:27,727] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.7025748e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.22914805265713045
[2019-03-23 21:14:28,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:14:28,070] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:14:28,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:14:28,123] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:14:29,135] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 675000, evaluation results [675000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:14:29,540] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8677249e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:29,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8580
[2019-03-23 21:14:29,551] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 71.33333333333334, 1.0, 2.0, 0.8026163119941679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259912919383, 985590.4937552037, 985590.4937552037, 199501.9998354639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1761600.0000, 
sim time next is 1762200.0000, 
raw observation next is [23.7, 71.0, 1.0, 2.0, 0.8438112084797657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426000119, 1035676.397492775, 1035676.397492775, 208372.078562974], 
processed observation next is [1.0, 0.391304347826087, 0.4333333333333333, 0.71, 1.0, 1.0, 0.8140609624759115, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621287162369, 0.36988442767599106, 0.36988442767599106, 0.4007155356980269], 
reward next is 0.5993, 
noisyNet noise sample is [array([0.19039468], dtype=float32), -0.49762392]. 
=============================================
[2019-03-23 21:14:31,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5466425e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:31,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-23 21:14:31,342] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 54.5, 1.0, 2.0, 0.330213125192198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418757.0510175923, 418757.0510175923, 119375.0906913095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1474200.0000, 
sim time next is 1474800.0000, 
raw observation next is [23.46666666666667, 55.66666666666667, 1.0, 2.0, 0.3281693068587796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416444.9954161446, 416444.9954161446, 119114.2706810304], 
processed observation next is [0.0, 0.043478260869565216, 0.42469135802469143, 0.5566666666666668, 1.0, 1.0, 0.20020155578426144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14873035550576594, 0.14873035550576594, 0.22906590515582767], 
reward next is 0.7709, 
noisyNet noise sample is [array([-2.2231622], dtype=float32), 1.5306331]. 
=============================================
[2019-03-23 21:14:33,493] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7270804e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:33,502] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5315
[2019-03-23 21:14:33,512] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 52.0, 1.0, 2.0, 0.5317715958465058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628449.0041842716, 628449.0041842716, 147751.7730522341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1533600.0000, 
sim time next is 1534200.0000, 
raw observation next is [29.2, 54.0, 1.0, 2.0, 0.5493174414445497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650148.1797353628, 650148.1797353628, 150663.7779339637], 
processed observation next is [0.0, 0.782608695652174, 0.637037037037037, 0.54, 1.0, 1.0, 0.4634731445768449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23219577847691528, 0.23219577847691528, 0.2897380344883917], 
reward next is 0.7103, 
noisyNet noise sample is [array([-1.715289], dtype=float32), -2.1671767]. 
=============================================
[2019-03-23 21:14:41,921] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.604473e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:14:41,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-23 21:14:41,934] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 73.5, 1.0, 2.0, 0.5700055760010804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 713713.3447229025, 713713.344722902, 155290.9124429884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1687800.0000, 
sim time next is 1688400.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.5790951217988284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724269.5517084831, 724269.5517084831, 156841.5490449847], 
processed observation next is [1.0, 0.5652173913043478, 0.37037037037037035, 0.73, 1.0, 1.0, 0.49892276404622427, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.258667697038744, 0.258667697038744, 0.30161836354804755], 
reward next is 0.6984, 
noisyNet noise sample is [array([-0.9391236], dtype=float32), -0.20039448]. 
=============================================
[2019-03-23 21:14:42,776] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3582385e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:42,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0211
[2019-03-23 21:14:42,790] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.23333333333333, 79.0, 1.0, 2.0, 0.4110556182954918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506933.9102305581, 506933.9102305581, 130131.5185266915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1719600.0000, 
sim time next is 1720200.0000, 
raw observation next is [22.16666666666667, 79.0, 1.0, 2.0, 0.4085984947186581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504372.9057820008, 504372.9057820003, 129792.8448064123], 
processed observation next is [1.0, 0.9130434782608695, 0.3765432098765434, 0.79, 1.0, 1.0, 0.29595058895078347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18013318063642886, 0.18013318063642866, 0.24960162462771596], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.9619937], dtype=float32), -0.95048726]. 
=============================================
[2019-03-23 21:14:44,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.964658e-35 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:14:44,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9020
[2019-03-23 21:14:44,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 80.5, 1.0, 2.0, 0.3795491917040898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472540.2968587949, 472540.2968587949, 125823.4352318677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1729800.0000, 
sim time next is 1730400.0000, 
raw observation next is [21.33333333333333, 80.66666666666667, 1.0, 2.0, 0.3790934535925704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471938.9603949608, 471938.9603949604, 125760.1662097239], 
processed observation next is [1.0, 0.0, 0.3456790123456788, 0.8066666666666668, 1.0, 1.0, 0.26082553999115526, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16854962871248602, 0.16854962871248585, 0.24184647348023827], 
reward next is 0.7582, 
noisyNet noise sample is [array([-1.0721388], dtype=float32), 0.6149773]. 
=============================================
[2019-03-23 21:14:46,530] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0645302e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:46,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7555
[2019-03-23 21:14:46,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1598349.648607751 W.
[2019-03-23 21:14:46,546] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.63333333333333, 58.83333333333334, 1.0, 2.0, 0.4643011451269241, 1.0, 2.0, 0.4643011451269241, 1.0, 2.0, 0.7394876328182529, 6.9112, 6.9112, 121.94756008, 1598349.648607751, 1598349.648607751, 326462.5543440392], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4634109812552484, 1.0, 2.0, 0.4634109812552484, 1.0, 2.0, 0.7378513060548796, 6.911200000000003, 6.9112, 121.94756008, 1588942.195143865, 1588942.195143864, 326000.7065457866], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.58, 1.0, 1.0, 0.3612035491133909, 1.0, 1.0, 0.3612035491133909, 1.0, 1.0, 0.6723141325685994, 2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.5674793554085232, 0.5674793554085229, 0.6269244356649742], 
reward next is 0.3731, 
noisyNet noise sample is [array([0.85733104], dtype=float32), -1.2527214]. 
=============================================
[2019-03-23 21:14:46,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.52822]
 [54.52822]
 [54.52822]
 [54.52822]
 [54.52822]], R is [[54.35601425]
 [54.18464279]
 [53.64279556]
 [53.10636902]
 [52.57530594]].
[2019-03-23 21:14:52,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0258598e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:52,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-23 21:14:52,586] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 87.0, 1.0, 2.0, 0.9384704841535779, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.163798152341809, 6.9112, 121.9249482406549, 1272962.748680047, 1143611.078750215, 229647.5393780759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1872000.0000, 
sim time next is 1872600.0000, 
raw observation next is [21.58333333333334, 87.16666666666667, 1.0, 2.0, 0.8491093716844622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258804466724, 1039384.07623486, 1039384.07623486, 209449.7461416448], 
processed observation next is [1.0, 0.6956521739130435, 0.3549382716049385, 0.8716666666666667, 1.0, 1.0, 0.8203682996243598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094610521866902, 0.37120859865530714, 0.37120859865530714, 0.40278797334931693], 
reward next is 0.5972, 
noisyNet noise sample is [array([-0.20763643], dtype=float32), -0.16550529]. 
=============================================
[2019-03-23 21:14:55,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.239053e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:14:55,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6613
[2019-03-23 21:14:55,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1516462.686172642 W.
[2019-03-23 21:14:55,817] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.96666666666667, 60.66666666666667, 1.0, 2.0, 0.6575612293164804, 1.0, 1.0, 0.6575612293164804, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1516462.686172642, 1516462.686172642, 289253.3672627325], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1956000.0000, 
sim time next is 1956600.0000, 
raw observation next is [28.05, 60.5, 1.0, 2.0, 0.7121660429270876, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9837777685869457, 6.911200000000001, 6.9112, 121.9260426156618, 1539595.500988383, 1539595.500988382, 316956.1854299727], 
processed observation next is [1.0, 0.6521739130434783, 0.5944444444444444, 0.605, 1.0, 1.0, 0.6573405272941519, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9797222107336819, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5498555360672797, 0.5498555360672792, 0.6095311258268706], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40103504], dtype=float32), 0.6066318]. 
=============================================
[2019-03-23 21:15:02,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.889087e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:15:02,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4254
[2019-03-23 21:15:02,655] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 80.66666666666667, 1.0, 2.0, 0.4679326429096379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564721.6582020267, 564721.6582020267, 138177.9831478198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2074800.0000, 
sim time next is 2075400.0000, 
raw observation next is [23.35, 81.0, 1.0, 2.0, 0.4660787166543252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562819.6351619432, 562819.6351619432, 137907.5143765752], 
processed observation next is [0.0, 0.0, 0.42037037037037045, 0.81, 1.0, 1.0, 0.3643794245884824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20100701255783684, 0.20100701255783684, 0.2652067584164907], 
reward next is 0.7348, 
noisyNet noise sample is [array([-1.2885627], dtype=float32), -1.3748548]. 
=============================================
[2019-03-23 21:15:13,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8255668e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:15:13,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-23 21:15:13,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2069983e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:15:13,809] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.33333333333334, 1.0, 2.0, 0.4527148859283502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549714.3692141621, 549714.3692141621, 135992.0753896517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2262000.0000, 
sim time next is 2262600.0000, 
raw observation next is [20.85, 96.0, 1.0, 2.0, 0.4434619770970255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540182.4311331596, 540182.4311331592, 134667.1598566798], 
processed observation next is [1.0, 0.17391304347826086, 0.32777777777777783, 0.96, 1.0, 1.0, 0.3374547346393161, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19292229683327128, 0.19292229683327114, 0.2589753074166919], 
reward next is 0.7410, 
noisyNet noise sample is [array([1.0478976], dtype=float32), -1.0640587]. 
=============================================
[2019-03-23 21:15:13,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1327
[2019-03-23 21:15:13,818] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 96.5, 1.0, 2.0, 0.4329399947933361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 531142.2359017992, 531142.2359017987, 133225.8139168049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2273400.0000, 
sim time next is 2274000.0000, 
raw observation next is [20.4, 96.66666666666666, 1.0, 2.0, 0.455937315283809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559182.8290031264, 559182.8290031264, 136635.5027017118], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.9666666666666666, 1.0, 1.0, 0.3523063277188202, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19970815321540228, 0.19970815321540228, 0.2627605821186766], 
reward next is 0.7372, 
noisyNet noise sample is [array([1.4289228], dtype=float32), -0.85982275]. 
=============================================
[2019-03-23 21:15:13,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.9876]
 [72.9876]
 [72.9876]
 [72.9876]
 [72.9876]], R is [[72.9949646 ]
 [73.00881195]
 [73.02135468]
 [73.02468872]
 [73.04149628]].
[2019-03-23 21:15:19,538] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 21:15:19,539] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:15:19,541] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:15:19,541] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:15:19,542] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:15:19,543] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:15:19,544] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:15:19,544] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:15:19,543] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:15:19,545] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:15:19,547] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:15:19,561] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 21:15:19,584] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 21:15:19,587] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 21:15:19,612] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 21:15:19,636] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 21:15:23,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:15:23,723] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.13333333333333, 24.66666666666666, 1.0, 2.0, 0.3557099750395847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454595.9906852816, 454595.9906852816, 122737.4854355467]
[2019-03-23 21:15:23,724] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:15:23,726] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.7440722036175389
[2019-03-23 21:15:32,307] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:15:32,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.39209064, 44.708263075, 1.0, 2.0, 0.3660517784361056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 457245.2712230607, 457245.2712230602, 124014.9400603685]
[2019-03-23 21:15:32,309] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:15:32,311] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.625579539392726
[2019-03-23 21:15:46,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:15:46,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.75, 88.0, 1.0, 2.0, 0.6209282597775108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768245.9312117927, 768245.9312117927, 164055.2454872641]
[2019-03-23 21:15:46,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:15:46,142] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.2044008698402554
[2019-03-23 21:16:27,188] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:16:27,189] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.61666666666667, 55.0, 1.0, 2.0, 0.5357162094768033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628580.1325775735, 628580.1325775735, 148208.1179071986]
[2019-03-23 21:16:27,189] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:16:27,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.4927631906981468
[2019-03-23 21:16:31,395] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:16:31,395] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.2, 94.0, 1.0, 2.0, 0.9026381384635186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1028907.165777182, 1028907.165777182, 218060.619607764]
[2019-03-23 21:16:31,396] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:16:31,398] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.22699261920041736
[2019-03-23 21:16:53,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:16:53,718] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.83333333333333, 92.83333333333333, 1.0, 2.0, 0.3783090275726883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470794.3461529625, 470794.3461529625, 125649.1119799913]
[2019-03-23 21:16:53,718] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:16:53,721] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.6942772852268826
[2019-03-23 21:16:55,317] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.28205398]
[2019-03-23 21:16:55,317] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.58333333333333, 61.66666666666666, 1.0, 2.0, 0.4173847984683571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517008.6923202752, 517008.6923202752, 131091.9632225666]
[2019-03-23 21:16:55,318] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:16:55,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7931712e-20 1.0000000e+00 2.9740786e-32 3.7112624e-35 1.0990205e-34], sampled 0.2933233311346052
[2019-03-23 21:16:58,716] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:16:59,237] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:16:59,323] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:16:59,422] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:16:59,635] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:17:00,647] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 700000, evaluation results [700000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:17:07,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2909177e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:17:07,736] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7322
[2019-03-23 21:17:07,741] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 59.0, 1.0, 2.0, 0.4574593701732498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572283.6923094315, 572283.6923094315, 137117.8420197973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2524200.0000, 
sim time next is 2524800.0000, 
raw observation next is [24.53333333333333, 58.00000000000001, 1.0, 2.0, 0.405650924022409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 506952.411496896, 506952.4114968955, 129506.2300183074], 
processed observation next is [1.0, 0.21739130434782608, 0.46419753086419746, 0.5800000000000001, 1.0, 1.0, 0.29244157621715355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18105443267746285, 0.18105443267746268, 0.24905044234289883], 
reward next is 0.7509, 
noisyNet noise sample is [array([0.28393346], dtype=float32), -0.53423226]. 
=============================================
[2019-03-23 21:17:12,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.821256e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:17:12,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2770
[2019-03-23 21:17:12,053] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 96.83333333333334, 1.0, 2.0, 0.4458410735145249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 544345.2075842358, 544345.2075842354, 135056.8733707511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2609400.0000, 
sim time next is 2610000.0000, 
raw observation next is [20.6, 97.0, 1.0, 2.0, 0.4444046744616402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542857.3420342486, 542857.3420342486, 134851.279304727], 
processed observation next is [0.0, 0.21739130434782608, 0.3185185185185186, 0.97, 1.0, 1.0, 0.33857699340671454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1938776221550888, 0.1938776221550888, 0.25932938327832117], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.3819282], dtype=float32), 0.19583777]. 
=============================================
[2019-03-23 21:17:12,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.80516]
 [69.80516]
 [69.80516]
 [69.80516]
 [69.80516]], R is [[69.84778595]
 [69.88957977]
 [69.93060303]
 [69.97092438]
 [70.01053619]].
[2019-03-23 21:17:14,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.232907e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:17:14,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2458
[2019-03-23 21:17:14,768] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6018201246287438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693456.9728720584, 693456.9728720584, 158761.7634790411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2656800.0000, 
sim time next is 2657400.0000, 
raw observation next is [26.83333333333333, 74.66666666666667, 1.0, 2.0, 0.6034079003132248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695372.9325631983, 695372.9325631983, 159040.4963275515], 
processed observation next is [0.0, 0.782608695652174, 0.5493827160493825, 0.7466666666666667, 1.0, 1.0, 0.5278665479919342, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24834747591542794, 0.24834747591542794, 0.3058471083222144], 
reward next is 0.6942, 
noisyNet noise sample is [array([0.63114095], dtype=float32), 1.4976072]. 
=============================================
[2019-03-23 21:17:24,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.93886087e-15 1.00000000e+00 1.08762825e-23 3.23923593e-25
 4.63019818e-24], sum to 1.0000
[2019-03-23 21:17:24,270] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1730
[2019-03-23 21:17:24,272] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.15, 58.33333333333334, 1.0, 2.0, 0.6660530607211025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759092.9119825382, 759092.9119825382, 169816.9274113612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6690302060352583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935529, 170363.6604325452], 
processed observation next is [1.0, 0.8260869565217391, 0.7037037037037037, 0.59, 1.0, 1.0, 0.6059883405181646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27231700621198335, 0.2723170062119832, 0.3276224239087408], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.62042516], dtype=float32), -0.8510911]. 
=============================================
[2019-03-23 21:17:27,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1257181e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:17:27,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-23 21:17:27,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1475067.510325377 W.
[2019-03-23 21:17:27,943] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.21666666666667, 92.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.455244077687846, 6.9112, 121.9237756316829, 1475067.510325377, 1196473.49646599, 247414.4781569341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2887800.0000, 
sim time next is 2888400.0000, 
raw observation next is [23.43333333333334, 90.66666666666667, 1.0, 2.0, 0.6120019027402059, 1.0, 1.0, 0.6120019027402059, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257150015441, 1405103.006123911, 1405103.00612391, 272666.593084387], 
processed observation next is [1.0, 0.43478260869565216, 0.42345679012345705, 0.9066666666666667, 1.0, 1.0, 0.5380975032621499, 1.0, 0.5, 0.5380975032621499, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094599538030891, 0.501822502187111, 0.5018225021871107, 0.5243588328545904], 
reward next is 0.4756, 
noisyNet noise sample is [array([0.9908393], dtype=float32), 1.0237468]. 
=============================================
[2019-03-23 21:17:33,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.64350323e-15 1.00000000e+00 1.00549268e-23 1.03846605e-26
 3.34598927e-25], sum to 1.0000
[2019-03-23 21:17:33,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9952
[2019-03-23 21:17:33,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1670994.354284446 W.
[2019-03-23 21:17:33,394] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.4884420245409767, 1.0, 2.0, 0.4884420245409767, 1.0, 2.0, 0.7776156105154176, 6.911200000000001, 6.9112, 121.94756008, 1670994.354284446, 1670994.354284446, 337952.4638883276], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2989200.0000, 
sim time next is 2989800.0000, 
raw observation next is [27.6, 81.0, 1.0, 2.0, 0.4919850748995699, 1.0, 2.0, 0.4919850748995699, 1.0, 2.0, 0.7832562620753925, 6.9112, 6.9112, 121.94756008, 1683126.793918377, 1683126.793918377, 339672.6275481238], 
processed observation next is [1.0, 0.6086956521739131, 0.5777777777777778, 0.81, 1.0, 1.0, 0.3952203272613927, 1.0, 1.0, 0.3952203272613927, 1.0, 1.0, 0.7290703275942406, 0.0, 0.0, 0.8096049824067558, 0.6011167121137061, 0.6011167121137061, 0.6532165914386997], 
reward next is 0.3468, 
noisyNet noise sample is [array([0.43908417], dtype=float32), 0.8573555]. 
=============================================
[2019-03-23 21:17:36,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.638888e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:17:36,643] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7251
[2019-03-23 21:17:36,645] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 100.0, 1.0, 2.0, 0.5544043391876251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649257.364330415, 649257.364330415, 151223.0767954571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3048600.0000, 
sim time next is 3049200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5934659658916112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690162.4106011273, 690162.4106011273, 157615.4483890788], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5160309117757276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24648657521468834, 0.24648657521468834, 0.30310663151745926], 
reward next is 0.6969, 
noisyNet noise sample is [array([0.6138222], dtype=float32), 1.1496648]. 
=============================================
[2019-03-23 21:17:39,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.447518e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:17:39,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7529
[2019-03-23 21:17:39,809] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 63.0, 1.0, 2.0, 0.5724565294969913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665057.7838694097, 665057.7838694097, 154007.6731573356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3106800.0000, 
sim time next is 3107400.0000, 
raw observation next is [28.41666666666666, 62.16666666666666, 1.0, 2.0, 0.5679403015571299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661731.3759892818, 661731.3759892818, 153334.2411957794], 
processed observation next is [1.0, 1.0, 0.6080246913580245, 0.6216666666666666, 1.0, 1.0, 0.4856432161394404, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23633263428188636, 0.23633263428188636, 0.2948735407611143], 
reward next is 0.7051, 
noisyNet noise sample is [array([-2.043102], dtype=float32), 1.0966159]. 
=============================================
[2019-03-23 21:17:45,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.590187e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:17:45,546] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2190
[2019-03-23 21:17:45,552] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4731051477948013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571240.9294934982, 571240.9294934982, 138975.7482786729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [23.5, 80.5, 1.0, 2.0, 0.4749967716696988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573053.8262096572, 573053.8262096572, 139249.8188188967], 
processed observation next is [0.0, 0.2608695652173913, 0.42592592592592593, 0.805, 1.0, 1.0, 0.3749961567496414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20466208078916331, 0.20466208078916331, 0.26778811311326284], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.14457741], dtype=float32), -0.16428107]. 
=============================================
[2019-03-23 21:17:46,961] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1265578e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:17:46,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1552
[2019-03-23 21:17:46,970] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 58.33333333333334, 1.0, 2.0, 0.6157414133320024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706157.5011715004, 706157.5011715004, 161025.0634570064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259200.0000, 
sim time next is 3259800.0000, 
raw observation next is [30.25, 56.0, 1.0, 2.0, 0.6064319214239654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698631.9362909428, 698631.9362909428, 159554.2818894814], 
processed observation next is [0.0, 0.7391304347826086, 0.6759259259259259, 0.56, 1.0, 1.0, 0.5314665731237683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24951140581819387, 0.24951140581819387, 0.30683515747977197], 
reward next is 0.6932, 
noisyNet noise sample is [array([0.3558799], dtype=float32), 0.45443222]. 
=============================================
[2019-03-23 21:17:51,240] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 21:17:51,243] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:17:51,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:51,245] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:17:51,246] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:51,247] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:17:51,249] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:51,250] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:17:51,250] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:51,251] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:17:51,256] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:51,269] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 21:17:51,295] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 21:17:51,295] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 21:17:51,340] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 21:17:51,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 21:18:01,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:18:01,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.66666666666667, 17.0, 1.0, 2.0, 0.6801120035297882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839550.5521890807, 839550.5521890807, 174976.6961659246]
[2019-03-23 21:18:01,983] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:01,985] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.27532364834895195
[2019-03-23 21:18:37,412] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:18:37,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.93333333333333, 78.0, 1.0, 2.0, 0.5822903748368836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676787.5739134444, 676787.5739134444, 155685.6868422117]
[2019-03-23 21:18:37,414] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:37,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8650698284944851
[2019-03-23 21:18:37,779] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:18:37,780] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.26666666666667, 34.33333333333334, 1.0, 2.0, 0.5560247891858069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 641855.7125221805, 641855.71252218, 151077.8412127146]
[2019-03-23 21:18:37,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:37,784] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.022820598350904775
[2019-03-23 21:18:52,977] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:18:52,978] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.92255447333334, 84.5784425, 1.0, 2.0, 0.4599735290797589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 555749.4262820132, 555749.4262820127, 136994.9948151754]
[2019-03-23 21:18:52,978] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:18:52,981] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6787219710695113
[2019-03-23 21:18:54,745] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:18:54,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.7, 95.0, 1.0, 2.0, 0.6177783609722018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716224.4410683787, 716224.4410683787, 161749.789697329]
[2019-03-23 21:18:54,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:54,750] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7297343947644174
[2019-03-23 21:19:13,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.30617642]
[2019-03-23 21:19:13,888] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.93048749, 68.96993191499999, 1.0, 2.0, 0.6702039457992793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763825.9843892198, 763825.9843892198, 170579.0245012564]
[2019-03-23 21:19:13,890] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:19:13,892] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.894824e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.717302555283516
[2019-03-23 21:19:31,062] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:19:31,066] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:19:31,120] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:19:31,225] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:19:31,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:19:32,263] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 725000, evaluation results [725000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:19:36,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3791566e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:19:36,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-23 21:19:36,209] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.8426452876225553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972214.9253807475, 972214.9253807475, 205526.0374113541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3381000.0000, 
sim time next is 3381600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.7864928973728856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 907434.9278149928, 907434.9278149924, 193730.4333058883], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.7458248778248638, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32408390279106886, 0.3240839027910687, 0.3725585255882467], 
reward next is 0.6274, 
noisyNet noise sample is [array([-0.26240098], dtype=float32), -1.5346166]. 
=============================================
[2019-03-23 21:19:37,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.34916865e-14 1.00000000e+00 1.48164076e-23 1.99965898e-25
 1.08591545e-24], sum to 1.0000
[2019-03-23 21:19:37,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3207
[2019-03-23 21:19:37,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2131543.95130853 W.
[2019-03-23 21:19:37,485] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.4, 59.33333333333333, 1.0, 2.0, 0.9343544630229277, 1.0, 2.0, 0.9343544630229277, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2131543.95130853, 2131543.951308529, 402399.6292881799], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [31.7, 59.16666666666667, 1.0, 2.0, 0.6549561898546012, 1.0, 2.0, 0.6408427569037353, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2193007.934024192, 2193007.934024193, 417355.3579591708], 
processed observation next is [1.0, 0.6086956521739131, 0.7296296296296296, 0.5916666666666667, 1.0, 1.0, 0.5892335593507158, 1.0, 1.0, 0.5724318534568277, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7832171192943542, 0.7832171192943546, 0.80260645761379], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.96952593], dtype=float32), 1.0673461]. 
=============================================
[2019-03-23 21:19:37,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[30.57483]
 [30.57483]
 [30.57483]
 [30.57483]
 [30.57483]], R is [[30.26908493]
 [29.96639442]
 [29.89293671]
 [29.85464668]
 [29.55610085]].
[2019-03-23 21:19:50,970] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8712380e-21 1.0000000e+00 2.6124460e-34 3.2008675e-37 7.3915386e-37], sum to 1.0000
[2019-03-23 21:19:50,977] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-23 21:19:50,982] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.3554689502314752, 1.0, 1.0, 0.3554689502314752, 1.0, 1.0, 0.565918145583998, 6.911199999999999, 6.9112, 121.94756008, 1215733.237497013, 1215733.237497013, 278124.9993711254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3668400.0000, 
sim time next is 3669000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.9090433078366024, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.926042553525, 1045604.15753304, 1045604.15753304, 220008.0627639077], 
processed observation next is [1.0, 0.4782608695652174, 0.4074074074074074, 1.0, 1.0, 1.0, 0.8917182236150029, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621284076121, 0.37343005626180004, 0.37343005626180004, 0.42309242839213024], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7743865], dtype=float32), 0.19140977]. 
=============================================
[2019-03-23 21:19:50,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.488777]
 [48.488777]
 [48.488777]
 [48.488777]
 [48.488777]], R is [[48.00388336]
 [47.52384567]
 [47.04860687]
 [46.57812119]
 [46.11233902]].
[2019-03-23 21:20:13,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.482158e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:20:13,582] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-23 21:20:13,585] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.35, 97.5, 1.0, 2.0, 0.5151642535870137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631031.8969552998, 631031.8969552998, 145838.1476494271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069800.0000, 
sim time next is 4070400.0000, 
raw observation next is [20.23333333333333, 98.33333333333333, 1.0, 2.0, 0.4872504576308698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597116.9283570194, 597116.9283570194, 141422.0694788536], 
processed observation next is [1.0, 0.08695652173913043, 0.3049382716049382, 0.9833333333333333, 1.0, 1.0, 0.38958387813198786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21325604584179267, 0.21325604584179267, 0.27196551822856463], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.19759914], dtype=float32), 1.0896313]. 
=============================================
[2019-03-23 21:20:17,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6957576e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:20:17,119] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1360
[2019-03-23 21:20:17,122] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.98333333333333, 99.83333333333334, 1.0, 2.0, 0.4153811282243607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509954.4578166292, 509954.4578166292, 130691.4825925105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4168200.0000, 
sim time next is 4168800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4178558864638895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512709.520101499, 512709.520101499, 131039.2413173896], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 1.0, 1.0, 1.0, 0.3069712934093922, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1831105428933925, 0.1831105428933925, 0.25199854099498004], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.02146047], dtype=float32), -1.2686932]. 
=============================================
[2019-03-23 21:20:18,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.757525e-24 1.000000e+00 3.943718e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:20:18,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-23 21:20:18,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1643701.185605705 W.
[2019-03-23 21:20:18,928] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 29.66666666666666, 1.0, 2.0, 0.6977974481576589, 1.0, 2.0, 0.6977974481576589, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1643701.185605705, 1643701.185605705, 305831.3993881799], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4200000.0000, 
sim time next is 4200600.0000, 
raw observation next is [34.13333333333333, 30.33333333333334, 1.0, 2.0, 0.7163786108635963, 1.0, 2.0, 0.7163786108635963, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1685542.344811651, 1685542.344811652, 312908.6640221058], 
processed observation next is [1.0, 0.6086956521739131, 0.8197530864197531, 0.3033333333333334, 1.0, 1.0, 0.662355489123329, 1.0, 1.0, 0.662355489123329, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6019794088613039, 0.6019794088613043, 0.601747430811742], 
reward next is 0.3983, 
noisyNet noise sample is [array([0.02125444], dtype=float32), -1.9765761]. 
=============================================
[2019-03-23 21:20:19,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8071139e-17 1.0000000e+00 8.4558474e-28 1.9091969e-30 1.9447593e-30], sum to 1.0000
[2019-03-23 21:20:19,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2828
[2019-03-23 21:20:19,350] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1588093.360485427 W.
[2019-03-23 21:20:19,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.08333333333333, 28.5, 1.0, 2.0, 0.4530636876568656, 1.0, 2.0, 0.4530636876568656, 1.0, 2.0, 0.7237528617857426, 6.911200000000001, 6.9112, 121.94756008, 1588093.360485427, 1588093.360485427, 321201.3950921373], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4197000.0000, 
sim time next is 4197600.0000, 
raw observation next is [34.3, 27.0, 1.0, 2.0, 0.6724063658404571, 1.0, 2.0, 0.6724063658404571, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1597446.280748452, 1597446.280748452, 296807.176998489], 
processed observation next is [1.0, 0.6086956521739131, 0.8259259259259258, 0.27, 1.0, 1.0, 0.6100075783814966, 1.0, 1.0, 0.6100075783814966, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5705165288387328, 0.5705165288387328, 0.5707830326894019], 
reward next is 0.4292, 
noisyNet noise sample is [array([-0.57052135], dtype=float32), 1.0260135]. 
=============================================
[2019-03-23 21:20:22,785] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:20:22,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:20:22,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:20:22,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:20:22,788] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:20:22,791] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:20:22,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:20:22,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:20:22,794] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:20:22,794] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:20:22,796] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:20:22,808] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 21:20:22,831] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 21:20:22,865] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 21:20:22,888] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 21:20:22,915] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 21:21:10,635] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37063122]
[2019-03-23 21:21:10,640] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.536185105, 61.129499825, 1.0, 2.0, 0.6718219962631347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775480.7553454658, 775480.7553454658, 171363.6974482808]
[2019-03-23 21:21:10,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:21:10,644] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5329447e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.42619222976495275
[2019-03-23 21:21:19,541] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37063122]
[2019-03-23 21:21:19,542] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.76341854, 101.0743340833333, 1.0, 2.0, 0.4295863639886432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 522310.4908042708, 522310.4908042703, 132602.3442840497]
[2019-03-23 21:21:19,544] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:21:19,550] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5329447e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4719216651667386
[2019-03-23 21:21:40,790] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37063122]
[2019-03-23 21:21:40,791] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.895456615, 80.58677869, 1.0, 2.0, 0.4644760469226247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556892.7733639957, 556892.7733639957, 137529.5230899308]
[2019-03-23 21:21:40,792] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:21:40,794] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5329447e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5250278068795591
[2019-03-23 21:21:47,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37063122]
[2019-03-23 21:21:47,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666666, 94.0, 1.0, 2.0, 0.6013748964640909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685347.0099875702, 685347.0099875702, 158314.4823587722]
[2019-03-23 21:21:47,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:21:47,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5329447e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9081129599241623
[2019-03-23 21:22:01,927] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:22:02,412] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:22:02,443] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:22:02,555] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:22:02,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:22:03,575] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 750000, evaluation results [750000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:22:05,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7241701e-16 1.0000000e+00 1.2640114e-24 4.2052680e-27 1.0292959e-27], sum to 1.0000
[2019-03-23 21:22:05,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7349
[2019-03-23 21:22:05,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2092828.983718703 W.
[2019-03-23 21:22:05,313] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.63333333333334, 44.0, 1.0, 2.0, 0.9174037638297314, 1.0, 2.0, 0.9174037638297314, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2092828.983718703, 2092828.983718703, 394654.2547614408], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4292400.0000, 
sim time next is 4293000.0000, 
raw observation next is [32.45, 44.0, 1.0, 2.0, 0.8965990435460994, 1.0, 2.0, 0.8965990435460994, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2045313.823887469, 2045313.823887469, 385285.9023369657], 
processed observation next is [1.0, 0.6956521739130435, 0.7574074074074075, 0.44, 1.0, 1.0, 0.8769036232691659, 1.0, 1.0, 0.8769036232691659, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7304692228169533, 0.7304692228169533, 0.740934427571088], 
reward next is 0.2591, 
noisyNet noise sample is [array([-0.99024254], dtype=float32), 0.44540974]. 
=============================================
[2019-03-23 21:22:05,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[34.135082]
 [34.135082]
 [34.135082]
 [34.135082]
 [34.135082]], R is [[34.05279922]
 [33.95332336]
 [33.87395859]
 [33.74925613]
 [33.62186813]].
[2019-03-23 21:22:07,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3987514e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:07,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1207
[2019-03-23 21:22:07,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1978080.066721098 W.
[2019-03-23 21:22:07,344] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 67.33333333333334, 1.0, 2.0, 0.5781058180408412, 1.0, 2.0, 0.5781058180408412, 1.0, 2.0, 0.9203632899130901, 6.911199999999999, 6.9112, 121.94756008, 1978080.066721098, 1978080.066721098, 383575.6222456161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4634400.0000, 
sim time next is 4635000.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.812916745398658, 6.9112, 121.9225375503443, 2340308.498195502, 1878562.204442806, 380895.8955772354], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.68, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.09017167453986578, 0.0, 0.8094388588314387, 0.8358244636412507, 0.6709150730152879, 0.7324921068792988], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08453699], dtype=float32), -0.26806682]. 
=============================================
[2019-03-23 21:22:07,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.310974]
 [68.310974]
 [68.310974]
 [68.310974]
 [68.310974]], R is [[67.62786102]
 [67.21393585]
 [66.79542542]
 [66.3524704 ]
 [65.94441986]].
[2019-03-23 21:22:14,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8849627e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:14,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8317
[2019-03-23 21:22:14,381] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7072838569960311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806107.879373672, 806107.879373672, 177527.620172185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485600.0000, 
sim time next is 4486200.0000, 
raw observation next is [26.73333333333333, 84.33333333333333, 1.0, 2.0, 0.6878113538315278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783903.2653246428, 783903.2653246428, 173849.0769777434], 
processed observation next is [0.0, 0.9565217391304348, 0.545679012345679, 0.8433333333333333, 1.0, 1.0, 0.6283468497994379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2799654519016581, 0.2799654519016581, 0.3343251480341219], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.78923935], dtype=float32), -0.023726594]. 
=============================================
[2019-03-23 21:22:14,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8468099e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:14,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-23 21:22:14,685] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6739670083472675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768116.8650125649, 768116.8650125649, 171274.6241884334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4468800.0000, 
sim time next is 4469400.0000, 
raw observation next is [29.25, 70.0, 1.0, 2.0, 0.6916875109710893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788323.2196592778, 788323.2196592778, 174576.7692202626], 
processed observation next is [0.0, 0.7391304347826086, 0.6388888888888888, 0.7, 1.0, 1.0, 0.6329613225846301, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28154400702117066, 0.28154400702117066, 0.33572455619281266], 
reward next is 0.6643, 
noisyNet noise sample is [array([0.71414393], dtype=float32), -2.9350717]. 
=============================================
[2019-03-23 21:22:15,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6556015e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:15,242] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6105
[2019-03-23 21:22:15,246] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 82.0, 1.0, 2.0, 0.7092177618125035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 808313.1579388967, 808313.1579388962, 177895.9574639437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4478400.0000, 
sim time next is 4479000.0000, 
raw observation next is [27.16666666666667, 82.33333333333334, 1.0, 2.0, 0.7065217970410074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805238.8856674564, 805238.8856674564, 177382.0618437039], 
processed observation next is [0.0, 0.8695652173913043, 0.5617283950617286, 0.8233333333333335, 1.0, 1.0, 0.6506211869535802, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2875853163098059, 0.2875853163098059, 0.3411193496994306], 
reward next is 0.6589, 
noisyNet noise sample is [array([1.2433015], dtype=float32), 0.7669109]. 
=============================================
[2019-03-23 21:22:15,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.08461]
 [66.08461]
 [66.08461]
 [66.08461]
 [66.08461]], R is [[66.08264923]
 [66.07971191]
 [66.07327271]
 [66.0634613 ]
 [66.05167389]].
[2019-03-23 21:22:17,233] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4116706e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:17,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1576
[2019-03-23 21:22:17,246] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 91.16666666666667, 1.0, 2.0, 0.5786809594054658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672625.5278761603, 672625.5278761603, 155074.2927513998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [24.2, 91.0, 1.0, 2.0, 0.5852850402488553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678714.2085457573, 678714.2085457573, 156125.4731403083], 
processed observation next is [0.0, 0.391304347826087, 0.45185185185185184, 0.91, 1.0, 1.0, 0.5062917145819705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24239793162348477, 0.24239793162348477, 0.3002412945005929], 
reward next is 0.6998, 
noisyNet noise sample is [array([0.5201132], dtype=float32), 2.1289093]. 
=============================================
[2019-03-23 21:22:24,882] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5745313e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:24,888] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4429
[2019-03-23 21:22:24,893] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 93.16666666666667, 1.0, 2.0, 0.6638812815026642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756616.5389298984, 756616.5389298984, 169417.7541399139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4665000.0000, 
sim time next is 4665600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6643972854834339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757204.9121717567, 757204.9121717567, 169512.2661281285], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6004729589088499, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2704303257756274, 0.2704303257756274, 0.3259851271694779], 
reward next is 0.6740, 
noisyNet noise sample is [array([0.8683826], dtype=float32), 1.5647572]. 
=============================================
[2019-03-23 21:22:37,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1740355e-13 1.0000000e+00 5.2978976e-20 3.3607837e-21 6.3244198e-21], sum to 1.0000
[2019-03-23 21:22:37,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6880
[2019-03-23 21:22:37,530] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.9623863264738182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.978461711434527, 6.9112, 121.9254907807397, 1143666.421620131, 1109222.569475021, 232448.0796094096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.9135093414925953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.92600208384, 1053599.239415883, 1053599.239415883, 221175.2313743659], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.8970349303483278, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618597309894, 0.3762854426485297, 0.3762854426485297, 0.4253369834122421], 
reward next is 0.5747, 
noisyNet noise sample is [array([-0.2709236], dtype=float32), 0.40326163]. 
=============================================
[2019-03-23 21:22:46,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3286889e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:22:46,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7576
[2019-03-23 21:22:46,449] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 78.33333333333334, 1.0, 2.0, 0.7992313664056755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 910964.8759796886, 910964.8759796881, 195791.6165877117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5055000.0000, 
sim time next is 5055600.0000, 
raw observation next is [30.0, 77.66666666666667, 1.0, 2.0, 0.8166722960570594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930856.1417673173, 930856.1417673173, 199418.4605122858], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.7766666666666667, 1.0, 1.0, 0.7817527334012612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33244862205975617, 0.33244862205975617, 0.38349703944670344], 
reward next is 0.6165, 
noisyNet noise sample is [array([2.550398], dtype=float32), -0.1593501]. 
=============================================
[2019-03-23 21:22:49,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.496398e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:22:49,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9503
[2019-03-23 21:22:49,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.28333333333333, 98.83333333333334, 1.0, 2.0, 0.7018959988453126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 799964.0075151563, 799964.0075151568, 176505.2395466994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [25.56666666666667, 97.66666666666667, 1.0, 2.0, 0.7172957570061383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817524.7603789673, 817524.7603789673, 179446.5098408479], 
processed observation next is [0.0, 0.30434782608695654, 0.5024691358024692, 0.9766666666666667, 1.0, 1.0, 0.6634473297692123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.291973128706774, 0.291973128706774, 0.34508944200163055], 
reward next is 0.6549, 
noisyNet noise sample is [array([-1.1055695], dtype=float32), 0.7656352]. 
=============================================
[2019-03-23 21:22:49,585] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.614105]
 [68.614105]
 [68.614105]
 [68.614105]
 [68.614105]], R is [[68.58286285]
 [68.55760193]
 [68.52913666]
 [68.50099182]
 [68.47319031]].
[2019-03-23 21:22:53,961] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 21:22:53,962] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:22:53,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:53,963] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:22:53,963] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:22:53,964] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:53,964] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:53,964] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:22:53,965] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:22:53,966] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:53,967] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:53,984] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 21:22:53,984] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 21:22:54,033] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 21:22:54,057] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 21:22:54,085] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 21:23:10,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37732282]
[2019-03-23 21:23:10,647] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.5, 54.83333333333334, 1.0, 2.0, 0.2391749025844984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 308512.2379648568, 308512.2379648568, 105591.9304942605]
[2019-03-23 21:23:10,648] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:23:10,650] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9475822e-24 1.0000000e+00 4.5462424e-38 0.0000000e+00 0.0000000e+00], sampled 0.3240026494128254
[2019-03-23 21:23:17,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37732282]
[2019-03-23 21:23:17,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.74695714333333, 70.27691049833334, 1.0, 2.0, 0.3070949026950202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394400.9229830519, 394400.9229830519, 116454.7751767446]
[2019-03-23 21:23:17,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:23:17,917] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9475822e-24 1.0000000e+00 4.5462424e-38 0.0000000e+00 0.0000000e+00], sampled 0.01239920947373152
[2019-03-23 21:24:22,409] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37732282]
[2019-03-23 21:24:22,409] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.46666666666667, 89.66666666666667, 1.0, 2.0, 0.5217904899143891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616410.1331641085, 616410.1331641085, 146131.9743577304]
[2019-03-23 21:24:22,411] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:24:22,414] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9475822e-24 1.0000000e+00 4.5462424e-38 0.0000000e+00 0.0000000e+00], sampled 0.601281758390105
[2019-03-23 21:24:32,653] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.37732282]
[2019-03-23 21:24:32,654] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.2684960368081432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 345513.6175035736, 345513.6175035741, 111765.5448902484]
[2019-03-23 21:24:32,655] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:24:32,656] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9475822e-24 1.0000000e+00 4.5462424e-38 0.0000000e+00 0.0000000e+00], sampled 0.393520337837703
[2019-03-23 21:24:34,036] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:24:34,183] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:24:34,259] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:24:34,370] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:24:34,409] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:24:35,425] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 775000, evaluation results [775000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:24:35,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5192287e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:24:35,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1908
[2019-03-23 21:24:35,829] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 96.0, 1.0, 2.0, 0.7051404431176043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816160.9928181246, 816160.9928181246, 177738.9671563395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5202000.0000, 
sim time next is 5202600.0000, 
raw observation next is [23.5, 96.66666666666666, 1.0, 2.0, 0.8109669078198083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 938980.736852728, 938980.736852728, 198971.0909657835], 
processed observation next is [1.0, 0.21739130434782608, 0.42592592592592593, 0.9666666666666666, 1.0, 1.0, 0.7749606045473908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33535026316168853, 0.33535026316168853, 0.3826367133957375], 
reward next is 0.6174, 
noisyNet noise sample is [array([-0.16827145], dtype=float32), -0.6652087]. 
=============================================
[2019-03-23 21:24:37,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4003551e-13 1.0000000e+00 3.8487652e-21 9.5503666e-24 1.2955338e-22], sum to 1.0000
[2019-03-23 21:24:37,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7151
[2019-03-23 21:24:37,376] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.45, 79.0, 1.0, 2.0, 0.7129299869823983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812546.3161122086, 812546.3161122086, 178609.8480046205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5250600.0000, 
sim time next is 5251200.0000, 
raw observation next is [28.26666666666667, 80.66666666666667, 1.0, 2.0, 0.7215567044299812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822383.7028541719, 822383.7028541719, 180268.9503446057], 
processed observation next is [1.0, 0.782608695652174, 0.6024691358024692, 0.8066666666666668, 1.0, 1.0, 0.6685198862261681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2937084653050614, 0.2937084653050614, 0.34667105835501094], 
reward next is 0.6533, 
noisyNet noise sample is [array([-1.5585318], dtype=float32), -1.681138]. 
=============================================
[2019-03-23 21:24:41,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1253320e-19 1.0000000e+00 1.5653309e-30 1.8812742e-32 3.7967430e-32], sum to 1.0000
[2019-03-23 21:24:41,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0454
[2019-03-23 21:24:41,323] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.6975119125361281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794964.7911373801, 794964.7911373801, 175673.7941017581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [25.56666666666667, 93.33333333333334, 1.0, 2.0, 0.6937312972677965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790653.7448559483, 790653.7448559483, 174960.5993993781], 
processed observation next is [1.0, 0.8695652173913043, 0.5024691358024692, 0.9333333333333335, 1.0, 1.0, 0.6353944015092815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28237633744855295, 0.28237633744855295, 0.33646269115265015], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.05640556], dtype=float32), 0.011058322]. 
=============================================
[2019-03-23 21:24:41,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1900263e-18 1.0000000e+00 2.4645119e-28 1.2973089e-30 5.0632149e-30], sum to 1.0000
[2019-03-23 21:24:41,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-23 21:24:41,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1430377.067848529 W.
[2019-03-23 21:24:41,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 75.0, 1.0, 2.0, 0.4181702498249862, 1.0, 2.0, 0.4181702498249862, 1.0, 2.0, 0.6657406565756332, 6.9112, 6.9112, 121.94756008, 1430377.067848529, 1430377.067848529, 305133.1662760464], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5313600.0000, 
sim time next is 5314200.0000, 
raw observation next is [26.08333333333333, 74.0, 1.0, 2.0, 0.7511561610561442, 1.0, 2.0, 0.7511561610561442, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1713212.595403471, 1713212.595403471, 323982.9515537106], 
processed observation next is [1.0, 0.5217391304347826, 0.5216049382716048, 0.74, 1.0, 1.0, 0.7037573345906479, 1.0, 1.0, 0.7037573345906479, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6118616412155253, 0.6118616412155253, 0.6230441376032897], 
reward next is 0.3770, 
noisyNet noise sample is [array([-0.00344988], dtype=float32), -0.63316834]. 
=============================================
[2019-03-23 21:24:47,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5847607e-22 1.0000000e+00 6.1300986e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:24:47,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-23 21:24:48,002] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1870477.196212102 W.
[2019-03-23 21:24:48,007] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 80.0, 1.0, 2.0, 0.5466911217955893, 1.0, 1.0, 0.5466911217955893, 1.0, 2.0, 0.8703500703854192, 6.911199999999999, 6.9112, 121.94756008, 1870477.196212102, 1870477.196212103, 367096.183258917], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5409000.0000, 
sim time next is 5409600.0000, 
raw observation next is [28.26666666666667, 81.33333333333334, 1.0, 2.0, 0.8272162968108018, 1.0, 2.0, 0.8272162968108018, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1886871.311344265, 1886871.311344265, 355129.9027269531], 
processed observation next is [1.0, 0.6086956521739131, 0.6024691358024692, 0.8133333333333335, 1.0, 1.0, 0.7943051152509545, 1.0, 1.0, 0.7943051152509545, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6738826111943803, 0.6738826111943803, 0.6829421206287559], 
reward next is 0.3171, 
noisyNet noise sample is [array([0.04168124], dtype=float32), 0.8527744]. 
=============================================
[2019-03-23 21:24:48,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.233906e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:24:48,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9185
[2019-03-23 21:24:48,563] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 91.33333333333333, 1.0, 2.0, 0.7462812850114514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850578.8184781222, 850578.8184781222, 185094.7973182434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5445600.0000, 
sim time next is 5446200.0000, 
raw observation next is [26.75, 91.66666666666667, 1.0, 2.0, 0.7453816407253178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849552.8749165284, 849552.8749165284, 184917.3462257712], 
processed observation next is [1.0, 0.0, 0.5462962962962963, 0.9166666666666667, 1.0, 1.0, 0.6968829056253782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3034117410416173, 0.3034117410416173, 0.35561028120340615], 
reward next is 0.6444, 
noisyNet noise sample is [array([-1.3372297], dtype=float32), -1.4442523]. 
=============================================
[2019-03-23 21:25:08,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6451474e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:25:08,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4953
[2019-03-23 21:25:08,371] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 78.0, 1.0, 2.0, 0.5015690723484025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608338.4231012223, 608338.4231012223, 143488.0198972076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817600.0000, 
sim time next is 5818200.0000, 
raw observation next is [23.66666666666667, 76.0, 1.0, 2.0, 0.5818576854634288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706586.9649667003, 706586.9649667003, 156782.9858275905], 
processed observation next is [1.0, 0.34782608695652173, 0.43209876543209896, 0.76, 1.0, 1.0, 0.5022115303136057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25235248748810724, 0.25235248748810724, 0.3015057419761356], 
reward next is 0.6985, 
noisyNet noise sample is [array([-2.13771], dtype=float32), -0.14823866]. 
=============================================
[2019-03-23 21:25:21,704] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5027378e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:25:21,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9797
[2019-03-23 21:25:21,720] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.33333333333334, 1.0, 2.0, 0.6715354160251952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805123.7029233002, 805123.7029233002, 172593.3069848037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [22.55, 90.0, 1.0, 2.0, 0.5922829493553897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710111.4878193743, 710111.4878193743, 158279.7568211124], 
processed observation next is [1.0, 0.08695652173913043, 0.3907407407407408, 0.9, 1.0, 1.0, 0.5146225587564163, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25361124564977655, 0.25361124564977655, 0.30438414773290845], 
reward next is 0.6956, 
noisyNet noise sample is [array([-1.2895628], dtype=float32), 0.85983896]. 
=============================================
[2019-03-23 21:25:21,736] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.49899]
 [71.49899]
 [71.49899]
 [71.49899]
 [71.49899]], R is [[71.47962952]
 [71.43292236]
 [71.34060669]
 [71.35385132]
 [71.36639404]].
[2019-03-23 21:25:25,866] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 21:25:25,868] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:25:25,869] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:25:25,870] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:25:25,871] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:25:25,871] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:25:25,871] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:25:25,871] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:25:25,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:25:25,872] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:25:25,874] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:25:25,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 21:25:25,918] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 21:25:25,941] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 21:25:25,969] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 21:25:25,992] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 21:25:36,807] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3786183]
[2019-03-23 21:25:36,809] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.68506644666667, 54.382755785, 1.0, 2.0, 0.7040596578484999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860213.2668050057, 860213.2668050057, 179336.9056138093]
[2019-03-23 21:25:36,810] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:25:36,813] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5862392e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6191879533930759
[2019-03-23 21:25:43,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3786183]
[2019-03-23 21:25:43,584] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.12282037666667, 87.55078323000001, 1.0, 2.0, 0.3168259021403946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401037.693211404, 401037.693211404, 117658.7451345707]
[2019-03-23 21:25:43,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:25:43,588] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5862392e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.17122866806059267
[2019-03-23 21:26:58,787] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3786183]
[2019-03-23 21:26:58,787] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.23333333333333, 72.66666666666667, 1.0, 2.0, 0.4175315469351801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514373.6308493998, 514373.6308493993, 131045.8785575341]
[2019-03-23 21:26:58,787] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:26:58,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5862392e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3833524048433058
[2019-03-23 21:26:59,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3786183]
[2019-03-23 21:26:59,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.2, 68.66666666666667, 1.0, 2.0, 0.6220488173526221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156553, 751438.2528803647, 751438.2528803647, 163724.6807120238]
[2019-03-23 21:26:59,524] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:26:59,528] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5862392e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.32535454002955166
[2019-03-23 21:27:06,024] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:27:06,024] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:27:06,075] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:27:06,084] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:27:06,309] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:27:07,323] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 800000, evaluation results [800000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:27:09,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5438939e-19 1.0000000e+00 1.5155410e-28 4.3089088e-32 3.1719481e-31], sum to 1.0000
[2019-03-23 21:27:09,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-23 21:27:09,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.53333333333333, 54.33333333333333, 1.0, 2.0, 0.5078946649955354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597255.3749149906, 597255.3749149906, 143808.2343565885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198000.0000, 
sim time next is 6198600.0000, 
raw observation next is [29.41666666666667, 55.16666666666667, 1.0, 2.0, 0.5209497850146838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611975.0662026742, 611975.0662026742, 145856.8548426119], 
processed observation next is [1.0, 0.7391304347826086, 0.6450617283950619, 0.5516666666666667, 1.0, 1.0, 0.42970212501748073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185625236438122, 0.2185625236438122, 0.2804939516204075], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.91718096], dtype=float32), 0.6077569]. 
=============================================
[2019-03-23 21:27:09,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4686873e-19 1.0000000e+00 5.2460654e-30 1.4987045e-32 3.8050073e-32], sum to 1.0000
[2019-03-23 21:27:09,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0554
[2019-03-23 21:27:09,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1802537.194716822 W.
[2019-03-23 21:27:09,800] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 54.0, 1.0, 2.0, 0.790280957316825, 1.0, 1.0, 0.790280957316825, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802537.194716822, 1802537.194716823, 339753.0984416734], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6188400.0000, 
sim time next is 6189000.0000, 
raw observation next is [29.9, 53.83333333333333, 1.0, 2.0, 0.8349806584843247, 1.0, 2.0, 0.8349806584843247, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1904600.618990157, 1904600.618990158, 358419.3369182386], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.5383333333333333, 1.0, 1.0, 0.8035484029575294, 1.0, 1.0, 0.8035484029575294, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.680214506782199, 0.6802145067821993, 0.6892679556119973], 
reward next is 0.3107, 
noisyNet noise sample is [array([1.0387732], dtype=float32), 0.049680464]. 
=============================================
[2019-03-23 21:27:09,815] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[44.1376]
 [44.1376]
 [44.1376]
 [44.1376]
 [44.1376]], R is [[44.00696564]
 [43.91352463]
 [43.76881409]
 [43.62537384]
 [43.48217392]].
[2019-03-23 21:27:10,084] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.7880338e-17 1.0000000e+00 2.2258918e-26 6.0617507e-29 1.2310173e-28], sum to 1.0000
[2019-03-23 21:27:10,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-23 21:27:10,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1799596.901022992 W.
[2019-03-23 21:27:10,102] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.86666666666667, 54.33333333333334, 1.0, 2.0, 0.9478058592759226, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9943545735737577, 6.911199999999998, 6.9112, 121.9260426156618, 1799596.901022992, 1799596.901022993, 366996.7289261215], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6187200.0000, 
sim time next is 6187800.0000, 
raw observation next is [29.88333333333333, 54.16666666666666, 1.0, 2.0, 0.5260488142189091, 1.0, 1.0, 0.5260488142189091, 1.0, 2.0, 0.8374868444503204, 6.911200000000001, 6.9112, 121.94756008, 1799779.396883696, 1799779.396883696, 356558.0325463067], 
processed observation next is [1.0, 0.6086956521739131, 0.6623456790123455, 0.5416666666666665, 1.0, 1.0, 0.4357723978796537, 1.0, 0.5, 0.4357723978796537, 1.0, 1.0, 0.7968585555629004, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6427783560298914, 0.6427783560298914, 0.6856885241275129], 
reward next is 0.3143, 
noisyNet noise sample is [array([1.0634913], dtype=float32), 1.8283129]. 
=============================================
[2019-03-23 21:27:11,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8782205e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:11,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8469
[2019-03-23 21:27:11,470] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1799698.667119212 W.
[2019-03-23 21:27:11,476] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.88333333333333, 54.16666666666666, 1.0, 2.0, 0.9513461213644878, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1799698.667119212, 1799698.667119212, 368280.0139218788], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6187800.0000, 
sim time next is 6188400.0000, 
raw observation next is [29.9, 54.0, 1.0, 2.0, 0.7902809518866328, 1.0, 1.0, 0.7902809518866328, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802537.1823187, 1802537.1823187, 339753.1002679807], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.54, 1.0, 1.0, 0.7503344665317058, 1.0, 0.5, 0.7503344665317058, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6437632793995357, 0.6437632793995357, 0.6533713466691937], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4996883], dtype=float32), -0.120735504]. 
=============================================
[2019-03-23 21:27:13,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5092164e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:13,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9308
[2019-03-23 21:27:13,049] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 89.0, 1.0, 2.0, 0.4713114215327286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569874.2895561907, 569874.2895561903, 138727.6561805833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6238800.0000, 
sim time next is 6239400.0000, 
raw observation next is [22.31666666666667, 88.66666666666667, 1.0, 2.0, 0.4733739762791322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571891.9158904561, 571891.9158904565, 139027.5690298678], 
processed observation next is [0.0, 0.21739130434782608, 0.38209876543209886, 0.8866666666666667, 1.0, 1.0, 0.3730642574751574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20424711281802002, 0.2042471128180202, 0.26736070967282266], 
reward next is 0.7326, 
noisyNet noise sample is [array([1.5266448], dtype=float32), 0.04552426]. 
=============================================
[2019-03-23 21:27:14,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1150719e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:14,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1360
[2019-03-23 21:27:14,057] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 66.0, 1.0, 2.0, 0.6292031585544916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717252.6895110175, 717252.6895110175, 163181.9238293973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6268800.0000, 
sim time next is 6269400.0000, 
raw observation next is [29.0, 65.5, 1.0, 2.0, 0.6310399585035453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719170.1683390286, 719170.1683390286, 163498.5566848642], 
processed observation next is [0.0, 0.5652173913043478, 0.6296296296296297, 0.655, 1.0, 1.0, 0.5607618553613635, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2568464886925102, 0.2568464886925102, 0.3144203013170465], 
reward next is 0.6856, 
noisyNet noise sample is [array([-0.6536053], dtype=float32), 0.40109193]. 
=============================================
[2019-03-23 21:27:14,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6375505e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:14,734] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0431
[2019-03-23 21:27:14,742] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 55.33333333333333, 1.0, 2.0, 0.4016593484904655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497441.1045848861, 497441.1045848861, 128847.7229830337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6572400.0000, 
sim time next is 6573000.0000, 
raw observation next is [25.63333333333333, 53.66666666666666, 1.0, 2.0, 0.3885985542534029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483308.9249505846, 483308.9249505841, 127063.4032977015], 
processed observation next is [1.0, 0.043478260869565216, 0.5049382716049381, 0.5366666666666666, 1.0, 1.0, 0.27214113601595585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1726103303394945, 0.17261033033949433, 0.24435269864942596], 
reward next is 0.7556, 
noisyNet noise sample is [array([1.5016277], dtype=float32), -0.5081736]. 
=============================================
[2019-03-23 21:27:14,755] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.84864]
 [75.84864]
 [75.84864]
 [75.84864]
 [75.84864]], R is [[75.84580994]
 [75.83956146]
 [75.82989502]
 [75.81664276]
 [75.79969025]].
[2019-03-23 21:27:20,227] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.520858e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:27:20,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3363
[2019-03-23 21:27:20,243] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 89.66666666666667, 1.0, 2.0, 0.3642301650912191, 1.0, 1.0, 0.3642301650912191, 1.0, 2.0, 0.5798662849735582, 6.9112, 6.9112, 121.94756008, 1245721.67660043, 1245721.67660043, 281767.7335935439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6405600.0000, 
sim time next is 6406200.0000, 
raw observation next is [25.2, 90.0, 1.0, 2.0, 1.017349781974202, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.251566664748762, 6.9112, 121.9245870236541, 1334192.681516073, 1159896.608364405, 244932.9481378706], 
processed observation next is [1.0, 0.13043478260869565, 0.4888888888888889, 0.9, 1.0, 1.0, 1.0206545023502402, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03403666647487622, 0.0, 0.8094524652029138, 0.47649738625574034, 0.4142487887015733, 0.47102490026513577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9555425], dtype=float32), 0.717355]. 
=============================================
[2019-03-23 21:27:21,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3451944e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:21,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2347
[2019-03-23 21:27:21,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 34.0, 1.0, 2.0, 0.8575837140099016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257479117928, 1088925.504183764, 1088925.504183764, 212171.635119738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6696000.0000, 
sim time next is 6696600.0000, 
raw observation next is [28.05, 33.5, 1.0, 2.0, 0.8195301993023086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425848816, 1040553.207292237, 1040553.207292237, 203814.9327012603], 
processed observation next is [1.0, 0.5217391304347826, 0.5944444444444444, 0.335, 1.0, 1.0, 0.785154999169415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621286157874, 0.3716261454615132, 0.3716261454615132, 0.3919517936562698], 
reward next is 0.6080, 
noisyNet noise sample is [array([0.86220694], dtype=float32), -0.9167229]. 
=============================================
[2019-03-23 21:27:29,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1432797e-21 1.0000000e+00 3.4722599e-35 0.0000000e+00 8.7199614e-38], sum to 1.0000
[2019-03-23 21:27:29,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9902
[2019-03-23 21:27:29,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 47.66666666666666, 1.0, 2.0, 0.3861487184713983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 487058.7513073586, 487058.751307359, 126837.0846498559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6581400.0000, 
sim time next is 6582000.0000, 
raw observation next is [25.6, 47.33333333333333, 1.0, 2.0, 0.3540339220151429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446892.3369879727, 446892.3369879727, 122475.2920264826], 
processed observation next is [1.0, 0.17391304347826086, 0.5037037037037038, 0.4733333333333333, 1.0, 1.0, 0.23099276430374155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1596044060671331, 0.1596044060671331, 0.23552940774323575], 
reward next is 0.7645, 
noisyNet noise sample is [array([0.62959605], dtype=float32), 1.5680922]. 
=============================================
[2019-03-23 21:27:29,993] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[55.78423]
 [55.78423]
 [55.78423]
 [55.78423]
 [55.78423]], R is [[55.99085236]
 [56.18702698]
 [56.37634277]
 [56.55687332]
 [56.73043442]].
[2019-03-23 21:27:35,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.725562e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:27:35,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-23 21:27:35,464] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 49.5, 1.0, 2.0, 0.5153395514461533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659140.0654743013, 659140.0654743013, 146323.5384411184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6683400.0000, 
sim time next is 6684000.0000, 
raw observation next is [23.86666666666667, 48.66666666666667, 1.0, 2.0, 0.5830821874468506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745291.6307558148, 745291.6307558148, 157706.2213339739], 
processed observation next is [1.0, 0.34782608695652173, 0.4395061728395063, 0.4866666666666667, 1.0, 1.0, 0.5036692707700602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.266175582412791, 0.266175582412791, 0.30328119487302674], 
reward next is 0.6967, 
noisyNet noise sample is [array([-1.5462611], dtype=float32), 0.1768938]. 
=============================================
[2019-03-23 21:27:35,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.75181]
 [69.75181]
 [69.75181]
 [69.75181]
 [69.75181]], R is [[69.75100708]
 [69.77210236]
 [69.80658722]
 [69.86698914]
 [69.94500732]].
[2019-03-23 21:27:48,864] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.693601e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:27:48,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4138
[2019-03-23 21:27:48,875] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 59.33333333333334, 1.0, 2.0, 0.4383704275454699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535919.550871799, 535919.550871799, 133971.8442861775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [25.85, 60.0, 1.0, 2.0, 0.436948972285028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534386.5107737497, 534386.5107737492, 133768.4299294778], 
processed observation next is [0.0, 0.8695652173913043, 0.5129629629629631, 0.6, 1.0, 1.0, 0.3297011574821762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19085232527633916, 0.190852325276339, 0.2572469806336112], 
reward next is 0.7428, 
noisyNet noise sample is [array([-0.10805001], dtype=float32), 0.5463922]. 
=============================================
[2019-03-23 21:27:54,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2721196e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:54,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2754
[2019-03-23 21:27:54,071] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333334, 84.66666666666667, 1.0, 2.0, 0.4806847461145044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588869.3645233469, 588869.3645233469, 140396.0718676852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7026000.0000, 
sim time next is 7026600.0000, 
raw observation next is [22.01666666666667, 84.33333333333333, 1.0, 2.0, 0.4617484529060805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565406.1846471156, 565406.1846471156, 137488.4370624188], 
processed observation next is [1.0, 0.30434782608695654, 0.37098765432098774, 0.8433333333333333, 1.0, 1.0, 0.35922434869771497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20193078023111274, 0.20193078023111274, 0.2644008405046515], 
reward next is 0.7356, 
noisyNet noise sample is [array([-0.4533274], dtype=float32), -0.020987354]. 
=============================================
[2019-03-23 21:27:57,275] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0727691e-21 1.0000000e+00 3.1299003e-33 5.2680056e-37 3.0182579e-36], sum to 1.0000
[2019-03-23 21:27:57,285] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2819
[2019-03-23 21:27:57,289] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333333, 79.66666666666666, 1.0, 2.0, 0.4808968388937233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579848.195135524, 579848.195135524, 140146.1321482739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7065600.0000, 
sim time next is 7066200.0000, 
raw observation next is [23.61666666666667, 79.83333333333334, 1.0, 2.0, 0.4805533991697147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579368.7097897033, 579368.7097897033, 140090.9899391512], 
processed observation next is [1.0, 0.782608695652174, 0.4302469135802471, 0.7983333333333335, 1.0, 1.0, 0.38161118948775563, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20691739635346545, 0.20691739635346545, 0.26940574988298305], 
reward next is 0.7306, 
noisyNet noise sample is [array([0.43519482], dtype=float32), -1.4685913]. 
=============================================
[2019-03-23 21:27:57,675] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 21:27:57,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:27:57,678] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:27:57,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:57,679] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:27:57,679] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:57,682] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:27:57,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:27:57,683] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:57,683] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:57,683] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:57,703] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 21:27:57,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 21:27:57,729] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 21:27:57,730] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 21:27:57,796] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 21:28:01,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:01,682] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.63116703, 31.43777221, 1.0, 2.0, 0.3845924488705105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472186.7074450069, 472186.7074450069, 126363.9164659841]
[2019-03-23 21:28:01,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:28:01,686] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9214332205291845
[2019-03-23 21:28:09,050] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:09,051] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.27251332, 47.587904915, 1.0, 2.0, 0.3122705041397438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398345.7241588195, 398345.7241588191, 117104.2615933724]
[2019-03-23 21:28:09,054] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:28:09,059] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.20204136888257407
[2019-03-23 21:28:27,520] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:27,521] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.33687681666667, 44.20131871666667, 1.0, 2.0, 0.5498387418304341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 640512.1850540721, 640512.1850540716, 150320.1137440521]
[2019-03-23 21:28:27,522] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:28:27,525] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.011336929555654018
[2019-03-23 21:28:37,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:37,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.91757587, 92.64509842999999, 1.0, 2.0, 0.4987465704900542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593729.1505531989, 593729.1505531989, 142657.5308501842]
[2019-03-23 21:28:37,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:28:37,356] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3791775484640847
[2019-03-23 21:28:44,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:44,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.77439510333333, 78.47712678, 1.0, 2.0, 0.6926707491283404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789444.4031684339, 789444.4031684339, 174761.3493187042]
[2019-03-23 21:28:44,055] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:28:44,058] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7425167991969588
[2019-03-23 21:28:45,588] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:28:45,588] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.51451406666667, 87.24321599000001, 1.0, 2.0, 0.5820571154569377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677156.58816836, 677156.58816836, 155674.5823285457]
[2019-03-23 21:28:45,588] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:28:45,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.10206558633706142
[2019-03-23 21:29:00,849] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:29:00,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.699298135, 81.46497616, 1.0, 2.0, 0.6098053786639227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 702157.3362237914, 702157.3362237909, 160123.9027723967]
[2019-03-23 21:29:00,852] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:29:00,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.352311828551518
[2019-03-23 21:29:36,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:29:36,575] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.0, 73.0, 1.0, 2.0, 0.3278235164303551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414819.0924372801, 414819.0924372801, 119059.1947107262]
[2019-03-23 21:29:36,576] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:29:36,578] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0476058702660942
[2019-03-23 21:29:36,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:29:36,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.3266462]
[2019-03-23 21:29:36,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 88.0, 1.0, 2.0, 0.3610699205592798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451779.8148381681, 451779.8148381676, 123357.5001914415]
[2019-03-23 21:29:36,981] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:29:36,982] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.519333e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8606430212442698
[2019-03-23 21:29:37,533] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:29:37,634] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:29:37,821] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:29:37,897] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:29:38,912] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 825000, evaluation results [825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:29:41,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.198157e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:29:41,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7460
[2019-03-23 21:29:41,225] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 80.33333333333334, 1.0, 2.0, 0.6688948714762415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 833970.2905854742, 833970.2905854742, 173043.2647480727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7116600.0000, 
sim time next is 7117200.0000, 
raw observation next is [21.3, 80.0, 1.0, 2.0, 0.6786775971389755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 845541.557644049, 845541.5576440486, 174886.5450479747], 
processed observation next is [1.0, 0.391304347826087, 0.3444444444444445, 0.8, 1.0, 1.0, 0.6174733299273517, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3019791277300175, 0.30197912773001734, 0.3363202789384129], 
reward next is 0.6637, 
noisyNet noise sample is [array([-2.0909736], dtype=float32), 0.9184722]. 
=============================================
[2019-03-23 21:29:45,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2327185e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:45,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-23 21:29:45,089] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333334, 84.66666666666667, 1.0, 2.0, 0.3768122534453771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469017.5583613761, 469017.5583613761, 125445.8377813615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7198800.0000, 
sim time next is 7199400.0000, 
raw observation next is [20.91666666666666, 84.33333333333333, 1.0, 2.0, 0.3773554709933296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469443.0186964705, 469443.0186964705, 125515.11568562], 
processed observation next is [1.0, 0.30434782608695654, 0.3302469135802467, 0.8433333333333333, 1.0, 1.0, 0.25875651308729714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16765822096302518, 0.16765822096302518, 0.24137522247234613], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.15548475], dtype=float32), -0.3072976]. 
=============================================
[2019-03-23 21:29:49,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1544856e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:49,688] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4657
[2019-03-23 21:29:49,692] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 90.0, 1.0, 2.0, 0.3998408377965622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493721.4800946898, 493721.4800946898, 128557.3675457648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7282200.0000, 
sim time next is 7282800.0000, 
raw observation next is [20.8, 90.0, 1.0, 2.0, 0.3990114344594107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492337.3746183746, 492337.3746183746, 128431.9679347042], 
processed observation next is [1.0, 0.30434782608695654, 0.32592592592592595, 0.9, 1.0, 1.0, 0.2845374219754889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17583477664941952, 0.17583477664941952, 0.246984553720585], 
reward next is 0.7530, 
noisyNet noise sample is [array([-1.4868337], dtype=float32), 0.20795783]. 
=============================================
[2019-03-23 21:29:59,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4996333e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:59,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-23 21:29:59,149] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 74.16666666666667, 1.0, 2.0, 0.5090661693607053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604370.9376977647, 604370.9376977647, 144221.2705981578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7481400.0000, 
sim time next is 7482000.0000, 
raw observation next is [25.33333333333333, 74.33333333333334, 1.0, 2.0, 0.509598815871246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605074.1236647009, 605074.1236647009, 144308.425016194], 
processed observation next is [0.0, 0.6086956521739131, 0.49382716049382697, 0.7433333333333334, 1.0, 1.0, 0.41618906651338805, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21609790130882175, 0.21609790130882175, 0.2775162019542192], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.0390276], dtype=float32), -0.9138105]. 
=============================================
[2019-03-23 21:29:59,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.839714]
 [74.839714]
 [74.839714]
 [74.839714]
 [74.839714]], R is [[74.813797  ]
 [74.78830719]
 [74.76342773]
 [74.73952484]
 [74.71655273]].
[2019-03-23 21:30:01,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.660043e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:30:01,502] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2956
[2019-03-23 21:30:01,505] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 62.33333333333334, 1.0, 2.0, 0.3206714923171368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407942.9510283774, 407942.9510283774, 118162.4584656018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7795200.0000, 
sim time next is 7795800.0000, 
raw observation next is [22.3, 61.5, 1.0, 2.0, 0.320832217644189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407902.0004886099, 407902.0004886099, 118181.4393829911], 
processed observation next is [1.0, 0.21739130434782608, 0.38148148148148153, 0.615, 1.0, 1.0, 0.19146692576689167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14567928588878926, 0.14567928588878926, 0.22727199881344443], 
reward next is 0.7727, 
noisyNet noise sample is [array([0.690406], dtype=float32), 0.8345718]. 
=============================================
[2019-03-23 21:30:03,007] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1564741e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:30:03,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4253
[2019-03-23 21:30:03,021] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 89.33333333333334, 1.0, 2.0, 0.46750733795384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562353.8727247455, 562353.8727247455, 138051.399362894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7550400.0000, 
sim time next is 7551000.0000, 
raw observation next is [22.7, 88.5, 1.0, 2.0, 0.472302222914937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567207.3429454203, 567207.3429454203, 138749.790488445], 
processed observation next is [0.0, 0.391304347826087, 0.39629629629629626, 0.885, 1.0, 1.0, 0.3717883606130203, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20257405105193582, 0.20257405105193582, 0.2668265201700865], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.47454163], dtype=float32), -0.33380073]. 
=============================================
[2019-03-23 21:30:03,040] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.7351]
 [67.7351]
 [67.7351]
 [67.7351]
 [67.7351]], R is [[67.79091644]
 [67.84752655]
 [67.90480804]
 [67.96273804]
 [68.02124786]].
[2019-03-23 21:30:06,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2871251e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:30:06,479] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2231
[2019-03-23 21:30:06,487] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666666, 62.0, 1.0, 2.0, 0.513592250810987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609676.6512104865, 609676.6512104865, 144937.6289073688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7577400.0000, 
sim time next is 7578000.0000, 
raw observation next is [27.3, 62.0, 1.0, 2.0, 0.5080096640461012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441987, 144096.2115306186], 
processed observation next is [0.0, 0.7391304347826086, 0.5666666666666667, 0.62, 1.0, 1.0, 0.41429721910250134, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21579624565864255, 0.2157962456586424, 0.27710809909734346], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.7989503], dtype=float32), 0.34742785]. 
=============================================
[2019-03-23 21:30:06,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[79.542496]
 [79.542496]
 [79.542496]
 [79.542496]
 [79.542496]], R is [[79.46995544]
 [79.39653015]
 [79.32215881]
 [79.24688721]
 [79.17090607]].
[2019-03-23 21:30:06,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.853704e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:30:06,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5785
[2019-03-23 21:30:06,883] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 79.66666666666667, 1.0, 2.0, 0.5164269362786462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612068.7723425358, 612068.7723425358, 145352.2926676721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7587600.0000, 
sim time next is 7588200.0000, 
raw observation next is [24.46666666666667, 80.83333333333334, 1.0, 2.0, 0.5171132825108291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612840.0154833532, 612840.0154833532, 145460.2865975299], 
processed observation next is [0.0, 0.8260869565217391, 0.46172839506172847, 0.8083333333333335, 1.0, 1.0, 0.4251348601319394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21887143410119755, 0.21887143410119755, 0.2797313203798652], 
reward next is 0.7203, 
noisyNet noise sample is [array([-1.3435929], dtype=float32), 0.6765778]. 
=============================================
[2019-03-23 21:30:07,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6271307e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:30:07,699] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4181
[2019-03-23 21:30:07,704] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 83.33333333333334, 1.0, 2.0, 0.515677485915133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611933.3422622832, 611933.3422622832, 145261.8125859998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7591200.0000, 
sim time next is 7591800.0000, 
raw observation next is [23.96666666666667, 83.66666666666666, 1.0, 2.0, 0.5144447287331845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610695.8372560407, 610695.8372560407, 145073.8558347258], 
processed observation next is [0.0, 0.8695652173913043, 0.4432098765432099, 0.8366666666666666, 1.0, 1.0, 0.42195801039664815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21810565616287167, 0.21810565616287167, 0.2789881842975496], 
reward next is 0.7210, 
noisyNet noise sample is [array([0.9227973], dtype=float32), -0.61289114]. 
=============================================
[2019-03-23 21:30:11,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:11,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:11,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 21:30:13,222] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.780084e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:30:13,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1642
[2019-03-23 21:30:13,232] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 77.0, 1.0, 2.0, 0.7026868825771038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867569.8130191348, 867569.8130191348, 179327.1831249861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7723200.0000, 
sim time next is 7723800.0000, 
raw observation next is [22.8, 75.5, 1.0, 2.0, 0.7251282902196988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 893425.433933542, 893425.433933542, 183688.1695104371], 
processed observation next is [1.0, 0.391304347826087, 0.4, 0.755, 1.0, 1.0, 0.67277177407107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31908051211912214, 0.31908051211912214, 0.35324647982776364], 
reward next is 0.6468, 
noisyNet noise sample is [array([0.9577812], dtype=float32), -0.67213964]. 
=============================================
[2019-03-23 21:30:25,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:25,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:25,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 21:30:25,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:25,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:25,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 21:30:25,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:25,506] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:25,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 21:30:26,068] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 21:30:26,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,156] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 21:30:26,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 21:30:26,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 21:30:26,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 21:30:26,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,367] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 21:30:26,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,494] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 21:30:26,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,521] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,524] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 21:30:26,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 21:30:26,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 21:30:26,773] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,773] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,774] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 21:30:26,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:30:26,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:26,866] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 21:30:30,501] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 21:30:30,503] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:30:30,504] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:30:30,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:30,506] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:30,507] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:30:30,506] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:30:30,509] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:30,508] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:30:30,510] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:30,512] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:30:30,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 21:30:30,526] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 21:30:30,527] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 21:30:30,550] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 21:30:30,638] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 21:30:39,814] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:30:39,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 44.66666666666666, 1.0, 2.0, 0.2878700356760232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367804.7146403035, 367804.7146403035, 114090.6960586704]
[2019-03-23 21:30:39,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:30:39,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.7858431898629488
[2019-03-23 21:31:01,659] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:31:01,707] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.92218780333334, 90.05997485, 1.0, 2.0, 0.6454588880258708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769963.2361477659, 769963.2361477659, 167615.2737315783]
[2019-03-23 21:31:01,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:31:01,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.7512841751154846
[2019-03-23 21:31:14,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:31:14,642] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.26666666666667, 35.66666666666667, 1.0, 2.0, 0.866331474781236, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9674029383433597, 6.911199999999999, 6.9112, 121.9260426156618, 1742037.096532813, 1742037.096532814, 343897.7534666107]
[2019-03-23 21:31:14,642] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:31:14,645] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.6145166959414589
[2019-03-23 21:31:14,649] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1742037.096532813 W.
[2019-03-23 21:32:01,305] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:32:01,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.35, 79.0, 1.0, 2.0, 0.9177027621693249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1046090.884446107, 1046090.884446107, 221460.3896291547]
[2019-03-23 21:32:01,309] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:32:01,312] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.49939070343048153
[2019-03-23 21:32:05,035] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:32:05,035] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 78.0, 1.0, 2.0, 0.2570278287447026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 331545.7145172572, 331545.7145172567, 105988.7306918713]
[2019-03-23 21:32:05,038] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:32:05,040] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.773639540105258
[2019-03-23 21:32:09,704] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:32:10,085] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25796655]
[2019-03-23 21:32:10,086] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 61.0, 1.0, 2.0, 0.927359355609291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.114261723127182, 6.9112, 121.9251126013805, 1238404.655099842, 1134419.696579131, 227189.3192512548]
[2019-03-23 21:32:10,087] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:32:10,089] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1707614e-24 1.0000000e+00 1.1734976e-37 0.0000000e+00 0.0000000e+00], sampled 0.03176814498428737
[2019-03-23 21:32:10,116] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:32:10,395] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:32:10,401] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:32:10,460] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:32:11,477] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 850000, evaluation results [850000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:32:11,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6674e-25 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-23 21:32:11,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4000
[2019-03-23 21:32:11,513] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1340297.49639667 W.
[2019-03-23 21:32:11,517] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 38.33333333333334, 1.0, 2.0, 0.3740100275380701, 1.0, 2.0, 0.3740100275380701, 1.0, 2.0, 0.6023452887424251, 6.911199999999999, 6.9112, 121.94756008, 1340297.49639667, 1340297.496396671, 285537.0083280458], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 58800.0000, 
sim time next is 59400.0000, 
raw observation next is [29.8, 38.5, 1.0, 2.0, 0.5514239265648199, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8958503732065569, 6.9112, 6.9112, 121.9260426156618, 1336670.115541295, 1336670.115541295, 273023.7783588727], 
processed observation next is [1.0, 0.6956521739130435, 0.6592592592592593, 0.385, 1.0, 1.0, 0.46598086495811886, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8698129665081961, 0.0, 0.0, 0.8094621288201359, 0.47738218412189104, 0.47738218412189104, 0.5250457276132167], 
reward next is 0.4750, 
noisyNet noise sample is [array([-0.14782216], dtype=float32), -0.106187314]. 
=============================================
[2019-03-23 21:32:15,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6793562e-21 1.0000000e+00 7.8748662e-35 9.4232053e-38 6.1706812e-37], sum to 1.0000
[2019-03-23 21:32:15,576] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-23 21:32:15,586] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1444900.249938725 W.
[2019-03-23 21:32:15,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.18333333333333, 32.33333333333334, 1.0, 2.0, 0.6129754635833545, 1.0, 2.0, 0.6129754635833545, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1444900.249938725, 1444900.249938725, 274716.9901213716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 130200.0000, 
sim time next is 130800.0000, 
raw observation next is [33.56666666666666, 30.66666666666667, 1.0, 2.0, 0.5115220982082561, 1.0, 2.0, 0.5115220982082561, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1214580.628293611, 1214580.628293611, 241106.3883217705], 
processed observation next is [1.0, 0.5217391304347826, 0.7987654320987653, 0.3066666666666667, 1.0, 1.0, 0.41847868834316204, 1.0, 1.0, 0.41847868834316204, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4337787958191468, 0.4337787958191468, 0.4636661313880202], 
reward next is 0.5363, 
noisyNet noise sample is [array([-1.4097601], dtype=float32), 0.18945685]. 
=============================================
[2019-03-23 21:32:19,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2645555e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:32:19,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1012
[2019-03-23 21:32:19,247] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 41.5, 1.0, 2.0, 0.2631969107847023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339505.1379254797, 339505.1379254797, 91923.77616648245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [21.16666666666667, 44.0, 1.0, 2.0, 0.2594843098906052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334715.104021851, 334715.104021851, 91782.12701774288], 
processed observation next is [0.0, 0.17391304347826086, 0.33950617283950635, 0.44, 1.0, 1.0, 0.1184337022507205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11954110857923249, 0.11954110857923249, 0.1765040904187363], 
reward next is 0.8235, 
noisyNet noise sample is [array([-0.17556609], dtype=float32), -0.36555532]. 
=============================================
[2019-03-23 21:32:20,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1717424e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:32:20,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4291
[2019-03-23 21:32:20,927] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.48333333333333, 15.5, 1.0, 2.0, 0.3848619138747487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492886.2030643176, 492886.2030643176, 126705.7155248914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [33.26666666666667, 16.0, 1.0, 2.0, 0.3814577846746978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488467.9608543933, 488467.9608543938, 126234.5876607838], 
processed observation next is [0.0, 0.7391304347826086, 0.7876543209876545, 0.16, 1.0, 1.0, 0.26364021985083075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17445284316228332, 0.1744528431622835, 0.24275882242458424], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.86880976], dtype=float32), -0.2609471]. 
=============================================
[2019-03-23 21:32:23,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.03202e-32 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:32:23,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7362
[2019-03-23 21:32:23,853] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 45.0, 1.0, 2.0, 0.2579794719956701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 332773.5560052347, 332773.5560052352, 92262.6888829051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 281400.0000, 
sim time next is 282000.0000, 
raw observation next is [21.4, 44.0, 1.0, 2.0, 0.2595269323237633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334770.0957312928, 334770.0957312928, 92762.11338450147], 
processed observation next is [0.0, 0.2608695652173913, 0.3481481481481481, 0.44, 1.0, 1.0, 0.11848444324257533, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1195607484754617, 0.1195607484754617, 0.17838867958557975], 
reward next is 0.8216, 
noisyNet noise sample is [array([0.03869542], dtype=float32), 0.07416627]. 
=============================================
[2019-03-23 21:32:23,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[79.9858]
 [79.9858]
 [79.9858]
 [79.9858]
 [79.9858]], R is [[80.0075531 ]
 [80.03005219]
 [80.05341339]
 [80.07687378]
 [80.10058594]].
[2019-03-23 21:32:25,708] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.433138e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:32:25,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0490
[2019-03-23 21:32:25,719] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 45.5, 1.0, 2.0, 0.2882914066455768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371634.7554156816, 371634.7554156816, 114129.4004449264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 342600.0000, 
sim time next is 343200.0000, 
raw observation next is [23.3, 46.0, 1.0, 2.0, 0.2850492714174047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367584.3988154322, 367584.3988154322, 113735.2502815941], 
processed observation next is [0.0, 1.0, 0.41851851851851857, 0.46, 1.0, 1.0, 0.14886818025881512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13128014243408292, 0.13128014243408292, 0.21872163515691173], 
reward next is 0.7813, 
noisyNet noise sample is [array([1.9035788], dtype=float32), 1.2389511]. 
=============================================
[2019-03-23 21:32:27,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4930717e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:32:27,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8259
[2019-03-23 21:32:27,173] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 50.5, 1.0, 2.0, 0.2694582073309508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347583.5916054388, 347583.5916054388, 105985.2170430282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 348600.0000, 
sim time next is 349200.0000, 
raw observation next is [21.8, 51.0, 1.0, 2.0, 0.2678388048109389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345494.1969839053, 345494.1969839049, 105130.1605125173], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.51, 1.0, 1.0, 0.12837952953683204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12339078463710902, 0.1233907846371089, 0.2021733856009948], 
reward next is 0.7978, 
noisyNet noise sample is [array([1.1434424], dtype=float32), -0.26542124]. 
=============================================
[2019-03-23 21:32:29,830] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1313783e-22 1.0000000e+00 3.4422810e-36 0.0000000e+00 7.4062968e-38], sum to 1.0000
[2019-03-23 21:32:29,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4691
[2019-03-23 21:32:29,840] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 25.5, 1.0, 2.0, 0.3418330719886604, 1.0, 2.0, 0.3418330719886604, 1.0, 2.0, 0.5641922315493002, 6.911200000000001, 6.9112, 121.94756008, 1265305.806270165, 1265305.806270165, 270728.407187172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 401400.0000, 
sim time next is 402000.0000, 
raw observation next is [30.76666666666667, 25.66666666666666, 1.0, 2.0, 0.9510212526323442, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.452990219497988, 6.9112, 121.9237837317303, 1474710.855206541, 1197270.978296376, 233642.961009524], 
processed observation next is [1.0, 0.6521739130434783, 0.6950617283950619, 0.2566666666666666, 1.0, 1.0, 0.9416919674194574, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.054179021949798754, 0.0, 0.8094471321799045, 0.5266824482880503, 0.42759677796299145, 0.44931338655677694], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28171536], dtype=float32), 0.20564383]. 
=============================================
[2019-03-23 21:32:29,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.72457]
 [53.72457]
 [53.72457]
 [53.72457]
 [53.72457]], R is [[53.18732452]
 [53.13482285]
 [52.60347366]
 [52.07743835]
 [52.04238129]].
[2019-03-23 21:32:30,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8018975e-23 1.0000000e+00 1.2371269e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:32:30,423] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2321
[2019-03-23 21:32:30,426] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 34.0, 1.0, 2.0, 0.3357965076349467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 426511.1483839593, 426511.1483839588, 120102.8627965531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 417600.0000, 
sim time next is 418200.0000, 
raw observation next is [27.95, 34.33333333333334, 1.0, 2.0, 0.3329472870055465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423051.2240079078, 423051.2240079078, 119734.494002285], 
processed observation next is [1.0, 0.8695652173913043, 0.5907407407407407, 0.34333333333333343, 1.0, 1.0, 0.20588962738755534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15108972285996708, 0.15108972285996708, 0.23025864231208654], 
reward next is 0.7697, 
noisyNet noise sample is [array([1.2527971], dtype=float32), 0.053208556]. 
=============================================
[2019-03-23 21:32:34,826] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6671194e-21 1.0000000e+00 8.6788952e-34 1.2472403e-35 2.6321698e-36], sum to 1.0000
[2019-03-23 21:32:34,833] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6276
[2019-03-23 21:32:34,839] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 31.0, 1.0, 2.0, 0.3539523856826731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445513.3244456212, 445513.3244456212, 122448.189467092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [29.8, 32.0, 1.0, 2.0, 0.3520439919386765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709488, 442907.6813709484, 122191.7861614804], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.32, 1.0, 1.0, 0.22862379992699586, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15818131477533887, 0.1581813147753387, 0.23498420415669308], 
reward next is 0.7650, 
noisyNet noise sample is [array([-0.75545925], dtype=float32), -1.0836425]. 
=============================================
[2019-03-23 21:32:41,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2378712e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:32:41,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-23 21:32:41,502] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 61.66666666666667, 1.0, 2.0, 0.3954400473174092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503076.7288244056, 503076.7288244056, 128174.0530975518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 616800.0000, 
sim time next is 617400.0000, 
raw observation next is [21.95, 62.5, 1.0, 2.0, 0.3834577661018769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488085.1728230429, 488085.1728230434, 126503.8905451277], 
processed observation next is [1.0, 0.13043478260869565, 0.36851851851851847, 0.625, 1.0, 1.0, 0.266021150121282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17431613315108674, 0.17431613315108693, 0.24327671258678402], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.1422504], dtype=float32), -0.8394681]. 
=============================================
[2019-03-23 21:32:44,560] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2523157e-20 1.0000000e+00 3.5597778e-32 4.7006831e-35 3.5902949e-34], sum to 1.0000
[2019-03-23 21:32:44,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9335
[2019-03-23 21:32:44,577] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.48333333333333, 30.33333333333334, 1.0, 2.0, 0.3526728739744572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446831.2075585652, 446831.2075585652, 122311.7713925933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 683400.0000, 
sim time next is 684000.0000, 
raw observation next is [29.3, 31.0, 1.0, 2.0, 0.3501385986089117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443560.777992088, 443560.777992088, 121974.9871829955], 
processed observation next is [1.0, 0.9565217391304348, 0.6407407407407407, 0.31, 1.0, 1.0, 0.22635547453441873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15841456356860287, 0.15841456356860287, 0.2345672830442221], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.08035567], dtype=float32), -0.8489017]. 
=============================================
[2019-03-23 21:32:44,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[46.960915]
 [46.960915]
 [46.960915]
 [46.960915]
 [46.960915]], R is [[47.25674057]
 [47.54895782]
 [47.83778   ]
 [48.12366486]
 [48.40662766]].
[2019-03-23 21:32:45,314] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.996214e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:32:45,322] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8581
[2019-03-23 21:32:45,331] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 38.33333333333334, 1.0, 2.0, 0.3127052923040178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399560.2896071015, 399560.2896071015, 117160.8535187185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 696000.0000, 
sim time next is 696600.0000, 
raw observation next is [26.1, 38.5, 1.0, 2.0, 0.3110322589490981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397705.7050359992, 397705.7050359992, 116950.8965419829], 
processed observation next is [1.0, 0.043478260869565216, 0.5222222222222223, 0.385, 1.0, 1.0, 0.17980030827273583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14203775179857114, 0.14203775179857114, 0.22490557027304406], 
reward next is 0.7751, 
noisyNet noise sample is [array([0.64106345], dtype=float32), -2.1822913]. 
=============================================
[2019-03-23 21:32:55,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.990077e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:32:55,922] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3269
[2019-03-23 21:32:55,926] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 61.33333333333334, 1.0, 2.0, 0.3928074039470443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488801.8696444911, 488801.8696444906, 127655.3603023668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865200.0000, 
sim time next is 865800.0000, 
raw observation next is [24.1, 62.0, 1.0, 2.0, 0.390455666055733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486182.2216009463, 486182.2216009463, 127333.4616915992], 
processed observation next is [0.0, 0.0, 0.4481481481481482, 0.62, 1.0, 1.0, 0.27435198339968214, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17363650771462366, 0.17363650771462366, 0.24487204171461383], 
reward next is 0.7551, 
noisyNet noise sample is [array([-1.1551344], dtype=float32), -0.6354069]. 
=============================================
[2019-03-23 21:32:55,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.990077e-33 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:32:55,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7505
[2019-03-23 21:32:55,962] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 62.0, 1.0, 2.0, 0.390455666055733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486182.2216009463, 486182.2216009463, 127333.4616915992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [23.93333333333334, 62.66666666666667, 1.0, 2.0, 0.3882338407358635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 127030.5572707251], 
processed observation next is [0.0, 0.0, 0.4419753086419756, 0.6266666666666667, 1.0, 1.0, 0.27170695325698035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1727598726105244, 0.17275987261052422, 0.24428953321293287], 
reward next is 0.7557, 
noisyNet noise sample is [array([-1.1551344], dtype=float32), -0.6354069]. 
=============================================
[2019-03-23 21:33:01,755] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 21:33:01,758] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:33:01,759] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:33:01,760] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:33:01,760] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:33:01,761] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:33:01,761] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:33:01,763] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:33:01,762] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:33:01,766] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:33:01,769] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:33:01,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 21:33:01,807] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 21:33:01,808] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 21:33:01,808] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 21:33:01,828] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 21:33:17,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:33:17,361] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.16991159, 55.45129560000001, 1.0, 2.0, 0.3648822817481261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464636.65499296, 464636.65499296, 123964.3568843759]
[2019-03-23 21:33:17,362] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:33:17,365] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.15321039287960048
[2019-03-23 21:33:21,121] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:33:21,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.13333333333334, 18.33333333333333, 1.0, 2.0, 0.536565389456058, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8730598307266284, 6.911200000000001, 6.9112, 121.9260426156417, 1303379.695242562, 1303379.695242561, 267468.9738839266]
[2019-03-23 21:33:21,126] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:33:21,129] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5658639638761378
[2019-03-23 21:33:21,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1303379.695242562 W.
[2019-03-23 21:33:41,932] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:33:41,934] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.62286175, 84.62860524166668, 1.0, 2.0, 0.4214008172582837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517421.3570289977, 517421.3570289977, 131558.8550905909]
[2019-03-23 21:33:41,934] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:33:41,936] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4220101316879583
[2019-03-23 21:33:56,056] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:33:56,057] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.30780732, 79.05492021333333, 1.0, 2.0, 0.5812076456117716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679490.2392862544, 679490.2392862544, 155676.0095381914]
[2019-03-23 21:33:56,060] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:33:56,063] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7790079675168927
[2019-03-23 21:34:17,034] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:34:17,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.97158279, 38.51501039, 1.0, 2.0, 0.3320428890154356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 420845.5591333308, 420845.5591333304, 119608.783879975]
[2019-03-23 21:34:17,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:34:17,038] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6865081456808761
[2019-03-23 21:34:39,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:34:39,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 54.5, 1.0, 2.0, 0.4680065638015431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580247.207899432, 580247.207899432, 138619.5067372411]
[2019-03-23 21:34:39,892] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:34:39,897] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6246222131400229
[2019-03-23 21:34:40,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:34:40,281] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.5, 77.33333333333333, 1.0, 2.0, 0.2455873385074549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 316785.342470512, 316785.342470512, 97900.56662575285]
[2019-03-23 21:34:40,282] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:34:40,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4623607919838739
[2019-03-23 21:34:41,245] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.25179276]
[2019-03-23 21:34:41,246] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.08333333333333, 54.66666666666667, 1.0, 2.0, 0.4366161652832436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532503.8509154575, 532503.8509154578, 133677.4889440414]
[2019-03-23 21:34:41,248] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:34:41,250] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.921999e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.702469463995465
[2019-03-23 21:34:41,319] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:34:41,427] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:34:41,750] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:34:41,808] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:34:41,880] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:34:42,894] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 875000, evaluation results [875000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:34:45,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.915904e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:34:45,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1818
[2019-03-23 21:34:45,998] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 72.0, 1.0, 2.0, 0.3116090600125833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 397986.9881579595, 397986.9881579591, 117022.7727051497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1054800.0000, 
sim time next is 1055400.0000, 
raw observation next is [20.33333333333333, 71.33333333333333, 1.0, 2.0, 0.3009283845031533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384271.6874596589, 384271.6874596589, 115690.9704858469], 
processed observation next is [1.0, 0.21739130434782608, 0.3086419753086418, 0.7133333333333333, 1.0, 1.0, 0.16777188631327772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1372398883784496, 0.1372398883784496, 0.2224826355497056], 
reward next is 0.7775, 
noisyNet noise sample is [array([-1.6748167], dtype=float32), 0.15922418]. 
=============================================
[2019-03-23 21:34:46,036] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2463107e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:34:46,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6527
[2019-03-23 21:34:46,050] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 63.33333333333333, 1.0, 2.0, 0.2963253524574443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378461.6701397922, 378461.6701397922, 115123.4635584812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1042800.0000, 
sim time next is 1043400.0000, 
raw observation next is [21.4, 64.16666666666667, 1.0, 2.0, 0.2974432789275849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 379786.1452795098, 379786.1452795098, 115260.7638705559], 
processed observation next is [1.0, 0.043478260869565216, 0.3481481481481481, 0.6416666666666667, 1.0, 1.0, 0.16362295110426772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13563790902839634, 0.13563790902839634, 0.2216553151356844], 
reward next is 0.7783, 
noisyNet noise sample is [array([-0.52506864], dtype=float32), 1.3690445]. 
=============================================
[2019-03-23 21:34:54,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3046254e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:34:54,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5124
[2019-03-23 21:34:54,981] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.95, 93.0, 1.0, 2.0, 0.3099180747284179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394472.2494697886, 394472.2494697886, 116805.671852361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1222200.0000, 
sim time next is 1222800.0000, 
raw observation next is [17.93333333333333, 93.0, 1.0, 2.0, 0.3078846671314152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391956.305094546, 391956.305094546, 116551.5936283999], 
processed observation next is [1.0, 0.13043478260869565, 0.21975308641975297, 0.93, 1.0, 1.0, 0.1760531751564467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13998439467662357, 0.13998439467662357, 0.2241376800546152], 
reward next is 0.7759, 
noisyNet noise sample is [array([0.8683214], dtype=float32), -1.5814381]. 
=============================================
[2019-03-23 21:34:58,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.349728e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:34:58,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1902
[2019-03-23 21:34:58,557] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 72.0, 1.0, 2.0, 0.4118373762853879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507627.6089707423, 507627.6089707423, 130236.4732028431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1284600.0000, 
sim time next is 1285200.0000, 
raw observation next is [23.1, 73.0, 1.0, 2.0, 0.4095421816569274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505133.4675446501, 505133.4675446501, 129917.3779599373], 
processed observation next is [1.0, 0.9130434782608695, 0.41111111111111115, 0.73, 1.0, 1.0, 0.29707402578205644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18040480983737503, 0.18040480983737503, 0.24984111146141788], 
reward next is 0.7502, 
noisyNet noise sample is [array([-0.28758138], dtype=float32), -1.005987]. 
=============================================
[2019-03-23 21:35:00,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.892527e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:35:00,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0609
[2019-03-23 21:35:00,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1366413.855748452 W.
[2019-03-23 21:35:00,034] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.3, 34.0, 1.0, 2.0, 0.5591817212929776, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9141805152632514, 6.911199999999999, 6.9112, 121.9260426156426, 1366413.855748452, 1366413.855748453, 275284.9948757445], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1345200.0000, 
sim time next is 1345800.0000, 
raw observation next is [30.5, 33.5, 1.0, 2.0, 0.3750041141482272, 1.0, 1.0, 0.3750041141482272, 1.0, 2.0, 0.6076943849371862, 6.9112, 6.9112, 121.94756008, 1358494.400077887, 1358494.400077887, 285613.7997738144], 
processed observation next is [1.0, 0.5652173913043478, 0.6851851851851852, 0.335, 1.0, 1.0, 0.25595727874788954, 1.0, 0.5, 0.25595727874788954, 1.0, 1.0, 0.5096179811714827, 0.0, 0.0, 0.8096049824067558, 0.48517657145638826, 0.48517657145638826, 0.5492573072573353], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7272316], dtype=float32), -0.64135915]. 
=============================================
[2019-03-23 21:35:02,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0733226e-24 1.0000000e+00 1.6368775e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:35:02,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5066
[2019-03-23 21:35:02,203] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 38.66666666666667, 1.0, 2.0, 0.8017282214219908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260389436195, 999432.6420431589, 999432.6420431589, 199700.7517071558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1340400.0000, 
sim time next is 1341000.0000, 
raw observation next is [28.95, 38.0, 1.0, 2.0, 0.7381924471272581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426145421, 920442.2094574657, 920442.2094574657, 186561.7279343432], 
processed observation next is [1.0, 0.5217391304347826, 0.6277777777777778, 0.38, 1.0, 1.0, 0.6883243418181644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288127023, 0.3287293605205235, 0.3287293605205235, 0.35877255371989075], 
reward next is 0.6412, 
noisyNet noise sample is [array([1.2527363], dtype=float32), 1.2929943]. 
=============================================
[2019-03-23 21:35:02,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.126434]
 [55.126434]
 [55.126434]
 [55.126434]
 [55.126434]], R is [[55.21639633]
 [55.28019333]
 [54.72739029]
 [54.71641541]
 [54.16925049]].
[2019-03-23 21:35:02,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5849617e-25 1.0000000e+00 2.9385910e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:35:02,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6904
[2019-03-23 21:35:02,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1347226.405385003 W.
[2019-03-23 21:35:02,296] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 28.0, 1.0, 2.0, 0.5437776304238257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9014803112919039, 6.911200000000001, 6.9112, 121.9260426156393, 1347226.405385003, 1347226.405385003, 268420.0672924451], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1357200.0000, 
sim time next is 1357800.0000, 
raw observation next is [30.75, 29.0, 1.0, 2.0, 0.1729749716226863, 1.0, 1.0, 0.1729749716226863, 1.0, 2.0, 0.2851774590408733, 6.9112, 6.9112, 121.94756008, 639345.011697532, 639345.011697532, 210202.4393714186], 
processed observation next is [1.0, 0.7391304347826086, 0.6944444444444444, 0.29, 1.0, 1.0, 0.015446394788912254, 1.0, 0.5, 0.015446394788912254, 1.0, 1.0, 0.10647182380109164, 0.0, 0.0, 0.8096049824067558, 0.22833750417769, 0.22833750417769, 0.40423546032965113], 
reward next is 0.5958, 
noisyNet noise sample is [array([0.12854145], dtype=float32), -0.41752243]. 
=============================================
[2019-03-23 21:35:12,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2351861e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:35:12,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5677
[2019-03-23 21:35:12,309] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 74.0, 1.0, 2.0, 0.5008325263600499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601367.0922144974, 601367.0922144974, 143170.0690369012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1539600.0000, 
sim time next is 1540200.0000, 
raw observation next is [24.2, 76.5, 1.0, 2.0, 0.496140355854865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596880.7825688266, 596880.7825688266, 142472.1912430766], 
processed observation next is [0.0, 0.8260869565217391, 0.45185185185185184, 0.765, 1.0, 1.0, 0.40016709030341074, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2131717080602952, 0.2131717080602952, 0.2739849831597627], 
reward next is 0.7260, 
noisyNet noise sample is [array([0.84641373], dtype=float32), -1.3977123]. 
=============================================
[2019-03-23 21:35:12,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0155613e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:35:12,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2058
[2019-03-23 21:35:12,839] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 64.0, 1.0, 2.0, 0.3881047563349218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489495.7460383771, 489495.7460383771, 127108.6077645705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581600.0000, 
sim time next is 1582200.0000, 
raw observation next is [22.85, 62.5, 1.0, 2.0, 0.4054451365563462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511511.4509548644, 511511.4509548644, 129550.2381680398], 
processed observation next is [1.0, 0.30434782608695654, 0.4018518518518519, 0.625, 1.0, 1.0, 0.2921965911385074, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1826826610553087, 0.1826826610553087, 0.24913507340007654], 
reward next is 0.7509, 
noisyNet noise sample is [array([-0.19558558], dtype=float32), -0.55143]. 
=============================================
[2019-03-23 21:35:12,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.398432e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:35:12,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3753
[2019-03-23 21:35:12,986] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 66.0, 1.0, 2.0, 0.3924247107007521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489523.1114988203, 489523.1114988203, 127625.5113308267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [23.2, 66.5, 1.0, 2.0, 0.3907700522048922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487579.9581589521, 487579.9581589521, 127396.8807257692], 
processed observation next is [0.0, 1.0, 0.4148148148148148, 0.665, 1.0, 1.0, 0.27472625262487166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1741356993424829, 0.1741356993424829, 0.24499400139570998], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.6175018], dtype=float32), 0.9478985]. 
=============================================
[2019-03-23 21:35:23,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3263783e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:35:23,251] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5541
[2019-03-23 21:35:23,254] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 66.33333333333334, 1.0, 2.0, 0.4700060626712658, 1.0, 1.0, 0.4700060626712658, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425203348, 1119417.005269753, 1119417.005269753, 228347.9638789915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [25.25, 66.0, 1.0, 2.0, 0.8564192769690653, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156328, 1034863.6074985, 1034863.607498499, 210598.2654671915], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.66, 1.0, 1.0, 0.8290705678203159, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199434, 0.3695941455351786, 0.3695941455351782, 0.40499666435998366], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3527808], dtype=float32), 0.33545014]. 
=============================================
[2019-03-23 21:35:23,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.68331]
 [70.68331]
 [70.68331]
 [70.68331]
 [70.68331]], R is [[69.97648621]
 [69.27672577]
 [68.58396149]
 [67.89812469]
 [67.68052673]].
[2019-03-23 21:35:32,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.718344e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:35:32,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9839
[2019-03-23 21:35:32,975] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 91.83333333333334, 1.0, 2.0, 0.3860827454696614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479997.5126775113, 479997.5126775113, 126710.9228292471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1923000.0000, 
sim time next is 1923600.0000, 
raw observation next is [20.06666666666667, 91.66666666666667, 1.0, 2.0, 0.3763008874103568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467742.8858127754, 467742.8858127754, 125362.7133763666], 
processed observation next is [1.0, 0.2608695652173913, 0.29876543209876555, 0.9166666666666667, 1.0, 1.0, 0.25750105644090093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1670510306474198, 0.1670510306474198, 0.24108214110839732], 
reward next is 0.7589, 
noisyNet noise sample is [array([0.32462677], dtype=float32), 0.6771393]. 
=============================================
[2019-03-23 21:35:33,098] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 21:35:33,100] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:35:33,102] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:35:33,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:35:33,107] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:35:33,109] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:35:33,109] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:35:33,109] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:35:33,111] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:35:33,112] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:35:33,113] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:35:33,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 21:35:33,155] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 21:35:33,155] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 21:35:33,212] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 21:35:33,235] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 21:35:35,805] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:35:35,807] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [37.4, 15.0, 1.0, 2.0, 0.6995439788493555, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9557889593130448, 6.9112, 6.9112, 121.9260426156618, 1572331.786000021, 1572331.786000021, 304432.2509338579]
[2019-03-23 21:35:35,809] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:35:35,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2853037070216419
[2019-03-23 21:35:35,815] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1572331.786000021 W.
[2019-03-23 21:36:00,535] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:36:00,537] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.75305102666667, 100.9643766133333, 1.0, 2.0, 0.5067631745637732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602779.0390838302, 602779.0390838302, 143900.1189211399]
[2019-03-23 21:36:00,538] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:36:00,543] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.058706254559799276
[2019-03-23 21:36:01,410] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:36:01,411] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.3, 93.83333333333334, 1.0, 2.0, 0.3636160546771721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455083.1247349414, 455083.1247349414, 123701.805630009]
[2019-03-23 21:36:01,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:36:01,416] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.24623533200876502
[2019-03-23 21:36:36,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:36:36,511] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.04555169, 91.45440948, 1.0, 2.0, 0.8235318476389658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 938679.5567849107, 938679.5567849107, 200860.5674704805]
[2019-03-23 21:36:36,513] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:36:36,515] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.22315980818646686
[2019-03-23 21:36:45,716] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:36:45,716] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.99565399333333, 80.81127887333335, 1.0, 2.0, 0.972569148806065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.975658164167855, 6.9112, 121.925522900915, 1141710.504000435, 1108702.303440561, 234186.5477395777]
[2019-03-23 21:36:45,718] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:36:45,720] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4534078100853026
[2019-03-23 21:36:53,819] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:36:53,821] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.31311435, 75.53168624, 1.0, 2.0, 0.4647291251844353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560532.6618850295, 560532.6618850295, 137681.7705061101]
[2019-03-23 21:36:53,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:36:53,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7596888434711192
[2019-03-23 21:37:04,097] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.185036]
[2019-03-23 21:37:04,098] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.35, 88.0, 1.0, 2.0, 0.8059582295060752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918636.758028421, 918636.758028421, 197178.0535425304]
[2019-03-23 21:37:04,099] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:37:04,102] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.359147e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.30672127237751257
[2019-03-23 21:37:13,107] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:37:13,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:37:13,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:37:13,326] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:37:13,364] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:37:14,379] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 900000, evaluation results [900000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:37:16,494] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6234837e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:16,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2137
[2019-03-23 21:37:16,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1539549.833121651 W.
[2019-03-23 21:37:16,513] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.9, 58.0, 1.0, 2.0, 0.672686304944767, 1.0, 1.0, 0.672686304944767, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1539549.833121651, 1539549.833121651, 294232.3361463395], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [28.75, 59.16666666666667, 1.0, 2.0, 0.3495604933338932, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5571905459261116, 6.9112, 6.9112, 121.9260426156618, 807348.5107887819, 807348.5107887819, 208847.8161181737], 
processed observation next is [1.0, 0.7391304347826086, 0.6203703703703703, 0.5916666666666667, 1.0, 1.0, 0.2256672539689205, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4464881824076395, 0.0, 0.0, 0.8094621288201359, 0.2883387538531364, 0.2883387538531364, 0.4016304156118725], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5259782], dtype=float32), -0.20067362]. 
=============================================
[2019-03-23 21:37:25,662] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.301782e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:37:25,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-23 21:37:25,671] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666666, 72.5, 1.0, 2.0, 0.6464389445774006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736728.1899442888, 736728.1899442893, 166250.2605322646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2148600.0000, 
sim time next is 2149200.0000, 
raw observation next is [27.7, 73.0, 1.0, 2.0, 0.6424040680890652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732127.5592935807, 732127.5592935807, 165525.0084929291], 
processed observation next is [0.0, 0.9130434782608695, 0.5814814814814815, 0.73, 1.0, 1.0, 0.5742905572488872, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26147412831913597, 0.26147412831913597, 0.3183173240248637], 
reward next is 0.6817, 
noisyNet noise sample is [array([-0.71481925], dtype=float32), 0.09731445]. 
=============================================
[2019-03-23 21:37:26,395] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6406608e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:26,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2971
[2019-03-23 21:37:26,405] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.71666666666667, 86.5, 1.0, 2.0, 0.5769438664895896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669866.5089392207, 669866.5089392207, 154746.6288275546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2164200.0000, 
sim time next is 2164800.0000, 
raw observation next is [24.63333333333333, 87.0, 1.0, 2.0, 0.5777238420240791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670961.3716772947, 670961.3716772947, 154887.1406491894], 
processed observation next is [1.0, 0.043478260869565216, 0.46790123456790106, 0.87, 1.0, 1.0, 0.4972902881239037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23962906131331954, 0.23962906131331954, 0.2978598858638257], 
reward next is 0.7021, 
noisyNet noise sample is [array([0.00518775], dtype=float32), 0.20183384]. 
=============================================
[2019-03-23 21:37:32,145] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7012197e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:32,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7305
[2019-03-23 21:37:32,157] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.5, 1.0, 2.0, 0.4119282119501079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506299.821431612, 506299.821431612, 130212.8729071048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [20.4, 95.66666666666667, 1.0, 2.0, 0.4124473977187059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506789.5223158078, 506789.5223158078, 130283.1625627234], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9566666666666667, 1.0, 1.0, 0.3005326163317928, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18099625796993135, 0.18099625796993135, 0.2505445433898527], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.7402471], dtype=float32), 0.6734144]. 
=============================================
[2019-03-23 21:37:32,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5404727e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:32,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3663
[2019-03-23 21:37:32,389] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.33333333333334, 1.0, 2.0, 0.4527148859283502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549714.3692141621, 549714.3692141621, 135992.0753896517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2262000.0000, 
sim time next is 2262600.0000, 
raw observation next is [20.85, 96.0, 1.0, 2.0, 0.4434619770970255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540182.4311331596, 540182.4311331592, 134667.1598566798], 
processed observation next is [1.0, 0.17391304347826086, 0.32777777777777783, 0.96, 1.0, 1.0, 0.3374547346393161, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19292229683327128, 0.19292229683327114, 0.2589753074166919], 
reward next is 0.7410, 
noisyNet noise sample is [array([-0.84087944], dtype=float32), 1.4027435]. 
=============================================
[2019-03-23 21:37:36,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7655792e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:36,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1985
[2019-03-23 21:37:36,696] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.68333333333333, 96.0, 1.0, 2.0, 0.5625342460256423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676144.3946712234, 676144.3946712234, 153252.8189502048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347800.0000, 
sim time next is 2348400.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.4835032768577763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581315.4868908126, 581315.4868908126, 140492.0714795557], 
processed observation next is [1.0, 0.17391304347826086, 0.3580246913580249, 0.96, 1.0, 1.0, 0.38512294864020985, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20761267388957594, 0.20761267388957594, 0.27017706053760715], 
reward next is 0.7298, 
noisyNet noise sample is [array([-0.5899044], dtype=float32), 0.49506706]. 
=============================================
[2019-03-23 21:37:40,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.54355e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:37:40,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8313
[2019-03-23 21:37:40,715] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 60.5, 1.0, 2.0, 0.3809781475477267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474672.5271166012, 474672.5271166008, 126026.9236939194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2413800.0000, 
sim time next is 2414400.0000, 
raw observation next is [24.13333333333333, 61.66666666666667, 1.0, 2.0, 0.3811058109836294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474904.7333167108, 474904.7333167108, 126045.9315545064], 
processed observation next is [1.0, 0.9565217391304348, 0.44938271604938257, 0.6166666666666667, 1.0, 1.0, 0.26322120355193973, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1696088333273967, 0.1696088333273967, 0.24239602222020462], 
reward next is 0.7576, 
noisyNet noise sample is [array([0.18168776], dtype=float32), -1.1162837]. 
=============================================
[2019-03-23 21:37:41,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.637539e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:37:41,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7819
[2019-03-23 21:37:41,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1453637.812919496 W.
[2019-03-23 21:37:41,449] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.36666666666667, 24.0, 1.0, 2.0, 0.9584787381622244, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.422783318207066, 6.9112, 121.9239171843829, 1453637.812919496, 1191665.996007138, 235116.3468815282], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2461200.0000, 
sim time next is 2461800.0000, 
raw observation next is [33.48333333333333, 24.0, 1.0, 2.0, 0.5431467381636076, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8940388933062772, 6.911199999999999, 6.9112, 121.9257345488942, 1336918.534071058, 1336918.534071059, 268802.0118456575], 
processed observation next is [1.0, 0.4782608695652174, 0.7956790123456788, 0.24, 1.0, 1.0, 0.45612706924239, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8675486166328463, -8.881784197001253e-17, 0.0, 0.8094600835771659, 0.47747090502537787, 0.4774709050253782, 0.5169269458570336], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57110983], dtype=float32), 0.08868479]. 
=============================================
[2019-03-23 21:37:45,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1232205e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:45,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5098
[2019-03-23 21:37:45,259] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 42.66666666666667, 1.0, 2.0, 0.3739251108096291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466986.9778884687, 466986.9778884687, 125081.6070145853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2499600.0000, 
sim time next is 2500200.0000, 
raw observation next is [27.6, 43.5, 1.0, 2.0, 0.3741292888076234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467086.0185037113, 467086.0185037113, 125106.5776807844], 
processed observation next is [1.0, 0.9565217391304348, 0.5777777777777778, 0.435, 1.0, 1.0, 0.2549158200090755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16681643517989692, 0.16681643517989692, 0.2405895724630469], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.61637026], dtype=float32), -0.15036148]. 
=============================================
[2019-03-23 21:37:54,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0201702e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:54,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2695
[2019-03-23 21:37:54,990] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 98.0, 1.0, 2.0, 0.5730683928862035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 668015.2568964132, 668015.2568964127, 154210.5954001421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2679600.0000, 
sim time next is 2680200.0000, 
raw observation next is [23.0, 97.0, 1.0, 2.0, 0.5680853121519677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663882.5722487791, 663882.5722487791, 153445.4823303308], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.97, 1.0, 1.0, 0.4858158477999615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23710091866027827, 0.23710091866027827, 0.2950874660198669], 
reward next is 0.7049, 
noisyNet noise sample is [array([-1.256417], dtype=float32), -0.19564758]. 
=============================================
[2019-03-23 21:37:55,869] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.009818e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:37:55,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2492
[2019-03-23 21:37:55,884] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.16666666666666, 1.0, 2.0, 0.4717347610908037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 138838.6368055314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.4591232413775544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559069.157127115, 559069.157127115, 137001.5699384149], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.93, 1.0, 1.0, 0.356099096878041, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19966755611682677, 0.19966755611682677, 0.2634645575738748], 
reward next is 0.7365, 
noisyNet noise sample is [array([-1.4883863], dtype=float32), -0.62604237]. 
=============================================
[2019-03-23 21:37:56,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9000526e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:56,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0220
[2019-03-23 21:37:56,640] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.06666666666667, 68.66666666666667, 1.0, 2.0, 0.6696282690184514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763169.5636305645, 763169.5636305645, 170473.3974637689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2749200.0000, 
sim time next is 2749800.0000, 
raw observation next is [28.83333333333334, 70.33333333333333, 1.0, 2.0, 0.6759704613931857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 770401.3379961839, 770401.3379961831, 171644.2548960155], 
processed observation next is [0.0, 0.8260869565217391, 0.623456790123457, 0.7033333333333333, 1.0, 1.0, 0.614250549277602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2751433349986371, 0.2751433349986368, 0.3300851055692606], 
reward next is 0.6699, 
noisyNet noise sample is [array([2.304857], dtype=float32), 1.2414724]. 
=============================================
[2019-03-23 21:37:59,615] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5868712e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:37:59,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6085
[2019-03-23 21:37:59,626] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3266357.312675195 W.
[2019-03-23 21:37:59,634] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.26666666666667, 79.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.01698959055815, 6.9112, 121.9041889931103, 3266357.312675195, 1164202.921779141, 245584.7393572843], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2794800.0000, 
sim time next is 2795400.0000, 
raw observation next is [27.45, 79.5, 1.0, 2.0, 0.7312176687594347, 1.0, 1.0, 0.6789734963561522, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2323663.725593945, 2323663.725593945, 437734.1339472731], 
processed observation next is [1.0, 0.34782608695652173, 0.5722222222222222, 0.795, 1.0, 1.0, 0.6800210342374223, 1.0, 0.5, 0.6178255909001812, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8298799019978375, 0.8298799019978375, 0.8417964114370636], 
reward next is 0.1582, 
noisyNet noise sample is [array([1.5051506], dtype=float32), 0.1653532]. 
=============================================
[2019-03-23 21:38:04,790] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 21:38:04,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:38:04,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:38:04,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:38:04,796] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:38:04,796] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:38:04,797] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:38:04,797] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:38:04,798] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:38:04,798] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:38:04,799] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:38:04,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 21:38:04,844] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 21:38:04,863] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 21:38:04,887] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 21:38:04,909] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 21:38:06,524] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:06,525] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 17.0, 1.0, 2.0, 0.4996184831560904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644600.1950163426, 644600.1950163426, 141836.6232383213]
[2019-03-23 21:38:06,528] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:06,532] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2643483598482339
[2019-03-23 21:38:11,974] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:11,976] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.17588121, 46.09274622, 1.0, 2.0, 0.2586818970704519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 333679.6433386275, 333679.6433386271, 93480.74169942661]
[2019-03-23 21:38:11,977] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:38:11,980] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.12926027734839918
[2019-03-23 21:38:12,777] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:12,779] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.43333333333333, 54.0, 1.0, 2.0, 0.3130455575148792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398469.8502616474, 398469.8502616469, 117198.5845507922]
[2019-03-23 21:38:12,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:12,784] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6352243857553308
[2019-03-23 21:38:29,173] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:29,173] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.35489658333334, 63.77920383, 1.0, 2.0, 0.3770661428769067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467593.8133140352, 467593.8133140352, 125444.3248977859]
[2019-03-23 21:38:29,174] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:38:29,176] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.668801497215457
[2019-03-23 21:38:29,345] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:29,346] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.95635255333333, 70.02198991333333, 1.0, 2.0, 0.4409699433449364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540439.8834864538, 540439.8834864543, 134392.1430217139]
[2019-03-23 21:38:29,346] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:38:29,349] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.039098543923307694
[2019-03-23 21:38:58,798] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14326166]
[2019-03-23 21:38:58,799] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.59497352666666, 67.83811199333334, 1.0, 2.0, 0.7030724464090596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801305.52769525, 801305.52769525, 176726.3535419522]
[2019-03-23 21:38:58,799] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:38:58,803] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6202757e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.10486328770620157
[2019-03-23 21:39:44,746] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:39:44,837] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:39:44,967] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:39:45,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:39:45,385] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:39:46,402] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 925000, evaluation results [925000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:39:58,571] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1269983e-20 1.0000000e+00 1.3773196e-33 5.3245351e-37 2.2924762e-36], sum to 1.0000
[2019-03-23 21:39:58,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4938
[2019-03-23 21:39:58,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1565599.367980525 W.
[2019-03-23 21:39:58,601] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.73333333333333, 84.66666666666667, 1.0, 2.0, 0.4576620809662627, 1.0, 2.0, 0.4576620809662627, 1.0, 1.0, 0.7286129379116941, 6.911200000000001, 6.9112, 121.94756008, 1565599.367980525, 1565599.367980525, 323261.6318181996], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3082800.0000, 
sim time next is 3083400.0000, 
raw observation next is [27.1, 85.0, 1.0, 2.0, 0.8070684483131693, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1635008.215355233, 1635008.215355233, 337642.8891915847], 
processed observation next is [1.0, 0.6956521739130435, 0.5592592592592593, 0.85, 1.0, 1.0, 0.7703195813252015, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5839315054840118, 0.5839315054840118, 0.6493132484453552], 
reward next is 0.3507, 
noisyNet noise sample is [array([-0.94520843], dtype=float32), 0.14377372]. 
=============================================
[2019-03-23 21:40:06,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1485106e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:06,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-23 21:40:06,669] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 42.16666666666667, 1.0, 2.0, 0.5198461911531532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616804.7315707975, 616804.7315707975, 145925.7005345662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3250200.0000, 
sim time next is 3250800.0000, 
raw observation next is [32.0, 41.0, 1.0, 2.0, 0.5133719072811277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610460.7773257695, 610460.7773257695, 144942.4691560862], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.41, 1.0, 1.0, 0.4206808420013425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21802170618777483, 0.21802170618777483, 0.2787355176078581], 
reward next is 0.7213, 
noisyNet noise sample is [array([-1.4245421], dtype=float32), -0.9762475]. 
=============================================
[2019-03-23 21:40:07,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4598631e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:07,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-23 21:40:07,931] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 53.5, 1.0, 2.0, 0.6067629961695977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694452.6567581544, 694452.6567581544, 159391.6389475257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3256200.0000, 
sim time next is 3256800.0000, 
raw observation next is [30.66666666666666, 56.66666666666667, 1.0, 2.0, 0.6207642027478143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708802.2786704525, 708802.2786704525, 161753.0671957672], 
processed observation next is [0.0, 0.6956521739130435, 0.6913580246913578, 0.5666666666666668, 1.0, 1.0, 0.548528812795017, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.253143670953733, 0.253143670953733, 0.31106359076109075], 
reward next is 0.6889, 
noisyNet noise sample is [array([0.4942964], dtype=float32), 1.2462082]. 
=============================================
[2019-03-23 21:40:08,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.303983e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:40:08,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-23 21:40:08,316] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.6008830990830424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694454.6736476488, 694454.6736476488, 158697.4296869911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273000.0000, 
sim time next is 3273600.0000, 
raw observation next is [25.33333333333334, 84.0, 1.0, 2.0, 0.6024407431656476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695763.6349880208, 695763.6349880208, 158944.1102006406], 
processed observation next is [0.0, 0.9130434782608695, 0.49382716049382736, 0.84, 1.0, 1.0, 0.5267151704352947, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2484870124957217, 0.2484870124957217, 0.3056617503858473], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.67212033], dtype=float32), -0.6585978]. 
=============================================
[2019-03-23 21:40:10,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7347928e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:10,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4956
[2019-03-23 21:40:10,932] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6577575185660002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 749633.9562521745, 749633.956252174, 168299.5946329774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3329400.0000, 
sim time next is 3330000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6595120227149743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751634.5122163635, 751634.5122163635, 168619.1155783043], 
processed observation next is [0.0, 0.5652173913043478, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5946571698987789, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2684408972201298, 0.2684408972201298, 0.3242675299582775], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.79047626], dtype=float32), -1.3619398]. 
=============================================
[2019-03-23 21:40:10,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.39254]
 [69.39254]
 [69.39254]
 [69.39254]
 [69.39254]], R is [[69.37434387]
 [69.35694885]
 [69.3403244 ]
 [69.32437134]
 [69.30929565]].
[2019-03-23 21:40:13,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1313211e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:13,618] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5205
[2019-03-23 21:40:13,623] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 0.6247753909888758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717778.6552727809, 717778.6552727809, 162675.3651219709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.6133088373476403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706990.7820918395, 706990.7820918395, 160774.188148523], 
processed observation next is [1.0, 0.043478260869565216, 0.45123456790123445, 0.9266666666666667, 1.0, 1.0, 0.5396533777948098, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25249670788994266, 0.25249670788994266, 0.30918113105485195], 
reward next is 0.6908, 
noisyNet noise sample is [array([-0.80120414], dtype=float32), -0.38998893]. 
=============================================
[2019-03-23 21:40:15,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0109397e-24 1.0000000e+00 2.4413500e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:15,363] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2315
[2019-03-23 21:40:15,368] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.8426452954427411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972214.9253807475, 972214.9253807475, 205526.0386251759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3381000.0000, 
sim time next is 3381600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.7864928980844861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 907434.9278149928, 907434.9278149924, 193730.4334105009], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.7458248786720072, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32408390279106886, 0.3240839027910687, 0.37255852578942483], 
reward next is 0.6274, 
noisyNet noise sample is [array([-1.8171427], dtype=float32), 0.6640435]. 
=============================================
[2019-03-23 21:40:15,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7569382e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:15,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9972
[2019-03-23 21:40:15,384] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.5447329242690204, 1.0, 2.0, 0.5447329242690204, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1242042.616320471, 1242042.616320471, 249563.8199840002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3416400.0000, 
sim time next is 3417000.0000, 
raw observation next is [30.86666666666667, 59.16666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.122783607601471, 6.9112, 121.9173260734031, 2296018.265648784, 1163570.754377308, 245583.5293794699], 
processed observation next is [1.0, 0.5652173913043478, 0.6987654320987656, 0.5916666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.22115836076014714, 0.0, 0.8094042600441033, 0.8200065234459943, 0.41556098370618144, 0.4722760180374421], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3122275], dtype=float32), -0.54571843]. 
=============================================
[2019-03-23 21:40:15,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[56.925]
 [56.925]
 [56.925]
 [56.925]
 [56.925]], R is [[56.35575104]
 [56.31226349]
 [55.74914169]
 [55.59674454]
 [55.456707  ]].
[2019-03-23 21:40:17,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2645356e-21 1.0000000e+00 4.0813186e-33 5.2384101e-36 2.1238458e-35], sum to 1.0000
[2019-03-23 21:40:17,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-23 21:40:17,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2153437.822228547 W.
[2019-03-23 21:40:17,071] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.75, 60.33333333333334, 1.0, 2.0, 0.6318576126558572, 1.0, 2.0, 0.6292934683043632, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2153437.822228547, 2153437.822228547, 411430.9882882961], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3412200.0000, 
sim time next is 3412800.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.9561016941148394, 1.0, 2.0, 0.9561016941148394, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2181216.534743735, 2181216.534743735, 412480.0032812436], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.59, 1.0, 1.0, 0.9477401120414755, 1.0, 1.0, 0.9477401120414755, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7790059052656196, 0.7790059052656196, 0.7932307755408531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10006431], dtype=float32), 0.013117086]. 
=============================================
[2019-03-23 21:40:19,458] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5720894e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:19,467] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3612
[2019-03-23 21:40:19,476] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.9077029482942526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1034684.384057117, 1034684.384057116, 219192.5841820769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3481800.0000, 
sim time next is 3482400.0000, 
raw observation next is [25.16666666666667, 91.33333333333334, 1.0, 2.0, 0.8153659350571235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929366.2277341749, 929366.2277341749, 199130.1482285752], 
processed observation next is [1.0, 0.30434782608695654, 0.4876543209876545, 0.9133333333333334, 1.0, 1.0, 0.7801975417346708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3319165099050625, 0.3319165099050625, 0.38294259274726], 
reward next is 0.6171, 
noisyNet noise sample is [array([0.29865667], dtype=float32), -0.5732412]. 
=============================================
[2019-03-23 21:40:22,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5036262e-22 1.0000000e+00 9.5437633e-34 1.9413418e-38 5.5937046e-37], sum to 1.0000
[2019-03-23 21:40:22,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9825
[2019-03-23 21:40:22,139] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 69.66666666666667, 1.0, 2.0, 0.5544917449815266, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642651.527728226, 642651.527728226, 150941.4002756183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3518400.0000, 
sim time next is 3519000.0000, 
raw observation next is [27.25, 72.0, 1.0, 2.0, 0.5647476955647727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652371.6480104356, 652371.6480104356, 152544.9850628283], 
processed observation next is [1.0, 0.7391304347826086, 0.5648148148148148, 0.72, 1.0, 1.0, 0.48184249471996743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2329898742894413, 0.2329898742894413, 0.293355740505439], 
reward next is 0.7066, 
noisyNet noise sample is [array([0.5848055], dtype=float32), 0.60919225]. 
=============================================
[2019-03-23 21:40:22,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.26192]
 [49.26192]
 [49.26192]
 [49.26192]
 [49.26192]], R is [[49.47594833]
 [48.98118973]
 [49.09792709]
 [49.10264587]
 [49.07165527]].
[2019-03-23 21:40:24,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6713155e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:24,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2917
[2019-03-23 21:40:24,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1298814.346106648 W.
[2019-03-23 21:40:24,398] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 90.66666666666667, 1.0, 2.0, 0.9602563925929403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.200854905725208, 6.9112, 121.9249444599202, 1298814.346106648, 1150486.481275673, 234063.1464219672], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3575400.0000, 
sim time next is 3576000.0000, 
raw observation next is [22.6, 90.33333333333334, 1.0, 2.0, 0.4869180271254426, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7808917360374134, 6.9112, 6.9112, 121.925868190604, 1151965.678294179, 1151965.678294179, 251455.5352523283], 
processed observation next is [1.0, 0.391304347826087, 0.39259259259259266, 0.9033333333333334, 1.0, 1.0, 0.3891881275302888, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7261146700467666, 0.0, 0.0, 0.8094609708191415, 0.4114163136764925, 0.4114163136764925, 0.4835683370237083], 
reward next is 0.5164, 
noisyNet noise sample is [array([-0.23374054], dtype=float32), 0.4022761]. 
=============================================
[2019-03-23 21:40:24,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.2603]
 [68.2603]
 [68.2603]
 [68.2603]
 [68.2603]], R is [[68.09412384]
 [67.41318512]
 [67.32798004]
 [67.27692413]
 [67.22424316]].
[2019-03-23 21:40:25,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0328796e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:40:25,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6781
[2019-03-23 21:40:25,188] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 89.66666666666666, 1.0, 2.0, 0.9600166190230688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.178911051743038, 6.9112, 121.9249275187384, 1283505.8800217, 1146415.147586813, 233844.833405882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3577200.0000, 
sim time next is 3577800.0000, 
raw observation next is [22.9, 89.33333333333333, 1.0, 2.0, 0.9890199752906842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.360212752886915, 6.9112, 121.9239616213407, 1409987.402584636, 1180056.665252634, 240778.9294290505], 
processed observation next is [1.0, 0.391304347826087, 0.4037037037037037, 0.8933333333333333, 1.0, 1.0, 0.9869285420127193, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04490127528869152, 0.0, 0.8094483131819253, 0.5035669294945129, 0.4214488090187979, 0.46303640274817404], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13412337], dtype=float32), -1.0392914]. 
=============================================
[2019-03-23 21:40:30,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5708978e-22 1.0000000e+00 2.4533715e-33 1.1947231e-36 1.4248868e-36], sum to 1.0000
[2019-03-23 21:40:30,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8696
[2019-03-23 21:40:30,647] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7038258997582904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802164.702685242, 802164.702685242, 176873.7307320724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3693600.0000, 
sim time next is 3694200.0000, 
raw observation next is [26.93333333333333, 89.16666666666667, 1.0, 2.0, 0.7136999304661727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813424.3079552135, 813424.3079552135, 178757.4554532334], 
processed observation next is [1.0, 0.782608695652174, 0.5530864197530863, 0.8916666666666667, 1.0, 1.0, 0.6591665838883008, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29050868141257624, 0.29050868141257624, 0.3437643374100642], 
reward next is 0.6562, 
noisyNet noise sample is [array([0.38405296], dtype=float32), 0.19270785]. 
=============================================
[2019-03-23 21:40:32,309] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1427e-27 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-23 21:40:32,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3557
[2019-03-23 21:40:32,323] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.8131925117447137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926887.4293711007, 926887.4293711007, 198676.6147371447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3726000.0000, 
sim time next is 3726600.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.729640548143817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 831602.1438237402, 831602.1438237398, 181827.9199490688], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.6781435096950201, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29700076565133576, 0.29700076565133565, 0.3496690768251323], 
reward next is 0.6503, 
noisyNet noise sample is [array([1.2744305], dtype=float32), 0.33358458]. 
=============================================
[2019-03-23 21:40:35,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4903975e-21 1.0000000e+00 1.4248416e-31 3.4354218e-35 1.8105888e-35], sum to 1.0000
[2019-03-23 21:40:35,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7384
[2019-03-23 21:40:35,698] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.58333333333334, 59.66666666666667, 1.0, 2.0, 0.7223528956618376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 823291.6375372452, 823291.6375372447, 180425.137465589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3784200.0000, 
sim time next is 3784800.0000, 
raw observation next is [32.16666666666667, 63.33333333333334, 1.0, 2.0, 0.7423879408439175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846138.9053400676, 846138.9053400676, 184331.5787092351], 
processed observation next is [1.0, 0.8260869565217391, 0.7469135802469138, 0.6333333333333334, 1.0, 1.0, 0.6933189771951398, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30219246619288126, 0.30219246619288126, 0.3544838052100675], 
reward next is 0.6455, 
noisyNet noise sample is [array([-0.19929928], dtype=float32), -1.0418477]. 
=============================================
[2019-03-23 21:40:36,933] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 21:40:36,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:40:36,936] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:40:36,937] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:40:36,937] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:40:36,938] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:40:36,939] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:40:36,942] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:40:36,942] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:40:36,943] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:40:36,937] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:40:36,957] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 21:40:36,985] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 21:40:37,011] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 21:40:37,011] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 21:40:37,012] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 21:41:19,983] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:41:19,985] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.49940943666667, 89.67695184, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 9.844576895280682, 6.9112, 121.9141730001092, 3381662.308339727, 1879657.391539484, 375471.2316469164]
[2019-03-23 21:41:19,986] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:41:19,988] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.456840254388305
[2019-03-23 21:41:19,988] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3381662.308339727 W.
[2019-03-23 21:41:21,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:41:21,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.01233253666666, 43.78241351666667, 1.0, 2.0, 0.7228805641937492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829460.0092365611, 829460.0092365611, 180799.8336467395]
[2019-03-23 21:41:21,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:41:21,372] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2685418671110207
[2019-03-23 21:41:40,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:41:40,906] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.91290448, 110.7741042, 1.0, 2.0, 0.8492785367261055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 985360.0128210868, 985360.0128210868, 207235.0882499449]
[2019-03-23 21:41:40,909] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:41:40,911] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2936743631027485
[2019-03-23 21:41:56,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:41:56,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.58333333333333, 67.5, 1.0, 2.0, 0.681680117023424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776911.9117737382, 776911.9117737378, 172705.085290306]
[2019-03-23 21:41:56,576] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:41:56,578] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5090659911902665
[2019-03-23 21:42:05,351] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:42:05,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.34043781666667, 51.35370053, 1.0, 2.0, 0.5489702979142566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 643201.8468847168, 643201.8468847163, 150337.7777951459]
[2019-03-23 21:42:05,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:42:05,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2041004236293984
[2019-03-23 21:42:12,950] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.14830315]
[2019-03-23 21:42:12,950] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.28646372666667, 93.48555517333334, 1.0, 2.0, 0.5323415362954972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625104.2958674409, 625104.2958674409, 147680.6409316883]
[2019-03-23 21:42:12,952] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:42:12,953] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.771864e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9166670639510694
[2019-03-23 21:42:16,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:42:17,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:42:17,146] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:42:17,192] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:42:17,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:42:18,334] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 950000, evaluation results [950000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:42:22,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.221888e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:42:22,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6568
[2019-03-23 21:42:22,291] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8176001568953689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 931914.3754272321, 931914.375427233, 199611.6080953157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3880800.0000, 
sim time next is 3881400.0000, 
raw observation next is [27.78333333333333, 89.0, 1.0, 2.0, 0.7817049349450454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890976.616011591, 890976.616011591, 192196.3192013887], 
processed observation next is [0.0, 0.9565217391304348, 0.5845679012345678, 0.89, 1.0, 1.0, 0.7401249225536255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31820593428985394, 0.31820593428985394, 0.3696083061565167], 
reward next is 0.6304, 
noisyNet noise sample is [array([-0.87697846], dtype=float32), 0.9802596]. 
=============================================
[2019-03-23 21:42:25,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6771944e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:42:25,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6833
[2019-03-23 21:42:25,545] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8116539409242017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925132.6877727499, 925132.6877727499, 198367.39843174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3934200.0000, 
sim time next is 3934800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8118968863671518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925409.7670324073, 925409.7670324073, 198418.0877953622], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.7, 1.0, 1.0, 0.776067721865657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3305034882258598, 0.3305034882258598, 0.38157324576031193], 
reward next is 0.6184, 
noisyNet noise sample is [array([1.501193], dtype=float32), -0.54461336]. 
=============================================
[2019-03-23 21:42:40,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5247145e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:42:40,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3296
[2019-03-23 21:42:40,958] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.4910025391168655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587777.3885420519, 587777.3885420519, 141567.0987810325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4233600.0000, 
sim time next is 4234200.0000, 
raw observation next is [25.16666666666667, 71.33333333333334, 1.0, 2.0, 0.4884672642338033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585866.8464131264, 585866.8464131264, 141212.1300198144], 
processed observation next is [1.0, 0.0, 0.4876543209876545, 0.7133333333333334, 1.0, 1.0, 0.39103245742119447, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20923815943325944, 0.20923815943325944, 0.2715617884996431], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.05819084], dtype=float32), 1.8846629]. 
=============================================
[2019-03-23 21:42:50,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0972373e-22 1.0000000e+00 2.2444341e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:42:50,015] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0807
[2019-03-23 21:42:50,020] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 50.66666666666667, 1.0, 2.0, 0.4461883304532918, 1.0, 2.0, 0.4461883304532918, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1017202.45791221, 1017202.457912211, 219242.681114073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4381800.0000, 
sim time next is 4382400.0000, 
raw observation next is [32.06666666666667, 52.33333333333334, 1.0, 2.0, 0.6168467687027848, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702987.3594480085, 702987.3594480085, 161000.4032916081], 
processed observation next is [1.0, 0.7391304347826086, 0.74320987654321, 0.5233333333333334, 1.0, 1.0, 0.5438652008366485, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25106691408857446, 0.25106691408857446, 0.3096161601761694], 
reward next is 0.6904, 
noisyNet noise sample is [array([-0.31950095], dtype=float32), -0.55505544]. 
=============================================
[2019-03-23 21:42:52,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6852368e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:42:52,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6386
[2019-03-23 21:42:52,444] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 74.0, 1.0, 2.0, 0.6305876495309908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720288.1324666169, 720288.1324666169, 163500.4237305037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4449600.0000, 
sim time next is 4450200.0000, 
raw observation next is [27.5, 74.0, 1.0, 2.0, 0.6319744171644636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720445.1336096615, 720445.1336096615, 163674.8744925956], 
processed observation next is [0.0, 0.5217391304347826, 0.5740740740740741, 0.74, 1.0, 1.0, 0.5618743061481709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25730183343202195, 0.25730183343202195, 0.3147593740242223], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.5081463], dtype=float32), -0.31004587]. 
=============================================
[2019-03-23 21:42:56,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.429284e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:42:56,336] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3878
[2019-03-23 21:42:56,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 98.5, 1.0, 2.0, 0.5742856120652567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 668888.4367742707, 668888.4367742703, 154392.2449472986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4513800.0000, 
sim time next is 4514400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5830250960188147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677172.45223416, 677172.45223416, 155789.6057178652], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5036013047843032, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24184730436934287, 0.24184730436934287, 0.29959539561127924], 
reward next is 0.7004, 
noisyNet noise sample is [array([-0.5490224], dtype=float32), -0.16312577]. 
=============================================
[2019-03-23 21:43:03,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.331055e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:43:03,651] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6611
[2019-03-23 21:43:03,657] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.6772716201310525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771885.0110457767, 771885.0110457767, 171884.7896413899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4650000.0000, 
sim time next is 4650600.0000, 
raw observation next is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.6717368064195233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765573.8455898293, 765573.8455898293, 170861.0484092824], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432101, 0.8233333333333335, 1.0, 1.0, 0.6092104838327658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27341923056779616, 0.27341923056779616, 0.32857893924862003], 
reward next is 0.6714, 
noisyNet noise sample is [array([-0.26325536], dtype=float32), -0.8593303]. 
=============================================
[2019-03-23 21:43:04,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.502539e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:43:04,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8083
[2019-03-23 21:43:04,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1879230.676945969 W.
[2019-03-23 21:43:04,959] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.08333333333333, 80.66666666666667, 1.0, 2.0, 0.5492468450054333, 1.0, 2.0, 0.5492468450054333, 1.0, 1.0, 0.8744188649695848, 6.911200000000001, 6.9112, 121.94756008, 1879230.676945969, 1879230.676945969, 368416.9413319991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4705800.0000, 
sim time next is 4706400.0000, 
raw observation next is [26.86666666666667, 82.33333333333334, 1.0, 2.0, 0.7488550005137281, 1.0, 2.0, 0.7488550005137281, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1707959.165815407, 1707959.165815407, 323073.5766355615], 
processed observation next is [1.0, 0.4782608695652174, 0.5506172839506175, 0.8233333333333335, 1.0, 1.0, 0.7010178577544383, 1.0, 1.0, 0.7010178577544383, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6099854163626454, 0.6099854163626454, 0.621295339683772], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7445278], dtype=float32), 1.3241838]. 
=============================================
[2019-03-23 21:43:08,279] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.79301331e-23 1.00000000e+00 1.02009025e-35 0.00000000e+00
 6.61222074e-38], sum to 1.0000
[2019-03-23 21:43:08,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0007
[2019-03-23 21:43:08,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1709244.103117286 W.
[2019-03-23 21:43:08,308] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.26666666666667, 82.33333333333334, 1.0, 2.0, 0.499611979617226, 1.0, 2.0, 0.499611979617226, 1.0, 1.0, 0.7953985427768465, 6.9112, 6.9112, 121.94756008, 1709244.103117286, 1709244.103117286, 343398.630963912], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4724400.0000, 
sim time next is 4725000.0000, 
raw observation next is [28.4, 81.5, 1.0, 2.0, 0.4849436163644777, 1.0, 2.0, 0.4849436163644777, 1.0, 2.0, 0.7720460307632312, 6.9112, 6.9112, 121.94756008, 1659014.944161345, 1659014.944161345, 336260.6600638476], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.815, 1.0, 1.0, 0.3868376385291401, 1.0, 1.0, 0.3868376385291401, 1.0, 1.0, 0.7150575384540389, 0.0, 0.0, 0.8096049824067558, 0.5925053372004804, 0.5925053372004804, 0.6466551155073993], 
reward next is 0.3533, 
noisyNet noise sample is [array([-0.686698], dtype=float32), -0.5184283]. 
=============================================
[2019-03-23 21:43:08,325] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.276978]
 [50.276978]
 [50.276978]
 [50.276978]
 [50.276978]], R is [[50.12755203]
 [49.96589661]
 [49.75801086]
 [49.5000267 ]
 [49.194561  ]].
[2019-03-23 21:43:08,456] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 21:43:08,457] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:43:08,458] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:43:08,458] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:43:08,459] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:43:08,458] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:43:08,461] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:43:08,459] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:43:08,460] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:43:08,467] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:43:08,468] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:43:08,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 21:43:08,510] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 21:43:08,511] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 21:43:08,512] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 21:43:08,536] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 21:43:19,219] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.15998435]
[2019-03-23 21:43:19,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.43333333333334, 53.0, 1.0, 2.0, 0.4570942161061065, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7555966692498637, 6.911199999999999, 6.9112, 121.9258284492075, 1129460.179214668, 1129460.179214668, 238744.9195413941]
[2019-03-23 21:43:19,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:43:19,226] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.054091e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.47722217114985743
[2019-03-23 21:43:40,386] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.15998435]
[2019-03-23 21:43:40,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.14888098, 101.7063663333333, 1.0, 2.0, 0.4877512035334047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 587555.6946148329, 587555.6946148324, 141189.1001207292]
[2019-03-23 21:43:40,388] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:43:40,391] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.054091e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5055326233897902
[2019-03-23 21:44:22,075] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.15998435]
[2019-03-23 21:44:22,076] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.61666666666667, 72.0, 1.0, 2.0, 0.6988024085025275, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260424991621, 1511434.441074402, 1511434.441074402, 317018.3462455361]
[2019-03-23 21:44:22,077] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:44:22,079] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.054091e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.29070337876050734
[2019-03-23 21:44:22,079] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1511434.441074402 W.
[2019-03-23 21:44:41,748] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.15998435]
[2019-03-23 21:44:41,749] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.66666666666666, 23.66666666666666, 1.0, 2.0, 0.3413755680116305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438387.0871118166, 438387.0871118166, 120839.2846005028]
[2019-03-23 21:44:41,751] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:44:41,752] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.054091e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.295748128752764
[2019-03-23 21:44:42,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.15998435]
[2019-03-23 21:44:42,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.7, 50.0, 1.0, 2.0, 0.2846321685669557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366232.5440304709, 366232.5440304709, 113691.5856667982]
[2019-03-23 21:44:42,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:44:42,278] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.054091e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.44952885236065454
[2019-03-23 21:44:48,407] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:44:48,522] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:44:48,627] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:44:48,795] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:44:48,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:44:49,846] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 975000, evaluation results [975000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:44:52,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3231275e-23 1.0000000e+00 9.4221677e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:52,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4952
[2019-03-23 21:44:52,355] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.6546996730137731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755695.431842102, 755695.431842102, 168214.4269480438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [23.98333333333333, 93.83333333333334, 1.0, 2.0, 0.6435295575258752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 743108.7560269831, 743108.7560269827, 166203.6056432379], 
processed observation next is [1.0, 0.30434782608695654, 0.4438271604938271, 0.9383333333333335, 1.0, 1.0, 0.5756304256260418, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2653959842953511, 0.26539598429535094, 0.3196223185446883], 
reward next is 0.6804, 
noisyNet noise sample is [array([0.4629468], dtype=float32), 0.57004315]. 
=============================================
[2019-03-23 21:44:58,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5579028e-22 1.0000000e+00 2.0497123e-33 0.0000000e+00 1.2858099e-37], sum to 1.0000
[2019-03-23 21:44:58,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0706
[2019-03-23 21:44:58,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2853299.851628855 W.
[2019-03-23 21:44:58,370] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 77.5, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8334859748071962, 1.0, 1.0, 0.9977734948820727, 6.95629955959781, 6.9112, 121.94756008, 2853299.851628855, 2830200.770363586, 528193.371705811], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [31.06666666666667, 73.66666666666667, 1.0, 2.0, 0.8918981222319912, 1.0, 2.0, 0.7593137230924304, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2599013.824764322, 2599013.824764322, 484786.9588906516], 
processed observation next is [1.0, 0.6956521739130435, 0.7061728395061729, 0.7366666666666667, 1.0, 1.0, 0.871307288371418, 1.0, 1.0, 0.713468717967179, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.928219223130115, 0.928219223130115, 0.9322826132512531], 
reward next is 0.0677, 
noisyNet noise sample is [array([2.168251], dtype=float32), -0.5538862]. 
=============================================
[2019-03-23 21:45:00,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9088858e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:00,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3751
[2019-03-23 21:45:00,200] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 76.33333333333334, 1.0, 2.0, 0.6306133331894446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720847.9187058123, 720847.9187058128, 163531.2198538065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [26.91666666666667, 75.66666666666666, 1.0, 2.0, 0.6214620955568229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 712246.0254546799, 712246.0254546803, 162006.4694399126], 
processed observation next is [1.0, 0.043478260869565216, 0.5524691358024693, 0.7566666666666666, 1.0, 1.0, 0.5493596375676463, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2543735805195285, 0.2543735805195287, 0.31155090276906267], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.6668532], dtype=float32), -0.81561035]. 
=============================================
[2019-03-23 21:45:05,501] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6230603e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:05,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-23 21:45:05,518] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 98.0, 1.0, 2.0, 0.5502946807557475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646815.3162712904, 646815.3162712904, 150642.8986651343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5018400.0000, 
sim time next is 5019000.0000, 
raw observation next is [22.66666666666667, 97.33333333333334, 1.0, 2.0, 0.547579652968225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644130.3209518847, 644130.3209518847, 150216.1939024548], 
processed observation next is [0.0, 0.08695652173913043, 0.39506172839506193, 0.9733333333333334, 1.0, 1.0, 0.4614043487716964, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2300465431971017, 0.2300465431971017, 0.2888772959662592], 
reward next is 0.7111, 
noisyNet noise sample is [array([1.5150692], dtype=float32), -0.33234838]. 
=============================================
[2019-03-23 21:45:05,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.14503]
 [67.14503]
 [67.14503]
 [67.14503]
 [67.14503]], R is [[67.18470001]
 [67.22315979]
 [67.25984192]
 [67.29438019]
 [67.3263092 ]].
[2019-03-23 21:45:12,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2800724e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:12,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-23 21:45:12,195] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.93333333333333, 69.33333333333334, 1.0, 2.0, 0.7927564118551285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 903580.3642281317, 903580.3642281317, 194454.8039803827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5157600.0000, 
sim time next is 5158200.0000, 
raw observation next is [30.91666666666666, 69.16666666666666, 1.0, 2.0, 0.7961589804291711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 907460.8934246823, 907460.8934246823, 195154.2813943087], 
processed observation next is [0.0, 0.6956521739130435, 0.7006172839506171, 0.6916666666666665, 1.0, 1.0, 0.757332119558537, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32409317622310085, 0.32409317622310085, 0.37529669498905516], 
reward next is 0.6247, 
noisyNet noise sample is [array([0.08478864], dtype=float32), 0.14126228]. 
=============================================
[2019-03-23 21:45:14,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.6580385e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:14,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-23 21:45:14,779] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 94.66666666666667, 1.0, 2.0, 0.743481735958343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858616.2828746102, 858616.2828746102, 185105.8588264808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [23.8, 95.0, 1.0, 2.0, 0.7290358989337891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842425.7353278663, 842425.7353278663, 182291.1209739638], 
processed observation next is [1.0, 0.17391304347826086, 0.43703703703703706, 0.95, 1.0, 1.0, 0.6774236892068918, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30086633404566654, 0.30086633404566654, 0.35055984802685347], 
reward next is 0.6494, 
noisyNet noise sample is [array([-0.43744698], dtype=float32), 1.8151788]. 
=============================================
[2019-03-23 21:45:22,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4005136e-20 1.0000000e+00 1.2394293e-34 5.8589074e-38 1.8882302e-36], sum to 1.0000
[2019-03-23 21:45:22,398] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1626
[2019-03-23 21:45:22,402] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 68.0, 1.0, 2.0, 0.5989265202865638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685650.4091171605, 685650.4091171605, 158046.2063548078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5335200.0000, 
sim time next is 5335800.0000, 
raw observation next is [28.26666666666667, 68.33333333333334, 1.0, 2.0, 0.6007137960509198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687436.2929672345, 687436.2929672345, 158341.2460408951], 
processed observation next is [1.0, 0.782608695652174, 0.6024691358024692, 0.6833333333333335, 1.0, 1.0, 0.5246592810129997, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24551296177401233, 0.24551296177401233, 0.30450239623249054], 
reward next is 0.6955, 
noisyNet noise sample is [array([-1.0128734], dtype=float32), -1.3441062]. 
=============================================
[2019-03-23 21:45:25,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.080517e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:45:25,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6981
[2019-03-23 21:45:25,374] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333333, 72.5, 1.0, 2.0, 0.3314254834336094, 1.0, 2.0, 0.3314254834336094, 1.0, 1.0, 0.527640163400749, 6.911199999999999, 6.9112, 121.94756008, 1133441.771740511, 1133441.771740511, 268347.370682981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5418600.0000, 
sim time next is 5419200.0000, 
raw observation next is [29.86666666666667, 73.0, 1.0, 2.0, 0.6932560963620734, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425790667, 790111.8736348825, 790111.8736348825, 174877.6538906269], 
processed observation next is [1.0, 0.7391304347826086, 0.6617283950617285, 0.73, 1.0, 1.0, 0.6348286861453255, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621285771826, 0.28218281201245804, 0.28218281201245804, 0.3363031805588979], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40198258], dtype=float32), -1.7676226]. 
=============================================
[2019-03-23 21:45:27,409] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8392025e-22 1.0000000e+00 5.3384286e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:27,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0905
[2019-03-23 21:45:27,419] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.73333333333333, 74.0, 1.0, 2.0, 0.6931546279227061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789996.16930233, 789996.16930233, 174858.7835387859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5420400.0000, 
sim time next is 5421000.0000, 
raw observation next is [29.66666666666667, 74.5, 1.0, 2.0, 0.7070884734301434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805885.0791077524, 805885.0791077529, 177496.6021932139], 
processed observation next is [1.0, 0.7391304347826086, 0.6543209876543211, 0.745, 1.0, 1.0, 0.6512958017025516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28781609968134014, 0.2878160996813403, 0.34133961960233444], 
reward next is 0.6587, 
noisyNet noise sample is [array([0.26122746], dtype=float32), -0.46661195]. 
=============================================
[2019-03-23 21:45:27,459] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[49.03278]
 [49.03278]
 [49.03278]
 [49.03278]
 [49.03278]], R is [[49.20111084]
 [49.37283325]
 [49.54653549]
 [49.71496964]
 [49.76940918]].
[2019-03-23 21:45:32,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5338874e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:32,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8573
[2019-03-23 21:45:32,996] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.51666666666667, 92.83333333333333, 1.0, 2.0, 0.6826853450136382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 778058.153176976, 778058.1531769747, 172891.7975419416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5536200.0000, 
sim time next is 5536800.0000, 
raw observation next is [25.5, 93.0, 1.0, 2.0, 0.6828738307968908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778273.0799424673, 778273.0799424673, 172926.9395340979], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.93, 1.0, 1.0, 0.6224688461867748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27795467140802405, 0.27795467140802405, 0.3325518067963421], 
reward next is 0.6674, 
noisyNet noise sample is [array([-0.3113822], dtype=float32), -0.82266384]. 
=============================================
[2019-03-23 21:45:38,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3760707e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:45:38,986] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5875
[2019-03-23 21:45:38,992] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5847347191477948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676671.177473789, 676671.177473789, 155967.0633027043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5632800.0000, 
sim time next is 5633400.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.5856501096822758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 677730.54054409, 677730.5405440895, 156123.0065192922], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5067263210503283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24204662162288929, 0.24204662162288912, 0.30023655099863883], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.305642], dtype=float32), 1.6304688]. 
=============================================
[2019-03-23 21:45:41,077] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 21:45:41,078] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:45:41,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:45:41,078] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:45:41,079] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:45:41,080] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:45:41,082] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:45:41,081] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:45:41,082] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:45:41,084] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:45:41,084] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:45:41,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 21:45:41,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 21:45:41,124] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 21:45:41,169] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 21:45:41,170] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 21:45:49,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:45:49,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.26499003, 74.62614048, 1.0, 2.0, 0.3055837615329428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 388505.6218352589, 388505.6218352584, 116261.4302986638]
[2019-03-23 21:45:49,923] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:45:49,927] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.22930411869913492
[2019-03-23 21:46:09,888] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:46:09,889] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.32066631, 89.572598555, 1.0, 2.0, 0.4345020381340275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 531902.1448509156, 531902.1448509152, 133423.1400717183]
[2019-03-23 21:46:09,891] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:46:09,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.013826685584336862
[2019-03-23 21:46:27,227] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:46:27,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5042006001144391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 598322.9476574365, 598322.947657436, 143441.9748236022]
[2019-03-23 21:46:27,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:46:27,231] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8871634571623227
[2019-03-23 21:46:46,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:46:46,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.93333333333334, 72.33333333333334, 1.0, 2.0, 0.5366583935340968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633414.4778053828, 633414.4778053828, 148514.1265720082]
[2019-03-23 21:46:46,858] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:46:46,861] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8237766963963415
[2019-03-23 21:47:00,611] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:47:00,612] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.141338415, 71.43234853, 1.0, 2.0, 0.4232497898091006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522340.8328743872, 522340.8328743872, 131893.5804992246]
[2019-03-23 21:47:00,613] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:47:00,616] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.649306880758958
[2019-03-23 21:47:06,943] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.2927775]
[2019-03-23 21:47:06,943] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.736205795, 55.199702365, 1.0, 2.0, 0.2561348828128644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 329884.6407279096, 329884.6407279096, 110318.7302557076]
[2019-03-23 21:47:06,946] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:47:06,949] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1874128e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.09701796188006273
[2019-03-23 21:47:22,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:47:22,291] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:47:22,480] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:47:22,510] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:47:22,741] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:47:23,755] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1000000, evaluation results [1000000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:47:29,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.804054e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:47:29,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9473
[2019-03-23 21:47:29,457] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 89.0, 1.0, 2.0, 0.5276308919112929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641051.1475370325, 641051.1475370325, 147704.1766388214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5799600.0000, 
sim time next is 5800200.0000, 
raw observation next is [21.83333333333333, 89.5, 1.0, 2.0, 0.5304913948440554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644525.8278643475, 644525.8278643475, 148170.6378122088], 
processed observation next is [1.0, 0.13043478260869565, 0.36419753086419737, 0.895, 1.0, 1.0, 0.44106118433816116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23018779566583839, 0.23018779566583839, 0.2849435342542477], 
reward next is 0.7151, 
noisyNet noise sample is [array([-1.1297054], dtype=float32), 0.4731003]. 
=============================================
[2019-03-23 21:47:30,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.917086e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:47:30,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-23 21:47:30,261] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.0, 1.0, 2.0, 0.4866668928933349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584490.0187378175, 584490.0187378171, 140960.2111245544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5788800.0000, 
sim time next is 5789400.0000, 
raw observation next is [23.03333333333334, 85.16666666666667, 1.0, 2.0, 0.4837998936722462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581595.902271298, 581595.902271298, 140535.2870206156], 
processed observation next is [1.0, 0.0, 0.40864197530864216, 0.8516666666666667, 1.0, 1.0, 0.38547606389553113, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2077128222397493, 0.2077128222397493, 0.27026016734733765], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.01342877], dtype=float32), 0.12962925]. 
=============================================
[2019-03-23 21:47:36,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2263826e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:47:36,259] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5009
[2019-03-23 21:47:36,264] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 47.0, 1.0, 2.0, 0.8177661055216664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 997720.0920992416, 997720.0920992416, 202532.599466911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5922000.0000, 
sim time next is 5922600.0000, 
raw observation next is [28.76666666666667, 46.16666666666667, 1.0, 2.0, 0.9520270966652452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.262109305418153, 6.9112, 121.9247772271569, 1341547.064391468, 1161852.001053281, 232918.9829515954], 
processed observation next is [1.0, 0.5652173913043478, 0.6209876543209878, 0.4616666666666667, 1.0, 1.0, 0.9428894007919586, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.035090930541815266, 0.0, 0.8094537279563747, 0.4791239515683814, 0.4149471432333146, 0.4479211210607604], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2641631], dtype=float32), 0.07666235]. 
=============================================
[2019-03-23 21:47:47,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1347523e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:47:47,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1398
[2019-03-23 21:47:47,826] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1413986.069250472 W.
[2019-03-23 21:47:47,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.56666666666667, 82.66666666666667, 1.0, 2.0, 1.003792148046634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.365945707105618, 6.9112, 121.9244272576414, 1413986.069250472, 1181118.707726232, 243614.6178424499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6164400.0000, 
sim time next is 6165000.0000, 
raw observation next is [24.75, 81.5, 1.0, 2.0, 0.6258679097484995, 1.0, 1.0, 0.6258679097484995, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257687756254, 1441784.165207818, 1441784.165207818, 277773.6753438927], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.815, 1.0, 1.0, 0.5546046544624994, 1.0, 0.5, 0.5546046544624994, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094603108070678, 0.5149229161456492, 0.5149229161456492, 0.5341801448921014], 
reward next is 0.4658, 
noisyNet noise sample is [array([-0.8953306], dtype=float32), -0.75894094]. 
=============================================
[2019-03-23 21:47:47,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.269665]
 [63.269665]
 [63.269665]
 [63.269665]
 [63.269665]], R is [[63.10279083]
 [62.47176361]
 [62.49186707]
 [62.57006073]
 [62.65046692]].
[2019-03-23 21:47:53,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.43801835e-30 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 21:47:53,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2189
[2019-03-23 21:47:53,660] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 86.33333333333334, 1.0, 2.0, 0.4937418765900969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591291.9303601391, 591291.9303601386, 142002.4580575171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6243600.0000, 
sim time next is 6244200.0000, 
raw observation next is [23.25, 86.0, 1.0, 2.0, 0.4975834271406459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595132.6421985315, 595132.6421985315, 142576.583015704], 
processed observation next is [0.0, 0.2608695652173913, 0.4166666666666667, 0.86, 1.0, 1.0, 0.40188503231029277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21254737221376127, 0.21254737221376127, 0.2741857365686615], 
reward next is 0.7258, 
noisyNet noise sample is [array([0.02641268], dtype=float32), 1.3959157]. 
=============================================
[2019-03-23 21:47:57,401] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.493736e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:47:57,414] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2000
[2019-03-23 21:47:57,419] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 64.33333333333334, 1.0, 2.0, 0.610273460766347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702326.1805748454, 702326.1805748454, 160188.3656797025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6289800.0000, 
sim time next is 6290400.0000, 
raw observation next is [28.56666666666667, 64.66666666666667, 1.0, 2.0, 0.6072403608543481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699594.3739285101, 699594.3739285101, 159696.5042580312], 
processed observation next is [0.0, 0.8260869565217391, 0.6135802469135804, 0.6466666666666667, 1.0, 1.0, 0.532429001017081, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24985513354589647, 0.24985513354589647, 0.3071086620346754], 
reward next is 0.6929, 
noisyNet noise sample is [array([-0.7511985], dtype=float32), -2.0411663]. 
=============================================
[2019-03-23 21:47:58,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.662303e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:47:58,206] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1515
[2019-03-23 21:47:58,210] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.4, 58.0, 1.0, 2.0, 0.6843818843457101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 779992.6869858245, 779992.686985824, 173208.3272793795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6357600.0000, 
sim time next is 6358200.0000, 
raw observation next is [31.45, 57.83333333333334, 1.0, 2.0, 0.6751274821531135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769440.1150886265, 769440.1150886265, 171489.1628739215], 
processed observation next is [0.0, 0.6086956521739131, 0.7203703703703703, 0.5783333333333335, 1.0, 1.0, 0.6132470025632303, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27480004110308087, 0.27480004110308087, 0.3297868516806183], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.01437892], dtype=float32), 1.0935872]. 
=============================================
[2019-03-23 21:48:00,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1671617e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:48:00,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8604
[2019-03-23 21:48:00,578] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.91666666666667, 77.33333333333334, 1.0, 2.0, 0.3196941848645871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406564.1003909291, 406564.1003909291, 118037.3092240172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6743400.0000, 
sim time next is 6744000.0000, 
raw observation next is [19.83333333333334, 77.66666666666667, 1.0, 2.0, 0.3182596268656392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 404904.1146652147, 404904.1146652142, 117856.186096029], 
processed observation next is [1.0, 0.043478260869565216, 0.2901234567901237, 0.7766666666666667, 1.0, 1.0, 0.18840431769718952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14460861238043382, 0.14460861238043365, 0.22664651172313272], 
reward next is 0.7734, 
noisyNet noise sample is [array([-0.04887672], dtype=float32), -0.25544223]. 
=============================================
[2019-03-23 21:48:00,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.30498]
 [69.30498]
 [69.30498]
 [69.30498]
 [69.30498]], R is [[69.38527679]
 [69.46442413]
 [69.54232025]
 [69.61869049]
 [69.693367  ]].
[2019-03-23 21:48:00,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4481e-27 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-23 21:48:00,745] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5505
[2019-03-23 21:48:00,755] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 58.0, 1.0, 2.0, 0.6749500059819319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769237.7447054767, 769237.7447054767, 171455.4059126619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [31.08333333333333, 58.66666666666667, 1.0, 2.0, 0.6739702014386448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 768120.5059864055, 768120.5059864065, 171274.3853588175], 
processed observation next is [0.0, 0.782608695652174, 0.7067901234567899, 0.5866666666666667, 1.0, 1.0, 0.6118692874269581, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.27432875213800195, 0.2743287521380023, 0.32937381799772597], 
reward next is 0.6706, 
noisyNet noise sample is [array([0.8264235], dtype=float32), -0.4761008]. 
=============================================
[2019-03-23 21:48:02,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.530069e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:48:02,989] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9671
[2019-03-23 21:48:02,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2185564.331165178 W.
[2019-03-23 21:48:03,003] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.06666666666666, 56.0, 1.0, 2.0, 0.9580051520522822, 1.0, 2.0, 0.9580051520522822, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2185564.331165178, 2185564.331165179, 413370.4760656772], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6442800.0000, 
sim time next is 6443400.0000, 
raw observation next is [32.23333333333333, 55.0, 1.0, 2.0, 0.966729778947626, 1.0, 2.0, 0.966729778947626, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2205493.018084946, 2205493.018084946, 417466.4697719496], 
processed observation next is [1.0, 0.5652173913043478, 0.7493827160493824, 0.55, 1.0, 1.0, 0.9603925939852691, 1.0, 1.0, 0.9603925939852691, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7876760778874807, 0.7876760778874807, 0.8028201341768261], 
reward next is 0.1972, 
noisyNet noise sample is [array([-1.6329064], dtype=float32), 0.5784807]. 
=============================================
[2019-03-23 21:48:10,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.471623e-19 1.000000e+00 8.608192e-29 2.364837e-32 3.073547e-32], sum to 1.0000
[2019-03-23 21:48:10,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5706
[2019-03-23 21:48:10,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2093117.016308745 W.
[2019-03-23 21:48:10,327] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.53333333333333, 79.33333333333334, 1.0, 2.0, 0.9175298767817137, 1.0, 2.0, 0.9175298767817137, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2093117.016308745, 2093117.016308745, 394713.8424476972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6520800.0000, 
sim time next is 6521400.0000, 
raw observation next is [28.45, 79.5, 1.0, 2.0, 0.9093795459554315, 1.0, 2.0, 0.9093795459554315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2074502.45872092, 2074502.45872092, 391025.5235221686], 
processed observation next is [1.0, 0.4782608695652174, 0.6092592592592593, 0.795, 1.0, 1.0, 0.8921185070897993, 1.0, 1.0, 0.8921185070897993, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7408937352574714, 0.7408937352574714, 0.751972160619555], 
reward next is 0.2480, 
noisyNet noise sample is [array([-0.16878837], dtype=float32), 0.11918919]. 
=============================================
[2019-03-23 21:48:11,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9588772e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:48:11,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4930
[2019-03-23 21:48:11,653] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 53.66666666666666, 1.0, 2.0, 0.3885985542534029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483308.9249505846, 483308.9249505841, 127063.4032977015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6573000.0000, 
sim time next is 6573600.0000, 
raw observation next is [25.6, 52.0, 1.0, 2.0, 0.3755892859523013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469053.9367859674, 469053.9367859674, 125308.3777586518], 
processed observation next is [1.0, 0.08695652173913043, 0.5037037037037038, 0.52, 1.0, 1.0, 0.25665391184797776, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1675192631378455, 0.1675192631378455, 0.24097764953586884], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.34771687], dtype=float32), 0.3028249]. 
=============================================
[2019-03-23 21:48:14,155] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:48:14,160] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:48:14,161] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:48:14,163] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:48:14,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:48:14,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:48:14,167] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:48:14,165] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:48:14,164] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:48:14,171] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:48:14,168] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:48:14,188] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 21:48:14,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 21:48:14,246] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 21:48:14,272] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 21:48:14,291] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 21:49:13,333] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.34378862]
[2019-03-23 21:49:13,333] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.11560137833334, 82.74107418999999, 1.0, 2.0, 0.4151503118003803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508909.6885786331, 508909.6885786331, 130637.7905855933]
[2019-03-23 21:49:13,334] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:49:13,337] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1515309e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.911716740995356
[2019-03-23 21:49:20,305] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.34378862]
[2019-03-23 21:49:20,306] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 74.0, 1.0, 2.0, 0.6425335343544113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732275.178369469, 732275.178369469, 165550.3990918608]
[2019-03-23 21:49:20,307] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:49:20,309] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1515309e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.25748574804649904
[2019-03-23 21:49:40,967] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.34378862]
[2019-03-23 21:49:40,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.3, 53.0, 1.0, 2.0, 0.333497446390577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421795.8533348631, 421795.8533348631, 119788.8613095731]
[2019-03-23 21:49:40,971] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:49:40,973] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1515309e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8710798620382316
[2019-03-23 21:49:54,087] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:49:54,314] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:49:54,540] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:49:54,545] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:49:54,634] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:49:55,651] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1025000, evaluation results [1025000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:50:01,120] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.539406e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:50:01,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7085
[2019-03-23 21:50:01,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 48.5, 1.0, 2.0, 0.3303662240398308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417991.9391431009, 417991.9391431009, 119385.9950891192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6726600.0000, 
sim time next is 6727200.0000, 
raw observation next is [24.86666666666667, 50.0, 1.0, 2.0, 0.3311351454490649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418882.9389094019, 418882.9389094014, 119484.322363319], 
processed observation next is [1.0, 0.8695652173913043, 0.47654320987654336, 0.5, 1.0, 1.0, 0.20373231601079156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14960104961050066, 0.1496010496105005, 0.2297775430063827], 
reward next is 0.7702, 
noisyNet noise sample is [array([-1.5493565], dtype=float32), -0.23197769]. 
=============================================
[2019-03-23 21:50:06,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5279385e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:06,914] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0371
[2019-03-23 21:50:06,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 48.16666666666666, 1.0, 2.0, 0.5283350413775774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622401.9285225354, 622401.9285225354, 147115.5237337783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [31.0, 48.0, 1.0, 2.0, 0.5340531269653118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 627828.1449778436, 627828.1449778432, 147987.744737002], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.48, 1.0, 1.0, 0.4453013416253712, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.224224337492087, 0.22422433749208684, 0.28459181680192697], 
reward next is 0.7154, 
noisyNet noise sample is [array([-0.44467765], dtype=float32), 0.4421501]. 
=============================================
[2019-03-23 21:50:06,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.93396]
 [75.93396]
 [75.93396]
 [75.93396]
 [75.93396]], R is [[75.89002991]
 [75.84822083]
 [75.80843353]
 [75.77050781]
 [75.73432159]].
[2019-03-23 21:50:06,975] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7635184e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:06,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7569
[2019-03-23 21:50:06,989] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1342002.205441603 W.
[2019-03-23 21:50:06,994] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9570506923477301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.262760643503156, 6.9112, 121.9243957398786, 1342002.205441603, 1161974.165536413, 233903.4322440339], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7225200.0000, 
sim time next is 7225800.0000, 
raw observation next is [23.98333333333333, 73.33333333333334, 1.0, 2.0, 0.3545765496168251, 1.0, 1.0, 0.3545765496168251, 1.0, 1.0, 0.5687562022292795, 6.911200000000001, 6.9112, 121.94756008, 1259006.553244371, 1259006.553244371, 277593.3925545536], 
processed observation next is [1.0, 0.6521739130434783, 0.4438271604938271, 0.7333333333333334, 1.0, 1.0, 0.23163874954383942, 1.0, 0.5, 0.23163874954383942, 1.0, 0.5, 0.4609452527865993, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44964519758727534, 0.44964519758727534, 0.5338334472202954], 
reward next is 0.4662, 
noisyNet noise sample is [array([0.9359807], dtype=float32), -1.7035862]. 
=============================================
[2019-03-23 21:50:09,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3972993e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:09,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-23 21:50:09,743] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 56.66666666666666, 1.0, 2.0, 0.4689682229626258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 567319.6217595834, 567319.6217595829, 138379.3205420501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6893400.0000, 
sim time next is 6894000.0000, 
raw observation next is [27.1, 57.0, 1.0, 2.0, 0.4659056999275188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 564178.0391820584, 564178.039182058, 137931.7898609003], 
processed observation next is [0.0, 0.8260869565217391, 0.5592592592592593, 0.57, 1.0, 1.0, 0.36417345229466525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20149215685073515, 0.201492156850735, 0.26525344204019285], 
reward next is 0.7347, 
noisyNet noise sample is [array([-0.48780656], dtype=float32), -1.8150674]. 
=============================================
[2019-03-23 21:50:09,757] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.44791]
 [73.44791]
 [73.44791]
 [73.44791]
 [73.44791]], R is [[73.44816589]
 [73.4475708 ]
 [73.44592285]
 [73.44306183]
 [73.43915558]].
[2019-03-23 21:50:11,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4601137e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:11,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1155
[2019-03-23 21:50:11,595] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 78.0, 1.0, 2.0, 0.4181834921441442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514893.965752678, 514893.9657526775, 131132.5835919751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6921000.0000, 
sim time next is 6921600.0000, 
raw observation next is [22.4, 78.66666666666666, 1.0, 2.0, 0.418301990992712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515085.9484009991, 515085.9484009991, 131150.8046902682], 
processed observation next is [0.0, 0.08695652173913043, 0.38518518518518513, 0.7866666666666666, 1.0, 1.0, 0.30750237022941906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18395926728607112, 0.18395926728607112, 0.2522130859428235], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.13301855], dtype=float32), 0.08594833]. 
=============================================
[2019-03-23 21:50:16,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1758645e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:16,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8399
[2019-03-23 21:50:16,074] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.66666666666667, 1.0, 2.0, 0.6231023053111859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768185.8993674765, 768185.8993674765, 164378.3602155882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7009800.0000, 
sim time next is 7010400.0000, 
raw observation next is [21.5, 84.33333333333334, 1.0, 2.0, 0.5534337162727762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682420.0236321852, 682420.0236321852, 152247.6667799015], 
processed observation next is [1.0, 0.13043478260869565, 0.35185185185185186, 0.8433333333333334, 1.0, 1.0, 0.4683734717533049, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2437214370114947, 0.2437214370114947, 0.29278397457673366], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.04780051], dtype=float32), 1.1946145]. 
=============================================
[2019-03-23 21:50:17,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7169472e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:17,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3495
[2019-03-23 21:50:17,411] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 88.5, 1.0, 2.0, 0.4590480154710156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564565.4628526187, 564565.4628526187, 137145.7977640184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7020600.0000, 
sim time next is 7021200.0000, 
raw observation next is [21.26666666666667, 88.0, 1.0, 2.0, 0.4331538285825101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 532591.7098035072, 532591.7098035068, 133288.2918898822], 
processed observation next is [1.0, 0.2608695652173913, 0.34320987654320995, 0.88, 1.0, 1.0, 0.325183129264893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.190211324929824, 0.19021132492982387, 0.2563236382497735], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.73073816], dtype=float32), -0.2510236]. 
=============================================
[2019-03-23 21:50:19,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.256628e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:50:19,274] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 21:50:19,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1524211.97317673 W.
[2019-03-23 21:50:19,288] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.75, 74.0, 1.0, 2.0, 1.014304778547108, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.523947217964544, 6.9112, 121.9235009685484, 1524211.97317673, 1210437.171880234, 246988.975473304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7036200.0000, 
sim time next is 7036800.0000, 
raw observation next is [24.93333333333334, 73.33333333333334, 1.0, 2.0, 0.3883605798593061, 1.0, 1.0, 0.3883605798593061, 1.0, 1.0, 0.6196372663974062, 6.9112, 6.9112, 121.94756008, 1353603.313214373, 1353603.313214373, 292086.1518324232], 
processed observation next is [1.0, 0.43478260869565216, 0.47901234567901263, 0.7333333333333334, 1.0, 1.0, 0.2718578331658406, 1.0, 0.5, 0.2718578331658406, 1.0, 0.5, 0.5245465829967577, 0.0, 0.0, 0.8096049824067558, 0.48342975471941896, 0.48342975471941896, 0.5617041381392753], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38424996], dtype=float32), -0.12824799]. 
=============================================
[2019-03-23 21:50:20,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.002083e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:50:20,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-23 21:50:20,547] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 85.5, 1.0, 2.0, 0.4112715701869368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 510128.6479314295, 510128.647931429, 130230.5598296082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7104600.0000, 
sim time next is 7105200.0000, 
raw observation next is [20.93333333333333, 85.33333333333334, 1.0, 2.0, 0.399734527495231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496111.1239663675, 496111.1239663675, 128599.9512600095], 
processed observation next is [1.0, 0.21739130434782608, 0.3308641975308641, 0.8533333333333334, 1.0, 1.0, 0.2853982470181321, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17718254427370267, 0.17718254427370267, 0.24730759857694135], 
reward next is 0.7527, 
noisyNet noise sample is [array([-1.1258088], dtype=float32), 0.18147269]. 
=============================================
[2019-03-23 21:50:34,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9403744e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:34,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0603
[2019-03-23 21:50:34,134] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 71.0, 1.0, 2.0, 0.4542785401026995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551429.8563118507, 551429.8563118507, 136220.6820071214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327800.0000, 
sim time next is 7328400.0000, 
raw observation next is [24.33333333333334, 71.66666666666667, 1.0, 2.0, 0.4515727417830693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548662.1811778174, 548662.1811778174, 135831.8067005974], 
processed observation next is [1.0, 0.8260869565217391, 0.4567901234567903, 0.7166666666666667, 1.0, 1.0, 0.34711040688460626, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19595077899207763, 0.19595077899207763, 0.2612150128857642], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.19202365], dtype=float32), 0.009263431]. 
=============================================
[2019-03-23 21:50:39,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3269947e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:39,962] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4597
[2019-03-23 21:50:39,968] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 90.16666666666666, 1.0, 2.0, 0.3835441661470839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477107.5915609535, 477107.5915609531, 126365.3866363147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7419000.0000, 
sim time next is 7419600.0000, 
raw observation next is [20.2, 90.0, 1.0, 2.0, 0.3831032359224726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476581.1530218244, 476581.1530218244, 126304.981134725], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 1.0, 1.0, 0.26559909038389595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17020755465065157, 0.17020755465065157, 0.24289419448985577], 
reward next is 0.7571, 
noisyNet noise sample is [array([1.6760895], dtype=float32), 0.36885408]. 
=============================================
[2019-03-23 21:50:45,856] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 21:50:45,857] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:50:45,857] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:50:45,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:45,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:45,862] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:50:45,864] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:50:45,860] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:50:45,866] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:45,866] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:45,868] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:45,881] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 21:50:45,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 21:50:45,905] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 21:50:45,931] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 21:50:45,979] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 21:50:48,386] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:50:48,387] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.75048907333334, 80.88561747, 1.0, 2.0, 0.5805838127379118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 668529.8427574099, 668529.8427574094, 155105.0631564076]
[2019-03-23 21:50:48,388] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:50:48,390] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5713349069426655
[2019-03-23 21:50:49,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:50:49,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [13.16666666666667, 76.16666666666667, 1.0, 2.0, 0.165122987638961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 212979.2468711003, 212979.2468711003, 70118.94654388045]
[2019-03-23 21:50:49,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:50:49,285] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.44634265228725045
[2019-03-23 21:50:53,226] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:50:53,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.05, 83.0, 1.0, 2.0, 0.2383300481358421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 307422.2399291765, 307422.2399291765, 98978.19383879924]
[2019-03-23 21:50:53,229] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:50:53,232] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3698418897350273
[2019-03-23 21:51:03,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:51:03,879] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.06625048, 97.83736819, 1.0, 2.0, 0.3142206295787552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 397473.9742355771, 397473.9742355766, 117327.2593407111]
[2019-03-23 21:51:03,881] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:51:03,886] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5697410093849149
[2019-03-23 21:51:13,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:51:13,767] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.13333333333333, 80.33333333333334, 1.0, 2.0, 0.4035784281717449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 503845.9621709556, 503845.9621709551, 129202.5203081495]
[2019-03-23 21:51:13,769] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:51:13,771] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.764497084495725
[2019-03-23 21:51:48,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:51:48,206] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 92.0, 1.0, 2.0, 0.5576559495450195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654780.906895364, 654780.906895364, 151834.8531801026]
[2019-03-23 21:51:48,208] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:51:48,210] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3331672011854603
[2019-03-23 21:52:00,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:52:00,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.06326541666667, 69.23948020333333, 1.0, 2.0, 0.7203287791237104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820983.4434058771, 820983.4434058771, 180031.3481075101]
[2019-03-23 21:52:00,961] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:52:00,966] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5913422137967979
[2019-03-23 21:52:19,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.41414085]
[2019-03-23 21:52:19,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.5915134386778493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683586.6440918191, 683586.6440918191, 157082.2443879806]
[2019-03-23 21:52:19,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:52:19,222] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.3631076e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.16382036707783787
[2019-03-23 21:52:26,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:52:26,112] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:52:26,523] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:52:26,556] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:52:26,663] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:52:27,677] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1050000, evaluation results [1050000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:52:29,379] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:29,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:29,420] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 21:52:35,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8138205e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:35,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7197
[2019-03-23 21:52:35,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 73.33333333333333, 1.0, 2.0, 0.3216856189043439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408769.0763851965, 408769.0763851965, 118288.4497030008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7674000.0000, 
sim time next is 7674600.0000, 
raw observation next is [20.25, 73.66666666666667, 1.0, 2.0, 0.3149562796480824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401032.677280709, 401032.677280709, 117439.888872424], 
processed observation next is [1.0, 0.8260869565217391, 0.3055555555555556, 0.7366666666666667, 1.0, 1.0, 0.1844717614858124, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14322595617168177, 0.14322595617168177, 0.22584594013927692], 
reward next is 0.7742, 
noisyNet noise sample is [array([-1.0042365], dtype=float32), -0.11162862]. 
=============================================
[2019-03-23 21:52:35,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7354177e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:35,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2070
[2019-03-23 21:52:35,427] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 78.0, 1.0, 2.0, 0.3163479656018405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402209.4503635289, 402209.4503635289, 117612.6525677301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678800.0000, 
sim time next is 7679400.0000, 
raw observation next is [19.86666666666667, 78.66666666666667, 1.0, 2.0, 0.3188066569046101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405087.1125240113, 405087.1125240109, 117922.4783106525], 
processed observation next is [1.0, 0.9130434782608695, 0.2913580246913582, 0.7866666666666667, 1.0, 1.0, 0.18905554393405963, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14467396875857547, 0.14467396875857533, 0.2267739967512548], 
reward next is 0.7732, 
noisyNet noise sample is [array([-0.5372171], dtype=float32), -0.49614623]. 
=============================================
[2019-03-23 21:52:38,612] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1055727: loss 0.0152
[2019-03-23 21:52:38,615] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1055727: learning rate 0.0010
[2019-03-23 21:52:43,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6849328e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:43,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0778
[2019-03-23 21:52:43,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 67.66666666666667, 1.0, 2.0, 0.4248676909078091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521980.4858177578, 521980.4858177578, 132069.0854877925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7856400.0000, 
sim time next is 7857000.0000, 
raw observation next is [24.1, 68.0, 1.0, 2.0, 0.4244384292127056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521785.3798909966, 521785.3798909961, 132015.4915472099], 
processed observation next is [1.0, 0.9565217391304348, 0.4481481481481482, 0.68, 1.0, 1.0, 0.3148076538246495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18635192138964166, 0.18635192138964146, 0.253875945283096], 
reward next is 0.7461, 
noisyNet noise sample is [array([-0.77589995], dtype=float32), 1.0400485]. 
=============================================
[2019-03-23 21:52:43,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.83183]
 [70.83183]
 [70.83183]
 [70.83183]
 [70.83183]], R is [[70.86963654]
 [70.90695953]
 [70.94343567]
 [70.97924042]
 [71.01464844]].
[2019-03-23 21:52:46,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:46,920] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:46,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 21:52:47,259] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:47,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:47,300] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 21:52:47,832] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:47,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:47,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 21:52:48,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 21:52:48,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 21:52:48,739] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 21:52:48,780] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,781] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 21:52:48,843] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 21:52:48,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 21:52:48,970] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:48,970] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:48,974] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 21:52:49,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:49,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:49,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:49,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:49,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 21:52:49,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 21:52:49,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:49,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:49,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 21:52:49,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:49,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:49,252] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 21:52:49,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:52:49,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:49,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 21:52:50,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1060946: loss 0.0114
[2019-03-23 21:52:50,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1060946: learning rate 0.0010
[2019-03-23 21:52:53,415] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1062440: loss 0.8584
[2019-03-23 21:52:53,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1062441: learning rate 0.0010
[2019-03-23 21:52:53,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0944621e-21 1.0000000e+00 1.7490834e-33 1.4136951e-37 1.0549670e-36], sum to 1.0000
[2019-03-23 21:52:53,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4821
[2019-03-23 21:52:53,628] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 42.0, 1.0, 2.0, 0.3994854187971782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492399.0682072408, 492399.0682072404, 128485.722088697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 64800.0000, 
sim time next is 65400.0000, 
raw observation next is [28.98333333333333, 42.5, 1.0, 2.0, 0.4042214720997148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498155.0731854548, 498155.0731854548, 129151.7478357751], 
processed observation next is [1.0, 0.782608695652174, 0.6290123456790122, 0.425, 1.0, 1.0, 0.29073984773775574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17791252613766242, 0.17791252613766242, 0.24836874583802904], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.617788], dtype=float32), -0.29821697]. 
=============================================
[2019-03-23 21:52:56,096] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1063767: loss 0.0064
[2019-03-23 21:52:56,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1063767: learning rate 0.0010
[2019-03-23 21:52:57,711] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064560: loss 0.9339
[2019-03-23 21:52:57,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064560: learning rate 0.0010
[2019-03-23 21:52:57,992] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064695: loss 1.1775
[2019-03-23 21:52:57,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064696: learning rate 0.0010
[2019-03-23 21:52:58,147] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064768: loss 1.2890
[2019-03-23 21:52:58,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064769: learning rate 0.0010
[2019-03-23 21:52:58,409] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064904: loss 1.1025
[2019-03-23 21:52:58,411] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064904: learning rate 0.0010
[2019-03-23 21:52:58,531] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064954: loss 1.0506
[2019-03-23 21:52:58,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064956: learning rate 0.0010
[2019-03-23 21:52:58,553] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064966: loss 1.0496
[2019-03-23 21:52:58,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064967: learning rate 0.0010
[2019-03-23 21:52:58,605] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064995: loss 0.9634
[2019-03-23 21:52:58,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064995: learning rate 0.0010
[2019-03-23 21:52:58,798] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1065089: loss 0.7013
[2019-03-23 21:52:58,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1065090: learning rate 0.0010
[2019-03-23 21:52:58,956] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1065165: loss 0.5693
[2019-03-23 21:52:58,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1065166: learning rate 0.0010
[2019-03-23 21:52:58,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1065174: loss 0.5765
[2019-03-23 21:52:58,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1065176: learning rate 0.0010
[2019-03-23 21:52:58,983] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065180: loss 0.4755
[2019-03-23 21:52:58,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065180: learning rate 0.0010
[2019-03-23 21:52:59,148] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1065260: loss 0.2548
[2019-03-23 21:52:59,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1065260: learning rate 0.0010
[2019-03-23 21:52:59,353] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1065357: loss 0.0487
[2019-03-23 21:52:59,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1065358: learning rate 0.0010
[2019-03-23 21:53:00,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2749318e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:53:00,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1964
[2019-03-23 21:53:00,483] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.279734927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195000.0000, 
sim time next is 195600.0000, 
raw observation next is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.2582619160811347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729705, 110570.5709980323], 
processed observation next is [0.0, 0.2608695652173913, 0.33950617283950635, 0.6133333333333334, 1.0, 1.0, 0.11697847152516035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11856162702606089, 0.11856162702606089, 0.21263571345775442], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.15802197], dtype=float32), -0.2555926]. 
=============================================
[2019-03-23 21:53:06,873] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1069074: loss 0.0024
[2019-03-23 21:53:06,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1069076: learning rate 0.0010
[2019-03-23 21:53:08,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3393635e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:53:08,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-23 21:53:08,753] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 52.5, 1.0, 2.0, 0.2634414910418191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339820.6988103485, 339820.6988103485, 102688.3589830012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351000.0000, 
sim time next is 351600.0000, 
raw observation next is [21.2, 53.0, 1.0, 2.0, 0.2615382937437919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337365.170336205, 337365.170336205, 101830.890899253], 
processed observation next is [1.0, 0.043478260869565216, 0.34074074074074073, 0.53, 1.0, 1.0, 0.12087892112356179, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12048756083435892, 0.12048756083435892, 0.1958286363447173], 
reward next is 0.8042, 
noisyNet noise sample is [array([0.03305091], dtype=float32), 0.4508855]. 
=============================================
[2019-03-23 21:53:09,231] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1070223: loss 0.0186
[2019-03-23 21:53:09,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1070223: learning rate 0.0010
[2019-03-23 21:53:09,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.888498e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:53:09,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7312
[2019-03-23 21:53:09,324] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 61.5, 1.0, 2.0, 0.2940244767195676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377452.2577115804, 377452.2577115804, 114839.3925971463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 456600.0000, 
sim time next is 457200.0000, 
raw observation next is [21.5, 60.0, 1.0, 2.0, 0.2967693502883728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380780.7892037732, 380780.7892037732, 115177.0153067773], 
processed observation next is [1.0, 0.30434782608695654, 0.35185185185185186, 0.6, 1.0, 1.0, 0.16282065510520574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13599313900134757, 0.13599313900134757, 0.22149426020534096], 
reward next is 0.7785, 
noisyNet noise sample is [array([0.33724016], dtype=float32), 0.2574802]. 
=============================================
[2019-03-23 21:53:11,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3049673e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:53:11,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0026
[2019-03-23 21:53:11,478] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.26666666666667, 36.66666666666667, 1.0, 2.0, 0.4347342156469842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530726.8673165791, 530726.8673165791, 133416.2168742236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 840000.0000, 
sim time next is 840600.0000, 
raw observation next is [31.2, 36.5, 1.0, 2.0, 0.4325094501183941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 528740.574143094, 528740.5741430935, 133111.2850237224], 
processed observation next is [0.0, 0.7391304347826086, 0.7111111111111111, 0.365, 1.0, 1.0, 0.3244160120457073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18883591933681929, 0.18883591933681912, 0.25598324043023535], 
reward next is 0.7440, 
noisyNet noise sample is [array([1.2213211], dtype=float32), -1.9972159]. 
=============================================
[2019-03-23 21:53:12,251] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1071707: loss 0.7646
[2019-03-23 21:53:12,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1071707: learning rate 0.0010
[2019-03-23 21:53:13,823] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072490: loss 0.0385
[2019-03-23 21:53:13,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072490: learning rate 0.0010
[2019-03-23 21:53:14,140] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072649: loss 0.0249
[2019-03-23 21:53:14,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072649: learning rate 0.0010
[2019-03-23 21:53:14,432] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072794: loss 0.0327
[2019-03-23 21:53:14,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072794: learning rate 0.0010
[2019-03-23 21:53:14,438] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072796: loss 0.0320
[2019-03-23 21:53:14,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072796: learning rate 0.0010
[2019-03-23 21:53:14,686] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0422224e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:53:14,690] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072914: loss 0.0002
[2019-03-23 21:53:14,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072914: learning rate 0.0010
[2019-03-23 21:53:14,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1038
[2019-03-23 21:53:14,702] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 66.0, 1.0, 2.0, 0.3020816470514685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388455.2767675213, 388455.2767675213, 115828.9057334496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454800.0000, 
sim time next is 455400.0000, 
raw observation next is [20.6, 64.5, 1.0, 2.0, 0.3006372982534543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386370.5165437894, 386370.5165437894, 115651.3918582249], 
processed observation next is [1.0, 0.2608695652173913, 0.3185185185185186, 0.645, 1.0, 1.0, 0.1674253550636361, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1379894701942105, 0.1379894701942105, 0.22240652280427867], 
reward next is 0.7776, 
noisyNet noise sample is [array([-1.1871357], dtype=float32), 0.3954304]. 
=============================================
[2019-03-23 21:53:14,739] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072942: loss 0.0002
[2019-03-23 21:53:14,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072942: learning rate 0.0010
[2019-03-23 21:53:14,826] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072983: loss 0.0155
[2019-03-23 21:53:14,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072984: learning rate 0.0010
[2019-03-23 21:53:14,865] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1073002: loss 0.0126
[2019-03-23 21:53:14,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1073004: learning rate 0.0010
[2019-03-23 21:53:15,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1073137: loss 0.0554
[2019-03-23 21:53:15,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1073137: loss 0.0357
[2019-03-23 21:53:15,133] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1073137: learning rate 0.0010
[2019-03-23 21:53:15,134] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1073137: learning rate 0.0010
[2019-03-23 21:53:15,232] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1073186: loss 0.0515
[2019-03-23 21:53:15,233] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1073186: learning rate 0.0010
[2019-03-23 21:53:15,450] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1073292: loss 0.0220
[2019-03-23 21:53:15,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1073293: learning rate 0.0010
[2019-03-23 21:53:15,599] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1073362: loss 0.0238
[2019-03-23 21:53:15,606] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1073363: learning rate 0.0010
[2019-03-23 21:53:17,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.019845e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:53:17,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4429
[2019-03-23 21:53:17,534] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.76666666666667, 24.66666666666666, 1.0, 2.0, 0.3657551449050228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461764.0699462777, 461764.0699462777, 124048.5546543594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 495600.0000, 
sim time next is 496200.0000, 
raw observation next is [31.53333333333333, 25.33333333333334, 1.0, 2.0, 0.3660305691725711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 462091.6017912859, 462091.6017912854, 124085.5574284298], 
processed observation next is [1.0, 0.7391304347826086, 0.7234567901234568, 0.2533333333333334, 1.0, 1.0, 0.2452744871102037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16503271492545926, 0.16503271492545907, 0.23862607197774963], 
reward next is 0.7614, 
noisyNet noise sample is [array([-0.16299158], dtype=float32), 0.43657354]. 
=============================================
[2019-03-23 21:53:18,934] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 21:53:18,936] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:53:18,937] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:53:18,938] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:53:18,940] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:53:18,941] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:53:18,942] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:53:18,944] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:53:18,947] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:53:18,946] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:53:18,949] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:53:18,960] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 21:53:18,985] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 21:53:18,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 21:53:19,031] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 21:53:19,063] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 21:53:23,073] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:53:23,074] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.03844218, 16.737273373, 1.0, 2.0, 0.3672064060435409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470744.3556453683, 470744.3556453683, 124282.4689550668]
[2019-03-23 21:53:23,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:53:23,081] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9145502666447497
[2019-03-23 21:54:28,218] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:28,220] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.77134121666667, 95.29724856333334, 1.0, 2.0, 0.6732999399843139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 767356.229953255, 767356.2299532546, 171149.0428302599]
[2019-03-23 21:54:28,221] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:54:28,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05641679737298999
[2019-03-23 21:54:30,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:30,730] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.7112917279905292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 810678.1589225646, 810678.1589225641, 178294.8550885806]
[2019-03-23 21:54:30,731] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:54:30,733] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.12025079173633724
[2019-03-23 21:54:36,085] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:36,086] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333333, 48.0, 1.0, 2.0, 0.9916490582159936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.348636045627955, 6.9112, 121.924417840694, 1401910.525241217, 1177907.157377177, 241181.4562363244]
[2019-03-23 21:54:36,090] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:54:36,095] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.814176787017665
[2019-03-23 21:54:36,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1401910.525241217 W.
[2019-03-23 21:54:47,158] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:47,158] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 92.33333333333333, 1.0, 2.0, 0.543350560561356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636738.0972927844, 636738.0972927844, 149419.930705262]
[2019-03-23 21:54:47,158] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:54:47,160] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9568180305533748
[2019-03-23 21:54:47,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:47,640] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.35, 93.5, 1.0, 2.0, 0.4929781656866896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589030.9114923181, 589030.9114923181, 141834.8073384024]
[2019-03-23 21:54:47,640] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:54:47,642] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2536688556284682
[2019-03-23 21:54:59,209] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:54:59,603] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.4521593]
[2019-03-23 21:54:59,603] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.06666666666667, 88.0, 1.0, 2.0, 0.3876767349954444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484488.8662833261, 484488.8662833261, 126980.6138106732]
[2019-03-23 21:54:59,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:54:59,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4681046e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.09950443629159778
[2019-03-23 21:54:59,660] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:54:59,665] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:54:59,750] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:54:59,909] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:55:00,924] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1075000, evaluation results [1075000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:55:03,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0325484e-21 1.0000000e+00 2.5672694e-33 7.1162416e-37 9.7750303e-37], sum to 1.0000
[2019-03-23 21:55:03,057] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-23 21:55:03,061] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 46.5, 1.0, 2.0, 0.2835979524466106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364564.3301331811, 364564.3301331811, 113569.3236691056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1027800.0000, 
sim time next is 1028400.0000, 
raw observation next is [23.6, 46.66666666666667, 1.0, 2.0, 0.2830587515776933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363916.1781013479, 363916.1781013479, 113504.0363684698], 
processed observation next is [1.0, 0.9130434782608695, 0.4296296296296297, 0.46666666666666673, 1.0, 1.0, 0.1464985137829682, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12997006360762425, 0.12997006360762425, 0.21827699301628806], 
reward next is 0.7817, 
noisyNet noise sample is [array([-1.3403009], dtype=float32), 1.1285462]. 
=============================================
[2019-03-23 21:55:04,464] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1076843: loss 0.3876
[2019-03-23 21:55:04,470] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1076843: learning rate 0.0010
[2019-03-23 21:55:06,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1950984e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:06,978] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5847
[2019-03-23 21:55:06,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1362827.265366263 W.
[2019-03-23 21:55:06,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.35, 33.0, 1.0, 2.0, 0.3845555840997484, 1.0, 1.0, 0.3845555840997484, 1.0, 2.0, 0.6163855001095424, 6.9112, 6.9112, 121.94756008, 1362827.265366263, 1362827.265366263, 290285.6837918746], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 646200.0000, 
sim time next is 646800.0000, 
raw observation next is [32.56666666666667, 32.0, 1.0, 2.0, 0.6752889026232688, 0.0, 1.0, 0.0, 1.0, 2.0, 0.962310705865679, 6.9112, 6.9112, 121.9260426156618, 1523211.548636713, 1523211.548636713, 304531.1047255006], 
processed observation next is [1.0, 0.4782608695652174, 0.7617283950617285, 0.32, 1.0, 1.0, 0.6134391697896057, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9528883823320988, 0.0, 0.0, 0.8094621288201359, 0.5440041245131119, 0.5440041245131119, 0.5856367398567319], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1382431], dtype=float32), 0.47701555]. 
=============================================
[2019-03-23 21:55:07,170] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1078244: loss 0.3142
[2019-03-23 21:55:07,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1078244: learning rate 0.0010
[2019-03-23 21:55:10,137] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1079828: loss 0.0411
[2019-03-23 21:55:10,139] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1079828: learning rate 0.0010
[2019-03-23 21:55:11,336] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080473: loss 0.1083
[2019-03-23 21:55:11,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080473: learning rate 0.0010
[2019-03-23 21:55:11,984] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080799: loss 0.6264
[2019-03-23 21:55:11,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080800: learning rate 0.0010
[2019-03-23 21:55:12,049] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080826: loss 0.6384
[2019-03-23 21:55:12,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080826: learning rate 0.0010
[2019-03-23 21:55:12,149] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080880: loss 0.6915
[2019-03-23 21:55:12,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080880: learning rate 0.0010
[2019-03-23 21:55:12,204] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080905: loss 0.7539
[2019-03-23 21:55:12,205] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080905: loss 0.7213
[2019-03-23 21:55:12,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080906: learning rate 0.0010
[2019-03-23 21:55:12,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080906: learning rate 0.0010
[2019-03-23 21:55:12,318] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080959: loss 0.6113
[2019-03-23 21:55:12,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080961: learning rate 0.0010
[2019-03-23 21:55:12,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1081082: loss 0.5060
[2019-03-23 21:55:12,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1081083: learning rate 0.0010
[2019-03-23 21:55:12,788] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1081186: loss 0.3619
[2019-03-23 21:55:12,790] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1081186: learning rate 0.0010
[2019-03-23 21:55:12,847] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1081215: loss 0.3458
[2019-03-23 21:55:12,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1081216: learning rate 0.0010
[2019-03-23 21:55:13,105] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1081342: loss 0.1492
[2019-03-23 21:55:13,108] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1081342: learning rate 0.0010
[2019-03-23 21:55:13,200] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1081387: loss 0.1113
[2019-03-23 21:55:13,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1081388: learning rate 0.0010
[2019-03-23 21:55:13,235] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1081405: loss 0.0700
[2019-03-23 21:55:13,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1081406: learning rate 0.0010
[2019-03-23 21:55:19,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4907348e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:19,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3578
[2019-03-23 21:55:19,360] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3825008799429552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477215.2071600215, 477215.207160021, 126249.1967258868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [26.8, 47.0, 1.0, 2.0, 0.3811214651478214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475594.6298961016, 475594.6298961016, 126060.9792502758], 
processed observation next is [0.0, 0.782608695652174, 0.5481481481481482, 0.47, 1.0, 1.0, 0.26323983946169216, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16985522496289343, 0.16985522496289343, 0.24242496009668424], 
reward next is 0.7576, 
noisyNet noise sample is [array([-0.04186077], dtype=float32), -0.8402662]. 
=============================================
[2019-03-23 21:55:19,974] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1084741: loss -80.9276
[2019-03-23 21:55:19,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1084741: learning rate 0.0010
[2019-03-23 21:55:20,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.870165e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:20,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5148
[2019-03-23 21:55:20,379] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.31666666666667, 42.33333333333333, 1.0, 2.0, 0.3919907896925347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486647.7062000291, 486647.7062000286, 127517.4837884933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [28.3, 42.0, 1.0, 2.0, 0.388472663818086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482799.8153977332, 482799.8153977332, 127038.805799046], 
processed observation next is [0.0, 0.7391304347826086, 0.6037037037037037, 0.42, 1.0, 1.0, 0.27199126645010235, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17242850549919042, 0.17242850549919042, 0.24430539576739613], 
reward next is 0.7557, 
noisyNet noise sample is [array([1.3102641], dtype=float32), 0.169115]. 
=============================================
[2019-03-23 21:55:20,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.106721e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:20,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1442
[2019-03-23 21:55:20,963] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.45, 47.0, 1.0, 2.0, 0.4374013760614284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535068.6616440361, 535068.6616440361, 133838.4959393693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 916200.0000, 
sim time next is 916800.0000, 
raw observation next is [28.43333333333333, 46.66666666666666, 1.0, 2.0, 0.4357345998095606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533660.5469159127, 533660.5469159122, 133610.9645262995], 
processed observation next is [0.0, 0.6086956521739131, 0.6086419753086418, 0.46666666666666656, 1.0, 1.0, 0.32825547596376264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1905930524699688, 0.19059305246996863, 0.25694416255057595], 
reward next is 0.7431, 
noisyNet noise sample is [array([-1.0440623], dtype=float32), -0.3857294]. 
=============================================
[2019-03-23 21:55:22,829] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1086154: loss 0.0214
[2019-03-23 21:55:22,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1086157: learning rate 0.0010
[2019-03-23 21:55:23,081] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.64218e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:55:23,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3362
[2019-03-23 21:55:23,091] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.0, 1.0, 2.0, 0.2893191973240508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373209.212769734, 373209.212769734, 112660.0829748012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 961200.0000, 
sim time next is 961800.0000, 
raw observation next is [20.95, 58.33333333333334, 1.0, 2.0, 0.3401718822859179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438825.738604555, 438825.738604555, 119563.6406718922], 
processed observation next is [1.0, 0.13043478260869565, 0.33148148148148143, 0.5833333333333335, 1.0, 1.0, 0.21449033605466414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15672347807305537, 0.15672347807305537, 0.2299300782151773], 
reward next is 0.7701, 
noisyNet noise sample is [array([2.3206868], dtype=float32), 0.6182751]. 
=============================================
[2019-03-23 21:55:23,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.541719e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:23,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-23 21:55:23,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.3062173992077812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390908.889819494, 390908.889819494, 116347.4439312228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945000.0000, 
sim time next is 945600.0000, 
raw observation next is [23.7, 49.66666666666667, 1.0, 2.0, 0.302166911303943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386270.7018576023, 386270.7018576023, 115844.8351577635], 
processed observation next is [0.0, 0.9565217391304348, 0.4333333333333333, 0.4966666666666667, 1.0, 1.0, 0.16924632298088454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13795382209200083, 0.13795382209200083, 0.2227785291495452], 
reward next is 0.7772, 
noisyNet noise sample is [array([0.48934495], dtype=float32), -0.16563644]. 
=============================================
[2019-03-23 21:55:24,112] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1911345e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:24,123] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1630
[2019-03-23 21:55:24,132] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 58.83333333333334, 1.0, 2.0, 0.36912866551098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472300.0001678134, 472300.0001678134, 124545.5988515884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 976200.0000, 
sim time next is 976800.0000, 
raw observation next is [22.13333333333333, 58.66666666666667, 1.0, 2.0, 0.3420397225429841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437275.2466354952, 437275.2466354952, 120929.3196598345], 
processed observation next is [1.0, 0.30434782608695654, 0.3753086419753085, 0.5866666666666667, 1.0, 1.0, 0.2167139554083144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15616973094124828, 0.15616973094124828, 0.2325563839612202], 
reward next is 0.7674, 
noisyNet noise sample is [array([-1.4052087], dtype=float32), -1.2581975]. 
=============================================
[2019-03-23 21:55:24,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0434371e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:24,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4465
[2019-03-23 21:55:24,294] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 57.66666666666667, 1.0, 2.0, 0.2951350011505979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380713.2095367122, 380713.2095367122, 113399.8953990322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 960600.0000, 
sim time next is 961200.0000, 
raw observation next is [21.0, 58.0, 1.0, 2.0, 0.2893191973240508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373209.212769734, 373209.212769734, 112660.0829748012], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 0.58, 1.0, 1.0, 0.15395142538577478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1332890045606193, 0.1332890045606193, 0.21665400572077154], 
reward next is 0.7833, 
noisyNet noise sample is [array([0.94412595], dtype=float32), -0.7840756]. 
=============================================
[2019-03-23 21:55:24,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5874602e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:24,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7081
[2019-03-23 21:55:24,523] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 60.16666666666666, 1.0, 2.0, 0.2899905560081428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 374075.447557412, 374075.4475574115, 112672.0874268806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 965400.0000, 
sim time next is 966000.0000, 
raw observation next is [20.6, 60.33333333333334, 1.0, 2.0, 0.2764986519003993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 356667.4197398776, 356667.4197398776, 110583.1499343881], 
processed observation next is [1.0, 0.17391304347826086, 0.3185185185185186, 0.6033333333333334, 1.0, 1.0, 0.13868887130999916, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12738122133567056, 0.12738122133567056, 0.21265990371997712], 
reward next is 0.7873, 
noisyNet noise sample is [array([-0.8925191], dtype=float32), 0.3844868]. 
=============================================
[2019-03-23 21:55:24,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.16422]
 [73.16422]
 [73.16422]
 [73.16422]
 [73.16422]], R is [[73.21990967]
 [73.27103424]
 [73.32094574]
 [73.37010193]
 [73.41741943]].
[2019-03-23 21:55:26,104] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1087774: loss 0.5347
[2019-03-23 21:55:26,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1087775: learning rate 0.0010
[2019-03-23 21:55:27,532] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088481: loss 0.0060
[2019-03-23 21:55:27,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088481: learning rate 0.0010
[2019-03-23 21:55:28,131] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088776: loss 0.0017
[2019-03-23 21:55:28,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088776: learning rate 0.0010
[2019-03-23 21:55:28,240] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088831: loss 0.0415
[2019-03-23 21:55:28,244] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088832: learning rate 0.0010
[2019-03-23 21:55:28,260] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088839: loss 0.0130
[2019-03-23 21:55:28,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088839: learning rate 0.0010
[2019-03-23 21:55:28,404] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088915: loss 0.0005
[2019-03-23 21:55:28,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088915: learning rate 0.0010
[2019-03-23 21:55:28,477] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088942: loss 0.0554
[2019-03-23 21:55:28,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088942: learning rate 0.0010
[2019-03-23 21:55:28,483] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088942: loss 0.0360
[2019-03-23 21:55:28,486] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088944: learning rate 0.0010
[2019-03-23 21:55:28,613] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1089010: loss 0.0219
[2019-03-23 21:55:28,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1089012: learning rate 0.0010
[2019-03-23 21:55:28,974] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1089190: loss 0.0003
[2019-03-23 21:55:28,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1089191: learning rate 0.0010
[2019-03-23 21:55:29,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1089203: loss 0.0000
[2019-03-23 21:55:29,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1089204: learning rate 0.0010
[2019-03-23 21:55:29,090] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1089249: loss 0.0398
[2019-03-23 21:55:29,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1089249: learning rate 0.0010
[2019-03-23 21:55:29,326] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1089364: loss 0.0419
[2019-03-23 21:55:29,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1089365: learning rate 0.0010
[2019-03-23 21:55:29,384] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1089395: loss 0.0512
[2019-03-23 21:55:29,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1089395: learning rate 0.0010
[2019-03-23 21:55:31,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3489525e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:31,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0985
[2019-03-23 21:55:31,486] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 52.0, 1.0, 2.0, 0.3364288838080957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424119.3167940284, 424119.3167940284, 120153.0021993818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1101600.0000, 
sim time next is 1102200.0000, 
raw observation next is [24.55, 53.16666666666667, 1.0, 2.0, 0.338043411997021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426298.4244697891, 426298.4244697895, 120364.864064152], 
processed observation next is [1.0, 0.782608695652174, 0.46481481481481485, 0.5316666666666667, 1.0, 1.0, 0.2119564428535964, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15224943731063895, 0.1522494373106391, 0.23147089243106153], 
reward next is 0.7685, 
noisyNet noise sample is [array([0.18982449], dtype=float32), -0.020735914]. 
=============================================
[2019-03-23 21:55:36,289] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1092783: loss 0.0253
[2019-03-23 21:55:36,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1092783: learning rate 0.0010
[2019-03-23 21:55:38,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.857963e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:38,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-23 21:55:38,114] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3219767765426765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 408646.4778648939, 408646.4778648934, 118322.1290933702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215600.0000, 
sim time next is 1216200.0000, 
raw observation next is [18.13333333333334, 93.16666666666666, 1.0, 2.0, 0.3195399059171826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 405784.6748449201, 405784.6748449201, 118013.8228896223], 
processed observation next is [1.0, 0.043478260869565216, 0.22716049382716075, 0.9316666666666665, 1.0, 1.0, 0.1899284594252174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14492309815890003, 0.14492309815890003, 0.2269496594031198], 
reward next is 0.7731, 
noisyNet noise sample is [array([-0.42493033], dtype=float32), 0.9416327]. 
=============================================
[2019-03-23 21:55:39,096] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1094166: loss -79.0058
[2019-03-23 21:55:39,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1094167: learning rate 0.0010
[2019-03-23 21:55:40,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4737886e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:55:40,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1333
[2019-03-23 21:55:40,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 53.66666666666666, 1.0, 2.0, 0.8493014117077159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260257064402, 1046201.881142384, 1046201.881142384, 209690.6986832805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1269600.0000, 
sim time next is 1270200.0000, 
raw observation next is [26.46666666666667, 53.33333333333334, 1.0, 2.0, 0.8393583154052429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426105058, 1034474.390773375, 1034474.390773376, 207522.2006077039], 
processed observation next is [1.0, 0.6956521739130435, 0.5358024691358025, 0.5333333333333334, 1.0, 1.0, 0.8087598992919558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621287859055, 0.36945513956191967, 0.36945513956192, 0.3990811550148152], 
reward next is 0.6009, 
noisyNet noise sample is [array([0.19062628], dtype=float32), -0.38036492]. 
=============================================
[2019-03-23 21:55:42,376] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1095788: loss -85.2245
[2019-03-23 21:55:42,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1095788: learning rate 0.0010
[2019-03-23 21:55:43,789] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096481: loss -79.7732
[2019-03-23 21:55:43,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096482: learning rate 0.0010
[2019-03-23 21:55:44,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.748317e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:44,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6973
[2019-03-23 21:55:44,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096802: loss -66.6950
[2019-03-23 21:55:44,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096805: learning rate 0.0010
[2019-03-23 21:55:44,445] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.31666666666667, 36.66666666666666, 1.0, 2.0, 0.7382802577890281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920575.1121414388, 920575.1121414388, 186579.9109965861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1342200.0000, 
sim time next is 1342800.0000, 
raw observation next is [29.5, 36.0, 1.0, 2.0, 0.7730733610207785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 963899.3315927201, 963899.3315927201, 193688.1393850568], 
processed observation next is [1.0, 0.5652173913043478, 0.6481481481481481, 0.36, 1.0, 1.0, 0.7298492393104505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34424976128311435, 0.34424976128311435, 0.37247719112510924], 
reward next is 0.6275, 
noisyNet noise sample is [array([-0.02730305], dtype=float32), 0.7296107]. 
=============================================
[2019-03-23 21:55:44,476] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096816: loss -63.5204
[2019-03-23 21:55:44,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096816: learning rate 0.0010
[2019-03-23 21:55:44,619] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096891: loss -79.5033
[2019-03-23 21:55:44,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096891: learning rate 0.0010
[2019-03-23 21:55:44,627] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096893: loss -62.3341
[2019-03-23 21:55:44,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096893: learning rate 0.0010
[2019-03-23 21:55:44,752] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096959: loss -71.4872
[2019-03-23 21:55:44,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096959: learning rate 0.0010
[2019-03-23 21:55:44,896] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1097031: loss -59.7816
[2019-03-23 21:55:44,896] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1097031: loss -42.1398
[2019-03-23 21:55:44,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1097031: learning rate 0.0010
[2019-03-23 21:55:44,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1097034: learning rate 0.0010
[2019-03-23 21:55:45,222] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1097190: loss -59.9249
[2019-03-23 21:55:45,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1097191: learning rate 0.0010
[2019-03-23 21:55:45,253] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1097203: loss -58.4862
[2019-03-23 21:55:45,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097203: learning rate 0.0010
[2019-03-23 21:55:45,318] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1097235: loss -53.1645
[2019-03-23 21:55:45,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1097236: learning rate 0.0010
[2019-03-23 21:55:45,520] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1097336: loss -66.0296
[2019-03-23 21:55:45,522] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1097337: learning rate 0.0010
[2019-03-23 21:55:45,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.553694e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:55:45,618] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0265
[2019-03-23 21:55:45,621] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 67.0, 1.0, 2.0, 0.31087256059901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396080.9093634709, 396080.9093634709, 116927.1945497177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1389000.0000, 
sim time next is 1389600.0000, 
raw observation next is [21.1, 67.0, 1.0, 2.0, 0.3079309893698134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392643.1958353252, 392643.1958353252, 116560.0424598762], 
processed observation next is [0.0, 0.08695652173913043, 0.3370370370370371, 0.67, 1.0, 1.0, 0.17610832067834928, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14022971279833044, 0.14022971279833044, 0.22415392780745425], 
reward next is 0.7758, 
noisyNet noise sample is [array([-1.5759544], dtype=float32), -0.61877143]. 
=============================================
[2019-03-23 21:55:45,667] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1097408: loss -56.6998
[2019-03-23 21:55:45,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1097409: learning rate 0.0010
[2019-03-23 21:55:50,952] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 21:55:50,955] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:55:50,956] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:55:50,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:50,960] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:50,962] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:55:50,963] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:55:50,964] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:50,964] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:55:50,965] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:50,965] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:50,982] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 21:55:51,007] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 21:55:51,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 21:55:51,010] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 21:55:51,050] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 21:56:00,653] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.36680257]
[2019-03-23 21:56:00,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.03185765666667, 75.77713925666666, 1.0, 2.0, 0.4763917472110075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612171.4281605837, 612171.4281605837, 140144.7834423563]
[2019-03-23 21:56:00,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:56:00,659] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.195871e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9096236054790003
[2019-03-23 21:56:11,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.36680257]
[2019-03-23 21:56:11,649] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.623905385, 18.771739629, 1.0, 2.0, 0.3980834179792281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495041.6242628471, 495041.6242628471, 128387.409258852]
[2019-03-23 21:56:11,650] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:56:11,652] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.195871e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4405618899644699
[2019-03-23 21:56:27,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.36680257]
[2019-03-23 21:56:27,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.34169021666666, 62.59120059833334, 1.0, 2.0, 0.5531072133414286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 645567.5420125223, 645567.5420125219, 150914.4669412219]
[2019-03-23 21:56:27,137] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:56:27,140] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.195871e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5287456989855215
[2019-03-23 21:57:01,304] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.36680257]
[2019-03-23 21:57:01,305] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.36913358, 67.73071917666667, 1.0, 2.0, 0.7692069715165996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 912763.4966579372, 912763.4966579367, 191375.0870931979]
[2019-03-23 21:57:01,307] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:57:01,311] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.195871e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4594650265485568
[2019-03-23 21:57:16,391] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.36680257]
[2019-03-23 21:57:16,391] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.66666666666667, 86.66666666666666, 1.0, 2.0, 0.7051666811894376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803693.6197289325, 803693.6197289325, 177124.8717188428]
[2019-03-23 21:57:16,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:57:16,397] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.195871e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.24380276903627773
[2019-03-23 21:57:31,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:57:31,784] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:57:31,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:57:31,869] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:57:31,894] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:57:32,906] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1100000, evaluation results [1100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:57:34,374] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1100767: loss -132.1112
[2019-03-23 21:57:34,376] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1100767: learning rate 0.0010
[2019-03-23 21:57:36,982] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1102127: loss 0.0417
[2019-03-23 21:57:36,985] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1102129: learning rate 0.0010
[2019-03-23 21:57:40,182] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1103787: loss 0.7288
[2019-03-23 21:57:40,186] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1103789: learning rate 0.0010
[2019-03-23 21:57:41,608] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104535: loss 0.0358
[2019-03-23 21:57:41,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104536: learning rate 0.0010
[2019-03-23 21:57:42,048] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104773: loss 0.0057
[2019-03-23 21:57:42,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104774: learning rate 0.0010
[2019-03-23 21:57:42,133] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104823: loss 0.0561
[2019-03-23 21:57:42,134] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104823: learning rate 0.0010
[2019-03-23 21:57:42,277] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104904: loss 0.0104
[2019-03-23 21:57:42,279] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104904: learning rate 0.0010
[2019-03-23 21:57:42,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104907: loss 0.0108
[2019-03-23 21:57:42,288] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104909: learning rate 0.0010
[2019-03-23 21:57:42,310] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104920: loss 0.0021
[2019-03-23 21:57:42,312] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104920: learning rate 0.0010
[2019-03-23 21:57:42,353] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104947: loss 0.0002
[2019-03-23 21:57:42,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104947: learning rate 0.0010
[2019-03-23 21:57:42,440] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104992: loss 0.0092
[2019-03-23 21:57:42,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104993: learning rate 0.0010
[2019-03-23 21:57:42,636] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1105116: loss 0.0138
[2019-03-23 21:57:42,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1105116: learning rate 0.0010
[2019-03-23 21:57:42,659] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1105129: loss 0.0231
[2019-03-23 21:57:42,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1105129: learning rate 0.0010
[2019-03-23 21:57:42,723] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1105166: loss 0.0343
[2019-03-23 21:57:42,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1105170: learning rate 0.0010
[2019-03-23 21:57:42,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.51964e-33 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:57:42,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7756
[2019-03-23 21:57:42,881] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 84.66666666666667, 1.0, 2.0, 0.5253966471744916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668631.0008025742, 668631.0008025742, 147950.0568056036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1672800.0000, 
sim time next is 1673400.0000, 
raw observation next is [18.93333333333333, 84.33333333333333, 1.0, 2.0, 0.5217613258003114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663845.8524393649, 663845.8524393649, 147354.9830178261], 
processed observation next is [1.0, 0.34782608695652173, 0.25679012345679, 0.8433333333333333, 1.0, 1.0, 0.4306682450003707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2370878044426303, 0.2370878044426303, 0.28337496734197326], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.427943], dtype=float32), -3.012355]. 
=============================================
[2019-03-23 21:57:43,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5267978e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:43,153] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2193
[2019-03-23 21:57:43,157] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.41666666666666, 48.5, 1.0, 2.0, 0.5596366888288822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651761.4318267031, 651761.4318267031, 151934.4379746965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2130600.0000, 
sim time next is 2131200.0000, 
raw observation next is [31.5, 48.0, 1.0, 2.0, 0.5575912010167071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649802.0809638724, 649802.0809638724, 151613.3122412155], 
processed observation next is [0.0, 0.6956521739130435, 0.7222222222222222, 0.48, 1.0, 1.0, 0.47332285835322274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23207217177281156, 0.23207217177281156, 0.2915640620023375], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.04268607], dtype=float32), 0.4613153]. 
=============================================
[2019-03-23 21:57:43,203] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1105435: loss 0.0255
[2019-03-23 21:57:43,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1105435: learning rate 0.0010
[2019-03-23 21:57:43,370] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1105519: loss 0.0466
[2019-03-23 21:57:43,373] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1105520: learning rate 0.0010
[2019-03-23 21:57:45,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9278545e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:45,517] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5523
[2019-03-23 21:57:45,520] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.35, 74.5, 1.0, 2.0, 0.4276892134618635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524120.9759386799, 524120.9759386799, 132443.8134072942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1709400.0000, 
sim time next is 1710000.0000, 
raw observation next is [23.3, 75.0, 1.0, 2.0, 0.4270631114828209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523172.8795674276, 523172.8795674276, 132347.8552647204], 
processed observation next is [1.0, 0.8260869565217391, 0.41851851851851857, 0.75, 1.0, 1.0, 0.3179322755747868, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.186847456988367, 0.186847456988367, 0.2545151062783084], 
reward next is 0.7455, 
noisyNet noise sample is [array([2.174469], dtype=float32), 1.4949012]. 
=============================================
[2019-03-23 21:57:45,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.06937]
 [73.06937]
 [73.06937]
 [73.06937]
 [73.06937]], R is [[73.08415985]
 [73.09861755]
 [73.1127243 ]
 [73.12671661]
 [73.14094543]].
[2019-03-23 21:57:48,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.046776e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:57:48,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-23 21:57:48,274] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 72.0, 1.0, 2.0, 0.75216536025585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925277.8708283833, 925277.8708283833, 189077.4284736365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1760400.0000, 
sim time next is 1761000.0000, 
raw observation next is [23.5, 71.66666666666667, 1.0, 2.0, 0.9051495465248885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.996429629283855, 6.9112, 121.9257398520821, 1156200.529293845, 1112555.449741284, 222206.1806991973], 
processed observation next is [1.0, 0.391304347826087, 0.42592592592592593, 0.7166666666666667, 1.0, 1.0, 0.8870827934820101, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008522962928385525, 0.0, 0.8094601187848187, 0.4129287604620875, 0.3973412320504585, 0.42731957826768713], 
reward next is 0.1465, 
noisyNet noise sample is [array([0.3596552], dtype=float32), 0.2445209]. 
=============================================
[2019-03-23 21:57:48,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.17025]
 [67.17025]
 [67.17025]
 [67.17025]
 [67.17025]], R is [[66.64508057]
 [66.61502075]
 [66.58394623]
 [66.55664062]
 [66.52791595]].
[2019-03-23 21:57:50,143] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1108823: loss 0.4561
[2019-03-23 21:57:50,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1108825: learning rate 0.0010
[2019-03-23 21:57:50,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4416525e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:50,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5423
[2019-03-23 21:57:50,494] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.56666666666667, 89.33333333333334, 1.0, 2.0, 0.3177197512744149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403572.800686598, 403572.800686598, 117783.6994603189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1813200.0000, 
sim time next is 1813800.0000, 
raw observation next is [18.53333333333333, 89.66666666666666, 1.0, 2.0, 0.3177670843061814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403609.4578437828, 403609.4578437828, 117789.5302583169], 
processed observation next is [1.0, 1.0, 0.24197530864197525, 0.8966666666666666, 1.0, 1.0, 0.1878179575073588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14414623494420814, 0.14414623494420814, 0.22651832741984018], 
reward next is 0.7735, 
noisyNet noise sample is [array([0.27593327], dtype=float32), -0.2648819]. 
=============================================
[2019-03-23 21:57:51,718] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5875259e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:51,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7621
[2019-03-23 21:57:51,731] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 77.0, 1.0, 2.0, 0.6304784178293111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 786737.9349976546, 786737.9349976542, 165931.385654004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1846800.0000, 
sim time next is 1847400.0000, 
raw observation next is [21.63333333333334, 77.0, 1.0, 2.0, 0.7066689076920537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881283.7390133124, 881283.7390133124, 180309.9592153153], 
processed observation next is [1.0, 0.391304347826087, 0.35679012345679034, 0.77, 1.0, 1.0, 0.6507963186810163, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31474419250475444, 0.31474419250475444, 0.346749921567914], 
reward next is 0.6533, 
noisyNet noise sample is [array([-1.1572742], dtype=float32), 0.53725517]. 
=============================================
[2019-03-23 21:57:51,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.661924e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:57:51,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5249
[2019-03-23 21:57:52,001] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.55, 85.83333333333334, 1.0, 2.0, 0.3654245814759852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461275.5201759666, 461275.5201759666, 124003.0843999078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1835400.0000, 
sim time next is 1836000.0000, 
raw observation next is [19.7, 85.0, 1.0, 2.0, 0.3452736613143095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435603.945951671, 435603.945951671, 121313.5116398421], 
processed observation next is [1.0, 0.2608695652173913, 0.28518518518518515, 0.85, 1.0, 1.0, 0.2205638825170351, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1555728378398825, 0.1555728378398825, 0.23329521469200404], 
reward next is 0.7667, 
noisyNet noise sample is [array([0.75658375], dtype=float32), 1.0583193]. 
=============================================
[2019-03-23 21:57:52,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.117572e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:57:52,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9483
[2019-03-23 21:57:52,017] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.923775]
 [78.923775]
 [78.923775]
 [78.923775]
 [78.923775]], R is [[78.90124512]
 [78.87377167]
 [78.84903717]
 [78.82914734]
 [78.80945587]].
[2019-03-23 21:57:52,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1392842.484051021 W.
[2019-03-23 21:57:52,029] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 80.0, 1.0, 2.0, 0.9809186374515272, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.335637064001537, 6.9112, 121.9242406215906, 1392842.484051021, 1175495.983826833, 239034.0099665901], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1942800.0000, 
sim time next is 1943400.0000, 
raw observation next is [23.85, 78.5, 1.0, 2.0, 0.5383554753842227, 1.0, 1.0, 0.5383554753842227, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257870269841, 1272392.626482244, 1272392.626482243, 249524.4515869336], 
processed observation next is [1.0, 0.4782608695652174, 0.43888888888888894, 0.785, 1.0, 1.0, 0.4504231849812175, 1.0, 0.5, 0.4504231849812175, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094604319771095, 0.4544259380293729, 0.4544259380293725, 0.4798547145902569], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8734472], dtype=float32), 0.32143855]. 
=============================================
[2019-03-23 21:57:52,832] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1110141: loss -107.3866
[2019-03-23 21:57:52,834] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1110141: learning rate 0.0010
[2019-03-23 21:57:56,193] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1111795: loss -173.8219
[2019-03-23 21:57:56,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1111796: learning rate 0.0010
[2019-03-23 21:57:57,689] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112527: loss -125.0845
[2019-03-23 21:57:57,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112527: learning rate 0.0010
[2019-03-23 21:57:58,336] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112787: loss -136.5490
[2019-03-23 21:57:58,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112788: learning rate 0.0010
[2019-03-23 21:57:58,357] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112798: loss -56.4860
[2019-03-23 21:57:58,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112798: learning rate 0.0010
[2019-03-23 21:57:58,456] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112846: loss -62.2710
[2019-03-23 21:57:58,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112846: learning rate 0.0010
[2019-03-23 21:57:58,568] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112902: loss -91.4264
[2019-03-23 21:57:58,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112902: learning rate 0.0010
[2019-03-23 21:57:58,680] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112956: loss -105.5505
[2019-03-23 21:57:58,686] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112956: loss -132.0170
[2019-03-23 21:57:58,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112956: learning rate 0.0010
[2019-03-23 21:57:58,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112957: learning rate 0.0010
[2019-03-23 21:57:58,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0078649e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:58,747] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6627
[2019-03-23 21:57:58,753] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 54.0, 1.0, 2.0, 0.3873916604473849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481776.8396765483, 481776.8396765483, 126895.4593176796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [25.46666666666667, 55.0, 1.0, 2.0, 0.3895451603603229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484669.687639064, 484669.6876390636, 127199.0478734369], 
processed observation next is [1.0, 0.9130434782608695, 0.4987654320987655, 0.55, 1.0, 1.0, 0.2732680480480034, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17309631701395142, 0.17309631701395128, 0.24461355360276327], 
reward next is 0.7554, 
noisyNet noise sample is [array([1.9187276], dtype=float32), -2.2793047]. 
=============================================
[2019-03-23 21:57:58,788] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1113009: loss -45.1250
[2019-03-23 21:57:58,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1113010: learning rate 0.0010
[2019-03-23 21:57:59,005] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1113112: loss -95.6655
[2019-03-23 21:57:59,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1113112: learning rate 0.0010
[2019-03-23 21:57:59,059] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1113139: loss -81.4424
[2019-03-23 21:57:59,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1113142: learning rate 0.0010
[2019-03-23 21:57:59,136] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1113175: loss -98.7216
[2019-03-23 21:57:59,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1113176: learning rate 0.0010
[2019-03-23 21:57:59,603] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113407: loss -85.3538
[2019-03-23 21:57:59,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113408: learning rate 0.0010
[2019-03-23 21:57:59,808] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1113501: loss -148.1479
[2019-03-23 21:57:59,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1113501: learning rate 0.0010
[2019-03-23 21:58:06,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.212806e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:58:06,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-23 21:58:06,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1472479.718022256 W.
[2019-03-23 21:58:06,441] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.13333333333333, 89.66666666666667, 1.0, 2.0, 0.4304671256015719, 1.0, 2.0, 0.4304671256015719, 1.0, 2.0, 0.6853176832932426, 6.9112, 6.9112, 121.94756008, 1472479.718022256, 1472479.718022256, 310685.4907468861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2202600.0000, 
sim time next is 2203200.0000, 
raw observation next is [25.3, 89.0, 1.0, 2.0, 0.7105225084405833, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1524811.562734077, 1524811.562734077, 319146.0345349347], 
processed observation next is [1.0, 0.5217391304347826, 0.49259259259259264, 0.89, 1.0, 1.0, 0.655383938619742, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5445755581193132, 0.5445755581193132, 0.6137423741056436], 
reward next is 0.3863, 
noisyNet noise sample is [array([-0.10312404], dtype=float32), 0.25295636]. 
=============================================
[2019-03-23 21:58:07,036] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1117075: loss -143.4602
[2019-03-23 21:58:07,037] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1117075: learning rate 0.0010
[2019-03-23 21:58:09,340] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1118206: loss 0.0137
[2019-03-23 21:58:09,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1118207: learning rate 0.0010
[2019-03-23 21:58:10,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7394726e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:58:10,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-23 21:58:10,825] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 82.0, 1.0, 2.0, 0.568494461590898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662149.905620034, 662149.905620034, 153417.4456827815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2160000.0000, 
sim time next is 2160600.0000, 
raw observation next is [25.13333333333333, 82.66666666666667, 1.0, 2.0, 0.5697573624843475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663367.0101283867, 663367.0101283867, 153618.3407752422], 
processed observation next is [1.0, 0.0, 0.4864197530864196, 0.8266666666666667, 1.0, 1.0, 0.48780638390993747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23691678933156668, 0.23691678933156668, 0.295419886106235], 
reward next is 0.7046, 
noisyNet noise sample is [array([0.14761399], dtype=float32), -0.71682525]. 
=============================================
[2019-03-23 21:58:12,406] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1119724: loss 0.3288
[2019-03-23 21:58:12,408] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1119726: learning rate 0.0010
[2019-03-23 21:58:14,079] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120537: loss 0.0769
[2019-03-23 21:58:14,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120538: learning rate 0.0010
[2019-03-23 21:58:14,471] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120735: loss 0.0119
[2019-03-23 21:58:14,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120735: learning rate 0.0010
[2019-03-23 21:58:14,528] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120763: loss 0.0231
[2019-03-23 21:58:14,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120763: learning rate 0.0010
[2019-03-23 21:58:14,615] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120805: loss 0.0107
[2019-03-23 21:58:14,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120807: learning rate 0.0010
[2019-03-23 21:58:14,644] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120823: loss 0.0054
[2019-03-23 21:58:14,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120824: learning rate 0.0010
[2019-03-23 21:58:14,761] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120880: loss 0.0012
[2019-03-23 21:58:14,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120882: learning rate 0.0010
[2019-03-23 21:58:14,811] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120909: loss 0.0082
[2019-03-23 21:58:14,812] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120909: learning rate 0.0010
[2019-03-23 21:58:14,876] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120939: loss 0.0012
[2019-03-23 21:58:14,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120940: learning rate 0.0010
[2019-03-23 21:58:15,136] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1121071: loss 0.0479
[2019-03-23 21:58:15,138] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1121073: learning rate 0.0010
[2019-03-23 21:58:15,177] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1121092: loss 0.0507
[2019-03-23 21:58:15,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1121093: learning rate 0.0010
[2019-03-23 21:58:15,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1121144: loss 0.0118
[2019-03-23 21:58:15,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1121145: learning rate 0.0010
[2019-03-23 21:58:15,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3740977e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:58:15,419] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6988
[2019-03-23 21:58:15,423] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.5, 1.0, 2.0, 0.4119282119501079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506299.821431612, 506299.821431612, 130212.8729071048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [20.4, 95.66666666666667, 1.0, 2.0, 0.4124473977187059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506789.5223158078, 506789.5223158078, 130283.1625627234], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9566666666666667, 1.0, 1.0, 0.3005326163317928, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18099625796993135, 0.18099625796993135, 0.2505445433898527], 
reward next is 0.7495, 
noisyNet noise sample is [array([1.3786969], dtype=float32), 0.42657676]. 
=============================================
[2019-03-23 21:58:15,988] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121491: loss 0.0104
[2019-03-23 21:58:15,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121493: learning rate 0.0010
[2019-03-23 21:58:16,089] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1121546: loss 0.0082
[2019-03-23 21:58:16,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1121546: learning rate 0.0010
[2019-03-23 21:58:23,136] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 21:58:23,139] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:58:23,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:58:23,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:58:23,141] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:58:23,141] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:58:23,143] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:58:23,143] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:58:23,143] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:58:23,144] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:58:23,146] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:58:23,157] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 21:58:23,158] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 21:58:23,158] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 21:58:23,232] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 21:58:23,257] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 21:58:25,072] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:58:25,074] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.027733425, 37.6947899, 1.0, 2.0, 0.7365478520227114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 917749.6431348204, 917749.6431348204, 186217.100573906]
[2019-03-23 21:58:25,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:58:25,079] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.15691967089285663
[2019-03-23 21:58:52,014] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:58:52,015] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.56666666666667, 50.33333333333334, 1.0, 2.0, 0.3775644207923067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 468768.213592358, 468768.2135923585, 125524.0540491111]
[2019-03-23 21:58:52,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:58:52,020] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3158742893597175
[2019-03-23 21:59:15,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:15,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.392422395, 64.34632737, 1.0, 2.0, 0.6744824704125058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 768704.629153693, 768704.6291536925, 171366.5862251761]
[2019-03-23 21:59:15,765] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:59:15,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0950707196219569
[2019-03-23 21:59:16,611] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:16,612] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.8, 85.66666666666667, 1.0, 2.0, 0.5770169068023177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 670094.2262702805, 670094.2262702801, 154765.348332384]
[2019-03-23 21:59:16,612] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:59:16,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4825373022813503
[2019-03-23 21:59:20,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:20,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.84682545333333, 105.0578398333333, 1.0, 2.0, 0.546710344524894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661908.2313858705, 661908.2313858705, 150769.5941970216]
[2019-03-23 21:59:20,882] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:59:20,884] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6292935403083149
[2019-03-23 21:59:52,018] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:52,019] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.827313255, 60.227181335, 1.0, 2.0, 0.569389953006429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663157.8716879507, 663157.8716879507, 153566.1538477122]
[2019-03-23 21:59:52,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:59:52,026] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7273716902678975
[2019-03-23 21:59:52,105] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:52,106] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.06666666666667, 78.66666666666667, 1.0, 2.0, 0.446600931601707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 544338.124545585, 544338.1245455845, 135142.6278965734]
[2019-03-23 21:59:52,108] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:59:52,112] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.714334383650263
[2019-03-23 21:59:56,115] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 21:59:56,116] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 94.0, 1.0, 2.0, 0.5740634756023951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668948.1054483472, 668948.1054483472, 154368.4441804836]
[2019-03-23 21:59:56,117] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:59:56,119] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.273074175470595
[2019-03-23 22:00:01,431] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 22:00:01,433] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.45418767333333, 101.9291426, 1.0, 2.0, 0.3969728196831853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491309.3341936296, 491309.3341936296, 128181.0528250172]
[2019-03-23 22:00:01,433] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:00:01,436] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5193905634152134
[2019-03-23 22:00:01,983] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.38840804]
[2019-03-23 22:00:01,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 28.0, 1.0, 2.0, 0.3075237459991058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396698.3644320845, 396698.3644320845, 111447.6207245747]
[2019-03-23 22:00:01,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:00:01,990] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.487814e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9035774317016553
[2019-03-23 22:00:03,679] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:00:04,025] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:00:04,194] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:00:04,240] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:00:04,262] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:00:05,274] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1125000, evaluation results [1125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:00:05,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1125045: loss 0.1381
[2019-03-23 22:00:05,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1125046: learning rate 0.0010
[2019-03-23 22:00:05,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9820028e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:05,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-23 22:00:05,455] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 47.0, 1.0, 2.0, 0.385082724376459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478378.6094021452, 478378.6094021452, 126564.6113445009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2406000.0000, 
sim time next is 2406600.0000, 
raw observation next is [27.05, 48.0, 1.0, 2.0, 0.38504556434815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478308.411445769, 478308.411445769, 126558.959703931], 
processed observation next is [1.0, 0.8695652173913043, 0.5574074074074075, 0.48, 1.0, 1.0, 0.26791138612875004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17082443265920322, 0.17082443265920322, 0.24338261481525192], 
reward next is 0.7566, 
noisyNet noise sample is [array([-0.1525914], dtype=float32), 1.0139813]. 
=============================================
[2019-03-23 22:00:07,750] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1126275: loss -157.7963
[2019-03-23 22:00:07,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1126275: learning rate 0.0010
[2019-03-23 22:00:08,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7825402e-24 1.0000000e+00 1.3110702e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:08,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7085
[2019-03-23 22:00:08,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1497660.284432607 W.
[2019-03-23 22:00:08,689] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.55, 23.16666666666667, 1.0, 2.0, 0.4169389060501081, 1.0, 2.0, 0.4169389060501081, 1.0, 1.0, 0.6722565615884036, 6.911199999999999, 6.9112, 121.94756008, 1497660.284432607, 1497660.284432608, 304227.0101269185], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [34.5, 23.33333333333334, 1.0, 2.0, 0.6072770921986215, 1.0, 2.0, 0.6072770921986215, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1465705.435326434, 1465705.435326434, 274028.1088529711], 
processed observation next is [1.0, 0.6521739130434783, 0.8333333333333334, 0.2333333333333334, 1.0, 1.0, 0.5324727288078827, 1.0, 1.0, 0.5324727288078827, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5234662269022978, 0.5234662269022978, 0.5269771324095598], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6609453], dtype=float32), 0.7457712]. 
=============================================
[2019-03-23 22:00:10,717] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1127815: loss -140.8638
[2019-03-23 22:00:10,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1127815: learning rate 0.0010
[2019-03-23 22:00:12,226] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128574: loss -112.9173
[2019-03-23 22:00:12,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128574: learning rate 0.0010
[2019-03-23 22:00:12,614] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128777: loss -106.9862
[2019-03-23 22:00:12,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128779: learning rate 0.0010
[2019-03-23 22:00:12,658] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128803: loss -133.5908
[2019-03-23 22:00:12,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128803: learning rate 0.0010
[2019-03-23 22:00:12,664] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128804: loss -69.2980
[2019-03-23 22:00:12,666] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128804: learning rate 0.0010
[2019-03-23 22:00:12,717] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128828: loss -96.7450
[2019-03-23 22:00:12,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128829: learning rate 0.0010
[2019-03-23 22:00:12,850] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128899: loss -116.5884
[2019-03-23 22:00:12,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128899: learning rate 0.0010
[2019-03-23 22:00:12,884] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128911: loss -67.8806
[2019-03-23 22:00:12,887] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128911: learning rate 0.0010
[2019-03-23 22:00:12,984] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128968: loss -73.3771
[2019-03-23 22:00:12,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128969: learning rate 0.0010
[2019-03-23 22:00:13,133] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129044: loss -56.9710
[2019-03-23 22:00:13,135] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129044: learning rate 0.0010
[2019-03-23 22:00:13,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1129049: loss -61.0784
[2019-03-23 22:00:13,147] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1129051: learning rate 0.0010
[2019-03-23 22:00:13,370] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1129162: loss -111.2215
[2019-03-23 22:00:13,376] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1129165: learning rate 0.0010
[2019-03-23 22:00:14,167] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1129579: loss -117.2934
[2019-03-23 22:00:14,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1129579: learning rate 0.0010
[2019-03-23 22:00:14,220] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129604: loss -96.2281
[2019-03-23 22:00:14,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129604: learning rate 0.0010
[2019-03-23 22:00:15,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.3980327e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:15,333] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4574
[2019-03-23 22:00:15,339] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 95.33333333333334, 1.0, 2.0, 0.4613519655701986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 560278.8899265549, 560278.8899265544, 137292.8598242629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [21.16666666666667, 94.16666666666666, 1.0, 2.0, 0.457409307275566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556452.3208468297, 556452.3208468297, 136727.7618162233], 
processed observation next is [0.0, 0.30434782608695654, 0.33950617283950635, 0.9416666666666665, 1.0, 1.0, 0.3540586991375786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1987329717310106, 0.1987329717310106, 0.2629380034927371], 
reward next is 0.7371, 
noisyNet noise sample is [array([1.1349627], dtype=float32), -2.4106421]. 
=============================================
[2019-03-23 22:00:16,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9009786e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:16,957] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4138
[2019-03-23 22:00:16,964] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 73.16666666666667, 1.0, 2.0, 0.6015049652638198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693937.5681185263, 693937.5681185263, 158746.8356159151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2650200.0000, 
sim time next is 2650800.0000, 
raw observation next is [27.0, 72.33333333333334, 1.0, 2.0, 0.5944041002331497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687625.5525615747, 687625.5525615747, 157610.5884213279], 
processed observation next is [0.0, 0.6956521739130435, 0.5555555555555556, 0.7233333333333334, 1.0, 1.0, 0.5171477383727973, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2455805544862767, 0.2455805544862767, 0.3030972854256306], 
reward next is 0.6969, 
noisyNet noise sample is [array([-0.42605552], dtype=float32), 0.722701]. 
=============================================
[2019-03-23 22:00:21,138] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1133133: loss -69.9106
[2019-03-23 22:00:21,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1133133: learning rate 0.0010
[2019-03-23 22:00:23,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1134295: loss 0.0296
[2019-03-23 22:00:23,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1134296: learning rate 0.0010
[2019-03-23 22:00:24,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.3601674e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:24,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-23 22:00:24,637] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333333, 1.0, 2.0, 0.5891486727694739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690245.2612547632, 690245.2612547632, 157098.0718686426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2785800.0000, 
sim time next is 2786400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.5970381451777205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698698.5881410378, 698698.5881410378, 158424.7525219857], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.89, 1.0, 1.0, 0.5202835061639529, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24953521005037066, 0.24953521005037066, 0.3046629856192033], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.33751827], dtype=float32), 0.24811734]. 
=============================================
[2019-03-23 22:00:26,429] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1135721: loss 0.4659
[2019-03-23 22:00:26,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1135721: learning rate 0.0010
[2019-03-23 22:00:28,170] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136583: loss 0.4422
[2019-03-23 22:00:28,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136583: learning rate 0.0010
[2019-03-23 22:00:28,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136706: loss 0.2088
[2019-03-23 22:00:28,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136707: learning rate 0.0010
[2019-03-23 22:00:28,552] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136762: loss 0.1306
[2019-03-23 22:00:28,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136764: learning rate 0.0010
[2019-03-23 22:00:28,676] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136823: loss 0.1057
[2019-03-23 22:00:28,677] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136823: learning rate 0.0010
[2019-03-23 22:00:28,681] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136823: loss 0.1097
[2019-03-23 22:00:28,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136823: learning rate 0.0010
[2019-03-23 22:00:28,742] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136852: loss 0.0720
[2019-03-23 22:00:28,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136853: learning rate 0.0010
[2019-03-23 22:00:28,759] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136861: loss 0.0742
[2019-03-23 22:00:28,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136863: learning rate 0.0010
[2019-03-23 22:00:28,860] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136912: loss 0.0492
[2019-03-23 22:00:28,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136912: learning rate 0.0010
[2019-03-23 22:00:29,044] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1137000: loss 0.0245
[2019-03-23 22:00:29,045] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1137000: learning rate 0.0010
[2019-03-23 22:00:29,279] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137119: loss 0.0261
[2019-03-23 22:00:29,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137120: learning rate 0.0010
[2019-03-23 22:00:29,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1137134: loss 0.0319
[2019-03-23 22:00:29,313] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1137135: learning rate 0.0010
[2019-03-23 22:00:30,228] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1137580: loss 0.0080
[2019-03-23 22:00:30,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1137580: learning rate 0.0010
[2019-03-23 22:00:30,265] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137599: loss 0.0075
[2019-03-23 22:00:30,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137599: learning rate 0.0010
[2019-03-23 22:00:31,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1211556e-24 1.0000000e+00 2.7715483e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:31,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7393
[2019-03-23 22:00:31,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1874152.94574354 W.
[2019-03-23 22:00:31,319] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.18333333333333, 87.5, 1.0, 2.0, 0.547764320603677, 1.0, 2.0, 0.547764320603677, 1.0, 2.0, 0.8720586378395397, 6.911199999999999, 6.9112, 121.94756008, 1874152.94574354, 1874152.94574354, 367650.3657850793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2904600.0000, 
sim time next is 2905200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5230006847172031, 1.0, 2.0, 0.5230006847172031, 1.0, 2.0, 0.8326341230129568, 6.9112, 6.9112, 121.94756008, 1789340.338097973, 1789340.338097973, 355021.4620190144], 
processed observation next is [1.0, 0.6521739130434783, 0.5185185185185185, 0.89, 1.0, 1.0, 0.4321436722823846, 1.0, 1.0, 0.4321436722823846, 1.0, 1.0, 0.790792653766196, 0.0, 0.0, 0.8096049824067558, 0.639050120749276, 0.639050120749276, 0.6827335808057969], 
reward next is 0.3173, 
noisyNet noise sample is [array([1.0738916], dtype=float32), -0.08545126]. 
=============================================
[2019-03-23 22:00:31,726] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2038812e-21 1.0000000e+00 3.6034552e-33 2.3418328e-36 1.1785322e-35], sum to 1.0000
[2019-03-23 22:00:31,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9869
[2019-03-23 22:00:31,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1687900.791222122 W.
[2019-03-23 22:00:31,749] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 82.33333333333334, 1.0, 2.0, 0.8534080825193044, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1687900.791222122, 1687900.791222122, 347092.4429137694], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2910000.0000, 
sim time next is 2910600.0000, 
raw observation next is [27.75, 81.5, 1.0, 2.0, 0.781365014483824, 1.0, 1.0, 0.781365014483824, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1782180.698495659, 1782180.69849566, 336114.8380074435], 
processed observation next is [1.0, 0.6956521739130435, 0.5833333333333334, 0.815, 1.0, 1.0, 0.7397202553378857, 1.0, 0.5, 0.7397202553378857, 0.0, 0.5, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.6364931066055926, 0.6364931066055929, 0.6463746884758529], 
reward next is 0.3536, 
noisyNet noise sample is [array([-0.16377321], dtype=float32), 0.13940085]. 
=============================================
[2019-03-23 22:00:32,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4653564e-22 1.0000000e+00 6.1343092e-35 0.0000000e+00 4.1989449e-38], sum to 1.0000
[2019-03-23 22:00:32,506] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 22:00:32,510] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 86.33333333333334, 1.0, 2.0, 0.6625041960020781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755046.3201919816, 755046.3201919816, 169165.7056526192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2924400.0000, 
sim time next is 2925000.0000, 
raw observation next is [26.0, 87.0, 1.0, 2.0, 0.668007872418223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761321.8944806884, 761321.8944806884, 170174.7753135026], 
processed observation next is [1.0, 0.8695652173913043, 0.5185185185185185, 0.87, 1.0, 1.0, 0.6047712766883607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27190067660024586, 0.27190067660024586, 0.3272591832951973], 
reward next is 0.6727, 
noisyNet noise sample is [array([1.561238], dtype=float32), -2.5078347]. 
=============================================
[2019-03-23 22:00:32,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[48.312336]
 [48.312336]
 [48.312336]
 [48.312336]
 [48.312336]], R is [[48.50195694]
 [48.69161987]
 [48.88364792]
 [49.07215881]
 [49.25684738]].
[2019-03-23 22:00:35,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.600569e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:00:35,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-23 22:00:35,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666666, 87.33333333333333, 1.0, 2.0, 0.8190852415208293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933608.1308864435, 933608.1308864435, 199908.2563580476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2965800.0000, 
sim time next is 2966400.0000, 
raw observation next is [25.5, 86.0, 1.0, 2.0, 0.7667353336988039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875966.1327951702, 875966.1327951702, 189265.5532478711], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 0.86, 1.0, 1.0, 0.7223039686890522, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3128450474268465, 0.3128450474268465, 0.3639722177843675], 
reward next is 0.6360, 
noisyNet noise sample is [array([-0.8219278], dtype=float32), -1.2004024]. 
=============================================
[2019-03-23 22:00:37,234] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1141005: loss 1.1400
[2019-03-23 22:00:37,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1141006: learning rate 0.0010
[2019-03-23 22:00:39,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1142345: loss -149.7193
[2019-03-23 22:00:39,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1142345: learning rate 0.0010
[2019-03-23 22:00:41,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0803516e-19 1.0000000e+00 3.7081323e-29 5.0668975e-33 1.6141629e-31], sum to 1.0000
[2019-03-23 22:00:41,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8933
[2019-03-23 22:00:41,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1756798.405685273 W.
[2019-03-23 22:00:41,382] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 86.0, 1.0, 2.0, 0.7702475381103795, 1.0, 2.0, 0.7702475381103795, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1756798.405685273, 1756798.405685273, 331615.100085161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3085200.0000, 
sim time next is 3085800.0000, 
raw observation next is [28.5, 84.16666666666667, 1.0, 2.0, 0.4488279975949235, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7145487894785125, 6.911199999999999, 6.9112, 121.9260426156618, 1023224.284303509, 1023224.284303509, 239653.9360576277], 
processed observation next is [1.0, 0.7391304347826086, 0.6111111111111112, 0.8416666666666667, 1.0, 1.0, 0.3438428542796709, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6431859868481407, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36543724439411035, 0.36543724439411035, 0.46087295395697636], 
reward next is 0.5391, 
noisyNet noise sample is [array([0.8527296], dtype=float32), -1.1497017]. 
=============================================
[2019-03-23 22:00:42,886] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1143774: loss -99.8492
[2019-03-23 22:00:42,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1143774: learning rate 0.0010
[2019-03-23 22:00:44,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144589: loss -179.8109
[2019-03-23 22:00:44,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144590: learning rate 0.0010
[2019-03-23 22:00:44,813] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144719: loss -104.5085
[2019-03-23 22:00:44,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144719: learning rate 0.0010
[2019-03-23 22:00:44,966] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144790: loss -59.9006
[2019-03-23 22:00:44,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144791: learning rate 0.0010
[2019-03-23 22:00:45,066] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144844: loss -47.9044
[2019-03-23 22:00:45,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144846: learning rate 0.0010
[2019-03-23 22:00:45,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144859: loss -103.6134
[2019-03-23 22:00:45,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144859: learning rate 0.0010
[2019-03-23 22:00:45,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.770654e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:00:45,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9351
[2019-03-23 22:00:45,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1507702.486229379 W.
[2019-03-23 22:00:45,185] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.0, 36.0, 1.0, 2.0, 0.6566782646348408, 1.0, 2.0, 0.6566782646348408, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1507702.486229379, 1507702.486229379, 288601.0977199296], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3157200.0000, 
sim time next is 3157800.0000, 
raw observation next is [34.05, 35.16666666666666, 1.0, 2.0, 0.5783744050367658, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9228437429477574, 6.9112, 6.9112, 121.9260426156618, 1344177.550676413, 1344177.550676413, 285111.0531909754], 
processed observation next is [1.0, 0.5652173913043478, 0.8166666666666665, 0.35166666666666657, 1.0, 1.0, 0.4980647679009117, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9035546786846967, 0.0, 0.0, 0.8094621288201359, 0.4800634109558618, 0.4800634109558618, 0.5482904869057219], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9692567], dtype=float32), -0.6575499]. 
=============================================
[2019-03-23 22:00:45,227] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144919: loss -142.4681
[2019-03-23 22:00:45,230] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144921: learning rate 0.0010
[2019-03-23 22:00:45,262] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144934: loss -65.9645
[2019-03-23 22:00:45,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144934: learning rate 0.0010
[2019-03-23 22:00:45,268] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144937: loss -38.8043
[2019-03-23 22:00:45,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144937: learning rate 0.0010
[2019-03-23 22:00:45,300] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144952: loss -42.0442
[2019-03-23 22:00:45,304] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144952: learning rate 0.0010
[2019-03-23 22:00:45,525] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145057: loss -94.9443
[2019-03-23 22:00:45,528] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145057: learning rate 0.0010
[2019-03-23 22:00:45,598] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1145099: loss -58.4570
[2019-03-23 22:00:45,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1145099: learning rate 0.0010
[2019-03-23 22:00:46,579] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145580: loss -62.9332
[2019-03-23 22:00:46,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145581: learning rate 0.0010
[2019-03-23 22:00:46,607] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1145587: loss -54.2751
[2019-03-23 22:00:46,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1145587: learning rate 0.0010
[2019-03-23 22:00:49,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.588565e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:00:49,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 22:00:49,623] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 46.33333333333334, 1.0, 2.0, 0.5258961550290514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622309.786574726, 622309.786574726, 146833.7960976989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3244200.0000, 
sim time next is 3244800.0000, 
raw observation next is [31.0, 46.66666666666667, 1.0, 2.0, 0.5278734388203734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 623874.1454339726, 623874.145433973, 147122.249193127], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.46666666666666673, 1.0, 1.0, 0.437944570024254, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22281219479784736, 0.22281219479784753, 0.282927402294475], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.7385779], dtype=float32), 0.923101]. 
=============================================
[2019-03-23 22:00:50,050] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5860767e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:00:50,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8496
[2019-03-23 22:00:50,065] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 81.83333333333334, 1.0, 2.0, 0.4704696278954424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569015.9565080705, 569015.9565080705, 138604.382886995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3217800.0000, 
sim time next is 3218400.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4702360725328094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 568628.3304964154, 568628.3304964158, 138565.3699262459], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.83, 1.0, 1.0, 0.369328657777154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20308154660586264, 0.2030815466058628, 0.2664718652427806], 
reward next is 0.7335, 
noisyNet noise sample is [array([-1.3028483], dtype=float32), 0.85302407]. 
=============================================
[2019-03-23 22:00:53,836] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1149149: loss -128.9922
[2019-03-23 22:00:53,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1149149: learning rate 0.0010
[2019-03-23 22:00:55,575] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 22:00:55,576] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:00:55,576] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:00:55,576] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:55,578] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:55,578] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:00:55,578] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:00:55,579] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:55,579] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:00:55,582] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:55,583] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:55,601] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 22:00:55,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 22:00:55,659] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 22:00:55,681] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 22:00:55,703] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 22:01:12,984] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:01:12,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.05, 25.0, 1.0, 2.0, 0.4650930378340023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580120.6342267911, 580120.6342267911, 138246.8405545363]
[2019-03-23 22:01:12,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:01:12,988] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.147276042590747
[2019-03-23 22:02:05,156] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:02:05,158] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.3, 85.0, 1.0, 2.0, 0.7360319343837549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838890.6631617954, 838890.6631617954, 183079.3868782075]
[2019-03-23 22:02:05,158] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:02:05,161] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.17664167370795614
[2019-03-23 22:02:10,089] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:02:10,090] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.75, 50.33333333333334, 1.0, 2.0, 0.9700315367324251, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1821029.964431474, 1821029.964431474, 372518.942371638]
[2019-03-23 22:02:10,091] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:02:10,094] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.366869206861262
[2019-03-23 22:02:10,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1821029.964431474 W.
[2019-03-23 22:02:14,419] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:02:14,420] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.86666666666667, 71.33333333333333, 1.0, 2.0, 0.504630883591448, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8106919645094444, 6.9112, 6.9112, 121.9260426156205, 1199010.078490934, 1199010.078490934, 257396.3866383496]
[2019-03-23 22:02:14,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:02:14,424] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5388979440288812
[2019-03-23 22:02:20,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:02:20,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.8573310313200186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 989170.1747584257, 989170.1747584257, 208702.1503966927]
[2019-03-23 22:02:20,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:02:20,731] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3110960823372467
[2019-03-23 22:02:25,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.56598896]
[2019-03-23 22:02:25,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.50448994833333, 87.90399067166668, 1.0, 2.0, 0.5655154644529722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656881.322551753, 656881.322551753, 152838.0303776726]
[2019-03-23 22:02:25,658] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:02:25,661] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.009283e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8565039212346423
[2019-03-23 22:02:35,901] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:02:36,247] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:02:36,380] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:02:36,464] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:02:36,623] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:02:37,639] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1150000, evaluation results [1150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:02:38,221] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1150307: loss 0.0022
[2019-03-23 22:02:38,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1150307: learning rate 0.0010
[2019-03-23 22:02:38,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4392875e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:38,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8675
[2019-03-23 22:02:38,270] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 81.5, 1.0, 2.0, 0.662468390644415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755005.4932539201, 755005.4932539201, 169160.0456915159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3357000.0000, 
sim time next is 3357600.0000, 
raw observation next is [26.93333333333334, 82.33333333333334, 1.0, 2.0, 0.6836873258452459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779200.6936159167, 779200.6936159167, 173078.1763028464], 
processed observation next is [0.0, 0.8695652173913043, 0.5530864197530867, 0.8233333333333335, 1.0, 1.0, 0.6234372926729118, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2782859620056845, 0.2782859620056845, 0.3328426467362431], 
reward next is 0.6672, 
noisyNet noise sample is [array([0.9419506], dtype=float32), -0.116300635]. 
=============================================
[2019-03-23 22:02:38,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.185743e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:02:38,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1103
[2019-03-23 22:02:38,735] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 92.33333333333334, 1.0, 2.0, 0.6555784458812256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747149.2974928991, 747149.2974928991, 167903.2377241526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3369000.0000, 
sim time next is 3369600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6644290147809884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757241.0914997566, 757241.0914997566, 169518.0692989845], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.600510731882129, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27044324696419875, 0.27044324696419875, 0.32599628711343176], 
reward next is 0.6740, 
noisyNet noise sample is [array([0.77421105], dtype=float32), -0.7066968]. 
=============================================
[2019-03-23 22:02:40,715] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1151602: loss 0.0801
[2019-03-23 22:02:40,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1151603: learning rate 0.0010
[2019-03-23 22:02:42,607] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152593: loss 0.5297
[2019-03-23 22:02:42,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152593: learning rate 0.0010
[2019-03-23 22:02:42,748] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152666: loss 0.3446
[2019-03-23 22:02:42,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152667: learning rate 0.0010
[2019-03-23 22:02:42,941] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152759: loss 0.1567
[2019-03-23 22:02:42,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152759: learning rate 0.0010
[2019-03-23 22:02:43,036] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152810: loss 0.1208
[2019-03-23 22:02:43,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152810: learning rate 0.0010
[2019-03-23 22:02:43,064] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152823: loss 0.1104
[2019-03-23 22:02:43,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152823: learning rate 0.0010
[2019-03-23 22:02:43,077] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152828: loss 0.1151
[2019-03-23 22:02:43,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152828: learning rate 0.0010
[2019-03-23 22:02:43,173] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152879: loss 0.0558
[2019-03-23 22:02:43,175] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152879: learning rate 0.0010
[2019-03-23 22:02:43,178] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152881: loss 0.0842
[2019-03-23 22:02:43,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152881: learning rate 0.0010
[2019-03-23 22:02:43,278] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152928: loss 0.0404
[2019-03-23 22:02:43,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152929: learning rate 0.0010
[2019-03-23 22:02:43,475] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153035: loss 0.0019
[2019-03-23 22:02:43,477] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153035: learning rate 0.0010
[2019-03-23 22:02:43,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1153140: loss 0.0000
[2019-03-23 22:02:43,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1153140: learning rate 0.0010
[2019-03-23 22:02:44,687] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153659: loss 0.0458
[2019-03-23 22:02:44,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153663: learning rate 0.0010
[2019-03-23 22:02:44,711] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1153670: loss 0.0274
[2019-03-23 22:02:44,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1153671: learning rate 0.0010
[2019-03-23 22:02:45,094] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1797707e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:45,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0204
[2019-03-23 22:02:45,105] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 90.0, 1.0, 2.0, 0.8016126170749517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 913680.6463050997, 913680.6463050992, 196267.8996272738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3483000.0000, 
sim time next is 3483600.0000, 
raw observation next is [25.33333333333334, 88.66666666666666, 1.0, 2.0, 0.7526443272227301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 857835.1947618364, 857835.1947618369, 186344.2423820634], 
processed observation next is [1.0, 0.30434782608695654, 0.49382716049382736, 0.8866666666666666, 1.0, 1.0, 0.7055289609794406, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3063697124149416, 0.30636971241494176, 0.35835431227319886], 
reward next is 0.6416, 
noisyNet noise sample is [array([-1.5560907], dtype=float32), -0.47290328]. 
=============================================
[2019-03-23 22:02:47,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8185136e-21 1.0000000e+00 2.8222072e-34 9.2146526e-37 1.9771730e-36], sum to 1.0000
[2019-03-23 22:02:47,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4160
[2019-03-23 22:02:47,067] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.5251337787343447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622716.8799743211, 622716.8799743211, 146761.8334709533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3625200.0000, 
sim time next is 3625800.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.5273703891640582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 624215.6525176283, 624215.6525176278, 147078.2825135923], 
processed observation next is [1.0, 1.0, 0.4444444444444444, 0.85, 1.0, 1.0, 0.43734570138578355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22293416161343868, 0.22293416161343851, 0.28284285098767753], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.73629075], dtype=float32), -0.1947104]. 
=============================================
[2019-03-23 22:02:47,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8402446e-21 1.0000000e+00 8.5266935e-34 1.0320709e-36 1.1437937e-36], sum to 1.0000
[2019-03-23 22:02:47,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3125
[2019-03-23 22:02:47,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1550515.911384391 W.
[2019-03-23 22:02:47,116] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666667, 73.0, 1.0, 2.0, 0.4532572852870829, 1.0, 1.0, 0.4532572852870829, 1.0, 2.0, 0.7216003597362596, 6.911199999999999, 6.9112, 121.94756008, 1550515.911384391, 1550515.911384392, 321196.9201437155], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3500400.0000, 
sim time next is 3501000.0000, 
raw observation next is [28.5, 74.5, 1.0, 2.0, 0.4202614570461209, 1.0, 2.0, 0.4202614570461209, 1.0, 2.0, 0.6690699265775442, 6.911199999999999, 6.9112, 121.94756008, 1437536.883026418, 1437536.883026419, 306071.4887621146], 
processed observation next is [1.0, 0.5217391304347826, 0.6111111111111112, 0.745, 1.0, 1.0, 0.30983506791204873, 1.0, 1.0, 0.30983506791204873, 1.0, 1.0, 0.5863374082219301, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5134060296522922, 0.5134060296522925, 0.5885990168502204], 
reward next is 0.4114, 
noisyNet noise sample is [array([-1.6775612], dtype=float32), 0.7943027]. 
=============================================
[2019-03-23 22:02:47,135] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[47.268124]
 [47.268124]
 [47.268124]
 [47.268124]
 [47.268124]], R is [[47.20684814]
 [46.73477936]
 [46.26743317]
 [46.1452446 ]
 [45.68379211]].
[2019-03-23 22:02:48,887] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.170219e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:02:48,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7478
[2019-03-23 22:02:48,898] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 93.66666666666667, 1.0, 2.0, 0.5806608267564172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688696.6442537673, 688696.6442537673, 155991.3025331475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3568800.0000, 
sim time next is 3569400.0000, 
raw observation next is [22.45, 93.5, 1.0, 2.0, 0.5779806286761224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688138.9564953335, 688138.9564953335, 155635.2423156492], 
processed observation next is [1.0, 0.30434782608695654, 0.387037037037037, 0.935, 1.0, 1.0, 0.49759598651919335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24576391303404765, 0.24576391303404765, 0.29929854291471], 
reward next is 0.7007, 
noisyNet noise sample is [array([0.7101617], dtype=float32), 1.2396942]. 
=============================================
[2019-03-23 22:02:51,457] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1157111: loss 0.2785
[2019-03-23 22:02:51,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1157111: learning rate 0.0010
[2019-03-23 22:02:52,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.191279e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:02:52,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5375
[2019-03-23 22:02:52,517] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5746921947565826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666982.761805297, 666982.761805297, 154354.0973528546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3630000.0000, 
sim time next is 3630600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5758509349146168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668323.7175208752, 668323.7175208752, 154549.5225962038], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.49506063680311524, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23868704197174112, 0.23868704197174112, 0.297210620377315], 
reward next is 0.7028, 
noisyNet noise sample is [array([1.6416479], dtype=float32), -1.515802]. 
=============================================
[2019-03-23 22:02:54,060] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1158381: loss -142.5409
[2019-03-23 22:02:54,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1158382: learning rate 0.0010
[2019-03-23 22:02:56,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9779364e-24 1.0000000e+00 7.0007315e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:56,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5684
[2019-03-23 22:02:56,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1571094.033142976 W.
[2019-03-23 22:02:56,422] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333333, 92.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.68667018144748, 6.9112, 121.9230466153868, 1571094.033142976, 1173993.747400829, 246208.7693687774], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3676200.0000, 
sim time next is 3676800.0000, 
raw observation next is [24.66666666666666, 91.33333333333334, 1.0, 2.0, 0.4366597594536418, 1.0, 1.0, 0.4366597594536418, 1.0, 1.0, 0.6951765580657423, 6.9112, 6.9112, 121.94756008, 1493683.23965746, 1493683.23965746, 313513.283879901], 
processed observation next is [1.0, 0.5652173913043478, 0.4691358024691356, 0.9133333333333334, 1.0, 1.0, 0.3293568564924308, 1.0, 0.5, 0.3293568564924308, 1.0, 0.5, 0.6189706975821778, 0.0, 0.0, 0.8096049824067558, 0.5334582998776642, 0.5334582998776642, 0.6029101613075019], 
reward next is 0.3971, 
noisyNet noise sample is [array([-0.19122784], dtype=float32), -0.5132875]. 
=============================================
[2019-03-23 22:02:56,677] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1159655: loss -101.7245
[2019-03-23 22:02:56,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1159655: learning rate 0.0010
[2019-03-23 22:02:57,419] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1341496e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:57,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0406
[2019-03-23 22:02:57,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 99.66666666666667, 1.0, 2.0, 0.5148839940511472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632071.5619682093, 632071.5619682089, 145830.7366114861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4162800.0000, 
sim time next is 4163400.0000, 
raw observation next is [19.95, 99.5, 1.0, 2.0, 0.5149247527170431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632461.3365437427, 632461.3365437427, 145846.359955911], 
processed observation next is [1.0, 0.17391304347826086, 0.2944444444444444, 0.995, 1.0, 1.0, 0.42252946752028936, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2258790487656224, 0.2258790487656224, 0.2804737691459827], 
reward next is 0.7195, 
noisyNet noise sample is [array([1.7930201], dtype=float32), -0.9103359]. 
=============================================
[2019-03-23 22:02:58,533] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160561: loss -107.2945
[2019-03-23 22:02:58,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160562: learning rate 0.0010
[2019-03-23 22:02:58,938] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160759: loss -164.7958
[2019-03-23 22:02:58,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160759: learning rate 0.0010
[2019-03-23 22:02:58,988] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160790: loss -138.9998
[2019-03-23 22:02:58,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160790: loss -125.1543
[2019-03-23 22:02:58,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160790: learning rate 0.0010
[2019-03-23 22:02:58,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160790: learning rate 0.0010
[2019-03-23 22:02:59,043] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160815: loss -97.6469
[2019-03-23 22:02:59,050] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160816: learning rate 0.0010
[2019-03-23 22:02:59,067] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160823: loss -92.5433
[2019-03-23 22:02:59,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160823: learning rate 0.0010
[2019-03-23 22:02:59,209] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160893: loss -110.1291
[2019-03-23 22:02:59,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160893: learning rate 0.0010
[2019-03-23 22:02:59,227] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160901: loss -88.8993
[2019-03-23 22:02:59,229] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160901: learning rate 0.0010
[2019-03-23 22:02:59,249] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160909: loss -86.4714
[2019-03-23 22:02:59,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160911: learning rate 0.0010
[2019-03-23 22:02:59,359] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160965: loss -82.7231
[2019-03-23 22:02:59,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160968: learning rate 0.0010
[2019-03-23 22:02:59,571] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1161069: loss -71.4675
[2019-03-23 22:02:59,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1161069: learning rate 0.0010
[2019-03-23 22:03:00,654] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1161601: loss -50.8056
[2019-03-23 22:03:00,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1161601: learning rate 0.0010
[2019-03-23 22:03:00,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161727: loss -56.5494
[2019-03-23 22:03:00,908] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161727: learning rate 0.0010
[2019-03-23 22:03:01,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4260202e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:03:01,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4860
[2019-03-23 22:03:01,480] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 71.0, 1.0, 2.0, 0.6793277239709042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774229.5316514578, 774229.5316514578, 172267.9735396351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796800.0000, 
sim time next is 3797400.0000, 
raw observation next is [28.75, 74.0, 1.0, 2.0, 0.6954518332404814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792615.6738845436, 792615.6738845436, 175286.0002065618], 
processed observation next is [1.0, 0.9565217391304348, 0.6203703703703703, 0.74, 1.0, 1.0, 0.6374426586196207, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.283077026387337, 0.283077026387337, 0.33708846193569575], 
reward next is 0.6629, 
noisyNet noise sample is [array([-0.4699628], dtype=float32), 0.0566478]. 
=============================================
[2019-03-23 22:03:02,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.152892e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:03:02,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5827
[2019-03-23 22:03:02,130] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 72.83333333333334, 1.0, 2.0, 0.5411766033706233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636827.3106506363, 636827.3106506363, 149174.4675696952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3822600.0000, 
sim time next is 3823200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5459941427748867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641448.976324186, 641448.9763241864, 149921.424855238], 
processed observation next is [0.0, 0.2608695652173913, 0.5185185185185185, 0.74, 1.0, 1.0, 0.45951683663676984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2290889201157807, 0.22908892011578086, 0.28831043241391924], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.4154936], dtype=float32), 1.3427774]. 
=============================================
[2019-03-23 22:03:08,215] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1165299: loss -153.0119
[2019-03-23 22:03:08,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1165299: learning rate 0.0010
[2019-03-23 22:03:10,307] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1166327: loss 0.0756
[2019-03-23 22:03:10,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1166327: learning rate 0.0010
[2019-03-23 22:03:12,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.337479e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:03:12,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1103
[2019-03-23 22:03:12,947] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 96.0, 1.0, 2.0, 0.6673389756573027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760559.1813245405, 760559.1813245405, 170051.3085762393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4051200.0000, 
sim time next is 4051800.0000, 
raw observation next is [24.5, 97.0, 1.0, 2.0, 0.6667487148035003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759886.133817924, 759886.133817924, 169942.7606816873], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.97, 1.0, 1.0, 0.6032722795279765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27138790493497283, 0.27138790493497283, 0.3268130013109371], 
reward next is 0.6732, 
noisyNet noise sample is [array([1.2175051], dtype=float32), -1.6696085]. 
=============================================
[2019-03-23 22:03:13,160] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1167727: loss 0.3029
[2019-03-23 22:03:13,163] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1167728: learning rate 0.0010
[2019-03-23 22:03:13,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7995255e-20 1.0000000e+00 1.9237810e-31 3.7027656e-34 2.3700728e-34], sum to 1.0000
[2019-03-23 22:03:13,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-23 22:03:13,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1708495.948504372 W.
[2019-03-23 22:03:13,738] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333333, 80.66666666666667, 1.0, 2.0, 0.8714509323179233, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1708495.948504372, 1708495.948504372, 350868.3108987067], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4025400.0000, 
sim time next is 4026000.0000, 
raw observation next is [26.26666666666667, 82.33333333333334, 1.0, 2.0, 0.9271254876818609, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1772049.11464466, 1772049.114644661, 362887.1438408665], 
processed observation next is [1.0, 0.6086956521739131, 0.5283950617283951, 0.8233333333333335, 1.0, 1.0, 0.9132446281926915, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6328746838016642, 0.6328746838016647, 0.6978598920016663], 
reward next is 0.3021, 
noisyNet noise sample is [array([0.33812398], dtype=float32), -0.42034712]. 
=============================================
[2019-03-23 22:03:13,747] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[43.98563]
 [43.98563]
 [43.98563]
 [43.98563]
 [43.98563]], R is [[43.84791183]
 [43.73468399]
 [43.29733658]
 [42.86436462]
 [42.71415329]].
[2019-03-23 22:03:14,773] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168511: loss 1.0867
[2019-03-23 22:03:14,775] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168511: learning rate 0.0010
[2019-03-23 22:03:15,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168699: loss 0.7248
[2019-03-23 22:03:15,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168699: learning rate 0.0010
[2019-03-23 22:03:15,216] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168735: loss 0.6960
[2019-03-23 22:03:15,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168735: learning rate 0.0010
[2019-03-23 22:03:15,236] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168745: loss 0.5707
[2019-03-23 22:03:15,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168746: learning rate 0.0010
[2019-03-23 22:03:15,327] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168786: loss 0.5690
[2019-03-23 22:03:15,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168787: learning rate 0.0010
[2019-03-23 22:03:15,410] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168829: loss 0.4409
[2019-03-23 22:03:15,411] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168829: learning rate 0.0010
[2019-03-23 22:03:15,479] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168856: loss 0.3768
[2019-03-23 22:03:15,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168858: learning rate 0.0010
[2019-03-23 22:03:15,536] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168887: loss 0.3034
[2019-03-23 22:03:15,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168888: learning rate 0.0010
[2019-03-23 22:03:15,592] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168912: loss 0.2850
[2019-03-23 22:03:15,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168912: learning rate 0.0010
[2019-03-23 22:03:15,859] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1169047: loss 0.0861
[2019-03-23 22:03:15,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1169047: learning rate 0.0010
[2019-03-23 22:03:16,042] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1169139: loss 0.0257
[2019-03-23 22:03:16,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1169139: learning rate 0.0010
[2019-03-23 22:03:17,084] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1169657: loss 0.0213
[2019-03-23 22:03:17,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1169657: learning rate 0.0010
[2019-03-23 22:03:17,506] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169860: loss 0.0006
[2019-03-23 22:03:17,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169860: learning rate 0.0010
[2019-03-23 22:03:18,224] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3383103e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:03:18,229] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3838
[2019-03-23 22:03:18,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1652536.25360786 W.
[2019-03-23 22:03:18,241] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.1, 31.0, 1.0, 2.0, 0.4767080281990775, 1.0, 2.0, 0.4767080281990775, 1.0, 2.0, 0.7598686947193241, 6.9112, 6.9112, 121.94756008, 1652536.25360786, 1652536.25360786, 332407.9533584813], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [34.08333333333334, 31.5, 1.0, 2.0, 0.4548778734157234, 1.0, 2.0, 0.4548778734157234, 1.0, 2.0, 0.7249535122750542, 6.9112, 6.9112, 121.94756008, 1574977.982230954, 1574977.982230954, 322057.6972254344], 
processed observation next is [1.0, 0.6521739130434783, 0.8179012345679015, 0.315, 1.0, 1.0, 0.35104508739967066, 1.0, 1.0, 0.35104508739967066, 1.0, 1.0, 0.6561918903438176, 0.0, 0.0, 0.8096049824067558, 0.562492136511055, 0.562492136511055, 0.6193417254335277], 
reward next is 0.3807, 
noisyNet noise sample is [array([0.73308617], dtype=float32), 1.052226]. 
=============================================
[2019-03-23 22:03:18,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0017156e-23 1.0000000e+00 1.8379432e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:03:18,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4773
[2019-03-23 22:03:18,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1974961.869080436 W.
[2019-03-23 22:03:18,506] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 69.0, 1.0, 2.0, 0.8657930991305481, 1.0, 1.0, 0.8657930991305481, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9259537048487, 1974961.869080436, 1974961.869080437, 371690.8823688011], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4113000.0000, 
sim time next is 4113600.0000, 
raw observation next is [28.93333333333333, 70.66666666666666, 1.0, 2.0, 0.8877540703095337, 1.0, 2.0, 0.8877540703095337, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425885506, 2025113.870374265, 2025113.870374265, 381350.0292845191], 
processed observation next is [1.0, 0.6086956521739131, 0.6271604938271603, 0.7066666666666666, 1.0, 1.0, 0.8663738932256353, 1.0, 1.0, 0.8663738932256353, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621286401458, 0.7232549537050946, 0.7232549537050946, 0.7333654409317675], 
reward next is 0.2666, 
noisyNet noise sample is [array([-0.6606585], dtype=float32), -0.08928332]. 
=============================================
[2019-03-23 22:03:23,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5538617e-21 1.0000000e+00 2.0293573e-35 0.0000000e+00 6.3439163e-37], sum to 1.0000
[2019-03-23 22:03:23,263] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4425
[2019-03-23 22:03:23,269] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.33333333333334, 27.33333333333333, 1.0, 2.0, 0.4164800195346542, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 508105.2393425407, 508105.2393425402, 130760.1227747225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4209600.0000, 
sim time next is 4210200.0000, 
raw observation next is [34.25, 29.0, 1.0, 2.0, 0.4137568809681574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503366.7294137212, 503366.7294137212, 130329.7503081316], 
processed observation next is [1.0, 0.7391304347826086, 0.8240740740740741, 0.29, 1.0, 1.0, 0.3020915249620922, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17977383193347185, 0.17977383193347185, 0.25063413520794536], 
reward next is 0.7494, 
noisyNet noise sample is [array([-1.6260408], dtype=float32), 0.55761904]. 
=============================================
[2019-03-23 22:03:24,074] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1173073: loss 0.5250
[2019-03-23 22:03:24,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1173073: learning rate 0.0010
[2019-03-23 22:03:26,586] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1174274: loss -178.6878
[2019-03-23 22:03:26,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1174274: learning rate 0.0010
[2019-03-23 22:03:28,079] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:03:28,081] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:03:28,082] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:03:28,083] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:03:28,083] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:03:28,083] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:03:28,084] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:03:28,085] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:03:28,085] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:03:28,086] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:03:28,087] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:03:28,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 22:03:28,126] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 22:03:28,127] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 22:03:28,188] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 22:03:28,214] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 22:03:35,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:03:35,954] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.58618921, 14.66603519333333, 1.0, 2.0, 0.8576932576467263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.923773624320972, 6.9112, 121.9259220582301, 1105513.340420111, 1099074.527316528, 212241.7932815089]
[2019-03-23 22:03:35,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:03:35,959] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.5058867032393628
[2019-03-23 22:03:42,903] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:03:42,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.649590145, 46.89727604, 1.0, 2.0, 0.3071719165389596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 396244.3954920229, 396244.3954920224, 111670.0626687877]
[2019-03-23 22:03:42,907] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:03:42,910] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.1627828045532811
[2019-03-23 22:03:47,384] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:03:47,385] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.193521445, 91.128716585, 1.0, 2.0, 0.3083772480695129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392120.6826150883, 392120.6826150883, 116610.3673327452]
[2019-03-23 22:03:47,386] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:03:47,392] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.06138962930205816
[2019-03-23 22:03:55,681] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:03:55,682] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.70522871666667, 86.46324591666666, 1.0, 2.0, 0.3806898812975169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471703.9612668306, 471703.9612668306, 125931.4673151946]
[2019-03-23 22:03:55,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:03:55,686] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.3044444569409004
[2019-03-23 22:04:17,071] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:04:17,072] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.08333333333333, 80.83333333333333, 1.0, 2.0, 0.7891645376198291, 1.0, 1.0, 0.7891645376198291, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9257285963919, 1799988.212667327, 1799988.212667327, 339297.2156591828]
[2019-03-23 22:04:17,073] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:04:17,078] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.049821931304791955
[2019-03-23 22:04:17,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1799988.212667327 W.
[2019-03-23 22:05:06,719] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.71293736]
[2019-03-23 22:05:06,720] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.07500543666666, 79.36641126833332, 1.0, 2.0, 0.4221656483780862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520384.8096993727, 520384.8096993727, 131721.3556894445]
[2019-03-23 22:05:06,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:05:06,723] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1440828e-20 1.0000000e+00 3.6414158e-32 4.6856447e-35 1.2788900e-34], sampled 0.18883147253055566
[2019-03-23 22:05:08,769] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:05:09,090] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:05:09,138] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:05:09,145] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:05:09,296] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:05:10,310] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1175000, evaluation results [1175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:05:11,914] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1175829: loss -119.2166
[2019-03-23 22:05:11,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1175830: learning rate 0.0010
[2019-03-23 22:05:13,317] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176559: loss -133.4723
[2019-03-23 22:05:13,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176559: learning rate 0.0010
[2019-03-23 22:05:13,495] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176649: loss -132.6429
[2019-03-23 22:05:13,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176649: learning rate 0.0010
[2019-03-23 22:05:13,771] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176799: loss -119.0099
[2019-03-23 22:05:13,778] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176799: learning rate 0.0010
[2019-03-23 22:05:13,784] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176802: loss -135.2385
[2019-03-23 22:05:13,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176803: learning rate 0.0010
[2019-03-23 22:05:13,808] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176814: loss -127.7838
[2019-03-23 22:05:13,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176814: learning rate 0.0010
[2019-03-23 22:05:13,842] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176833: loss -107.7768
[2019-03-23 22:05:13,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176833: learning rate 0.0010
[2019-03-23 22:05:13,911] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176868: loss -99.5700
[2019-03-23 22:05:13,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176868: learning rate 0.0010
[2019-03-23 22:05:13,931] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176881: loss -133.4545
[2019-03-23 22:05:13,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176883: learning rate 0.0010
[2019-03-23 22:05:13,976] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176903: loss -108.1528
[2019-03-23 22:05:13,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176904: learning rate 0.0010
[2019-03-23 22:05:14,031] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176929: loss -135.8537
[2019-03-23 22:05:14,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176929: learning rate 0.0010
[2019-03-23 22:05:14,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1177009: loss -66.4389
[2019-03-23 22:05:14,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1177010: learning rate 0.0010
[2019-03-23 22:05:14,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.17150902e-19 1.00000000e+00 6.88966290e-32 1.11852226e-35
 2.64496417e-35], sum to 1.0000
[2019-03-23 22:05:14,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9459
[2019-03-23 22:05:14,923] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.06666666666667, 52.33333333333334, 1.0, 2.0, 0.616846782750919, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702987.3754652587, 702987.3754652587, 161000.4038373338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4382400.0000, 
sim time next is 4383000.0000, 
raw observation next is [31.8, 54.0, 1.0, 2.0, 0.6120392894670379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697506.0392171474, 697506.0392171474, 160162.1839846743], 
processed observation next is [1.0, 0.7391304347826086, 0.7333333333333334, 0.54, 1.0, 1.0, 0.5381420112702832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2491092997204098, 0.2491092997204098, 0.3080041999705275], 
reward next is 0.6920, 
noisyNet noise sample is [array([-0.7220558], dtype=float32), 0.2417505]. 
=============================================
[2019-03-23 22:05:14,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[44.23988]
 [44.23988]
 [44.23988]
 [44.23988]
 [44.23988]], R is [[44.48948288]
 [44.73497391]
 [44.86598969]
 [44.57725143]
 [44.29354095]].
[2019-03-23 22:05:15,403] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1177637: loss -83.8066
[2019-03-23 22:05:15,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1177638: learning rate 0.0010
[2019-03-23 22:05:15,767] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177826: loss -105.5092
[2019-03-23 22:05:15,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177827: learning rate 0.0010
[2019-03-23 22:05:20,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.702774e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:05:20,644] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5416
[2019-03-23 22:05:20,648] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7072838569960311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806107.879373672, 806107.879373672, 177527.620172185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485600.0000, 
sim time next is 4486200.0000, 
raw observation next is [26.73333333333333, 84.33333333333333, 1.0, 2.0, 0.6878113538315278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783903.2653246428, 783903.2653246428, 173849.0769777434], 
processed observation next is [0.0, 0.9565217391304348, 0.545679012345679, 0.8433333333333333, 1.0, 1.0, 0.6283468497994379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2799654519016581, 0.2799654519016581, 0.3343251480341219], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.36968026], dtype=float32), 2.0308821]. 
=============================================
[2019-03-23 22:05:22,123] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1181169: loss 0.5808
[2019-03-23 22:05:22,125] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1181170: learning rate 0.0010
[2019-03-23 22:05:24,518] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1182345: loss 0.0043
[2019-03-23 22:05:24,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1182345: learning rate 0.0010
[2019-03-23 22:05:25,239] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0348047e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:25,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4294
[2019-03-23 22:05:25,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1578862.209292539 W.
[2019-03-23 22:05:25,257] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.7578758259532594, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1578862.209292539, 1578862.20929254, 328014.435087329], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4614000.0000, 
sim time next is 4614600.0000, 
raw observation next is [26.0, 80.66666666666667, 1.0, 2.0, 0.6836891414469289, 1.0, 1.0, 0.6836891414469289, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1559198.450620959, 1559198.450620959, 298035.7900348324], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.8066666666666668, 1.0, 1.0, 0.6234394541034868, 1.0, 0.5, 0.6234394541034868, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5568565895074854, 0.5568565895074854, 0.5731457500669853], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1004633], dtype=float32), -0.14106122]. 
=============================================
[2019-03-23 22:05:27,662] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1183866: loss 0.0282
[2019-03-23 22:05:27,663] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1183866: learning rate 0.0010
[2019-03-23 22:05:28,897] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184472: loss 0.5125
[2019-03-23 22:05:28,899] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184472: learning rate 0.0010
[2019-03-23 22:05:29,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4685920e-21 1.0000000e+00 2.8684569e-33 8.5819267e-37 4.1823876e-36], sum to 1.0000
[2019-03-23 22:05:29,214] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3279
[2019-03-23 22:05:29,219] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6798404523414978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 774814.183313291, 774814.1833132906, 172364.0833811841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4646400.0000, 
sim time next is 4647000.0000, 
raw observation next is [27.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6928696638352028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789671.2252089819, 789671.2252089819, 174799.2757235329], 
processed observation next is [1.0, 0.782608695652174, 0.5617283950617282, 0.8316666666666666, 1.0, 1.0, 0.6343686474228604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2820254375746364, 0.2820254375746364, 0.33615245331448634], 
reward next is 0.6638, 
noisyNet noise sample is [array([-1.2821269], dtype=float32), 1.0750223]. 
=============================================
[2019-03-23 22:05:29,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[45.785168]
 [45.785168]
 [45.785168]
 [45.785168]
 [45.785168]], R is [[45.99116516]
 [46.19978333]
 [46.40608978]
 [46.60950851]
 [46.81149673]].
[2019-03-23 22:05:29,311] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184665: loss 0.4649
[2019-03-23 22:05:29,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184666: learning rate 0.0010
[2019-03-23 22:05:29,514] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184768: loss 0.2362
[2019-03-23 22:05:29,517] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184768: learning rate 0.0010
[2019-03-23 22:05:29,583] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184802: loss 0.1784
[2019-03-23 22:05:29,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184803: learning rate 0.0010
[2019-03-23 22:05:29,616] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184819: loss 0.1450
[2019-03-23 22:05:29,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184819: learning rate 0.0010
[2019-03-23 22:05:29,677] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184847: loss 0.1391
[2019-03-23 22:05:29,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184847: learning rate 0.0010
[2019-03-23 22:05:29,702] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184860: loss 0.0834
[2019-03-23 22:05:29,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184860: learning rate 0.0010
[2019-03-23 22:05:29,765] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184889: loss 0.0926
[2019-03-23 22:05:29,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184893: learning rate 0.0010
[2019-03-23 22:05:29,825] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184918: loss 0.0622
[2019-03-23 22:05:29,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184918: learning rate 0.0010
[2019-03-23 22:05:29,920] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184964: loss 0.0202
[2019-03-23 22:05:29,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184964: learning rate 0.0010
[2019-03-23 22:05:29,956] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184988: loss 0.0118
[2019-03-23 22:05:29,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184989: learning rate 0.0010
[2019-03-23 22:05:30,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.856968e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:05:30,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4371
[2019-03-23 22:05:30,120] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.724836188387455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 826123.4611044952, 826123.4611044952, 180901.0190813387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4658400.0000, 
sim time next is 4659000.0000, 
raw observation next is [25.93333333333333, 93.16666666666667, 1.0, 2.0, 0.7198819902489384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820473.9502301267, 820473.9502301267, 179943.0692521453], 
processed observation next is [1.0, 0.9565217391304348, 0.5160493827160493, 0.9316666666666668, 1.0, 1.0, 0.6665261788677838, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29302641079647385, 0.29302641079647385, 0.3460443639464333], 
reward next is 0.6540, 
noisyNet noise sample is [array([1.9287461], dtype=float32), 1.0285062]. 
=============================================
[2019-03-23 22:05:30,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.87262]
 [64.87262]
 [64.87262]
 [64.87262]
 [64.87262]], R is [[64.87783813]
 [64.88117218]
 [64.88485718]
 [64.88896179]
 [64.89348602]].
[2019-03-23 22:05:31,595] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1185785: loss 0.0028
[2019-03-23 22:05:31,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1185785: learning rate 0.0010
[2019-03-23 22:05:31,736] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185854: loss 0.0030
[2019-03-23 22:05:31,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185854: learning rate 0.0010
[2019-03-23 22:05:38,436] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1189139: loss 0.9459
[2019-03-23 22:05:38,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1189139: learning rate 0.0010
[2019-03-23 22:05:39,157] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2852584e-23 1.0000000e+00 1.1050056e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:39,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7670
[2019-03-23 22:05:39,169] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 89.5, 1.0, 2.0, 0.6781405491867231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 772875.8268973255, 772875.826897325, 172045.9025064698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5268600.0000, 
sim time next is 5269200.0000, 
raw observation next is [25.73333333333333, 89.33333333333333, 1.0, 2.0, 0.6752255690308232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769551.9604307952, 769551.9604307952, 171505.7347562688], 
processed observation next is [1.0, 1.0, 0.5086419753086419, 0.8933333333333333, 1.0, 1.0, 0.6133637726557419, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2748399858681411, 0.2748399858681411, 0.3298187206851323], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.2304068], dtype=float32), -0.13887256]. 
=============================================
[2019-03-23 22:05:40,903] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1190345: loss 0.6866
[2019-03-23 22:05:40,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1190345: learning rate 0.0010
[2019-03-23 22:05:44,050] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1191875: loss 0.1625
[2019-03-23 22:05:44,052] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1191875: learning rate 0.0010
[2019-03-23 22:05:45,113] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192400: loss 0.5864
[2019-03-23 22:05:45,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192401: learning rate 0.0010
[2019-03-23 22:05:45,511] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192595: loss 0.7151
[2019-03-23 22:05:45,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192596: learning rate 0.0010
[2019-03-23 22:05:45,747] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192710: loss 0.7610
[2019-03-23 22:05:45,751] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192710: learning rate 0.0010
[2019-03-23 22:05:45,824] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192752: loss 0.7442
[2019-03-23 22:05:45,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192753: learning rate 0.0010
[2019-03-23 22:05:45,906] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192791: loss 0.5728
[2019-03-23 22:05:45,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192792: learning rate 0.0010
[2019-03-23 22:05:45,933] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192803: loss 0.5375
[2019-03-23 22:05:45,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192803: learning rate 0.0010
[2019-03-23 22:05:45,993] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192834: loss 0.6329
[2019-03-23 22:05:45,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192835: learning rate 0.0010
[2019-03-23 22:05:46,091] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192882: loss 0.4254
[2019-03-23 22:05:46,093] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192882: learning rate 0.0010
[2019-03-23 22:05:46,101] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192884: loss 0.5764
[2019-03-23 22:05:46,103] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192884: learning rate 0.0010
[2019-03-23 22:05:46,282] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192972: loss 0.3434
[2019-03-23 22:05:46,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192972: learning rate 0.0010
[2019-03-23 22:05:46,380] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1193023: loss 0.3297
[2019-03-23 22:05:46,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1193023: learning rate 0.0010
[2019-03-23 22:05:47,701] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1193667: loss 0.1197
[2019-03-23 22:05:47,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1193667: learning rate 0.0010
[2019-03-23 22:05:47,947] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193787: loss 0.1103
[2019-03-23 22:05:47,949] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193789: learning rate 0.0010
[2019-03-23 22:05:55,127] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1197300: loss 0.0025
[2019-03-23 22:05:55,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1197301: learning rate 0.0010
[2019-03-23 22:05:56,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9024666e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:56,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-23 22:05:56,103] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 70.16666666666667, 1.0, 2.0, 0.8445603019111253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 962663.30224472, 962663.30224472, 205330.9898472625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5151000.0000, 
sim time next is 5151600.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.8766951898356354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 999315.8043861691, 999315.8043861686, 212309.5964318768], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.71, 1.0, 1.0, 0.8532085593281374, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35689850156648895, 0.3568985015664888, 0.4082876854459169], 
reward next is 0.5917, 
noisyNet noise sample is [array([-0.83194405], dtype=float32), -0.58476895]. 
=============================================
[2019-03-23 22:05:57,353] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1198386: loss 0.0003
[2019-03-23 22:05:57,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1198386: learning rate 0.0010
[2019-03-23 22:05:57,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2540348e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:57,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8724
[2019-03-23 22:05:57,443] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 86.5, 1.0, 2.0, 0.6860157552627734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781855.7657241931, 781855.7657241931, 173511.5016113731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5175000.0000, 
sim time next is 5175600.0000, 
raw observation next is [25.9, 86.66666666666667, 1.0, 2.0, 0.6799070803669547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774890.1576592195, 774890.1576592195, 172372.6700215303], 
processed observation next is [0.0, 0.9130434782608695, 0.5148148148148147, 0.8666666666666667, 1.0, 1.0, 0.6189370004368508, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2767464848782927, 0.2767464848782927, 0.3314859038875583], 
reward next is 0.6685, 
noisyNet noise sample is [array([-2.3833292], dtype=float32), 0.0717795]. 
=============================================
[2019-03-23 22:05:58,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7297084e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:58,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0294
[2019-03-23 22:05:58,526] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.5, 1.0, 2.0, 0.8202268341588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934910.1324755118, 934910.1324755118, 200162.8231536591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146200.0000, 
sim time next is 5146800.0000, 
raw observation next is [31.0, 69.0, 1.0, 2.0, 0.8117256801840731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 925214.5063828866, 925214.5063828861, 198381.4075003505], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.69, 1.0, 1.0, 0.7758639049810394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33043375227960237, 0.3304337522796022, 0.38150270673144326], 
reward next is 0.6185, 
noisyNet noise sample is [array([0.9655654], dtype=float32), 0.3828616]. 
=============================================
[2019-03-23 22:06:00,639] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 22:06:00,642] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:06:00,645] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:06:00,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200000: loss 0.2222
[2019-03-23 22:06:00,647] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:06:00,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200000: learning rate 0.0010
[2019-03-23 22:06:00,648] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:06:00,646] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:06:00,649] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:06:00,648] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:06:00,655] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:06:00,657] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:06:00,658] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:06:00,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 22:06:00,700] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 22:06:00,703] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 22:06:00,748] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 22:06:00,749] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 22:06:04,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:06:04,978] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.816305005, 26.44936030833333, 1.0, 2.0, 0.3957796329442436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488688.7411727026, 488688.7411727026, 127987.1914368758]
[2019-03-23 22:06:04,979] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:06:04,984] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.4079979896604058
[2019-03-23 22:06:25,457] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:06:25,460] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.70703571, 84.14901122, 1.0, 2.0, 0.4963566661830903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591274.7463918878, 591274.7463918878, 142296.5486110045]
[2019-03-23 22:06:25,460] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:06:25,464] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.03723881729438849
[2019-03-23 22:06:59,672] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:06:59,674] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.70346014, 68.01120125, 1.0, 2.0, 0.6465980187344339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736909.5694059564, 736909.5694059564, 166283.5905724552]
[2019-03-23 22:06:59,674] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:06:59,677] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.967477181364647
[2019-03-23 22:07:04,749] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:04,750] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.41703453, 94.582709025, 1.0, 2.0, 0.5202057780514164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618303.9001592357, 618303.9001592357, 146024.4388227274]
[2019-03-23 22:07:04,751] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:07:04,754] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.7180916840362273
[2019-03-23 22:07:04,792] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:04,792] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333333, 92.33333333333334, 1.0, 2.0, 0.5718754046768876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658836.8871815298, 658836.8871815298, 153654.5835430957]
[2019-03-23 22:07:04,793] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:07:04,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.23774842363352278
[2019-03-23 22:07:10,242] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:10,245] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.69460096, 74.2740832, 1.0, 2.0, 0.8367972118717885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 953809.11776492, 953809.11776492, 203670.2513228096]
[2019-03-23 22:07:10,248] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:07:10,250] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.7245832887420609
[2019-03-23 22:07:13,498] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:13,500] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.41666666666666, 87.16666666666667, 1.0, 2.0, 0.7508831821987435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 855826.7883560732, 855826.7883560727, 186004.7076165926]
[2019-03-23 22:07:13,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:07:13,503] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.9389515551632762
[2019-03-23 22:07:28,634] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:28,635] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666667, 89.66666666666667, 1.0, 2.0, 0.522858486221414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 618098.9747705989, 618098.9747705985, 146320.4120220614]
[2019-03-23 22:07:28,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:07:28,638] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.16643875905022654
[2019-03-23 22:07:32,931] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.75178206]
[2019-03-23 22:07:32,932] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.114787895, 60.45249348999999, 1.0, 2.0, 0.4508543292331944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568230.1448836148, 568230.1448836148, 136185.9783046353]
[2019-03-23 22:07:32,933] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:07:32,935] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4236281e-22 1.0000000e+00 2.8944166e-35 1.8786008e-38 5.6970036e-38], sampled 0.6633853110008505
[2019-03-23 22:07:41,184] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:07:41,423] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:07:41,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:07:41,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:07:41,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:07:43,008] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1200000, evaluation results [1200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:07:43,767] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200393: loss 0.6407
[2019-03-23 22:07:43,770] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200393: learning rate 0.0010
[2019-03-23 22:07:44,253] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200641: loss 0.8975
[2019-03-23 22:07:44,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200643: learning rate 0.0010
[2019-03-23 22:07:44,382] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200704: loss 0.8945
[2019-03-23 22:07:44,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200705: learning rate 0.0010
[2019-03-23 22:07:44,479] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200756: loss 0.7003
[2019-03-23 22:07:44,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200757: learning rate 0.0010
[2019-03-23 22:07:44,510] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200772: loss 0.7238
[2019-03-23 22:07:44,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200774: learning rate 0.0010
[2019-03-23 22:07:44,545] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200790: loss 0.6834
[2019-03-23 22:07:44,546] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200790: learning rate 0.0010
[2019-03-23 22:07:44,631] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200834: loss 0.5932
[2019-03-23 22:07:44,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200834: learning rate 0.0010
[2019-03-23 22:07:44,702] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200871: loss 0.5115
[2019-03-23 22:07:44,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200871: learning rate 0.0010
[2019-03-23 22:07:44,781] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200913: loss 0.4671
[2019-03-23 22:07:44,785] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200914: learning rate 0.0010
[2019-03-23 22:07:45,063] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1201058: loss 0.1253
[2019-03-23 22:07:45,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1201058: learning rate 0.0010
[2019-03-23 22:07:45,070] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201063: loss 0.2157
[2019-03-23 22:07:45,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201063: learning rate 0.0010
[2019-03-23 22:07:46,222] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1201658: loss 0.0024
[2019-03-23 22:07:46,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1201658: learning rate 0.0010
[2019-03-23 22:07:46,592] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201850: loss 0.0186
[2019-03-23 22:07:46,594] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201851: learning rate 0.0010
[2019-03-23 22:07:46,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.691977e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:07:46,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1122
[2019-03-23 22:07:46,754] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.01666666666667, 86.66666666666666, 1.0, 2.0, 0.5622096614417561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661350.8497132135, 661350.8497132135, 152645.6208490443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5287800.0000, 
sim time next is 5288400.0000, 
raw observation next is [23.9, 87.0, 1.0, 2.0, 0.5583365039067092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657704.8431916254, 657704.8431916254, 152036.4902211149], 
processed observation next is [1.0, 0.21739130434782608, 0.4407407407407407, 0.87, 1.0, 1.0, 0.4742101236984633, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23489458685415193, 0.23489458685415193, 0.2923778658098363], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.4570619], dtype=float32), -0.18355918]. 
=============================================
[2019-03-23 22:07:47,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0831389e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:47,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0442
[2019-03-23 22:07:47,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1730043.58175426 W.
[2019-03-23 22:07:47,136] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 78.5, 1.0, 2.0, 0.8903277747983669, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1730043.58175426, 1730043.58175426, 354885.3054077447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394600.0000, 
sim time next is 5395200.0000, 
raw observation next is [27.66666666666666, 77.66666666666667, 1.0, 2.0, 0.8051821681450533, 1.0, 1.0, 0.8051821681450533, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1836560.032380311, 1836560.032380312, 345900.3535496072], 
processed observation next is [1.0, 0.43478260869565216, 0.5802469135802467, 0.7766666666666667, 1.0, 1.0, 0.768074009696492, 1.0, 0.5, 0.768074009696492, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6559142972786826, 0.6559142972786829, 0.6651929875953985], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67751145], dtype=float32), -0.5149508]. 
=============================================
[2019-03-23 22:07:47,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6411354e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:47,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2185
[2019-03-23 22:07:47,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 89.16666666666667, 1.0, 2.0, 0.6723716593830729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766297.744839073, 766297.744839073, 170978.3061268118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5269800.0000, 
sim time next is 5270400.0000, 
raw observation next is [25.7, 89.0, 1.0, 2.0, 0.6695125508480188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763037.6149873456, 763037.6149873456, 170451.3321501382], 
processed observation next is [1.0, 0.0, 0.5074074074074074, 0.89, 1.0, 1.0, 0.6065625605333557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27251343392405203, 0.27251343392405203, 0.32779102336565036], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.2342237], dtype=float32), -0.15308057]. 
=============================================
[2019-03-23 22:07:47,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6417292e-21 1.0000000e+00 1.0031003e-34 8.1398482e-37 9.6967405e-37], sum to 1.0000
[2019-03-23 22:07:47,961] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3189
[2019-03-23 22:07:47,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1364765.111845864 W.
[2019-03-23 22:07:47,971] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 80.83333333333334, 1.0, 2.0, 0.5908655155069306, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9417847190375183, 6.911199999999999, 6.9112, 121.9260426156618, 1364765.111845864, 1364765.111845865, 290057.2281169544], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5310600.0000, 
sim time next is 5311200.0000, 
raw observation next is [25.1, 79.66666666666667, 1.0, 2.0, 0.5976479006524604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9527046862825559, 6.9112, 6.9112, 121.9260426156618, 1381528.422255974, 1381528.422255974, 292657.9361813903], 
processed observation next is [1.0, 0.4782608695652174, 0.4851851851851852, 0.7966666666666667, 1.0, 1.0, 0.5210094055386434, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9408808578531949, 0.0, 0.0, 0.8094621288201359, 0.4934030079485622, 0.4934030079485622, 0.5628037234257506], 
reward next is 0.4372, 
noisyNet noise sample is [array([0.39628857], dtype=float32), 0.1138241]. 
=============================================
[2019-03-23 22:07:51,046] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8394292e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:51,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6437
[2019-03-23 22:07:51,060] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 89.0, 1.0, 2.0, 0.7800177783022999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 902071.2844874734, 902071.2844874734, 192510.7482931109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5369400.0000, 
sim time next is 5370000.0000, 
raw observation next is [24.5, 89.33333333333334, 1.0, 2.0, 0.7355190177753853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850714.0881658734, 850714.0881658734, 183599.9220249022], 
processed observation next is [1.0, 0.13043478260869565, 0.46296296296296297, 0.8933333333333334, 1.0, 1.0, 0.6851416878278397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3038264600592405, 0.3038264600592405, 0.3530767731248119], 
reward next is 0.6469, 
noisyNet noise sample is [array([-0.29586673], dtype=float32), -0.56821054]. 
=============================================
[2019-03-23 22:07:51,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.337845]
 [64.337845]
 [64.337845]
 [64.337845]
 [64.337845]], R is [[64.34139252]
 [64.32776642]
 [64.31607819]
 [64.29950714]
 [64.29800415]].
[2019-03-23 22:07:52,961] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1205139: loss 1.6506
[2019-03-23 22:07:52,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1205140: learning rate 0.0010
[2019-03-23 22:07:55,358] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1206445: loss 0.0628
[2019-03-23 22:07:55,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1206445: learning rate 0.0010
[2019-03-23 22:07:58,264] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1207858: loss 0.6071
[2019-03-23 22:07:58,265] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1207858: learning rate 0.0010
[2019-03-23 22:07:59,300] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208366: loss 0.0216
[2019-03-23 22:07:59,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208367: learning rate 0.0010
[2019-03-23 22:07:59,761] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208591: loss 0.0031
[2019-03-23 22:07:59,765] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208592: learning rate 0.0010
[2019-03-23 22:07:59,928] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208676: loss 0.0040
[2019-03-23 22:07:59,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208679: learning rate 0.0010
[2019-03-23 22:07:59,988] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208707: loss 0.0004
[2019-03-23 22:07:59,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208707: learning rate 0.0010
[2019-03-23 22:08:00,073] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208751: loss 0.0044
[2019-03-23 22:08:00,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208752: learning rate 0.0010
[2019-03-23 22:08:00,104] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208765: loss 0.0007
[2019-03-23 22:08:00,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208765: learning rate 0.0010
[2019-03-23 22:08:00,151] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208786: loss 0.0034
[2019-03-23 22:08:00,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208787: learning rate 0.0010
[2019-03-23 22:08:00,293] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208860: loss 0.0048
[2019-03-23 22:08:00,294] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208860: learning rate 0.0010
[2019-03-23 22:08:00,408] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208920: loss 0.0031
[2019-03-23 22:08:00,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208920: learning rate 0.0010
[2019-03-23 22:08:00,805] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209107: loss 0.0098
[2019-03-23 22:08:00,807] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209109: learning rate 0.0010
[2019-03-23 22:08:00,856] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1209132: loss 0.0215
[2019-03-23 22:08:00,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1209132: learning rate 0.0010
[2019-03-23 22:08:01,761] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1209576: loss 0.2623
[2019-03-23 22:08:01,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1209576: learning rate 0.0010
[2019-03-23 22:08:02,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6032996e-22 1.0000000e+00 6.7265081e-36 1.4502706e-37 1.1830585e-36], sum to 1.0000
[2019-03-23 22:08:02,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0689
[2019-03-23 22:08:02,334] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 88.5, 1.0, 2.0, 0.7071391312505909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805942.8453512962, 805942.8453512962, 177495.2281904262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5553000.0000, 
sim time next is 5553600.0000, 
raw observation next is [25.36666666666667, 88.0, 1.0, 2.0, 0.6622101813099844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754711.0709974088, 754711.0709974088, 169110.0552901584], 
processed observation next is [1.0, 0.2608695652173913, 0.49506172839506185, 0.88, 1.0, 1.0, 0.5978692634642672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2695396682133603, 0.2695396682133603, 0.32521164478876613], 
reward next is 0.6748, 
noisyNet noise sample is [array([-0.04769162], dtype=float32), 0.60352683]. 
=============================================
[2019-03-23 22:08:02,440] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209911: loss 0.3504
[2019-03-23 22:08:02,441] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209911: learning rate 0.0010
[2019-03-23 22:08:07,101] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0554095e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:08:07,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-23 22:08:07,114] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 75.0, 1.0, 2.0, 0.7440681908811801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 848055.0349222095, 848055.034922209, 184659.0969731581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682600.0000, 
sim time next is 5683200.0000, 
raw observation next is [29.23333333333333, 76.0, 1.0, 2.0, 0.7484476564788561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 853049.328170646, 853049.3281706455, 185523.1615510812], 
processed observation next is [0.0, 0.782608695652174, 0.6382716049382715, 0.76, 1.0, 1.0, 0.7005329243795906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30466047434665927, 0.3046604743466591, 0.35677531067515617], 
reward next is 0.6432, 
noisyNet noise sample is [array([-0.6345832], dtype=float32), 1.2682291]. 
=============================================
[2019-03-23 22:08:09,175] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1213237: loss 0.0010
[2019-03-23 22:08:09,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1213237: learning rate 0.0010
[2019-03-23 22:08:10,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2906373e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:08:10,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0446
[2019-03-23 22:08:10,645] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1377113.998779999 W.
[2019-03-23 22:08:10,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.95, 44.0, 1.0, 2.0, 0.562849987664262, 0.0, 2.0, 0.0, 1.0, 1.0, 0.921184130529137, 6.9112, 6.9112, 121.9257009745741, 1377113.998779999, 1377113.998779999, 276542.7879556805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5844600.0000, 
sim time next is 5845200.0000, 
raw observation next is [27.96666666666667, 43.66666666666666, 1.0, 2.0, 0.5195172757705616, 1.0, 1.0, 0.5195172757705616, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425114851, 1264081.939859426, 1264081.939859427, 244728.7612697062], 
processed observation next is [1.0, 0.6521739130434783, 0.5913580246913581, 0.4366666666666666, 1.0, 1.0, 0.42799675686971617, 1.0, 0.5, 0.42799675686971617, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621281285109, 0.45145783566408076, 0.4514578356640811, 0.47063223321097347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4104546], dtype=float32), -0.12179502]. 
=============================================
[2019-03-23 22:08:11,245] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1214251: loss 0.0762
[2019-03-23 22:08:11,246] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1214252: learning rate 0.0010
[2019-03-23 22:08:14,514] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1215863: loss 0.1159
[2019-03-23 22:08:14,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1215864: learning rate 0.0010
[2019-03-23 22:08:14,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.394337e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:08:14,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1067
[2019-03-23 22:08:14,582] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 70.0, 1.0, 2.0, 0.9246001724041987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.083156771902974, 6.9112, 121.925192952788, 1216704.941231122, 1128648.318337125, 226464.4636006141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5820000.0000, 
sim time next is 5820600.0000, 
raw observation next is [24.33333333333333, 68.0, 1.0, 2.0, 0.9257848150509024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.10367564535606, 6.9112, 121.9250163096507, 1231019.819151672, 1132455.91511483, 226819.7731716586], 
processed observation next is [1.0, 0.34782608695652173, 0.45679012345678993, 0.68, 1.0, 1.0, 0.9116485893463123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.01924756453560601, 0.0, 0.8094553152155053, 0.4396499354113115, 0.4044485411124393, 0.4361918714839588], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43818593], dtype=float32), -0.7528965]. 
=============================================
[2019-03-23 22:08:15,649] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216426: loss 0.3880
[2019-03-23 22:08:15,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216426: learning rate 0.0010
[2019-03-23 22:08:16,095] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216637: loss 0.5283
[2019-03-23 22:08:16,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216638: learning rate 0.0010
[2019-03-23 22:08:16,157] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216670: loss 0.4097
[2019-03-23 22:08:16,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216671: learning rate 0.0010
[2019-03-23 22:08:16,180] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216680: loss 0.4105
[2019-03-23 22:08:16,181] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216680: loss 0.3685
[2019-03-23 22:08:16,183] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216680: learning rate 0.0010
[2019-03-23 22:08:16,186] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216682: learning rate 0.0010
[2019-03-23 22:08:16,280] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216729: loss 0.3550
[2019-03-23 22:08:16,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216729: learning rate 0.0010
[2019-03-23 22:08:16,536] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216850: loss 0.2161
[2019-03-23 22:08:16,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216850: loss 0.2022
[2019-03-23 22:08:16,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216850: learning rate 0.0010
[2019-03-23 22:08:16,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216850: learning rate 0.0010
[2019-03-23 22:08:16,662] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216913: loss 0.1310
[2019-03-23 22:08:16,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216914: learning rate 0.0010
[2019-03-23 22:08:17,201] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217176: loss 0.0064
[2019-03-23 22:08:17,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217176: learning rate 0.0010
[2019-03-23 22:08:17,252] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1217201: loss 0.0085
[2019-03-23 22:08:17,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1217202: learning rate 0.0010
[2019-03-23 22:08:18,223] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1217680: loss 0.0001
[2019-03-23 22:08:18,226] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1217681: learning rate 0.0010
[2019-03-23 22:08:18,965] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218045: loss 0.0029
[2019-03-23 22:08:18,967] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218046: learning rate 0.0010
[2019-03-23 22:08:21,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.054629e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:08:21,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2401
[2019-03-23 22:08:21,564] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 73.33333333333334, 1.0, 2.0, 0.4874253980267235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585736.4319147958, 585736.4319147958, 141089.5578702785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952000.0000, 
sim time next is 5952600.0000, 
raw observation next is [24.55, 74.5, 1.0, 2.0, 0.485579866758287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583868.0260103213, 583868.0260103213, 140815.3472373937], 
processed observation next is [1.0, 0.9130434782608695, 0.46481481481481485, 0.745, 1.0, 1.0, 0.38759507947415117, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2085242950036862, 0.2085242950036862, 0.2707987446872956], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.3413216], dtype=float32), -0.2217067]. 
=============================================
[2019-03-23 22:08:21,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.589697e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:08:21,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0205
[2019-03-23 22:08:21,683] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 67.0, 1.0, 2.0, 0.4867751379126182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585044.8665275396, 585044.8665275396, 140991.8141292874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5949000.0000, 
sim time next is 5949600.0000, 
raw observation next is [25.6, 68.33333333333333, 1.0, 2.0, 0.4899221221304359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588593.999987, 588593.999987, 141472.8592579244], 
processed observation next is [1.0, 0.8695652173913043, 0.5037037037037038, 0.6833333333333332, 1.0, 1.0, 0.39276443110766185, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2102121428525, 0.2102121428525, 0.27206319088062386], 
reward next is 0.7279, 
noisyNet noise sample is [array([0.29237485], dtype=float32), 0.39466104]. 
=============================================
[2019-03-23 22:08:23,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.37027e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:08:23,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4481
[2019-03-23 22:08:23,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1499979.059207733 W.
[2019-03-23 22:08:23,405] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.53333333333333, 70.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.497077956287765, 6.9112, 121.9239894088543, 1499979.059207733, 1199962.232711029, 247589.6578655135], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6078000.0000, 
sim time next is 6078600.0000, 
raw observation next is [27.55, 65.5, 1.0, 2.0, 0.4491941440424541, 1.0, 1.0, 0.4491941440424541, 1.0, 1.0, 0.7151317065475384, 6.9112, 6.9112, 121.94756008, 1536602.654359754, 1536602.654359754, 319301.8605845397], 
processed observation next is [1.0, 0.34782608695652173, 0.575925925925926, 0.655, 1.0, 1.0, 0.3442787429076835, 1.0, 0.5, 0.3442787429076835, 1.0, 0.5, 0.6439146331844231, 0.0, 0.0, 0.8096049824067558, 0.5487866622713407, 0.5487866622713407, 0.6140420395856533], 
reward next is 0.3860, 
noisyNet noise sample is [array([0.1448119], dtype=float32), 0.6797704]. 
=============================================
[2019-03-23 22:08:23,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4504054e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:08:23,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5076
[2019-03-23 22:08:23,489] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 75.66666666666667, 1.0, 2.0, 0.4838867661827436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582208.0135118129, 582208.0135118129, 140566.0875576438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5953200.0000, 
sim time next is 5953800.0000, 
raw observation next is [24.11666666666667, 76.83333333333333, 1.0, 2.0, 0.4820572733888371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580407.807674649, 580407.8076746486, 140296.9992594557], 
processed observation next is [1.0, 0.9130434782608695, 0.44876543209876557, 0.7683333333333333, 1.0, 1.0, 0.3834015159390917, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2072885027409461, 0.20728850274094593, 0.2698019216527994], 
reward next is 0.7302, 
noisyNet noise sample is [array([0.34144306], dtype=float32), 0.33320516]. 
=============================================
[2019-03-23 22:08:25,525] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1221234: loss -13.5380
[2019-03-23 22:08:25,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1221234: learning rate 0.0010
[2019-03-23 22:08:25,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6616585e-23 1.0000000e+00 1.7881846e-35 1.4277256e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:08:25,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-23 22:08:25,984] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 59.0, 1.0, 2.0, 0.5189586186271605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614043.0751578473, 614043.0751578473, 145716.8818676592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6026400.0000, 
sim time next is 6027000.0000, 
raw observation next is [28.08333333333333, 59.66666666666667, 1.0, 2.0, 0.5191020843670581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614117.1614733814, 614117.1614733814, 145736.0840938953], 
processed observation next is [1.0, 0.782608695652174, 0.5956790123456789, 0.5966666666666667, 1.0, 1.0, 0.4275024813893548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2193275576690648, 0.2193275576690648, 0.2802617001805679], 
reward next is 0.7197, 
noisyNet noise sample is [array([-1.3809537], dtype=float32), -0.9397353]. 
=============================================
[2019-03-23 22:08:26,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[51.622986]
 [51.622986]
 [51.622986]
 [51.622986]
 [51.622986]], R is [[51.82649994]
 [52.02801132]
 [52.22901535]
 [52.43040848]
 [52.63361359]].
[2019-03-23 22:08:27,718] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1222318: loss 0.0001
[2019-03-23 22:08:27,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1222318: learning rate 0.0010
[2019-03-23 22:08:30,850] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1223862: loss 0.8065
[2019-03-23 22:08:30,853] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1223862: learning rate 0.0010
[2019-03-23 22:08:31,846] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224355: loss 0.0100
[2019-03-23 22:08:31,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224356: learning rate 0.0010
[2019-03-23 22:08:32,256] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224553: loss 0.0619
[2019-03-23 22:08:32,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224556: learning rate 0.0010
[2019-03-23 22:08:32,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224614: loss 0.0323
[2019-03-23 22:08:32,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224616: learning rate 0.0010
[2019-03-23 22:08:32,610] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224730: loss 0.0071
[2019-03-23 22:08:32,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224731: learning rate 0.0010
[2019-03-23 22:08:32,630] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224739: loss 0.0000
[2019-03-23 22:08:32,631] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224739: learning rate 0.0010
[2019-03-23 22:08:32,663] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224750: loss 0.0001
[2019-03-23 22:08:32,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224750: learning rate 0.0010
[2019-03-23 22:08:32,766] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224804: loss 0.0014
[2019-03-23 22:08:32,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224805: learning rate 0.0010
[2019-03-23 22:08:32,809] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224824: loss 0.0000
[2019-03-23 22:08:32,810] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224825: learning rate 0.0010
[2019-03-23 22:08:33,063] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224951: loss 0.0380
[2019-03-23 22:08:33,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224951: learning rate 0.0010
[2019-03-23 22:08:33,171] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 22:08:33,173] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:08:33,173] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:08:33,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:08:33,176] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:08:33,177] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:08:33,178] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:08:33,178] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:08:33,179] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:08:33,183] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:08:33,188] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:08:33,204] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 22:08:33,229] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 22:08:33,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 22:08:33,299] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 22:08:33,326] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 22:08:40,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7875468]
[2019-03-23 22:08:40,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.8, 74.0, 1.0, 2.0, 0.2715724520037527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 350257.0408728049, 350257.0408728049, 112121.9111047836]
[2019-03-23 22:08:40,353] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:08:40,356] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.815883e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6137003356636795
[2019-03-23 22:08:51,752] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7875468]
[2019-03-23 22:08:51,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.64724578, 81.98485357, 1.0, 2.0, 0.3702538675629187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463608.4666934172, 463608.4666934172, 124603.0500871112]
[2019-03-23 22:08:51,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:08:51,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.815883e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4451673332560274
[2019-03-23 22:08:58,888] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7875468]
[2019-03-23 22:08:58,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 94.0, 1.0, 2.0, 0.3938350079862894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488119.7114380864, 488119.7114380864, 127757.2545890887]
[2019-03-23 22:08:58,892] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:08:58,895] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.815883e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.08371189582608063
[2019-03-23 22:09:19,868] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7875468]
[2019-03-23 22:09:19,868] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.38333333333333, 76.00000000000001, 1.0, 2.0, 0.7739171548881101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 882095.102350893, 882095.1023508934, 190614.8569603013]
[2019-03-23 22:09:19,870] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:09:19,873] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.815883e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7431316278998499
[2019-03-23 22:09:26,238] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7875468]
[2019-03-23 22:09:26,238] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [35.18719121666667, 53.67456121333333, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 6.940041111379161, 6.9112, 122.4171698609213, 2342017.661434842, 2327188.943065984, 443121.1869835664]
[2019-03-23 22:09:26,240] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:09:26,244] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.815883e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8313921372046826
[2019-03-23 22:09:26,245] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2342017.661434842 W.
[2019-03-23 22:10:13,998] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:10:14,640] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:10:14,682] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:10:14,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:10:14,861] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:10:15,875] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1225000, evaluation results [1225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:10:16,007] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225071: loss 0.0233
[2019-03-23 22:10:16,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225071: learning rate 0.0010
[2019-03-23 22:10:16,293] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1225216: loss 0.0521
[2019-03-23 22:10:16,296] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1225216: learning rate 0.0010
[2019-03-23 22:10:17,131] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1225644: loss 0.4054
[2019-03-23 22:10:17,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1225644: learning rate 0.0010
[2019-03-23 22:10:17,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6272187e-22 1.0000000e+00 1.1581520e-34 6.9904004e-38 1.5582484e-36], sum to 1.0000
[2019-03-23 22:10:17,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1567
[2019-03-23 22:10:17,490] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1799737.478212872 W.
[2019-03-23 22:10:17,496] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.88333333333333, 54.16666666666666, 1.0, 2.0, 0.7890547213915498, 1.0, 1.0, 0.7890547213915498, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1799737.478212872, 1799737.478212873, 339250.8049912814], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6187800.0000, 
sim time next is 6188400.0000, 
raw observation next is [29.9, 54.0, 1.0, 2.0, 0.5268663209140614, 1.0, 2.0, 0.5268663209140614, 1.0, 1.0, 0.838788341733337, 6.911200000000001, 6.9112, 121.94756008, 1802579.167587416, 1802579.167587416, 356970.9953404853], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.54, 1.0, 1.0, 0.4367456201357873, 1.0, 1.0, 0.4367456201357873, 1.0, 0.5, 0.7984854271666714, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6437782741383629, 0.6437782741383629, 0.6864826833470871], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.91219276], dtype=float32), 0.28347322]. 
=============================================
[2019-03-23 22:10:17,844] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226013: loss 0.7268
[2019-03-23 22:10:17,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226014: learning rate 0.0010
[2019-03-23 22:10:20,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.986296e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:10:20,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3681
[2019-03-23 22:10:20,919] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 73.0, 1.0, 2.0, 0.6128863335832349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 703619.425102945, 703619.4251029445, 160562.0008303425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6262200.0000, 
sim time next is 6262800.0000, 
raw observation next is [27.43333333333333, 72.33333333333333, 1.0, 2.0, 0.6155978042853035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706392.8666301301, 706392.8666301301, 161019.7107148675], 
processed observation next is [0.0, 0.4782608695652174, 0.5716049382716049, 0.7233333333333333, 1.0, 1.0, 0.5423783384348851, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2522831666536179, 0.2522831666536179, 0.30965328983628365], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.48442242], dtype=float32), 0.7186358]. 
=============================================
[2019-03-23 22:10:23,884] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1229153: loss 0.1111
[2019-03-23 22:10:23,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1229153: learning rate 0.0010
[2019-03-23 22:10:25,975] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1230243: loss -153.7451
[2019-03-23 22:10:25,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1230243: learning rate 0.0010
[2019-03-23 22:10:28,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0383965e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:28,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6883
[2019-03-23 22:10:28,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2244955.984319707 W.
[2019-03-23 22:10:28,801] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.23333333333333, 84.50000000000001, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.626899825217475, 6.9112, 121.9232850791277, 2244955.984319707, 1878461.994271205, 381565.8691620057], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6513000.0000, 
sim time next is 6513600.0000, 
raw observation next is [27.36666666666667, 84.0, 1.0, 2.0, 0.9218726599713165, 1.0, 1.0, 0.9218726599713165, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9256116330037, 2103035.675125952, 2103035.675125952, 396688.0310175144], 
processed observation next is [1.0, 0.391304347826087, 0.569135802469136, 0.84, 1.0, 1.0, 0.9069912618706149, 1.0, 0.5, 0.9069912618706149, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094592675434765, 0.75108416968784, 0.75108416968784, 0.7628615981106046], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0791527], dtype=float32), 0.8499137]. 
=============================================
[2019-03-23 22:10:29,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232033: loss -72.1201
[2019-03-23 22:10:29,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232035: learning rate 0.0010
[2019-03-23 22:10:30,224] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232458: loss -4.8150
[2019-03-23 22:10:30,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232458: learning rate 0.0010
[2019-03-23 22:10:30,475] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232577: loss -2.3442
[2019-03-23 22:10:30,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232581: learning rate 0.0010
[2019-03-23 22:10:30,676] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232673: loss -38.4116
[2019-03-23 22:10:30,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232674: learning rate 0.0010
[2019-03-23 22:10:30,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232680: loss 8.9518
[2019-03-23 22:10:30,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232680: learning rate 0.0010
[2019-03-23 22:10:30,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1392270e-19 1.0000000e+00 1.8226444e-30 3.2555500e-33 2.9210722e-34], sum to 1.0000
[2019-03-23 22:10:30,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-23 22:10:30,803] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 78.5, 1.0, 2.0, 0.6656662957473992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758651.9023154157, 758651.9023154157, 169744.8463633388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6484200.0000, 
sim time next is 6484800.0000, 
raw observation next is [27.16666666666667, 79.0, 1.0, 2.0, 0.6665151221333827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 759619.7789227375, 759619.778922737, 169900.5803052402], 
processed observation next is [1.0, 0.043478260869565216, 0.5617283950617286, 0.79, 1.0, 1.0, 0.6029941930159318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27129277818669195, 0.2712927781866918, 0.326731885202385], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.07106921], dtype=float32), 0.8609219]. 
=============================================
[2019-03-23 22:10:30,832] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232749: loss -85.3865
[2019-03-23 22:10:30,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232749: learning rate 0.0010
[2019-03-23 22:10:30,968] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232818: loss 10.7363
[2019-03-23 22:10:30,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232820: learning rate 0.0010
[2019-03-23 22:10:31,097] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232880: loss 7.4019
[2019-03-23 22:10:31,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232880: learning rate 0.0010
[2019-03-23 22:10:31,135] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232898: loss -46.8779
[2019-03-23 22:10:31,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232900: learning rate 0.0010
[2019-03-23 22:10:31,525] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1233089: loss -5.3560
[2019-03-23 22:10:31,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1233089: learning rate 0.0010
[2019-03-23 22:10:31,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233112: loss -13.5688
[2019-03-23 22:10:31,577] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233113: learning rate 0.0010
[2019-03-23 22:10:32,008] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1233326: loss -77.6129
[2019-03-23 22:10:32,011] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1233326: learning rate 0.0010
[2019-03-23 22:10:32,825] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233724: loss -52.0481
[2019-03-23 22:10:32,829] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233724: learning rate 0.0010
[2019-03-23 22:10:33,483] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234036: loss -37.6422
[2019-03-23 22:10:33,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234036: learning rate 0.0010
[2019-03-23 22:10:37,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.604663e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:10:37,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5512
[2019-03-23 22:10:37,729] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 51.16666666666667, 1.0, 2.0, 0.376815483784276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482693.0523720703, 482693.0523720703, 125595.3107556165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6682200.0000, 
sim time next is 6682800.0000, 
raw observation next is [23.43333333333334, 50.33333333333334, 1.0, 2.0, 0.4705817381555523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602336.7627038907, 602336.7627038902, 139251.9643351559], 
processed observation next is [1.0, 0.34782608695652173, 0.42345679012345705, 0.5033333333333334, 1.0, 1.0, 0.36974016447089564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21512027239424666, 0.2151202723942465, 0.26779223910606903], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.69058084], dtype=float32), 2.055862]. 
=============================================
[2019-03-23 22:10:39,594] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1237029: loss -143.7777
[2019-03-23 22:10:39,597] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1237031: learning rate 0.0010
[2019-03-23 22:10:40,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0735754e-24 1.0000000e+00 1.9666550e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:40,296] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0782
[2019-03-23 22:10:40,303] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 52.0, 1.0, 2.0, 0.8732565322546809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.949253699488906, 6.9112, 121.9254664739502, 1123290.301577648, 1103803.498320421, 215631.7879748763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6616800.0000, 
sim time next is 6617400.0000, 
raw observation next is [25.08333333333333, 49.5, 1.0, 2.0, 0.7852156749052415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260196538256, 991177.7307767702, 991177.7307767716, 196436.0279239989], 
processed observation next is [1.0, 0.6086956521739131, 0.4845679012345677, 0.495, 1.0, 1.0, 0.7443043748871923, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094619763774222, 0.3539920467059893, 0.3539920467059898, 0.3777615921615363], 
reward next is 0.6222, 
noisyNet noise sample is [array([-1.1862754], dtype=float32), 0.74090093]. 
=============================================
[2019-03-23 22:10:41,771] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1238114: loss 0.0086
[2019-03-23 22:10:41,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1238115: learning rate 0.0010
[2019-03-23 22:10:42,104] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1603532e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:42,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6837
[2019-03-23 22:10:42,127] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333333, 54.33333333333334, 1.0, 2.0, 0.3608073747049155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453044.7675075154, 453044.7675075154, 123348.155428724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6641400.0000, 
sim time next is 6642000.0000, 
raw observation next is [24.7, 53.0, 1.0, 2.0, 0.3532643968011641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 444671.3450133196, 444671.3450133192, 122356.7951524227], 
processed observation next is [1.0, 0.9130434782608695, 0.4703703703703703, 0.53, 1.0, 1.0, 0.2300766628585287, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15881119464761415, 0.158811194647614, 0.2353015291392744], 
reward next is 0.7647, 
noisyNet noise sample is [array([-1.0571287], dtype=float32), -0.6661112]. 
=============================================
[2019-03-23 22:10:42,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[79.87117]
 [79.87117]
 [79.87117]
 [79.87117]
 [79.87117]], R is [[79.8371582 ]
 [79.80158234]
 [79.76421356]
 [79.72489929]
 [79.68412018]].
[2019-03-23 22:10:45,364] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1239885: loss 0.0284
[2019-03-23 22:10:45,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1239885: learning rate 0.0010
[2019-03-23 22:10:46,452] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240421: loss 0.0203
[2019-03-23 22:10:46,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240421: learning rate 0.0010
[2019-03-23 22:10:46,480] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240438: loss 0.0351
[2019-03-23 22:10:46,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240439: learning rate 0.0010
[2019-03-23 22:10:47,053] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240713: loss 0.0003
[2019-03-23 22:10:47,056] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240714: loss 0.0007
[2019-03-23 22:10:47,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240714: learning rate 0.0010
[2019-03-23 22:10:47,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240717: learning rate 0.0010
[2019-03-23 22:10:47,066] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240718: loss 0.0010
[2019-03-23 22:10:47,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240718: learning rate 0.0010
[2019-03-23 22:10:47,290] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240826: loss 0.0191
[2019-03-23 22:10:47,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240827: learning rate 0.0010
[2019-03-23 22:10:47,328] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240844: loss 0.0072
[2019-03-23 22:10:47,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240847: learning rate 0.0010
[2019-03-23 22:10:47,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1240902: loss 0.0001
[2019-03-23 22:10:47,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1240903: learning rate 0.0010
[2019-03-23 22:10:47,716] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241037: loss 0.0049
[2019-03-23 22:10:47,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241038: learning rate 0.0010
[2019-03-23 22:10:47,834] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1241094: loss 0.0182
[2019-03-23 22:10:47,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1241097: learning rate 0.0010
[2019-03-23 22:10:48,360] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1241350: loss 0.0266
[2019-03-23 22:10:48,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1241350: learning rate 0.0010
[2019-03-23 22:10:49,020] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241678: loss 0.1891
[2019-03-23 22:10:49,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241680: learning rate 0.0010
[2019-03-23 22:10:49,745] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242036: loss 0.2982
[2019-03-23 22:10:49,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242036: learning rate 0.0010
[2019-03-23 22:10:53,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3017023e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:53,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5197
[2019-03-23 22:10:53,801] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 78.16666666666666, 1.0, 2.0, 0.4332177326816992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530189.3394483243, 530189.3394483243, 133231.1694607488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828600.0000, 
sim time next is 6829200.0000, 
raw observation next is [22.8, 78.0, 1.0, 2.0, 0.4291414769872715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525901.6028709454, 525901.6028709454, 132655.1261700755], 
processed observation next is [0.0, 0.043478260869565216, 0.4, 0.78, 1.0, 1.0, 0.3204065202229423, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18782200102533764, 0.18782200102533764, 0.2551060118655298], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.1895875], dtype=float32), 1.2922697]. 
=============================================
[2019-03-23 22:10:55,673] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1244947: loss 0.0138
[2019-03-23 22:10:55,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1244947: learning rate 0.0010
[2019-03-23 22:10:57,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.362155e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:10:57,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5302
[2019-03-23 22:10:57,829] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 66.16666666666667, 1.0, 2.0, 0.4889754430994624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586012.8494496302, 586012.8494496302, 141275.134411497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6947400.0000, 
sim time next is 6948000.0000, 
raw observation next is [26.4, 65.0, 1.0, 2.0, 0.4913908458616804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588282.6674694567, 588282.6674694567, 141628.7799140247], 
processed observation next is [0.0, 0.43478260869565216, 0.5333333333333333, 0.65, 1.0, 1.0, 0.3945129117400958, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2101009526676631, 0.2101009526676631, 0.27236303829620134], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.1185258], dtype=float32), 0.20614256]. 
=============================================
[2019-03-23 22:10:57,856] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.31532]
 [75.31532]
 [75.31532]
 [75.31532]
 [75.31532]], R is [[75.28980255]
 [75.26522064]
 [75.24150848]
 [75.21865845]
 [75.19683075]].
[2019-03-23 22:10:58,109] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1246150: loss -137.8193
[2019-03-23 22:10:58,110] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1246150: learning rate 0.0010
[2019-03-23 22:11:01,912] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248024: loss -155.0693
[2019-03-23 22:11:01,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248024: learning rate 0.0010
[2019-03-23 22:11:02,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0181438e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:11:02,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-23 22:11:02,552] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 77.33333333333334, 1.0, 2.0, 0.9117049276440871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.929700850558277, 6.9112, 121.9256510925107, 1109649.186937602, 1100175.128287253, 223012.2347911715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7033200.0000, 
sim time next is 7033800.0000, 
raw observation next is [24.03333333333333, 76.66666666666667, 1.0, 2.0, 0.8777665849981997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260314456514, 1058172.739179532, 1058172.739179532, 215256.6212411764], 
processed observation next is [1.0, 0.391304347826087, 0.4456790123456789, 0.7666666666666667, 1.0, 1.0, 0.8544840297597616, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094620546628829, 0.3779188354212614, 0.3779188354212614, 0.41395504084841617], 
reward next is 0.5860, 
noisyNet noise sample is [array([-0.08426799], dtype=float32), -1.2465]. 
=============================================
[2019-03-23 22:11:02,833] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248478: loss -96.8082
[2019-03-23 22:11:02,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248478: learning rate 0.0010
[2019-03-23 22:11:02,887] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248502: loss -114.4045
[2019-03-23 22:11:02,890] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248503: learning rate 0.0010
[2019-03-23 22:11:02,969] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9640817e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:11:02,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5579
[2019-03-23 22:11:02,982] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 84.33333333333333, 1.0, 2.0, 0.4617484529060805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565406.1846471156, 565406.1846471156, 137488.4370624188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7026600.0000, 
sim time next is 7027200.0000, 
raw observation next is [22.1, 84.0, 1.0, 2.0, 0.4677781872583915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572475.7249896991, 572475.7249896991, 138396.2938534987], 
processed observation next is [1.0, 0.34782608695652173, 0.3740740740740741, 0.84, 1.0, 1.0, 0.36640260387903745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20445561606774967, 0.20445561606774967, 0.26614671894903597], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.31214234], dtype=float32), -0.023142438]. 
=============================================
[2019-03-23 22:11:03,330] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248722: loss -121.5520
[2019-03-23 22:11:03,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248722: learning rate 0.0010
[2019-03-23 22:11:03,359] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248734: loss -122.2177
[2019-03-23 22:11:03,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248734: learning rate 0.0010
[2019-03-23 22:11:03,439] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248774: loss -84.6358
[2019-03-23 22:11:03,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248775: learning rate 0.0010
[2019-03-23 22:11:03,521] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248814: loss -68.9546
[2019-03-23 22:11:03,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248814: learning rate 0.0010
[2019-03-23 22:11:03,753] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248931: loss -108.5432
[2019-03-23 22:11:03,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248931: learning rate 0.0010
[2019-03-23 22:11:03,801] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1248954: loss -61.6534
[2019-03-23 22:11:03,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1248955: learning rate 0.0010
[2019-03-23 22:11:04,008] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249054: loss -75.2875
[2019-03-23 22:11:04,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249055: learning rate 0.0010
[2019-03-23 22:11:04,100] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1249102: loss -148.9532
[2019-03-23 22:11:04,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1249102: learning rate 0.0010
[2019-03-23 22:11:04,670] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1249377: loss -139.1828
[2019-03-23 22:11:04,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1249377: learning rate 0.0010
[2019-03-23 22:11:05,436] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249760: loss -117.6680
[2019-03-23 22:11:05,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249760: learning rate 0.0010
[2019-03-23 22:11:05,925] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 22:11:05,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:11:05,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:11:05,928] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:11:05,929] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:11:05,929] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:11:05,930] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:11:05,930] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:11:05,931] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:11:05,930] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:11:05,931] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:11:05,952] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 22:11:05,979] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 22:11:05,980] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 22:11:05,980] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 22:11:06,034] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 22:11:46,337] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8358539]
[2019-03-23 22:11:46,338] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.55, 86.0, 1.0, 2.0, 0.4965552768218274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590719.1029745352, 590719.1029745352, 142298.0138756413]
[2019-03-23 22:11:46,338] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:11:46,342] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1354534e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6894587600917954
[2019-03-23 22:12:02,247] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8358539]
[2019-03-23 22:12:02,248] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.2, 65.0, 1.0, 2.0, 0.6803239615873521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775365.5175280286, 775365.5175280286, 172453.5767455237]
[2019-03-23 22:12:02,251] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:12:02,255] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1354534e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7518650899115027
[2019-03-23 22:12:15,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8358539]
[2019-03-23 22:12:15,716] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.86666666666667, 98.66666666666667, 1.0, 2.0, 0.6972788844665742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 794699.0678694922, 794699.0678694927, 175629.2856186639]
[2019-03-23 22:12:15,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:12:15,720] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1354534e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.728281082477998
[2019-03-23 22:12:46,561] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:12:47,014] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:12:47,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:12:47,312] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:12:47,330] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:12:48,343] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1250000, evaluation results [1250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:12:48,387] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250025: loss -121.0586
[2019-03-23 22:12:48,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250026: learning rate 0.0010
[2019-03-23 22:12:49,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1616472e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:49,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0594
[2019-03-23 22:12:49,198] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 85.16666666666667, 1.0, 2.0, 0.3943889358150593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 489743.1032359584, 489743.1032359579, 127855.1367226138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7105800.0000, 
sim time next is 7106400.0000, 
raw observation next is [20.9, 85.0, 1.0, 2.0, 0.3916708456832716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486622.6452664703, 486622.6452664703, 127480.8294944167], 
processed observation next is [1.0, 0.2608695652173913, 0.32962962962962955, 0.85, 1.0, 1.0, 0.2757986258134186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17379380188088225, 0.17379380188088225, 0.24515544133541672], 
reward next is 0.7548, 
noisyNet noise sample is [array([-0.36702496], dtype=float32), -1.1765451]. 
=============================================
[2019-03-23 22:12:50,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7757793e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:50,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1549
[2019-03-23 22:12:50,915] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 85.33333333333334, 1.0, 2.0, 0.399734527495231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496111.1239663675, 496111.1239663675, 128599.9512600095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7105200.0000, 
sim time next is 7105800.0000, 
raw observation next is [20.91666666666667, 85.16666666666667, 1.0, 2.0, 0.3943889358150593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 489743.1032359584, 489743.1032359579, 127855.1367226138], 
processed observation next is [1.0, 0.21739130434782608, 0.3302469135802471, 0.8516666666666667, 1.0, 1.0, 0.2790344473988801, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1749082511556994, 0.17490825115569925, 0.24587526292810347], 
reward next is 0.7541, 
noisyNet noise sample is [array([1.0097083], dtype=float32), -0.4498934]. 
=============================================
[2019-03-23 22:12:53,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6127664e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:53,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1134
[2019-03-23 22:12:53,278] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 92.66666666666667, 1.0, 2.0, 0.3919056490899957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488842.5039301991, 488842.5039301991, 127552.3691725932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186800.0000, 
sim time next is 7187400.0000, 
raw observation next is [19.65, 92.5, 1.0, 2.0, 0.3927668850734701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 490158.2920594907, 490158.2920594902, 127677.2524216326], 
processed observation next is [1.0, 0.17391304347826086, 0.28333333333333327, 0.925, 1.0, 1.0, 0.2771034346112739, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17505653287838954, 0.17505653287838938, 0.24553317773390884], 
reward next is 0.7545, 
noisyNet noise sample is [array([1.4580102], dtype=float32), 0.34506115]. 
=============================================
[2019-03-23 22:12:53,738] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1252792: loss -140.8176
[2019-03-23 22:12:53,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1252792: learning rate 0.0010
[2019-03-23 22:12:56,077] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1254002: loss 0.0088
[2019-03-23 22:12:56,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1254002: learning rate 0.0010
[2019-03-23 22:12:58,435] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9085417e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:58,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4783
[2019-03-23 22:12:58,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 81.16666666666667, 1.0, 2.0, 0.7442171260370095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 908230.2889891181, 908230.2889891181, 187251.3772902105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7294200.0000, 
sim time next is 7294800.0000, 
raw observation next is [22.73333333333333, 80.33333333333334, 1.0, 2.0, 0.7454474234868029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909693.8367945339, 909693.8367945339, 187498.0645545613], 
processed observation next is [1.0, 0.43478260869565216, 0.39753086419753075, 0.8033333333333335, 1.0, 1.0, 0.6969612184366701, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32489065599804784, 0.32489065599804784, 0.36057320106646407], 
reward next is 0.6394, 
noisyNet noise sample is [array([-0.12205639], dtype=float32), 0.33008203]. 
=============================================
[2019-03-23 22:12:59,813] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1255959: loss 0.0229
[2019-03-23 22:12:59,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1255959: learning rate 0.0010
[2019-03-23 22:13:00,475] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256346: loss 0.0216
[2019-03-23 22:13:00,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256347: learning rate 0.0010
[2019-03-23 22:13:00,832] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256534: loss 0.0011
[2019-03-23 22:13:00,838] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256536: learning rate 0.0010
[2019-03-23 22:13:00,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256611: loss 0.0113
[2019-03-23 22:13:00,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256612: learning rate 0.0010
[2019-03-23 22:13:01,115] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256671: loss 0.0113
[2019-03-23 22:13:01,117] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256672: learning rate 0.0010
[2019-03-23 22:13:01,395] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256807: loss 0.0054
[2019-03-23 22:13:01,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256808: learning rate 0.0010
[2019-03-23 22:13:01,511] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256865: loss 0.0029
[2019-03-23 22:13:01,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256866: learning rate 0.0010
[2019-03-23 22:13:01,611] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256914: loss 0.0287
[2019-03-23 22:13:01,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256918: learning rate 0.0010
[2019-03-23 22:13:01,764] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1256994: loss 0.0088
[2019-03-23 22:13:01,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1256994: learning rate 0.0010
[2019-03-23 22:13:01,940] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257077: loss 0.0130
[2019-03-23 22:13:01,942] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257077: learning rate 0.0010
[2019-03-23 22:13:02,046] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1257130: loss 0.0061
[2019-03-23 22:13:02,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1257131: learning rate 0.0010
[2019-03-23 22:13:02,661] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1257433: loss 0.0220
[2019-03-23 22:13:02,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1257433: learning rate 0.0010
[2019-03-23 22:13:03,305] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257752: loss 0.0365
[2019-03-23 22:13:03,306] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257753: learning rate 0.0010
[2019-03-23 22:13:03,849] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258023: loss 0.1309
[2019-03-23 22:13:03,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258023: learning rate 0.0010
[2019-03-23 22:13:04,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5107623e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:04,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6565
[2019-03-23 22:13:04,036] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 66.33333333333333, 1.0, 2.0, 0.4285047899572014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525404.3844410321, 525404.3844410321, 132570.1177782814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7854000.0000, 
sim time next is 7854600.0000, 
raw observation next is [24.48333333333333, 66.66666666666667, 1.0, 2.0, 0.4279639570861988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 524947.2747456584, 524947.2747456579, 132496.9173350326], 
processed observation next is [1.0, 0.9130434782608695, 0.4623456790123456, 0.6666666666666667, 1.0, 1.0, 0.31900471081690335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18748116955202085, 0.18748116955202068, 0.25480176410583194], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.6813813], dtype=float32), 1.238984]. 
=============================================
[2019-03-23 22:13:09,716] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7695993e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:09,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4612
[2019-03-23 22:13:09,731] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 96.0, 1.0, 2.0, 0.4510505803765643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547517.4028652122, 547517.4028652117, 135738.1884835943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521600.0000, 
sim time next is 7522200.0000, 
raw observation next is [21.05, 96.0, 1.0, 2.0, 0.4493095472454283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545855.2887666344, 545855.2887666344, 135492.4616006439], 
processed observation next is [0.0, 0.043478260869565216, 0.3351851851851852, 0.96, 1.0, 1.0, 0.344416127673129, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19494831741665514, 0.19494831741665514, 0.2605624261550844], 
reward next is 0.7394, 
noisyNet noise sample is [array([0.12144177], dtype=float32), -2.6836777]. 
=============================================
[2019-03-23 22:13:10,032] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:10,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:10,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 22:13:11,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1261900: loss -113.1053
[2019-03-23 22:13:11,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1261900: learning rate 0.0010
[2019-03-23 22:13:13,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.13645e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:13:13,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 22:13:13,719] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 88.0, 1.0, 2.0, 0.5048441690310732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601256.5090055052, 601256.5090055052, 143625.6206045605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7599600.0000, 
sim time next is 7600200.0000, 
raw observation next is [23.08333333333333, 87.83333333333334, 1.0, 2.0, 0.5001194341422562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596784.4685564176, 596784.4685564172, 142924.2605586253], 
processed observation next is [0.0, 1.0, 0.41049382716049365, 0.8783333333333334, 1.0, 1.0, 0.40490408826459073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21313731019872056, 0.2131373101987204, 0.2748543472281256], 
reward next is 0.7251, 
noisyNet noise sample is [array([-1.8859928], dtype=float32), -0.25496054]. 
=============================================
[2019-03-23 22:13:15,561] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1263960: loss -143.4038
[2019-03-23 22:13:15,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1263960: learning rate 0.0010
[2019-03-23 22:13:16,005] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8594485e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:16,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9996
[2019-03-23 22:13:16,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 89.33333333333334, 1.0, 2.0, 0.5232079077722789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641474.1763295025, 641474.176329503, 147155.0431440931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7633200.0000, 
sim time next is 7633800.0000, 
raw observation next is [21.6, 88.5, 1.0, 2.0, 0.5756228112746771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703884.8272197307, 703884.8272197312, 155858.9875080073], 
processed observation next is [1.0, 0.34782608695652173, 0.3555555555555556, 0.885, 1.0, 1.0, 0.49478906104128223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25138743829276095, 0.2513874382927611, 0.2997288221307833], 
reward next is 0.7003, 
noisyNet noise sample is [array([-1.6213707], dtype=float32), -0.8334871]. 
=============================================
[2019-03-23 22:13:16,150] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264249: loss -83.9601
[2019-03-23 22:13:16,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264253: learning rate 0.0010
[2019-03-23 22:13:16,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0444515e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:16,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7566
[2019-03-23 22:13:16,339] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 70.5, 1.0, 2.0, 0.3667188488549963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459516.1470016887, 459516.1470016892, 124129.5861119863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7669800.0000, 
sim time next is 7670400.0000, 
raw observation next is [21.96666666666667, 71.0, 1.0, 2.0, 0.3581968669999386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449673.2146761096, 449673.2146761091, 122997.0012219432], 
processed observation next is [1.0, 0.782608695652174, 0.36913580246913585, 0.71, 1.0, 1.0, 0.23594865119040306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16059757667003915, 0.16059757667003896, 0.23653269465758306], 
reward next is 0.7635, 
noisyNet noise sample is [array([0.35811532], dtype=float32), -0.72760135]. 
=============================================
[2019-03-23 22:13:16,537] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264441: loss -98.6063
[2019-03-23 22:13:16,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264441: learning rate 0.0010
[2019-03-23 22:13:16,736] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264534: loss -120.0286
[2019-03-23 22:13:16,737] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264534: learning rate 0.0010
[2019-03-23 22:13:16,783] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264562: loss -118.6551
[2019-03-23 22:13:16,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264564: learning rate 0.0010
[2019-03-23 22:13:17,133] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264731: loss -91.0524
[2019-03-23 22:13:17,135] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264732: learning rate 0.0010
[2019-03-23 22:13:17,187] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264752: loss -93.8499
[2019-03-23 22:13:17,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264754: learning rate 0.0010
[2019-03-23 22:13:17,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264826: loss -115.6927
[2019-03-23 22:13:17,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264826: learning rate 0.0010
[2019-03-23 22:13:17,556] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264937: loss -115.9329
[2019-03-23 22:13:17,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264939: learning rate 0.0010
[2019-03-23 22:13:17,609] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264967: loss -91.1137
[2019-03-23 22:13:17,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264968: learning rate 0.0010
[2019-03-23 22:13:17,834] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1265074: loss -125.0586
[2019-03-23 22:13:17,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1265074: learning rate 0.0010
[2019-03-23 22:13:18,464] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1265391: loss -85.4330
[2019-03-23 22:13:18,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1265392: learning rate 0.0010
[2019-03-23 22:13:19,136] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1265716: loss -122.6004
[2019-03-23 22:13:19,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1265716: learning rate 0.0010
[2019-03-23 22:13:19,446] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265870: loss -150.9715
[2019-03-23 22:13:19,448] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265870: learning rate 0.0010
[2019-03-23 22:13:21,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.073929e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:13:21,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7604
[2019-03-23 22:13:21,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1479218.460259279 W.
[2019-03-23 22:13:21,498] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.46666666666667, 47.0, 1.0, 2.0, 0.6271729878843153, 1.0, 1.0, 0.6271729878843153, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1479218.460259279, 1479218.460259279, 279793.5758485735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7742400.0000, 
sim time next is 7743000.0000, 
raw observation next is [29.43333333333333, 47.5, 1.0, 2.0, 0.6309705840316334, 1.0, 2.0, 0.6309705840316334, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1484864.221521689, 1484864.22152169, 281013.5287414084], 
processed observation next is [1.0, 0.6086956521739131, 0.6456790123456789, 0.475, 1.0, 1.0, 0.5606792667043254, 1.0, 1.0, 0.5606792667043254, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5303086505434604, 0.5303086505434608, 0.5404106321950161], 
reward next is 0.4596, 
noisyNet noise sample is [array([-1.6278008], dtype=float32), 2.8212914]. 
=============================================
[2019-03-23 22:13:21,520] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.734375]
 [68.734375]
 [68.734375]
 [68.734375]
 [68.734375]], R is [[68.50662994]
 [68.28350067]
 [68.0215683 ]
 [67.34135437]
 [67.13668823]].
[2019-03-23 22:13:21,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1218942e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:21,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3417
[2019-03-23 22:13:21,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1457224.132955182 W.
[2019-03-23 22:13:21,753] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.56666666666667, 45.5, 1.0, 2.0, 0.4146008167741526, 1.0, 1.0, 0.4146008167741526, 1.0, 2.0, 0.6627929239591893, 6.911199999999997, 6.9112, 121.94756008, 1457224.132955182, 1457224.132955183, 303575.1781515137], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7740600.0000, 
sim time next is 7741200.0000, 
raw observation next is [29.53333333333334, 46.0, 1.0, 2.0, 0.4208708458818147, 1.0, 2.0, 0.4208708458818147, 1.0, 2.0, 0.6719474117191727, 6.911199999999999, 6.9112, 121.94756008, 1471612.631517687, 1471612.631517687, 306423.268772249], 
processed observation next is [1.0, 0.6086956521739131, 0.6493827160493829, 0.46, 1.0, 1.0, 0.3105605308116842, 1.0, 1.0, 0.3105605308116842, 1.0, 1.0, 0.5899342646489658, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5255759398277454, 0.5255759398277454, 0.5892755168697096], 
reward next is 0.4107, 
noisyNet noise sample is [array([-2.5827734], dtype=float32), -1.321596]. 
=============================================
[2019-03-23 22:13:23,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0695126e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:23,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6816
[2019-03-23 22:13:23,609] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 87.0, 1.0, 2.0, 0.3826289148375085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479060.1089465229, 479060.1089465224, 126297.2101693247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7881600.0000, 
sim time next is 7882200.0000, 
raw observation next is [20.2, 86.0, 1.0, 2.0, 0.3810255358940519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477012.9666297468, 477012.9666297468, 126075.4240589064], 
processed observation next is [1.0, 0.21739130434782608, 0.3037037037037037, 0.86, 1.0, 1.0, 0.2631256379691094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17036177379633813, 0.17036177379633813, 0.24245273857482], 
reward next is 0.7575, 
noisyNet noise sample is [array([0.0539441], dtype=float32), -0.7639767]. 
=============================================
[2019-03-23 22:13:28,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:28,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:28,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 22:13:29,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1694505e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:29,279] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1759
[2019-03-23 22:13:29,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1443261.458541509 W.
[2019-03-23 22:13:29,291] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 53.0, 1.0, 2.0, 0.6118846893741794, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9649663597936818, 6.911200000000001, 6.9112, 121.9260426156104, 1443261.458541509, 1443261.458541509, 294432.8447021525], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7904400.0000, 
sim time next is 7905000.0000, 
raw observation next is [28.05, 52.5, 1.0, 2.0, 0.6211145404133676, 1.0, 1.0, 0.6211145404133676, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1468914.057184567, 1468914.057184568, 277799.3293639205], 
processed observation next is [1.0, 0.4782608695652174, 0.5944444444444444, 0.525, 1.0, 1.0, 0.5489458814444852, 1.0, 0.5, 0.5489458814444852, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5246121632802024, 0.5246121632802028, 0.534229479546001], 
reward next is 0.4658, 
noisyNet noise sample is [array([0.4607256], dtype=float32), -1.1466994]. 
=============================================
[2019-03-23 22:13:29,309] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.72106]
 [76.72106]
 [76.72106]
 [76.72106]
 [76.72106]], R is [[76.41962433]
 [76.08921051]
 [75.32831573]
 [74.5750351 ]
 [73.82928467]].
[2019-03-23 22:13:29,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0693305e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:29,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3984
[2019-03-23 22:13:29,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1683814.553232305 W.
[2019-03-23 22:13:29,735] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 48.33333333333333, 1.0, 2.0, 0.491435797209282, 1.0, 2.0, 0.491435797209282, 1.0, 1.0, 0.7824387071122633, 6.9112, 6.9112, 121.94756008, 1683814.553232305, 1683814.553232305, 339424.6284186689], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [30.1, 48.66666666666666, 1.0, 2.0, 0.7493711122146206, 1.0, 2.0, 0.7493711122146206, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1727986.975760309, 1727986.975760309, 324248.0601930359], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.4866666666666666, 1.0, 1.0, 0.7016322764459769, 1.0, 1.0, 0.7016322764459769, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6171382056286818, 0.6171382056286818, 0.6235539619096845], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2549617], dtype=float32), -1.4062196]. 
=============================================
[2019-03-23 22:13:32,210] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2059704e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:13:32,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5677
[2019-03-23 22:13:32,220] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.45, 55.5, 1.0, 2.0, 0.5015188048172486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 597734.3183553835, 597734.3183553839, 143117.8511850305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [28.23333333333333, 56.33333333333333, 1.0, 2.0, 0.4998454146960509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596180.8265209994, 596180.826520999, 142871.1264699279], 
processed observation next is [1.0, 0.782608695652174, 0.6012345679012344, 0.5633333333333332, 1.0, 1.0, 0.40457787463815587, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2129217237574998, 0.21292172375749963, 0.2747521662883229], 
reward next is 0.7252, 
noisyNet noise sample is [array([1.4963138], dtype=float32), 1.0449584]. 
=============================================
[2019-03-23 22:13:32,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:32,259] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:32,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.49644e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:13:32,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-23 22:13:32,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 22:13:32,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 68.66666666666667, 1.0, 2.0, 0.4558021369667031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554193.0335248316, 554193.0335248316, 136477.1169163056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7942200.0000, 
sim time next is 7942800.0000, 
raw observation next is [24.63333333333333, 69.33333333333334, 1.0, 2.0, 0.4556057927784745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554166.8207135566, 554166.8207135566, 136454.0552582926], 
processed observation next is [1.0, 0.9565217391304348, 0.46790123456790106, 0.6933333333333335, 1.0, 1.0, 0.35191165806961255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19791672168341307, 0.19791672168341307, 0.26241164472748574], 
reward next is 0.7376, 
noisyNet noise sample is [array([-0.2856903], dtype=float32), -0.09583255]. 
=============================================
[2019-03-23 22:13:32,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:32,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:32,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 22:13:33,143] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,144] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 22:13:33,200] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,200] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,208] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 22:13:33,284] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,284] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 22:13:33,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,572] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,580] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,580] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,587] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 22:13:33,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 22:13:33,647] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 22:13:33,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 22:13:33,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:33,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:33,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 22:13:33,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 22:13:34,011] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:34,011] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:34,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 22:13:34,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:34,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:34,218] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 22:13:34,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:13:34,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:34,277] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 22:13:38,800] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 22:13:38,803] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:13:38,804] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:13:38,805] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:38,807] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:13:38,810] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:13:38,809] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:38,812] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:13:38,811] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:38,815] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:38,813] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:13:38,832] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 22:13:38,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 22:13:38,860] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 22:13:38,885] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 22:13:38,912] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 22:13:54,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:13:54,990] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.66342732333333, 57.30800709333334, 1.0, 2.0, 0.3021815372991613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385664.3226090949, 385664.3226090949, 115845.944507674]
[2019-03-23 22:13:54,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:13:54,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9734411340477683
[2019-03-23 22:13:59,775] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:13:59,777] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 45.66666666666667, 1.0, 2.0, 0.3497209899701348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438572.0361077664, 438572.036107766, 121862.6369855273]
[2019-03-23 22:13:59,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:13:59,784] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8349961457776989
[2019-03-23 22:14:01,307] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:01,310] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.45610017, 82.09205751333334, 1.0, 2.0, 0.6278912558450845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795566.304352642, 795566.3043526416, 165643.0261438473]
[2019-03-23 22:14:01,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:14:01,317] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.05297711292147145
[2019-03-23 22:14:03,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:03,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.85, 51.5, 1.0, 2.0, 0.5110377269531183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622151.2843112539, 622151.2843112539, 145064.9964511453]
[2019-03-23 22:14:03,842] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:03,845] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.40672681329194815
[2019-03-23 22:14:03,954] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:03,956] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.88223637666667, 78.36110633666667, 1.0, 2.0, 0.6698790744828222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763455.5468053222, 763455.5468053222, 170517.0350871189]
[2019-03-23 22:14:03,957] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:14:03,959] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7033052580747016
[2019-03-23 22:14:06,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:06,378] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.4, 85.0, 1.0, 2.0, 0.4357307665049129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 544896.0271615621, 544896.0271615617, 133867.4880061543]
[2019-03-23 22:14:06,378] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:06,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4542383271895526
[2019-03-23 22:14:12,018] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:12,019] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.73604103833333, 42.02132789500001, 1.0, 2.0, 0.4513394107277493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558735.8331512087, 558735.8331512087, 136075.1150938565]
[2019-03-23 22:14:12,020] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:14:12,023] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6363394840304066
[2019-03-23 22:14:16,524] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:16,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.45016335, 95.16332235, 1.0, 2.0, 0.4178399971234719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518291.7734146254, 518291.7734146254, 131172.3743224481]
[2019-03-23 22:14:16,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:14:16,529] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.1668539967516839
[2019-03-23 22:14:19,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:19,832] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.329632595, 82.246275585, 1.0, 2.0, 0.6374814513604091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726514.750427, 726514.750427, 164644.9195032116]
[2019-03-23 22:14:19,834] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:14:19,837] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7059658473228106
[2019-03-23 22:14:22,157] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:22,159] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.77330422666667, 70.79038848333334, 1.0, 2.0, 0.6756377949409685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770022.0086834062, 770022.0086834062, 171582.7389518352]
[2019-03-23 22:14:22,163] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:14:22,166] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5499277e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9618513130597262
[2019-03-23 22:14:28,192] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:28,192] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.7, 80.66666666666667, 1.0, 2.0, 0.6582631049147422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750210.4455391531, 750210.4455391531, 168391.4017260685]
[2019-03-23 22:14:28,193] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:28,196] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8189712718711308
[2019-03-23 22:14:54,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:14:54,705] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.86666666666667, 80.0, 1.0, 2.0, 0.701955363230559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800031.7015264021, 800031.7015264021, 176516.0986382145]
[2019-03-23 22:14:54,706] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:54,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0162557465664952
[2019-03-23 22:15:17,749] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8973214]
[2019-03-23 22:15:17,751] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [14.8, 82.0, 1.0, 2.0, 0.1729895044953397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 223127.1283700849, 223127.1283700849, 75451.74775479473]
[2019-03-23 22:15:17,752] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:15:17,756] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.484275e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7263277936042838
[2019-03-23 22:15:19,864] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:15:19,888] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:15:20,087] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:15:20,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:15:20,240] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:15:21,255] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1275000, evaluation results [1275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:15:26,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2549354e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:26,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 22:15:26,212] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.15, 12.33333333333333, 1.0, 2.0, 0.3371212754719128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434889.3039559643, 434889.3039559643, 101611.0013962774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 173400.0000, 
sim time next is 174000.0000, 
raw observation next is [28.9, 12.66666666666667, 1.0, 2.0, 0.3346288182085058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431673.1079750034, 431673.1079750034, 100979.9417050135], 
processed observation next is [0.0, 0.0, 0.6259259259259259, 0.1266666666666667, 1.0, 1.0, 0.20789145024822123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1541689671339298, 0.1541689671339298, 0.19419219558656442], 
reward next is 0.8058, 
noisyNet noise sample is [array([-0.3149285], dtype=float32), -0.16472147]. 
=============================================
[2019-03-23 22:15:26,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.46938]
 [70.46938]
 [70.46938]
 [70.46938]
 [70.46938]], R is [[70.57048798]
 [70.66938019]
 [70.76583862]
 [70.85971832]
 [70.95122528]].
[2019-03-23 22:15:39,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2608779e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:39,439] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8148
[2019-03-23 22:15:39,443] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 52.33333333333333, 1.0, 2.0, 0.3543339989158085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445818.808018348, 445818.808018348, 122496.3886468374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 938400.0000, 
sim time next is 939000.0000, 
raw observation next is [24.8, 52.16666666666667, 1.0, 2.0, 0.3501506132553511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441155.3507295502, 441155.3507295502, 121949.3028163029], 
processed observation next is [0.0, 0.8695652173913043, 0.4740740740740741, 0.5216666666666667, 1.0, 1.0, 0.22636977768494176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15755548240341077, 0.15755548240341077, 0.2345178900313517], 
reward next is 0.7655, 
noisyNet noise sample is [array([0.364328], dtype=float32), 0.07075613]. 
=============================================
[2019-03-23 22:15:39,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.38239]
 [71.38239]
 [71.38239]
 [71.38239]
 [71.38239]], R is [[71.43405914]
 [71.48414612]
 [71.53259277]
 [71.57961273]
 [71.62545013]].
[2019-03-23 22:15:47,832] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9203510e-21 1.0000000e+00 6.2338853e-34 9.3920951e-37 2.2336719e-36], sum to 1.0000
[2019-03-23 22:15:47,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8930
[2019-03-23 22:15:47,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1509891.637661958 W.
[2019-03-23 22:15:47,854] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 36.33333333333334, 1.0, 2.0, 0.6260357921876986, 1.0, 1.0, 0.6260357921876986, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424373227, 1509891.637661958, 1509891.637661958, 280676.2007619318], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 567600.0000, 
sim time next is 568200.0000, 
raw observation next is [30.46666666666667, 35.66666666666666, 1.0, 2.0, 0.6493799013362994, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9576538172486386, 6.911199999999999, 6.9112, 121.9260426156074, 1502165.994429489, 1502165.99442949, 297478.3859250636], 
processed observation next is [1.0, 0.5652173913043478, 0.6839506172839507, 0.3566666666666666, 1.0, 1.0, 0.5825951206384516, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9470672715607983, -8.881784197001253e-17, 0.0, 0.8094621288197748, 0.5364878551533889, 0.5364878551533893, 0.5720738190866607], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8283668], dtype=float32), 1.2554071]. 
=============================================
[2019-03-23 22:15:49,271] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2387848e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:49,280] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2568
[2019-03-23 22:15:49,282] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 45.0, 1.0, 2.0, 0.3531963990795027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444291.8388528557, 444291.8388528557, 122343.7950725963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 600000.0000, 
sim time next is 600600.0000, 
raw observation next is [26.28333333333333, 45.5, 1.0, 2.0, 0.3503931148352916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441085.5432829835, 441085.5432829835, 121976.4219694003], 
processed observation next is [1.0, 0.9565217391304348, 0.5290123456790122, 0.455, 1.0, 1.0, 0.22665847004201384, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1575305511724941, 0.1575305511724941, 0.23457004224884673], 
reward next is 0.7654, 
noisyNet noise sample is [array([-0.4331006], dtype=float32), 1.4183345]. 
=============================================
[2019-03-23 22:15:56,137] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6106694e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:56,146] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3695
[2019-03-23 22:15:56,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1375519.608632104 W.
[2019-03-23 22:15:56,158] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 41.0, 1.0, 2.0, 0.5640341370827059, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9205636204446264, 6.911199999999999, 6.9112, 121.9260426156618, 1375519.608632104, 1375519.608632104, 277241.0579549632], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 734400.0000, 
sim time next is 735000.0000, 
raw observation next is [28.98333333333333, 39.33333333333334, 1.0, 2.0, 0.6270804723228597, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9561540346149976, 6.911199999999999, 6.9112, 121.9260426156618, 1480710.813211406, 1480710.813211407, 292103.3912517244], 
processed observation next is [1.0, 0.5217391304347826, 0.6290123456790122, 0.3933333333333334, 1.0, 1.0, 0.5560481813367377, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9451925432687469, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.528825290432645, 0.5288252904326454, 0.5617372908687007], 
reward next is 0.4383, 
noisyNet noise sample is [array([-1.4478673], dtype=float32), 0.6403786]. 
=============================================
[2019-03-23 22:15:56,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.26932]
 [72.26932]
 [72.26932]
 [72.26932]
 [72.26932]], R is [[71.98488617]
 [71.73188019]
 [71.51186371]
 [71.29723358]
 [71.09799194]].
[2019-03-23 22:15:59,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8789e-32 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-23 22:15:59,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0030
[2019-03-23 22:15:59,594] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 58.16666666666667, 1.0, 2.0, 0.3172864357530921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 402656.7213380275, 402656.7213380279, 117726.1771874299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 799800.0000, 
sim time next is 800400.0000, 
raw observation next is [23.13333333333333, 58.33333333333334, 1.0, 2.0, 0.3210496661510182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407055.6977871213, 407055.6977871213, 118200.810843074], 
processed observation next is [0.0, 0.2608695652173913, 0.41234567901234553, 0.5833333333333335, 1.0, 1.0, 0.19172579303692644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1453770349239719, 0.1453770349239719, 0.22730925162129614], 
reward next is 0.7727, 
noisyNet noise sample is [array([0.88959885], dtype=float32), 0.40983868]. 
=============================================
[2019-03-23 22:16:01,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5880643e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:16:01,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4017
[2019-03-23 22:16:01,091] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 51.5, 1.0, 2.0, 0.3878690794766997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481358.9713252078, 481358.9713252078, 126940.4451537402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 811800.0000, 
sim time next is 812400.0000, 
raw observation next is [26.7, 50.66666666666667, 1.0, 2.0, 0.3917939236719075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485483.0727770826, 485483.0727770826, 127469.9898725707], 
processed observation next is [0.0, 0.391304347826087, 0.5444444444444444, 0.5066666666666667, 1.0, 1.0, 0.27594514722846136, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17338681170610093, 0.17338681170610093, 0.2451345959087898], 
reward next is 0.7549, 
noisyNet noise sample is [array([-0.29716688], dtype=float32), 3.2260368]. 
=============================================
[2019-03-23 22:16:03,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6561582e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:16:03,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-23 22:16:03,813] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 66.33333333333334, 1.0, 2.0, 0.3379137662042673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428373.8733191731, 428373.8733191731, 120371.727495494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 877200.0000, 
sim time next is 877800.0000, 
raw observation next is [21.68333333333334, 66.16666666666666, 1.0, 2.0, 0.3349065986664459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425028.9059156064, 425028.9059156064, 119984.6153110949], 
processed observation next is [0.0, 0.13043478260869565, 0.3586419753086422, 0.6616666666666666, 1.0, 1.0, 0.20822214126957844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1517960378270023, 0.1517960378270023, 0.23073964482902865], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.7646727], dtype=float32), 0.5379628]. 
=============================================
[2019-03-23 22:16:05,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6139805e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:16:05,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0199
[2019-03-23 22:16:05,631] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 64.0, 1.0, 2.0, 0.3704828104529171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463277.4087245807, 463277.4087245811, 124623.7059617012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 898200.0000, 
sim time next is 898800.0000, 
raw observation next is [23.6, 63.66666666666667, 1.0, 2.0, 0.3755210641442139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 469048.3747197594, 469048.3747197589, 125300.9019369397], 
processed observation next is [0.0, 0.391304347826087, 0.4296296296296297, 0.6366666666666667, 1.0, 1.0, 0.25657269540977845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16751727668562835, 0.16751727668562819, 0.24096327295565326], 
reward next is 0.7590, 
noisyNet noise sample is [array([-0.74568564], dtype=float32), -1.7997442]. 
=============================================
[2019-03-23 22:16:08,584] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9996615e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:16:08,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1196
[2019-03-23 22:16:08,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 59.66666666666666, 1.0, 2.0, 0.2914878988877665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376007.4295045176, 376007.4295045176, 113172.1821217291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [20.7, 60.0, 1.0, 2.0, 0.2903184508242002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 374498.5211570468, 374498.5211570463, 113034.6751537354], 
processed observation next is [1.0, 0.17391304347826086, 0.3222222222222222, 0.6, 1.0, 1.0, 0.15514101288595264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13374947184180241, 0.13374947184180225, 0.217374375295645], 
reward next is 0.7826, 
noisyNet noise sample is [array([0.8442052], dtype=float32), -2.0729468]. 
=============================================
[2019-03-23 22:16:09,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.81143e-30 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:16:09,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2947
[2019-03-23 22:16:09,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 67.0, 1.0, 2.0, 0.4918452642739484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630711.6436112695, 630711.6436112695, 142565.9837819485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1155600.0000, 
sim time next is 1156200.0000, 
raw observation next is [20.46666666666667, 66.83333333333334, 1.0, 2.0, 0.5678287166299141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727826.5450798428, 727826.5450798428, 155072.1664190622], 
processed observation next is [1.0, 0.391304347826087, 0.31358024691358033, 0.6683333333333334, 1.0, 1.0, 0.48551037694037386, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2599380518142296, 0.2599380518142296, 0.2982157046520427], 
reward next is 0.7018, 
noisyNet noise sample is [array([0.9081414], dtype=float32), 2.1073906]. 
=============================================
[2019-03-23 22:16:11,519] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:16:11,522] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:16:11,524] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:16:11,526] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:16:11,527] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:16:11,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:16:11,530] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:16:11,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:16:11,531] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:16:11,532] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:16:11,532] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:16:11,554] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 22:16:11,578] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 22:16:11,602] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 22:16:11,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 22:16:11,655] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 22:16:19,031] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:16:19,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.110140355, 39.43715130166667, 1.0, 2.0, 0.4902429373991081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615104.7552422957, 615104.7552422957, 142206.0173807448]
[2019-03-23 22:16:19,033] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:16:19,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.38776989247925364
[2019-03-23 22:16:23,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:16:23,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.66666666666667, 51.0, 1.0, 2.0, 0.2975972077020465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380004.8513250869, 380004.8513250869, 115279.7610683204]
[2019-03-23 22:16:23,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:16:23,410] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.7671113865921926
[2019-03-23 22:16:30,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:16:30,267] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.194264325, 60.885011865, 1.0, 2.0, 0.3007934348231652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 383383.2444948228, 383383.2444948228, 115672.2327975206]
[2019-03-23 22:16:30,268] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:16:30,272] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.8665585837961084
[2019-03-23 22:17:00,891] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:17:00,892] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.91666666666667, 85.5, 1.0, 2.0, 0.6090598800419786, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9696431647223209, 6.911199999999999, 6.9112, 121.9260426156618, 1388847.135478195, 1388847.135478196, 297401.8482936214]
[2019-03-23 22:17:00,893] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:17:00,899] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.4547742234056712
[2019-03-23 22:17:00,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1388847.135478195 W.
[2019-03-23 22:17:15,763] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:17:15,764] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.75, 77.16666666666667, 1.0, 2.0, 0.6158917483668526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704604.1195611919, 704604.1195611919, 160966.6842561322]
[2019-03-23 22:17:15,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:17:15,766] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.5214023544374728
[2019-03-23 22:17:16,119] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:17:16,119] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.23333333333333, 91.83333333333334, 1.0, 2.0, 0.5624287919779954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650034.0075716368, 650034.0075716368, 152174.407310027]
[2019-03-23 22:17:16,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:17:16,121] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.4010410452487908
[2019-03-23 22:17:22,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.87522507]
[2019-03-23 22:17:22,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.9317833576013076, 1.0, 2.0, 0.9317833576013076, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2125671.503654614, 2125671.503654614, 401218.5504240533]
[2019-03-23 22:17:22,537] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:17:22,541] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.337093e-24 1.000000e+00 4.706400e-38 0.000000e+00 0.000000e+00], sampled 0.5377053132924903
[2019-03-23 22:17:22,542] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2125671.503654614 W.
[2019-03-23 22:17:52,520] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:17:52,557] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:17:52,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:17:52,723] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:17:52,833] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:17:53,847] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1300000, evaluation results [1300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:17:56,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0932035e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:56,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3750
[2019-03-23 22:17:56,118] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 67.0, 1.0, 2.0, 0.3719948789214019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469001.7899200449, 469001.7899200449, 124887.7267406114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1580400.0000, 
sim time next is 1581000.0000, 
raw observation next is [22.41666666666667, 65.5, 1.0, 2.0, 0.4260652149790158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537272.7089941041, 537272.7089941036, 132518.2774377753], 
processed observation next is [1.0, 0.30434782608695654, 0.38580246913580263, 0.655, 1.0, 1.0, 0.3167443035464474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19188311035503716, 0.191883110355037, 0.254842841226491], 
reward next is 0.7452, 
noisyNet noise sample is [array([-1.7845312], dtype=float32), -0.3345226]. 
=============================================
[2019-03-23 22:17:56,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.30842]
 [72.30842]
 [72.30842]
 [72.30842]
 [72.30842]], R is [[72.33049774]
 [72.36702728]
 [72.39426422]
 [72.42356873]
 [72.45870972]].
[2019-03-23 22:17:56,910] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.031406e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:17:56,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-23 22:17:56,921] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 42.5, 1.0, 2.0, 0.4928115525574556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 624677.0602824417, 624677.0602824421, 142690.3344281677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1084200.0000, 
sim time next is 1084800.0000, 
raw observation next is [26.3, 42.0, 1.0, 2.0, 0.7159088842489795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906994.3503135585, 906994.3503135585, 182351.1523373349], 
processed observation next is [1.0, 0.5652173913043478, 0.5296296296296297, 0.42, 1.0, 1.0, 0.6617962907725946, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3239265536834137, 0.3239265536834137, 0.35067529295641325], 
reward next is 0.6493, 
noisyNet noise sample is [array([0.28501487], dtype=float32), 0.44503558]. 
=============================================
[2019-03-23 22:17:57,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8950343e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:57,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3173
[2019-03-23 22:17:57,924] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 44.33333333333334, 1.0, 2.0, 0.3142627902018569, 1.0, 1.0, 0.3142627902018569, 1.0, 1.0, 0.5166085957717017, 6.9112, 6.9112, 121.94756008, 1158645.944227151, 1158645.944227151, 259972.721571719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1095000.0000, 
sim time next is 1095600.0000, 
raw observation next is [26.43333333333333, 44.66666666666667, 1.0, 2.0, 0.8782532939544612, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.914246843395814, 6.9112, 121.9259111735249, 1098867.254410285, 1097306.999949887, 216537.6131744974], 
processed observation next is [1.0, 0.6956521739130435, 0.5345679012345678, 0.4466666666666667, 1.0, 1.0, 0.8550634451838823, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0003046843395813958, 0.0, 0.809461256181037, 0.3924525908608161, 0.3918953571249596, 0.4164184868740335], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4226857], dtype=float32), 0.897882]. 
=============================================
[2019-03-23 22:17:58,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1827944e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:58,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3491
[2019-03-23 22:17:58,094] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 45.0, 1.0, 2.0, 0.6954023657833318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 880847.3473521969, 880847.3473521979, 178333.1044297551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1081800.0000, 
sim time next is 1082400.0000, 
raw observation next is [25.73333333333333, 44.33333333333333, 1.0, 2.0, 0.6367231581033033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806675.5395366829, 806675.5395366829, 167256.7702502885], 
processed observation next is [1.0, 0.5217391304347826, 0.5086419753086419, 0.4433333333333333, 1.0, 1.0, 0.5675275691705991, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28809840697738676, 0.28809840697738676, 0.3216476350967087], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.10595775], dtype=float32), -0.5376639]. 
=============================================
[2019-03-23 22:18:07,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.668468e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:18:07,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5833
[2019-03-23 22:18:07,230] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 64.5, 1.0, 2.0, 0.4120285502980475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506995.4315805744, 506995.4315805744, 130241.9676317489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1279800.0000, 
sim time next is 1280400.0000, 
raw observation next is [24.53333333333333, 65.33333333333333, 1.0, 2.0, 0.412211974875676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 507059.3239510685, 507059.323951068, 130264.0146332309], 
processed observation next is [1.0, 0.8260869565217391, 0.46419753086419746, 0.6533333333333333, 1.0, 1.0, 0.3002523510424715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18109261569681018, 0.18109261569680998, 0.25050772044852093], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.1654347], dtype=float32), -0.4462207]. 
=============================================
[2019-03-23 22:18:13,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1753986e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:18:13,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1850
[2019-03-23 22:18:13,363] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 67.0, 1.0, 2.0, 0.3365495966281851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425900.5294356198, 425900.5294356198, 120187.2632822076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1383600.0000, 
sim time next is 1384200.0000, 
raw observation next is [21.8, 67.0, 1.0, 2.0, 0.3336414516030382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422512.0950723681, 422512.0950723681, 119812.7683802453], 
processed observation next is [0.0, 0.0, 0.362962962962963, 0.67, 1.0, 1.0, 0.20671601381314073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15089717681156004, 0.15089717681156004, 0.2304091699620102], 
reward next is 0.7696, 
noisyNet noise sample is [array([-0.18019858], dtype=float32), -0.784091]. 
=============================================
[2019-03-23 22:18:21,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3398531e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:18:21,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-23 22:18:21,292] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.3, 23.5, 1.0, 2.0, 0.4151328433774259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510323.920576083, 510323.920576083, 130673.7403910202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1521000.0000, 
sim time next is 1521600.0000, 
raw observation next is [35.13333333333333, 24.66666666666667, 1.0, 2.0, 0.4151789534370213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508747.9055829988, 508747.9055829988, 130637.071002131], 
processed observation next is [0.0, 0.6086956521739131, 0.8567901234567901, 0.2466666666666667, 1.0, 1.0, 0.30378446837740636, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18169568056535673, 0.18169568056535673, 0.2512251365425596], 
reward next is 0.7488, 
noisyNet noise sample is [array([-1.2821342], dtype=float32), 1.106036]. 
=============================================
[2019-03-23 22:18:33,324] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.499161e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:18:33,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9300
[2019-03-23 22:18:33,338] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 70.0, 1.0, 2.0, 0.3418888471011343, 1.0, 1.0, 0.3418888471011343, 1.0, 1.0, 0.5506162263886438, 6.9112, 6.9112, 121.94756008, 1225106.652583557, 1225106.652583557, 272179.783543145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1764000.0000, 
sim time next is 1764600.0000, 
raw observation next is [24.11666666666667, 69.66666666666667, 1.0, 2.0, 0.9171293545809143, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.004556817241948, 6.9112, 121.925562942038, 1161870.770391995, 1114063.923905849, 224534.6526646428], 
processed observation next is [1.0, 0.43478260869565216, 0.44876543209876557, 0.6966666666666668, 1.0, 1.0, 0.9013444697391837, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.00933568172419479, 0.0, 0.8094589442860993, 0.41495384656856965, 0.3978799728235175, 0.4317974089704669], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1781491], dtype=float32), 1.4653817]. 
=============================================
[2019-03-23 22:18:38,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.485598e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:18:38,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7994
[2019-03-23 22:18:38,502] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.23333333333333, 82.33333333333334, 1.0, 2.0, 0.3586523463831733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451444.6773719257, 451444.6773719257, 123075.6441675862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1838400.0000, 
sim time next is 1839000.0000, 
raw observation next is [20.36666666666667, 81.66666666666666, 1.0, 2.0, 0.3586146710446833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451150.3303973478, 451150.3303973473, 123067.1620622136], 
processed observation next is [1.0, 0.2608695652173913, 0.3098765432098767, 0.8166666666666665, 1.0, 1.0, 0.23644603695795632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1611251179990528, 0.1611251179990526, 0.23666761935041075], 
reward next is 0.7633, 
noisyNet noise sample is [array([0.09456126], dtype=float32), 1.4285231]. 
=============================================
[2019-03-23 22:18:38,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.593575]
 [73.593575]
 [73.593575]
 [73.593575]
 [73.593575]], R is [[73.62097168]
 [73.64807892]
 [73.67378998]
 [73.69841766]
 [73.71923065]].
[2019-03-23 22:18:39,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3772347e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:18:39,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6229
[2019-03-23 22:18:39,835] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 90.33333333333334, 1.0, 2.0, 0.4237275688383195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519780.9215856869, 519780.9215856869, 131882.7723258742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1884000.0000, 
sim time next is 1884600.0000, 
raw observation next is [21.1, 90.5, 1.0, 2.0, 0.4232319930000827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519274.4318275136, 519274.4318275136, 131813.7474378971], 
processed observation next is [1.0, 0.8260869565217391, 0.3370370370370371, 0.905, 1.0, 1.0, 0.3133714202381937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18545515422411202, 0.18545515422411202, 0.2534879758421098], 
reward next is 0.7465, 
noisyNet noise sample is [array([-1.8527682], dtype=float32), 0.9833477]. 
=============================================
[2019-03-23 22:18:43,809] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 22:18:43,812] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:18:43,814] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:18:43,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:43,815] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:18:43,817] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:43,817] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:18:43,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:18:43,819] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:43,820] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:43,821] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:43,849] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 22:18:43,849] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 22:18:43,897] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 22:18:43,897] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 22:18:43,958] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 22:18:57,561] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:18:57,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.55044391333334, 33.68754735, 1.0, 2.0, 0.3420224853434279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 431964.7891642033, 431964.7891642028, 120891.5465413427]
[2019-03-23 22:18:57,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:18:57,566] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9442549263796917
[2019-03-23 22:18:57,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:18:57,575] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.33333333333334, 42.66666666666667, 1.0, 2.0, 0.3954039503796831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490352.4742866163, 490352.4742866163, 127983.1011797371]
[2019-03-23 22:18:57,576] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:18:57,580] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6710534364296687
[2019-03-23 22:19:09,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:19:09,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.69870777, 75.82326766666668, 1.0, 2.0, 0.3053372678550975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389483.4837352896, 389483.4837352896, 116236.6674593783]
[2019-03-23 22:19:09,708] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:19:09,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7040953400429679
[2019-03-23 22:19:40,905] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:19:40,907] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.56666666666666, 86.0, 1.0, 2.0, 0.6911635355096067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 787725.7326886469, 787725.7326886478, 174483.2460791588]
[2019-03-23 22:19:40,908] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:19:40,911] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8225623693772495
[2019-03-23 22:19:58,037] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:19:58,038] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.26666666666667, 50.0, 1.0, 2.0, 0.7897467266257425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1615237.812848408, 1615237.812848408, 334209.9734821811]
[2019-03-23 22:19:58,039] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:19:58,041] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.853863823203857
[2019-03-23 22:19:58,043] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1615237.812848408 W.
[2019-03-23 22:20:05,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:20:05,423] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.35, 84.5, 1.0, 2.0, 0.7385422535341732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841753.3646401901, 841753.3646401901, 183570.6212143395]
[2019-03-23 22:20:05,426] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:20:05,428] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8204154470170827
[2019-03-23 22:20:09,794] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:20:09,795] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.15085587, 91.45792754, 1.0, 2.0, 0.7038377246943021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802178.1868579162, 802178.1868579162, 176873.1291970561]
[2019-03-23 22:20:09,796] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:20:09,799] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.677984409927012
[2019-03-23 22:20:19,741] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7705446]
[2019-03-23 22:20:19,742] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.61666666666667, 68.0, 1.0, 2.0, 0.2843123564157625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363835.6423511341, 363835.6423511341, 113660.5333954424]
[2019-03-23 22:20:19,743] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:20:19,746] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6863886e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.317641218703415
[2019-03-23 22:20:25,490] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:20:25,535] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:20:25,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:20:25,564] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:20:25,700] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:20:26,717] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1325000, evaluation results [1325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:20:38,853] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.363439e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:20:38,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8763
[2019-03-23 22:20:38,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1604094.419262303 W.
[2019-03-23 22:20:38,875] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.45, 89.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.734746560400988, 6.9112, 121.9227228355241, 1604094.419262303, 1182376.455353444, 246671.015597291], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2190600.0000, 
sim time next is 2191200.0000, 
raw observation next is [24.43333333333333, 89.33333333333334, 1.0, 2.0, 0.6429271079965755, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9960146200960222, 6.9112, 6.9112, 121.9255466594163, 1449025.015828885, 1449025.015828885, 306858.1593453815], 
processed observation next is [1.0, 0.34782608695652173, 0.4604938271604937, 0.8933333333333334, 1.0, 1.0, 0.574913223805447, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9950182751200276, 0.0, 0.0, 0.809458836186424, 0.5175089342246018, 0.5175089342246018, 0.5901118448949644], 
reward next is 0.4099, 
noisyNet noise sample is [array([-1.1692066], dtype=float32), 0.76577115]. 
=============================================
[2019-03-23 22:20:45,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1261864e-22 1.0000000e+00 2.6812833e-34 1.1389298e-37 3.8862513e-37], sum to 1.0000
[2019-03-23 22:20:45,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1299
[2019-03-23 22:20:45,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 78.16666666666667, 1.0, 2.0, 0.5595134486156641, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8915797509090313, 6.911199999999999, 6.9112, 121.9260426156618, 1289794.558807742, 1289794.558807743, 278228.7788630956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2297400.0000, 
sim time next is 2298000.0000, 
raw observation next is [25.40000000000001, 77.33333333333334, 1.0, 2.0, 1.012389861025413, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.388441229628329, 6.9112, 121.92401521399, 1429680.012834394, 1185293.911678214, 245425.0220766473], 
processed observation next is [1.0, 0.6086956521739131, 0.4962962962962966, 0.7733333333333334, 1.0, 1.0, 1.014749834554063, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.047724122962832904, 0.0, 0.8094486689813843, 0.5106000045837121, 0.42331925417079075, 0.4719711963012448], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8734732], dtype=float32), 0.9618373]. 
=============================================
[2019-03-23 22:20:45,071] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[47.71758]
 [47.71758]
 [47.71758]
 [47.71758]
 [47.71758]], R is [[47.24040222]
 [47.23294067]
 [46.76061249]
 [46.2930069 ]
 [45.83007812]].
[2019-03-23 22:20:46,891] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.389993e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:20:46,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1833
[2019-03-23 22:20:46,904] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.98333333333333, 95.16666666666667, 1.0, 2.0, 0.6879333448862882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823968.0027519426, 823968.0027519426, 175662.571377764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340600.0000, 
sim time next is 2341200.0000, 
raw observation next is [21.96666666666667, 95.33333333333334, 1.0, 2.0, 0.5762303466377764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690029.2884244634, 690029.2884244634, 155485.0879480663], 
processed observation next is [1.0, 0.08695652173913043, 0.36913580246913585, 0.9533333333333335, 1.0, 1.0, 0.4955123174259243, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24643903158016547, 0.24643903158016547, 0.29900978451551213], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.43622708], dtype=float32), 1.4546119]. 
=============================================
[2019-03-23 22:20:48,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.710199e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:20:48,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-23 22:20:48,597] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 39.16666666666666, 1.0, 2.0, 0.9245395731856912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.179670231185129, 6.9112, 121.9247225073102, 1284035.967230486, 1146556.701787861, 226992.4929442511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2371800.0000, 
sim time next is 2372400.0000, 
raw observation next is [29.3, 39.0, 1.0, 2.0, 0.9459526090099009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.319730257232711, 6.9112, 121.924120252041, 1381745.807083757, 1172545.099804116, 232030.4339397342], 
processed observation next is [1.0, 0.4782608695652174, 0.6407407407407407, 0.39, 1.0, 1.0, 0.9356578678689296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04085302572327114, 0.0, 0.8094493663248111, 0.49348064538705605, 0.4187661070728986, 0.44621237296102734], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9600064], dtype=float32), 0.6944609]. 
=============================================
[2019-03-23 22:20:56,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.167314e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:20:56,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6856
[2019-03-23 22:20:56,084] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 52.00000000000001, 1.0, 2.0, 0.3740782967175675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466789.5037554429, 466789.5037554429, 125095.2281408949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2510400.0000, 
sim time next is 2511000.0000, 
raw observation next is [25.7, 52.5, 1.0, 2.0, 0.3740608859485603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466770.3559294539, 466770.3559294543, 125092.9007008643], 
processed observation next is [1.0, 0.043478260869565216, 0.5074074074074074, 0.525, 1.0, 1.0, 0.2548343880340004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16670369854623354, 0.16670369854623368, 0.24056327057858518], 
reward next is 0.7594, 
noisyNet noise sample is [array([0.5362189], dtype=float32), -1.309493]. 
=============================================
[2019-03-23 22:20:56,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.287384]
 [68.287384]
 [68.287384]
 [68.287384]
 [68.287384]], R is [[68.36394501]
 [68.43973541]
 [68.51461792]
 [68.58843231]
 [68.66105652]].
[2019-03-23 22:21:03,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2107484e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:21:03,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5855
[2019-03-23 22:21:03,378] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1627618.993982028 W.
[2019-03-23 22:21:03,385] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.95, 35.0, 1.0, 2.0, 0.7728514659304362, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9696732841416168, 6.911200000000001, 6.9112, 121.9260426156618, 1627618.993982028, 1627618.993982028, 325337.7858230755], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3151800.0000, 
sim time next is 3152400.0000, 
raw observation next is [32.96666666666667, 36.0, 1.0, 2.0, 0.5042221201737712, 1.0, 1.0, 0.5042221201737712, 1.0, 2.0, 0.803387539238301, 6.911200000000001, 6.9112, 121.94756008, 1742485.03567661, 1742485.03567661, 345765.6829591404], 
processed observation next is [1.0, 0.4782608695652174, 0.7765432098765432, 0.36, 1.0, 1.0, 0.4097882383021086, 1.0, 0.5, 0.4097882383021086, 1.0, 1.0, 0.7542344240478762, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6223160841702179, 0.6223160841702179, 0.6649340056906546], 
reward next is 0.3351, 
noisyNet noise sample is [array([-1.4132754], dtype=float32), -0.3847263]. 
=============================================
[2019-03-23 22:21:16,888] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 22:21:16,890] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:21:16,890] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:21:16,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:21:16,891] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:21:16,891] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:21:16,891] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:21:16,892] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:21:16,893] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:21:16,894] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:21:16,897] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:21:16,916] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 22:21:16,916] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 22:21:16,962] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 22:21:16,987] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 22:21:17,014] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 22:21:27,500] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:21:27,501] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.7, 52.0, 1.0, 2.0, 0.2477333763220718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 319554.13205479, 319554.13205479, 102748.6182433042]
[2019-03-23 22:21:27,502] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:21:27,507] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5225968955579465
[2019-03-23 22:21:33,782] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:21:33,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.37743040666667, 60.57291834833334, 1.0, 2.0, 0.2554761548494252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 329543.7768048043, 329543.7768048043, 91118.1052745665]
[2019-03-23 22:21:33,786] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:21:33,789] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.08996007261697281
[2019-03-23 22:21:46,368] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:21:46,369] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.1, 90.0, 1.0, 2.0, 0.3364580859870697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424346.304162466, 424346.304162466, 120159.1798113615]
[2019-03-23 22:21:46,371] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:21:46,373] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5610023687108586
[2019-03-23 22:21:53,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:21:53,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.33333333333334, 64.66666666666667, 1.0, 2.0, 0.6272119009908014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714805.4552932412, 714805.4552932412, 162821.7023460483]
[2019-03-23 22:21:53,957] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:21:53,960] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8778161851311617
[2019-03-23 22:22:22,860] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:22:22,861] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.53856403, 98.70459011666667, 1.0, 2.0, 0.5794464449967938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668181.1166819007, 668181.1166819007, 154959.1860220844]
[2019-03-23 22:22:22,863] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:22:22,866] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6659948259895441
[2019-03-23 22:22:28,732] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:22:28,735] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.46666666666667, 76.33333333333334, 1.0, 2.0, 0.5923617382516492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684314.1981481357, 684314.1981481357, 157215.8709042503]
[2019-03-23 22:22:28,736] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:22:28,738] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6988785790294844
[2019-03-23 22:22:37,649] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:22:37,650] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.64507635333334, 74.36004501000001, 1.0, 2.0, 0.6983687209076223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795941.8155166053, 795941.8155166048, 175836.429358624]
[2019-03-23 22:22:37,651] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:22:37,653] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.96230715979509
[2019-03-23 22:22:39,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:22:39,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.21059364166667, 50.79885937333333, 1.0, 2.0, 0.4802356356575171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581498.2063150575, 581498.2063150575, 140123.2535297296]
[2019-03-23 22:22:39,025] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:22:39,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7906406235205943
[2019-03-23 22:22:56,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9403091]
[2019-03-23 22:22:56,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.02216364666667, 37.33439076, 1.0, 2.0, 0.8841205276785302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.927692758228845, 6.9112, 121.9258925594748, 1108247.52091278, 1099801.764987938, 217759.2341540598]
[2019-03-23 22:22:56,862] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:22:56,865] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.334965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8249595864388536
[2019-03-23 22:22:58,240] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:22:58,625] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:22:58,655] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:22:58,755] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:22:58,884] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:22:59,901] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1350000, evaluation results [1350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:23:05,279] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6313673e-18 1.0000000e+00 5.7031860e-28 2.9649515e-30 1.4596055e-30], sum to 1.0000
[2019-03-23 22:23:05,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3664
[2019-03-23 22:23:05,289] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7180946563233842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 818435.7774468975, 818435.7774468984, 179599.8971846747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3006000.0000, 
sim time next is 3006600.0000, 
raw observation next is [26.08333333333334, 92.33333333333334, 1.0, 2.0, 0.7147128781689868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814579.4070225364, 814579.4070225364, 178949.3707319259], 
processed observation next is [1.0, 0.8260869565217391, 0.5216049382716051, 0.9233333333333335, 1.0, 1.0, 0.6603724740106985, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.290921216793763, 0.290921216793763, 0.3441334052537037], 
reward next is 0.6559, 
noisyNet noise sample is [array([0.8337963], dtype=float32), 0.19596063]. 
=============================================
[2019-03-23 22:23:05,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0045135e-17 1.0000000e+00 5.1466885e-26 4.6828919e-28 1.7391015e-28], sum to 1.0000
[2019-03-23 22:23:05,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-23 22:23:05,627] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 100.0, 1.0, 2.0, 0.5455099765724837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643149.7612290598, 643149.7612290598, 149935.7355840038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3048000.0000, 
sim time next is 3048600.0000, 
raw observation next is [22.66666666666667, 100.0, 1.0, 2.0, 0.5544043391876251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649257.364330415, 649257.364330415, 151223.0767954571], 
processed observation next is [1.0, 0.2608695652173913, 0.39506172839506193, 1.0, 1.0, 1.0, 0.4695289752233632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23187763011800536, 0.23187763011800536, 0.2908136092220329], 
reward next is 0.7092, 
noisyNet noise sample is [array([0.12090277], dtype=float32), -2.2493432]. 
=============================================
[2019-03-23 22:23:10,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.38901125e-19 1.00000000e+00 2.83729165e-31 1.24274861e-33
 1.30659935e-33], sum to 1.0000
[2019-03-23 22:23:10,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1002
[2019-03-23 22:23:10,051] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 78.66666666666667, 1.0, 2.0, 0.732242935850536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834569.8098274067, 834569.8098274067, 182345.9201613894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087600.0000, 
sim time next is 3088200.0000, 
raw observation next is [29.7, 76.83333333333333, 1.0, 2.0, 0.7470198366651731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851421.0549589035, 851421.0549589035, 185244.3539856439], 
processed observation next is [1.0, 0.7391304347826086, 0.6555555555555556, 0.7683333333333333, 1.0, 1.0, 0.6988331388871108, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3040789481996084, 0.3040789481996084, 0.3562391422800844], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.5936049], dtype=float32), 0.29999483]. 
=============================================
[2019-03-23 22:23:11,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3101977e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:23:11,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7182
[2019-03-23 22:23:11,608] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 63.33333333333334, 1.0, 2.0, 0.6235041777034367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715176.2322249399, 715176.2322249399, 162395.0555186931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3100800.0000, 
sim time next is 3101400.0000, 
raw observation next is [29.0, 62.0, 1.0, 2.0, 0.60747021360841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700300.4287062406, 700300.4287062406, 159757.2035214588], 
processed observation next is [1.0, 0.9130434782608695, 0.6296296296296297, 0.62, 1.0, 1.0, 0.5327026352481071, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2501072959665145, 0.2501072959665145, 0.3072253913874208], 
reward next is 0.6928, 
noisyNet noise sample is [array([1.4710441], dtype=float32), 0.493757]. 
=============================================
[2019-03-23 22:23:18,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4478123e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:23:18,194] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1968
[2019-03-23 22:23:18,203] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.498524497325872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595452.6286057978, 595452.6286057982, 142694.9802678739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3230400.0000, 
sim time next is 3231000.0000, 
raw observation next is [27.5, 60.0, 1.0, 2.0, 0.5004242934435484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597322.828683481, 597322.828683481, 142978.815413227], 
processed observation next is [0.0, 0.391304347826087, 0.5740740740740741, 0.6, 1.0, 1.0, 0.4052670160042243, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21332958167267177, 0.21332958167267177, 0.274959260410052], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.52390915], dtype=float32), 0.15159127]. 
=============================================
[2019-03-23 22:23:18,225] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.34046]
 [69.34046]
 [69.34046]
 [69.34046]
 [69.34046]], R is [[69.37210846]
 [69.40397644]
 [69.436203  ]
 [69.4693222 ]
 [69.50457764]].
[2019-03-23 22:23:18,295] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.492379e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:23:18,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2847
[2019-03-23 22:23:18,308] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 45.66666666666666, 1.0, 2.0, 0.534827068309566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630648.936660699, 630648.936660699, 148191.5234827288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3248400.0000, 
sim time next is 3249000.0000, 
raw observation next is [31.5, 44.5, 1.0, 2.0, 0.530535646588999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626846.2067352091, 626846.2067352091, 147545.7643708859], 
processed observation next is [0.0, 0.6086956521739131, 0.7222222222222222, 0.445, 1.0, 1.0, 0.4411138649869035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22387364526257467, 0.22387364526257467, 0.283741854559396], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.81741047], dtype=float32), 2.0480762]. 
=============================================
[2019-03-23 22:23:18,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.03866]
 [68.03866]
 [68.03866]
 [68.03866]
 [68.03866]], R is [[68.07452393]
 [68.10879517]
 [68.14170837]
 [68.17391205]
 [68.20690155]].
[2019-03-23 22:23:28,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2738105e-21 1.0000000e+00 3.5181554e-33 1.0067488e-36 7.8637853e-36], sum to 1.0000
[2019-03-23 22:23:28,098] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3377
[2019-03-23 22:23:28,102] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.6669696433266434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760138.0484584371, 760138.0484584371, 169986.7445992983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3434400.0000, 
sim time next is 3435000.0000, 
raw observation next is [29.66666666666666, 68.16666666666667, 1.0, 2.0, 0.6796153128475105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774557.4621817714, 774557.4621817714, 172322.1329161257], 
processed observation next is [1.0, 0.782608695652174, 0.6543209876543208, 0.6816666666666668, 1.0, 1.0, 0.6185896581517982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27662766506491837, 0.27662766506491837, 0.33138871714639556], 
reward next is 0.6686, 
noisyNet noise sample is [array([-0.52695596], dtype=float32), 0.14200027]. 
=============================================
[2019-03-23 22:23:28,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[46.299942]
 [46.299942]
 [46.299942]
 [46.299942]
 [46.299942]], R is [[46.5055542 ]
 [46.71360397]
 [46.92427444]
 [47.13737869]
 [47.35154343]].
[2019-03-23 22:23:38,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6139508e-20 1.0000000e+00 1.1094900e-31 8.0200554e-34 2.0953990e-34], sum to 1.0000
[2019-03-23 22:23:38,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-23 22:23:38,137] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.66666666666667, 1.0, 2.0, 0.5802899139998906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687709.3409518662, 687709.3409518662, 155906.5039325657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3651600.0000, 
sim time next is 3652200.0000, 
raw observation next is [22.0, 99.5, 1.0, 2.0, 0.5732787669761643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679696.7373171429, 679696.7373171429, 154724.3203862602], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.995, 1.0, 1.0, 0.4919985321144813, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24274883475612247, 0.24274883475612247, 0.2975467699735773], 
reward next is 0.7025, 
noisyNet noise sample is [array([-1.3516259], dtype=float32), 0.45367935]. 
=============================================
[2019-03-23 22:23:45,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3000048e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:23:45,256] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1762
[2019-03-23 22:23:45,264] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 99.0, 1.0, 2.0, 0.7198645809294398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820454.0976175911, 820454.0976175911, 179934.7794025377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3735000.0000, 
sim time next is 3735600.0000, 
raw observation next is [24.13333333333333, 99.33333333333333, 1.0, 2.0, 0.7064567375206022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805164.6969128795, 805164.6969128795, 177366.2212870654], 
processed observation next is [1.0, 0.21739130434782608, 0.44938271604938257, 0.9933333333333333, 1.0, 1.0, 0.6505437351435741, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28755882032602836, 0.28755882032602836, 0.3410888870905104], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.7903871], dtype=float32), -0.7329025]. 
=============================================
[2019-03-23 22:23:46,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8226265e-22 1.0000000e+00 2.0899706e-34 0.0000000e+00 7.7714237e-37], sum to 1.0000
[2019-03-23 22:23:46,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4028
[2019-03-23 22:23:46,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1626330.634549357 W.
[2019-03-23 22:23:46,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 94.0, 1.0, 2.0, 0.4753984123347514, 1.0, 1.0, 0.4753984123347514, 1.0, 2.0, 0.7568497550823143, 6.911200000000001, 6.9112, 121.94756008, 1626330.634549357, 1626330.634549357, 331678.4766072875], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.7506644138166236, 1.0, 2.0, 0.7506644138166236, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1712089.959488586, 1712089.959488587, 323790.8814568204], 
processed observation next is [1.0, 0.391304347826087, 0.5370370370370371, 0.94, 1.0, 1.0, 0.7031719212102662, 1.0, 1.0, 0.7031719212102662, 0.0, 0.5, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.6114606998173522, 0.6114606998173525, 0.6226747720323469], 
reward next is 0.3773, 
noisyNet noise sample is [array([-0.5142764], dtype=float32), 0.6225879]. 
=============================================
[2019-03-23 22:23:46,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3627894e-19 1.0000000e+00 3.2466486e-31 1.2401399e-32 6.3244535e-33], sum to 1.0000
[2019-03-23 22:23:47,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5788
[2019-03-23 22:23:47,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2194059.801707331 W.
[2019-03-23 22:23:47,024] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.65, 78.0, 1.0, 2.0, 0.6555701910076769, 1.0, 2.0, 0.6411497574802733, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2194059.801707331, 2194059.801707331, 417514.4120379385], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3756600.0000, 
sim time next is 3757200.0000, 
raw observation next is [29.76666666666667, 78.33333333333333, 1.0, 2.0, 0.6195474786088329, 1.0, 2.0, 0.6195474786088329, 1.0, 2.0, 0.9863397631979929, 6.9112, 6.9112, 121.94756008, 2120047.52766223, 2120047.52766223, 406128.8875224986], 
processed observation next is [1.0, 0.4782608695652174, 0.6580246913580248, 0.7833333333333333, 1.0, 1.0, 0.547080331677182, 1.0, 1.0, 0.547080331677182, 1.0, 1.0, 0.9829247039974911, 0.0, 0.0, 0.8096049824067558, 0.7571598313079394, 0.7571598313079394, 0.7810170913894204], 
reward next is 0.2190, 
noisyNet noise sample is [array([-0.54138166], dtype=float32), 0.97883034]. 
=============================================
[2019-03-23 22:23:48,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.744667e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:23:48,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7686
[2019-03-23 22:23:48,683] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.7, 52.0, 1.0, 2.0, 0.6568196522778167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748564.5656552116, 748564.5656552116, 168131.3968645958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3843000.0000, 
sim time next is 3843600.0000, 
raw observation next is [32.8, 54.33333333333333, 1.0, 2.0, 0.6858853085541327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781707.0191135512, 781707.0191135512, 173491.6074656623], 
processed observation next is [0.0, 0.4782608695652174, 0.7703703703703703, 0.5433333333333333, 1.0, 1.0, 0.6260539387549198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27918107825483973, 0.27918107825483973, 0.3336377066647352], 
reward next is 0.6664, 
noisyNet noise sample is [array([0.33367056], dtype=float32), -0.25643066]. 
=============================================
[2019-03-23 22:23:50,066] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 22:23:50,068] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:23:50,068] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:23:50,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:50,070] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:23:50,070] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:23:50,071] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:50,071] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:50,071] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:23:50,072] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:50,076] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:50,103] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 22:23:50,104] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 22:23:50,126] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 22:23:50,183] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 22:23:50,208] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 22:24:05,272] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3087947]
[2019-03-23 22:24:05,274] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.90209794666667, 60.49739217666667, 1.0, 2.0, 0.3196662645526747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405152.9756982283, 405152.9756982279, 118023.9581516221]
[2019-03-23 22:24:05,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:24:05,281] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.208642e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.061691274732771806
[2019-03-23 22:24:47,131] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3087947]
[2019-03-23 22:24:47,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.95212945, 77.90461087166668, 1.0, 2.0, 0.7412058850867761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906978.9690544022, 906978.9690544022, 186720.9465601741]
[2019-03-23 22:24:47,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:24:47,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.208642e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.17886870100401986
[2019-03-23 22:24:50,306] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3087947]
[2019-03-23 22:24:50,307] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.53333333333333, 59.0, 1.0, 2.0, 0.5817475833562563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672832.1059404433, 672832.1059404433, 155441.6561390012]
[2019-03-23 22:24:50,308] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:24:50,311] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.208642e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.05174439912552842
[2019-03-23 22:25:24,250] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3087947]
[2019-03-23 22:25:24,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.32766121, 89.60494896, 1.0, 2.0, 0.4690216003842177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564194.5508548886, 564194.5508548886, 138281.4732926253]
[2019-03-23 22:25:24,254] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:25:24,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.208642e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9184188273852006
[2019-03-23 22:25:31,571] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:25:31,750] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:25:31,830] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:25:31,837] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:25:32,021] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:25:33,037] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1375000, evaluation results [1375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:25:37,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6196053e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:25:37,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6326
[2019-03-23 22:25:37,830] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7271866314658577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828803.7991768759, 828803.7991768759, 181356.499783127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3909600.0000, 
sim time next is 3910200.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.7297302374155257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831704.4219371504, 831704.4219371504, 181850.5024717706], 
processed observation next is [0.0, 0.2608695652173913, 0.5185185185185185, 0.9400000000000002, 1.0, 1.0, 0.6782502826375305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2970372935489823, 0.2970372935489823, 0.349712504753405], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.00286224], dtype=float32), 0.120182686]. 
=============================================
[2019-03-23 22:25:43,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3351267e-19 1.0000000e+00 9.1636123e-30 5.4753397e-34 1.0918009e-32], sum to 1.0000
[2019-03-23 22:25:43,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8766
[2019-03-23 22:25:43,156] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.58333333333333, 95.83333333333334, 1.0, 2.0, 0.4356136567447474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533543.0486959536, 533543.0486959536, 133594.1681586828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4067400.0000, 
sim time next is 4068000.0000, 
raw observation next is [20.7, 95.0, 1.0, 2.0, 0.4356081159735787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533378.8401937499, 533378.8401937499, 133589.0339948165], 
processed observation next is [1.0, 0.08695652173913043, 0.3222222222222222, 0.95, 1.0, 1.0, 0.3281048999685461, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19049244292633924, 0.19049244292633924, 0.2569019884515702], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.93053526], dtype=float32), -0.30908096]. 
=============================================
[2019-03-23 22:25:43,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[42.99135]
 [42.99135]
 [42.99135]
 [42.99135]
 [42.99135]], R is [[43.30452728]
 [43.61457062]
 [43.92159653]
 [44.22577286]
 [44.52708435]].
[2019-03-23 22:25:47,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0182508e-21 1.0000000e+00 3.3796620e-33 1.9071594e-37 4.4222509e-37], sum to 1.0000
[2019-03-23 22:25:47,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0522
[2019-03-23 22:25:47,819] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.6313478390641286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762228.7486964829, 762228.7486964824, 165384.284548989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4086000.0000, 
sim time next is 4086600.0000, 
raw observation next is [21.28333333333333, 97.33333333333334, 1.0, 2.0, 0.5796742187276378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699492.2599861135, 699492.2599861135, 156261.6901607243], 
processed observation next is [1.0, 0.30434782608695654, 0.3438271604938271, 0.9733333333333334, 1.0, 1.0, 0.4996121651519497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24981866428075483, 0.24981866428075483, 0.3005032503090852], 
reward next is 0.6995, 
noisyNet noise sample is [array([-0.19405667], dtype=float32), -0.40212402]. 
=============================================
[2019-03-23 22:26:00,854] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.968953e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:26:00,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1868
[2019-03-23 22:26:00,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1625632.887789285 W.
[2019-03-23 22:26:00,875] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.66666666666667, 61.0, 1.0, 2.0, 0.7127918410186121, 1.0, 2.0, 0.7127918410186121, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1625632.887789285, 1625632.887789284, 309036.2633659317], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [31.0, 60.5, 1.0, 2.0, 0.7337143812691331, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1551283.05857156, 1551283.058571561, 323443.7196263642], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.605, 1.0, 1.0, 0.6829933110346823, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5540296637755572, 0.5540296637755575, 0.6220071531276234], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23874559], dtype=float32), 1.1561677]. 
=============================================
[2019-03-23 22:26:00,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.33887]
 [66.33887]
 [66.33887]
 [66.33887]
 [66.33887]], R is [[65.67547607]
 [65.42442322]
 [65.02832794]
 [64.63189697]
 [64.22078705]].
[2019-03-23 22:26:17,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1104068e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:26:17,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5217
[2019-03-23 22:26:17,954] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.5, 1.0, 2.0, 0.6647910966818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757653.9554678148, 757653.9554678148, 169584.2214464859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671000.0000, 
sim time next is 4671600.0000, 
raw observation next is [24.86666666666667, 94.66666666666666, 1.0, 2.0, 0.6635041865116785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756186.5568692551, 756186.5568692551, 169348.5695985363], 
processed observation next is [1.0, 0.043478260869565216, 0.47654320987654336, 0.9466666666666665, 1.0, 1.0, 0.5994097458472363, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2700666274533054, 0.2700666274533054, 0.32567032615103136], 
reward next is 0.6743, 
noisyNet noise sample is [array([0.97607905], dtype=float32), 1.4752296]. 
=============================================
[2019-03-23 22:26:18,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0296184e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:26:18,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3243
[2019-03-23 22:26:18,429] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6648746103903599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757749.1820240607, 757749.1820240607, 169599.6906452617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4667400.0000, 
sim time next is 4668000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6657908827654112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758793.9629268016, 758793.9629268016, 169767.6205528828], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6021320032921562, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27099784390242915, 0.27099784390242915, 0.3264761933709285], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.1448449], dtype=float32), -1.1792607]. 
=============================================
[2019-03-23 22:26:18,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.67126]
 [63.67126]
 [63.67126]
 [63.67126]
 [63.67126]], R is [[63.70806885]
 [63.7448349 ]
 [63.78138351]
 [63.81752777]
 [63.85336685]].
[2019-03-23 22:26:20,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2170346e-18 1.0000000e+00 2.7199117e-29 1.0205439e-31 1.1232108e-31], sum to 1.0000
[2019-03-23 22:26:20,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3015
[2019-03-23 22:26:20,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1957030.680145821 W.
[2019-03-23 22:26:20,897] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.13333333333334, 83.16666666666667, 1.0, 2.0, 0.5719607398889587, 1.0, 2.0, 0.5719607398889587, 1.0, 2.0, 0.9105801253640696, 6.911199999999999, 6.9112, 121.94756008, 1957030.680145821, 1957030.680145821, 380310.1446591352], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4723800.0000, 
sim time next is 4724400.0000, 
raw observation next is [28.26666666666667, 82.33333333333334, 1.0, 2.0, 0.4995997431873929, 1.0, 2.0, 0.4995997431873929, 1.0, 2.0, 0.7953790619820394, 6.911199999999999, 6.9112, 121.94756008, 1709202.200497985, 1709202.200497985, 343392.62777688], 
processed observation next is [1.0, 0.6956521739130435, 0.6024691358024692, 0.8233333333333335, 1.0, 1.0, 0.4042854085564202, 1.0, 1.0, 0.4042854085564202, 1.0, 1.0, 0.7442238274775492, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6104293573207089, 0.6104293573207089, 0.6603704380324615], 
reward next is 0.3396, 
noisyNet noise sample is [array([-0.06787499], dtype=float32), -0.5365191]. 
=============================================
[2019-03-23 22:26:23,053] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:26:23,057] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:26:23,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:26:23,062] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:26:23,063] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:26:23,064] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:26:23,064] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:26:23,066] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:26:23,065] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:26:23,068] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:26:23,069] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:26:23,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 22:26:23,116] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 22:26:23,116] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 22:26:23,141] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 22:26:23,190] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 22:26:46,954] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:26:46,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 32.0, 1.0, 2.0, 0.4817725779322485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592907.1553139251, 592907.1553139251, 140636.380022425]
[2019-03-23 22:26:46,957] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:26:46,960] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.19029973957942803
[2019-03-23 22:26:49,073] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:26:49,075] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.03333333333333, 80.66666666666666, 1.0, 2.0, 0.4070973839944517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502283.2650903771, 502283.2650903771, 129573.8814376331]
[2019-03-23 22:26:49,076] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:26:49,078] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3816328008438101
[2019-03-23 22:27:33,134] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:27:33,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.93333333333334, 58.66666666666667, 1.0, 2.0, 0.5070200466206108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603532.4502619045, 603532.4502619045, 143957.8609412731]
[2019-03-23 22:27:33,136] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:27:33,139] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8488188540856939
[2019-03-23 22:27:46,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:27:46,562] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.75, 91.5, 1.0, 2.0, 0.4997212545094458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595163.5539853597, 595163.5539853597, 142819.381882642]
[2019-03-23 22:27:46,562] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:27:46,564] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9047386425784174
[2019-03-23 22:27:53,721] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:27:53,725] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.5279388831178949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622047.2864941449, 622047.2864941445, 147056.0015275742]
[2019-03-23 22:27:53,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:27:53,730] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5217974212717926
[2019-03-23 22:27:58,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:27:58,854] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.65926717333333, 103.748602065, 1.0, 2.0, 0.3671441837700798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 459120.0466144194, 459120.046614419, 124171.3100623886]
[2019-03-23 22:27:58,855] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:27:58,860] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.030041725572348077
[2019-03-23 22:28:03,014] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1727664]
[2019-03-23 22:28:03,015] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.35212809666666, 57.27884554333333, 1.0, 2.0, 0.9228915387190383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.918935269242491, 6.9112, 121.9260151372437, 1102137.681819883, 1098176.533489931, 224961.2872040269]
[2019-03-23 22:28:03,018] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:28:03,021] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.950751e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.813626215205819
[2019-03-23 22:28:04,231] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:28:04,372] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:28:04,712] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:28:04,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:28:04,863] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:28:05,877] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1400000, evaluation results [1400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:28:06,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1862194e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:06,110] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0073
[2019-03-23 22:28:06,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 93.66666666666667, 1.0, 2.0, 0.601154174279258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 693891.905055628, 693891.9050556276, 158703.2067515549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4756200.0000, 
sim time next is 4756800.0000, 
raw observation next is [24.06666666666667, 93.33333333333334, 1.0, 2.0, 0.5991566582037656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691757.3930729034, 691757.3930729034, 158366.0853529192], 
processed observation next is [1.0, 0.043478260869565216, 0.4469135802469137, 0.9333333333333335, 1.0, 1.0, 0.5228055454806734, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24705621181175122, 0.24705621181175122, 0.30455016414022923], 
reward next is 0.6954, 
noisyNet noise sample is [array([1.5306638], dtype=float32), -0.936742]. 
=============================================
[2019-03-23 22:28:16,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1437802e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:16,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3185
[2019-03-23 22:28:16,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1514122.450529583 W.
[2019-03-23 22:28:16,996] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6639433923450412, 1.0, 1.0, 0.6639433923450412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.925076047097, 1514122.450529583, 1514122.450529583, 290739.2980905004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4958400.0000, 
sim time next is 4959000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6155427462815052, 1.0, 2.0, 0.6155427462815052, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.926042320915, 1403643.645829387, 1403643.645829387, 273427.320290802], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5423127931922681, 1.0, 1.0, 0.5423127931922681, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621268633237, 0.5013013020819239, 0.5013013020819239, 0.5258217697900038], 
reward next is 0.4742, 
noisyNet noise sample is [array([-1.2214675], dtype=float32), -0.8477705]. 
=============================================
[2019-03-23 22:28:17,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[61.801132]
 [61.801132]
 [61.801132]
 [61.801132]
 [61.801132]], R is [[61.65729904]
 [61.04072571]
 [60.43032074]
 [60.27998352]
 [60.13979721]].
[2019-03-23 22:28:22,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.955417e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:28:22,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9052
[2019-03-23 22:28:22,051] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 78.33333333333334, 1.0, 2.0, 0.7992313664056755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 910964.8759796886, 910964.8759796881, 195791.6165877117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5055000.0000, 
sim time next is 5055600.0000, 
raw observation next is [30.0, 77.66666666666667, 1.0, 2.0, 0.8166722960570594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930856.1417673173, 930856.1417673173, 199418.4605122858], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.7766666666666667, 1.0, 1.0, 0.7817527334012612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33244862205975617, 0.33244862205975617, 0.38349703944670344], 
reward next is 0.6165, 
noisyNet noise sample is [array([0.662623], dtype=float32), 1.7611309]. 
=============================================
[2019-03-23 22:28:25,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1543614e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:25,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6143
[2019-03-23 22:28:25,556] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.7129400595417431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812557.8021759657, 812557.8021759657, 178609.0805670461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5112000.0000, 
sim time next is 5112600.0000, 
raw observation next is [24.96666666666667, 99.66666666666667, 1.0, 2.0, 0.710499611697434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 809774.8859480429, 809774.8859480424, 178141.7645139608], 
processed observation next is [0.0, 0.17391304347826086, 0.48024691358024696, 0.9966666666666667, 1.0, 1.0, 0.6553566805921833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2892053164100153, 0.2892053164100151, 0.34258031637300157], 
reward next is 0.6574, 
noisyNet noise sample is [array([-0.81203634], dtype=float32), -0.2531839]. 
=============================================
[2019-03-23 22:28:34,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1955737e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:34,909] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0014
[2019-03-23 22:28:34,917] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 87.0, 1.0, 2.0, 0.8647534086429418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156448, 1030006.93003045, 1030006.930030449, 211850.1280128793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5304600.0000, 
sim time next is 5305200.0000, 
raw observation next is [23.46666666666667, 86.33333333333334, 1.0, 2.0, 0.9500595832733603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.091985566990326, 6.9112, 121.9253596617677, 1222863.673320566, 1130285.823157367, 231298.5008273046], 
processed observation next is [1.0, 0.391304347826087, 0.42469135802469143, 0.8633333333333334, 1.0, 1.0, 0.9405471229444765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.018078556699032598, 0.0, 0.8094575947165011, 0.4367370261859165, 0.40367350827048826, 0.4448048092832781], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00489325], dtype=float32), -1.7005525]. 
=============================================
[2019-03-23 22:28:37,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7736136e-19 1.0000000e+00 5.2229821e-30 4.3204773e-33 1.6912466e-32], sum to 1.0000
[2019-03-23 22:28:37,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0198
[2019-03-23 22:28:37,108] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 76.0, 1.0, 2.0, 0.6211976482652297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711770.4260914836, 711770.4260914836, 161951.5715912486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5349600.0000, 
sim time next is 5350200.0000, 
raw observation next is [26.81666666666667, 76.5, 1.0, 2.0, 0.6209874779525661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711693.8402046094, 711693.8402046094, 161922.6856383289], 
processed observation next is [1.0, 0.9565217391304348, 0.5487654320987656, 0.765, 1.0, 1.0, 0.5487946166101978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25417637150164624, 0.25417637150164624, 0.31138978007370943], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.16512287], dtype=float32), -0.63678247]. 
=============================================
[2019-03-23 22:28:41,696] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5554364e-17 1.0000000e+00 4.3969909e-27 4.5738345e-29 4.4782223e-29], sum to 1.0000
[2019-03-23 22:28:41,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8365
[2019-03-23 22:28:41,711] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 84.0, 1.0, 2.0, 0.783239923578256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892727.1940942667, 892727.1940942667, 192507.5156436846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5432400.0000, 
sim time next is 5433000.0000, 
raw observation next is [28.23333333333333, 84.33333333333333, 1.0, 2.0, 0.7840229331145561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 893620.1790110203, 893620.1790110199, 192666.9824748277], 
processed observation next is [1.0, 0.9130434782608695, 0.6012345679012344, 0.8433333333333333, 1.0, 1.0, 0.7428844441839954, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3191500639325073, 0.3191500639325071, 0.3705134278362071], 
reward next is 0.6295, 
noisyNet noise sample is [array([-0.84040195], dtype=float32), 0.3351972]. 
=============================================
[2019-03-23 22:28:41,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[37.679214]
 [37.679214]
 [37.679214]
 [37.679214]
 [37.679214]], R is [[37.93190765]
 [38.18238449]
 [38.4313736 ]
 [38.67907715]
 [38.9253273 ]].
[2019-03-23 22:28:46,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6320176e-18 1.0000000e+00 1.5015409e-27 4.6335740e-31 4.1160821e-30], sum to 1.0000
[2019-03-23 22:28:46,368] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2345
[2019-03-23 22:28:46,372] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 88.0, 1.0, 2.0, 0.6748170602792001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769086.1510216102, 769086.1510216102, 171430.7294077771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5523600.0000, 
sim time next is 5524200.0000, 
raw observation next is [26.0, 88.5, 1.0, 2.0, 0.6767768588703053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771320.8489896905, 771320.848989691, 171793.6432992636], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.885, 1.0, 1.0, 0.6152105462741729, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2754717317820323, 0.2754717317820325, 0.33037239096012233], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.3885054], dtype=float32), -1.8643974]. 
=============================================
[2019-03-23 22:28:49,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7394471e-20 1.0000000e+00 2.5448711e-34 9.0292579e-37 2.2171180e-36], sum to 1.0000
[2019-03-23 22:28:49,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3778
[2019-03-23 22:28:49,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1753606.121617639 W.
[2019-03-23 22:28:49,986] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.03333333333333, 54.33333333333334, 1.0, 2.0, 0.5125662828767401, 1.0, 1.0, 0.5125662828767401, 1.0, 2.0, 0.8160222154581963, 6.9112, 6.9112, 121.94756008, 1753606.121617639, 1753606.121617639, 349799.54450339], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6106800.0000, 
sim time next is 6107400.0000, 
raw observation next is [30.0, 54.5, 1.0, 2.0, 0.9235349173332758, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1767950.299547931, 1767950.299547932, 362093.1693867485], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666666, 0.545, 1.0, 1.0, 0.9089701396824711, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6314108212671182, 0.6314108212671186, 0.6963330180514394], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7630354], dtype=float32), 0.65995693]. 
=============================================
[2019-03-23 22:28:56,444] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 22:28:56,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:28:56,448] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:56,449] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:28:56,450] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:28:56,450] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:56,451] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:56,451] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:28:56,451] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:28:56,454] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:56,454] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:56,475] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 22:28:56,504] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 22:28:56,531] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 22:28:56,531] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 22:28:56,531] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 22:30:21,759] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2546979]
[2019-03-23 22:30:21,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.053824775, 66.03175973166667, 1.0, 2.0, 0.7635637388400152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 870287.7882950949, 870287.7882950957, 188526.0475585997]
[2019-03-23 22:30:21,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:30:21,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3652774e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8765323296268842
[2019-03-23 22:30:26,280] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2546979]
[2019-03-23 22:30:26,284] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.75114962333333, 78.87915930666666, 1.0, 2.0, 0.4320566181904044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 528639.6361400347, 528639.6361400351, 133057.6043066283]
[2019-03-23 22:30:26,285] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:30:26,288] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3652774e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7297274614049012
[2019-03-23 22:30:27,461] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2546979]
[2019-03-23 22:30:27,463] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.48039538666667, 83.13111967, 1.0, 2.0, 0.4034822432815569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499193.4116117247, 499193.4116117247, 129094.1300382763]
[2019-03-23 22:30:27,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:30:27,466] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3652774e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4521864393970981
[2019-03-23 22:30:38,317] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:30:38,619] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:30:38,780] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:30:38,791] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:30:38,800] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:30:39,812] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1425000, evaluation results [1425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:30:49,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1325829e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:49,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-23 22:30:49,376] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.96666666666667, 85.0, 1.0, 2.0, 0.3357987230548986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426882.915325749, 426882.915325749, 120105.5737033603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5892600.0000, 
sim time next is 5893200.0000, 
raw observation next is [18.9, 85.0, 1.0, 2.0, 0.3309899785833231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 421070.2915628336, 421070.2915628331, 119484.6771363105], 
processed observation next is [1.0, 0.21739130434782608, 0.2555555555555555, 0.85, 1.0, 1.0, 0.20355949831347986, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15038224698672628, 0.15038224698672611, 0.2297782252621356], 
reward next is 0.7702, 
noisyNet noise sample is [array([-0.22868493], dtype=float32), 1.2369962]. 
=============================================
[2019-03-23 22:30:50,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1877527e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:50,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6445
[2019-03-23 22:30:50,422] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 79.0, 1.0, 2.0, 0.344900374261239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434984.5085578361, 434984.5085578361, 121262.6236774779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5898600.0000, 
sim time next is 5899200.0000, 
raw observation next is [20.66666666666667, 78.33333333333333, 1.0, 2.0, 0.3506405240445292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441836.0621481664, 441836.0621481664, 122015.1914018172], 
processed observation next is [1.0, 0.2608695652173913, 0.3209876543209878, 0.7833333333333333, 1.0, 1.0, 0.22695300481491573, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15779859362434515, 0.15779859362434515, 0.23464459884964844], 
reward next is 0.7654, 
noisyNet noise sample is [array([-1.1391696], dtype=float32), -1.4443078]. 
=============================================
[2019-03-23 22:30:52,940] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9946556e-23 1.0000000e+00 2.6340268e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:52,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6912
[2019-03-23 22:30:52,952] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 61.0, 1.0, 2.0, 0.4798338107353349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577159.6777315339, 577159.6777315339, 139934.8149052363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5945400.0000, 
sim time next is 5946000.0000, 
raw observation next is [26.66666666666666, 61.66666666666667, 1.0, 2.0, 0.4812901867726312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579001.4724363487, 579001.4724363487, 140162.2800339866], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432096, 0.6166666666666667, 1.0, 1.0, 0.38248831758646573, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20678624015583882, 0.20678624015583882, 0.269542846219205], 
reward next is 0.7305, 
noisyNet noise sample is [array([-1.3346081], dtype=float32), -0.94506407]. 
=============================================
[2019-03-23 22:30:52,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.906696]
 [58.906696]
 [58.906696]
 [58.906696]
 [58.906696]], R is [[59.04809189]
 [59.18850708]
 [59.32784653]
 [59.46589661]
 [59.60294724]].
[2019-03-23 22:30:53,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5133588e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:53,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3652
[2019-03-23 22:30:53,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 86.5, 1.0, 2.0, 0.4790407165262715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577486.6641014894, 577486.6641014894, 139855.9124694236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5958600.0000, 
sim time next is 5959200.0000, 
raw observation next is [22.66666666666667, 86.0, 1.0, 2.0, 0.4749588702974188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573350.140502261, 573350.140502261, 139255.1278822108], 
processed observation next is [1.0, 1.0, 0.39506172839506193, 0.86, 1.0, 1.0, 0.37495103606835567, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20476790732223607, 0.20476790732223607, 0.2677983228504054], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.3165483], dtype=float32), 1.6640784]. 
=============================================
[2019-03-23 22:30:56,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4952249e-21 1.0000000e+00 4.2830119e-34 3.5169139e-37 1.3885701e-36], sum to 1.0000
[2019-03-23 22:30:56,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5681
[2019-03-23 22:30:56,301] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 55.66666666666667, 1.0, 2.0, 0.3548465543399571, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5664693477176518, 6.911200000000001, 6.9112, 121.9260426156618, 826385.8713131892, 826385.8713131887, 210197.6959631757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6023400.0000, 
sim time next is 6024000.0000, 
raw observation next is [28.73333333333333, 56.33333333333334, 1.0, 2.0, 0.5011139500587664, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590965.9627960616, 590965.9627960616, 142809.9725261094], 
processed observation next is [1.0, 0.7391304347826086, 0.619753086419753, 0.5633333333333335, 1.0, 1.0, 0.4060880357842456, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21105927242716488, 0.21105927242716488, 0.2746345625502104], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.044817], dtype=float32), -0.41886216]. 
=============================================
[2019-03-23 22:30:56,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[49.124355]
 [49.124355]
 [49.124355]
 [49.124355]
 [49.124355]], R is [[48.63311386]
 [48.14678192]
 [48.03810501]
 [47.88675308]
 [47.73213959]].
[2019-03-23 22:31:01,626] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8302761e-19 1.0000000e+00 3.3290098e-30 2.7906289e-32 1.1562512e-31], sum to 1.0000
[2019-03-23 22:31:01,640] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7237
[2019-03-23 22:31:01,651] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1802511.302258742 W.
[2019-03-23 22:31:01,653] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.3, 53.33333333333334, 1.0, 2.0, 0.953809909660793, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1802511.302258742, 1802511.302258742, 368835.1007293038], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6103200.0000, 
sim time next is 6103800.0000, 
raw observation next is [30.25, 53.5, 1.0, 2.0, 0.9579817403348345, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9976766531310196, 6.9112, 6.9112, 121.9260426156618, 1807384.698043018, 1807384.698043018, 369763.0848344768], 
processed observation next is [1.0, 0.6521739130434783, 0.6759259259259259, 0.535, 1.0, 1.0, 0.9499782623033745, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9970958164137744, 0.0, 0.0, 0.8094621288201359, 0.6454945350153636, 0.6454945350153636, 0.711082855450917], 
reward next is 0.2889, 
noisyNet noise sample is [array([-1.2708544], dtype=float32), 1.423957]. 
=============================================
[2019-03-23 22:31:03,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.912621e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:31:03,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4309
[2019-03-23 22:31:03,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1612904.800355066 W.
[2019-03-23 22:31:03,615] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.53333333333333, 89.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.705243889217307, 6.9112, 122.7667189345042, 1612904.800355066, 1203479.715884419, 247882.5527499793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6142200.0000, 
sim time next is 6142800.0000, 
raw observation next is [23.46666666666667, 89.33333333333334, 1.0, 2.0, 0.3614424988267914, 1.0, 1.0, 0.3614424988267914, 1.0, 1.0, 0.5755794465748127, 6.911199999999999, 6.9112, 121.94756008, 1241722.727014277, 1241722.727014277, 280636.196201523], 
processed observation next is [1.0, 0.08695652173913043, 0.42469135802469143, 0.8933333333333334, 1.0, 1.0, 0.23981249860332313, 1.0, 0.5, 0.23981249860332313, 1.0, 0.5, 0.4694743082185159, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4434724025050989, 0.4434724025050989, 0.5396849926952365], 
reward next is 0.4603, 
noisyNet noise sample is [array([-0.29614216], dtype=float32), -0.09325665]. 
=============================================
[2019-03-23 22:31:04,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3641982e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:31:04,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9117
[2019-03-23 22:31:04,524] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 58.33333333333334, 1.0, 2.0, 0.9519630340262001, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.949347956076128, 6.9112, 121.9257629363768, 1123355.132251145, 1103820.013925154, 230353.3678237326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6181800.0000, 
sim time next is 6182400.0000, 
raw observation next is [29.26666666666667, 57.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.506610797526868, 6.9112, 121.9198657531633, 2006563.021108303, 1189611.486034687, 247043.0228197856], 
processed observation next is [1.0, 0.5652173913043478, 0.6395061728395063, 0.5766666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.15954107975268678, 0.0, 0.8094211208766301, 0.7166296503958225, 0.4248612450123882, 0.4750827361918954], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.363591], dtype=float32), -0.26221657]. 
=============================================
[2019-03-23 22:31:07,639] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8877653e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:31:07,649] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3874
[2019-03-23 22:31:07,657] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 71.33333333333334, 1.0, 2.0, 0.5148095440250734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613100.236040233, 613100.236040233, 145206.8156738478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6216000.0000, 
sim time next is 6216600.0000, 
raw observation next is [25.45, 71.66666666666666, 1.0, 2.0, 0.5097521901699522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608079.854497078, 608079.854497078, 144438.9863962015], 
processed observation next is [1.0, 0.9565217391304348, 0.4981481481481481, 0.7166666666666666, 1.0, 1.0, 0.4163716549642288, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21717137660609928, 0.21717137660609928, 0.27776728153115676], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.8492039], dtype=float32), -0.35305575]. 
=============================================
[2019-03-23 22:31:07,870] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.575769e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:31:07,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8852
[2019-03-23 22:31:07,885] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 73.66666666666667, 1.0, 2.0, 0.4986009729511823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596714.564151352, 596714.5641513516, 142749.2572320183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6220200.0000, 
sim time next is 6220800.0000, 
raw observation next is [24.9, 74.0, 1.0, 2.0, 0.4972502351633676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595248.4770954245, 595248.4770954245, 142542.7010816298], 
processed observation next is [0.0, 0.0, 0.47777777777777775, 0.74, 1.0, 1.0, 0.40148837519448527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21258874181979448, 0.21258874181979448, 0.27412057900313425], 
reward next is 0.7259, 
noisyNet noise sample is [array([-1.3079511], dtype=float32), 1.4057672]. 
=============================================
[2019-03-23 22:31:24,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3395952e-18 1.0000000e+00 1.2717910e-28 3.5709729e-31 4.7100110e-30], sum to 1.0000
[2019-03-23 22:31:24,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2160
[2019-03-23 22:31:24,482] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 86.0, 1.0, 2.0, 0.6960741926792022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 793325.3522617398, 793325.3522617407, 175402.0718761391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6555600.0000, 
sim time next is 6556200.0000, 
raw observation next is [26.56666666666667, 85.5, 1.0, 2.0, 0.6908147414217868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787328.0045450013, 787328.0045450013, 174412.0215696066], 
processed observation next is [1.0, 0.9130434782608695, 0.5395061728395063, 0.855, 1.0, 1.0, 0.6319223112164128, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2811885730517862, 0.2811885730517862, 0.335407733787705], 
reward next is 0.6646, 
noisyNet noise sample is [array([0.58874637], dtype=float32), -0.68222976]. 
=============================================
[2019-03-23 22:31:26,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.720347e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:31:26,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 22:31:26,301] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 79.5, 1.0, 2.0, 0.6140384032348974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705425.283044616, 705425.283044616, 160786.3961622478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6563400.0000, 
sim time next is 6564000.0000, 
raw observation next is [26.13333333333333, 78.0, 1.0, 2.0, 0.602099703350336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695471.4963159402, 695471.4963159402, 158889.4411665298], 
processed observation next is [1.0, 1.0, 0.5234567901234567, 0.78, 1.0, 1.0, 0.5263091706551619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2483826772556929, 0.2483826772556929, 0.30555661762794195], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.6212231], dtype=float32), -0.31979558]. 
=============================================
[2019-03-23 22:31:26,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.091663]
 [61.091663]
 [61.091663]
 [61.091663]
 [61.091663]], R is [[61.1751976 ]
 [61.25424194]
 [61.32801056]
 [61.39893723]
 [61.46701431]].
[2019-03-23 22:31:29,882] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 22:31:29,884] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:31:29,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:31:29,885] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:31:29,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:31:29,886] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:31:29,886] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:31:29,887] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:31:29,888] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:31:29,890] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:31:29,888] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:31:29,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 22:31:29,940] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 22:31:29,941] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 22:31:29,941] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 22:31:29,942] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 22:31:36,828] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2164412]
[2019-03-23 22:31:36,831] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.8, 73.5, 1.0, 2.0, 0.2577352184344405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 332458.419523585, 332458.4195235845, 109358.9348156511]
[2019-03-23 22:31:36,831] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:31:36,833] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4238348e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1677405254343124
[2019-03-23 22:32:29,439] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2164412]
[2019-03-23 22:32:29,441] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 93.0, 1.0, 2.0, 0.751878460436364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856961.8011016283, 856961.8011016283, 186201.4254700695]
[2019-03-23 22:32:29,442] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:32:29,445] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.4238348e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4352969825030034
[2019-03-23 22:32:45,052] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2164412]
[2019-03-23 22:32:45,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.19723064, 68.40023778666668, 1.0, 2.0, 0.6948736381836063, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1506950.262107615, 1506950.262107616, 316307.7690106794]
[2019-03-23 22:32:45,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:32:45,057] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4238348e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7679263501628474
[2019-03-23 22:32:45,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1506950.262107615 W.
[2019-03-23 22:32:50,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2164412]
[2019-03-23 22:32:50,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.11271773, 61.63140622, 1.0, 2.0, 0.5707432143955146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717531.7065366547, 717531.7065366547, 155464.1481406332]
[2019-03-23 22:32:50,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:32:50,780] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4238348e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8867330747580534
[2019-03-23 22:33:04,559] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.2164412]
[2019-03-23 22:33:04,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.43114302, 45.15540562, 1.0, 2.0, 0.2778866529047445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 358101.3786876095, 358101.3786876091, 103857.2186798976]
[2019-03-23 22:33:04,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:33:04,564] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4238348e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2626392004427809
[2019-03-23 22:33:12,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:33:12,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:33:12,514] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:33:12,523] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:33:12,587] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:33:13,602] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1450000, evaluation results [1450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:33:14,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.468986e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:14,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0880
[2019-03-23 22:33:14,254] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 46.0, 1.0, 2.0, 0.2925322612171223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377354.9453891329, 377354.9453891329, 111409.7969111983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6663600.0000, 
sim time next is 6664200.0000, 
raw observation next is [23.0, 45.83333333333334, 1.0, 2.0, 0.3643249584942124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469993.0400836995, 469993.0400836995, 121112.3599290975], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.4583333333333334, 1.0, 1.0, 0.24324399820739576, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16785465717274983, 0.16785465717274983, 0.23290838447903364], 
reward next is 0.7671, 
noisyNet noise sample is [array([1.5779738], dtype=float32), 0.42697296]. 
=============================================
[2019-03-23 22:33:15,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.312451e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:15,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0586
[2019-03-23 22:33:15,734] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 44.5, 1.0, 2.0, 0.3027928114173101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 390594.0164774077, 390594.0164774082, 109469.4160924824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6669000.0000, 
sim time next is 6669600.0000, 
raw observation next is [22.93333333333333, 44.33333333333334, 1.0, 2.0, 0.2946495679940916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380086.863587001, 380086.863587001, 107873.3022219369], 
processed observation next is [1.0, 0.17391304347826086, 0.40493827160493817, 0.4433333333333334, 1.0, 1.0, 0.16029710475487094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13574530842392893, 0.13574530842392893, 0.20744865811910942], 
reward next is 0.7926, 
noisyNet noise sample is [array([0.70179486], dtype=float32), -1.3275821]. 
=============================================
[2019-03-23 22:33:18,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.978317e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:18,103] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4040
[2019-03-23 22:33:18,107] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 71.66666666666667, 1.0, 2.0, 0.4100403090438498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506260.6562815921, 506260.6562815921, 130000.8884324313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6913200.0000, 
sim time next is 6913800.0000, 
raw observation next is [23.2, 72.0, 1.0, 2.0, 0.4105530689806585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506774.4371653355, 506774.4371653359, 130071.1324403012], 
processed observation next is [0.0, 0.0, 0.4148148148148148, 0.72, 1.0, 1.0, 0.2982774630722126, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18099087041619125, 0.1809908704161914, 0.2501367931544254], 
reward next is 0.7499, 
noisyNet noise sample is [array([-1.0433782], dtype=float32), -0.0010931542]. 
=============================================
[2019-03-23 22:33:20,592] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.098443e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:20,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3300
[2019-03-23 22:33:20,605] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 76.33333333333333, 1.0, 2.0, 0.4069674032828495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502730.1609447891, 502730.1609447891, 129569.8333193667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6832200.0000, 
sim time next is 6832800.0000, 
raw observation next is [22.4, 76.0, 1.0, 2.0, 0.4027239474904973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498262.6167798675, 498262.6167798675, 128986.9146093066], 
processed observation next is [0.0, 0.08695652173913043, 0.38518518518518513, 0.76, 1.0, 1.0, 0.2889570803458301, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17795093456423838, 0.17795093456423838, 0.24805175886405115], 
reward next is 0.7519, 
noisyNet noise sample is [array([-0.45319703], dtype=float32), -0.45271662]. 
=============================================
[2019-03-23 22:33:21,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.923662e-25 1.000000e+00 1.725401e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:21,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0506
[2019-03-23 22:33:21,421] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333334, 49.66666666666666, 1.0, 2.0, 0.4816314701779366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579745.1660463713, 579745.1660463718, 140226.1496574828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6978000.0000, 
sim time next is 6978600.0000, 
raw observation next is [28.75, 50.5, 1.0, 2.0, 0.479363916129103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577835.0687358053, 577835.0687358053, 139904.2815187816], 
processed observation next is [0.0, 0.782608695652174, 0.6203703703703703, 0.505, 1.0, 1.0, 0.38019513824893214, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20636966740564477, 0.20636966740564477, 0.2690466952284261], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.41870958], dtype=float32), -0.2741617]. 
=============================================
[2019-03-23 22:33:23,177] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0418773e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:23,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1699
[2019-03-23 22:33:23,187] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.91666666666667, 61.66666666666667, 1.0, 2.0, 0.4833382447318442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579068.8017540162, 579068.8017540157, 140395.123228294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6804600.0000, 
sim time next is 6805200.0000, 
raw observation next is [26.73333333333333, 62.33333333333334, 1.0, 2.0, 0.486206372560653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583057.1898966172, 583057.1898966172, 140858.141799929], 
processed observation next is [1.0, 0.782608695652174, 0.545679012345679, 0.6233333333333334, 1.0, 1.0, 0.38834091971506307, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2082347106773633, 0.2082347106773633, 0.2708810419229404], 
reward next is 0.7291, 
noisyNet noise sample is [array([0.00507366], dtype=float32), -1.7641083]. 
=============================================
[2019-03-23 22:33:26,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1424373e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:26,252] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2736
[2019-03-23 22:33:26,256] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 58.0, 1.0, 2.0, 0.4384102247901225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534152.5927552242, 534152.5927552247, 133925.4943601931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6861600.0000, 
sim time next is 6862200.0000, 
raw observation next is [26.76666666666667, 56.66666666666667, 1.0, 2.0, 0.4389646023959998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534728.0280825008, 534728.0280825008, 134004.1450696203], 
processed observation next is [0.0, 0.43478260869565216, 0.5469135802469137, 0.5666666666666668, 1.0, 1.0, 0.3321007171380951, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19097429574375027, 0.19097429574375027, 0.25770027898003905], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.43356246], dtype=float32), -2.052622]. 
=============================================
[2019-03-23 22:33:30,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9367254e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:30,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9772
[2019-03-23 22:33:30,401] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 50.5, 1.0, 2.0, 0.5736049632336135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666804.776432595, 666804.776432595, 154219.4835527587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6967800.0000, 
sim time next is 6968400.0000, 
raw observation next is [31.0, 50.0, 1.0, 2.0, 0.5685662834672567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662298.4782320516, 662298.4782320516, 153432.2581826554], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.5, 1.0, 1.0, 0.4863884326991151, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23653517079716127, 0.23653517079716127, 0.295062034966645], 
reward next is 0.7049, 
noisyNet noise sample is [array([1.1806189], dtype=float32), -0.056908913]. 
=============================================
[2019-03-23 22:33:31,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.897266e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:31,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-23 22:33:31,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 66.66666666666667, 1.0, 2.0, 0.4315750944132516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529509.7766815688, 529509.7766815693, 133027.1922884852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6991800.0000, 
sim time next is 6992400.0000, 
raw observation next is [24.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4305148063830414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 528386.3500231773, 528386.3500231769, 132877.0102742246], 
processed observation next is [0.0, 0.9565217391304348, 0.4567901234567903, 0.6733333333333335, 1.0, 1.0, 0.32204143617028735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18870941072256334, 0.18870941072256317, 0.2555327120658165], 
reward next is 0.7445, 
noisyNet noise sample is [array([-0.64429647], dtype=float32), 0.027875029]. 
=============================================
[2019-03-23 22:33:35,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.671108e-21 1.000000e+00 8.896134e-35 8.107062e-37 2.246223e-37], sum to 1.0000
[2019-03-23 22:33:35,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4603
[2019-03-23 22:33:35,765] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 78.83333333333334, 1.0, 2.0, 0.4732737554168641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570814.6962833119, 570814.6962833119, 138980.6807613203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7062600.0000, 
sim time next is 7063200.0000, 
raw observation next is [23.7, 79.0, 1.0, 2.0, 0.4798382727261717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578810.4308872506, 578810.4308872506, 139990.8665154779], 
processed observation next is [1.0, 0.782608695652174, 0.4333333333333333, 0.79, 1.0, 1.0, 0.3807598484835378, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20671801103116091, 0.20671801103116091, 0.2692132048374575], 
reward next is 0.7308, 
noisyNet noise sample is [array([1.3355222], dtype=float32), 0.0076931403]. 
=============================================
[2019-03-23 22:33:40,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.228257e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:40,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8265
[2019-03-23 22:33:40,304] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 62.66666666666667, 1.0, 2.0, 0.7161364453999706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 895300.1823684236, 895300.1823684236, 182214.594190932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7140000.0000, 
sim time next is 7140600.0000, 
raw observation next is [23.5, 63.0, 1.0, 2.0, 0.7235415673308246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904680.890374803, 904680.890374803, 183683.554116752], 
processed observation next is [1.0, 0.6521739130434783, 0.42592592592592593, 0.63, 1.0, 1.0, 0.6708828182509817, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3231003179910011, 0.3231003179910011, 0.35323760407067695], 
reward next is 0.6468, 
noisyNet noise sample is [array([-0.5338237], dtype=float32), -0.6517306]. 
=============================================
[2019-03-23 22:33:48,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5791163e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:48,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2465
[2019-03-23 22:33:48,937] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 78.0, 1.0, 2.0, 0.5199300058996031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615932.3355638115, 615932.3355638115, 145901.4905615465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7491600.0000, 
sim time next is 7492200.0000, 
raw observation next is [24.78333333333333, 78.66666666666667, 1.0, 2.0, 0.5185310200625776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614441.4705036068, 614441.4705036068, 145683.9262028838], 
processed observation next is [0.0, 0.7391304347826086, 0.4734567901234567, 0.7866666666666667, 1.0, 1.0, 0.42682264293163996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21944338232271673, 0.21944338232271673, 0.2801613965440073], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.2922714], dtype=float32), 0.88677156]. 
=============================================
[2019-03-23 22:33:50,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9363593e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:50,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1731
[2019-03-23 22:33:50,762] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4387027754841036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534413.9669915632, 534413.9669915632, 133965.7295388391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7527000.0000, 
sim time next is 7527600.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4383501295906114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533984.7759384912, 533984.7759384912, 133913.8438600072], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3313692018935851, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19070884854946116, 0.19070884854946116, 0.25752662280770616], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.27542028], dtype=float32), 1.7080775]. 
=============================================
[2019-03-23 22:33:51,431] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3729682e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:51,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4254
[2019-03-23 22:33:51,455] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 85.83333333333334, 1.0, 2.0, 0.3972623683990515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492399.8274076884, 492399.8274076884, 128238.0749310361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7344600.0000, 
sim time next is 7345200.0000, 
raw observation next is [20.93333333333334, 85.66666666666667, 1.0, 2.0, 0.3936933990508909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488343.7337531163, 488343.7337531159, 127746.228495835], 
processed observation next is [1.0, 0.0, 0.3308641975308645, 0.8566666666666667, 1.0, 1.0, 0.2782064274415368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17440847634039866, 0.17440847634039855, 0.24566582403045192], 
reward next is 0.7543, 
noisyNet noise sample is [array([1.0769155], dtype=float32), 1.1588225]. 
=============================================
[2019-03-23 22:33:51,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.929422e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:33:51,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-23 22:33:51,646] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 84.66666666666667, 1.0, 2.0, 0.3817437938477067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475360.3903191776, 475360.3903191772, 126127.0194295634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7348200.0000, 
sim time next is 7348800.0000, 
raw observation next is [20.73333333333333, 84.33333333333334, 1.0, 2.0, 0.3795631430128835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473112.7410589083, 473112.7410589079, 125836.2528675191], 
processed observation next is [1.0, 0.043478260869565216, 0.3234567901234567, 0.8433333333333334, 1.0, 1.0, 0.26138469406295656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16896883609246724, 0.1689688360924671, 0.24199279397599827], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.16383561], dtype=float32), -1.1046034]. 
=============================================
[2019-03-23 22:33:52,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2694712e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:52,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0442
[2019-03-23 22:33:52,473] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.3789534873130062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471995.0521062265, 471995.0521062265, 125745.5189083229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7363800.0000, 
sim time next is 7364400.0000, 
raw observation next is [19.36666666666667, 96.0, 1.0, 2.0, 0.3814648601614822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475338.084300661, 475338.084300661, 126095.0766824331], 
processed observation next is [1.0, 0.21739130434782608, 0.27283950617283964, 0.96, 1.0, 1.0, 0.26364864304938357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16976360153595035, 0.16976360153595035, 0.2424905320816021], 
reward next is 0.7575, 
noisyNet noise sample is [array([0.10860781], dtype=float32), 1.3100747]. 
=============================================
[2019-03-23 22:33:55,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:33:55,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:55,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 22:34:00,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.684373e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:34:00,680] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2744
[2019-03-23 22:34:00,684] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4378345164946644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533357.3265483236, 533357.3265483236, 133838.0225019919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7530000.0000, 
sim time next is 7530600.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4376790944393379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533168.5250358587, 533168.5250358587, 133815.1866299729], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.33057035052302136, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19041733036994954, 0.19041733036994954, 0.2573368973653325], 
reward next is 0.7427, 
noisyNet noise sample is [array([2.4820728], dtype=float32), 0.1886507]. 
=============================================
[2019-03-23 22:34:01,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6377422e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:34:01,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0412
[2019-03-23 22:34:01,495] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4374252703043596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532859.6530138631, 532859.6530138631, 133777.8860587587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531800.0000, 
sim time next is 7532400.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4368630656383334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532175.3883648764, 532175.3883648764, 133695.3042195106], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 1.0, 1.0, 0.32959888766468265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19006263870174156, 0.19006263870174156, 0.25710635426828965], 
reward next is 0.7429, 
noisyNet noise sample is [array([-0.13788472], dtype=float32), 0.58720624]. 
=============================================
[2019-03-23 22:34:03,543] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 22:34:03,546] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:34:03,548] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:34:03,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:34:03,549] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:34:03,550] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:34:03,550] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:34:03,551] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:34:03,551] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:34:03,551] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:34:03,554] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:34:03,584] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 22:34:03,610] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 22:34:03,610] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 22:34:03,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 22:34:03,694] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 22:34:15,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:15,984] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.64117555, 41.45322216, 1.0, 2.0, 0.4377945923605706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 531023.1640311033, 531023.1640311037, 133763.4108066055]
[2019-03-23 22:34:15,986] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:15,992] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8703251671840553
[2019-03-23 22:34:19,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:19,084] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.65, 70.5, 1.0, 2.0, 0.3264054889007911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419868.22829423, 419868.22829423, 118895.4925756466]
[2019-03-23 22:34:19,086] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:34:19,091] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6047065340331422
[2019-03-23 22:34:22,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:22,944] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.46666666666667, 17.0, 1.0, 2.0, 0.7522657559888964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930112.0372257112, 930112.0372257112, 189225.1213765324]
[2019-03-23 22:34:22,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:34:22,948] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9609265619995982
[2019-03-23 22:34:26,651] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:26,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.75286604, 37.823234115, 1.0, 2.0, 0.3107667533750695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398886.3522169197, 398886.3522169197, 116915.4702740016]
[2019-03-23 22:34:26,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:26,660] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9634806791760319
[2019-03-23 22:34:29,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:29,468] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.73333333333333, 63.33333333333333, 1.0, 2.0, 0.9428700365192785, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.145762057996047, 6.9112, 121.92499057922, 1260380.279142871, 1140264.576954947, 230368.3021533627]
[2019-03-23 22:34:29,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:34:29,474] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.015798523797667885
[2019-03-23 22:34:43,601] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:43,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.24572544166667, 74.36873548666668, 1.0, 2.0, 0.6466334996564637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738788.9013902205, 738788.9013902205, 166377.352800265]
[2019-03-23 22:34:43,605] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:43,609] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2551220580425305
[2019-03-23 22:34:47,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:34:47,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.17975678333333, 40.80742875666667, 1.0, 2.0, 0.83370248897558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1028470.267262755, 1028470.267262755, 206315.0198366546]
[2019-03-23 22:34:47,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:47,661] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.37627876685555095
[2019-03-23 22:35:13,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:35:13,852] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.60090545666667, 58.06283844333333, 1.0, 2.0, 0.7177757548047462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 818072.1210712645, 818072.121071264, 179536.3116885753]
[2019-03-23 22:35:13,853] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:35:13,855] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.21320224047397507
[2019-03-23 22:35:25,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:35:25,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.31930401, 71.53615764666668, 1.0, 2.0, 0.4766474584304188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578069.8153826846, 578069.815382685, 139599.6352577787]
[2019-03-23 22:35:25,598] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:35:25,599] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6874673685613871
[2019-03-23 22:35:31,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:35:31,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.5, 91.5, 1.0, 2.0, 0.5084155874488709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608076.5510840941, 608076.5510840941, 144285.0242147822]
[2019-03-23 22:35:31,215] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:35:31,217] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7627546740045898
[2019-03-23 22:35:41,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:35:41,853] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.2968242351507034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378633.015707164, 378633.015707164, 115183.5923579089]
[2019-03-23 22:35:41,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:35:41,856] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.057971426496413625
[2019-03-23 22:35:43,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.316236]
[2019-03-23 22:35:43,088] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.53874096333333, 64.122286425, 1.0, 2.0, 0.3559942163761931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449482.8783443271, 449482.8783443271, 122737.9389608488]
[2019-03-23 22:35:43,091] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:35:43,092] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7033577e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.24726695274428134
[2019-03-23 22:35:45,904] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:35:46,001] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:35:46,127] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:35:46,379] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:35:46,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:35:47,432] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1475000, evaluation results [1475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:35:50,634] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2639726e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:35:50,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4517
[2019-03-23 22:35:50,659] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 89.33333333333334, 1.0, 2.0, 0.5232079077722789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641474.1763295025, 641474.176329503, 147155.0431440931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7633200.0000, 
sim time next is 7633800.0000, 
raw observation next is [21.6, 88.5, 1.0, 2.0, 0.5756228112746771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703884.8272197307, 703884.8272197312, 155858.9875080073], 
processed observation next is [1.0, 0.34782608695652173, 0.3555555555555556, 0.885, 1.0, 1.0, 0.49478906104128223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25138743829276095, 0.2513874382927611, 0.2997288221307833], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.16644467], dtype=float32), 0.5228891]. 
=============================================
[2019-03-23 22:35:55,947] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.091722e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:35:55,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7739
[2019-03-23 22:35:55,963] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 61.00000000000001, 1.0, 2.0, 0.5257305415218485, 1.0, 1.0, 0.5257305415218485, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258172521946, 1247222.749723533, 1247222.749723533, 245613.8514756436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7730400.0000, 
sim time next is 7731000.0000, 
raw observation next is [26.7, 60.0, 1.0, 2.0, 0.980385467068095, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.347287682863413, 6.9112, 121.9242136612397, 1400970.221531932, 1177657.700685942, 239022.1480818913], 
processed observation next is [1.0, 0.4782608695652174, 0.5444444444444444, 0.6, 1.0, 1.0, 0.976649365557256, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04360876828634126, 0.0, 0.8094499864647517, 0.5003465076899757, 0.42059203595926503, 0.45965797708056017], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6453405], dtype=float32), 0.46713424]. 
=============================================
[2019-03-23 22:35:55,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.760933]
 [63.760933]
 [63.760933]
 [63.760933]
 [63.760933]], R is [[63.12333298]
 [63.01976395]
 [62.38956833]
 [61.76567459]
 [61.14801788]].
[2019-03-23 22:35:56,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2036356e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:35:56,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9674
[2019-03-23 22:35:56,353] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 64.33333333333334, 1.0, 2.0, 0.4131001198454716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508689.936248274, 508689.936248274, 130404.5154896087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7760400.0000, 
sim time next is 7761000.0000, 
raw observation next is [24.28333333333333, 65.16666666666666, 1.0, 2.0, 0.4088779821147539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504448.532317954, 504448.5323179535, 129826.0107573336], 
processed observation next is [1.0, 0.8260869565217391, 0.4549382716049382, 0.6516666666666666, 1.0, 1.0, 0.2962833120413737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.180160190113555, 0.1801601901135548, 0.24966540530256462], 
reward next is 0.7503, 
noisyNet noise sample is [array([1.4573896], dtype=float32), -0.3262604]. 
=============================================
[2019-03-23 22:35:56,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.850548]
 [61.850548]
 [61.850548]
 [61.850548]
 [61.850548]], R is [[61.98238373]
 [62.11178207]
 [62.23851013]
 [62.36257553]
 [62.48403549]].
[2019-03-23 22:35:58,088] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:35:58,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:35:58,123] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 22:36:03,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.32969285e-27 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:36:03,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7724
[2019-03-23 22:36:03,944] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 78.83333333333333, 1.0, 2.0, 0.3782182963420791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472260.8182454479, 472260.8182454479, 125667.4037781121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7887000.0000, 
sim time next is 7887600.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4176058456776866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521171.5420578849, 521171.5420578844, 131204.4873860599], 
processed observation next is [1.0, 0.30434782608695654, 0.35185185185185186, 0.78, 1.0, 1.0, 0.3066736258067698, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18613269359210174, 0.18613269359210158, 0.252316321896269], 
reward next is 0.7477, 
noisyNet noise sample is [array([1.6305822], dtype=float32), 1.0415764]. 
=============================================
[2019-03-23 22:36:04,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:04,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:04,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 22:36:04,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2574533e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:04,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0381
[2019-03-23 22:36:04,552] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1587466.446975249 W.
[2019-03-23 22:36:04,554] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.1, 47.16666666666667, 1.0, 2.0, 0.4604998619915238, 1.0, 1.0, 0.4604998619915238, 1.0, 2.0, 0.7335309193442255, 6.911200000000001, 6.9112, 121.94756008, 1587466.446975249, 1587466.446975248, 324676.3627428235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7917000.0000, 
sim time next is 7917600.0000, 
raw observation next is [30.1, 47.33333333333334, 1.0, 2.0, 0.4776392955995569, 1.0, 2.0, 0.4776392955995569, 1.0, 2.0, 0.7605839304913636, 6.9112, 6.9112, 121.94756008, 1640355.24893081, 1640355.24893081, 332793.3141493815], 
processed observation next is [1.0, 0.6521739130434783, 0.6703703703703704, 0.47333333333333344, 1.0, 1.0, 0.37814201857090113, 1.0, 1.0, 0.37814201857090113, 1.0, 1.0, 0.7007299131142044, 0.0, 0.0, 0.8096049824067558, 0.5858411603324322, 0.5858411603324322, 0.6399871425949644], 
reward next is 0.3600, 
noisyNet noise sample is [array([-0.17534953], dtype=float32), 0.44066334]. 
=============================================
[2019-03-23 22:36:04,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.461341e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:36:04,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9877
[2019-03-23 22:36:04,666] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 61.0, 1.0, 2.0, 0.4867333026983443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585345.829749269, 585345.829749269, 140997.2606760871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7934400.0000, 
sim time next is 7935000.0000, 
raw observation next is [26.63333333333334, 61.66666666666667, 1.0, 2.0, 0.4837149483863589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582189.5232183633, 582189.5232183633, 140545.9083646198], 
processed observation next is [1.0, 0.8695652173913043, 0.5419753086419755, 0.6166666666666667, 1.0, 1.0, 0.38537493855518923, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20792482972084403, 0.20792482972084403, 0.27028059300888424], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.17792319], dtype=float32), 0.8892266]. 
=============================================
[2019-03-23 22:36:04,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.174377]
 [61.174377]
 [61.174377]
 [61.174377]
 [61.174377]], R is [[61.29235458]
 [61.40828323]
 [61.52194214]
 [61.63393784]
 [61.74509048]].
[2019-03-23 22:36:06,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:06,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:06,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 22:36:06,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:06,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:06,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 22:36:06,692] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:06,693] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:06,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 22:36:06,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:06,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:06,753] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 22:36:06,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:06,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:06,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 22:36:07,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 22:36:07,200] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,201] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,206] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 22:36:07,332] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,338] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 22:36:07,402] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,403] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 22:36:07,541] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,542] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,546] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 22:36:07,572] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:07,577] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:07,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 22:36:07,614] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 22:36:08,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:36:08,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:08,127] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 22:36:14,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0233561e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:14,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1869
[2019-03-23 22:36:14,674] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333333, 13.33333333333333, 1.0, 2.0, 0.3768583626498536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485775.5694201395, 485775.5694201395, 125586.4697225247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 224400.0000, 
sim time next is 225000.0000, 
raw observation next is [33.34999999999999, 13.5, 1.0, 2.0, 0.3775442400541742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486420.565585551, 486420.5655855506, 125682.7348079272], 
processed observation next is [0.0, 0.6086956521739131, 0.7907407407407403, 0.135, 1.0, 1.0, 0.2589812381597312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17372163056626821, 0.17372163056626808, 0.24169756693832156], 
reward next is 0.7583, 
noisyNet noise sample is [array([-2.5848446], dtype=float32), 0.72710335]. 
=============================================
[2019-03-23 22:36:14,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.398346]
 [71.398346]
 [71.398346]
 [71.398346]
 [71.398346]], R is [[71.4426651 ]
 [71.48672485]
 [71.53064728]
 [71.57440186]
 [71.61806488]].
[2019-03-23 22:36:27,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7851866e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:27,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-23 22:36:27,993] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 64.0, 1.0, 2.0, 0.2297894508521557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 296403.5836472972, 296403.5836472972, 90303.36846305357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364800.0000, 
sim time next is 365400.0000, 
raw observation next is [18.95, 62.0, 1.0, 2.0, 0.2311742207469147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 298190.1345361223, 298190.1345361223, 91122.53726009889], 
processed observation next is [1.0, 0.21739130434782608, 0.25740740740740736, 0.62, 1.0, 1.0, 0.08473121517489847, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.10649647662004369, 0.10649647662004369, 0.17523564857711327], 
reward next is 0.8248, 
noisyNet noise sample is [array([0.06008459], dtype=float32), -1.1410941]. 
=============================================
[2019-03-23 22:36:29,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.767226e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:36:29,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6444
[2019-03-23 22:36:29,559] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 36.5, 1.0, 2.0, 0.6923815796424679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890324.1815792727, 890324.1815792727, 177791.4373056368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [25.83333333333334, 36.0, 1.0, 2.0, 0.6509779399814067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836608.1421276532, 836608.1421276532, 169931.7114405165], 
processed observation next is [1.0, 0.34782608695652173, 0.5123456790123458, 0.36, 1.0, 1.0, 0.5844975475969127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2987886221884476, 0.2987886221884476, 0.32679175277022404], 
reward next is 0.6732, 
noisyNet noise sample is [array([0.66535705], dtype=float32), 0.19596472]. 
=============================================
[2019-03-23 22:36:31,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0854563e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:31,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-23 22:36:31,211] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 45.83333333333334, 1.0, 2.0, 0.2894801883946098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371073.8589290125, 371073.8589290125, 114286.1486384805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 431400.0000, 
sim time next is 432000.0000, 
raw observation next is [23.9, 47.0, 1.0, 2.0, 0.2866383481308504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367516.2610158189, 367516.2610158189, 113940.8367881442], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.47, 1.0, 1.0, 0.15075993825101236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1312558075056496, 0.1312558075056496, 0.21911699382335423], 
reward next is 0.7809, 
noisyNet noise sample is [array([-0.76487786], dtype=float32), 0.6942122]. 
=============================================
[2019-03-23 22:36:31,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.585815]
 [63.585815]
 [63.585815]
 [63.585815]
 [63.585815]], R is [[63.73083878]
 [63.87375259]
 [64.01459503]
 [64.15337372]
 [64.28996277]].
[2019-03-23 22:36:34,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7964471e-24 1.0000000e+00 1.0381473e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:34,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3829
[2019-03-23 22:36:34,709] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 31.0, 1.0, 2.0, 0.9107586957490412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.113599934321262, 6.9112, 121.9252491366955, 1237942.632427928, 1134296.450274971, 223903.2704705731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [31.16666666666667, 30.5, 1.0, 2.0, 0.9979731348508909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.699939733881802, 6.9112, 121.9228390446852, 1646987.465051947, 1243092.837038628, 244801.5782282595], 
processed observation next is [1.0, 0.5652173913043478, 0.7098765432098767, 0.305, 1.0, 1.0, 0.9975870652986797, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.07887397338818021, 0.0, 0.8094408604403304, 0.5882098089471239, 0.44396172751379576, 0.47077226582357595], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06199586], dtype=float32), 0.5971437]. 
=============================================
[2019-03-23 22:36:36,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5202478e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:36:36,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3959
[2019-03-23 22:36:36,315] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 58.0, 1.0, 2.0, 0.3143918569470782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400044.3823367539, 400044.3823367539, 117367.4629770729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 517800.0000, 
sim time next is 518400.0000, 
raw observation next is [22.6, 59.0, 1.0, 2.0, 0.3161306310778657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402241.7789574796, 402241.7789574796, 117586.9293508268], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.59, 1.0, 1.0, 0.18586979890222108, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14365777819909986, 0.14365777819909986, 0.22612871029005155], 
reward next is 0.7739, 
noisyNet noise sample is [array([0.394208], dtype=float32), 0.8196332]. 
=============================================
[2019-03-23 22:36:38,240] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 22:36:38,241] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:36:38,244] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:36:38,246] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:36:38,247] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:38,248] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:38,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:38,247] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:36:38,249] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:36:38,254] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:38,257] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:38,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 22:36:38,274] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 22:36:38,320] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 22:36:38,321] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 22:36:38,342] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 22:36:45,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:36:45,143] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.85, 42.0, 1.0, 2.0, 0.3927432815619978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506665.868683465, 506665.868683465, 126286.3028752449]
[2019-03-23 22:36:45,146] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:36:45,149] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4304873579483687
[2019-03-23 22:37:08,282] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:37:08,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.465761065, 75.75342172, 1.0, 2.0, 0.5627195964668981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646562.4470011882, 646562.4470011882, 152047.0223606698]
[2019-03-23 22:37:08,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:37:08,286] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0697766961488494
[2019-03-23 22:37:11,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:37:11,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 76.66666666666667, 1.0, 2.0, 0.4037519550782894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495099.9097002809, 495099.9097002809, 129021.2351449116]
[2019-03-23 22:37:11,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:37:11,596] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.20591443205576565
[2019-03-23 22:37:55,356] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:37:55,357] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.91666666666667, 68.16666666666666, 1.0, 2.0, 0.5153067801892915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614915.8596493258, 614915.8596493258, 145331.2930205335]
[2019-03-23 22:37:55,358] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:37:55,361] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5759446657685195
[2019-03-23 22:37:56,383] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:37:56,384] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.16666666666667, 93.5, 1.0, 2.0, 0.4505641896240974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549034.5074374175, 549034.5074374175, 135729.1561449211]
[2019-03-23 22:37:56,386] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:37:56,390] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.35978944168602467
[2019-03-23 22:38:14,789] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3426971]
[2019-03-23 22:38:14,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.08333333333334, 54.66666666666667, 1.0, 2.0, 0.2823150438483732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363229.5429416567, 363229.5429416567, 113412.8417447027]
[2019-03-23 22:38:14,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:38:14,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.695756e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3536560758583216
[2019-03-23 22:38:21,599] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:38:21,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:38:21,640] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:38:21,645] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:38:21,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:38:22,875] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1500000, evaluation results [1500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:38:24,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.981432e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:38:24,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6892
[2019-03-23 22:38:24,890] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.01666666666667, 43.5, 1.0, 2.0, 0.3616294993125028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453936.9561147283, 453936.9561147288, 123456.5429672165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [26.83333333333334, 44.0, 1.0, 2.0, 0.3586482503421252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 450508.1208305991, 450508.1208305991, 123061.5723934116], 
processed observation next is [1.0, 0.9565217391304348, 0.5493827160493829, 0.44, 1.0, 1.0, 0.23648601231205385, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1608957574394997, 0.1608957574394997, 0.23665686998733], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.19207321], dtype=float32), -0.68432367]. 
=============================================
[2019-03-23 22:38:30,364] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.039381e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:38:30,449] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0251
[2019-03-23 22:38:30,453] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 38.83333333333333, 1.0, 2.0, 0.3077676977582069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394086.4120223318, 394086.4120223318, 116542.005657892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 697800.0000, 
sim time next is 698400.0000, 
raw observation next is [25.7, 39.0, 1.0, 2.0, 0.306154905753686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392294.4831150185, 392294.4831150185, 116340.3760059402], 
processed observation next is [1.0, 0.08695652173913043, 0.5074074074074074, 0.39, 1.0, 1.0, 0.17399393542105474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14010517254107804, 0.14010517254107804, 0.22373149231911577], 
reward next is 0.7763, 
noisyNet noise sample is [array([0.91356885], dtype=float32), -1.2356291]. 
=============================================
[2019-03-23 22:38:33,779] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6179188e-22 1.0000000e+00 6.4402517e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:33,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1002
[2019-03-23 22:38:33,790] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 37.0, 1.0, 2.0, 0.3221232098410585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409638.5289375304, 409638.5289375304, 118346.4065690274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772200.0000, 
sim time next is 772800.0000, 
raw observation next is [27.03333333333333, 37.66666666666667, 1.0, 2.0, 0.3198388060529134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406731.2795676654, 406731.2795676654, 118055.6227420541], 
processed observation next is [1.0, 0.9565217391304348, 0.55679012345679, 0.3766666666666667, 1.0, 1.0, 0.19028429292013505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1452611712741662, 0.1452611712741662, 0.2270300437347194], 
reward next is 0.7730, 
noisyNet noise sample is [array([0.56430703], dtype=float32), -1.2568324]. 
=============================================
[2019-03-23 22:38:35,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5690443e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:35,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8422
[2019-03-23 22:38:35,291] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 48.66666666666666, 1.0, 2.0, 0.2990819723255301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 381789.9455762807, 381789.9455762807, 115462.4794327256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783600.0000, 
sim time next is 784200.0000, 
raw observation next is [23.96666666666667, 49.33333333333334, 1.0, 2.0, 0.297786083458835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380248.458658112, 380248.458658112, 115302.9739770747], 
processed observation next is [0.0, 0.043478260869565216, 0.4432098765432099, 0.4933333333333334, 1.0, 1.0, 0.16403105173670834, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1358030209493257, 0.1358030209493257, 0.22173648841745133], 
reward next is 0.7783, 
noisyNet noise sample is [array([-1.0543637], dtype=float32), 1.3833963]. 
=============================================
[2019-03-23 22:38:38,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.046764e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:38:38,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4929
[2019-03-23 22:38:38,913] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 42.66666666666667, 1.0, 2.0, 0.3838255448646262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477681.2104617027, 477681.2104617027, 126408.8324135307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 850800.0000, 
sim time next is 851400.0000, 
raw observation next is [27.9, 43.5, 1.0, 2.0, 0.3846687101003035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478558.591754847, 478558.591754847, 126521.8508273086], 
processed observation next is [0.0, 0.8695652173913043, 0.5888888888888888, 0.435, 1.0, 1.0, 0.26746275011940895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1709137827695882, 0.1709137827695882, 0.24331125159097808], 
reward next is 0.7567, 
noisyNet noise sample is [array([1.7256955], dtype=float32), -0.5251814]. 
=============================================
[2019-03-23 22:38:39,189] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7535512e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:39,195] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4343
[2019-03-23 22:38:39,203] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 66.5, 1.0, 2.0, 0.3429790681987868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434309.4052427977, 434309.4052427977, 121029.4824522859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [21.76666666666667, 66.33333333333334, 1.0, 2.0, 0.3379137662042673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428373.8733191731, 428373.8733191731, 120371.727495494], 
processed observation next is [0.0, 0.13043478260869565, 0.3617283950617285, 0.6633333333333334, 1.0, 1.0, 0.2118021026241277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15299066904256184, 0.15299066904256184, 0.23148409133748846], 
reward next is 0.7685, 
noisyNet noise sample is [array([0.45093685], dtype=float32), 0.8422892]. 
=============================================
[2019-03-23 22:38:39,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0103737e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:39,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3815
[2019-03-23 22:38:39,686] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 65.16666666666667, 1.0, 2.0, 0.305672672079111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390975.8709444478, 390975.8709444478, 116280.8449591544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 882600.0000, 
sim time next is 883200.0000, 
raw observation next is [21.13333333333333, 65.33333333333334, 1.0, 2.0, 0.3077348920318592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393305.6928160409, 393305.6928160409, 116537.8975447615], 
processed observation next is [0.0, 0.21739130434782608, 0.33827160493827146, 0.6533333333333334, 1.0, 1.0, 0.17587487146649908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14046631886287175, 0.14046631886287175, 0.22411134143223363], 
reward next is 0.7759, 
noisyNet noise sample is [array([-0.39567006], dtype=float32), 0.8631687]. 
=============================================
[2019-03-23 22:38:40,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5331651e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:40,748] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2207
[2019-03-23 22:38:40,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1331078.549409983 W.
[2019-03-23 22:38:40,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.68333333333333, 45.66666666666667, 1.0, 2.0, 0.9262162320732851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.247102148675471, 6.9112, 121.9243880845902, 1331078.549409983, 1159068.960889049, 227630.8322303966], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1008600.0000, 
sim time next is 1009200.0000, 
raw observation next is [26.76666666666667, 45.33333333333334, 1.0, 2.0, 0.4787104095445708, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7929798396555314, 6.911200000000001, 6.9112, 121.9258402929754, 1185087.878832465, 1185087.878832464, 245756.7897973482], 
processed observation next is [1.0, 0.6956521739130435, 0.5469135802469137, 0.4533333333333334, 1.0, 1.0, 0.3794171542197271, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7412247995694143, 8.881784197001253e-17, 0.0, 0.809460785607899, 0.42324567101159466, 0.4232456710115943, 0.47260921114874654], 
reward next is 0.5274, 
noisyNet noise sample is [array([0.74417883], dtype=float32), -0.1810389]. 
=============================================
[2019-03-23 22:38:44,749] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.828619e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:38:44,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7779
[2019-03-23 22:38:44,763] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 44.33333333333333, 1.0, 2.0, 0.6367231581033033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806675.5395366829, 806675.5395366829, 167256.7702502885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1082400.0000, 
sim time next is 1083000.0000, 
raw observation next is [25.86666666666667, 43.66666666666666, 1.0, 2.0, 0.6198586027614277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785483.1668739958, 785483.1668739958, 164188.2044975219], 
processed observation next is [1.0, 0.5217391304347826, 0.5135802469135804, 0.4366666666666666, 1.0, 1.0, 0.5474507175731281, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2805297024549985, 0.2805297024549985, 0.315746547110619], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.601385], dtype=float32), -0.43064046]. 
=============================================
[2019-03-23 22:38:44,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.43229]
 [74.43229]
 [74.43229]
 [74.43229]
 [74.43229]], R is [[74.37221527]
 [74.30684662]
 [74.22083282]
 [74.13767242]
 [74.00104523]].
[2019-03-23 22:38:58,175] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.186904e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:38:58,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9864
[2019-03-23 22:38:58,184] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 92.66666666666667, 1.0, 2.0, 0.3500173704665095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 440785.6547891969, 440785.6547891964, 121929.1031344427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [18.86666666666667, 93.33333333333334, 1.0, 2.0, 0.3491113679655188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 121808.6121606411], 
processed observation next is [1.0, 0.9565217391304348, 0.25432098765432115, 0.9333333333333335, 1.0, 1.0, 0.2251325809113319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15699849883061928, 0.15699849883061928, 0.23424733107815596], 
reward next is 0.7658, 
noisyNet noise sample is [array([0.75312996], dtype=float32), 2.0874715]. 
=============================================
[2019-03-23 22:39:03,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3899786e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:39:03,363] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8203
[2019-03-23 22:39:03,366] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 63.0, 1.0, 2.0, 0.6934400188655374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861098.6426238023, 861098.6426238023, 177656.8269512242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1328400.0000, 
sim time next is 1329000.0000, 
raw observation next is [24.35, 61.33333333333333, 1.0, 2.0, 0.8847264892058664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.922956422362629, 6.9112, 121.9260008528098, 1104942.986417901, 1098922.649453251, 217857.7997400848], 
processed observation next is [1.0, 0.391304347826087, 0.4574074074074075, 0.6133333333333333, 1.0, 1.0, 0.8627696300069838, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0011756422362629415, 0.0, 0.809461851558229, 0.39462249514925035, 0.39247237480473246, 0.41895730719247076], 
reward next is 0.5223, 
noisyNet noise sample is [array([1.7628393], dtype=float32), -0.08106858]. 
=============================================
[2019-03-23 22:39:03,383] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.12991]
 [77.12991]
 [77.12991]
 [77.12991]
 [77.12991]], R is [[76.880867  ]
 [76.77041626]
 [76.68601227]
 [76.59928131]
 [76.49221802]].
[2019-03-23 22:39:04,395] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5224372e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:39:04,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0153
[2019-03-23 22:39:04,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1356323.48416104 W.
[2019-03-23 22:39:04,415] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 41.5, 1.0, 2.0, 0.9324386242027977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.283289024314552, 6.9112, 121.9242486955599, 1356323.48416104, 1165783.450263894, 229072.4400827722], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1337400.0000, 
sim time next is 1338000.0000, 
raw observation next is [28.0, 41.0, 1.0, 2.0, 0.5006408645007534, 1.0, 1.0, 0.5006408645007534, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258185011756, 1230845.63731525, 1230845.63731525, 239063.972665842], 
processed observation next is [1.0, 0.4782608695652174, 0.5925925925925926, 0.41, 1.0, 1.0, 0.40552483869137307, 1.0, 0.5, 0.40552483869137307, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094606409330102, 0.4395877276125893, 0.4395877276125893, 0.45973840897277307], 
reward next is 0.5403, 
noisyNet noise sample is [array([0.93527704], dtype=float32), -0.61290616]. 
=============================================
[2019-03-23 22:39:04,438] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.87899]
 [74.87899]
 [74.87899]
 [74.87899]
 [74.87899]], R is [[74.67046356]
 [73.92375946]
 [73.18452454]
 [72.4526825 ]
 [72.35869598]].
[2019-03-23 22:39:05,082] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1934065e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:39:05,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4265
[2019-03-23 22:39:05,100] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1347226.416475793 W.
[2019-03-23 22:39:05,105] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 28.0, 1.0, 2.0, 0.5463422713676143, 1.0, 1.0, 0.5463422713676143, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156392, 1347226.416475793, 1347226.416475792, 254025.8675875006], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1357200.0000, 
sim time next is 1357800.0000, 
raw observation next is [30.75, 29.0, 1.0, 2.0, 0.257198664811099, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4283712266995009, 6.911199999999999, 6.9112, 121.9260426156618, 639330.5123609356, 639330.512360936, 180744.278351717], 
processed observation next is [1.0, 0.7391304347826086, 0.6944444444444444, 0.29, 1.0, 1.0, 0.11571269620368926, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.2854640333743761, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22833232584319127, 0.22833232584319144, 0.34758515067637885], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0494058], dtype=float32), 1.5602762]. 
=============================================
[2019-03-23 22:39:13,006] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:39:13,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:39:13,007] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:39:13,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:39:13,009] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:39:13,009] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:39:13,009] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:39:13,011] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:39:13,011] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:39:13,012] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:39:13,013] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:39:13,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 22:39:13,038] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 22:39:13,061] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 22:39:13,062] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 22:39:13,111] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 22:39:44,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:39:44,056] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.54806444666667, 85.96046698, 1.0, 2.0, 0.775209128355541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899564.2322018968, 899564.2322018968, 191679.4278821811]
[2019-03-23 22:39:44,057] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:39:44,060] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6281800614882582
[2019-03-23 22:40:02,799] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:02,801] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.5, 91.5, 1.0, 2.0, 0.4994128175512745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 597315.7428835197, 597315.7428835194, 142863.4141285697]
[2019-03-23 22:40:02,802] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:40:02,807] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8967392956096899
[2019-03-23 22:40:18,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:18,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.1, 89.0, 1.0, 2.0, 0.753598480393158, 1.0, 1.0, 0.753598480393158, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9248820300606, 1718788.332698158, 1718788.332698158, 324952.5963710189]
[2019-03-23 22:40:18,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:40:18,904] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05168007690283438
[2019-03-23 22:40:18,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1718788.332698158 W.
[2019-03-23 22:40:19,142] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:19,144] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 66.0, 1.0, 2.0, 0.9605771345587946, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.974222899651014, 6.9112, 121.9256675915287, 1140708.791272101, 1108435.532995385, 232091.6021508708]
[2019-03-23 22:40:19,144] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:40:19,146] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9712784543679118
[2019-03-23 22:40:20,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:20,252] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 94.0, 1.0, 2.0, 0.7948422791761713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905959.2321137297, 905959.2321137297, 194883.4481258615]
[2019-03-23 22:40:20,253] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:40:20,257] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.036728474603500705
[2019-03-23 22:40:25,750] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:25,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.09646252666667, 78.23857807666667, 1.0, 2.0, 0.6783921076334516, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1488139.030479919, 1488139.030479919, 313358.3996235094]
[2019-03-23 22:40:25,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:40:25,755] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1228268939686401
[2019-03-23 22:40:25,755] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1488139.030479919 W.
[2019-03-23 22:40:46,963] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:46,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.5957855647671071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687627.6496000605, 687627.6496000605, 157773.9547406602]
[2019-03-23 22:40:46,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:40:46,971] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9105700909006953
[2019-03-23 22:40:48,483] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.4120814]
[2019-03-23 22:40:48,485] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 77.0, 1.0, 2.0, 0.7241256019119819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883705.0942532007, 883705.0942532007, 183240.983387063]
[2019-03-23 22:40:48,485] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:40:48,487] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1592783e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9795187955270834
[2019-03-23 22:40:54,910] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:40:54,991] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:40:55,315] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:40:55,421] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:40:55,438] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:40:56,453] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1525000, evaluation results [1525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:41:02,535] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4205025e-24 1.0000000e+00 2.3176395e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:02,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7000
[2019-03-23 22:41:02,544] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 48.33333333333334, 1.0, 2.0, 0.7480068360116064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615618, 931047.7144932259, 931047.7144932259, 188509.5864576457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.71666666666667, 47.66666666666667, 1.0, 2.0, 0.7632341876177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950635.108880318, 950635.1088803175, 191634.0829601784], 
processed observation next is [1.0, 0.5217391304347826, 0.5450617283950618, 0.47666666666666674, 1.0, 1.0, 0.7181359376401191, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3395125388858279, 0.3395125388858277, 0.3685270826157277], 
reward next is 0.6315, 
noisyNet noise sample is [array([-1.7006217], dtype=float32), -0.18435042]. 
=============================================
[2019-03-23 22:41:04,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0323204e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:04,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8305
[2019-03-23 22:41:04,306] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 66.0, 1.0, 2.0, 0.3142578712587937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399041.7897404566, 399041.7897404566, 117345.1993184392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1648800.0000, 
sim time next is 1649400.0000, 
raw observation next is [21.48333333333333, 67.16666666666667, 1.0, 2.0, 0.5130906042522863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 651514.3627255817, 651514.3627255813, 145938.5653514462], 
processed observation next is [1.0, 0.08695652173913043, 0.3512345679012345, 0.6716666666666667, 1.0, 1.0, 0.4203459574431979, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23268370097342206, 0.2326837009734219, 0.2806510872143196], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.04340067], dtype=float32), 0.0747425]. 
=============================================
[2019-03-23 22:41:05,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8235304e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:05,964] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3262
[2019-03-23 22:41:05,971] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 98.0, 1.0, 2.0, 0.535858211647659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630982.5914931594, 630982.5914931594, 148323.2755444137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2256000.0000, 
sim time next is 2256600.0000, 
raw observation next is [22.35, 98.0, 1.0, 2.0, 0.5247841329304803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619794.6712019248, 619794.6712019248, 146606.6178025482], 
processed observation next is [1.0, 0.08695652173913043, 0.38333333333333336, 0.98, 1.0, 1.0, 0.43426682491723845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22135523971497315, 0.22135523971497315, 0.2819358034664388], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.34965247], dtype=float32), 2.5324223]. 
=============================================
[2019-03-23 22:41:07,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.998495e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:41:07,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7538
[2019-03-23 22:41:07,116] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.35, 69.0, 1.0, 2.0, 0.9168353423273282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.117978036393645, 6.9112, 121.9250713929785, 1240997.340699031, 1135109.347929891, 225144.2387597731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1695000.0000, 
sim time next is 1695600.0000, 
raw observation next is [23.4, 69.0, 1.0, 2.0, 0.9293877459980766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.19766794850163, 6.9112, 121.9246324187759, 1296591.746999765, 1149896.249852312, 228057.6793158924], 
processed observation next is [1.0, 0.6521739130434783, 0.42222222222222217, 0.69, 1.0, 1.0, 0.9159377928548531, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.028646794850163016, 0.0, 0.809452766579315, 0.4630684810713447, 0.4106772320901114, 0.43857246022287], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8135278], dtype=float32), -0.61947674]. 
=============================================
[2019-03-23 22:41:15,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2410373e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:15,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-23 22:41:15,405] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 90.33333333333334, 1.0, 2.0, 0.430481588839321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526717.3548389501, 526717.3548389501, 132827.9517976651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2087400.0000, 
sim time next is 2088000.0000, 
raw observation next is [21.2, 91.0, 1.0, 2.0, 0.4286356496197306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524602.9993731484, 524602.9993731484, 132562.9306741179], 
processed observation next is [0.0, 0.17391304347826086, 0.34074074074074073, 0.91, 1.0, 1.0, 0.3198043447853936, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18735821406183872, 0.18735821406183872, 0.25492871283484214], 
reward next is 0.7451, 
noisyNet noise sample is [array([1.3669449], dtype=float32), -0.3452901]. 
=============================================
[2019-03-23 22:41:15,421] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.360596]
 [72.360596]
 [72.360596]
 [72.360596]
 [72.360596]], R is [[72.38205719]
 [72.40279388]
 [72.42279816]
 [72.442276  ]
 [72.46148682]].
[2019-03-23 22:41:15,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.643568e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:41:15,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1122
[2019-03-23 22:41:15,976] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 79.66666666666667, 1.0, 2.0, 0.8017647072072939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 991123.2525348304, 991123.2525348304, 199506.0593129837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1857000.0000, 
sim time next is 1857600.0000, 
raw observation next is [21.9, 80.0, 1.0, 2.0, 0.8048721451297315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 994570.7589350571, 994570.7589350566, 200155.8101044679], 
processed observation next is [1.0, 0.5217391304347826, 0.36666666666666664, 0.8, 1.0, 1.0, 0.7677049346782517, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3552038424768061, 0.3552038424768059, 0.38491501943166906], 
reward next is 0.6151, 
noisyNet noise sample is [array([0.8756345], dtype=float32), -1.971209]. 
=============================================
[2019-03-23 22:41:20,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0877024e-24 1.0000000e+00 2.5519930e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:20,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0833
[2019-03-23 22:41:20,892] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.66666666666667, 1.0, 2.0, 0.4839988202271064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581349.8269153845, 581349.8269153845, 140549.3174520034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071200.0000, 
sim time next is 2071800.0000, 
raw observation next is [23.9, 79.0, 1.0, 2.0, 0.4812316632542629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578528.5895406122, 578528.5895406127, 140139.4401367291], 
processed observation next is [0.0, 1.0, 0.4407407407407407, 0.79, 1.0, 1.0, 0.38241864673126535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20661735340736148, 0.20661735340736165, 0.26949892333986364], 
reward next is 0.7305, 
noisyNet noise sample is [array([-1.1788796], dtype=float32), 0.6357086]. 
=============================================
[2019-03-23 22:41:22,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.591018e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:41:22,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8489
[2019-03-23 22:41:22,843] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 89.5, 1.0, 2.0, 0.384589664062062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479720.6134049647, 479720.6134049647, 126535.5258072171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1983000.0000, 
sim time next is 1983600.0000, 
raw observation next is [19.6, 90.0, 1.0, 2.0, 0.3727037209194766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466739.9671854268, 466739.9671854268, 124937.3477147367], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.9, 1.0, 1.0, 0.2532187153803293, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1666928454233667, 0.1666928454233667, 0.2402641302206475], 
reward next is 0.7597, 
noisyNet noise sample is [array([1.3814338], dtype=float32), -1.2492398]. 
=============================================
[2019-03-23 22:41:23,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3195551e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:23,265] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9670
[2019-03-23 22:41:23,269] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 91.5, 1.0, 2.0, 0.3650164658558199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 456371.6234671082, 456371.6234671077, 123882.4088999343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2007000.0000, 
sim time next is 2007600.0000, 
raw observation next is [19.76666666666667, 90.66666666666666, 1.0, 2.0, 0.3653928423047593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456733.3813334937, 456733.3813334937, 123931.2394638577], 
processed observation next is [0.0, 0.21739130434782608, 0.2876543209876544, 0.9066666666666666, 1.0, 1.0, 0.24451528845804682, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16311906476196203, 0.16311906476196203, 0.2383293066612648], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.18149744], dtype=float32), -0.015574011]. 
=============================================
[2019-03-23 22:41:29,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.354542e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:41:29,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5347
[2019-03-23 22:41:29,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.08333333333334, 50.5, 1.0, 2.0, 0.5670168790508037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658730.7007236711, 658730.7007236711, 153093.8867206312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2128200.0000, 
sim time next is 2128800.0000, 
raw observation next is [31.16666666666667, 50.00000000000001, 1.0, 2.0, 0.5651955083141743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657008.7065250205, 657008.7065250205, 152806.8928094555], 
processed observation next is [0.0, 0.6521739130434783, 0.7098765432098767, 0.5000000000000001, 1.0, 1.0, 0.48237560513592176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23464596661607875, 0.23464596661607875, 0.2938594092489529], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.07306412], dtype=float32), -0.10876369]. 
=============================================
[2019-03-23 22:41:32,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1445934e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:32,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0199
[2019-03-23 22:41:32,546] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 89.0, 1.0, 2.0, 0.6389522271495482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744835.7685452169, 744835.7685452169, 165704.2841612931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2169600.0000, 
sim time next is 2170200.0000, 
raw observation next is [24.13333333333333, 89.0, 1.0, 2.0, 0.6245746367383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728599.8148983652, 728599.8148983652, 163155.0482917241], 
processed observation next is [1.0, 0.08695652173913043, 0.44938271604938257, 0.89, 1.0, 1.0, 0.5530650437361341, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.260214219606559, 0.260214219606559, 0.31375970825331556], 
reward next is 0.6862, 
noisyNet noise sample is [array([-0.5505519], dtype=float32), -1.7796339]. 
=============================================
[2019-03-23 22:41:34,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1523589e-23 1.0000000e+00 1.4611323e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:34,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7311
[2019-03-23 22:41:34,606] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666666, 90.0, 1.0, 2.0, 0.3680275762529487, 1.0, 2.0, 0.3680275762529487, 1.0, 2.0, 0.5859118872160792, 6.911200000000001, 6.9112, 121.94756008, 1258720.059800518, 1258720.059800518, 283359.8617838447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2217000.0000, 
sim time next is 2217600.0000, 
raw observation next is [24.7, 91.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 9.459640878121764, 6.9112, 121.9155337444074, 2468600.148097454, 1163683.122633873, 245579.3798975835], 
processed observation next is [1.0, 0.6956521739130435, 0.4703703703703703, 0.91, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.2548440878121764, 0.0, 0.8093923608434626, 0.881642910034805, 0.4156011152263832, 0.4722680382645837], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7556604], dtype=float32), 0.032190353]. 
=============================================
[2019-03-23 22:41:35,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0346562e-21 1.0000000e+00 1.2986289e-33 1.8930912e-36 5.3593226e-36], sum to 1.0000
[2019-03-23 22:41:35,162] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3811
[2019-03-23 22:41:35,169] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 95.66666666666666, 1.0, 2.0, 0.5632102010780073, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654320.2793799406, 654320.2793799406, 152457.644550149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2222400.0000, 
sim time next is 2223000.0000, 
raw observation next is [23.3, 95.5, 1.0, 2.0, 0.5532743641115818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645303.8219831049, 645303.8219831049, 150921.791023264], 
processed observation next is [1.0, 0.7391304347826086, 0.41851851851851857, 0.955, 1.0, 1.0, 0.46818376679950213, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23046565070825176, 0.23046565070825176, 0.29023421350627693], 
reward next is 0.7098, 
noisyNet noise sample is [array([1.0304743], dtype=float32), -1.4953266]. 
=============================================
[2019-03-23 22:41:35,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[50.574757]
 [50.574757]
 [50.574757]
 [50.574757]
 [50.574757]], R is [[50.77877045]
 [50.27098465]
 [49.76827621]
 [49.27059555]
 [48.77788925]].
[2019-03-23 22:41:36,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6190489e-21 1.0000000e+00 8.3219958e-34 2.1533922e-37 2.3373524e-36], sum to 1.0000
[2019-03-23 22:41:36,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2094
[2019-03-23 22:41:36,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1329675.199401551 W.
[2019-03-23 22:41:36,268] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.13333333333333, 89.0, 1.0, 2.0, 0.3887556216153405, 1.0, 1.0, 0.3887556216153405, 1.0, 2.0, 0.6189116104983156, 6.9112, 6.9112, 121.94756008, 1329675.199401551, 1329675.199401551, 292191.5137945578], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2216400.0000, 
sim time next is 2217000.0000, 
raw observation next is [24.91666666666666, 90.0, 1.0, 2.0, 0.5520281393526921, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8788467761508539, 6.911199999999999, 6.9112, 121.9260426156618, 1258690.062861829, 1258690.06286183, 275659.4858392011], 
processed observation next is [1.0, 0.6521739130434783, 0.47839506172839485, 0.9, 1.0, 1.0, 0.46670016589606206, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8485584701885673, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4495321653077961, 0.44953216530779644, 0.5301143958446175], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8714201], dtype=float32), 0.05524419]. 
=============================================
[2019-03-23 22:41:36,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[51.281593]
 [51.281593]
 [51.281593]
 [51.281593]
 [51.281593]], R is [[50.76877975]
 [50.26109314]
 [49.75848389]
 [49.26089859]
 [49.13196182]].
[2019-03-23 22:41:42,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6591217e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:42,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0101
[2019-03-23 22:41:42,474] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 41.66666666666667, 1.0, 2.0, 0.6605099494491294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 828302.0881995057, 828302.0881995052, 171556.3622450665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2362800.0000, 
sim time next is 2363400.0000, 
raw observation next is [27.7, 41.5, 1.0, 2.0, 0.7717974533914647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 966779.5718291216, 966779.5718291216, 193513.8658002998], 
processed observation next is [1.0, 0.34782608695652173, 0.5814814814814815, 0.415, 1.0, 1.0, 0.7283303016565056, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34527841851040053, 0.34527841851040053, 0.37214204961596115], 
reward next is 0.6279, 
noisyNet noise sample is [array([-0.1193228], dtype=float32), -0.44651487]. 
=============================================
[2019-03-23 22:41:43,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8400534e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:43,046] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-23 22:41:43,050] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 96.0, 1.0, 2.0, 0.5033125377124583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604401.6493859722, 604401.6493859722, 143563.4620408373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2346600.0000, 
sim time next is 2347200.0000, 
raw observation next is [21.7, 96.0, 1.0, 2.0, 0.4896094906252275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588301.5979496023, 588301.5979496023, 141426.9974333128], 
processed observation next is [1.0, 0.17391304347826086, 0.3592592592592592, 0.96, 1.0, 1.0, 0.39239225074431844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2101077135534294, 0.2101077135534294, 0.2719749950640631], 
reward next is 0.7280, 
noisyNet noise sample is [array([0.02946267], dtype=float32), -0.051830087]. 
=============================================
[2019-03-23 22:41:46,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0673092e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:41:46,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9831
[2019-03-23 22:41:46,371] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 43.0, 1.0, 2.0, 0.3980457636829498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491541.2408701501, 491541.2408701501, 128305.7733391776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2401200.0000, 
sim time next is 2401800.0000, 
raw observation next is [28.53333333333333, 43.33333333333334, 1.0, 2.0, 0.3971317555418499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490834.4865633972, 490834.4865633972, 128187.5029557526], 
processed observation next is [1.0, 0.8260869565217391, 0.6123456790123456, 0.4333333333333334, 1.0, 1.0, 0.28229970897839274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.175298030915499, 0.175298030915499, 0.2465144287610627], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.948647], dtype=float32), 1.0368955]. 
=============================================
[2019-03-23 22:41:46,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.249759e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:41:46,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9643
[2019-03-23 22:41:46,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1534357.275629237 W.
[2019-03-23 22:41:46,542] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4485384106540056, 1.0, 1.0, 0.4485384106540056, 1.0, 2.0, 0.714087757637383, 6.9112, 6.9112, 121.94756008, 1534357.275629237, 1534357.275629237, 318996.8797690921], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2992200.0000, 
sim time next is 2992800.0000, 
raw observation next is [25.33333333333334, 92.33333333333334, 1.0, 2.0, 0.7186671554623092, 1.0, 2.0, 0.7186671554623092, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1639044.749691494, 1639044.749691494, 311292.2528988568], 
processed observation next is [1.0, 0.6521739130434783, 0.49382716049382736, 0.9233333333333335, 1.0, 1.0, 0.6650799469789395, 1.0, 1.0, 0.6650799469789395, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5853731248898193, 0.5853731248898193, 0.598638947882417], 
reward next is 0.4014, 
noisyNet noise sample is [array([-0.00407916], dtype=float32), -0.36461052]. 
=============================================
[2019-03-23 22:41:46,658] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 22:41:46,660] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:41:46,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:41:46,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:46,662] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:41:46,664] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:41:46,666] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:41:46,662] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:46,668] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:46,668] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:46,667] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:46,689] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 22:41:46,714] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 22:41:46,736] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 22:41:46,761] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 22:41:46,762] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 22:42:09,582] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:09,583] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 71.0, 1.0, 2.0, 0.3677348923011368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459958.9593121283, 459958.9593121283, 124253.0790138923]
[2019-03-23 22:42:09,584] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:42:09,587] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.985105541007443
[2019-03-23 22:42:09,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:09,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.2148697, 46.52184339666667, 1.0, 2.0, 0.3569164454314743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448223.1601829343, 448223.1601829343, 122828.1596099831]
[2019-03-23 22:42:09,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:42:09,765] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1024488987161144
[2019-03-23 22:42:42,630] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:42,631] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.83333333333334, 53.0, 1.0, 2.0, 0.7382594656500615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 841430.8802918093, 841430.880291809, 183518.273653064]
[2019-03-23 22:42:42,632] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:42:42,633] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9706827516699137
[2019-03-23 22:42:45,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:45,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.348069945, 76.71805376166667, 1.0, 2.0, 0.8723912941774475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1065340.210346007, 1065340.210346006, 214540.6822842841]
[2019-03-23 22:42:45,372] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:42:45,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5567992164055848
[2019-03-23 22:42:58,778] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:58,779] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.1, 64.0, 1.0, 2.0, 0.6153562836416204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703075.1087642849, 703075.1087642849, 160827.7125654496]
[2019-03-23 22:42:58,781] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:42:58,783] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5609331291742323
[2019-03-23 22:42:59,306] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:42:59,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.035892525, 67.54377488, 1.0, 2.0, 0.4644021747557848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563439.3134807923, 563439.3134807923, 137737.5669406987]
[2019-03-23 22:42:59,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:42:59,310] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9357620995273181
[2019-03-23 22:43:11,808] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:43:11,810] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.4897450149538367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584063.5757197806, 584063.5757197806, 141290.930973653]
[2019-03-23 22:43:11,810] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:43:11,815] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9695319287128401
[2019-03-23 22:43:23,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3740845]
[2019-03-23 22:43:23,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.9, 79.0, 1.0, 2.0, 0.4702041824265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 565518.8106887608, 565518.8106887604, 138458.6000358745]
[2019-03-23 22:43:23,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:43:23,553] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8790181e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6427999479181915
[2019-03-23 22:43:28,046] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:43:28,405] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:43:28,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:43:28,678] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:43:28,939] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:43:29,953] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1550000, evaluation results [1550000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:43:30,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0213447e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:43:30,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1775
[2019-03-23 22:43:30,727] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333334, 63.0, 1.0, 2.0, 0.4677973381928228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600558.0168356763, 600558.0168356763, 138820.9235446876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2427000.0000, 
sim time next is 2427600.0000, 
raw observation next is [20.76666666666667, 64.0, 1.0, 2.0, 0.364258662723538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467614.5108516598, 467614.5108516598, 123883.1791230963], 
processed observation next is [1.0, 0.08695652173913043, 0.32469135802469146, 0.64, 1.0, 1.0, 0.2431650746708786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16700518244702137, 0.16700518244702137, 0.23823688292903134], 
reward next is 0.7618, 
noisyNet noise sample is [array([0.5930198], dtype=float32), 1.2606584]. 
=============================================
[2019-03-23 22:43:40,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.725423e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:43:40,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0588
[2019-03-23 22:43:40,179] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.83333333333333, 1.0, 2.0, 0.5424266417892043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639520.6459540956, 639520.6459540952, 149428.9725322851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2638200.0000, 
sim time next is 2638800.0000, 
raw observation next is [25.0, 78.0, 1.0, 2.0, 0.537642247684299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635339.1946563706, 635339.1946563706, 148705.3111686533], 
processed observation next is [0.0, 0.5652173913043478, 0.48148148148148145, 0.78, 1.0, 1.0, 0.44957410438607026, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22690685523441806, 0.22690685523441806, 0.2859717522474102], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.48397827], dtype=float32), 0.31659228]. 
=============================================
[2019-03-23 22:43:41,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5926972e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:43:41,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5405
[2019-03-23 22:43:41,183] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 75.66666666666667, 1.0, 2.0, 0.5593360506258221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653979.8334402264, 653979.8334402264, 151996.8708593738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2643000.0000, 
sim time next is 2643600.0000, 
raw observation next is [26.2, 75.33333333333334, 1.0, 2.0, 0.5661863187073365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660109.2236011971, 660109.2236011971, 153059.2910414867], 
processed observation next is [0.0, 0.6086956521739131, 0.5259259259259259, 0.7533333333333334, 1.0, 1.0, 0.4835551413182577, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2357532941432847, 0.2357532941432847, 0.2943447904643975], 
reward next is 0.7057, 
noisyNet noise sample is [array([0.06824593], dtype=float32), -0.2420907]. 
=============================================
[2019-03-23 22:43:52,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.450989e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:43:52,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-23 22:43:52,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 96.0, 1.0, 2.0, 0.5420500040597784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639883.7637113745, 639883.7637113745, 149400.1401901021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2853600.0000, 
sim time next is 2854200.0000, 
raw observation next is [22.83333333333334, 95.0, 1.0, 2.0, 0.5457146209060896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643655.39165634, 643655.3916563404, 149979.7710566662], 
processed observation next is [1.0, 0.0, 0.4012345679012348, 0.95, 1.0, 1.0, 0.45918407250724946, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22987692559154999, 0.22987692559155015, 0.288422636647435], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.14336663], dtype=float32), -0.08059061]. 
=============================================
[2019-03-23 22:43:53,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2345268e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:43:53,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6797
[2019-03-23 22:43:53,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.08333333333334, 98.5, 1.0, 2.0, 0.7131324677796188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846304.3051973502, 846304.3051973502, 180206.7990436283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2861400.0000, 
sim time next is 2862000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.6626077533301579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784989.0747185445, 784989.0747185445, 170558.4491279759], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.5983425634882832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28035324097090875, 0.28035324097090875, 0.32799701755379984], 
reward next is 0.6720, 
noisyNet noise sample is [array([-1.5905931], dtype=float32), -0.9927461]. 
=============================================
[2019-03-23 22:43:53,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.9803]
 [66.9803]
 [66.9803]
 [66.9803]
 [66.9803]], R is [[66.98249817]
 [66.96612549]
 [66.94594574]
 [66.27648926]
 [66.10886383]].
[2019-03-23 22:43:53,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.326793e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:43:53,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0964
[2019-03-23 22:43:53,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1408977.531123394 W.
[2019-03-23 22:43:53,610] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.43333333333334, 90.66666666666667, 1.0, 2.0, 0.6108915087964957, 1.0, 1.0, 0.6108915087964957, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256930638042, 1408977.531123394, 1408977.531123394, 272589.9008109774], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2888400.0000, 
sim time next is 2889000.0000, 
raw observation next is [23.65, 89.0, 1.0, 2.0, 0.4093696704504031, 1.0, 2.0, 0.4093696704504031, 1.0, 1.0, 0.6517298475964362, 6.9112, 6.9112, 121.94756008, 1400246.630554183, 1400246.630554183, 301210.8921122546], 
processed observation next is [1.0, 0.43478260869565216, 0.4314814814814814, 0.89, 1.0, 1.0, 0.29686865529809897, 1.0, 1.0, 0.29686865529809897, 1.0, 0.5, 0.5646623094955452, 0.0, 0.0, 0.8096049824067558, 0.5000880823407796, 0.5000880823407796, 0.5792517156004896], 
reward next is 0.4207, 
noisyNet noise sample is [array([-0.1250583], dtype=float32), -0.056903407]. 
=============================================
[2019-03-23 22:43:53,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.411118]
 [61.411118]
 [61.411118]
 [61.411118]
 [61.411118]], R is [[61.21776199]
 [60.60558319]
 [59.99952698]
 [59.39953232]
 [58.80553818]].
[2019-03-23 22:43:53,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1963525e-25 1.0000000e+00 1.3561439e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:43:53,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2267
[2019-03-23 22:43:53,675] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 94.0, 1.0, 2.0, 0.5221099896723945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625007.2064691097, 625007.2064691097, 146495.1361821729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871600.0000, 
sim time next is 2872200.0000, 
raw observation next is [22.06666666666667, 94.0, 1.0, 2.0, 0.515185894179611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617462.4393169502, 617462.4393169502, 145409.8856975252], 
processed observation next is [1.0, 0.21739130434782608, 0.3728395061728396, 0.94, 1.0, 1.0, 0.4228403502138226, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2205222997560536, 0.2205222997560536, 0.27963439557216385], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.54233164], dtype=float32), 0.62376994]. 
=============================================
[2019-03-23 22:43:56,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3753354e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:43:56,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0381
[2019-03-23 22:43:56,586] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 85.66666666666667, 1.0, 2.0, 0.6604289601480257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 752680.0431125803, 752680.0431125798, 168786.3083789485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2922600.0000, 
sim time next is 2923200.0000, 
raw observation next is [26.0, 85.0, 1.0, 2.0, 0.6549002147889951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746375.9551190342, 746375.9551190342, 167779.9148239584], 
processed observation next is [1.0, 0.8695652173913043, 0.5185185185185185, 0.85, 1.0, 1.0, 0.5891669223678513, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2665628411139408, 0.2665628411139408, 0.3226536823537661], 
reward next is 0.6773, 
noisyNet noise sample is [array([-0.8181401], dtype=float32), 0.37389985]. 
=============================================
[2019-03-23 22:43:57,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.810948e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:43:57,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9346
[2019-03-23 22:43:57,130] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 90.0, 1.0, 2.0, 0.6460838069726847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736323.2552639624, 736323.2552639624, 166186.2659664574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2935800.0000, 
sim time next is 2936400.0000, 
raw observation next is [25.16666666666667, 90.33333333333334, 1.0, 2.0, 0.6465684997179202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736875.9112433739, 736875.9112433739, 166273.5592879111], 
processed observation next is [1.0, 1.0, 0.4876543209876545, 0.9033333333333334, 1.0, 1.0, 0.579248213949905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.263169968301205, 0.263169968301205, 0.31975684478444444], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.595507], dtype=float32), 0.735036]. 
=============================================
[2019-03-23 22:44:00,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3040741e-22 1.0000000e+00 3.6060880e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:44:00,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4862
[2019-03-23 22:44:00,548] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6700423593875182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763641.7339361912, 763641.7339361907, 170548.7111947747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3013200.0000, 
sim time next is 3013800.0000, 
raw observation next is [24.83333333333334, 95.0, 1.0, 2.0, 0.6697633206911303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763323.5574954136, 763323.5574954136, 170497.1716030522], 
processed observation next is [1.0, 0.9130434782608695, 0.47530864197530887, 0.95, 1.0, 1.0, 0.6068610960608694, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.272615556248362, 0.272615556248362, 0.3278791761597158], 
reward next is 0.6721, 
noisyNet noise sample is [array([1.0273842], dtype=float32), -2.2079673]. 
=============================================
[2019-03-23 22:44:06,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.446922e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:44:06,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3048
[2019-03-23 22:44:06,783] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 63.0, 1.0, 2.0, 0.5724565294969913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665057.7838694097, 665057.7838694097, 154007.6731573356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3106800.0000, 
sim time next is 3107400.0000, 
raw observation next is [28.41666666666666, 62.16666666666666, 1.0, 2.0, 0.5679403015571299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661731.3759892818, 661731.3759892818, 153334.2411957794], 
processed observation next is [1.0, 1.0, 0.6080246913580245, 0.6216666666666666, 1.0, 1.0, 0.4856432161394404, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23633263428188636, 0.23633263428188636, 0.2948735407611143], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.80199856], dtype=float32), -1.435383]. 
=============================================
[2019-03-23 22:44:08,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0025804e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:44:08,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2200
[2019-03-23 22:44:08,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1827579.230576507 W.
[2019-03-23 22:44:08,916] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.96666666666667, 52.16666666666667, 1.0, 2.0, 0.8005645312817092, 1.0, 2.0, 0.8005645312817092, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426154992, 1827579.230576507, 1827579.230576508, 344070.0939765544], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3142200.0000, 
sim time next is 3142800.0000, 
raw observation next is [30.0, 52.0, 1.0, 2.0, 0.5181229991839157, 1.0, 2.0, 0.5181229991839157, 1.0, 1.0, 0.8248686887888359, 6.911199999999997, 6.9112, 121.94756008, 1772635.774698271, 1772635.774698272, 352573.073914781], 
processed observation next is [1.0, 0.391304347826087, 0.6666666666666666, 0.52, 1.0, 1.0, 0.4263369037903758, 1.0, 1.0, 0.4263369037903758, 1.0, 0.5, 0.7810858609860449, -2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.6330842052493825, 0.6330842052493829, 0.6780251421438096], 
reward next is 0.3220, 
noisyNet noise sample is [array([0.34518284], dtype=float32), -0.07860524]. 
=============================================
[2019-03-23 22:44:13,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2271873e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:44:13,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4813
[2019-03-23 22:44:13,362] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 42.5, 1.0, 2.0, 0.5378371488195902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631953.3831294867, 631953.3831294867, 148590.0775396554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252600.0000, 
sim time next is 3253200.0000, 
raw observation next is [32.66666666666667, 43.0, 1.0, 2.0, 0.549470300284706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642487.571370909, 642487.571370909, 150365.0762703643], 
processed observation next is [0.0, 0.6521739130434783, 0.7654320987654323, 0.43, 1.0, 1.0, 0.46365511938655474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22945984691818178, 0.22945984691818178, 0.2891636082122391], 
reward next is 0.7108, 
noisyNet noise sample is [array([-0.27415693], dtype=float32), 1.7104127]. 
=============================================
[2019-03-23 22:44:18,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8556566e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:44:18,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2977
[2019-03-23 22:44:18,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.656055196167234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747692.9050019969, 747692.9050019969, 167990.0865584463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3328800.0000, 
sim time next is 3329400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6577575185660002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 749633.9562521745, 749633.956252174, 168299.5946329774], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5925684744833335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2677264129472052, 0.267726412947205, 0.3236530666018796], 
reward next is 0.6763, 
noisyNet noise sample is [array([0.06415787], dtype=float32), 0.33623937]. 
=============================================
[2019-03-23 22:44:18,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.88039e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:44:19,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7606
[2019-03-23 22:44:19,007] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 76.66666666666667, 1.0, 2.0, 0.6725027176248161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766447.1857683905, 766447.1857683905, 171003.1903993582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3334800.0000, 
sim time next is 3335400.0000, 
raw observation next is [28.05, 76.0, 1.0, 2.0, 0.6833903263783068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778862.0303715129, 778862.0303715124, 173023.380896441], 
processed observation next is [0.0, 0.6086956521739131, 0.5944444444444444, 0.76, 1.0, 1.0, 0.6230837218789366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2781650108469689, 0.2781650108469687, 0.33273727095469424], 
reward next is 0.6673, 
noisyNet noise sample is [array([0.34247166], dtype=float32), 0.22497003]. 
=============================================
[2019-03-23 22:44:19,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.028489e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:44:19,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5945
[2019-03-23 22:44:19,199] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 78.0, 1.0, 2.0, 0.6563930315369608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748078.117052158, 748078.117052158, 168051.2031212042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3333600.0000, 
sim time next is 3334200.0000, 
raw observation next is [27.41666666666667, 77.33333333333333, 1.0, 2.0, 0.6630909740381354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755715.3921742433, 755715.3921742433, 169273.2585985254], 
processed observation next is [0.0, 0.6086956521739131, 0.5709876543209879, 0.7733333333333333, 1.0, 1.0, 0.5989178262358755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26989835434794407, 0.26989835434794407, 0.3255254973048565], 
reward next is 0.6745, 
noisyNet noise sample is [array([1.4946859], dtype=float32), -1.1362481]. 
=============================================
[2019-03-23 22:44:20,085] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 22:44:20,088] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:44:20,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:44:20,090] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:44:20,090] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:44:20,092] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:44:20,093] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:44:20,093] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:44:20,092] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:44:20,096] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:44:20,093] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:44:20,119] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 22:44:20,144] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 22:44:20,145] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 22:44:20,145] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 22:44:20,194] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 22:45:06,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3700371]
[2019-03-23 22:45:06,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.4968562031045753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596458.5941132623, 596458.5941132623, 142540.3549543247]
[2019-03-23 22:45:06,401] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:45:06,404] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.130065e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.860493364688175
[2019-03-23 22:45:16,143] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3700371]
[2019-03-23 22:45:16,145] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.53333333333333, 93.33333333333334, 1.0, 2.0, 0.7737701673325889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 883998.56186385, 883998.5618638486, 190683.6765101138]
[2019-03-23 22:45:16,146] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:45:16,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.130065e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6524606057231274
[2019-03-23 22:45:23,646] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3700371]
[2019-03-23 22:45:23,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.66728203, 101.3890782, 1.0, 2.0, 0.6833727385819724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778841.9753228083, 778841.9753228083, 173020.255091827]
[2019-03-23 22:45:23,651] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:45:23,653] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.130065e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.45875527903536095
[2019-03-23 22:45:58,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3700371]
[2019-03-23 22:45:58,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.9, 87.0, 1.0, 2.0, 0.4253191647055198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519203.1123151537, 519203.1123151532, 132043.4499645171]
[2019-03-23 22:45:58,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:45:58,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.130065e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2892083606638506
[2019-03-23 22:45:58,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.3700371]
[2019-03-23 22:45:58,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.3496984, 72.65879298, 1.0, 2.0, 0.44333045901409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538769.2340534787, 538769.2340534787, 134611.0842588996]
[2019-03-23 22:45:58,800] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:45:58,804] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.130065e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7988960490551381
[2019-03-23 22:46:02,497] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:46:02,837] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:46:02,951] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:46:02,972] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:46:03,052] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:46:04,066] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1575000, evaluation results [1575000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:46:12,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6282742e-23 1.0000000e+00 9.3736258e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:12,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8939
[2019-03-23 22:46:12,769] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 72.0, 1.0, 2.0, 0.5648036793334628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652371.6432526987, 652371.6432526987, 152551.3005535639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3519000.0000, 
sim time next is 3519600.0000, 
raw observation next is [27.16666666666667, 74.33333333333333, 1.0, 2.0, 0.58337100604841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 669763.5517666665, 669763.551766666, 155484.3246604036], 
processed observation next is [1.0, 0.7391304347826086, 0.5617283950617286, 0.7433333333333333, 1.0, 1.0, 0.5040131024385833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23920126848809517, 0.239201268488095, 0.2990083166546223], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.2422878], dtype=float32), -0.09044565]. 
=============================================
[2019-03-23 22:46:13,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4498513e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:13,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6101
[2019-03-23 22:46:13,966] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 88.33333333333334, 1.0, 2.0, 0.4822217530721446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580428.4370370995, 580428.437037099, 140316.3183933349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3547200.0000, 
sim time next is 3547800.0000, 
raw observation next is [22.8, 85.5, 1.0, 2.0, 0.4779677947699353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576311.7512919304, 576311.7512919304, 139694.800353021], 
processed observation next is [1.0, 0.043478260869565216, 0.4, 0.855, 1.0, 1.0, 0.37853308901182775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20582562546140373, 0.20582562546140373, 0.26864384683273274], 
reward next is 0.7314, 
noisyNet noise sample is [array([1.8981469], dtype=float32), -1.1653521]. 
=============================================
[2019-03-23 22:46:15,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4522014e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:15,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5917
[2019-03-23 22:46:15,433] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333333, 74.0, 1.0, 2.0, 0.5917612412142687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686358.2195252635, 686358.2195252635, 157239.0434101971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808200.0000, 
sim time next is 3808800.0000, 
raw observation next is [26.7, 72.0, 1.0, 2.0, 0.579787430937748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675223.980189638, 675223.980189638, 155320.1993962217], 
processed observation next is [0.0, 0.08695652173913043, 0.5444444444444444, 0.72, 1.0, 1.0, 0.4997469415925571, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24115142149629928, 0.24115142149629928, 0.2986926911465802], 
reward next is 0.7013, 
noisyNet noise sample is [array([-0.30606857], dtype=float32), -0.829624]. 
=============================================
[2019-03-23 22:46:15,434] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.200545e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:46:15,438] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6758
[2019-03-23 22:46:15,446] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.5, 1.0, 2.0, 0.4674151029483292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565568.7048263142, 565568.7048263142, 138147.5465554538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3562200.0000, 
sim time next is 3562800.0000, 
raw observation next is [23.06666666666667, 84.66666666666666, 1.0, 2.0, 0.4747596557315575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571972.5794886055, 571972.5794886055, 139187.2593974828], 
processed observation next is [1.0, 0.21739130434782608, 0.40987654320987665, 0.8466666666666666, 1.0, 1.0, 0.3747138758709018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20427592124593053, 0.20427592124593053, 0.26766780653362077], 
reward next is 0.7323, 
noisyNet noise sample is [array([0.24047183], dtype=float32), -1.1083155]. 
=============================================
[2019-03-23 22:46:22,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9810446e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:22,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6177
[2019-03-23 22:46:22,517] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.66666666666666, 1.0, 2.0, 0.8380881399994127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156103, 955281.4774415961, 955281.4774415961, 203930.7867436251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3724800.0000, 
sim time next is 3725400.0000, 
raw observation next is [24.95, 94.33333333333334, 1.0, 2.0, 0.8163253053881283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 930460.3961532767, 930460.3961532762, 199331.8564211188], 
processed observation next is [1.0, 0.08695652173913043, 0.47962962962962963, 0.9433333333333335, 1.0, 1.0, 0.7813396492715813, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.332307284340456, 0.3323072843404558, 0.38333049311753614], 
reward next is 0.6167, 
noisyNet noise sample is [array([-1.1478447], dtype=float32), 1.0641019]. 
=============================================
[2019-03-23 22:46:26,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.083028e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:46:26,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7835
[2019-03-23 22:46:26,779] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 79.0, 1.0, 2.0, 0.6266055113852503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717501.9396928785, 717501.9396928785, 162882.9673076873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3803400.0000, 
sim time next is 3804000.0000, 
raw observation next is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.6309695370669983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721121.8955817649, 721121.8955817653, 163588.0578404977], 
processed observation next is [0.0, 0.0, 0.5308641975308644, 0.8066666666666668, 1.0, 1.0, 0.5606780203178551, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2575435341363446, 0.2575435341363448, 0.31459241892403406], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.17003411], dtype=float32), 0.5092691]. 
=============================================
[2019-03-23 22:46:26,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.272667]
 [57.272667]
 [57.272667]
 [57.272667]
 [57.272667]], R is [[57.38534546]
 [57.49825668]
 [57.61079407]
 [57.722332  ]
 [57.83137131]].
[2019-03-23 22:46:28,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.02575645e-27 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:46:28,305] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9188
[2019-03-23 22:46:28,316] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333333, 51.0, 1.0, 2.0, 0.6481785967793179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738711.7777041461, 738711.7777041461, 166562.782038945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3840000.0000, 
sim time next is 3840600.0000, 
raw observation next is [32.16666666666666, 48.0, 1.0, 2.0, 0.6220688465859998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714722.5073302977, 714722.5073302977, 162199.7901033965], 
processed observation next is [0.0, 0.43478260869565216, 0.7469135802469132, 0.48, 1.0, 1.0, 0.5500819602214283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2552580383322492, 0.2552580383322492, 0.31192267327576245], 
reward next is 0.6881, 
noisyNet noise sample is [array([-1.3491894], dtype=float32), 0.22805162]. 
=============================================
[2019-03-23 22:46:28,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.623431e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:46:28,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8571
[2019-03-23 22:46:28,753] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 73.0, 1.0, 2.0, 0.5644940898804863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660367.1454318785, 660367.1454318785, 152872.7495798923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3817800.0000, 
sim time next is 3818400.0000, 
raw observation next is [26.4, 71.0, 1.0, 2.0, 0.5551715643455029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652211.1241779516, 652211.1241779516, 151436.3703513848], 
processed observation next is [0.0, 0.17391304347826086, 0.5333333333333333, 0.71, 1.0, 1.0, 0.470442338506551, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23293254434926844, 0.23293254434926844, 0.2912237891372785], 
reward next is 0.7088, 
noisyNet noise sample is [array([-1.2579602], dtype=float32), 0.775681]. 
=============================================
[2019-03-23 22:46:33,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0687035e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:33,327] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-23 22:46:33,334] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.730687373195987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 832795.9027382996, 832795.9027382991, 182036.6809763397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3910800.0000, 
sim time next is 3911400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7320073223076495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834301.1244464569, 834301.1244464569, 182293.692103545], 
processed observation next is [0.0, 0.2608695652173913, 0.5185185185185185, 0.94, 1.0, 1.0, 0.680961097985297, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.297964687302306, 0.297964687302306, 0.3505647925068173], 
reward next is 0.6494, 
noisyNet noise sample is [array([0.61328983], dtype=float32), -0.7079154]. 
=============================================
[2019-03-23 22:46:50,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2873562e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:50,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8777
[2019-03-23 22:46:50,110] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 65.5, 1.0, 2.0, 0.4247945727126373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521366.4954598566, 521366.4954598566, 132044.7330957495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4240200.0000, 
sim time next is 4240800.0000, 
raw observation next is [24.4, 67.0, 1.0, 2.0, 0.4243797512685884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520974.327480688, 520974.327480688, 131987.6899759992], 
processed observation next is [1.0, 0.08695652173913043, 0.4592592592592592, 0.67, 1.0, 1.0, 0.31473779912927186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18606225981453142, 0.18606225981453142, 0.2538224807230754], 
reward next is 0.7462, 
noisyNet noise sample is [array([0.21445855], dtype=float32), -0.12216495]. 
=============================================
[2019-03-23 22:46:51,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.718829e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:46:51,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4223
[2019-03-23 22:46:51,906] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 80.33333333333333, 1.0, 2.0, 0.383564133127775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476429.3078101993, 476429.3078101993, 126353.3763818865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4254000.0000, 
sim time next is 4254600.0000, 
raw observation next is [21.26666666666667, 81.66666666666667, 1.0, 2.0, 0.38055044511115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473231.0643949041, 473231.0643949037, 125949.6476042653], 
processed observation next is [1.0, 0.21739130434782608, 0.34320987654320995, 0.8166666666666668, 1.0, 1.0, 0.26256005370375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16901109442675147, 0.16901109442675133, 0.24221086077743326], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.82980955], dtype=float32), 0.783083]. 
=============================================
[2019-03-23 22:46:54,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0641542e-24 1.0000000e+00 5.0131914e-36 0.0000000e+00 5.5448596e-38], sum to 1.0000
[2019-03-23 22:46:54,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-23 22:46:54,084] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6130068705476998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705931.64816092, 705931.64816092, 160687.686198488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [26.78333333333333, 74.0, 1.0, 2.0, 0.6027933885313154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696414.5724932022, 696414.5724932022, 159016.3283177271], 
processed observation next is [1.0, 0.9565217391304348, 0.5475308641975308, 0.74, 1.0, 1.0, 0.527134986346804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24871949017614364, 0.24871949017614364, 0.30580063138024444], 
reward next is 0.6942, 
noisyNet noise sample is [array([1.2672707], dtype=float32), 0.062377766]. 
=============================================
[2019-03-23 22:46:54,263] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 22:46:54,264] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:46:54,265] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:46:54,265] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:54,265] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:54,265] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:46:54,268] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:46:54,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:46:54,270] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:54,270] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:54,272] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:54,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 22:46:54,319] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 22:46:54,343] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 22:46:54,369] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 22:46:54,372] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 22:47:04,873] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:47:04,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.74388923333333, 36.8536213, 1.0, 2.0, 0.2932165627208152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378237.8848006765, 378237.8848006761, 109137.7630526658]
[2019-03-23 22:47:04,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:47:04,878] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.9685558791685583
[2019-03-23 22:47:36,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:47:36,675] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 98.66666666666666, 1.0, 2.0, 0.5928792599395037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685741.3057570759, 685741.3057570759, 157343.1154256288]
[2019-03-23 22:47:36,676] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:36,679] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.042763584573625946
[2019-03-23 22:47:40,023] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:47:40,025] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.13075756333334, 58.21577977333334, 1.0, 2.0, 0.4759593472267546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573789.0032313108, 573789.0032313108, 139382.9013737093]
[2019-03-23 22:47:40,027] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:47:40,029] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.5250387959212264
[2019-03-23 22:47:43,925] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:47:43,926] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.76888662, 66.57119302, 1.0, 2.0, 0.4660747999575542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561674.5600989639, 561674.5600989639, 137869.5036544825]
[2019-03-23 22:47:43,927] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:47:43,929] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.16334875790034054
[2019-03-23 22:47:49,826] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:47:49,827] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.4, 87.66666666666667, 1.0, 2.0, 0.5905951566515385, 1.0, 1.0, 0.5905951566515385, 1.0, 1.0, 0.9402467237306821, 6.9112, 6.9112, 122.6481493992758, 2020849.589813647, 2020849.589813647, 390453.393339048]
[2019-03-23 22:47:49,828] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:49,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.19018234726891348
[2019-03-23 22:47:49,831] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2020849.589813647 W.
[2019-03-23 22:48:00,853] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:48:00,854] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 77.66666666666667, 1.0, 2.0, 0.6086021051990292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 723479.3692506243, 723479.3692506239, 160903.2816614294]
[2019-03-23 22:48:00,855] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:48:00,858] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.6378404638653509
[2019-03-23 22:48:03,459] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:48:03,460] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 86.5, 1.0, 2.0, 0.694565277759069, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1506598.310007861, 1506598.310007861, 316245.7042245623]
[2019-03-23 22:48:03,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:48:03,466] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.03381547975770438
[2019-03-23 22:48:03,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1506598.310007861 W.
[2019-03-23 22:48:18,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1358247]
[2019-03-23 22:48:18,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.42975455, 75.57781955, 1.0, 2.0, 0.8015972309603423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 913663.0987081259, 913663.0987081259, 196280.4134083502]
[2019-03-23 22:48:18,239] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:48:18,241] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.378235e-23 1.000000e+00 6.204792e-36 0.000000e+00 0.000000e+00], sampled 0.9796897936362965
[2019-03-23 22:48:36,751] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:48:37,052] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:48:37,213] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:48:37,258] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:48:37,275] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:48:38,291] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1600000, evaluation results [1600000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:48:43,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9252324e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:43,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 22:48:43,714] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 78.33333333333334, 1.0, 2.0, 0.5553034366926217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654210.4289146812, 654210.4289146812, 151534.5712762493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4401600.0000, 
sim time next is 4402200.0000, 
raw observation next is [24.78333333333333, 78.16666666666666, 1.0, 2.0, 0.5385271867271654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638057.4717540786, 638057.4717540786, 148915.8895508468], 
processed observation next is [1.0, 0.9565217391304348, 0.4734567901234567, 0.7816666666666666, 1.0, 1.0, 0.45062760324662543, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22787766848359953, 0.22787766848359953, 0.2863767106747054], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.50594693], dtype=float32), 0.55885977]. 
=============================================
[2019-03-23 22:48:49,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3862618e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:49,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-23 22:48:49,106] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 82.0, 1.0, 2.0, 0.8076347456277324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 920548.810373055, 920548.8103730537, 197529.4553938703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5083200.0000, 
sim time next is 5083800.0000, 
raw observation next is [28.66666666666666, 83.16666666666667, 1.0, 2.0, 0.7849912267545391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 894724.4730229318, 894724.4730229314, 192865.8666804119], 
processed observation next is [0.0, 0.8695652173913043, 0.6172839506172837, 0.8316666666666667, 1.0, 1.0, 0.7440371747077846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3195444546510471, 0.3195444546510469, 0.3708958974623306], 
reward next is 0.6291, 
noisyNet noise sample is [array([-0.8560325], dtype=float32), -0.3522299]. 
=============================================
[2019-03-23 22:48:49,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.053689e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:48:49,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5089
[2019-03-23 22:48:49,461] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 91.33333333333334, 1.0, 2.0, 0.5794330857793148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 675025.0614722486, 675025.0614722482, 155269.9272334273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4501200.0000, 
sim time next is 4501800.0000, 
raw observation next is [23.95, 92.0, 1.0, 2.0, 0.5834772491726299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678279.8887525077, 678279.8887525077, 155892.79314699], 
processed observation next is [0.0, 0.08695652173913043, 0.4425925925925926, 0.92, 1.0, 1.0, 0.5041395823483689, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2422428174116099, 0.2422428174116099, 0.2997938329749808], 
reward next is 0.7002, 
noisyNet noise sample is [array([1.9565904], dtype=float32), -0.03833839]. 
=============================================
[2019-03-23 22:48:53,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0141297e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:53,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7062
[2019-03-23 22:48:53,494] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1624136.367538489 W.
[2019-03-23 22:48:53,499] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.23333333333333, 87.66666666666666, 1.0, 2.0, 0.4747575808366449, 1.0, 1.0, 0.4747575808366449, 1.0, 1.0, 0.7558295304669037, 6.911199999999999, 6.9112, 121.94756008, 1624136.367538489, 1624136.36753849, 331372.6178332629], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4610400.0000, 
sim time next is 4611000.0000, 
raw observation next is [25.61666666666667, 88.33333333333334, 1.0, 2.0, 0.4439437495780523, 1.0, 2.0, 0.4439437495780523, 1.0, 2.0, 0.7067729075668009, 6.9112, 6.9112, 121.94756008, 1518624.306485724, 1518624.306485724, 316866.5747602108], 
processed observation next is [1.0, 0.34782608695652173, 0.5043209876543211, 0.8833333333333334, 1.0, 1.0, 0.3380282733072052, 1.0, 1.0, 0.3380282733072052, 1.0, 1.0, 0.633466134458501, 0.0, 0.0, 0.8096049824067558, 0.5423658237449014, 0.5423658237449014, 0.60935879761579], 
reward next is 0.3906, 
noisyNet noise sample is [array([0.57349545], dtype=float32), -0.73015934]. 
=============================================
[2019-03-23 22:48:53,511] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.55993]
 [73.55993]
 [73.55993]
 [73.55993]
 [73.55993]], R is [[73.21497345]
 [72.84557343]
 [72.11711884]
 [71.39595032]
 [71.37076569]].
[2019-03-23 22:48:53,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2172665e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:53,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1575
[2019-03-23 22:48:53,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4767870266231637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575292.6595478867, 575292.6595478867, 139526.9669840808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582800.0000, 
sim time next is 4583400.0000, 
raw observation next is [21.1, 99.66666666666667, 1.0, 2.0, 0.4775865532115207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575808.052026434, 575808.052026434, 139634.9541864309], 
processed observation next is [1.0, 0.043478260869565216, 0.3370370370370371, 0.9966666666666667, 1.0, 1.0, 0.3780792300137152, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20564573286658358, 0.20564573286658358, 0.26852875805082865], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.9138955], dtype=float32), -0.07641497]. 
=============================================
[2019-03-23 22:48:54,403] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8351424e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:54,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9512
[2019-03-23 22:48:54,417] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 99.5, 1.0, 2.0, 0.4915601988732447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363577, 141759.4939517889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4599000.0000, 
sim time next is 4599600.0000, 
raw observation next is [21.13333333333333, 99.66666666666666, 1.0, 2.0, 0.4839474435163825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582815.624805106, 582815.624805106, 140593.5783564216], 
processed observation next is [1.0, 0.21739130434782608, 0.33827160493827146, 0.9966666666666666, 1.0, 1.0, 0.38565171847188395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.208148437430395, 0.208148437430395, 0.27037226607004156], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.3063596], dtype=float32), -0.41212657]. 
=============================================
[2019-03-23 22:49:00,701] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1954751e-22 1.0000000e+00 2.2339372e-35 0.0000000e+00 1.2942644e-37], sum to 1.0000
[2019-03-23 22:49:00,708] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9500
[2019-03-23 22:49:00,712] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.6759829253545243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770415.5502711849, 770415.5502711849, 171645.6613856204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4744200.0000, 
sim time next is 4744800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6755061229902269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769871.8672639655, 769871.8672639655, 171557.1365517173], 
processed observation next is [1.0, 0.9565217391304348, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6136977654645559, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27495423830855914, 0.27495423830855914, 0.32991757029176405], 
reward next is 0.6701, 
noisyNet noise sample is [array([0.58359236], dtype=float32), -1.2149918]. 
=============================================
[2019-03-23 22:49:11,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7704579e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:49:11,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0889
[2019-03-23 22:49:11,896] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5537677345398572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 658111.790752446, 658111.7907524456, 151507.0661203344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4946400.0000, 
sim time next is 4947000.0000, 
raw observation next is [24.0, 84.0, 1.0, 2.0, 0.636919320688908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755462.4723722412, 755462.4723722412, 165891.990159952], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.84, 1.0, 1.0, 0.5677610960582238, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.269808025847229, 0.269808025847229, 0.31902305799990766], 
reward next is 0.6810, 
noisyNet noise sample is [array([0.68122953], dtype=float32), 1.8239881]. 
=============================================
[2019-03-23 22:49:11,915] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.32636]
 [64.32636]
 [64.32636]
 [64.32636]
 [64.32636]], R is [[64.36408234]
 [64.42908478]
 [64.48647308]
 [64.5423584 ]
 [64.60169983]].
[2019-03-23 22:49:17,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.018433e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:49:17,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8172
[2019-03-23 22:49:17,493] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6999827028641323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797782.2534369333, 797782.2534369333, 176141.8424371745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.7036257484046079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801936.4667788643, 801936.4667788643, 176832.9369591526], 
processed observation next is [0.0, 0.43478260869565216, 0.5925925925925926, 0.79, 1.0, 1.0, 0.6471735100054856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2864058809924515, 0.2864058809924515, 0.3400633403060627], 
reward next is 0.6599, 
noisyNet noise sample is [array([1.0898007], dtype=float32), -0.431042]. 
=============================================
[2019-03-23 22:49:22,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5434766e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:49:22,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0926
[2019-03-23 22:49:22,451] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 98.66666666666667, 1.0, 2.0, 0.6972788844665742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 794699.0678694922, 794699.0678694927, 175629.2856186639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5116800.0000, 
sim time next is 5117400.0000, 
raw observation next is [24.9, 99.0, 1.0, 2.0, 0.6997310125369762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797495.2484367747, 797495.2484367747, 176093.1684611981], 
processed observation next is [0.0, 0.21739130434782608, 0.47777777777777775, 0.99, 1.0, 1.0, 0.6425369196868764, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2848197315845624, 0.2848197315845624, 0.3386407085792271], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.04515674], dtype=float32), -0.06624099]. 
=============================================
[2019-03-23 22:49:28,271] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 22:49:28,272] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:49:28,273] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:49:28,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:49:28,274] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:49:28,275] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:49:28,277] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:49:28,276] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:49:28,278] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:49:28,279] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:49:28,282] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:49:28,303] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 22:49:28,328] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 22:49:28,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 22:49:28,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 22:49:28,412] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 22:49:40,554] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:49:40,556] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333333, 20.0, 1.0, 2.0, 0.284970838125336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367598.6737374099, 367598.6737374099, 91420.22992861082]
[2019-03-23 22:49:40,558] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:49:40,563] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.9802392349194706
[2019-03-23 22:49:42,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:49:42,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.19490523, 56.85612667333334, 1.0, 2.0, 0.2578929792209492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332546.4975612842, 332546.4975612842, 108788.4541411966]
[2019-03-23 22:49:42,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:49:42,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.16616466089733872
[2019-03-23 22:49:58,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:49:58,716] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.1, 38.5, 1.0, 2.0, 0.4262158175957543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518572.6373697738, 518572.6373697738, 132122.8883566741]
[2019-03-23 22:49:58,717] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:49:58,719] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.658923732322068
[2019-03-23 22:50:20,723] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:50:20,724] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.83333333333334, 84.0, 1.0, 2.0, 0.6330729239400374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738619.0042714042, 738619.0042714042, 164676.5275514531]
[2019-03-23 22:50:20,724] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:50:20,728] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.6077956132316765
[2019-03-23 22:50:28,512] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:50:28,513] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.03125098, 70.29580963333333, 1.0, 2.0, 0.6447728921176811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734828.5269588369, 734828.5269588369, 165949.6520564616]
[2019-03-23 22:50:28,514] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:50:28,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.8579759017519715
[2019-03-23 22:50:54,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:50:54,901] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.55, 76.5, 1.0, 2.0, 0.6653070274408106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758242.2460146851, 758242.2460146851, 169678.9873844772]
[2019-03-23 22:50:54,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:50:54,904] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.452775399674736
[2019-03-23 22:51:08,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1236056]
[2019-03-23 22:51:08,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.85, 54.5, 1.0, 2.0, 0.2391325979301328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 308457.5657256162, 308457.5657256157, 97836.7174640002]
[2019-03-23 22:51:08,841] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:51:08,842] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5411569e-20 1.0000000e+00 2.0803730e-31 3.0782372e-34 8.0367153e-34], sampled 0.5957766777697965
[2019-03-23 22:51:11,365] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:51:11,468] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:51:11,676] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:51:11,685] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:51:11,741] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:51:12,758] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1625000, evaluation results [1625000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:51:20,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2432029e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:20,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6094
[2019-03-23 22:51:20,308] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 84.0, 1.0, 2.0, 0.4606573856079867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559119.1993514259, 559119.1993514259, 137178.2494934613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5961600.0000, 
sim time next is 5962200.0000, 
raw observation next is [22.6, 83.5, 1.0, 2.0, 0.4575130799846978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555938.3395941849, 555938.3395941849, 136724.045576379], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.835, 1.0, 1.0, 0.3541822380770212, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19854940699792317, 0.19854940699792317, 0.2629308568776519], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.4379516], dtype=float32), -0.11590122]. 
=============================================
[2019-03-23 22:51:31,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8747939e-22 1.0000000e+00 3.4938492e-36 1.9285954e-37 6.6269680e-38], sum to 1.0000
[2019-03-23 22:51:31,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3765
[2019-03-23 22:51:31,520] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 96.5, 1.0, 2.0, 0.4689354422845984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568106.7817178323, 568106.7817178323, 138400.6692168432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718600.0000, 
sim time next is 5719200.0000, 
raw observation next is [21.1, 96.33333333333334, 1.0, 2.0, 0.4654199867372461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564507.6823005414, 564507.6823005414, 137886.9658407118], 
processed observation next is [0.0, 0.17391304347826086, 0.3370370370370371, 0.9633333333333334, 1.0, 1.0, 0.3635952223062454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20160988653590767, 0.20160988653590767, 0.2651672420013689], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.24469447], dtype=float32), -0.20756142]. 
=============================================
[2019-03-23 22:51:31,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.338275e-23 1.000000e+00 5.654567e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:51:31,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0178
[2019-03-23 22:51:31,793] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.587064863284078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679366.606560098, 679366.606560098, 156364.2512795041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5634000.0000, 
sim time next is 5634600.0000, 
raw observation next is [23.56666666666667, 96.83333333333334, 1.0, 2.0, 0.5898100526047624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 682046.2381021536, 682046.2381021532, 156810.4943662388], 
processed observation next is [0.0, 0.21739130434782608, 0.4283950617283952, 0.9683333333333334, 1.0, 1.0, 0.5116786340532885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2435879421793406, 0.24358794217934043, 0.3015586430119977], 
reward next is 0.6984, 
noisyNet noise sample is [array([0.45084044], dtype=float32), 0.4002309]. 
=============================================
[2019-03-23 22:51:36,135] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5497054e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:36,139] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0947
[2019-03-23 22:51:36,143] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.7188922886172006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3507572464, 819345.3507572464, 179754.4587506498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.722934523462194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823954.896026817, 823954.896026817, 180534.3265788479], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.6701601469788023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29426960572386324, 0.29426960572386324, 0.3471813972670152], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.85777915], dtype=float32), 1.223399]. 
=============================================
[2019-03-23 22:51:36,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.738102]
 [63.738102]
 [63.738102]
 [63.738102]
 [63.738102]], R is [[63.75353622]
 [63.77032089]
 [63.79090118]
 [63.81070709]
 [63.82702637]].
[2019-03-23 22:51:36,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0440024e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:36,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5947
[2019-03-23 22:51:36,874] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.511636823715528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609955.1199025614, 609955.1199025614, 144724.8595837246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5709600.0000, 
sim time next is 5710200.0000, 
raw observation next is [21.95, 97.0, 1.0, 2.0, 0.5092100330453363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607666.6994001782, 607666.6994001782, 144361.5665911681], 
processed observation next is [0.0, 0.08695652173913043, 0.36851851851851847, 0.97, 1.0, 1.0, 0.41572622981587654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21702382121434935, 0.21702382121434935, 0.2776183972907079], 
reward next is 0.7224, 
noisyNet noise sample is [array([0.16156407], dtype=float32), 0.26468974]. 
=============================================
[2019-03-23 22:51:39,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.10759345e-27 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:51:39,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1623
[2019-03-23 22:51:39,762] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 83.0, 1.0, 2.0, 0.4363861488584428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533156.7657907709, 533156.7657907704, 133670.593158254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5733600.0000, 
sim time next is 5734200.0000, 
raw observation next is [22.58333333333333, 82.0, 1.0, 2.0, 0.4430735809690162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540644.6661157018, 540644.6661157018, 134637.352041851], 
processed observation next is [0.0, 0.34782608695652173, 0.3919753086419751, 0.82, 1.0, 1.0, 0.3369923582964479, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19308738075560777, 0.19308738075560777, 0.2589179846958673], 
reward next is 0.7411, 
noisyNet noise sample is [array([-0.9411179], dtype=float32), 2.074585]. 
=============================================
[2019-03-23 22:51:41,647] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1343487e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:41,654] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2974
[2019-03-23 22:51:41,659] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 86.0, 1.0, 2.0, 0.4664251620147882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566133.030100642, 566133.030100642, 138052.2843304335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5812200.0000, 
sim time next is 5812800.0000, 
raw observation next is [22.46666666666667, 85.0, 1.0, 2.0, 0.4621053316207475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561033.7989933807, 561033.7989933807, 137401.9280171401], 
processed observation next is [1.0, 0.2608695652173913, 0.3876543209876544, 0.85, 1.0, 1.0, 0.3596492043104137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2003692139262074, 0.2003692139262074, 0.2642344769560387], 
reward next is 0.7358, 
noisyNet noise sample is [array([-0.59908503], dtype=float32), -0.19973816]. 
=============================================
[2019-03-23 22:51:44,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.112222e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:51:44,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6910
[2019-03-23 22:51:44,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1314091.52630265 W.
[2019-03-23 22:51:44,835] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 45.0, 1.0, 2.0, 0.3658471971053435, 1.0, 2.0, 0.3658471971053435, 1.0, 2.0, 0.5899046975475727, 6.9112, 6.9112, 121.94756008, 1314091.52630265, 1314091.52630265, 282023.0793029161], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [27.91666666666666, 44.66666666666666, 1.0, 2.0, 0.3348654408178695, 1.0, 2.0, 0.3348654408178695, 1.0, 2.0, 0.5407735602651019, 6.911199999999999, 6.9112, 121.94756008, 1206084.126419769, 1206084.126419769, 269186.5942940022], 
processed observation next is [1.0, 0.6521739130434783, 0.5895061728395059, 0.44666666666666655, 1.0, 1.0, 0.20817314383079705, 1.0, 1.0, 0.20817314383079705, 1.0, 1.0, 0.4259669503313774, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.43074433086420316, 0.43074433086420316, 0.5176665274884658], 
reward next is 0.4823, 
noisyNet noise sample is [array([1.1616018], dtype=float32), 0.7076386]. 
=============================================
[2019-03-23 22:51:45,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8044984e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:45,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-23 22:51:45,662] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 45.0, 1.0, 2.0, 0.3629899099450619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451634.0122678951, 451634.0122678951, 123567.2316227681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5852400.0000, 
sim time next is 5853000.0000, 
raw observation next is [27.36666666666667, 46.0, 1.0, 2.0, 0.3674101542215324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456828.9431559573, 456828.9431559573, 124156.8081246243], 
processed observation next is [1.0, 0.7391304347826086, 0.569135802469136, 0.46, 1.0, 1.0, 0.24691685026372903, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16315319398427047, 0.16315319398427047, 0.23876309254735442], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.24996102], dtype=float32), 1.0045753]. 
=============================================
[2019-03-23 22:51:45,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.404873]
 [62.404873]
 [62.404873]
 [62.404873]
 [62.404873]], R is [[62.54206467]
 [62.67901611]
 [62.8159523 ]
 [62.95059967]
 [62.97557068]].
[2019-03-23 22:51:48,900] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2782527e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:48,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7869
[2019-03-23 22:51:48,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1462163.966666555 W.
[2019-03-23 22:51:48,920] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.43333333333333, 42.83333333333333, 1.0, 2.0, 0.412105198188829, 1.0, 1.0, 0.412105198188829, 1.0, 2.0, 0.6608110489080806, 6.9112, 6.9112, 121.94756008, 1462163.966666555, 1462163.966666555, 302340.9998557612], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5925000.0000, 
sim time next is 5925600.0000, 
raw observation next is [29.6, 42.0, 1.0, 2.0, 0.6134567673416482, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9616363883402848, 6.9112, 6.9112, 121.9260426156618, 1450219.052959745, 1450219.052959745, 293408.9793460764], 
processed observation next is [1.0, 0.6086956521739131, 0.6518518518518519, 0.42, 1.0, 1.0, 0.5398294849305336, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9520454854253559, 0.0, 0.0, 0.8094621288201359, 0.5179353760570518, 0.5179353760570518, 0.5642480372039931], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27951613], dtype=float32), -0.8260029]. 
=============================================
[2019-03-23 22:51:49,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8554381e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:49,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9205
[2019-03-23 22:51:49,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1458462.764521058 W.
[2019-03-23 22:51:49,332] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 48.0, 1.0, 2.0, 0.6266620985280472, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9667283579872951, 6.911200000000002, 6.9112, 121.9260426156618, 1458462.764521058, 1458462.764521057, 297540.4057837311], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5932800.0000, 
sim time next is 5933400.0000, 
raw observation next is [29.05, 48.5, 1.0, 2.0, 0.4544157652178276, 1.0, 1.0, 0.4544157652178276, 1.0, 2.0, 0.7254830973678779, 6.911200000000001, 6.9112, 121.94756008, 1588820.664685973, 1588820.664685973, 321846.018467197], 
processed observation next is [1.0, 0.6956521739130435, 0.6314814814814815, 0.485, 1.0, 1.0, 0.35049495859265195, 1.0, 0.5, 0.35049495859265195, 1.0, 1.0, 0.6568538717098473, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5674359516735618, 0.5674359516735618, 0.6189346508984558], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6032501], dtype=float32), -1.2608124]. 
=============================================
[2019-03-23 22:51:57,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4959528e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:57,040] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2754
[2019-03-23 22:51:57,047] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1883576.66295554 W.
[2019-03-23 22:51:57,050] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333334, 55.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.272637783636165, 6.9112, 121.9208210425114, 1883576.66295554, 1186428.690962824, 246878.9958546688], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6095400.0000, 
sim time next is 6096000.0000, 
raw observation next is [30.06666666666667, 54.33333333333334, 1.0, 2.0, 0.8643430164578281, 1.0, 1.0, 0.8643430164578281, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9252227776633, 1971650.445076786, 1971650.445076787, 371057.6685590916], 
processed observation next is [1.0, 0.5652173913043478, 0.669135802469136, 0.5433333333333334, 1.0, 1.0, 0.8385035910212238, 1.0, 0.5, 0.8385035910212238, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094566859483973, 0.7041608732417093, 0.7041608732417096, 0.7135724395367146], 
reward next is 0.2864, 
noisyNet noise sample is [array([-0.6924646], dtype=float32), 1.2009847]. 
=============================================
[2019-03-23 22:51:57,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.55891]
 [69.55891]
 [69.55891]
 [69.55891]
 [69.55891]], R is [[69.14974976]
 [68.45825195]
 [68.35012817]
 [68.24119568]
 [67.84848022]].
[2019-03-23 22:51:58,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.457155e-24 1.000000e+00 8.995772e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:51:58,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-23 22:51:58,545] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 87.0, 1.0, 2.0, 0.5794511685449021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673662.8334219552, 673662.8334219552, 155211.2102375193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6330600.0000, 
sim time next is 6331200.0000, 
raw observation next is [24.66666666666666, 87.0, 1.0, 2.0, 0.5825668534794746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676355.6260961153, 676355.6260961153, 155698.6655052133], 
processed observation next is [0.0, 0.2608695652173913, 0.4691358024691356, 0.87, 1.0, 1.0, 0.5030557779517554, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2415555807486126, 0.2415555807486126, 0.2994205105869487], 
reward next is 0.7006, 
noisyNet noise sample is [array([-1.5133932], dtype=float32), -0.62160987]. 
=============================================
[2019-03-23 22:51:59,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8958713e-22 1.0000000e+00 7.5885364e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:59,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3602
[2019-03-23 22:51:59,306] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 80.5, 1.0, 2.0, 0.534537817318551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630646.5685114714, 630646.5685114714, 148158.3399626271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6136200.0000, 
sim time next is 6136800.0000, 
raw observation next is [24.63333333333333, 81.33333333333333, 1.0, 2.0, 0.5347063336186618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 630795.9122011961, 630795.9122011956, 148183.7455595596], 
processed observation next is [1.0, 0.0, 0.46790123456790106, 0.8133333333333332, 1.0, 1.0, 0.446078968593645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22528425435757002, 0.22528425435756985, 0.28496874146069157], 
reward next is 0.7150, 
noisyNet noise sample is [array([2.318561], dtype=float32), -1.9801928]. 
=============================================
[2019-03-23 22:52:02,797] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:52:02,798] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:52:02,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:52:02,799] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:52:02,801] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:52:02,801] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:52:02,806] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:52:02,804] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:52:02,806] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:52:02,807] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:52:02,812] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:52:02,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 22:52:02,852] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 22:52:02,878] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 22:52:02,901] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 22:52:02,927] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 22:52:07,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:52:07,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.46666666666667, 32.66666666666667, 1.0, 2.0, 0.269552016197223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347704.6263825727, 347704.6263825732, 93056.61303470185]
[2019-03-23 22:52:07,221] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:07,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5101299645296578
[2019-03-23 22:52:21,375] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:52:21,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [39.0, 13.0, 1.0, 2.0, 0.8304837386610716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032319.834660639, 1032319.834660639, 205817.2528264437]
[2019-03-23 22:52:21,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:21,382] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.24545396213941606
[2019-03-23 22:52:59,650] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:52:59,652] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.10334799, 98.58864986, 1.0, 2.0, 0.6802264915284458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790786.544741398, 790786.544741398, 173190.8482118052]
[2019-03-23 22:52:59,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:52:59,659] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6458763136685135
[2019-03-23 22:53:16,115] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:53:16,116] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.02302676333333, 84.91833090666667, 1.0, 2.0, 0.5366131385007936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633909.8922267215, 633909.8922267215, 148528.8507469182]
[2019-03-23 22:53:16,118] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:53:16,121] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.19315061881366447
[2019-03-23 22:53:16,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:53:16,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.09637315, 71.80839817333334, 1.0, 2.0, 0.3839413691375079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475205.7016240539, 475205.7016240539, 126368.2943302177]
[2019-03-23 22:53:16,313] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:53:16,317] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6642569377720601
[2019-03-23 22:53:20,765] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:53:20,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.89472287, 86.889051765, 1.0, 2.0, 0.5918113753749655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683770.3688769479, 683770.3688769479, 157125.7569791859]
[2019-03-23 22:53:20,769] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:53:20,771] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.027300077656117527
[2019-03-23 22:53:34,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:53:34,121] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.75, 94.83333333333334, 1.0, 2.0, 0.5219259370812961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616808.5364095562, 616808.5364095562, 146163.0339471064]
[2019-03-23 22:53:34,123] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:53:34,125] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.29888739555196253
[2019-03-23 22:53:34,957] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.1309934]
[2019-03-23 22:53:34,957] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.13333333333333, 75.33333333333333, 1.0, 2.0, 0.6146602641660651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702264.2339672613, 702264.2339672613, 160705.3726680702]
[2019-03-23 22:53:34,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:53:34,963] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.772404e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.32061861634315303
[2019-03-23 22:53:45,632] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:53:46,018] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:53:46,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:53:46,194] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:53:46,238] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:53:47,255] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1650000, evaluation results [1650000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:53:48,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1892397e-22 1.0000000e+00 5.5369178e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:48,206] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-23 22:53:48,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1841911.038189013 W.
[2019-03-23 22:53:48,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5383505861505165, 1.0, 1.0, 0.5383505861505165, 1.0, 2.0, 0.8570716660061809, 6.9112, 6.9112, 121.94756008, 1841911.038189013, 1841911.038189013, 362810.4886619996], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6175200.0000, 
sim time next is 6175800.0000, 
raw observation next is [27.8, 65.0, 1.0, 2.0, 0.5408901620703829, 1.0, 2.0, 0.5408901620703829, 1.0, 2.0, 0.8611147535788217, 6.9112, 6.9112, 121.94756008, 1850608.93523044, 1850608.93523044, 364111.4396372517], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.65, 1.0, 1.0, 0.4534406691314082, 1.0, 1.0, 0.4534406691314082, 1.0, 1.0, 0.8263934419735272, 0.0, 0.0, 0.8096049824067558, 0.6609317625823, 0.6609317625823, 0.7002143069947149], 
reward next is 0.2998, 
noisyNet noise sample is [array([-0.5005853], dtype=float32), 0.4453381]. 
=============================================
[2019-03-23 22:53:48,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.280827e-23 1.000000e+00 6.852220e-36 0.000000e+00 2.408677e-38], sum to 1.0000
[2019-03-23 22:53:48,405] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2310
[2019-03-23 22:53:48,410] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 74.66666666666667, 1.0, 2.0, 0.4938597158079047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591780.7023833265, 591780.7023833265, 142033.0849310197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6222000.0000, 
sim time next is 6222600.0000, 
raw observation next is [24.65, 75.0, 1.0, 2.0, 0.4921361758388176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590036.3017642167, 590036.3017642167, 141775.3793728581], 
processed observation next is [0.0, 0.0, 0.46851851851851845, 0.75, 1.0, 1.0, 0.3954002093319257, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2107272506300774, 0.2107272506300774, 0.2726449603324194], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.99059117], dtype=float32), 0.48850477]. 
=============================================
[2019-03-23 22:53:50,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4437361e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:50,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6206
[2019-03-23 22:53:50,647] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 60.16666666666667, 1.0, 2.0, 0.6875110275544865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783560.8064772821, 783560.8064772821, 173792.5097834777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6353400.0000, 
sim time next is 6354000.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6838886156706565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779430.2209322713, 779430.2209322713, 173115.5035440881], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.59, 1.0, 1.0, 0.6236769234174482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27836793604723975, 0.27836793604723975, 0.3329144298924771], 
reward next is 0.6671, 
noisyNet noise sample is [array([1.30399], dtype=float32), 0.2804921]. 
=============================================
[2019-03-23 22:53:50,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.61335]
 [72.61335]
 [72.61335]
 [72.61335]
 [72.61335]], R is [[72.5542984 ]
 [72.49454498]
 [72.43418884]
 [72.37349701]
 [72.31377411]].
[2019-03-23 22:53:55,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0246035e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:55,864] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0229
[2019-03-23 22:53:55,866] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.45, 57.83333333333334, 1.0, 2.0, 0.6751274821531135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769440.1150886265, 769440.1150886265, 171489.1628739215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6358200.0000, 
sim time next is 6358800.0000, 
raw observation next is [31.5, 57.66666666666667, 1.0, 2.0, 0.6703784505360019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764024.9651357065, 764024.9651357065, 170612.7375476144], 
processed observation next is [0.0, 0.6086956521739131, 0.7222222222222222, 0.5766666666666667, 1.0, 1.0, 0.6075933934952403, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27286605897703803, 0.27286605897703803, 0.3281014183607969], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.1917658], dtype=float32), -0.028606962]. 
=============================================
[2019-03-23 22:53:56,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1331775e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:56,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9500
[2019-03-23 22:53:56,293] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 62.0, 1.0, 2.0, 0.6831113597142169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 778543.9297498517, 778543.9297498526, 172971.080577509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6375600.0000, 
sim time next is 6376200.0000, 
raw observation next is [30.36666666666667, 62.66666666666667, 1.0, 2.0, 0.6719545361535174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765822.114639712, 765822.1146397116, 170902.7256122067], 
processed observation next is [0.0, 0.8260869565217391, 0.680246913580247, 0.6266666666666667, 1.0, 1.0, 0.6094696858970445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27350789808561143, 0.27350789808561127, 0.3286590877157821], 
reward next is 0.6713, 
noisyNet noise sample is [array([-1.5647811], dtype=float32), 0.48325935]. 
=============================================
[2019-03-23 22:54:04,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0285571e-23 1.0000000e+00 5.8689346e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:54:04,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6690
[2019-03-23 22:54:04,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1953476.145832111 W.
[2019-03-23 22:54:04,934] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333334, 80.33333333333334, 1.0, 2.0, 0.8563843770097034, 1.0, 1.0, 0.8563843770097034, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9259923282257, 1953476.145832111, 1953476.145832111, 367604.261454499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6528000.0000, 
sim time next is 6528600.0000, 
raw observation next is [27.35, 80.5, 1.0, 2.0, 0.8526867338317146, 1.0, 2.0, 0.8526867338317146, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426003279, 1945032.362351799, 1945032.362351799, 366006.4127719724], 
processed observation next is [1.0, 0.5652173913043478, 0.5685185185185185, 0.805, 1.0, 1.0, 0.8246270640853745, 1.0, 1.0, 0.8246270640853745, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621287183348, 0.6946544151256425, 0.6946544151256425, 0.703858486099947], 
reward next is 0.2961, 
noisyNet noise sample is [array([-1.4094774], dtype=float32), 0.5985162]. 
=============================================
[2019-03-23 22:54:06,710] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0007073e-20 1.0000000e+00 1.0250062e-33 3.2510896e-36 1.9878213e-36], sum to 1.0000
[2019-03-23 22:54:06,716] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8908
[2019-03-23 22:54:06,722] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 73.5, 1.0, 2.0, 0.5562583872630064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652738.5433766241, 652738.5433766241, 151585.3688661635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6565800.0000, 
sim time next is 6566400.0000, 
raw observation next is [26.0, 72.0, 1.0, 2.0, 0.542728943076501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640093.279883915, 640093.279883915, 149487.1558382529], 
processed observation next is [1.0, 0.0, 0.5185185185185185, 0.72, 1.0, 1.0, 0.45562969413869164, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2286047428156839, 0.2286047428156839, 0.28747529968894786], 
reward next is 0.7125, 
noisyNet noise sample is [array([0.09450676], dtype=float32), -0.86208946]. 
=============================================
[2019-03-23 22:54:07,324] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8304902e-23 1.0000000e+00 2.7225166e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:54:07,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5782
[2019-03-23 22:54:07,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2161291.316800313 W.
[2019-03-23 22:54:07,342] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 78.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.463686308120253, 6.9112, 121.9238305934663, 2161291.316800313, 1878374.079247167, 382151.7176324527], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6539400.0000, 
sim time next is 6540000.0000, 
raw observation next is [27.8, 78.33333333333334, 1.0, 2.0, 0.854211914876267, 1.0, 1.0, 0.854211914876267, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9257099177619, 1948515.197828995, 1948515.197828995, 366664.9395545083], 
processed observation next is [1.0, 0.6956521739130435, 0.5851851851851853, 0.7833333333333334, 1.0, 1.0, 0.8264427558050798, 1.0, 0.5, 0.8264427558050798, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094599200520621, 0.6958982849389268, 0.6958982849389268, 0.7051248837586698], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6067309], dtype=float32), 0.55283]. 
=============================================
[2019-03-23 22:54:07,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[56.91176]
 [56.91176]
 [56.91176]
 [56.91176]
 [56.91176]], R is [[56.34263992]
 [55.77921295]
 [55.51578522]
 [55.22811127]
 [54.67583084]].
[2019-03-23 22:54:08,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.119346e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:54:08,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0060
[2019-03-23 22:54:08,576] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 79.5, 1.0, 2.0, 0.6140384032348974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705425.283044616, 705425.283044616, 160786.3961622478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6563400.0000, 
sim time next is 6564000.0000, 
raw observation next is [26.13333333333333, 78.0, 1.0, 2.0, 0.602099703350336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695471.4963159402, 695471.4963159402, 158889.4411665298], 
processed observation next is [1.0, 1.0, 0.5234567901234567, 0.78, 1.0, 1.0, 0.5263091706551619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2483826772556929, 0.2483826772556929, 0.30555661762794195], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.32815182], dtype=float32), -0.048663754]. 
=============================================
[2019-03-23 22:54:08,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.158035]
 [72.158035]
 [72.158035]
 [72.158035]
 [72.158035]], R is [[72.13089752]
 [72.10038757]
 [72.06569672]
 [72.0292511 ]
 [71.9910202 ]].
[2019-03-23 22:54:12,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.322403e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:54:12,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8757
[2019-03-23 22:54:12,895] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 46.5, 1.0, 2.0, 0.3319409276759566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428195.9636084027, 428195.9636084027, 118687.3253338917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6661800.0000, 
sim time next is 6662400.0000, 
raw observation next is [23.03333333333333, 46.33333333333333, 1.0, 2.0, 0.3050017611553217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393444.0332392146, 393444.0332392146, 114332.665448672], 
processed observation next is [1.0, 0.08695652173913043, 0.4086419753086419, 0.46333333333333326, 1.0, 1.0, 0.1726211442325258, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14051572615686236, 0.14051572615686236, 0.2198705104782154], 
reward next is 0.7801, 
noisyNet noise sample is [array([-1.1668476], dtype=float32), 0.24547017]. 
=============================================
[2019-03-23 22:54:13,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1129046e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:54:13,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6665
[2019-03-23 22:54:13,823] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 44.50000000000001, 1.0, 2.0, 0.2785569088717665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359275.750479993, 359275.750479993, 112953.6195837305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6657000.0000, 
sim time next is 6657600.0000, 
raw observation next is [23.5, 45.0, 1.0, 2.0, 0.2767993470316647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357007.3934933548, 357007.3934933548, 112743.5069567076], 
processed observation next is [1.0, 0.043478260869565216, 0.42592592592592593, 0.45, 1.0, 1.0, 0.13904684170436274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12750264053334098, 0.12750264053334098, 0.21681443645520693], 
reward next is 0.7832, 
noisyNet noise sample is [array([-0.6896602], dtype=float32), -0.0960674]. 
=============================================
[2019-03-23 22:54:31,424] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8323635e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:54:31,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2502
[2019-03-23 22:54:31,440] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 79.0, 1.0, 2.0, 0.632629261401902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786096.906766881, 786096.906766881, 166253.3973632899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119000.0000, 
sim time next is 7119600.0000, 
raw observation next is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.6555154906893286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813799.1866184906, 813799.1866184906, 170456.1721635787], 
processed observation next is [1.0, 0.391304347826087, 0.3617283950617285, 0.7866666666666667, 1.0, 1.0, 0.5898993936777721, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2906425666494609, 0.2906425666494609, 0.3278003310838052], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.5065907], dtype=float32), -0.8925745]. 
=============================================
[2019-03-23 22:54:32,016] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.276939e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:54:32,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2356
[2019-03-23 22:54:32,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.4946124618754451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610530.3801565828, 610530.3801565828, 142689.4460914669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7012800.0000, 
sim time next is 7013400.0000, 
raw observation next is [21.01666666666667, 87.66666666666667, 1.0, 2.0, 0.5481723195881592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676657.2751228169, 676657.2751228169, 151384.4194440593], 
processed observation next is [1.0, 0.17391304347826086, 0.3339506172839507, 0.8766666666666667, 1.0, 1.0, 0.462109904271618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24166331254386317, 0.24166331254386317, 0.2911238835462679], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.17395212], dtype=float32), 1.4751945]. 
=============================================
[2019-03-23 22:54:37,331] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 22:54:37,333] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:54:37,333] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:54:37,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:37,335] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:54:37,338] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:37,336] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:54:37,335] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:54:37,347] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:37,346] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:37,347] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:37,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 22:54:37,398] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 22:54:37,399] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 22:54:37,448] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 22:54:37,448] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 22:54:43,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:54:43,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.13333333333333, 48.0, 1.0, 2.0, 0.257457995902608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331692.0846750094, 331692.0846750094, 110471.4390601086]
[2019-03-23 22:54:43,113] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:54:43,115] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.20003107693374977
[2019-03-23 22:54:53,556] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:54:53,559] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.8, 39.33333333333334, 1.0, 2.0, 0.3191135182345311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404706.2824700043, 404706.2824700043, 117955.2706042728]
[2019-03-23 22:54:53,560] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:54:53,564] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.538101837784646
[2019-03-23 22:55:00,129] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:00,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.26666666666667, 70.33333333333333, 1.0, 2.0, 0.3623410021072812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454164.0204546896, 454164.0204546896, 123541.6831494537]
[2019-03-23 22:55:00,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:55:00,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.056494444759756846
[2019-03-23 22:55:33,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:33,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 68.0, 1.0, 2.0, 0.8874852894166338, 1.0, 2.0, 0.8874852894166338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260424774966, 2024500.041693791, 2024500.041693791, 381232.1647362306]
[2019-03-23 22:55:33,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:55:33,826] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.35795320251694485
[2019-03-23 22:55:33,827] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2024500.041693791 W.
[2019-03-23 22:55:43,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:43,890] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5480581228547367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641245.917969142, 641245.917969142, 150149.8709290637]
[2019-03-23 22:55:43,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:55:43,896] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7910290578296236
[2019-03-23 22:55:50,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:50,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 86.33333333333334, 1.0, 2.0, 0.637455309539156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727279.2496162936, 727279.2496162936, 164679.6342551687]
[2019-03-23 22:55:50,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:55:50,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7594477905921555
[2019-03-23 22:55:55,122] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:55,123] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.93333333333334, 74.0, 1.0, 2.0, 0.7086480396169277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807663.489242532, 807663.489242532, 177789.523173187]
[2019-03-23 22:55:55,124] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:55:55,125] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.06295384213499733
[2019-03-23 22:55:56,001] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:55:56,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.06666666666667, 92.0, 1.0, 2.0, 0.5264111938118012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622505.7262489339, 622505.7262489339, 146900.4206975262]
[2019-03-23 22:55:56,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:55:56,009] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.39075711306812466
[2019-03-23 22:56:17,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0489095]
[2019-03-23 22:56:17,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.11666666666667, 64.33333333333334, 1.0, 2.0, 0.3980746464701227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493208.091248278, 493208.0912482785, 128347.7942810152]
[2019-03-23 22:56:17,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:56:17,768] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.496589e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6218707227724714
[2019-03-23 22:56:20,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:56:20,903] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:56:20,943] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:56:20,968] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:56:21,012] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:56:22,027] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1675000, evaluation results [1675000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:56:26,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6468856e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:26,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4728
[2019-03-23 22:56:26,931] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 81.0, 1.0, 2.0, 0.6458488332650792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 801339.5047764058, 801339.5047764048, 168652.4108974049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7201800.0000, 
sim time next is 7202400.0000, 
raw observation next is [21.66666666666667, 80.0, 1.0, 2.0, 0.6576701869972394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815532.3827895352, 815532.3827895352, 170836.3193853628], 
processed observation next is [1.0, 0.34782608695652173, 0.3580246913580249, 0.8, 1.0, 1.0, 0.5924645083300469, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2912615652819769, 0.2912615652819769, 0.32853138343339], 
reward next is 0.6715, 
noisyNet noise sample is [array([-1.1030846], dtype=float32), 0.8116205]. 
=============================================
[2019-03-23 22:56:31,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7606983e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:31,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9695
[2019-03-23 22:56:31,065] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 79.5, 1.0, 2.0, 0.7570829414554107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 923869.2039488368, 923869.2039488368, 189854.9162592643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7295400.0000, 
sim time next is 7296000.0000, 
raw observation next is [22.96666666666667, 78.66666666666666, 1.0, 2.0, 0.7608955896981393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 928509.190828683, 928509.1908286834, 190632.2493468704], 
processed observation next is [1.0, 0.43478260869565216, 0.4061728395061729, 0.7866666666666666, 1.0, 1.0, 0.7153518924977849, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3316104252959582, 0.33161042529595836, 0.36660047951321234], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.05054148], dtype=float32), -1.2362577]. 
=============================================
[2019-03-23 22:56:31,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.128044]
 [69.128044]
 [69.128044]
 [69.128044]
 [69.128044]], R is [[69.07016754]
 [69.01435852]
 [68.96364594]
 [68.91390991]
 [68.86547089]].
[2019-03-23 22:56:33,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.232799e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:56:33,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0519
[2019-03-23 22:56:33,722] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 78.0, 1.0, 2.0, 0.4437119589189752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541524.4306412261, 541524.4306412261, 134734.6542720724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7333200.0000, 
sim time next is 7333800.0000, 
raw observation next is [22.93333333333334, 78.66666666666667, 1.0, 2.0, 0.4420644554898553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540003.7077979653, 540003.7077979653, 134504.7884001213], 
processed observation next is [1.0, 0.9130434782608695, 0.40493827160493856, 0.7866666666666667, 1.0, 1.0, 0.3357910184403039, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1928584670707019, 0.1928584670707019, 0.2586630546156179], 
reward next is 0.7413, 
noisyNet noise sample is [array([0.46365437], dtype=float32), 1.5831634]. 
=============================================
[2019-03-23 22:56:35,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:56:35,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:35,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 22:56:36,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4731951e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:36,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8703
[2019-03-23 22:56:36,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 91.0, 1.0, 2.0, 0.3825739667965511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473949.8267218302, 473949.8267218302, 126189.540803023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7628400.0000, 
sim time next is 7629000.0000, 
raw observation next is [20.46666666666667, 91.00000000000001, 1.0, 2.0, 0.4393660787266304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543796.7407683703, 543796.7407683703, 134289.4652207541], 
processed observation next is [1.0, 0.30434782608695654, 0.31358024691358033, 0.9100000000000001, 1.0, 1.0, 0.3325786651507505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1942131217029894, 0.1942131217029894, 0.25824897157837323], 
reward next is 0.7418, 
noisyNet noise sample is [array([-0.08662222], dtype=float32), -3.6547136]. 
=============================================
[2019-03-23 22:56:36,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.943306]
 [67.943306]
 [67.943306]
 [67.943306]
 [67.943306]], R is [[68.00562286]
 [68.08289337]
 [68.16001129]
 [68.23639679]
 [68.31145477]].
[2019-03-23 22:56:54,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:56:54,631] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:54,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 22:56:55,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9912456e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:55,312] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2113
[2019-03-23 22:56:55,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1457189.495799137 W.
[2019-03-23 22:56:55,328] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.56666666666667, 45.5, 1.0, 2.0, 0.6232977400599827, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9647388559190103, 6.911199999999999, 6.9112, 121.9260426156618, 1457189.495799137, 1457189.495799138, 296295.5308611209], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7740600.0000, 
sim time next is 7741200.0000, 
raw observation next is [29.53333333333334, 46.0, 1.0, 2.0, 0.6222988663269768, 1.0, 1.0, 0.6222988663269768, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1471609.438195809, 1471609.438195809, 278216.5864390961], 
processed observation next is [1.0, 0.6086956521739131, 0.6493827160493829, 0.46, 1.0, 1.0, 0.5503557932464009, 1.0, 0.5, 0.5503557932464009, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5255747993556461, 0.5255747993556461, 0.5350318969982617], 
reward next is 0.4650, 
noisyNet noise sample is [array([0.8347455], dtype=float32), 0.6676191]. 
=============================================
[2019-03-23 22:56:55,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4212906e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:55,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3722
[2019-03-23 22:56:55,764] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 54.66666666666666, 1.0, 2.0, 0.488166199136604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 629818.5624798606, 629818.5624798601, 135159.0585931651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.53333333333333, 55.33333333333334, 1.0, 2.0, 0.426611548963842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 550373.94625414, 550373.9462541403, 125579.6402148762], 
processed observation next is [1.0, 0.08695652173913043, 0.3160493827160493, 0.5533333333333335, 1.0, 1.0, 0.31739470114743096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19656212366219286, 0.19656212366219297, 0.24149930810553116], 
reward next is 0.7585, 
noisyNet noise sample is [array([0.6675614], dtype=float32), -0.10389734]. 
=============================================
[2019-03-23 22:56:55,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.3516]
 [71.3516]
 [71.3516]
 [71.3516]
 [71.3516]], R is [[71.39658356]
 [71.42269897]
 [71.51567841]
 [71.60624695]
 [71.6943512 ]].
[2019-03-23 22:56:55,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3210387e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:55,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3228
[2019-03-23 22:56:55,960] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 64.33333333333334, 1.0, 2.0, 0.4131001198454753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508689.936248274, 508689.936248274, 130404.5154896091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7760400.0000, 
sim time next is 7761000.0000, 
raw observation next is [24.28333333333333, 65.16666666666666, 1.0, 2.0, 0.4088779821147548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504448.532317954, 504448.5323179535, 129826.0107573337], 
processed observation next is [1.0, 0.8260869565217391, 0.4549382716049382, 0.6516666666666666, 1.0, 1.0, 0.29628331204137476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.180160190113555, 0.1801601901135548, 0.2496654053025648], 
reward next is 0.7503, 
noisyNet noise sample is [array([-0.3623545], dtype=float32), -0.7612875]. 
=============================================
[2019-03-23 22:56:55,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.78153]
 [76.78153]
 [76.78153]
 [76.78153]
 [76.78153]], R is [[76.76404572]
 [76.74562836]
 [76.72601318]
 [76.7052002 ]
 [76.68323517]].
[2019-03-23 22:57:00,578] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:00,578] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:00,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 22:57:01,467] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1322902e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:57:01,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8577
[2019-03-23 22:57:01,480] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 76.33333333333334, 1.0, 2.0, 0.470119229811812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586252.9803463769, 586252.9803463769, 139013.617417027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7888800.0000, 
sim time next is 7889400.0000, 
raw observation next is [21.9, 75.5, 1.0, 2.0, 0.4808113374052574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599453.0694460477, 599453.0694460477, 140662.7212493946], 
processed observation next is [1.0, 0.30434782608695654, 0.36666666666666664, 0.755, 1.0, 1.0, 0.38191825881578256, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.214090381945017, 0.214090381945017, 0.2705052331719127], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.4910126], dtype=float32), -1.2923621]. 
=============================================
[2019-03-23 22:57:04,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3786941e-22 1.0000000e+00 3.9801414e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:57:04,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1319
[2019-03-23 22:57:04,708] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333334, 50.5, 1.0, 2.0, 0.3509117558281442, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5604696784369336, 6.9112, 6.9112, 121.9260426156618, 819011.6149665266, 819011.6149665266, 209005.6537950232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7924200.0000, 
sim time next is 7924800.0000, 
raw observation next is [29.76666666666667, 51.0, 1.0, 2.0, 0.5099590017111587, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602358.4776851059, 602358.4776851059, 144241.706208573], 
processed observation next is [1.0, 0.7391304347826086, 0.6580246913580248, 0.51, 1.0, 1.0, 0.4166178591799508, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21512802774468068, 0.21512802774468068, 0.2773878965549481], 
reward next is 0.7226, 
noisyNet noise sample is [array([-0.66153675], dtype=float32), -0.35480377]. 
=============================================
[2019-03-23 22:57:04,830] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1408345e-24 1.0000000e+00 1.3778994e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:57:04,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9231
[2019-03-23 22:57:04,842] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 54.66666666666667, 1.0, 2.0, 0.5026658939900084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598684.9647947743, 598684.9647947743, 143282.9323814536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7928400.0000, 
sim time next is 7929000.0000, 
raw observation next is [28.45, 55.5, 1.0, 2.0, 0.5015188048106544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 597734.3183553835, 597734.3183553839, 143117.851184287], 
processed observation next is [1.0, 0.782608695652174, 0.6092592592592593, 0.555, 1.0, 1.0, 0.40657000572696944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2134765422697798, 0.21347654226977997, 0.2752266368928596], 
reward next is 0.7248, 
noisyNet noise sample is [array([0.32463804], dtype=float32), 0.16677055]. 
=============================================
[2019-03-23 22:57:04,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.59665]
 [59.59665]
 [59.59665]
 [59.59665]
 [59.59665]], R is [[59.72545624]
 [59.85265732]
 [59.97887421]
 [60.10404968]
 [60.22774887]].
[2019-03-23 22:57:05,391] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:05,391] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:05,457] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 22:57:05,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:05,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:05,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 22:57:05,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.099804e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:57:05,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1499
[2019-03-23 22:57:05,838] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 67.5, 1.0, 2.0, 0.4594010766375486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557702.8146296784, 557702.8146296784, 136992.135092983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7941000.0000, 
sim time next is 7941600.0000, 
raw observation next is [24.9, 68.0, 1.0, 2.0, 0.4566334956476324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554902.9374261406, 554902.9374261406, 136592.8213404809], 
processed observation next is [1.0, 0.9565217391304348, 0.47777777777777775, 0.68, 1.0, 1.0, 0.3531351138662291, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19817962050933594, 0.19817962050933594, 0.2626785025778479], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.65774345], dtype=float32), 1.7291136]. 
=============================================
[2019-03-23 22:57:05,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:05,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:05,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 22:57:06,003] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,003] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 22:57:06,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 22:57:06,201] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,210] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 22:57:06,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,251] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 22:57:06,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,538] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 22:57:06,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,574] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 22:57:06,600] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,600] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,604] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 22:57:06,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,732] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 22:57:06,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:06,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 22:57:06,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:57:06,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:07,000] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 22:57:08,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3303555e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:57:08,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0523
[2019-03-23 22:57:08,390] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 52.5, 1.0, 2.0, 0.2986657886433667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385268.9385542075, 385268.9385542075, 112107.1427186931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [22.13333333333333, 51.0, 1.0, 2.0, 0.2782287702170556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358899.6954481937, 358899.6954481937, 110190.3335170448], 
processed observation next is [1.0, 0.30434782608695654, 0.3753086419753085, 0.51, 1.0, 1.0, 0.14074853597268525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1281784626600692, 0.1281784626600692, 0.21190448753277846], 
reward next is 0.7881, 
noisyNet noise sample is [array([-0.864262], dtype=float32), -2.7589507]. 
=============================================
[2019-03-23 22:57:09,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0695085e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:57:09,082] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8625
[2019-03-23 22:57:09,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 62.33333333333334, 1.0, 2.0, 0.2560994534170583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 330347.9552395532, 330347.9552395532, 102374.6996347997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 24000.0000, 
sim time next is 24600.0000, 
raw observation next is [20.33333333333334, 59.66666666666666, 1.0, 2.0, 0.2622180342391662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 338242.1789497917, 338242.1789497917, 103904.0881047091], 
processed observation next is [1.0, 0.2608695652173913, 0.3086419753086422, 0.5966666666666666, 1.0, 1.0, 0.12168813599900735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12080077819635418, 0.12080077819635418, 0.1998155540475175], 
reward next is 0.8002, 
noisyNet noise sample is [array([0.23100956], dtype=float32), 0.4460169]. 
=============================================
[2019-03-23 22:57:10,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.658455e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:57:10,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2259
[2019-03-23 22:57:10,804] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 45.5, 1.0, 2.0, 0.4078407244862004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502417.1201627719, 502417.1201627719, 129659.9965006902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 69000.0000, 
sim time next is 69600.0000, 
raw observation next is [28.2, 46.0, 1.0, 2.0, 0.4105921434208857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505708.1031354629, 505708.1031354629, 130049.1876591055], 
processed observation next is [1.0, 0.8260869565217391, 0.6, 0.46, 1.0, 1.0, 0.29832398026295914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1806100368340939, 0.1806100368340939, 0.250094591652126], 
reward next is 0.7499, 
noisyNet noise sample is [array([0.15464984], dtype=float32), -1.3173419]. 
=============================================
[2019-03-23 22:57:12,528] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 22:57:12,534] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:57:12,536] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:57:12,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:12,538] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:12,539] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:57:12,540] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:12,540] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:57:12,542] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:12,543] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:57:12,546] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:57:12,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 22:57:12,591] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 22:57:12,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 22:57:12,615] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 22:57:12,639] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 22:58:00,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:00,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.585010614633623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676621.5130320084, 676621.5130320084, 155996.9983190079]
[2019-03-23 22:58:00,669] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:58:00,673] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.16651469729265567
[2019-03-23 22:58:20,224] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:20,227] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.987697255, 104.8299687083333, 1.0, 2.0, 0.5886197242048877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684325.9860923344, 684325.9860923344, 156774.3117322937]
[2019-03-23 22:58:20,230] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:58:20,233] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5118649832631073
[2019-03-23 22:58:20,703] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:20,703] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.55, 67.5, 1.0, 2.0, 0.8419366872755153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156562, 959670.9297852166, 959670.929785217, 204750.3555870711]
[2019-03-23 22:58:20,704] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:58:20,710] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.06838869927893698
[2019-03-23 22:58:22,914] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:22,914] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.55882304666667, 85.63975507666666, 1.0, 2.0, 0.5857102100098189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681042.5408271193, 681042.5408271193, 156280.0086034207]
[2019-03-23 22:58:22,915] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:58:22,918] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9109602969446575
[2019-03-23 22:58:36,136] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:36,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 86.5, 1.0, 2.0, 0.9098522669549366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259629320707, 1037136.036235433, 1037136.036235432, 219682.4973186236]
[2019-03-23 22:58:36,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:58:36,141] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.01879932883617641
[2019-03-23 22:58:39,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0474118]
[2019-03-23 22:58:39,753] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.68001286000001, 83.09360597666668, 1.0, 2.0, 0.8821556674124589, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260425700188, 1720715.179647719, 1720715.179647718, 353139.3660347445]
[2019-03-23 22:58:39,753] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:58:39,756] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.750313e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3194902449074841
[2019-03-23 22:58:39,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1720715.179647719 W.
[2019-03-23 22:58:55,658] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:58:56,041] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:58:56,107] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:58:56,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:58:56,171] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:58:57,188] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1700000, evaluation results [1700000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:58:58,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.03068e-29 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 22:58:58,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1846
[2019-03-23 22:58:58,105] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 74.5, 1.0, 2.0, 0.4121979849723029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508143.0141626775, 508143.0141626775, 130289.753999777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 93000.0000, 
sim time next is 93600.0000, 
raw observation next is [22.8, 75.0, 1.0, 2.0, 0.4095931353262159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505236.1574292886, 505236.1574292886, 129925.6180010513], 
processed observation next is [1.0, 0.08695652173913043, 0.4, 0.75, 1.0, 1.0, 0.2971346849121618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1804414847961745, 0.1804414847961745, 0.24985695769432945], 
reward next is 0.7501, 
noisyNet noise sample is [array([1.6018829], dtype=float32), -0.78018934]. 
=============================================
[2019-03-23 22:58:59,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1489583e-21 1.0000000e+00 7.6130162e-34 0.0000000e+00 1.2918178e-37], sum to 1.0000
[2019-03-23 22:58:59,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9745
[2019-03-23 22:58:59,644] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 30.5, 1.0, 2.0, 0.3176557778469826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409689.1743081359, 409689.1743081359, 117770.8497025641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304200.0000, 
sim time next is 304800.0000, 
raw observation next is [27.0, 30.66666666666666, 1.0, 2.0, 0.3184419884592032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410411.1732270969, 410411.1732270969, 117873.4281333943], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.3066666666666666, 1.0, 1.0, 0.18862141483238476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14657541900967747, 0.14657541900967747, 0.22667966948729673], 
reward next is 0.7733, 
noisyNet noise sample is [array([-0.7081527], dtype=float32), -0.18071629]. 
=============================================
[2019-03-23 22:59:03,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1870635e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:03,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3557
[2019-03-23 22:59:03,725] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 60.0, 1.0, 2.0, 0.3733642525189765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466794.668473474, 466794.668473474, 125014.2210369136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 203400.0000, 
sim time next is 204000.0000, 
raw observation next is [24.46666666666667, 57.33333333333333, 1.0, 2.0, 0.37238914799631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466108.7465854274, 466108.7465854274, 124890.6531178959], 
processed observation next is [0.0, 0.34782608695652173, 0.46172839506172847, 0.5733333333333333, 1.0, 1.0, 0.252844223805131, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1664674094947955, 0.1664674094947955, 0.24017433291903056], 
reward next is 0.7598, 
noisyNet noise sample is [array([-1.2034073], dtype=float32), -0.50208044]. 
=============================================
[2019-03-23 22:59:03,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.141525]
 [71.141525]
 [71.141525]
 [71.141525]
 [71.141525]], R is [[71.18993378]
 [71.23762512]
 [71.28478241]
 [71.33182526]
 [71.37944031]].
[2019-03-23 22:59:06,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1565648e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:06,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5126
[2019-03-23 22:59:06,908] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 51.33333333333334, 1.0, 2.0, 0.2532964030626842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326731.4727316831, 326731.4727316831, 92626.55987684756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 271200.0000, 
sim time next is 271800.0000, 
raw observation next is [20.2, 51.5, 1.0, 2.0, 0.2522889807608559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 325431.7053372579, 325431.7053372575, 92287.14132097311], 
processed observation next is [0.0, 0.13043478260869565, 0.3037037037037037, 0.515, 1.0, 1.0, 0.10986783423911414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11622560904902067, 0.11622560904902053, 0.17747527177110214], 
reward next is 0.8225, 
noisyNet noise sample is [array([-0.2153246], dtype=float32), 0.6236929]. 
=============================================
[2019-03-23 22:59:07,236] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4135801e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:07,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5913
[2019-03-23 22:59:07,256] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 29.66666666666667, 1.0, 2.0, 0.3124136765490744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403007.9167273271, 403007.9167273271, 111061.483239631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 301200.0000, 
sim time next is 301800.0000, 
raw observation next is [26.51666666666667, 29.83333333333333, 1.0, 2.0, 0.3134467816145898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404340.9546614452, 404340.9546614452, 112247.5445223868], 
processed observation next is [0.0, 0.4782608695652174, 0.5376543209876544, 0.2983333333333333, 1.0, 1.0, 0.18267474001736878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.144407483807659, 0.144407483807659, 0.21586066254305153], 
reward next is 0.7841, 
noisyNet noise sample is [array([-0.6662258], dtype=float32), -1.8492469]. 
=============================================
[2019-03-23 22:59:09,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2241027e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:09,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8470
[2019-03-23 22:59:09,507] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 30.83333333333334, 1.0, 2.0, 0.3338279191838805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427074.7550995255, 427074.755099526, 119859.1155408171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 317400.0000, 
sim time next is 318000.0000, 
raw observation next is [28.03333333333333, 30.66666666666667, 1.0, 2.0, 0.3338385569133337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427180.3671322999, 427180.3671322995, 119860.5047748595], 
processed observation next is [0.0, 0.6956521739130435, 0.5938271604938271, 0.3066666666666667, 1.0, 1.0, 0.20695066299206394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15256441683296426, 0.15256441683296412, 0.23050097072088366], 
reward next is 0.7695, 
noisyNet noise sample is [array([0.17970368], dtype=float32), -0.6628699]. 
=============================================
[2019-03-23 22:59:09,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[80.36135]
 [80.36135]
 [80.36135]
 [80.36135]
 [80.36135]], R is [[80.32724762]
 [80.29347992]
 [80.26013947]
 [80.22724152]
 [80.1947937 ]].
[2019-03-23 22:59:10,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7511508e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:10,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-23 22:59:10,873] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 64.0, 1.0, 2.0, 0.400307221665574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507108.7213487819, 507108.7213487823, 128844.2085628123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 627000.0000, 
sim time next is 627600.0000, 
raw observation next is [22.53333333333333, 63.0, 1.0, 2.0, 0.3867193633809118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489310.0803654932, 489310.0803654932, 126933.724894175], 
processed observation next is [1.0, 0.2608695652173913, 0.3901234567901234, 0.63, 1.0, 1.0, 0.269904004024895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1747536001305333, 0.1747536001305333, 0.2441033171041827], 
reward next is 0.7559, 
noisyNet noise sample is [array([-0.9000007], dtype=float32), -0.6703966]. 
=============================================
[2019-03-23 22:59:11,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1183369e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:11,044] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 22:59:11,049] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 45.5, 1.0, 2.0, 0.2882914066455768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371634.7554156816, 371634.7554156816, 114129.4004449264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 342600.0000, 
sim time next is 343200.0000, 
raw observation next is [23.3, 46.0, 1.0, 2.0, 0.2850492714174047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367584.3988154322, 367584.3988154322, 113735.2502815941], 
processed observation next is [0.0, 1.0, 0.41851851851851857, 0.46, 1.0, 1.0, 0.14886818025881512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13128014243408292, 0.13128014243408292, 0.21872163515691173], 
reward next is 0.7813, 
noisyNet noise sample is [array([1.1743828], dtype=float32), -0.06778428]. 
=============================================
[2019-03-23 22:59:13,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8314875e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:13,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5847
[2019-03-23 22:59:13,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 35.33333333333334, 1.0, 2.0, 0.3251118444090932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413705.5180874131, 413705.5180874131, 118729.7062575924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 420000.0000, 
sim time next is 420600.0000, 
raw observation next is [27.35, 35.66666666666666, 1.0, 2.0, 0.3247005917244273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413388.7260886453, 413388.7260886453, 118678.1556789142], 
processed observation next is [1.0, 0.8695652173913043, 0.5685185185185185, 0.3566666666666666, 1.0, 1.0, 0.19607213300527057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14763883074594475, 0.14763883074594475, 0.2282272224594504], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.51069486], dtype=float32), 1.0561955]. 
=============================================
[2019-03-23 22:59:13,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.722352e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:13,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1887
[2019-03-23 22:59:13,817] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 43.5, 1.0, 2.0, 0.2950064419536046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378030.3166560044, 378030.3166560044, 114961.6315932462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430200.0000, 
sim time next is 430800.0000, 
raw observation next is [24.43333333333333, 44.66666666666667, 1.0, 2.0, 0.2922182588713689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374512.6402303048, 374512.6402303048, 114620.1689070849], 
processed observation next is [1.0, 1.0, 0.4604938271604937, 0.4466666666666667, 1.0, 1.0, 0.15740268913258199, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.133754514367966, 0.133754514367966, 0.22042340174439404], 
reward next is 0.7796, 
noisyNet noise sample is [array([0.99912184], dtype=float32), -0.35574833]. 
=============================================
[2019-03-23 22:59:14,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.374196e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:14,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8802
[2019-03-23 22:59:14,465] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 29.66666666666667, 1.0, 2.0, 0.3492065879482256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442594.2863759515, 442594.2863759515, 121853.5081173123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [29.45, 30.0, 1.0, 2.0, 0.3468357487798041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439761.6224802005, 439761.6224802005, 121541.8699109104], 
processed observation next is [1.0, 0.782608695652174, 0.6462962962962963, 0.3, 1.0, 1.0, 0.22242351045214775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15705772231435733, 0.15705772231435733, 0.23373436521328925], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.49664012], dtype=float32), 0.15868004]. 
=============================================
[2019-03-23 22:59:21,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.850412e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:21,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3953
[2019-03-23 22:59:21,155] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.26666666666667, 43.0, 1.0, 2.0, 0.3123111647988001, 1.0, 2.0, 0.3123111647988001, 1.0, 2.0, 0.5014940728478976, 6.9112, 6.9112, 121.94756008, 1111783.307056666, 1111783.307056666, 260547.35021918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 562800.0000, 
sim time next is 563400.0000, 
raw observation next is [29.4, 42.0, 1.0, 2.0, 0.8663553942019004, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1054297.161803027, 1054297.161803027, 213064.7166920094], 
processed observation next is [1.0, 0.5217391304347826, 0.6444444444444444, 0.42, 1.0, 1.0, 0.8408992788117863, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3765347006439382, 0.3765347006439382, 0.40973983979232576], 
reward next is 0.5903, 
noisyNet noise sample is [array([-0.42256775], dtype=float32), 0.38531354]. 
=============================================
[2019-03-23 22:59:23,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.965568e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:23,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8002
[2019-03-23 22:59:23,847] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.58333333333333, 39.5, 1.0, 2.0, 0.3718707479841937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463953.7039064373, 463953.7039064369, 124792.8613908357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 593400.0000, 
sim time next is 594000.0000, 
raw observation next is [28.4, 40.0, 1.0, 2.0, 0.3703346438562604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462309.7809312706, 462309.7809312706, 124589.2094247234], 
processed observation next is [1.0, 0.9130434782608695, 0.6074074074074074, 0.4, 1.0, 1.0, 0.2503983855431672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16511063604688236, 0.16511063604688236, 0.23959463350908347], 
reward next is 0.7604, 
noisyNet noise sample is [array([0.2861953], dtype=float32), 2.0776348]. 
=============================================
[2019-03-23 22:59:23,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.13104]
 [73.13104]
 [73.13104]
 [73.13104]
 [73.13104]], R is [[73.16013336]
 [73.18855286]
 [73.21627045]
 [73.24329376]
 [73.26964569]].
[2019-03-23 22:59:24,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5563504e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:25,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-23 22:59:25,015] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 60.0, 1.0, 2.0, 0.3733028551054384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474550.2434781885, 474550.2434781885, 125103.7140034272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 615600.0000, 
sim time next is 616200.0000, 
raw observation next is [22.31666666666667, 60.83333333333333, 1.0, 2.0, 0.431516826716082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548756.5494349329, 548756.5494349329, 133360.2152600392], 
processed observation next is [1.0, 0.13043478260869565, 0.38209876543209886, 0.6083333333333333, 1.0, 1.0, 0.3232343175191453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19598448194104745, 0.19598448194104745, 0.2564619524231523], 
reward next is 0.7435, 
noisyNet noise sample is [array([-0.17764212], dtype=float32), -0.4212726]. 
=============================================
[2019-03-23 22:59:33,873] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4408784e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:33,883] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5477
[2019-03-23 22:59:33,890] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 58.0, 1.0, 2.0, 0.3042170729066074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387782.5609744494, 387782.5609744494, 116096.76011453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 795600.0000, 
sim time next is 796200.0000, 
raw observation next is [22.66666666666667, 58.0, 1.0, 2.0, 0.3055435975247331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389285.3410063101, 389285.3410063105, 116261.0815725421], 
processed observation next is [0.0, 0.21739130434782608, 0.39506172839506193, 0.58, 1.0, 1.0, 0.17326618752944417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.139030478930825, 0.13903047893082518, 0.22357900302411943], 
reward next is 0.7764, 
noisyNet noise sample is [array([0.5524014], dtype=float32), -1.136441]. 
=============================================
[2019-03-23 22:59:35,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1321555e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:35,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5112
[2019-03-23 22:59:35,557] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 59.0, 1.0, 2.0, 0.3463678754265289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436201.8302523502, 436201.8302523502, 121447.5123690665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 805200.0000, 
sim time next is 805800.0000, 
raw observation next is [23.73333333333333, 59.0, 1.0, 2.0, 0.3485828751705239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438676.9477939233, 438676.9477939228, 121735.3548788527], 
processed observation next is [0.0, 0.30434782608695654, 0.4345679012345678, 0.59, 1.0, 1.0, 0.22450342282205224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15667033849782977, 0.15667033849782958, 0.23410645169010133], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.21790934], dtype=float32), -1.066106]. 
=============================================
[2019-03-23 22:59:43,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1942173e-31 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:59:43,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2509
[2019-03-23 22:59:43,150] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 75.0, 1.0, 2.0, 0.2825405016659709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 362818.4909446609, 362818.4909446609, 113443.833503697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1123200.0000, 
sim time next is 1123800.0000, 
raw observation next is [19.2, 74.83333333333333, 1.0, 2.0, 0.2815990463554197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 361674.4464131907, 361674.4464131903, 113330.2143063304], 
processed observation next is [1.0, 0.0, 0.26666666666666666, 0.7483333333333333, 1.0, 1.0, 0.14476076947073777, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1291694451475681, 0.12916944514756795, 0.21794271981986615], 
reward next is 0.7821, 
noisyNet noise sample is [array([-1.0929544], dtype=float32), -1.9897635]. 
=============================================
[2019-03-23 22:59:44,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.13570394e-26 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:59:44,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-23 22:59:44,995] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 55.66666666666667, 1.0, 2.0, 0.808310738650775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425961743, 1007190.46155339, 1007190.46155339, 201093.6678576189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 991200.0000, 
sim time next is 991800.0000, 
raw observation next is [25.1, 55.5, 1.0, 2.0, 0.8434659630808002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156559, 1050924.635166446, 1050924.635166446, 208713.832463234], 
processed observation next is [1.0, 0.4782608695652174, 0.4851851851851852, 0.555, 1.0, 1.0, 0.8136499560485717, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200968, 0.37533022684515926, 0.37533022684515926, 0.40137275473698847], 
reward next is 0.5986, 
noisyNet noise sample is [array([-0.52232456], dtype=float32), 1.6402116]. 
=============================================
[2019-03-23 22:59:45,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.446967e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:45,557] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0723
[2019-03-23 22:59:45,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 57.0, 1.0, 2.0, 0.8114390686702763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1018380.033603192, 1018380.033603192, 201909.7199202496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 986400.0000, 
sim time next is 987000.0000, 
raw observation next is [24.33333333333334, 56.83333333333333, 1.0, 2.0, 0.9015877651787937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.091602098145234, 6.9112, 121.925370030727, 1222596.129653075, 1130214.640856231, 221942.3247172404], 
processed observation next is [1.0, 0.43478260869565216, 0.4567901234567903, 0.5683333333333332, 1.0, 1.0, 0.882842577593802, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.018040209814523412, 0.0, 0.8094576635556079, 0.4366414748760982, 0.4036480860200825, 0.42681216291777], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3287581], dtype=float32), 0.17097862]. 
=============================================
[2019-03-23 22:59:45,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.82913]
 [64.82913]
 [64.82913]
 [64.82913]
 [64.82913]], R is [[64.18083954]
 [64.15074158]
 [64.13272095]
 [64.12417603]
 [64.14115906]].
[2019-03-23 22:59:46,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.287652e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:59:46,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3487
[2019-03-23 22:59:46,415] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 47.5, 1.0, 2.0, 0.690676000443966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425790123, 864436.7654952244, 864436.7654952244, 177265.043666265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1006200.0000, 
sim time next is 1006800.0000, 
raw observation next is [26.4, 47.0, 1.0, 2.0, 0.8731199586554236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156506, 1092790.475652677, 1092790.475652677, 215419.8549431309], 
processed observation next is [1.0, 0.6521739130434783, 0.5333333333333333, 0.47, 1.0, 1.0, 0.8489523317326471, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200616, 0.39028231273309894, 0.39028231273309894, 0.41426895181371326], 
reward next is 0.5857, 
noisyNet noise sample is [array([-0.2930661], dtype=float32), 0.2336673]. 
=============================================
[2019-03-23 22:59:47,096] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 22:59:47,098] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:59:47,100] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:47,101] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:59:47,102] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:47,102] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:59:47,105] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:59:47,107] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:59:47,108] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:47,108] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:47,109] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:47,137] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 22:59:47,138] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 22:59:47,138] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 22:59:47,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 22:59:47,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 22:59:54,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 22:59:54,857] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.03333333333333, 82.0, 1.0, 2.0, 0.2398632167362712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 309400.2750013284, 309400.2750013284, 97808.08519742727]
[2019-03-23 22:59:54,858] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:59:54,860] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8740950343949266
[2019-03-23 22:59:59,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 22:59:59,414] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.06628926666667, 35.79460994, 1.0, 2.0, 0.5302543076107229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 617869.7618040455, 617869.761804046, 147138.9172985944]
[2019-03-23 22:59:59,414] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:59:59,417] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6832184277246242
[2019-03-23 23:00:01,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:01,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 29.0, 1.0, 2.0, 0.263252603784693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339576.9938053163, 339576.9938053163, 89152.44523035835]
[2019-03-23 23:00:01,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:01,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3045205117074149
[2019-03-23 23:00:02,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:02,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.86666666666667, 54.66666666666666, 1.0, 2.0, 0.2298733409061875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 296511.8136768373, 296511.8136768373, 89779.02147369803]
[2019-03-23 23:00:02,391] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:02,395] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.46293476612592455
[2019-03-23 23:00:09,149] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:09,150] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.76113119333333, 72.39467758, 1.0, 2.0, 0.4444788251134461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542664.4289677015, 542664.4289677015, 134853.5882986056]
[2019-03-23 23:00:09,152] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:00:09,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5817806745804376
[2019-03-23 23:00:11,832] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:11,833] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.6, 79.0, 1.0, 2.0, 0.3890610876070346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483903.291445818, 483903.2914458176, 127128.3079422943]
[2019-03-23 23:00:11,834] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:11,836] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.033924022452546
[2019-03-23 23:00:54,303] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:54,304] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.16666666666667, 87.66666666666666, 1.0, 2.0, 0.8489366933908696, 1.0, 2.0, 0.8489366933908696, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425261831, 1936469.009102961, 1936469.009102961, 364391.5812858315]
[2019-03-23 23:00:54,306] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:54,310] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6069462170615403
[2019-03-23 23:00:54,312] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1936469.009102961 W.
[2019-03-23 23:00:56,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:00:56,361] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.58333333333333, 89.83333333333334, 1.0, 2.0, 0.7671619039144195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 123.8299958126402, 902779.9996655216, 902779.9996655216, 190924.0904695349]
[2019-03-23 23:00:56,362] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:00:56,366] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8818183822641658
[2019-03-23 23:01:04,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0022141]
[2019-03-23 23:01:04,804] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.06326541666667, 69.23948020333333, 1.0, 2.0, 0.7241170263444754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825303.3633876023, 825303.3633876023, 180762.9798722026]
[2019-03-23 23:01:04,806] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:01:04,808] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.481552e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.40457571857514796
[2019-03-23 23:01:30,285] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:01:30,357] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:01:30,366] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:01:30,464] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:01:30,719] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:01:31,734] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1725000, evaluation results [1725000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:01:36,162] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.408007e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:01:36,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4306
[2019-03-23 23:01:36,177] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 74.16666666666667, 1.0, 2.0, 0.2785771796344524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 358066.6381955377, 358066.6381955373, 112966.1341955742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1126200.0000, 
sim time next is 1126800.0000, 
raw observation next is [19.2, 74.0, 1.0, 2.0, 0.2771509314595217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 356301.6846647697, 356301.6846647692, 112795.1375354087], 
processed observation next is [1.0, 0.043478260869565216, 0.26666666666666666, 0.74, 1.0, 1.0, 0.13946539459466867, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12725060166598917, 0.127250601665989, 0.21691372602963213], 
reward next is 0.7831, 
noisyNet noise sample is [array([1.922281], dtype=float32), -0.29548606]. 
=============================================
[2019-03-23 23:01:42,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6771395e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:01:42,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6226
[2019-03-23 23:01:42,895] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.53333333333333, 21.33333333333333, 1.0, 2.0, 0.4143239774341992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512058.5365688694, 512058.5365688694, 130625.2514068128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1518000.0000, 
sim time next is 1518600.0000, 
raw observation next is [35.66666666666666, 20.66666666666667, 1.0, 2.0, 0.4148730577431489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513509.366259232, 513509.366259232, 130721.9792041577], 
processed observation next is [0.0, 0.5652173913043478, 0.8765432098765429, 0.20666666666666672, 1.0, 1.0, 0.3034203068370821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18339620223544, 0.18339620223544, 0.25138842154645713], 
reward next is 0.7486, 
noisyNet noise sample is [array([1.7005303], dtype=float32), 0.61328197]. 
=============================================
[2019-03-23 23:01:43,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1464543e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:01:43,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 23:01:43,036] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 74.0, 1.0, 2.0, 0.6915228865664614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868073.2946939792, 868073.2946939792, 177474.1859402438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1245600.0000, 
sim time next is 1246200.0000, 
raw observation next is [21.7, 73.0, 1.0, 2.0, 0.6096614364567849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764912.7889781232, 764912.7889781232, 162255.0322729647], 
processed observation next is [1.0, 0.43478260869565216, 0.3592592592592592, 0.73, 1.0, 1.0, 0.5353112338771249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2731831389207583, 0.2731831389207583, 0.3120289082172398], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.68111455], dtype=float32), -0.55794156]. 
=============================================
[2019-03-23 23:01:45,581] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9904465e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:01:45,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8149
[2019-03-23 23:01:45,592] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 81.83333333333333, 1.0, 2.0, 0.3695342025741535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462107.2071783562, 462107.2071783566, 124495.2287621833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1320600.0000, 
sim time next is 1321200.0000, 
raw observation next is [21.1, 81.0, 1.0, 2.0, 0.3677332372885538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459138.6487449835, 459138.6487449835, 124238.1400699036], 
processed observation next is [1.0, 0.30434782608695654, 0.3370370370370371, 0.81, 1.0, 1.0, 0.24730147296256402, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1639780888374941, 0.1639780888374941, 0.23891950013443], 
reward next is 0.7611, 
noisyNet noise sample is [array([1.055256], dtype=float32), 0.29172578]. 
=============================================
[2019-03-23 23:01:47,730] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3647896e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:01:47,743] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0269
[2019-03-23 23:01:47,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328696.181427162 W.
[2019-03-23 23:01:47,757] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 40.5, 1.0, 2.0, 0.9343088073849283, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.243687855128421, 6.9112, 121.9246277016174, 1328696.181427162, 1158434.658029426, 229279.6984393071], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1338600.0000, 
sim time next is 1339200.0000, 
raw observation next is [28.4, 40.0, 1.0, 2.0, 0.5074322077521921, 1.0, 1.0, 0.5074322077521921, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258423972982, 1244847.316728402, 1244847.316728402, 241151.2715946382], 
processed observation next is [1.0, 0.5217391304347826, 0.6074074074074074, 0.4, 1.0, 1.0, 0.413609771133562, 1.0, 0.5, 0.413609771133562, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809460799578414, 0.4445883274030007, 0.4445883274030007, 0.46375244537430427], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.103969], dtype=float32), 0.043514613]. 
=============================================
[2019-03-23 23:01:55,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.172868e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:01:55,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-23 23:01:55,732] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 65.0, 1.0, 2.0, 0.3688476260535219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461774.0944889897, 461774.0944889897, 124411.1958379898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1490400.0000, 
sim time next is 1491000.0000, 
raw observation next is [23.53333333333333, 63.83333333333334, 1.0, 2.0, 0.3728538525038321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466111.421080178, 466111.421080178, 124944.0370999134], 
processed observation next is [0.0, 0.2608695652173913, 0.4271604938271604, 0.6383333333333334, 1.0, 1.0, 0.25339744345694293, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16646836467149215, 0.16646836467149215, 0.2402769944229104], 
reward next is 0.7597, 
noisyNet noise sample is [array([1.0830171], dtype=float32), -0.19726802]. 
=============================================
[2019-03-23 23:01:55,745] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.64816]
 [75.64816]
 [75.64816]
 [75.64816]
 [75.64816]], R is [[75.65140533]
 [75.65563965]
 [75.66043091]
 [75.66578674]
 [75.67172241]].
[2019-03-23 23:02:05,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.08494796e-29 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 23:02:05,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-23 23:02:05,098] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 84.33333333333333, 1.0, 2.0, 0.5217613258003114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663845.8524393649, 663845.8524393649, 147354.9830178261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1673400.0000, 
sim time next is 1674000.0000, 
raw observation next is [19.0, 84.0, 1.0, 2.0, 0.5715101313666584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726911.3091917833, 726911.3091917833, 155688.7209153823], 
processed observation next is [1.0, 0.391304347826087, 0.25925925925925924, 0.84, 1.0, 1.0, 0.4898930135317362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25961118185420834, 0.25961118185420834, 0.29940138637573516], 
reward next is 0.7006, 
noisyNet noise sample is [array([0.12202752], dtype=float32), -0.069023445]. 
=============================================
[2019-03-23 23:02:05,109] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.57215]
 [72.57215]
 [72.57215]
 [72.57215]
 [72.57215]], R is [[72.54703522]
 [72.53818512]
 [72.52828217]
 [72.51045227]
 [72.5074234 ]].
[2019-03-23 23:02:09,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5387405e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:02:09,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9976
[2019-03-23 23:02:09,704] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.55, 79.83333333333334, 1.0, 2.0, 0.3917666191467478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487099.6334474399, 487099.6334474399, 127501.7593080895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1752600.0000, 
sim time next is 1753200.0000, 
raw observation next is [21.7, 79.0, 1.0, 2.0, 0.3899748295550697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484634.4341276718, 484634.4341276713, 127247.1114093763], 
processed observation next is [1.0, 0.30434782608695654, 0.3592592592592592, 0.79, 1.0, 1.0, 0.2737795589941306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1730837264741685, 0.1730837264741683, 0.24470598347956982], 
reward next is 0.7553, 
noisyNet noise sample is [array([-2.1084592], dtype=float32), -0.57969344]. 
=============================================
[2019-03-23 23:02:14,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0345935e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:02:14,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9302
[2019-03-23 23:02:14,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 83.0, 1.0, 2.0, 0.3629908797728466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457155.5864622861, 457155.5864622861, 123661.5328101723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837800.0000, 
sim time next is 1838400.0000, 
raw observation next is [20.23333333333333, 82.33333333333334, 1.0, 2.0, 0.3586523463831733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451444.6773719257, 451444.6773719257, 123075.6441675862], 
processed observation next is [1.0, 0.2608695652173913, 0.3049382716049382, 0.8233333333333335, 1.0, 1.0, 0.23649088855139677, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16123024191854488, 0.16123024191854488, 0.23668393109151192], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.4001762], dtype=float32), 1.3489397]. 
=============================================
[2019-03-23 23:02:21,662] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 23:02:21,663] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:02:21,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:02:21,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:02:21,666] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:02:21,667] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:02:21,667] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:02:21,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:02:21,670] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:02:21,672] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:02:21,673] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:02:21,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 23:02:21,713] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 23:02:21,747] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 23:02:21,748] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 23:02:21,748] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 23:03:08,343] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0106622]
[2019-03-23 23:03:08,345] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.5337970848405502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632303.5394192906, 632303.5394192906, 148138.756846108]
[2019-03-23 23:03:08,345] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:03:08,349] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5148698e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7635360629270075
[2019-03-23 23:03:30,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0106622]
[2019-03-23 23:03:30,962] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.6002446875893018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 688295.7795555944, 688295.779555594, 158328.8105541671]
[2019-03-23 23:03:30,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:03:30,967] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5148698e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6571884825236176
[2019-03-23 23:03:33,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0106622]
[2019-03-23 23:03:33,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.86943981666667, 76.89112229333332, 1.0, 2.0, 0.8295106194351499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945498.4952179127, 945498.4952179127, 202126.3585288683]
[2019-03-23 23:03:33,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:03:33,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5148698e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4887408638440428
[2019-03-23 23:04:04,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0106622]
[2019-03-23 23:04:04,331] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.13333333333333, 78.0, 1.0, 2.0, 0.2472843067371333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 318974.7515753632, 318974.7515753632, 106596.755659824]
[2019-03-23 23:04:04,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:04:04,334] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5148698e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.96661955313446
[2019-03-23 23:04:04,948] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:04:04,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:04:05,168] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:04:05,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:04:05,480] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:04:06,494] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1750000, evaluation results [1750000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:04:08,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5746175e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:08,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4630
[2019-03-23 23:04:08,031] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 79.0, 1.0, 2.0, 0.3718639624381854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463292.9871949694, 463292.9871949689, 124779.3544310266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2016000.0000, 
sim time next is 2016600.0000, 
raw observation next is [21.71666666666667, 78.33333333333334, 1.0, 2.0, 0.3753655707504654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467104.290209505, 467104.290209505, 125245.7956745098], 
processed observation next is [0.0, 0.34782608695652173, 0.3598765432098766, 0.7833333333333334, 1.0, 1.0, 0.2563875842267445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16682296078910894, 0.16682296078910894, 0.2408572993740573], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.7344277], dtype=float32), -0.44796512]. 
=============================================
[2019-03-23 23:04:09,509] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9521942e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:09,518] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3803
[2019-03-23 23:04:09,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6018201246287438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693456.9728720584, 693456.9728720584, 158761.7634790411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2656800.0000, 
sim time next is 2657400.0000, 
raw observation next is [26.83333333333333, 74.66666666666667, 1.0, 2.0, 0.6034079003132248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695372.9325631983, 695372.9325631983, 159040.4963275515], 
processed observation next is [0.0, 0.782608695652174, 0.5493827160493825, 0.7466666666666667, 1.0, 1.0, 0.5278665479919342, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24834747591542794, 0.24834747591542794, 0.3058471083222144], 
reward next is 0.6942, 
noisyNet noise sample is [array([1.0568315], dtype=float32), -0.5660706]. 
=============================================
[2019-03-23 23:04:11,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7868214e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:11,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5447
[2019-03-23 23:04:11,123] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 84.16666666666667, 1.0, 2.0, 0.4672008526479182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 565040.0534650126, 565040.0534650121, 138105.9675418639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325000.0000, 
sim time next is 2325600.0000, 
raw observation next is [22.7, 85.0, 1.0, 2.0, 0.4660314872721054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563817.8743421691, 563817.8743421691, 137934.5720422346], 
processed observation next is [1.0, 0.9565217391304348, 0.39629629629629626, 0.85, 1.0, 1.0, 0.3643231991334588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2013635265507747, 0.2013635265507747, 0.2652587923889127], 
reward next is 0.7347, 
noisyNet noise sample is [array([-0.38635737], dtype=float32), -1.2272443]. 
=============================================
[2019-03-23 23:04:14,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8255403e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:14,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6435
[2019-03-23 23:04:14,855] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 61.0, 1.0, 2.0, 0.6157624208629313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702832.5890122625, 702832.5890122625, 160863.7447894841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2142000.0000, 
sim time next is 2142600.0000, 
raw observation next is [29.61666666666667, 62.5, 1.0, 2.0, 0.6211832068503412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707931.6486727141, 707931.6486727141, 161759.1660706276], 
processed observation next is [0.0, 0.8260869565217391, 0.6524691358024692, 0.625, 1.0, 1.0, 0.5490276272027872, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25283273166882647, 0.25283273166882647, 0.31107531936659155], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.54611564], dtype=float32), 1.461531]. 
=============================================
[2019-03-23 23:04:15,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5356445e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:15,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0163
[2019-03-23 23:04:15,700] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.28333333333333, 81.5, 1.0, 2.0, 0.5687727720824777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662337.8966197898, 662337.8966197898, 153458.1306126975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2159400.0000, 
sim time next is 2160000.0000, 
raw observation next is [25.2, 82.0, 1.0, 2.0, 0.568494461590898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662149.905620034, 662149.905620034, 153417.4456827815], 
processed observation next is [1.0, 0.0, 0.4888888888888889, 0.82, 1.0, 1.0, 0.4863029304653547, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23648210915001214, 0.23648210915001214, 0.2950335493899644], 
reward next is 0.7050, 
noisyNet noise sample is [array([-1.7485038], dtype=float32), -1.5300086]. 
=============================================
[2019-03-23 23:04:15,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.12743]
 [73.12743]
 [73.12743]
 [73.12743]
 [73.12743]], R is [[73.10112762]
 [73.07500458]
 [73.04895782]
 [73.02285004]
 [72.99671173]].
[2019-03-23 23:04:21,072] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3503726e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:21,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7596
[2019-03-23 23:04:21,083] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.4227916523796962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519134.5993493839, 519134.5993493839, 131760.6692666854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [20.4, 96.0, 1.0, 2.0, 0.4223415212808672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518580.7199765248, 518580.7199765248, 131695.5419513159], 
processed observation next is [1.0, 0.2608695652173913, 0.31111111111111106, 0.96, 1.0, 1.0, 0.31231133485817525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.185207399991616, 0.185207399991616, 0.25326065759868444], 
reward next is 0.7467, 
noisyNet noise sample is [array([-0.13280934], dtype=float32), -0.73169416]. 
=============================================
[2019-03-23 23:04:21,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.9128]
 [73.9128]
 [73.9128]
 [73.9128]
 [73.9128]], R is [[73.92042542]
 [73.92783356]
 [73.9355545 ]
 [73.94441223]
 [73.94462585]].
[2019-03-23 23:04:28,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9833189e-23 1.0000000e+00 1.5912697e-35 0.0000000e+00 4.2381782e-38], sum to 1.0000
[2019-03-23 23:04:28,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-23 23:04:28,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1321842.178941016 W.
[2019-03-23 23:04:28,685] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 38.16666666666666, 1.0, 2.0, 0.9359364719115578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.233862419219114, 6.9112, 121.924425151831, 1321842.178941016, 1156612.373019179, 229560.6282508649], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2375400.0000, 
sim time next is 2376000.0000, 
raw observation next is [29.9, 38.0, 1.0, 2.0, 0.5142178761560816, 0.0, 2.0, 0.0, 1.0, 1.0, 0.83993765722144, 6.9112, 6.9112, 121.925848264278, 1255157.615370314, 1255157.615370314, 259152.7783328477], 
processed observation next is [1.0, 0.5217391304347826, 0.6629629629629629, 0.38, 1.0, 1.0, 0.421687947804859, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7999220715267998, 0.0, 0.0, 0.8094608385290587, 0.44827057691796934, 0.44827057691796934, 0.49837072756316864], 
reward next is 0.5016, 
noisyNet noise sample is [array([0.0708301], dtype=float32), 0.22195353]. 
=============================================
[2019-03-23 23:04:28,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.282135]
 [54.282135]
 [54.282135]
 [54.282135]
 [54.282135]], R is [[54.24094009]
 [53.6985321 ]
 [53.16154861]
 [52.6299324 ]
 [52.10363388]].
[2019-03-23 23:04:28,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1930702e-23 1.0000000e+00 7.5396243e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:28,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6270
[2019-03-23 23:04:28,821] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 45.0, 1.0, 2.0, 0.387319023498969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481105.9917725433, 481105.9917725433, 126873.1825324388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2404800.0000, 
sim time next is 2405400.0000, 
raw observation next is [27.48333333333333, 46.0, 1.0, 2.0, 0.3858380657623475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479355.4639577733, 479355.4639577733, 126669.9411202704], 
processed observation next is [1.0, 0.8695652173913043, 0.5734567901234567, 0.46, 1.0, 1.0, 0.2688548401932709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17119837998491902, 0.17119837998491902, 0.24359604061590462], 
reward next is 0.7564, 
noisyNet noise sample is [array([1.9983858], dtype=float32), 0.6763832]. 
=============================================
[2019-03-23 23:04:29,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3657991e-24 1.0000000e+00 3.3447293e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:29,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-23 23:04:29,282] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1424371.158992751 W.
[2019-03-23 23:04:29,287] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.05, 37.0, 1.0, 2.0, 0.4022685864438507, 1.0, 2.0, 0.4022685864438507, 1.0, 2.0, 0.6445691973692477, 6.911199999999999, 6.9112, 121.94756008, 1424371.158992751, 1424371.158992752, 298013.7617246243], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2385000.0000, 
sim time next is 2385600.0000, 
raw observation next is [31.03333333333333, 37.0, 1.0, 2.0, 0.5770359048296161, 1.0, 2.0, 0.5770359048296161, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1377124.816687668, 1377124.816687668, 262947.4209302606], 
processed observation next is [1.0, 0.6086956521739131, 0.7049382716049382, 0.37, 1.0, 1.0, 0.4964713152733525, 1.0, 1.0, 0.4964713152733525, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49183029167416714, 0.49183029167416714, 0.5056681171735781], 
reward next is 0.4943, 
noisyNet noise sample is [array([-0.38836735], dtype=float32), 0.9595371]. 
=============================================
[2019-03-23 23:04:32,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.272437e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:04:32,164] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1902
[2019-03-23 23:04:32,171] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 90.66666666666666, 1.0, 2.0, 0.5282786477449464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 624329.4816665682, 624329.4816665687, 147186.9939813909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 89.83333333333333, 1.0, 2.0, 0.5395357577532224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634859.4340804506, 634859.4340804506, 148904.8401706192], 
processed observation next is [0.0, 0.391304347826087, 0.4320987654320985, 0.8983333333333333, 1.0, 1.0, 0.4518282830395504, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2267355121715895, 0.2267355121715895, 0.2863554618665754], 
reward next is 0.7136, 
noisyNet noise sample is [array([-0.78948784], dtype=float32), -1.3829308]. 
=============================================
[2019-03-23 23:04:35,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4894843e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:35,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-23 23:04:35,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 51.0, 1.0, 2.0, 0.375903222366292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469046.4326446087, 469046.4326446087, 125344.1401790569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2509200.0000, 
sim time next is 2509800.0000, 
raw observation next is [25.9, 51.5, 1.0, 2.0, 0.3746791517032829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467539.0742093048, 467539.0742093048, 125177.2434157752], 
processed observation next is [1.0, 0.043478260869565216, 0.5148148148148147, 0.515, 1.0, 1.0, 0.25557041869438446, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16697824078903745, 0.16697824078903745, 0.24072546810726], 
reward next is 0.7593, 
noisyNet noise sample is [array([-0.06497917], dtype=float32), 0.25117472]. 
=============================================
[2019-03-23 23:04:38,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4142568e-21 1.0000000e+00 5.8050370e-34 3.8303231e-37 2.3049632e-36], sum to 1.0000
[2019-03-23 23:04:38,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5334
[2019-03-23 23:04:38,203] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 48.5, 1.0, 2.0, 0.4988310243676123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595027.4291742184, 595027.4291742188, 142714.0227687861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2575800.0000, 
sim time next is 2576400.0000, 
raw observation next is [29.76666666666667, 49.33333333333334, 1.0, 2.0, 0.5007967545478165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597275.8698285886, 597275.8698285886, 143019.2486998682], 
processed observation next is [1.0, 0.8260869565217391, 0.6580246913580248, 0.4933333333333334, 1.0, 1.0, 0.4057104220807339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21331281065306734, 0.21331281065306734, 0.2750370167305158], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.952049], dtype=float32), 0.4686316]. 
=============================================
[2019-03-23 23:04:38,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1746914e-21 1.0000000e+00 2.5088020e-34 9.4072982e-37 1.7340334e-36], sum to 1.0000
[2019-03-23 23:04:38,372] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2111
[2019-03-23 23:04:38,376] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 54.0, 1.0, 2.0, 0.5066427734368697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604558.1784963744, 604558.1784963744, 143952.9597990683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2579400.0000, 
sim time next is 2580000.0000, 
raw observation next is [28.46666666666667, 55.0, 1.0, 2.0, 0.5103956717043563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609260.3224403311, 609260.3224403306, 144556.5398570107], 
processed observation next is [1.0, 0.8695652173913043, 0.6098765432098766, 0.55, 1.0, 1.0, 0.41713770440994796, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21759297230011826, 0.2175929723001181, 0.27799334587886676], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.0385942], dtype=float32), 0.039563343]. 
=============================================
[2019-03-23 23:04:38,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.148033]
 [50.148033]
 [50.148033]
 [50.148033]
 [50.148033]], R is [[50.36856461]
 [50.58804703]
 [50.80654907]
 [51.02286148]
 [51.23685074]].
[2019-03-23 23:04:38,897] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.340609e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:04:38,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6568
[2019-03-23 23:04:38,914] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 62.83333333333334, 1.0, 2.0, 0.5007565331675203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598890.2063113574, 598890.2063113574, 143073.6060343808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584200.0000, 
sim time next is 2584800.0000, 
raw observation next is [26.6, 64.0, 1.0, 2.0, 0.5013315521229745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599791.3945577956, 599791.3945577956, 143171.8190985648], 
processed observation next is [1.0, 0.9565217391304348, 0.5407407407407407, 0.64, 1.0, 1.0, 0.40634708586068397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21421121234206986, 0.21421121234206986, 0.27533042134339386], 
reward next is 0.7247, 
noisyNet noise sample is [array([-2.1369236], dtype=float32), -0.2675266]. 
=============================================
[2019-03-23 23:04:42,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.154874e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:04:42,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2468
[2019-03-23 23:04:42,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 92.0, 1.0, 2.0, 0.5673444495582289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665466.048663016, 665466.048663016, 153425.929866243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3277800.0000, 
sim time next is 3278400.0000, 
raw observation next is [23.2, 91.33333333333334, 1.0, 2.0, 0.5528875727123698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652160.8176600632, 652160.8176600632, 151166.1400406913], 
processed observation next is [0.0, 0.9565217391304348, 0.4148148148148148, 0.9133333333333334, 1.0, 1.0, 0.46772330084805924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23291457773573684, 0.23291457773573684, 0.2907041154628679], 
reward next is 0.7093, 
noisyNet noise sample is [array([-1.1851709], dtype=float32), -0.54333586]. 
=============================================
[2019-03-23 23:04:46,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.662044e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:04:46,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1499
[2019-03-23 23:04:46,158] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 98.83333333333334, 1.0, 2.0, 0.5207624790511927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619200.6196697124, 619200.6196697124, 146122.6778618797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2693400.0000, 
sim time next is 2694000.0000, 
raw observation next is [21.73333333333333, 97.66666666666667, 1.0, 2.0, 0.508563474014928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 607734.6242354274, 607734.6242354269, 144289.4023234086], 
processed observation next is [0.0, 0.17391304347826086, 0.3604938271604937, 0.9766666666666667, 1.0, 1.0, 0.414956516684438, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2170480800840812, 0.21704808008408102, 0.27747961985270886], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.10696661], dtype=float32), 0.6007705]. 
=============================================
[2019-03-23 23:04:46,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.65746]
 [68.65746]
 [68.65746]
 [68.65746]
 [68.65746]], R is [[68.69339752]
 [68.72545624]
 [68.7542572 ]
 [68.78182983]
 [68.80831909]].
[2019-03-23 23:04:48,638] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2593296e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:48,645] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4267
[2019-03-23 23:04:48,651] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 90.66666666666667, 1.0, 2.0, 0.6649332718305613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757816.0707735464, 757816.0707735464, 169609.8991987137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2762400.0000, 
sim time next is 2763000.0000, 
raw observation next is [25.25, 91.5, 1.0, 2.0, 0.667561648879245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 760813.0855881756, 760813.0855881751, 170092.173662014], 
processed observation next is [0.0, 1.0, 0.49074074074074076, 0.915, 1.0, 1.0, 0.6042400581895773, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27171895913863414, 0.271718959138634, 0.3271003339654115], 
reward next is 0.6729, 
noisyNet noise sample is [array([0.83866906], dtype=float32), 1.1272422]. 
=============================================
[2019-03-23 23:04:48,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.67984]
 [65.67984]
 [65.67984]
 [65.67984]
 [65.67984]], R is [[65.69593811]
 [65.7128067 ]
 [65.73077393]
 [65.74947357]
 [65.76842499]].
[2019-03-23 23:04:51,621] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1215142e-18 1.0000000e+00 2.3896506e-30 1.4816961e-32 6.6458736e-32], sum to 1.0000
[2019-03-23 23:04:51,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4466
[2019-03-23 23:04:51,637] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 85.33333333333333, 1.0, 2.0, 0.6721665693800213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766063.8882530314, 766063.8882530314, 170940.6611769492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3444000.0000, 
sim time next is 3444600.0000, 
raw observation next is [26.15, 87.16666666666667, 1.0, 2.0, 0.6781675950849908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772906.6666101961, 772906.6666101961, 172051.2675279593], 
processed observation next is [1.0, 0.8695652173913043, 0.524074074074074, 0.8716666666666667, 1.0, 1.0, 0.616866184624989, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27603809521792716, 0.27603809521792716, 0.3308678221691525], 
reward next is 0.6691, 
noisyNet noise sample is [array([-1.099004], dtype=float32), 1.7477423]. 
=============================================
[2019-03-23 23:04:52,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7663356e-18 1.0000000e+00 8.5357584e-30 1.0797822e-30 4.4201538e-32], sum to 1.0000
[2019-03-23 23:04:52,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5023
[2019-03-23 23:04:52,721] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.15, 58.33333333333334, 1.0, 2.0, 0.6660530607211025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759092.9119825382, 759092.9119825382, 169816.9274113612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6690302060352583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935529, 170363.6604325452], 
processed observation next is [1.0, 0.8260869565217391, 0.7037037037037037, 0.59, 1.0, 1.0, 0.6059883405181646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27231700621198335, 0.2723170062119832, 0.3276224239087408], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.3275716], dtype=float32), -0.9368036]. 
=============================================
[2019-03-23 23:04:53,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8936859e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:53,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-23 23:04:53,977] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 92.5, 1.0, 2.0, 0.5289554795365603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627987.1611233429, 627987.1611233429, 147408.0251452324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2856600.0000, 
sim time next is 2857200.0000, 
raw observation next is [22.66666666666667, 92.0, 1.0, 2.0, 0.5222750799583226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621748.3819943088, 621748.3819943093, 146394.3492373932], 
processed observation next is [1.0, 0.043478260869565216, 0.39506172839506193, 0.92, 1.0, 1.0, 0.4312798570932411, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.222052993569396, 0.22205299356939617, 0.28152759468729466], 
reward next is 0.7185, 
noisyNet noise sample is [array([-1.3770853], dtype=float32), 0.1818696]. 
=============================================
[2019-03-23 23:04:55,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6893355e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:04:55,539] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2628
[2019-03-23 23:04:55,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1363065.379113942 W.
[2019-03-23 23:04:55,553] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.41666666666666, 84.83333333333333, 1.0, 2.0, 0.5932185774108526, 1.0, 1.0, 0.5932185774108526, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1363065.379113942, 1363065.379113941, 266227.5270374805], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [24.53333333333333, 85.66666666666667, 1.0, 2.0, 0.4289205927522602, 1.0, 2.0, 0.4289205927522602, 1.0, 1.0, 0.6828555526300797, 6.911200000000001, 6.9112, 121.94756008, 1467184.495298696, 1467184.495298695, 309982.5952101913], 
processed observation next is [1.0, 0.4782608695652174, 0.46419753086419746, 0.8566666666666667, 1.0, 1.0, 0.3201435628003098, 1.0, 1.0, 0.3201435628003098, 1.0, 0.5, 0.6035694407875996, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5239944626066771, 0.5239944626066768, 0.5961203754042141], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33572745], dtype=float32), -0.8586646]. 
=============================================
[2019-03-23 23:04:55,573] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.032578]
 [62.032578]
 [62.032578]
 [62.032578]
 [62.032578]], R is [[61.41224289]
 [61.28614807]
 [61.13332367]
 [60.52199173]
 [59.91677094]].
[2019-03-23 23:04:56,024] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6524510e-20 1.0000000e+00 5.4883648e-35 1.0200780e-36 2.9461237e-37], sum to 1.0000
[2019-03-23 23:04:56,028] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-23 23:04:56,031] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6751724573973988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769491.3989250066, 769491.3989250066, 171498.1310926753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2916600.0000, 
sim time next is 2917200.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6881961344592514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784342.0267900283, 784342.0267900283, 173921.7283386575], 
processed observation next is [1.0, 0.782608695652174, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.6288049219752994, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2801221524250101, 0.2801221524250101, 0.334464862189726], 
reward next is 0.6655, 
noisyNet noise sample is [array([-1.0390828], dtype=float32), -0.54315]. 
=============================================
[2019-03-23 23:04:56,460] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:04:56,462] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:04:56,462] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:04:56,462] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:56,463] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:04:56,463] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:56,464] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:04:56,464] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:04:56,466] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:56,465] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:56,467] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:56,492] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 23:04:56,520] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 23:04:56,547] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 23:04:56,547] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 23:04:56,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 23:05:10,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:05:10,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.5, 33.5, 1.0, 2.0, 0.2259672153165201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 291472.3756433039, 291472.3756433039, 80151.72498384428]
[2019-03-23 23:05:10,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:05:10,843] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.8916539240638851
[2019-03-23 23:05:46,148] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:05:46,149] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.96901579, 75.21909004, 1.0, 2.0, 0.6356505126792087, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260425107478, 1439357.968666245, 1439357.968666245, 305919.3778926249]
[2019-03-23 23:05:46,150] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:05:46,154] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.719743776167224
[2019-03-23 23:05:46,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1439357.968666245 W.
[2019-03-23 23:05:50,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:05:50,388] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.93832478333333, 67.99073498333334, 1.0, 2.0, 0.6577210405470125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749592.3626080214, 749592.3626080214, 168293.3694911859]
[2019-03-23 23:05:50,390] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:05:50,395] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.0796137497252698
[2019-03-23 23:05:51,522] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:05:51,524] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 72.0, 1.0, 2.0, 0.7516804673075069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856736.0101121458, 856736.0101121458, 186163.5590033977]
[2019-03-23 23:05:51,526] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:05:51,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.4794517858878784
[2019-03-23 23:06:03,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:06:03,023] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.53929430333333, 90.0614279, 1.0, 2.0, 0.6144159049320573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724530.80534593, 724530.80534593, 161693.6359418849]
[2019-03-23 23:06:03,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:06:03,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.4042338399369396
[2019-03-23 23:06:39,837] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:06:39,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:06:39,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.81136864]
[2019-03-23 23:06:39,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.4, 80.66666666666667, 1.0, 2.0, 0.3771359116196927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469164.0227154521, 469164.0227154521, 125484.9475957839]
[2019-03-23 23:06:39,946] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:06:39,947] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8537245e-19 1.0000000e+00 6.6457504e-31 7.9856189e-34 2.0607039e-33], sampled 0.3238626229943067
[2019-03-23 23:06:39,959] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:06:40,091] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:06:40,125] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:06:41,139] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1775000, evaluation results [1775000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:06:45,051] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7901486e-21 1.0000000e+00 2.2169511e-34 2.2531570e-37 2.7646726e-37], sum to 1.0000
[2019-03-23 23:06:45,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5393
[2019-03-23 23:06:45,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2227416.352146637 W.
[2019-03-23 23:06:45,070] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 71.66666666666666, 1.0, 2.0, 0.6750408584482863, 1.0, 2.0, 0.6508850912005779, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2227416.352146637, 2227416.352146637, 422600.4679413808], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2986800.0000, 
sim time next is 2987400.0000, 
raw observation next is [30.0, 69.83333333333334, 1.0, 2.0, 0.9510693170178313, 1.0, 2.0, 0.9510693170178313, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2169721.898277042, 2169721.898277042, 410133.6093426334], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.6983333333333335, 1.0, 1.0, 0.9417491869259896, 1.0, 1.0, 0.9417491869259896, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7749006779560864, 0.7749006779560864, 0.7887184795050642], 
reward next is 0.2113, 
noisyNet noise sample is [array([0.45020932], dtype=float32), 0.063830025]. 
=============================================
[2019-03-23 23:06:49,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2376833e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:06:49,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-23 23:06:49,127] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 78.16666666666666, 1.0, 2.0, 0.6570224859552536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748795.8441557282, 748795.8441557282, 168165.6709499928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3333000.0000, 
sim time next is 3333600.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.6563930315369608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748078.117052158, 748078.117052158, 168051.2031212042], 
processed observation next is [0.0, 0.6086956521739131, 0.5592592592592593, 0.78, 1.0, 1.0, 0.5909440851630486, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2671707560900564, 0.2671707560900564, 0.32317539061770034], 
reward next is 0.6768, 
noisyNet noise sample is [array([1.2543254], dtype=float32), -0.0670062]. 
=============================================
[2019-03-23 23:06:49,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6471789e-21 1.0000000e+00 7.8519487e-35 2.1716395e-37 2.5070283e-37], sum to 1.0000
[2019-03-23 23:06:49,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-23 23:06:49,621] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 89.83333333333333, 1.0, 2.0, 0.7226846454459286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823669.9478925539, 823669.9478925539, 180485.4404705233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3696600.0000, 
sim time next is 3697200.0000, 
raw observation next is [26.6, 90.0, 1.0, 2.0, 0.7221030726120632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823006.7523304786, 823006.7523304786, 180372.8575266687], 
processed observation next is [1.0, 0.8260869565217391, 0.5407407407407407, 0.9, 1.0, 1.0, 0.6691703245381705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29393098297517095, 0.29393098297517095, 0.34687087985897824], 
reward next is 0.6531, 
noisyNet noise sample is [array([-1.5266992], dtype=float32), 0.2667249]. 
=============================================
[2019-03-23 23:06:55,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9703255e-22 1.0000000e+00 1.4496036e-34 2.5128006e-38 1.1767290e-38], sum to 1.0000
[2019-03-23 23:06:55,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9371
[2019-03-23 23:06:55,559] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 55.33333333333334, 1.0, 2.0, 0.5508126531099784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647666.2521731247, 647666.2521731247, 150738.7141848776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3187200.0000, 
sim time next is 3187800.0000, 
raw observation next is [29.0, 57.0, 1.0, 2.0, 0.5500750789812728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646643.6022451231, 646643.6022451231, 150610.3799314334], 
processed observation next is [1.0, 0.9130434782608695, 0.6296296296296297, 0.57, 1.0, 1.0, 0.4643750940253248, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23094414365897253, 0.23094414365897253, 0.28963534602198726], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.47988796], dtype=float32), -0.81744593]. 
=============================================
[2019-03-23 23:06:57,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1587327e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:06:57,251] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-23 23:06:57,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1861964.471158653 W.
[2019-03-23 23:06:57,265] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5442056671616026, 1.0, 2.0, 0.5442056671616026, 1.0, 1.0, 0.8663931456625059, 6.9112, 6.9112, 121.94756008, 1861964.471158653, 1861964.471158653, 365815.1251234877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5533652268258419, 1.0, 2.0, 0.5533652268258419, 1.0, 2.0, 0.8809754629540074, 6.911200000000001, 6.9112, 121.94756008, 1893336.522617778, 1893336.522617777, 370552.6838975576], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.89, 1.0, 1.0, 0.4682919366974308, 1.0, 1.0, 0.4682919366974308, 1.0, 1.0, 0.8512193286925093, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.676191615220635, 0.6761916152206346, 0.7126013151876108], 
reward next is 0.2874, 
noisyNet noise sample is [array([-0.81127733], dtype=float32), 0.687264]. 
=============================================
[2019-03-23 23:06:59,578] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7913976e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:06:59,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-23 23:06:59,595] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 50.33333333333334, 1.0, 2.0, 0.5957467955115648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683918.319568973, 683918.319568973, 157592.987372483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3255600.0000, 
sim time next is 3256200.0000, 
raw observation next is [31.25, 53.5, 1.0, 2.0, 0.6067629961695977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694452.6567581544, 694452.6567581544, 159391.6389475257], 
processed observation next is [0.0, 0.6956521739130435, 0.7129629629629629, 0.535, 1.0, 1.0, 0.5318607097257115, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24801880598505513, 0.24801880598505513, 0.3065223825913956], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.24999008], dtype=float32), -0.8770342]. 
=============================================
[2019-03-23 23:07:00,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.733942e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:07:00,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0940
[2019-03-23 23:07:00,735] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 92.66666666666667, 1.0, 2.0, 0.5361189403161418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634960.381396709, 634960.381396709, 148513.4950350495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3282000.0000, 
sim time next is 3282600.0000, 
raw observation next is [22.96666666666667, 93.33333333333334, 1.0, 2.0, 0.5418473262755364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 640300.9767796063, 640300.9767796058, 149393.3834556077], 
processed observation next is [0.0, 1.0, 0.4061728395061729, 0.9333333333333335, 1.0, 1.0, 0.45458015032801957, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22867892027843081, 0.22867892027843065, 0.28729496818386097], 
reward next is 0.7127, 
noisyNet noise sample is [array([0.06024009], dtype=float32), -0.7007592]. 
=============================================
[2019-03-23 23:07:14,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0164593e-21 1.0000000e+00 2.9263812e-34 7.2762775e-37 1.0175985e-36], sum to 1.0000
[2019-03-23 23:07:14,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4095
[2019-03-23 23:07:14,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.55, 85.5, 1.0, 2.0, 0.4596795471343116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 557635.6775241789, 557635.6775241784, 137022.0342737676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3540600.0000, 
sim time next is 3541200.0000, 
raw observation next is [22.7, 86.66666666666666, 1.0, 2.0, 0.4710333664386297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568559.370255031, 568559.370255031, 138653.7074414325], 
processed observation next is [1.0, 1.0, 0.39629629629629626, 0.8666666666666666, 1.0, 1.0, 0.37027781718884484, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20305691794822536, 0.20305691794822536, 0.26664174507967786], 
reward next is 0.7334, 
noisyNet noise sample is [array([0.09080134], dtype=float32), -0.16240199]. 
=============================================
[2019-03-23 23:07:19,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.880593e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:07:19,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6305
[2019-03-23 23:07:19,528] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7365721423684509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839506.7011383262, 839506.7011383262, 183184.8507221237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3902400.0000, 
sim time next is 3903000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.7306647913521597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832770.1512549352, 832770.1512549352, 182031.6845773126], 
processed observation next is [0.0, 0.17391304347826086, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.6793628468478091, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29741791116247684, 0.29741791116247684, 0.3500609318794473], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.552973], dtype=float32), 0.5855245]. 
=============================================
[2019-03-23 23:07:19,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.93368]
 [67.93368]
 [67.93368]
 [67.93368]
 [67.93368]], R is [[67.90428162]
 [67.87296295]
 [67.84057617]
 [67.80721283]
 [67.7731781 ]].
[2019-03-23 23:07:22,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6547640e-22 1.0000000e+00 3.3892238e-36 1.9063510e-38 4.0709060e-38], sum to 1.0000
[2019-03-23 23:07:22,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-23 23:07:22,195] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1745618.411793723 W.
[2019-03-23 23:07:22,199] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.93333333333333, 85.66666666666667, 1.0, 2.0, 0.9039718488862353, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1745618.411793723, 1745618.411793723, 357827.0484361718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3688800.0000, 
sim time next is 3689400.0000, 
raw observation next is [26.91666666666667, 84.83333333333333, 1.0, 2.0, 0.889471219534136, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1729065.825478979, 1729065.82547898, 354702.8849536823], 
processed observation next is [1.0, 0.6956521739130435, 0.5524691358024693, 0.8483333333333333, 1.0, 1.0, 0.8684181184930191, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6175235090996354, 0.6175235090996357, 0.6821209326032353], 
reward next is 0.3179, 
noisyNet noise sample is [array([-0.01007321], dtype=float32), 0.23185]. 
=============================================
[2019-03-23 23:07:22,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4845184e-22 1.0000000e+00 1.6860345e-33 1.0586759e-36 5.0342116e-37], sum to 1.0000
[2019-03-23 23:07:22,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8461
[2019-03-23 23:07:22,510] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.15, 76.0, 1.0, 2.0, 0.7691149365758765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876618.5008408854, 876618.5008408854, 189645.1020437579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3958200.0000, 
sim time next is 3958800.0000, 
raw observation next is [29.2, 75.0, 1.0, 2.0, 0.7673327315892439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 874586.0279146407, 874586.0279146407, 189286.0553163248], 
processed observation next is [0.0, 0.8260869565217391, 0.637037037037037, 0.75, 1.0, 1.0, 0.7230151566538617, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3123521528266574, 0.3123521528266574, 0.36401164483908616], 
reward next is 0.6360, 
noisyNet noise sample is [array([-0.1372462], dtype=float32), -0.49297515]. 
=============================================
[2019-03-23 23:07:23,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4316906e-23 1.0000000e+00 7.6639419e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:07:23,280] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5458
[2019-03-23 23:07:23,289] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 94.0, 1.0, 2.0, 0.6722157191625018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766119.9319354702, 766119.9319354702, 170949.3738746103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3709200.0000, 
sim time next is 3709800.0000, 
raw observation next is [25.05, 94.0, 1.0, 2.0, 0.6605747577007183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752846.2877885294, 752846.2877885294, 168813.8150085364], 
processed observation next is [1.0, 0.9565217391304348, 0.48333333333333334, 0.94, 1.0, 1.0, 0.5959223305960931, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2688736742101891, 0.2688736742101891, 0.3246419519394931], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.2558088], dtype=float32), -0.05240901]. 
=============================================
[2019-03-23 23:07:25,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8483954e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:07:25,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0933
[2019-03-23 23:07:25,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1626295.659814325 W.
[2019-03-23 23:07:25,747] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 94.0, 1.0, 2.0, 0.4753881980423909, 1.0, 2.0, 0.4753881980423909, 1.0, 2.0, 0.75683349359622, 6.9112, 6.9112, 121.94756008, 1626295.659814325, 1626295.659814325, 331673.599736602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.7506644089309884, 1.0, 2.0, 0.7506644089309884, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1712089.948334917, 1712089.948334917, 323790.8810350903], 
processed observation next is [1.0, 0.391304347826087, 0.5370370370370371, 0.94, 1.0, 1.0, 0.7031719153940338, 1.0, 1.0, 0.7031719153940338, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.611460695833899, 0.611460695833899, 0.6226747712213275], 
reward next is 0.3773, 
noisyNet noise sample is [array([-1.8189489], dtype=float32), 0.10955794]. 
=============================================
[2019-03-23 23:07:29,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.105429e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:07:29,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-23 23:07:29,518] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.6263506300250398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714206.8510819931, 714206.8510819931, 162688.3900677504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834600.0000, 
sim time next is 3835200.0000, 
raw observation next is [30.33333333333334, 60.33333333333334, 1.0, 2.0, 0.6361725441720472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725022.3303932924, 725022.3303932924, 164412.3876616361], 
processed observation next is [0.0, 0.391304347826087, 0.6790123456790126, 0.6033333333333334, 1.0, 1.0, 0.5668720763952942, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.258936546569033, 0.258936546569033, 0.31617766858006946], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.03372736], dtype=float32), -2.2125869]. 
=============================================
[2019-03-23 23:07:29,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9044283e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:07:29,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6221
[2019-03-23 23:07:29,559] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 78.0, 1.0, 2.0, 0.6209268158451215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 714393.9298166349, 714393.9298166345, 162046.3548421381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3807000.0000, 
sim time next is 3807600.0000, 
raw observation next is [26.46666666666667, 76.0, 1.0, 2.0, 0.6062511974745713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700317.9445604827, 700317.9445604827, 159612.3821746621], 
processed observation next is [0.0, 0.043478260869565216, 0.5358024691358025, 0.76, 1.0, 1.0, 0.5312514255649659, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2501135516287438, 0.2501135516287438, 0.30694688879742715], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.3959859], dtype=float32), -0.44894904]. 
=============================================
[2019-03-23 23:07:30,561] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9237392e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:07:30,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6179
[2019-03-23 23:07:30,576] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.46666666666667, 57.00000000000001, 1.0, 2.0, 0.6678189946350281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761106.5254880466, 761106.5254880466, 170141.1686405479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3838800.0000, 
sim time next is 3839400.0000, 
raw observation next is [31.7, 54.0, 1.0, 2.0, 0.6633544376759383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756015.8060258911, 756015.8060258911, 169320.9014074612], 
processed observation next is [0.0, 0.43478260869565216, 0.7296296296296296, 0.54, 1.0, 1.0, 0.5992314734237361, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27000564500924684, 0.27000564500924684, 0.32561711809127153], 
reward next is 0.6744, 
noisyNet noise sample is [array([-0.20426229], dtype=float32), 0.21165358]. 
=============================================
[2019-03-23 23:07:31,058] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 23:07:31,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:07:31,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:07:31,064] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:07:31,065] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:07:31,067] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:07:31,068] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:07:31,068] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:07:31,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:07:31,070] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:07:31,073] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:07:31,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 23:07:31,129] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 23:07:31,154] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 23:07:31,155] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 23:07:31,180] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 23:07:41,628] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:07:41,629] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.56666666666667, 49.66666666666667, 1.0, 2.0, 0.2611515744176906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 336865.9922022574, 336865.9922022574, 110246.1809804216]
[2019-03-23 23:07:41,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:07:41,633] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9938605229059317
[2019-03-23 23:07:46,638] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:07:46,639] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.18020155666667, 48.91030534833333, 1.0, 2.0, 0.2536504309006742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 326879.5119895163, 326879.5119895159, 104169.0355358947]
[2019-03-23 23:07:46,643] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:07:46,645] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.244851841311034
[2019-03-23 23:07:47,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:07:47,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.11639470666667, 83.49065093, 1.0, 2.0, 0.267051333139859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 343131.6058203356, 343131.6058203356, 111598.6794150221]
[2019-03-23 23:07:47,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:07:47,730] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8018650323401608
[2019-03-23 23:08:12,032] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:08:12,032] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.9884797788115639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.073681400301303, 6.9112, 121.9252063872968, 1210094.673689091, 1126890.244972591, 237953.7690704281]
[2019-03-23 23:08:12,033] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:08:12,036] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5475705660742962
[2019-03-23 23:08:23,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:08:23,470] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 97.0, 1.0, 2.0, 0.736522942016139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839450.5944212601, 839450.5944212601, 183170.4996122172]
[2019-03-23 23:08:23,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:08:23,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.33260393519641107
[2019-03-23 23:08:51,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:08:51,869] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.763777845, 64.00207096833333, 1.0, 2.0, 0.618725147821667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740103.6847895281, 740103.6847895281, 162870.1569672143]
[2019-03-23 23:08:51,870] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:08:51,873] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.968181449597365
[2019-03-23 23:09:01,288] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:09:01,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.18333333333333, 87.16666666666667, 1.0, 2.0, 0.5544703343507215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649789.3183348689, 649789.3183348689, 151253.0140566503]
[2019-03-23 23:09:01,290] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:09:01,295] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.49738860527770856
[2019-03-23 23:09:02,893] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:09:02,893] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.61504160333333, 58.07392316166666, 1.0, 2.0, 0.4653341504831245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564816.543869073, 564816.543869073, 137886.3247385983]
[2019-03-23 23:09:02,895] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:09:02,897] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.43792926250531583
[2019-03-23 23:09:04,970] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:09:04,971] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.86713637, 88.32097152, 1.0, 2.0, 0.5104144419648003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602760.82027681, 602760.82027681, 144310.4788902279]
[2019-03-23 23:09:04,972] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:09:04,973] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3969880010893658
[2019-03-23 23:09:10,384] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.89010423]
[2019-03-23 23:09:10,385] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 62.66666666666667, 1.0, 2.0, 0.3431479426226583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432184.8696840663, 432184.8696840663, 121024.8369869993]
[2019-03-23 23:09:10,386] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:09:10,388] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.051324e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9020353329397324
[2019-03-23 23:09:14,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:09:14,770] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:09:14,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:09:14,915] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:09:14,980] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:09:15,995] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1800000, evaluation results [1800000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:09:22,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1970277e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:22,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4461
[2019-03-23 23:09:22,727] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 96.0, 1.0, 2.0, 0.5525970020150659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664749.9994434472, 664749.9994434472, 151606.2506700605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4602600.0000, 
sim time next is 4603200.0000, 
raw observation next is [21.86666666666667, 94.66666666666666, 1.0, 2.0, 0.5166979839057189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620958.3121919427, 620958.3121919427, 145711.2953111999], 
processed observation next is [1.0, 0.2608695652173913, 0.36543209876543226, 0.9466666666666665, 1.0, 1.0, 0.42464045703061765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2217708257828367, 0.2217708257828367, 0.2802140294446152], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.5222935], dtype=float32), -1.9475075]. 
=============================================
[2019-03-23 23:09:23,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1946737e-23 1.0000000e+00 1.8641601e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:23,784] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-23 23:09:23,790] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 88.66666666666667, 1.0, 2.0, 0.3565379234420707, 1.0, 2.0, 0.3565379234420707, 1.0, 1.0, 0.5676199857492931, 6.9112, 6.9112, 121.94756008, 1219392.123592425, 1219392.123592425, 278567.1728978973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3984600.0000, 
sim time next is 3985200.0000, 
raw observation next is [25.2, 89.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.529248496553415, 6.9112, 121.92361267107, 1479518.174146507, 1163028.411022501, 245580.2871809829], 
processed observation next is [1.0, 0.13043478260869565, 0.4888888888888889, 0.89, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.06180484965534152, 0.0, 0.8094459965150107, 0.5283993479094667, 0.41536728965089326, 0.4722697830403517], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0092133], dtype=float32), -0.48721898]. 
=============================================
[2019-03-23 23:09:29,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2543032e-21 1.0000000e+00 5.1760208e-35 1.1090972e-37 1.8829855e-37], sum to 1.0000
[2019-03-23 23:09:29,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2620
[2019-03-23 23:09:29,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1994999.798216191 W.
[2019-03-23 23:09:29,940] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.5830451953531931, 1.0, 2.0, 0.5830451953531931, 1.0, 1.0, 0.928226939458643, 6.9112, 6.9112, 121.94756008, 1994999.798216191, 1994999.798216191, 386215.15680661], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4118400.0000, 
sim time next is 4119000.0000, 
raw observation next is [29.03333333333333, 69.33333333333334, 1.0, 2.0, 0.6351593860092722, 1.0, 2.0, 0.6309443549810709, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2159093.974066848, 2159093.974066847, 412270.7681505967], 
processed observation next is [1.0, 0.6956521739130435, 0.6308641975308641, 0.6933333333333335, 1.0, 1.0, 0.5656659357253241, 1.0, 1.0, 0.5606480416441321, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.77110499073816, 0.7711049907381596, 0.7928284002896091], 
reward next is 0.2072, 
noisyNet noise sample is [array([0.24056862], dtype=float32), 0.69221103]. 
=============================================
[2019-03-23 23:09:29,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.015396]
 [53.015396]
 [53.015396]
 [53.015396]
 [53.015396]], R is [[52.69241333]
 [52.1654892 ]
 [51.64383316]
 [51.37861633]
 [51.1359787 ]].
[2019-03-23 23:09:32,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4453734e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:32,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0832
[2019-03-23 23:09:32,647] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 99.00000000000001, 1.0, 2.0, 0.4550666236471802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556863.2356760966, 556863.2356760966, 136470.5677476217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4169400.0000, 
sim time next is 4170000.0000, 
raw observation next is [20.66666666666667, 98.0, 1.0, 2.0, 0.4455702109876105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543338.7417447862, 543338.7417447862, 134997.4503779067], 
processed observation next is [1.0, 0.2608695652173913, 0.3209876543209878, 0.98, 1.0, 1.0, 0.3399645368900125, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19404955062313792, 0.19404955062313792, 0.25961048149597443], 
reward next is 0.7404, 
noisyNet noise sample is [array([1.1469564], dtype=float32), 0.80407184]. 
=============================================
[2019-03-23 23:09:32,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.759735]
 [73.759735]
 [73.759735]
 [73.759735]
 [73.759735]], R is [[73.76252747]
 [73.7624588 ]
 [73.77283478]
 [73.78378296]
 [73.79514313]].
[2019-03-23 23:09:35,810] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7805147e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:35,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0701
[2019-03-23 23:09:35,823] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 60.16666666666667, 1.0, 2.0, 0.6482728068548976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738819.1981456872, 738819.1981456872, 166584.3366366456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4385400.0000, 
sim time next is 4386000.0000, 
raw observation next is [31.0, 61.33333333333334, 1.0, 2.0, 0.657978958631706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749886.4508041452, 749886.4508041452, 168343.7523593812], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6133333333333334, 1.0, 1.0, 0.5928320936091738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.267816589572909, 0.267816589572909, 0.32373798530650233], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.84382766], dtype=float32), -0.20861399]. 
=============================================
[2019-03-23 23:09:35,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.99731]
 [65.99731]
 [65.99731]
 [65.99731]
 [65.99731]], R is [[66.01359558]
 [66.03310394]
 [66.05712891]
 [66.08354187]
 [66.11184692]].
[2019-03-23 23:09:40,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6916712e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:40,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1512
[2019-03-23 23:09:40,542] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 83.83333333333333, 1.0, 2.0, 0.629039042969281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718316.1266784486, 718316.1266784486, 163215.4566752736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320600.0000, 
sim time next is 4321200.0000, 
raw observation next is [25.66666666666667, 83.66666666666667, 1.0, 2.0, 0.6210189390997047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712043.2314131403, 712043.2314131403, 161943.3405617178], 
processed observation next is [1.0, 0.0, 0.506172839506173, 0.8366666666666667, 1.0, 1.0, 0.5488320703567914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2543011540761215, 0.2543011540761215, 0.31142950108022655], 
reward next is 0.6886, 
noisyNet noise sample is [array([2.4477305], dtype=float32), -1.0236253]. 
=============================================
[2019-03-23 23:09:47,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7479158e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:47,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4035
[2019-03-23 23:09:47,139] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 99.66666666666666, 1.0, 2.0, 0.4839474435163825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582815.624805106, 582815.624805106, 140593.5783564216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4599600.0000, 
sim time next is 4600200.0000, 
raw observation next is [21.06666666666667, 99.83333333333334, 1.0, 2.0, 0.4796460240427888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578124.1239498281, 578124.1239498281, 139946.0620563609], 
processed observation next is [1.0, 0.21739130434782608, 0.3358024691358026, 0.9983333333333334, 1.0, 1.0, 0.38053098100331995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2064729014106529, 0.2064729014106529, 0.26912704241607865], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.3533921], dtype=float32), -1.2507238]. 
=============================================
[2019-03-23 23:09:47,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0642944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:47,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0906
[2019-03-23 23:09:47,158] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4971350863131743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596799.5503907937, 596799.5503907937, 142584.3235940139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408200.0000, 
sim time next is 4408800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4971854405220825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596859.4299680429, 596859.4299680424, 142592.2053055023], 
processed observation next is [0.0, 0.0, 0.37037037037037035, 0.94, 1.0, 1.0, 0.40141123871676493, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2131640821314439, 0.21316408213144372, 0.27421577943365827], 
reward next is 0.7258, 
noisyNet noise sample is [array([2.1312659], dtype=float32), 0.34702045]. 
=============================================
[2019-03-23 23:09:59,581] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.667432e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:09:59,590] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5674
[2019-03-23 23:09:59,594] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 89.0, 1.0, 2.0, 0.6742998717215981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768496.4179262482, 768496.4179262482, 171333.7039570647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662000.0000, 
sim time next is 4662600.0000, 
raw observation next is [25.5, 89.83333333333334, 1.0, 2.0, 0.6689259112879898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762368.6945120457, 762368.6945120452, 170343.0084551845], 
processed observation next is [1.0, 1.0, 0.5, 0.8983333333333334, 1.0, 1.0, 0.6058641801047497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27227453375430205, 0.2722745337543019, 0.3275827085676625], 
reward next is 0.6724, 
noisyNet noise sample is [array([1.3869289], dtype=float32), -0.77837807]. 
=============================================
[2019-03-23 23:10:00,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.737936e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:10:00,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6369
[2019-03-23 23:10:00,476] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 97.33333333333333, 1.0, 2.0, 0.7078710132406543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806777.4272089533, 806777.4272089533, 177640.6275622077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4837200.0000, 
sim time next is 4837800.0000, 
raw observation next is [25.18333333333334, 98.66666666666667, 1.0, 2.0, 0.7070792773449115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805874.5926069357, 805874.5926069357, 177489.6666104037], 
processed observation next is [1.0, 1.0, 0.4882716049382719, 0.9866666666666667, 1.0, 1.0, 0.6512848539820375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.287812354502477, 0.287812354502477, 0.34132628194308406], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.09712446], dtype=float32), 0.35673133]. 
=============================================
[2019-03-23 23:10:02,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1387617e-19 1.0000000e+00 1.7240658e-30 5.8165000e-33 3.9146651e-32], sum to 1.0000
[2019-03-23 23:10:02,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-23 23:10:02,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 76.0, 1.0, 2.0, 0.6211976482652297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711770.4260914836, 711770.4260914836, 161951.5715912486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5349600.0000, 
sim time next is 5350200.0000, 
raw observation next is [26.81666666666667, 76.5, 1.0, 2.0, 0.6209874779525661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711693.8402046094, 711693.8402046094, 161922.6856383289], 
processed observation next is [1.0, 0.9565217391304348, 0.5487654320987656, 0.765, 1.0, 1.0, 0.5487946166101978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25417637150164624, 0.25417637150164624, 0.31138978007370943], 
reward next is 0.6886, 
noisyNet noise sample is [array([-1.1210974], dtype=float32), -0.6192897]. 
=============================================
[2019-03-23 23:10:05,959] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 23:10:05,963] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:10:05,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:10:05,965] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:10:05,966] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:10:05,966] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:10:05,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:10:05,967] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:10:05,968] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:10:05,967] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:10:05,969] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:10:05,986] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 23:10:06,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 23:10:06,014] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 23:10:06,037] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 23:10:06,038] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 23:10:15,509] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:10:15,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.89455496, 64.07713506, 1.0, 2.0, 0.4523450759426885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556207.9585021525, 556207.9585021525, 136134.3103444515]
[2019-03-23 23:10:15,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:10:15,513] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8440922473737406
[2019-03-23 23:10:27,651] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:10:27,651] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.75, 41.0, 1.0, 2.0, 0.360884492902847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452540.4857838054, 452540.4857838054, 123349.2575294467]
[2019-03-23 23:10:27,653] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:10:27,657] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7802107383535958
[2019-03-23 23:10:40,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:10:40,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.40388681666667, 25.40607077333333, 1.0, 2.0, 0.7367683319367087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905090.4820573477, 905090.4820573477, 185934.8404116296]
[2019-03-23 23:10:40,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:10:40,830] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7090741904582518
[2019-03-23 23:10:57,629] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:10:57,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.16666666666667, 66.0, 1.0, 2.0, 1.018241906733818, 1.0, 2.0, 1.018241906733818, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.4905574721438, 2323151.531944939, 2323151.531944939, 442273.5085886838]
[2019-03-23 23:10:57,631] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:10:57,634] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.08213935953139595
[2019-03-23 23:10:57,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2323151.531944939 W.
[2019-03-23 23:11:05,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:11:05,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.468026065, 74.45832949333334, 1.0, 2.0, 0.531559668149165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628758.0775872563, 628758.0775872563, 147739.5252115309]
[2019-03-23 23:11:05,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:11:05,305] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.26522782668699807
[2019-03-23 23:11:37,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:11:37,823] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.20166343, 63.50991957, 1.0, 2.0, 0.3582562406272842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449558.6712815941, 449558.6712815937, 123002.1341972865]
[2019-03-23 23:11:37,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:11:37,826] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6591880925984664
[2019-03-23 23:11:48,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:11:48,998] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9171078]
[2019-03-23 23:11:48,998] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.089899815, 70.07893908166668, 1.0, 2.0, 0.6975661132170202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795026.5965033736, 795026.5965033732, 175688.475608483]
[2019-03-23 23:11:48,999] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:11:49,001] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6047253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.12977150320795183
[2019-03-23 23:11:49,192] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:11:49,252] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:11:49,297] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:11:49,410] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:11:50,424] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1825000, evaluation results [1825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:11:57,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7922588e-24 1.0000000e+00 4.0355602e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:11:57,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3327
[2019-03-23 23:11:57,453] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748876867928476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769166.6841465341, 769166.6841465341, 171442.7296825626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185800.0000, 
sim time next is 5186400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6750413076304544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769341.8530389302, 769341.8530389302, 171471.1410374106], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6131444138457791, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2747649475139036, 0.2747649475139036, 0.3297521943027127], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.58291715], dtype=float32), -1.0233768]. 
=============================================
[2019-03-23 23:11:58,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.760707e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:11:58,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4857
[2019-03-23 23:11:58,135] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 84.33333333333334, 1.0, 2.0, 0.8561951453732246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259891461126, 994880.550157246, 994880.550157246, 208812.2539332991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4936800.0000, 
sim time next is 4937400.0000, 
raw observation next is [24.7, 85.5, 1.0, 2.0, 0.8065152902156109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425993576, 938616.2622414769, 938616.2622414769, 198274.5947533857], 
processed observation next is [1.0, 0.13043478260869565, 0.4703703703703703, 0.855, 1.0, 1.0, 0.7696610597804892, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128711893, 0.3352200936576703, 0.3352200936576703, 0.3812972976026648], 
reward next is 0.6187, 
noisyNet noise sample is [array([-0.4581825], dtype=float32), -0.07641694]. 
=============================================
[2019-03-23 23:12:01,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7575952e-21 1.0000000e+00 6.0576699e-33 5.6757269e-37 2.6947955e-36], sum to 1.0000
[2019-03-23 23:12:01,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6545
[2019-03-23 23:12:01,546] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 90.0, 1.0, 2.0, 0.6875615509971854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783618.4178088874, 783618.4178088874, 173801.7087721412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5266800.0000, 
sim time next is 5267400.0000, 
raw observation next is [25.78333333333333, 89.83333333333333, 1.0, 2.0, 0.6845355985977543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780167.9648712903, 780167.9648712903, 173236.0738414295], 
processed observation next is [1.0, 1.0, 0.5104938271604937, 0.8983333333333333, 1.0, 1.0, 0.6244471411878026, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2786314160254608, 0.2786314160254608, 0.3331462958489029], 
reward next is 0.6669, 
noisyNet noise sample is [array([1.2321055], dtype=float32), -0.538572]. 
=============================================
[2019-03-23 23:12:06,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.921747e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:12:06,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9989
[2019-03-23 23:12:06,097] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 82.0, 1.0, 2.0, 0.8076347456277324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 920548.810373055, 920548.8103730537, 197529.4553938703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5083200.0000, 
sim time next is 5083800.0000, 
raw observation next is [28.66666666666666, 83.16666666666667, 1.0, 2.0, 0.7849912267545391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 894724.4730229318, 894724.4730229314, 192865.8666804119], 
processed observation next is [0.0, 0.8695652173913043, 0.6172839506172837, 0.8316666666666667, 1.0, 1.0, 0.7440371747077846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3195444546510471, 0.3195444546510469, 0.3708958974623306], 
reward next is 0.6291, 
noisyNet noise sample is [array([0.17377023], dtype=float32), -0.43069088]. 
=============================================
[2019-03-23 23:12:06,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6033484e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:12:06,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4456
[2019-03-23 23:12:06,636] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 97.0, 1.0, 2.0, 0.4928386393709086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591482.1489319628, 591482.1489319628, 141906.1239214645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5713800.0000, 
sim time next is 5714400.0000, 
raw observation next is [21.56666666666667, 97.0, 1.0, 2.0, 0.4936852323276351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 593197.7878048585, 593197.7878048581, 142062.6821886919], 
processed observation next is [0.0, 0.13043478260869565, 0.35432098765432113, 0.97, 1.0, 1.0, 0.3972443241995657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21185635278744946, 0.2118563527874493, 0.2731974657474844], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.88142025], dtype=float32), 0.37624547]. 
=============================================
[2019-03-23 23:12:13,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0694707e-19 1.0000000e+00 5.6034603e-31 6.9369905e-35 4.6349637e-34], sum to 1.0000
[2019-03-23 23:12:13,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2640
[2019-03-23 23:12:13,869] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2037858.747767877 W.
[2019-03-23 23:12:13,872] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.8933347054297545, 1.0, 2.0, 0.8933347054297545, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2037858.747767877, 2037858.747767877, 383831.697864887], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5239200.0000, 
sim time next is 5239800.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5978575940409846, 1.0, 2.0, 0.5978575940409846, 1.0, 1.0, 0.9518087605757538, 6.9112, 6.9112, 121.94756008, 2045741.275452702, 2045741.275452702, 394209.5366008832], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.74, 1.0, 1.0, 0.5212590405249816, 1.0, 1.0, 0.5212590405249816, 1.0, 0.5, 0.9397609507196921, 0.0, 0.0, 0.8096049824067558, 0.7306218840902508, 0.7306218840902508, 0.7580952626940061], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.377102], dtype=float32), -1.4697105]. 
=============================================
[2019-03-23 23:12:22,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8312026e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:12:22,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8241
[2019-03-23 23:12:22,286] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1758477.955441291 W.
[2019-03-23 23:12:22,288] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 79.33333333333334, 1.0, 2.0, 0.7709831927892987, 1.0, 2.0, 0.7709831927892987, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1758477.955441291, 1758477.955441291, 331909.9640789878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394000.0000, 
sim time next is 5394600.0000, 
raw observation next is [27.5, 78.5, 1.0, 2.0, 0.7585285550742968, 1.0, 2.0, 0.7585285550742968, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1730043.594764329, 1730043.594764329, 326915.6426525441], 
processed observation next is [1.0, 0.43478260869565216, 0.5740740740740741, 0.785, 1.0, 1.0, 0.7125339941360677, 1.0, 1.0, 0.7125339941360677, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6178727124158317, 0.6178727124158317, 0.6286839281779694], 
reward next is 0.3713, 
noisyNet noise sample is [array([1.1309593], dtype=float32), -1.1045915]. 
=============================================
[2019-03-23 23:12:30,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.453731e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:12:30,298] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2407
[2019-03-23 23:12:30,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462057.549316227 W.
[2019-03-23 23:12:30,310] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 93.0, 1.0, 2.0, 0.4274231969415151, 1.0, 1.0, 0.4274231969415151, 1.0, 1.0, 0.6804716497325966, 6.911199999999999, 6.9112, 121.94756008, 1462057.549316227, 1462057.549316228, 309303.2932392492], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5538000.0000, 
sim time next is 5538600.0000, 
raw observation next is [25.45, 93.0, 1.0, 2.0, 0.4872376018205661, 1.0, 2.0, 0.4872376018205661, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260422952314, 1110852.796190883, 1110852.796190883, 231464.4543974336], 
processed observation next is [1.0, 0.08695652173913043, 0.4981481481481481, 0.93, 1.0, 1.0, 0.38956857359591196, 1.0, 1.0, 0.38956857359591196, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621266928113, 0.39673314149674394, 0.39673314149674394, 0.4451239507642954], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02348646], dtype=float32), -0.1770266]. 
=============================================
[2019-03-23 23:12:33,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3085276e-21 1.0000000e+00 2.7149808e-34 4.3790743e-37 6.9588226e-37], sum to 1.0000
[2019-03-23 23:12:33,494] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1855
[2019-03-23 23:12:33,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1698709.484003227 W.
[2019-03-23 23:12:33,505] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 75.66666666666667, 1.0, 2.0, 0.4965356353056847, 1.0, 2.0, 0.4965356353056847, 1.0, 1.0, 0.790500902443333, 6.9112, 6.9112, 121.94756008, 1698709.484003227, 1698709.484003227, 341891.9343097054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5577000.0000, 
sim time next is 5577600.0000, 
raw observation next is [29.7, 75.33333333333334, 1.0, 2.0, 0.9002692602013858, 1.0, 2.0, 0.9002692602013858, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156611, 2053695.917346817, 2053695.917346817, 386930.5415315654], 
processed observation next is [1.0, 0.5652173913043478, 0.6555555555555556, 0.7533333333333334, 1.0, 1.0, 0.8812729288111735, 1.0, 1.0, 0.8812729288111735, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201314, 0.7334628276238632, 0.7334628276238632, 0.7440971952530104], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33613834], dtype=float32), -0.25170565]. 
=============================================
[2019-03-23 23:12:37,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.804939e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:12:37,116] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5876
[2019-03-23 23:12:37,129] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 79.0, 1.0, 2.0, 0.7062518492804526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804931.0585427047, 804931.0585427047, 177332.8115762883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5659200.0000, 
sim time next is 5659800.0000, 
raw observation next is [28.2, 78.33333333333334, 1.0, 2.0, 0.707916567177014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806829.3734398125, 806829.3734398125, 177649.9210315976], 
processed observation next is [0.0, 0.5217391304347826, 0.6, 0.7833333333333334, 1.0, 1.0, 0.6522816275916833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2881533476570759, 0.2881533476570759, 0.3416344635223031], 
reward next is 0.6584, 
noisyNet noise sample is [array([-0.3962425], dtype=float32), -1.2801051]. 
=============================================
[2019-03-23 23:12:40,612] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 23:12:40,614] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:12:40,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:40,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:12:40,616] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:12:40,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:12:40,616] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:40,618] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:40,619] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:12:40,617] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:40,621] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:40,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 23:12:40,647] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 23:12:40,693] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 23:12:40,694] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 23:12:40,739] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 23:13:23,379] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.95818275]
[2019-03-23 23:13:23,380] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.86666666666667, 93.33333333333334, 1.0, 2.0, 0.4785955126516218, 0.0, 2.0, 0.0, 1.0, 1.0, 0.76193964290906, 6.9112, 6.9112, 121.9258403260916, 1091135.67227779, 1091135.67227779, 249595.2708145156]
[2019-03-23 23:13:23,380] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:13:23,383] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1448902e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8269409256302631
[2019-03-23 23:13:49,800] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.95818275]
[2019-03-23 23:13:49,802] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.58333333333333, 48.16666666666666, 1.0, 2.0, 0.5468124057075193, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8730149433688267, 6.9112, 6.9112, 121.9258105929622, 1274447.751348893, 1274447.751348893, 273238.7381520414]
[2019-03-23 23:13:49,804] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:13:49,807] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1448902e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6500301333603344
[2019-03-23 23:13:56,783] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.95818275]
[2019-03-23 23:13:56,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.879294415, 89.3969546, 1.0, 2.0, 0.6080520694062248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698059.679492441, 698059.679492441, 159719.3164227134]
[2019-03-23 23:13:56,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:13:56,785] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1448902e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8078407794538256
[2019-03-23 23:14:24,201] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:14:24,246] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:14:24,286] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:14:24,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:14:24,437] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:14:25,451] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1850000, evaluation results [1850000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:14:25,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.967414e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:25,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2242
[2019-03-23 23:14:25,521] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 91.0, 1.0, 2.0, 0.4398037884615745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537615.466645261, 537615.466645261, 134181.4988775511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5726400.0000, 
sim time next is 5727000.0000, 
raw observation next is [21.28333333333333, 90.5, 1.0, 2.0, 0.4373498019436791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534989.0889191792, 534989.0889191792, 133830.4902410252], 
processed observation next is [0.0, 0.2608695652173913, 0.3438271604938271, 0.905, 1.0, 1.0, 0.33017833564723703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1910675317568497, 0.1910675317568497, 0.25736632738658693], 
reward next is 0.7426, 
noisyNet noise sample is [array([1.330466], dtype=float32), 0.061843965]. 
=============================================
[2019-03-23 23:14:25,541] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.49071]
 [70.49071]
 [70.49071]
 [70.49071]
 [70.49071]], R is [[70.52842712]
 [70.56510162]
 [70.60070801]
 [70.6353302 ]
 [70.6690979 ]].
[2019-03-23 23:14:28,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.775868e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:28,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2935
[2019-03-23 23:14:28,023] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 81.66666666666667, 1.0, 2.0, 0.5220997903382565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618988.3209184683, 618988.3209184683, 146268.5616748449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5781000.0000, 
sim time next is 5781600.0000, 
raw observation next is [24.2, 82.0, 1.0, 2.0, 0.5193102156899587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616271.2921081213, 616271.2921081213, 145843.826759305], 
processed observation next is [0.0, 0.9565217391304348, 0.45185185185185184, 0.82, 1.0, 1.0, 0.4277502567737604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22009689003861477, 0.22009689003861477, 0.2804688976140481], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.6598743], dtype=float32), -0.040027145]. 
=============================================
[2019-03-23 23:14:29,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0431932e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:14:29,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8893
[2019-03-23 23:14:29,018] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 74.66666666666667, 1.0, 2.0, 0.5679535832223236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662255.8335748088, 662255.8335748088, 153359.1038053811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5771400.0000, 
sim time next is 5772000.0000, 
raw observation next is [26.06666666666667, 75.33333333333334, 1.0, 2.0, 0.5645940136546346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659114.118741183, 659114.118741183, 152830.2813937778], 
processed observation next is [0.0, 0.8260869565217391, 0.5209876543209878, 0.7533333333333334, 1.0, 1.0, 0.48165954006504114, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23539789955042248, 0.23539789955042248, 0.29390438729572654], 
reward next is 0.7061, 
noisyNet noise sample is [array([-1.1014473], dtype=float32), 1.3498498]. 
=============================================
[2019-03-23 23:14:29,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.70288]
 [68.70288]
 [68.70288]
 [68.70288]
 [68.70288]], R is [[68.72195435]
 [68.73981476]
 [68.75662994]
 [68.7727356 ]
 [68.78811646]].
[2019-03-23 23:14:30,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5703065e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:14:30,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2447
[2019-03-23 23:14:30,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1626502.09959629 W.
[2019-03-23 23:14:30,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.16666666666667, 53.33333333333334, 1.0, 2.0, 0.4754484883085951, 1.0, 2.0, 0.4754484883085951, 1.0, 1.0, 0.756929477663534, 6.911200000000001, 6.9112, 121.94756008, 1626502.09959629, 1626502.099596289, 331702.3864796447], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6081600.0000, 
sim time next is 6082200.0000, 
raw observation next is [29.95, 54.5, 1.0, 2.0, 0.4627287027544739, 1.0, 2.0, 0.4627287027544739, 1.0, 2.0, 0.7366791648068781, 6.911199999999999, 6.9112, 121.94756008, 1582949.363256841, 1582949.363256842, 325649.8217882651], 
processed observation next is [1.0, 0.391304347826087, 0.6648148148148147, 0.545, 1.0, 1.0, 0.3603913128029452, 1.0, 1.0, 0.3603913128029452, 1.0, 1.0, 0.6708489560085975, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5653390583060146, 0.5653390583060149, 0.6262496572851252], 
reward next is 0.3738, 
noisyNet noise sample is [array([-0.81760436], dtype=float32), -0.44879234]. 
=============================================
[2019-03-23 23:14:35,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.398747e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:35,894] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4997
[2019-03-23 23:14:35,901] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1403112.979759405 W.
[2019-03-23 23:14:35,906] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.93333333333334, 55.33333333333334, 1.0, 2.0, 0.5888881430106695, 1.0, 2.0, 0.5888881430106695, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425580528, 1403112.979759405, 1403112.979759405, 266929.3411601323], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5916000.0000, 
sim time next is 5916600.0000, 
raw observation next is [27.1, 54.5, 1.0, 2.0, 0.3961189405365488, 1.0, 2.0, 0.3961189405365488, 1.0, 1.0, 0.6345105305166889, 6.9112, 6.9112, 121.94756008, 1401269.497909498, 1401269.497909498, 295329.8347275471], 
processed observation next is [1.0, 0.4782608695652174, 0.5592592592592593, 0.545, 1.0, 1.0, 0.28109397682922477, 1.0, 1.0, 0.28109397682922477, 1.0, 0.5, 0.5431381631458612, 0.0, 0.0, 0.8096049824067558, 0.500453392110535, 0.500453392110535, 0.5679419898606675], 
reward next is 0.4321, 
noisyNet noise sample is [array([0.6317709], dtype=float32), 0.24797627]. 
=============================================
[2019-03-23 23:14:41,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.702368e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:41,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8748
[2019-03-23 23:14:41,793] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.71666666666667, 59.33333333333333, 1.0, 2.0, 0.5456168687816767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639119.733959976, 639119.733959976, 149779.8979902902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6202200.0000, 
sim time next is 6202800.0000, 
raw observation next is [28.6, 60.0, 1.0, 2.0, 0.5473855503612821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641025.5394610317, 641025.5394610317, 150063.4694142425], 
processed observation next is [1.0, 0.8260869565217391, 0.6148148148148148, 0.6, 1.0, 1.0, 0.46117327423962157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22893769266465416, 0.22893769266465416, 0.28858359502738945], 
reward next is 0.7114, 
noisyNet noise sample is [array([-1.3196613], dtype=float32), -0.15828508]. 
=============================================
[2019-03-23 23:14:43,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.373965e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:43,335] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7799
[2019-03-23 23:14:43,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1536602.654359754 W.
[2019-03-23 23:14:43,354] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.55, 65.5, 1.0, 2.0, 0.4491941440424541, 1.0, 1.0, 0.4491941440424541, 1.0, 1.0, 0.7151317065475384, 6.9112, 6.9112, 121.94756008, 1536602.654359754, 1536602.654359754, 319301.8605845397], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6078600.0000, 
sim time next is 6079200.0000, 
raw observation next is [28.56666666666667, 60.66666666666667, 1.0, 2.0, 0.7090133906291959, 1.0, 2.0, 0.7090133906291959, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425082366, 1617007.744350574, 1617007.744350574, 307590.0136455902], 
processed observation next is [1.0, 0.34782608695652173, 0.6135802469135804, 0.6066666666666667, 1.0, 1.0, 0.6535873697966618, 1.0, 1.0, 0.6535873697966618, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621281069444, 0.5775027658394907, 0.5775027658394907, 0.5915192570107505], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4181907], dtype=float32), 0.2897084]. 
=============================================
[2019-03-23 23:14:44,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.531192e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:14:44,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3659
[2019-03-23 23:14:44,013] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 84.0, 1.0, 2.0, 0.5533368090083992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658304.0828428038, 658304.0828428038, 151462.3972131374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6069600.0000, 
sim time next is 6070200.0000, 
raw observation next is [23.86666666666667, 83.66666666666667, 1.0, 2.0, 0.5647680373201055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671640.3748998907, 671640.3748998907, 153365.5885396237], 
processed observation next is [1.0, 0.2608695652173913, 0.4395061728395063, 0.8366666666666667, 1.0, 1.0, 0.48186671109536366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23987156246424668, 0.23987156246424668, 0.294933824114661], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.05299951], dtype=float32), 0.08480207]. 
=============================================
[2019-03-23 23:14:58,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9475993e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:14:58,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2793
[2019-03-23 23:14:58,915] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 85.0, 1.0, 2.0, 0.6141530613575292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705829.62746143, 705829.62746143, 160820.064527889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6336600.0000, 
sim time next is 6337200.0000, 
raw observation next is [25.66666666666667, 84.0, 1.0, 2.0, 0.6192677869400317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710322.7788066772, 710322.7788066772, 161649.8395018038], 
processed observation next is [0.0, 0.34782608695652173, 0.506172839506173, 0.84, 1.0, 1.0, 0.5467473654047996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25368670671667043, 0.25368670671667043, 0.3108650759650073], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.9101711], dtype=float32), 1.7630417]. 
=============================================
[2019-03-23 23:15:06,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0851615e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:15:06,100] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-23 23:15:06,105] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 81.66666666666667, 1.0, 2.0, 0.3200354331073484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 409032.4818227926, 409032.4818227921, 118088.1794191024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6751200.0000, 
sim time next is 6751800.0000, 
raw observation next is [18.75, 82.0, 1.0, 2.0, 0.3343920926065007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427600.2872453324, 427600.2872453328, 119932.1401068448], 
processed observation next is [1.0, 0.13043478260869565, 0.25, 0.82, 1.0, 1.0, 0.20760963405535798, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15271438830190442, 0.15271438830190456, 0.23063873097470156], 
reward next is 0.7694, 
noisyNet noise sample is [array([1.2112254], dtype=float32), 0.3710536]. 
=============================================
[2019-03-23 23:15:06,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7398595e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:15:06,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8700
[2019-03-23 23:15:06,417] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.73333333333333, 60.0, 1.0, 2.0, 0.6516968181887002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742723.3428933832, 742723.3428933832, 167201.545279671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6460800.0000, 
sim time next is 6461400.0000, 
raw observation next is [30.66666666666667, 60.5, 1.0, 2.0, 0.6635966711380114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 756292.0123187861, 756292.0123187857, 169366.7988423904], 
processed observation next is [1.0, 0.782608695652174, 0.6913580246913582, 0.605, 1.0, 1.0, 0.5995198465928706, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2701042901138522, 0.270104290113852, 0.32570538238921226], 
reward next is 0.6743, 
noisyNet noise sample is [array([1.080262], dtype=float32), -0.583803]. 
=============================================
[2019-03-23 23:15:07,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8824324e-22 1.0000000e+00 2.3288818e-34 1.2098711e-37 2.0030889e-38], sum to 1.0000
[2019-03-23 23:15:07,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3667
[2019-03-23 23:15:07,884] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 41.16666666666666, 1.0, 2.0, 0.6732691894257484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856856.0081500561, 856856.0081500561, 174116.1639831924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6689400.0000, 
sim time next is 6690000.0000, 
raw observation next is [26.13333333333334, 40.33333333333334, 1.0, 2.0, 0.6488166198656851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825592.5691936245, 825592.5691936245, 169519.1984412937], 
processed observation next is [1.0, 0.43478260869565216, 0.523456790123457, 0.40333333333333343, 1.0, 1.0, 0.5819245474591489, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29485448899772304, 0.29485448899772304, 0.32599845854094944], 
reward next is 0.6740, 
noisyNet noise sample is [array([0.11555421], dtype=float32), -1.1709236]. 
=============================================
[2019-03-23 23:15:07,897] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.7135]
 [54.7135]
 [54.7135]
 [54.7135]
 [54.7135]], R is [[54.84037018]
 [54.95712662]
 [55.07356644]
 [55.17414856]
 [55.28963852]].
[2019-03-23 23:15:15,363] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 23:15:15,364] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:15:15,366] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:15:15,367] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:15:15,369] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:15:15,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:15:15,371] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:15:15,371] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:15:15,373] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:15:15,373] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:15:15,374] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:15:15,396] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 23:15:15,422] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 23:15:15,423] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 23:15:15,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 23:15:15,474] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 23:15:21,316] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:15:21,317] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666667, 37.0, 1.0, 2.0, 0.3286834908724779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416053.6359972061, 416053.6359972061, 119171.0940806229]
[2019-03-23 23:15:21,318] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:15:21,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.18389821154267172
[2019-03-23 23:15:30,615] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:15:30,616] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.588210515, 66.59233295166666, 1.0, 2.0, 0.3494103628875732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439186.341752155, 439186.3417521545, 121837.141231447]
[2019-03-23 23:15:30,617] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:15:30,619] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8401541190317887
[2019-03-23 23:15:31,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:15:31,616] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.35383368, 49.57046022, 1.0, 2.0, 0.5866152624228975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723243.9627083425, 723243.9627083425, 157917.4924744672]
[2019-03-23 23:15:31,617] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:15:31,619] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.360879939863083
[2019-03-23 23:15:43,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:15:43,693] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.98333333333333, 94.00000000000001, 1.0, 2.0, 0.3464908862362168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435235.4173578231, 435235.4173578231, 121447.6279606594]
[2019-03-23 23:15:43,693] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:15:43,696] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7882007567121202
[2019-03-23 23:15:55,463] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:15:55,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.54711477666667, 82.33755703499999, 1.0, 2.0, 0.9086331188824855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1035745.395760266, 1035745.395760266, 219423.8490359261]
[2019-03-23 23:15:55,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:15:55,468] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.261339384534959
[2019-03-23 23:16:13,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:16:13,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.16666666666666, 93.0, 1.0, 2.0, 0.4448917307628546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542653.5568961147, 542653.5568961147, 134900.5567341625]
[2019-03-23 23:16:13,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:16:13,452] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9472742299647434
[2019-03-23 23:16:27,042] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:16:27,044] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.08856091333334, 90.29848629, 1.0, 2.0, 0.6935654266322183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790464.6026563891, 790464.6026563891, 174929.9217102866]
[2019-03-23 23:16:27,045] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:16:27,047] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3657315540651438
[2019-03-23 23:16:30,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:16:30,596] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.25546763, 77.23880243666667, 1.0, 2.0, 0.679440370966076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787921.1978173066, 787921.1978173066, 172953.0281579008]
[2019-03-23 23:16:30,598] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:16:30,600] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.33934137846174806
[2019-03-23 23:16:42,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0089227]
[2019-03-23 23:16:42,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.86666666666667, 77.33333333333333, 1.0, 2.0, 0.6878217981271365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 783915.1748461728, 783915.1748461723, 173851.2955910795]
[2019-03-23 23:16:42,760] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:16:42,764] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9362116e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6717936014160732
[2019-03-23 23:16:58,467] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:16:59,181] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:16:59,228] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:16:59,293] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:16:59,476] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:17:00,493] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1875000, evaluation results [1875000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:17:06,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4909865e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:06,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4458
[2019-03-23 23:17:06,877] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 62.33333333333334, 1.0, 2.0, 0.3285205400627927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417867.5302177183, 417867.5302177183, 119166.2517451118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [22.35, 61.16666666666666, 1.0, 2.0, 0.3294078650786771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418748.0746044568, 418748.0746044563, 119278.9391035286], 
processed observation next is [1.0, 0.30434782608695654, 0.38333333333333336, 0.6116666666666666, 1.0, 1.0, 0.20167602985556796, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.149552883787306, 0.14955288378730583, 0.22938257519909344], 
reward next is 0.7706, 
noisyNet noise sample is [array([-2.0286264], dtype=float32), -0.564404]. 
=============================================
[2019-03-23 23:17:09,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0993117e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:09,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4020
[2019-03-23 23:17:09,658] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 82.66666666666667, 1.0, 2.0, 0.4048839931050919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500795.9928313701, 500795.9928313701, 129289.455103953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7100400.0000, 
sim time next is 7101000.0000, 
raw observation next is [21.4, 83.5, 1.0, 2.0, 0.4034444051291486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499184.0462514674, 499184.0462514674, 129089.557869442], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.835, 1.0, 1.0, 0.2898147680108912, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1782800165183812, 0.1782800165183812, 0.24824914974892692], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.35626143], dtype=float32), -1.1338704]. 
=============================================
[2019-03-23 23:17:09,676] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.95608]
 [69.95608]
 [69.95608]
 [69.95608]
 [69.95608]], R is [[70.00826263]
 [70.05954742]
 [70.10758209]
 [70.15859222]
 [70.20878601]].
[2019-03-23 23:17:18,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.490067e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:17:18,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1140
[2019-03-23 23:17:18,420] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 86.66666666666667, 1.0, 2.0, 0.3790081806421055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472419.8146216884, 472419.8146216884, 125760.097313411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7269600.0000, 
sim time next is 7270200.0000, 
raw observation next is [20.45, 87.0, 1.0, 2.0, 0.377824482356769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470804.9671626744, 470804.9671626744, 125594.9737258816], 
processed observation next is [1.0, 0.13043478260869565, 0.31296296296296294, 0.87, 1.0, 1.0, 0.25931485994853454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16814463112952657, 0.16814463112952657, 0.24152879562669538], 
reward next is 0.7585, 
noisyNet noise sample is [array([-0.22099862], dtype=float32), -2.721701]. 
=============================================
[2019-03-23 23:17:19,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2001754e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:19,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4452
[2019-03-23 23:17:19,592] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.4946124618754451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610530.3801565828, 610530.3801565828, 142689.4460914669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7012800.0000, 
sim time next is 7013400.0000, 
raw observation next is [21.01666666666667, 87.66666666666667, 1.0, 2.0, 0.5481723195881592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676657.2751228169, 676657.2751228169, 151384.4194440593], 
processed observation next is [1.0, 0.17391304347826086, 0.3339506172839507, 0.8766666666666667, 1.0, 1.0, 0.462109904271618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24166331254386317, 0.24166331254386317, 0.2911238835462679], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.21960409], dtype=float32), 0.37876385]. 
=============================================
[2019-03-23 23:17:20,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6376925e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:20,136] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4835
[2019-03-23 23:17:20,138] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 85.33333333333334, 1.0, 2.0, 0.5411091741482005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663680.1257801737, 663680.1257801737, 150097.7586922327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7024800.0000, 
sim time next is 7025400.0000, 
raw observation next is [21.85, 85.0, 1.0, 2.0, 0.5510501042014846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 675430.3849379709, 675430.3849379704, 151740.5543534129], 
processed observation next is [1.0, 0.30434782608695654, 0.36481481481481487, 0.85, 1.0, 1.0, 0.4655358383351007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24122513747784674, 0.24122513747784657, 0.2918087583719479], 
reward next is 0.7082, 
noisyNet noise sample is [array([1.7398047], dtype=float32), -0.468002]. 
=============================================
[2019-03-23 23:17:20,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7741434e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:20,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5589
[2019-03-23 23:17:20,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1458911.173271259 W.
[2019-03-23 23:17:20,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 64.5, 1.0, 2.0, 0.6279800867459207, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9675869091260682, 6.911199999999999, 6.9112, 121.9257220263407, 1458911.173271259, 1458911.17327126, 298037.3055045343], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7306200.0000, 
sim time next is 7306800.0000, 
raw observation next is [26.4, 63.66666666666666, 1.0, 2.0, 0.4081176069428128, 1.0, 1.0, 0.4081176069428128, 1.0, 2.0, 0.6511580903808575, 6.9112, 6.9112, 121.94756008, 1422507.505153424, 1422507.505153424, 300735.2747725327], 
processed observation next is [1.0, 0.5652173913043478, 0.5333333333333333, 0.6366666666666666, 1.0, 1.0, 0.2953781035033486, 1.0, 0.5, 0.2953781035033486, 1.0, 1.0, 0.5639476129760718, 0.0, 0.0, 0.8096049824067558, 0.5080383946976514, 0.5080383946976514, 0.5783370668702552], 
reward next is 0.4217, 
noisyNet noise sample is [array([0.9581801], dtype=float32), 0.94659066]. 
=============================================
[2019-03-23 23:17:22,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.265469e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:17:22,626] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1437
[2019-03-23 23:17:22,630] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 79.0, 1.0, 2.0, 0.4112266081418879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507777.8279089141, 507777.8279089141, 130171.3598498505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7097400.0000, 
sim time next is 7098000.0000, 
raw observation next is [22.03333333333333, 79.66666666666667, 1.0, 2.0, 0.4080152142950841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 503993.7797441803, 503993.7797441799, 129718.1045314433], 
processed observation next is [1.0, 0.13043478260869565, 0.37160493827160485, 0.7966666666666667, 1.0, 1.0, 0.2952562074941477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1799977784800644, 0.17999777848006426, 0.24945789332969864], 
reward next is 0.7505, 
noisyNet noise sample is [array([1.3981562], dtype=float32), 0.22493176]. 
=============================================
[2019-03-23 23:17:22,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.41287]
 [71.41287]
 [71.41287]
 [71.41287]
 [71.41287]], R is [[71.44928741]
 [71.48446655]
 [71.51874542]
 [71.54074097]
 [71.5737381 ]].
[2019-03-23 23:17:31,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.775222e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:17:31,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3855
[2019-03-23 23:17:31,946] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 95.33333333333334, 1.0, 2.0, 0.4601884925915818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556593.9676071306, 556593.9676071306, 137045.8645534857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7518000.0000, 
sim time next is 7518600.0000, 
raw observation next is [21.35, 95.5, 1.0, 2.0, 0.4592866100097051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 555786.3449624241, 555786.3449624237, 136919.0887187358], 
processed observation next is [0.0, 0.0, 0.3462962962962963, 0.955, 1.0, 1.0, 0.3562935833448871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19849512320086576, 0.1984951232008656, 0.2633059398437227], 
reward next is 0.7367, 
noisyNet noise sample is [array([1.6818713], dtype=float32), -0.7158182]. 
=============================================
[2019-03-23 23:17:35,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:17:35,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:35,576] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 23:17:39,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2925533e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:39,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8461
[2019-03-23 23:17:39,799] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.6335726683794218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777226.5920981201, 777226.5920981201, 166171.8768489499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7390800.0000, 
sim time next is 7391400.0000, 
raw observation next is [20.88333333333334, 92.83333333333333, 1.0, 2.0, 0.6983034024003433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855621.5031138731, 855621.5031138731, 178295.3819428627], 
processed observation next is [1.0, 0.5652173913043478, 0.3290123456790126, 0.9283333333333332, 1.0, 1.0, 0.6408373838099325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30557910825495466, 0.30557910825495466, 0.3428757345055052], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.9433862], dtype=float32), -0.5148348]. 
=============================================
[2019-03-23 23:17:47,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9771381e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:47,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4772
[2019-03-23 23:17:47,146] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4383429611470255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533976.3554238365, 533976.355423836, 133912.7984093979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7528200.0000, 
sim time next is 7528800.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4385645393199104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534246.1993203267, 534246.1993203267, 133945.4019786304], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.331624451571322, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19080221404297382, 0.19080221404297382, 0.25758731149736613], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.3626277], dtype=float32), 1.4080554]. 
=============================================
[2019-03-23 23:17:47,433] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4581207e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:47,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6663
[2019-03-23 23:17:47,445] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 76.66666666666666, 1.0, 2.0, 0.5336449251431068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628185.7329483355, 628185.7329483355, 147955.9564966011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7558800.0000, 
sim time next is 7559400.0000, 
raw observation next is [25.73333333333333, 75.33333333333334, 1.0, 2.0, 0.5361449239782884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630402.6490595455, 630402.6490595455, 148332.4383418111], 
processed observation next is [0.0, 0.4782608695652174, 0.5086419753086419, 0.7533333333333334, 1.0, 1.0, 0.447791576164629, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22514380323555197, 0.22514380323555197, 0.2852546891188675], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.11416844], dtype=float32), 0.26250467]. 
=============================================
[2019-03-23 23:17:48,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6164329e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:17:48,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1394
[2019-03-23 23:17:48,299] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 90.16666666666667, 1.0, 2.0, 0.463057879438743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557904.6555819703, 557904.6555819703, 137408.3051992574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549800.0000, 
sim time next is 7550400.0000, 
raw observation next is [22.5, 89.33333333333334, 1.0, 2.0, 0.46750733795384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562353.8727247455, 562353.8727247455, 138051.399362894], 
processed observation next is [0.0, 0.391304347826087, 0.3888888888888889, 0.8933333333333334, 1.0, 1.0, 0.3660801642307619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20084066883026627, 0.20084066883026627, 0.2654834603132577], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.5378016], dtype=float32), 1.3626608]. 
=============================================
[2019-03-23 23:17:50,290] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 23:17:50,292] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:17:50,293] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:17:50,294] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:50,296] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:17:50,296] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:50,297] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:17:50,297] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:50,298] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:17:50,300] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:50,301] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:50,326] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 23:17:50,351] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 23:17:50,352] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 23:17:50,401] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 23:17:50,431] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 23:17:52,185] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:17:52,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.7, 39.0, 1.0, 2.0, 0.9830575632314825, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.511961268177132, 6.9112, 121.9235390597642, 1515850.339151643, 1208213.191377653, 240673.2745911617]
[2019-03-23 23:17:52,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:17:52,191] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.11209065856754052
[2019-03-23 23:17:52,193] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1515850.339151643 W.
[2019-03-23 23:17:52,432] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:17:52,434] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 46.0, 1.0, 2.0, 0.2912842806116871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 375744.7059380141, 375744.7059380137, 94039.33006350703]
[2019-03-23 23:17:52,435] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:17:52,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.373208602434391
[2019-03-23 23:18:05,419] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:05,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 42.0, 1.0, 2.0, 0.2645044709008492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 341192.1718711556, 341192.1718711556, 100169.1247007822]
[2019-03-23 23:18:05,422] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:18:05,424] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0977245135405379
[2019-03-23 23:18:29,014] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:29,016] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 58.0, 1.0, 2.0, 0.5465107852214803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639999.6910424521, 639999.6910424521, 149919.5355059897]
[2019-03-23 23:18:29,017] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:18:29,020] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9313480545322488
[2019-03-23 23:18:36,667] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:36,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 71.5, 1.0, 2.0, 0.7303575095760781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832419.7387880131, 832419.7387880131, 181975.4202618544]
[2019-03-23 23:18:36,669] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:18:36,671] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9812925678317678
[2019-03-23 23:18:37,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:37,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.66666666666667, 54.0, 1.0, 2.0, 0.7390143009871628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842291.6762487125, 842291.6762487125, 183666.4201389755]
[2019-03-23 23:18:37,318] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:18:37,320] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7101193196248581
[2019-03-23 23:18:50,145] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:50,146] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.62648015, 32.49971608333334, 1.0, 2.0, 0.6230853198233359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761460.413812893, 761460.413812893, 164189.7628611432]
[2019-03-23 23:18:50,148] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:18:50,152] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.33762577964013185
[2019-03-23 23:18:54,424] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:18:54,428] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.708924395, 91.62284976500001, 1.0, 2.0, 0.4458534494480755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 541446.5416875944, 541446.5416875939, 134972.7102555882]
[2019-03-23 23:18:54,430] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:18:54,434] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9920746725341878
[2019-03-23 23:19:04,181] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:19:04,182] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333334, 66.0, 1.0, 2.0, 0.5269322642390605, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8388933256543597, 6.911200000000001, 6.9112, 121.9258363705279, 1201423.601668862, 1201423.601668861, 266511.8419765314]
[2019-03-23 23:19:04,182] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:19:04,185] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.8468217056570272
[2019-03-23 23:19:08,697] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0034424]
[2019-03-23 23:19:08,698] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.30641304, 57.97260718, 1.0, 2.0, 0.5439319114327542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642763.4911291518, 642763.4911291518, 149734.6919281029]
[2019-03-23 23:19:08,699] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:19:08,700] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.826839e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9813307272127221
[2019-03-23 23:19:33,906] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:19:33,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:19:34,167] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:19:34,256] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:19:34,302] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:19:35,318] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1900000, evaluation results [1900000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:19:38,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3330552e-25 1.0000000e+00 2.8690297e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:19:38,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3734
[2019-03-23 23:19:38,891] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 91.33333333333334, 1.0, 2.0, 0.3799843583735951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471352.2854934214, 471352.2854934214, 125846.917540235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7627200.0000, 
sim time next is 7627800.0000, 
raw observation next is [20.33333333333333, 91.16666666666667, 1.0, 2.0, 0.380186962848824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471300.1216024373, 471300.1216024373, 125868.0480642961], 
processed observation next is [1.0, 0.2608695652173913, 0.3086419753086418, 0.9116666666666667, 1.0, 1.0, 0.26212733672479044, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16832147200087047, 0.16832147200087047, 0.2420539385851848], 
reward next is 0.7579, 
noisyNet noise sample is [array([-0.8030193], dtype=float32), -0.031577617]. 
=============================================
[2019-03-23 23:19:39,017] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5191324e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:19:39,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7708
[2019-03-23 23:19:39,031] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 66.0, 1.0, 2.0, 0.9395124625577491, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.051018382232674, 6.9112, 121.9255457592108, 1194283.510022706, 1122684.293266973, 229030.8872536329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7659000.0000, 
sim time next is 7659600.0000, 
raw observation next is [25.6, 66.0, 1.0, 2.0, 0.9632980195194984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.266634772334514, 6.9112, 121.9244780065209, 1344704.711893464, 1162692.675748005, 235136.4255302441], 
processed observation next is [1.0, 0.6521739130434783, 0.5037037037037038, 0.66, 1.0, 1.0, 0.9563071660946411, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.035543477233451436, 0.0, 0.8094517414425192, 0.48025168281909425, 0.4152473841957161, 0.45218543371200787], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.659478], dtype=float32), -0.42137554]. 
=============================================
[2019-03-23 23:19:39,307] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.827553e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:19:39,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1595
[2019-03-23 23:19:39,316] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 78.0, 1.0, 2.0, 0.3095476053615512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394446.1569163094, 394446.1569163094, 116761.2170086818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7689600.0000, 
sim time next is 7690200.0000, 
raw observation next is [19.61666666666667, 76.5, 1.0, 2.0, 0.3029789643203206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386751.112853147, 386751.112853147, 115944.5450581823], 
processed observation next is [1.0, 0.0, 0.28209876543209894, 0.765, 1.0, 1.0, 0.17021305276228646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13812539744755248, 0.13812539744755248, 0.2229702789580429], 
reward next is 0.7770, 
noisyNet noise sample is [array([-1.317421], dtype=float32), -0.8671007]. 
=============================================
[2019-03-23 23:19:40,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:40,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:41,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 23:19:41,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.669672e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:19:41,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4994
[2019-03-23 23:19:41,604] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 59.0, 1.0, 2.0, 0.5136179178955618, 1.0, 1.0, 0.5136179178955618, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257800765545, 1217766.70675366, 1217766.70675366, 241703.2294235912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7731600.0000, 
sim time next is 7732200.0000, 
raw observation next is [27.1, 58.0, 1.0, 2.0, 0.9516258135920475, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.158743252618809, 6.9112, 121.9249597153595, 1269436.314752976, 1142673.170118875, 232115.9572160114], 
processed observation next is [1.0, 0.4782608695652174, 0.5592592592592593, 0.58, 1.0, 1.0, 0.9424116828476755, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.024754325261880882, 0.0, 0.8094549394882656, 0.4533701124117771, 0.4080975607567411, 0.4463768408000219], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2704511], dtype=float32), 2.1775436]. 
=============================================
[2019-03-23 23:19:42,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4211029e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:19:42,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 23:19:42,882] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 61.83333333333334, 1.0, 2.0, 0.4285376007991493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524728.4590188278, 524728.4590188278, 132555.2912960734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7758600.0000, 
sim time next is 7759200.0000, 
raw observation next is [25.13333333333334, 62.66666666666667, 1.0, 2.0, 0.4234745542458125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519500.0332944028, 519500.0332944028, 131846.7886880489], 
processed observation next is [1.0, 0.8260869565217391, 0.48641975308642, 0.6266666666666667, 1.0, 1.0, 0.3136601836259672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18553572617657244, 0.18553572617657244, 0.25355151670778636], 
reward next is 0.7464, 
noisyNet noise sample is [array([-1.1758744], dtype=float32), 0.9688707]. 
=============================================
[2019-03-23 23:19:45,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:45,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:45,230] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 23:19:46,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7727427e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:19:46,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1580
[2019-03-23 23:19:46,270] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 39.16666666666666, 1.0, 2.0, 0.3403177296411147, 1.0, 1.0, 0.3403177296411147, 1.0, 1.0, 0.5517704576683505, 6.911200000000001, 6.9112, 121.94756008, 1233708.132605484, 1233708.132605484, 271165.4738665651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7818600.0000, 
sim time next is 7819200.0000, 
raw observation next is [29.4, 39.0, 1.0, 2.0, 0.9545437684152746, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.31969668906957, 6.9112, 121.9243258156663, 1381722.025727328, 1172538.155393824, 233767.6620626905], 
processed observation next is [1.0, 0.5217391304347826, 0.6444444444444444, 0.39, 1.0, 1.0, 0.9458854385896126, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.04084966890695698, 0.0, 0.809450731053512, 0.49347215204547423, 0.4187636269263657, 0.4495531962744048], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1093085], dtype=float32), -1.3626292]. 
=============================================
[2019-03-23 23:19:47,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8441477e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:19:47,206] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4753
[2019-03-23 23:19:47,210] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.06666666666667, 75.66666666666667, 1.0, 2.0, 0.290960663736095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375327.1513664683, 375327.1513664683, 108192.1938665509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 15600.0000, 
sim time next is 16200.0000, 
raw observation next is [18.05, 75.5, 1.0, 2.0, 0.2894111251017926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373327.8244777619, 373327.8244777619, 107372.8512020683], 
processed observation next is [1.0, 0.17391304347826086, 0.2240740740740741, 0.755, 1.0, 1.0, 0.1540608632164198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13333136588491498, 0.13333136588491498, 0.2064862523116698], 
reward next is 0.7935, 
noisyNet noise sample is [array([1.1031747], dtype=float32), 0.29848364]. 
=============================================
[2019-03-23 23:19:52,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:52,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,012] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 23:19:53,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,088] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 23:19:53,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,312] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 23:19:53,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,441] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 23:19:53,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 23:19:53,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 23:19:53,790] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,791] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 23:19:53,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:53,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:53,896] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 23:19:54,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:54,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:54,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 23:19:54,195] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:54,195] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:54,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 23:19:54,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:54,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:54,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 23:19:54,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:54,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:54,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 23:19:54,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:19:54,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:54,942] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 23:19:57,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.278334e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:19:57,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5946
[2019-03-23 23:19:57,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1340294.921889279 W.
[2019-03-23 23:19:58,002] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 38.33333333333334, 1.0, 2.0, 0.5513064902220843, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8975898486295877, 6.9112, 6.9112, 121.9260426156618, 1340294.921889279, 1340294.921889279, 272774.4146566268], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 58800.0000, 
sim time next is 59400.0000, 
raw observation next is [29.8, 38.5, 1.0, 2.0, 0.5498483215095995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8951913082854036, 6.911199999999999, 6.9112, 121.9260426156618, 1336698.884667624, 1336698.884667625, 272242.6677920833], 
processed observation next is [1.0, 0.6956521739130435, 0.6592592592592593, 0.385, 1.0, 1.0, 0.4641051446542851, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8689891353567544, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4773924588098657, 0.477392458809866, 0.5235435919078525], 
reward next is 0.4765, 
noisyNet noise sample is [array([0.3190824], dtype=float32), 0.33401495]. 
=============================================
[2019-03-23 23:19:59,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.055208e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:19:59,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0880
[2019-03-23 23:19:59,614] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 41.0, 1.0, 2.0, 0.266605023861239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 343902.3450126949, 343902.3450126945, 94541.24628585525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [22.4, 40.0, 1.0, 2.0, 0.2689863459543875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 346974.7833803201, 346974.7833803201, 95108.80677546827], 
processed observation next is [0.0, 0.30434782608695654, 0.38518518518518513, 0.4, 1.0, 1.0, 0.12974564994569937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12391956549297148, 0.12391956549297148, 0.18290155149128515], 
reward next is 0.8171, 
noisyNet noise sample is [array([-2.5903206], dtype=float32), 1.8587353]. 
=============================================
[2019-03-23 23:20:01,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3754868e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:20:01,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9616
[2019-03-23 23:20:01,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1418564.431891763 W.
[2019-03-23 23:20:01,679] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.25, 19.5, 1.0, 2.0, 0.5832521143807159, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9498746970839205, 6.9112, 6.9112, 121.926042522102, 1418564.431891763, 1418564.431891763, 284666.9058193505], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 135000.0000, 
sim time next is 135600.0000, 
raw observation next is [36.63333333333333, 18.0, 1.0, 2.0, 0.4110908774434885, 1.0, 1.0, 0.4110908774434885, 1.0, 2.0, 0.6637496564872432, 6.911199999999999, 6.9112, 121.94756008, 1480414.881790593, 1480414.881790593, 301535.822043986], 
processed observation next is [1.0, 0.5652173913043478, 0.9123456790123456, 0.18, 1.0, 1.0, 0.2989177112422482, 1.0, 0.5, 0.2989177112422482, 1.0, 1.0, 0.5796870706090539, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5287196006394975, 0.5287196006394975, 0.5798765808538192], 
reward next is 0.4201, 
noisyNet noise sample is [array([-0.26990628], dtype=float32), -0.20854424]. 
=============================================
[2019-03-23 23:20:04,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.054292e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:20:04,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2058
[2019-03-23 23:20:04,977] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 30.0, 1.0, 2.0, 0.8317433585152408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1063225.56967228, 1063225.56967228, 206510.1691732751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 384000.0000, 
sim time next is 384600.0000, 
raw observation next is [28.31666666666667, 29.5, 1.0, 2.0, 0.8408082973067451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1074523.144838236, 1074523.144838235, 208497.0475717311], 
processed observation next is [1.0, 0.43478260869565216, 0.6043209876543211, 0.295, 1.0, 1.0, 0.8104860682223156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.3837582660136557, 0.38375826601365537, 0.4009558607148675], 
reward next is 0.5990, 
noisyNet noise sample is [array([0.73933876], dtype=float32), -1.2646624]. 
=============================================
[2019-03-23 23:20:07,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5310109e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:20:07,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2452
[2019-03-23 23:20:07,420] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.11666666666667, 42.0, 1.0, 2.0, 0.3523455634421698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443411.2316915885, 443411.2316915885, 122233.4489346682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 208200.0000, 
sim time next is 208800.0000, 
raw observation next is [27.5, 40.0, 1.0, 2.0, 0.3492456434168283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439897.6877402157, 439897.6877402157, 121828.0613200149], 
processed observation next is [0.0, 0.43478260869565216, 0.5740740740740741, 0.4, 1.0, 1.0, 0.2252924326390813, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15710631705007702, 0.15710631705007702, 0.23428473330772095], 
reward next is 0.7657, 
noisyNet noise sample is [array([-1.471645], dtype=float32), -0.26393363]. 
=============================================
[2019-03-23 23:20:10,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7529158e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:20:10,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9535
[2019-03-23 23:20:10,355] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 30.33333333333334, 1.0, 2.0, 0.317767662704615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409916.3066156639, 409916.3066156639, 116732.6948921115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 303600.0000, 
sim time next is 304200.0000, 
raw observation next is [26.9, 30.5, 1.0, 2.0, 0.3176557778469826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409689.1743081359, 409689.1743081359, 117770.8497025641], 
processed observation next is [0.0, 0.5217391304347826, 0.5518518518518518, 0.305, 1.0, 1.0, 0.18768544981783647, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14631756225290568, 0.14631756225290568, 0.22648240327416172], 
reward next is 0.7735, 
noisyNet noise sample is [array([0.22581445], dtype=float32), 0.8235334]. 
=============================================
[2019-03-23 23:20:25,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7452991e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:20:25,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2248
[2019-03-23 23:20:25,792] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 55.0, 1.0, 2.0, 0.4007074542806749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496280.7489411772, 496280.7489411772, 128714.1709372753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 859200.0000, 
sim time next is 859800.0000, 
raw observation next is [25.66666666666666, 56.0, 1.0, 2.0, 0.4029223144603589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498866.4382114506, 498866.4382114506, 129023.3136083342], 
processed observation next is [0.0, 0.9565217391304348, 0.5061728395061726, 0.56, 1.0, 1.0, 0.2891932315004273, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17816658507551808, 0.17816658507551808, 0.2481217569391042], 
reward next is 0.7519, 
noisyNet noise sample is [array([0.30998647], dtype=float32), -0.20243503]. 
=============================================
[2019-03-23 23:20:26,233] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 23:20:26,236] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:20:26,236] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:20:26,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:20:26,237] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:20:26,238] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:20:26,237] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:20:26,242] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:20:26,239] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:20:26,243] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:20:26,244] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:20:26,264] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 23:20:26,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 23:20:26,316] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 23:20:26,316] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 23:20:26,340] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 23:21:09,583] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:09,584] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.89179151, 82.47205934499999, 1.0, 2.0, 0.8160953905244174, 1.0, 2.0, 0.8160953905244174, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1861478.211763537, 1861478.211763537, 350452.7613117993]
[2019-03-23 23:21:09,585] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:21:09,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.11882447783467087
[2019-03-23 23:21:09,589] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1861478.211763537 W.
[2019-03-23 23:21:11,413] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:11,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.5, 90.0, 1.0, 2.0, 0.3961627156339919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491112.4321003992, 491112.4321003992, 128085.6557309418]
[2019-03-23 23:21:11,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:21:11,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.9133030187283165
[2019-03-23 23:21:12,406] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:12,407] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 89.0, 1.0, 2.0, 0.7327059001356329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835097.7582569798, 835097.7582569798, 182430.6476436129]
[2019-03-23 23:21:12,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:21:12,410] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.3114838724882525
[2019-03-23 23:21:28,682] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:28,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.86646573, 77.801977385, 1.0, 2.0, 0.819651040371028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934253.4317248068, 934253.4317248068, 200042.6400330672]
[2019-03-23 23:21:28,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:21:28,687] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.07955511652625102
[2019-03-23 23:21:38,982] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:38,982] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.44476711, 75.78260488, 1.0, 2.0, 0.8003641562840014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156333, 912256.7997230947, 912256.7997230947, 196010.1451645177]
[2019-03-23 23:21:38,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:21:38,987] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.8599539019548751
[2019-03-23 23:21:41,809] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:41,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.43333333333333, 92.66666666666667, 1.0, 2.0, 0.7345480812398187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837198.5213613972, 837198.5213613972, 182790.7144537469]
[2019-03-23 23:21:41,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:21:41,813] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.049172967482611796
[2019-03-23 23:21:54,857] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:54,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.05826201333333, 36.81791043666666, 1.0, 2.0, 0.515308823237277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 656179.3209057725, 656179.320905772, 146309.5037315351]
[2019-03-23 23:21:54,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:21:54,862] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.3909905914530827
[2019-03-23 23:21:57,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:21:57,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.78333333333333, 84.33333333333334, 1.0, 2.0, 0.5516663541198077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643476.8638104717, 643476.8638104717, 150658.4511510714]
[2019-03-23 23:21:57,865] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:21:57,870] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.18772462685447333
[2019-03-23 23:22:02,540] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:22:02,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.28333333333333, 98.5, 1.0, 2.0, 0.5169450050255193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610753.0326437581, 610753.0326437581, 145358.852144947]
[2019-03-23 23:22:02,542] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:22:02,545] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.42284830490428205
[2019-03-23 23:22:03,645] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0191371]
[2019-03-23 23:22:03,646] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.8, 74.5, 1.0, 2.0, 0.3837788699507111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495097.4270353442, 495097.4270353442, 118607.5152719446]
[2019-03-23 23:22:03,647] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:22:03,652] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.59636007e-23 1.00000000e+00 1.28751375e-36 0.00000000e+00
 0.00000000e+00], sampled 0.12337188983224334
[2019-03-23 23:22:09,785] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:22:09,798] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:22:09,988] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:22:10,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:22:10,029] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:22:11,042] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1925000, evaluation results [1925000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:22:11,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1160951e-23 1.0000000e+00 4.4560170e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:11,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8869
[2019-03-23 23:22:11,131] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 35.0, 1.0, 2.0, 0.3878907361475935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 480929.8525535394, 480929.852553539, 126933.3297111795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 586800.0000, 
sim time next is 587400.0000, 
raw observation next is [30.25, 35.33333333333334, 1.0, 2.0, 0.3866809267953579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479662.7217968241, 479662.7217968237, 126770.7080872232], 
processed observation next is [1.0, 0.8260869565217391, 0.6759259259259259, 0.35333333333333344, 1.0, 1.0, 0.2698582461849499, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17130811492743717, 0.17130811492743706, 0.24378982324466], 
reward next is 0.7562, 
noisyNet noise sample is [array([1.0239419], dtype=float32), 0.90444505]. 
=============================================
[2019-03-23 23:22:20,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4913998e-23 1.0000000e+00 2.1013182e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:20,088] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-23 23:22:20,095] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 29.0, 1.0, 2.0, 0.3445352374039384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437191.5270338323, 437191.5270338323, 121241.8462332824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 763200.0000, 
sim time next is 763800.0000, 
raw observation next is [29.53333333333333, 29.5, 1.0, 2.0, 0.3430630999221179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435366.0811052377, 435366.0811052377, 121048.8365045616], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493827, 0.295, 1.0, 1.0, 0.21793226181204514, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15548788610901346, 0.15548788610901346, 0.23278622404723384], 
reward next is 0.7672, 
noisyNet noise sample is [array([-0.9156736], dtype=float32), 0.6439893]. 
=============================================
[2019-03-23 23:22:20,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1461572e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:20,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3444
[2019-03-23 23:22:20,207] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 67.0, 1.0, 2.0, 0.3055278783972733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389829.385167547, 389829.3851675475, 116261.1198766306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1046400.0000, 
sim time next is 1047000.0000, 
raw observation next is [20.96666666666667, 67.5, 1.0, 2.0, 0.3020588726728706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385395.3665520631, 385395.3665520636, 115830.1218730082], 
processed observation next is [1.0, 0.08695652173913043, 0.3320987654320988, 0.675, 1.0, 1.0, 0.16911770556294123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13764120234002253, 0.13764120234002272, 0.22275023437116961], 
reward next is 0.7772, 
noisyNet noise sample is [array([-0.17833675], dtype=float32), 0.071390435]. 
=============================================
[2019-03-23 23:22:20,220] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.62525]
 [59.62525]
 [59.62525]
 [59.62525]
 [59.62525]], R is [[59.8062439 ]
 [59.98460388]
 [60.15787506]
 [60.31999207]
 [60.45078278]].
[2019-03-23 23:22:37,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0216168e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:37,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2383
[2019-03-23 23:22:37,893] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 45.66666666666667, 1.0, 2.0, 0.6900406171025352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873795.9744029912, 873795.9744029912, 177292.632377884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1081200.0000, 
sim time next is 1081800.0000, 
raw observation next is [25.6, 45.0, 1.0, 2.0, 0.6954023657833318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 880847.3473521969, 880847.3473521979, 178333.1044297551], 
processed observation next is [1.0, 0.5217391304347826, 0.5037037037037038, 0.45, 1.0, 1.0, 0.6373837687896807, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.31458833834007033, 0.31458833834007066, 0.342948277749529], 
reward next is 0.6571, 
noisyNet noise sample is [array([-0.20103733], dtype=float32), 0.9059996]. 
=============================================
[2019-03-23 23:22:39,289] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.100555e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:22:39,297] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1501
[2019-03-23 23:22:39,302] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 51.0, 1.0, 2.0, 0.3351694553964083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422306.2484225116, 422306.2484225116, 119986.579725971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1101000.0000, 
sim time next is 1101600.0000, 
raw observation next is [24.8, 52.0, 1.0, 2.0, 0.3364288838102241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424119.3167940284, 424119.3167940284, 120153.0021996232], 
processed observation next is [1.0, 0.782608695652174, 0.4740740740740741, 0.52, 1.0, 1.0, 0.21003438548836206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15147118456929584, 0.15147118456929584, 0.23106346576850614], 
reward next is 0.7689, 
noisyNet noise sample is [array([-0.8552669], dtype=float32), 2.1204143]. 
=============================================
[2019-03-23 23:22:41,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2698197e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:41,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9247
[2019-03-23 23:22:41,274] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 65.0, 1.0, 2.0, 0.4837092308815488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615196.653234478, 615196.653234478, 141276.1184528689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1167600.0000, 
sim time next is 1168200.0000, 
raw observation next is [21.65, 65.0, 1.0, 2.0, 0.4423751533057765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562525.1688699543, 562525.1688699543, 134966.733689781], 
processed observation next is [1.0, 0.5217391304347826, 0.35740740740740734, 0.65, 1.0, 1.0, 0.33616089679259104, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20090184602498368, 0.20090184602498368, 0.2595514109418865], 
reward next is 0.7404, 
noisyNet noise sample is [array([1.5656623], dtype=float32), 0.34254834]. 
=============================================
[2019-03-23 23:22:43,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0391363e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:43,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1494
[2019-03-23 23:22:43,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 93.33333333333334, 1.0, 2.0, 0.3491113679655188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 121808.6121606411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1205400.0000, 
sim time next is 1206000.0000, 
raw observation next is [18.8, 94.0, 1.0, 2.0, 0.3485289790037249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438816.0934933131, 438816.0934933131, 121731.032696335], 
processed observation next is [1.0, 1.0, 0.2518518518518519, 0.94, 1.0, 1.0, 0.22443926071872014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15672003339046897, 0.15672003339046897, 0.23409813980064423], 
reward next is 0.7659, 
noisyNet noise sample is [array([-1.7001065], dtype=float32), -0.77812475]. 
=============================================
[2019-03-23 23:22:43,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.38109]
 [71.38109]
 [71.38109]
 [71.38109]
 [71.38109]], R is [[71.43317413]
 [71.48459625]
 [71.53527069]
 [71.5852356 ]
 [71.63468933]].
[2019-03-23 23:22:47,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9745893e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:47,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4156
[2019-03-23 23:22:47,712] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1433263.570943855 W.
[2019-03-23 23:22:47,716] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666666, 56.33333333333334, 1.0, 2.0, 0.9660251005652204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.393577660487933, 6.9112, 121.9238212241761, 1433263.570943855, 1186247.594856413, 236511.6018835795], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1263000.0000, 
sim time next is 1263600.0000, 
raw observation next is [26.2, 56.0, 1.0, 2.0, 0.5365815681491323, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8724642383796601, 6.911199999999998, 6.9112, 121.9257520844523, 1302164.339731646, 1302164.339731647, 267542.5678638193], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.56, 1.0, 1.0, 0.4483113906537289, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8405802979745752, -1.7763568394002506e-16, 0.0, 0.809460199995036, 0.46505869276130213, 0.46505869276130246, 0.5145049381996525], 
reward next is 0.4855, 
noisyNet noise sample is [array([0.64833176], dtype=float32), 0.9149471]. 
=============================================
[2019-03-23 23:22:59,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7046815e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:22:59,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5055
[2019-03-23 23:22:59,183] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.65, 27.16666666666666, 1.0, 2.0, 0.3748956210701425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470387.7424663295, 470387.7424663295, 125251.458642557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1451400.0000, 
sim time next is 1452000.0000, 
raw observation next is [31.5, 27.33333333333334, 1.0, 2.0, 0.3731092533850652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468522.9472224521, 468522.9472224521, 125013.3576946312], 
processed observation next is [0.0, 0.8260869565217391, 0.7222222222222222, 0.2733333333333334, 1.0, 1.0, 0.2537014921250776, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1673296240080186, 0.1673296240080186, 0.24041030325890614], 
reward next is 0.7596, 
noisyNet noise sample is [array([0.6012052], dtype=float32), 0.57330984]. 
=============================================
[2019-03-23 23:22:59,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.53679]
 [72.53679]
 [72.53679]
 [72.53679]
 [72.53679]], R is [[72.57102203]
 [72.60444641]
 [72.63750458]
 [72.66988373]
 [72.70159912]].
[2019-03-23 23:23:00,830] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 23:23:00,832] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:23:00,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:23:00,833] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:23:00,834] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:23:00,836] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:23:00,837] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:23:00,838] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:23:00,838] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:23:00,839] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:23:00,842] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:23:00,863] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 23:23:00,891] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 23:23:00,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 23:23:00,935] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 23:23:00,936] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 23:23:21,445] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9147638]
[2019-03-23 23:23:21,446] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.0, 25.0, 1.0, 2.0, 0.4175723251477091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511254.4804808572, 511254.4804808572, 130968.505816025]
[2019-03-23 23:23:21,446] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:23:21,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9503705e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6927472048446766
[2019-03-23 23:23:26,950] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9147638]
[2019-03-23 23:23:26,952] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.18642418, 87.98410180666667, 1.0, 2.0, 0.3687937404212185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460195.6939022979, 460195.6939022983, 124376.542519997]
[2019-03-23 23:23:26,952] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:23:26,957] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9503705e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.554141875740863
[2019-03-23 23:24:33,143] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9147638]
[2019-03-23 23:24:33,144] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.37530989833333, 56.31887605833333, 1.0, 2.0, 0.5595153978659287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654404.1922262646, 654404.1922262646, 152035.6593627167]
[2019-03-23 23:24:33,144] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:24:33,147] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9503705e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9042064882754821
[2019-03-23 23:24:40,954] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9147638]
[2019-03-23 23:24:40,955] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.46666666666667, 53.0, 1.0, 2.0, 0.4998403374578578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623356.9844643164, 623356.9844643164, 143655.6710137333]
[2019-03-23 23:24:40,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:24:40,957] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9503705e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4159207004502239
[2019-03-23 23:24:44,339] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:24:44,740] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:24:44,772] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:24:44,804] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:24:44,852] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:24:45,867] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1950000, evaluation results [1950000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:24:46,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4484985e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:24:46,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-23 23:24:46,837] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.25, 31.0, 1.0, 2.0, 0.4538180729178393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546709.0851057012, 546709.0851057012, 136018.0912940512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [34.06666666666667, 32.33333333333334, 1.0, 2.0, 0.4641295654958781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557176.7981535305, 557176.7981535305, 137501.5992232789], 
processed observation next is [0.0, 0.6521739130434783, 0.8172839506172841, 0.3233333333333334, 1.0, 1.0, 0.36205900654271206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1989917136262609, 0.1989917136262609, 0.2644261523524594], 
reward next is 0.7356, 
noisyNet noise sample is [array([0.7484062], dtype=float32), 0.3025303]. 
=============================================
[2019-03-23 23:24:47,477] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8652272e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:24:47,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7820
[2019-03-23 23:24:47,493] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 64.0, 1.0, 2.0, 0.5127866119608023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 612223.0596424909, 612223.0596424905, 144941.022547382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537200.0000, 
sim time next is 1537800.0000, 
raw observation next is [26.2, 66.5, 1.0, 2.0, 0.5105627510353288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610379.2742631013, 610379.2742631013, 144616.6385040554], 
processed observation next is [0.0, 0.8260869565217391, 0.5259259259259259, 0.665, 1.0, 1.0, 0.4173366083753914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2179925979511076, 0.2179925979511076, 0.2781089202001065], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.2222726], dtype=float32), 1.000073]. 
=============================================
[2019-03-23 23:24:48,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.0268133e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:24:48,381] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4659
[2019-03-23 23:24:48,388] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 84.33333333333334, 1.0, 2.0, 0.5165251653410867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648033.2476901554, 648033.2476901554, 146399.5357370795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1570800.0000, 
sim time next is 1571400.0000, 
raw observation next is [20.05, 85.0, 1.0, 2.0, 0.5093079375004854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639345.0963212316, 639345.0963212316, 145241.2631753161], 
processed observation next is [1.0, 0.17391304347826086, 0.29814814814814816, 0.85, 1.0, 1.0, 0.4158427827386731, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22833753440043986, 0.22833753440043986, 0.2793101214909925], 
reward next is 0.7207, 
noisyNet noise sample is [array([1.8325143], dtype=float32), 0.9504523]. 
=============================================
[2019-03-23 23:24:51,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3564204e-22 1.0000000e+00 2.4374441e-36 0.0000000e+00 3.0813561e-38], sum to 1.0000
[2019-03-23 23:24:51,077] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1109
[2019-03-23 23:24:51,081] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 44.0, 1.0, 2.0, 0.35713598722127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447043.3988951675, 447043.3988951675, 122834.1684784435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1620000.0000, 
sim time next is 1620600.0000, 
raw observation next is [27.08333333333334, 44.33333333333334, 1.0, 2.0, 0.3618470403954392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453092.8986665614, 453092.8986665614, 123467.662899306], 
processed observation next is [1.0, 0.782608695652174, 0.5586419753086422, 0.4433333333333334, 1.0, 1.0, 0.24029409570885618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1618188923809148, 0.1618188923809148, 0.23743781326789615], 
reward next is 0.7626, 
noisyNet noise sample is [array([0.7725332], dtype=float32), -0.09040423]. 
=============================================
[2019-03-23 23:24:56,463] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.633558e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:24:56,468] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0500
[2019-03-23 23:24:56,472] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 79.83333333333334, 1.0, 2.0, 0.3800923904239326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473223.5969294467, 473223.5969294467, 125898.2061617515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1727400.0000, 
sim time next is 1728000.0000, 
raw observation next is [21.4, 80.0, 1.0, 2.0, 0.3792892726903206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 472291.0501568278, 472291.0501568273, 125789.2108271674], 
processed observation next is [1.0, 0.0, 0.3481481481481481, 0.8, 1.0, 1.0, 0.2610586579646674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16867537505600994, 0.16867537505600977, 0.24190232851378346], 
reward next is 0.7581, 
noisyNet noise sample is [array([0.96281743], dtype=float32), 0.7413339]. 
=============================================
[2019-03-23 23:24:56,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.1794]
 [77.1794]
 [77.1794]
 [77.1794]
 [77.1794]], R is [[77.16570282]
 [77.15193176]
 [77.13806915]
 [77.12405396]
 [77.10979462]].
[2019-03-23 23:25:06,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.980081e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:25:06,700] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5275
[2019-03-23 23:25:06,706] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.61666666666667, 89.83333333333333, 1.0, 2.0, 0.4334155368112574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 536385.2346796136, 536385.2346796131, 133411.782846542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1930200.0000, 
sim time next is 1930800.0000, 
raw observation next is [20.73333333333333, 89.66666666666667, 1.0, 2.0, 0.6183258064372523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 764007.4104922903, 764007.4104922898, 163562.4307178027], 
processed observation next is [1.0, 0.34782608695652173, 0.3234567901234567, 0.8966666666666667, 1.0, 1.0, 0.5456259600443479, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2728597894615322, 0.27285978946153205, 0.31454313599577444], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.9814284], dtype=float32), 0.09133871]. 
=============================================
[2019-03-23 23:25:10,256] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6565077e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:10,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-23 23:25:10,270] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333333, 90.33333333333334, 1.0, 2.0, 0.3579401869639867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449433.3822047869, 449433.3822047865, 122964.054278972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1993200.0000, 
sim time next is 1993800.0000, 
raw observation next is [19.41666666666667, 90.16666666666666, 1.0, 2.0, 0.3558367490951517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446994.0100493766, 446994.0100493766, 122686.2727968426], 
processed observation next is [0.0, 0.043478260869565216, 0.2746913580246915, 0.9016666666666666, 1.0, 1.0, 0.23313898701803779, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15964071787477735, 0.15964071787477735, 0.2359351399939281], 
reward next is 0.7641, 
noisyNet noise sample is [array([0.10471894], dtype=float32), 0.7013188]. 
=============================================
[2019-03-23 23:25:10,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1807913e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:10,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3282
[2019-03-23 23:25:10,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 88.66666666666667, 1.0, 2.0, 0.6042063688133398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 703352.4951790023, 703352.4951790018, 159505.0486598809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2186400.0000, 
sim time next is 2187000.0000, 
raw observation next is [24.35, 88.5, 1.0, 2.0, 0.5998071704423842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697854.7797410656, 697854.7797410651, 158724.1953770493], 
processed observation next is [1.0, 0.30434782608695654, 0.4574074074074075, 0.885, 1.0, 1.0, 0.5235799648123621, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24923384990752342, 0.24923384990752326, 0.30523883726355633], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.4913977], dtype=float32), 1.9492685]. 
=============================================
[2019-03-23 23:25:10,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.32956]
 [74.32956]
 [74.32956]
 [74.32956]
 [74.32956]], R is [[74.28102875]
 [74.23147583]
 [74.17189026]
 [74.13033295]
 [74.0903244 ]].
[2019-03-23 23:25:15,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9710925e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:15,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5190
[2019-03-23 23:25:15,506] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 89.0, 1.0, 2.0, 0.4335741194609855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530227.5143461027, 530227.5143461027, 133272.3660401231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086200.0000, 
sim time next is 2086800.0000, 
raw observation next is [21.4, 89.66666666666667, 1.0, 2.0, 0.432385788827361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528907.501738096, 528907.501738096, 133102.2056423074], 
processed observation next is [0.0, 0.13043478260869565, 0.3481481481481481, 0.8966666666666667, 1.0, 1.0, 0.32426879622304877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18889553633503428, 0.18889553633503428, 0.2559657800813604], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.16019684], dtype=float32), 0.6110163]. 
=============================================
[2019-03-23 23:25:17,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3308092e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:17,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9098
[2019-03-23 23:25:17,651] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 94.0, 1.0, 2.0, 0.4223334168373572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517898.7626031915, 517898.7626031915, 131676.5697465199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092800.0000, 
sim time next is 2093400.0000, 
raw observation next is [20.85, 93.5, 1.0, 2.0, 0.4241409264303296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519658.4891345546, 519658.4891345546, 131925.744499537], 
processed observation next is [0.0, 0.21739130434782608, 0.32777777777777783, 0.935, 1.0, 1.0, 0.3144534838456305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18559231754805522, 0.18559231754805522, 0.2537033548068019], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.7646562], dtype=float32), 1.5987766]. 
=============================================
[2019-03-23 23:25:18,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5378656e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:18,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6629
[2019-03-23 23:25:18,171] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 45.0, 1.0, 2.0, 0.5449509052264665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637752.2500287021, 637752.2500287021, 149645.4993120064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2134800.0000, 
sim time next is 2135400.0000, 
raw observation next is [31.81666666666667, 46.16666666666666, 1.0, 2.0, 0.5514531866084407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644599.5955474618, 644599.5955474613, 150682.9823092593], 
processed observation next is [0.0, 0.7391304347826086, 0.7339506172839507, 0.46166666666666656, 1.0, 1.0, 0.46601569834338175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23021414126695064, 0.23021414126695047, 0.2897749659793448], 
reward next is 0.7102, 
noisyNet noise sample is [array([0.9255111], dtype=float32), -1.9289322]. 
=============================================
[2019-03-23 23:25:35,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2131216e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:25:35,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1399
[2019-03-23 23:25:35,171] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.509812359784565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607377.6794736056, 607377.6794736056, 144419.8956623308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3111000.0000, 
sim time next is 3111600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5082033126191244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 605491.9333228176, 605491.9333228171, 144165.8066066599], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 1.0, 1.0, 0.41452775311800527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2162471190438634, 0.21624711904386323, 0.27724193578203826], 
reward next is 0.7228, 
noisyNet noise sample is [array([1.5399542], dtype=float32), 1.4455494]. 
=============================================
[2019-03-23 23:25:35,622] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 23:25:35,624] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:25:35,626] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:25:35,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:35,628] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:25:35,629] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:25:35,631] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:25:35,631] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:35,630] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:35,632] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:35,631] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:35,653] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 23:25:35,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 23:25:35,703] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 23:25:35,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 23:25:35,756] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 23:25:52,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:25:52,158] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.58093463666667, 97.621385705, 1.0, 2.0, 0.4005814250829539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496123.7833870261, 496123.7833870261, 128696.204216631]
[2019-03-23 23:25:52,158] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:25:52,162] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7252189205119445
[2019-03-23 23:25:54,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:25:54,811] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.13859774833333, 83.65035835166667, 1.0, 2.0, 0.2849983374167919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365708.4279946415, 365708.4279946415, 113741.2591205954]
[2019-03-23 23:25:54,812] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:25:54,815] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5801126089997486
[2019-03-23 23:25:57,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:25:57,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.2, 62.0, 1.0, 2.0, 0.5165174966652265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615338.3590598828, 615338.3590598828, 145487.3588015352]
[2019-03-23 23:25:57,465] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:25:57,466] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.39996885480930433
[2019-03-23 23:26:10,954] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:26:10,955] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.479954225, 43.575314685, 1.0, 2.0, 0.3133883050249309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396755.1209065467, 396755.1209065467, 117226.3393175549]
[2019-03-23 23:26:10,958] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:26:10,961] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7707498063965088
[2019-03-23 23:26:30,907] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:26:30,909] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.4, 69.33333333333334, 1.0, 2.0, 0.7336630176908976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 836189.2231071142, 836189.2231071137, 182619.5385405546]
[2019-03-23 23:26:30,910] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:26:30,914] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2988513607297506
[2019-03-23 23:26:34,931] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:26:34,932] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.226047965, 54.254018845, 1.0, 2.0, 0.5844807779106476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668847.0589088382, 668847.0589088382, 155566.6223792029]
[2019-03-23 23:26:34,933] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:26:34,937] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7856435380709258
[2019-03-23 23:27:06,076] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7954601]
[2019-03-23 23:27:06,077] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 49.0, 1.0, 2.0, 0.6952536573497554, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9904133351754165, 6.9112, 6.9112, 121.9260426156618, 1513742.416732754, 1513742.416732754, 315107.6947144666]
[2019-03-23 23:27:06,078] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:27:06,080] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.8536944e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8187880647476345
[2019-03-23 23:27:06,082] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1513742.416732754 W.
[2019-03-23 23:27:19,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:27:19,391] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:27:19,518] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:27:19,610] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:27:19,655] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:27:20,671] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1975000, evaluation results [1975000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:27:21,327] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6388343e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:21,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6994
[2019-03-23 23:27:21,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1640336.746912886 W.
[2019-03-23 23:27:21,346] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [35.0, 23.0, 1.0, 2.0, 0.4610788048321195, 1.0, 2.0, 0.4610788048321195, 1.0, 2.0, 0.7400832490585367, 6.9112, 6.9112, 121.94756008, 1640336.746912886, 1640336.746912886, 324786.7008589637], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2469600.0000, 
sim time next is 2470200.0000, 
raw observation next is [34.93333333333334, 23.0, 1.0, 2.0, 0.5924497791890047, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9585612833112694, 6.911199999999999, 6.9112, 121.9260426156618, 1430827.754976633, 1430827.754976633, 288303.5830859738], 
processed observation next is [1.0, 0.6086956521739131, 0.8493827160493829, 0.23, 1.0, 1.0, 0.514821165701196, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9482016041390867, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5110099124916546, 0.5110099124916546, 0.5544299674730265], 
reward next is 0.4456, 
noisyNet noise sample is [array([-2.328978], dtype=float32), 1.1770338]. 
=============================================
[2019-03-23 23:27:32,863] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0637167e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:32,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4663
[2019-03-23 23:27:32,877] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5489646878266121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646354.8074278297, 646354.8074278297, 150468.9682860523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2682000.0000, 
sim time next is 2682600.0000, 
raw observation next is [23.05, 92.83333333333334, 1.0, 2.0, 0.5424671020889597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640015.9270082418, 640015.9270082418, 149453.8017534663], 
processed observation next is [0.0, 0.043478260869565216, 0.40925925925925927, 0.9283333333333335, 1.0, 1.0, 0.4553179786773329, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22857711678865777, 0.22857711678865777, 0.2874111572182044], 
reward next is 0.7126, 
noisyNet noise sample is [array([-1.0817487], dtype=float32), 0.085387595]. 
=============================================
[2019-03-23 23:27:42,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7180948e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:42,720] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1527
[2019-03-23 23:27:42,729] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1525740.387371822 W.
[2019-03-23 23:27:42,735] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.65, 86.5, 1.0, 2.0, 0.4460219436869456, 1.0, 2.0, 0.4460219436869456, 1.0, 2.0, 0.710081460270216, 6.9112, 6.9112, 121.94756008, 1525740.387371822, 1525740.387371822, 317828.6798494877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2892600.0000, 
sim time next is 2893200.0000, 
raw observation next is [24.76666666666667, 87.33333333333333, 1.0, 2.0, 0.4194263885362488, 1.0, 2.0, 0.4194263885362488, 1.0, 2.0, 0.667740470313545, 6.9112, 6.9112, 121.94756008, 1434677.791437577, 1434677.791437577, 305696.5040554212], 
processed observation next is [1.0, 0.4782608695652174, 0.4728395061728396, 0.8733333333333333, 1.0, 1.0, 0.3088409387336295, 1.0, 1.0, 0.3088409387336295, 1.0, 1.0, 0.5846755878919312, 0.0, 0.0, 0.8096049824067558, 0.5123849255134204, 0.5123849255134204, 0.5878778924142716], 
reward next is 0.4121, 
noisyNet noise sample is [array([1.6866012], dtype=float32), -0.6158826]. 
=============================================
[2019-03-23 23:27:44,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0273810e-22 1.0000000e+00 2.4648862e-37 3.6856378e-37 1.1154277e-37], sum to 1.0000
[2019-03-23 23:27:44,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9088
[2019-03-23 23:27:44,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 89.0, 1.0, 2.0, 0.6598484439921382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752018.113839408, 752018.113839408, 168679.8826275056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2933400.0000, 
sim time next is 2934000.0000, 
raw observation next is [25.3, 89.0, 1.0, 2.0, 0.6507398556777464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741632.1879140491, 741632.1879140491, 167025.783518373], 
processed observation next is [1.0, 1.0, 0.49259259259259264, 0.89, 1.0, 1.0, 0.584214113902079, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26486863854073184, 0.26486863854073184, 0.321203429843025], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.3352101], dtype=float32), 0.50753677]. 
=============================================
[2019-03-23 23:27:45,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.855766]
 [51.855766]
 [51.855766]
 [51.855766]
 [51.855766]], R is [[52.01600647]
 [52.17146301]
 [52.32236862]
 [52.46941757]
 [52.61337662]].
[2019-03-23 23:27:45,980] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2636215e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:45,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3169
[2019-03-23 23:27:45,993] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.8251272356298684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940499.1306660377, 940499.1306660377, 201181.6076131642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947800.0000, 
sim time next is 2948400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.795110088513358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906264.6610070218, 906264.6610070218, 194927.6578652557], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7560834387063785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3236659503596506, 0.3236659503596506, 0.3748608805101071], 
reward next is 0.6251, 
noisyNet noise sample is [array([-0.40970105], dtype=float32), -0.5573333]. 
=============================================
[2019-03-23 23:27:51,220] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7789611e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:51,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9344
[2019-03-23 23:27:51,239] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 98.16666666666667, 1.0, 2.0, 0.5101875044030053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607290.5358897154, 607290.5358897154, 144458.6980109983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3045000.0000, 
sim time next is 3045600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4846311793082476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583048.2446076545, 583048.2446076545, 140678.6613099667], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3864656896526757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20823151593130518, 0.20823151593130518, 0.27053588713455134], 
reward next is 0.7295, 
noisyNet noise sample is [array([-0.01729866], dtype=float32), -1.1628438]. 
=============================================
[2019-03-23 23:27:52,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4898694e-24 1.0000000e+00 1.3506667e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:27:52,650] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4866
[2019-03-23 23:27:52,656] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1522716.240177412 W.
[2019-03-23 23:27:52,658] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 76.33333333333334, 1.0, 2.0, 0.6677080352994307, 1.0, 1.0, 0.6677080352994307, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1522716.240177412, 1522716.240177413, 292124.2334695643], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [31.0, 75.66666666666666, 1.0, 2.0, 0.6561641307074912, 1.0, 2.0, 0.6561641307074912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1496364.504915244, 1496364.504915245, 287906.2748701594], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.7566666666666666, 1.0, 1.0, 0.5906715841755849, 1.0, 1.0, 0.5906715841755849, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5344158946125871, 0.5344158946125875, 0.553665913211845], 
reward next is 0.4463, 
noisyNet noise sample is [array([-0.66950804], dtype=float32), -1.3278095]. 
=============================================
[2019-03-23 23:27:57,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.378753e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:27:57,429] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2221
[2019-03-23 23:27:57,433] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 75.0, 1.0, 2.0, 0.5732290422503387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667768.7041838819, 667768.7041838823, 154218.4133774266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3817200.0000, 
sim time next is 3817800.0000, 
raw observation next is [26.3, 73.0, 1.0, 2.0, 0.5644940898804863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660367.1454318785, 660367.1454318785, 152872.7495798923], 
processed observation next is [0.0, 0.17391304347826086, 0.5296296296296297, 0.73, 1.0, 1.0, 0.48154058319105514, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23584540908281376, 0.23584540908281376, 0.29398605688440826], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.49273646], dtype=float32), 1.1627293]. 
=============================================
[2019-03-23 23:28:05,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9793572e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:28:05,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5308
[2019-03-23 23:28:05,855] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 89.5, 1.0, 2.0, 0.5411211575120652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 638371.5911602963, 638371.5911602959, 149231.2170256189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3313800.0000, 
sim time next is 3314400.0000, 
raw observation next is [23.7, 89.33333333333333, 1.0, 2.0, 0.5462342034884574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 642806.7945335443, 642806.7945335439, 150005.585231488], 
processed observation next is [0.0, 0.34782608695652173, 0.4333333333333333, 0.8933333333333333, 1.0, 1.0, 0.45980262320054455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22957385519055154, 0.22957385519055137, 0.2884722792913231], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.78566176], dtype=float32), -0.91866755]. 
=============================================
[2019-03-23 23:28:07,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2510192e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:28:07,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1805
[2019-03-23 23:28:07,618] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666667, 77.33333333333333, 1.0, 2.0, 0.6630909740381354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755715.3921742433, 755715.3921742433, 169273.2585985254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3334200.0000, 
sim time next is 3334800.0000, 
raw observation next is [27.73333333333333, 76.66666666666667, 1.0, 2.0, 0.6725027176248161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766447.1857683905, 766447.1857683905, 171003.1903993582], 
processed observation next is [0.0, 0.6086956521739131, 0.5827160493827159, 0.7666666666666667, 1.0, 1.0, 0.6101222828866858, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2737311377744252, 0.2737311377744252, 0.32885228922953497], 
reward next is 0.6711, 
noisyNet noise sample is [array([-0.11700455], dtype=float32), -0.680751]. 
=============================================
[2019-03-23 23:28:07,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.682553e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:28:07,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7948
[2019-03-23 23:28:07,870] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.7087376391138634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807765.6617891369, 807765.6617891369, 177805.2038524174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3351000.0000, 
sim time next is 3351600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7060024309188142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804646.6416343995, 804646.6416343995, 177283.5934532998], 
processed observation next is [0.0, 0.8260869565217391, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6500028939509693, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28737380058371415, 0.28737380058371415, 0.3409299874101919], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.16908696], dtype=float32), -0.34141332]. 
=============================================
[2019-03-23 23:28:08,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4354461e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:28:08,429] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7829
[2019-03-23 23:28:08,434] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 82.33333333333334, 1.0, 2.0, 0.6836873258452459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779200.6936159167, 779200.6936159167, 173078.1763028464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3357600.0000, 
sim time next is 3358200.0000, 
raw observation next is [26.96666666666667, 83.16666666666666, 1.0, 2.0, 0.6928554004809137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789654.9607325121, 789654.9607325121, 174795.6478156993], 
processed observation next is [0.0, 0.8695652173913043, 0.554320987654321, 0.8316666666666666, 1.0, 1.0, 0.6343516672391829, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28201962883304005, 0.28201962883304005, 0.3361454765686525], 
reward next is 0.6639, 
noisyNet noise sample is [array([0.40162572], dtype=float32), 1.7634286]. 
=============================================
[2019-03-23 23:28:09,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2746575e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:28:09,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7771
[2019-03-23 23:28:09,827] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.7087376391138634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807765.6617891369, 807765.6617891369, 177805.2038524174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3351000.0000, 
sim time next is 3351600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7060024309188142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804646.6416343995, 804646.6416343995, 177283.5934532998], 
processed observation next is [0.0, 0.8260869565217391, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6500028939509693, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28737380058371415, 0.28737380058371415, 0.3409299874101919], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.8354993], dtype=float32), -0.8591795]. 
=============================================
[2019-03-23 23:28:10,732] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:28:10,733] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:28:10,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:28:10,734] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:28:10,735] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:28:10,736] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:28:10,737] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:28:10,738] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:28:10,739] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:28:10,740] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:28:10,741] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:28:10,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 23:28:10,788] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 23:28:10,789] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 23:28:10,840] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 23:28:10,841] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 23:28:56,332] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.77935183]
[2019-03-23 23:28:56,333] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.8578896, 30.49426596166667, 1.0, 2.0, 0.7902393180092667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 947771.0050124063, 947771.0050124053, 196116.5993594757]
[2019-03-23 23:28:56,334] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:28:56,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.6612598e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7712305524637464
[2019-03-23 23:29:54,945] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:29:55,401] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:29:55,435] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:29:55,622] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:29:55,685] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:29:56,703] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2000000, evaluation results [2000000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:29:59,238] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5266600e-20 1.0000000e+00 1.9578815e-31 4.8128177e-35 7.8396519e-34], sum to 1.0000
[2019-03-23 23:29:59,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6591
[2019-03-23 23:29:59,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.687556671858564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783612.8541800531, 783612.8541800531, 173801.0932862964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445800.0000, 
sim time next is 3446400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6880079618401421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 784127.4554207048, 784127.4554207039, 173885.559573154], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6285809069525501, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2800455197931089, 0.28004551979310854, 0.33439530687144997], 
reward next is 0.6656, 
noisyNet noise sample is [array([0.60563934], dtype=float32), 0.50473654]. 
=============================================
[2019-03-23 23:30:05,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4354672e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:05,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1614
[2019-03-23 23:30:05,587] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6493440275759913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740040.6291007247, 740040.6291007247, 166774.7896785205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3535200.0000, 
sim time next is 3535800.0000, 
raw observation next is [26.18333333333333, 79.50000000000001, 1.0, 2.0, 0.6215720065471262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711885.312990757, 711885.312990757, 162001.1530302078], 
processed observation next is [1.0, 0.9565217391304348, 0.5253086419753085, 0.7950000000000002, 1.0, 1.0, 0.549490483984674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2542447546395561, 0.2542447546395561, 0.31154067890424575], 
reward next is 0.6885, 
noisyNet noise sample is [array([1.7706184], dtype=float32), 0.13546403]. 
=============================================
[2019-03-23 23:30:08,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0384863e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:08,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-23 23:30:09,002] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 72.0, 1.0, 2.0, 0.579787430937748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675223.980189638, 675223.980189638, 155320.1993962217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808800.0000, 
sim time next is 3809400.0000, 
raw observation next is [26.58333333333333, 72.33333333333333, 1.0, 2.0, 0.5731643605778134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668825.050354991, 668825.050354991, 154257.5633832238], 
processed observation next is [0.0, 0.08695652173913043, 0.5401234567901233, 0.7233333333333333, 1.0, 1.0, 0.4918623340212064, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2388660894124968, 0.2388660894124968, 0.2966491603523535], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.8077393], dtype=float32), -1.1792233]. 
=============================================
[2019-03-23 23:30:09,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.505291e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:30:09,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8107
[2019-03-23 23:30:09,964] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6094632921911061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701868.0557538342, 701868.0557538342, 160069.8898919813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4310400.0000, 
sim time next is 4311000.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6108317038106827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703440.2113786127, 703440.2113786127, 160308.3437909443], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5367044092984318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2512286469209331, 0.2512286469209331, 0.3082852765210467], 
reward next is 0.6917, 
noisyNet noise sample is [array([1.5817602], dtype=float32), 0.013553645]. 
=============================================
[2019-03-23 23:30:09,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.24964]
 [67.24964]
 [67.24964]
 [67.24964]
 [67.24964]], R is [[67.26885986]
 [67.28834534]
 [67.30768585]
 [67.32714844]
 [67.34676361]].
[2019-03-23 23:30:13,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.031248e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:30:13,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5768
[2019-03-23 23:30:13,968] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7161779667802015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 816250.1009816426, 816250.1009816421, 179225.0833507559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3738000.0000, 
sim time next is 3738600.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7115210916734526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 810939.7091208806, 810939.709120881, 178332.4423425056], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6565727281826816, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2896213246860288, 0.28962132468602897, 0.3429470045048184], 
reward next is 0.6571, 
noisyNet noise sample is [array([1.5424207], dtype=float32), 0.43422326]. 
=============================================
[2019-03-23 23:30:15,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4560997e-23 1.0000000e+00 1.1762225e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:15,657] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7402
[2019-03-23 23:30:15,662] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4358984806353341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534721.4216754317, 534721.4216754317, 133658.4226802251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4062600.0000, 
sim time next is 4063200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4343319192227653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 532803.6449466487, 532803.6449466483, 133428.5425492016], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 1.0, 1.0, 0.3265856181223397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19028701605237455, 0.19028701605237439, 0.25659335105615694], 
reward next is 0.7434, 
noisyNet noise sample is [array([-0.11703949], dtype=float32), 0.42089283]. 
=============================================
[2019-03-23 23:30:18,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.084101e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:30:18,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2045
[2019-03-23 23:30:18,465] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 71.0, 1.0, 2.0, 0.5551715643455029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652211.1241779516, 652211.1241779516, 151436.3703513848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3818400.0000, 
sim time next is 3819000.0000, 
raw observation next is [26.5, 69.0, 1.0, 2.0, 0.5437893144275144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641550.8922792011, 641550.8922792011, 149669.6512489198], 
processed observation next is [0.0, 0.17391304347826086, 0.5370370370370371, 0.69, 1.0, 1.0, 0.4568920409851362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22912531867114325, 0.22912531867114325, 0.28782625240176885], 
reward next is 0.7122, 
noisyNet noise sample is [array([1.4986826], dtype=float32), 0.03802846]. 
=============================================
[2019-03-23 23:30:18,490] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.0329]
 [69.0329]
 [69.0329]
 [69.0329]
 [69.0329]], R is [[69.05474091]
 [69.07297516]
 [69.08826447]
 [69.10080719]
 [69.11069489]].
[2019-03-23 23:30:18,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5430659e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:18,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4687
[2019-03-23 23:30:19,002] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 59.0, 1.0, 2.0, 0.6135837868754735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703500.6134347584, 703500.6134347584, 160639.2923472571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834000.0000, 
sim time next is 3834600.0000, 
raw observation next is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.6263506300250398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714206.8510819931, 714206.8510819931, 162688.3900677504], 
processed observation next is [0.0, 0.391304347826087, 0.6728395061728393, 0.5966666666666667, 1.0, 1.0, 0.5551793214583807, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2550738753864261, 0.2550738753864261, 0.31286228859182774], 
reward next is 0.6871, 
noisyNet noise sample is [array([0.06320135], dtype=float32), 0.8583971]. 
=============================================
[2019-03-23 23:30:21,728] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00754584e-25 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 23:30:21,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9974
[2019-03-23 23:30:21,748] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 96.0, 1.0, 2.0, 0.6432201923596365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734674.6909072524, 734674.6909072524, 165752.6029487009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [24.25, 94.0, 1.0, 2.0, 0.6277624505740885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719807.7341837866, 719807.7341837866, 163135.641455112], 
processed observation next is [1.0, 0.9565217391304348, 0.4537037037037037, 0.94, 1.0, 1.0, 0.5568600602072482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2570741907799238, 0.2570741907799238, 0.3137223874136769], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.36258876], dtype=float32), 0.30556783]. 
=============================================
[2019-03-23 23:30:39,680] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1033040e-21 1.0000000e+00 8.2892071e-33 3.4915307e-36 1.1670474e-36], sum to 1.0000
[2019-03-23 23:30:39,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-23 23:30:39,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1703461.169176089 W.
[2019-03-23 23:30:39,696] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.05, 32.5, 1.0, 2.0, 0.7304209899145298, 1.0, 2.0, 0.7304209899145298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1703461.169176089, 1703461.169176089, 317709.8660175038], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4203000.0000, 
sim time next is 4203600.0000, 
raw observation next is [34.03333333333333, 33.0, 1.0, 2.0, 0.7126374920824435, 1.0, 2.0, 0.7126374920824435, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1658847.952742482, 1658847.952742482, 310642.5578713915], 
processed observation next is [1.0, 0.6521739130434783, 0.8160493827160493, 0.33, 1.0, 1.0, 0.6579017762886232, 1.0, 1.0, 0.6579017762886232, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5924456974080293, 0.5924456974080293, 0.5973895343680605], 
reward next is 0.4026, 
noisyNet noise sample is [array([-0.5695974], dtype=float32), -1.1222969]. 
=============================================
[2019-03-23 23:30:40,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.47288e-25 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 23:30:40,967] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4247
[2019-03-23 23:30:40,971] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 63.33333333333333, 1.0, 2.0, 0.4596972703242607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558505.5430934534, 558505.5430934534, 137050.1222168395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4236000.0000, 
sim time next is 4236600.0000, 
raw observation next is [25.83333333333334, 60.66666666666666, 1.0, 2.0, 0.4475809465096103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546189.3536171968, 546189.3536171968, 135307.2122418234], 
processed observation next is [1.0, 0.0, 0.5123456790123458, 0.6066666666666666, 1.0, 1.0, 0.342358269654298, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.195067626291856, 0.195067626291856, 0.26020617738812196], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.35496703], dtype=float32), 0.01819056]. 
=============================================
[2019-03-23 23:30:45,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8187421e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:45,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5704
[2019-03-23 23:30:45,870] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 75.66666666666667, 1.0, 2.0, 0.5520562436333247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649187.8237337567, 649187.8237337563, 150947.2108553022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4317000.0000, 
sim time next is 4317600.0000, 
raw observation next is [25.8, 77.33333333333334, 1.0, 2.0, 0.5633121973548753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 658612.8718541499, 658612.8718541494, 152659.6501633433], 
processed observation next is [1.0, 1.0, 0.5111111111111112, 0.7733333333333334, 1.0, 1.0, 0.4801335682796134, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23521888280505351, 0.23521888280505335, 0.2935762503141217], 
reward next is 0.7064, 
noisyNet noise sample is [array([1.6489754], dtype=float32), 0.14018185]. 
=============================================
[2019-03-23 23:30:46,647] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 23:30:46,648] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:30:46,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:46,652] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:30:46,654] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:30:46,654] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:46,655] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:46,656] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:30:46,655] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:30:46,658] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:46,658] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:46,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 23:30:46,704] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 23:30:46,730] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 23:30:46,731] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 23:30:46,776] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 23:30:57,287] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7844523]
[2019-03-23 23:30:57,289] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 56.0, 1.0, 2.0, 0.2477074353462903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 319520.6635215422, 319520.6635215422, 102667.3683558863]
[2019-03-23 23:30:57,291] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:30:57,294] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5011103e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5609290056669904
[2019-03-23 23:31:21,797] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7844523]
[2019-03-23 23:31:21,798] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.16666666666666, 24.0, 1.0, 2.0, 0.8083121726433482, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9571551336403754, 6.9112, 6.9112, 121.9260426156618, 1697063.327370145, 1697063.327370145, 327465.9912095335]
[2019-03-23 23:31:21,802] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:31:21,804] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5011103e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9847153178635862
[2019-03-23 23:31:21,805] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1697063.327370145 W.
[2019-03-23 23:31:42,903] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7844523]
[2019-03-23 23:31:42,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.09380339, 80.24382857, 1.0, 2.0, 0.754170622309971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866076.1898256964, 866076.1898256964, 186984.2014014004]
[2019-03-23 23:31:42,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:31:42,908] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.5011103e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9806487944704871
[2019-03-23 23:32:22,573] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7844523]
[2019-03-23 23:32:22,576] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.83333333333334, 78.0, 1.0, 2.0, 0.8295511077946167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1016203.440701442, 1016203.440701442, 205202.5843017852]
[2019-03-23 23:32:22,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:32:22,579] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5011103e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.341827813871281
[2019-03-23 23:32:29,964] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.7844523]
[2019-03-23 23:32:29,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.11666666666667, 63.83333333333334, 1.0, 2.0, 0.4785426117043484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577387.0667054808, 577387.0667054808, 139796.1238798991]
[2019-03-23 23:32:29,967] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:32:29,970] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.5011103e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8274147177852602
[2019-03-23 23:32:30,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:32:30,634] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:32:30,746] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:32:30,776] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:32:30,845] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:32:31,860] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2025000, evaluation results [2025000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:32:34,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4331892e-21 1.0000000e+00 2.1351373e-35 0.0000000e+00 1.9562032e-37], sum to 1.0000
[2019-03-23 23:32:34,191] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1709
[2019-03-23 23:32:34,195] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 50.66666666666667, 1.0, 2.0, 0.4462103057109566, 1.0, 2.0, 0.4462103057109566, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1017252.58948707, 1017252.58948707, 219249.0749678339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4381800.0000, 
sim time next is 4382400.0000, 
raw observation next is [32.06666666666667, 52.33333333333334, 1.0, 2.0, 0.6168467827445356, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702987.3754579806, 702987.3754579806, 161000.4039133526], 
processed observation next is [1.0, 0.7391304347826086, 0.74320987654321, 0.5233333333333334, 1.0, 1.0, 0.5438652175530186, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25106691980642165, 0.25106691980642165, 0.30961616137183195], 
reward next is 0.6904, 
noisyNet noise sample is [array([-0.38473147], dtype=float32), -0.23642386]. 
=============================================
[2019-03-23 23:32:43,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.087598e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:32:43,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0905
[2019-03-23 23:32:43,140] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 92.66666666666666, 1.0, 2.0, 0.6052485081550651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697663.0296351592, 697663.0296351587, 159367.6272525587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545600.0000, 
sim time next is 4546200.0000, 
raw observation next is [23.6, 96.33333333333334, 1.0, 2.0, 0.5989772276898916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692333.2739733598, 692333.2739733598, 158371.5832707838], 
processed observation next is [0.0, 0.6086956521739131, 0.4296296296296297, 0.9633333333333334, 1.0, 1.0, 0.5225919377260614, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24726188356191423, 0.24726188356191423, 0.3045607370591996], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.29836318], dtype=float32), 1.411114]. 
=============================================
[2019-03-23 23:32:54,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.637254e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:32:54,913] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4152
[2019-03-23 23:32:54,918] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1542743.239548811 W.
[2019-03-23 23:32:54,930] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.9, 93.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.615890172909142, 6.9112, 121.9237209840415, 1542743.239548811, 1181885.757856536, 246646.8589371103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4782000.0000, 
sim time next is 4782600.0000, 
raw observation next is [23.9, 93.5, 1.0, 2.0, 0.6551880887837752, 1.0, 1.0, 0.6551880887837752, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256182628544, 1494136.501412994, 1494136.501412994, 287547.8457608538], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.935, 1.0, 1.0, 0.5895096295044943, 1.0, 0.5, 0.5895096295044943, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094593115587906, 0.5336201790760693, 0.5336201790760693, 0.5529766264631804], 
reward next is 0.4470, 
noisyNet noise sample is [array([-1.7434633], dtype=float32), -1.3770666]. 
=============================================
[2019-03-23 23:33:12,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3612476e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:33:12,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4125
[2019-03-23 23:33:12,878] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.8633119045024922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984050.8455976768, 984050.8455976768, 209382.1818688658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065200.0000, 
sim time next is 5065800.0000, 
raw observation next is [31.83333333333334, 71.66666666666667, 1.0, 2.0, 0.8284606687385568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944300.9958549596, 944300.9958549596, 201904.3485119912], 
processed observation next is [0.0, 0.6521739130434783, 0.7345679012345682, 0.7166666666666667, 1.0, 1.0, 0.7957865104030438, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33725035566248557, 0.33725035566248557, 0.3882775932922908], 
reward next is 0.6117, 
noisyNet noise sample is [array([-1.2029862], dtype=float32), 0.3480727]. 
=============================================
[2019-03-23 23:33:12,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7202063e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:33:12,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1684
[2019-03-23 23:33:12,976] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 94.66666666666667, 1.0, 2.0, 0.7437036388320024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847639.3053379781, 847639.3053379781, 184585.9693264507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095200.0000, 
sim time next is 5095800.0000, 
raw observation next is [26.15, 96.0, 1.0, 2.0, 0.7499639071000209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854778.450888112, 854778.450888112, 185822.457047293], 
processed observation next is [0.0, 1.0, 0.524074074074074, 0.96, 1.0, 1.0, 0.702337984642882, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3052780181743257, 0.3052780181743257, 0.35735087893710193], 
reward next is 0.6426, 
noisyNet noise sample is [array([0.2223259], dtype=float32), -0.17832334]. 
=============================================
[2019-03-23 23:33:21,751] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 23:33:21,754] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:33:21,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:33:21,756] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:33:21,756] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:33:21,758] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:33:21,761] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:33:21,762] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:33:21,762] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:33:21,764] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:33:21,764] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:33:21,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 23:33:21,812] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 23:33:21,835] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 23:33:21,859] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 23:33:21,894] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 23:33:33,059] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:33:33,060] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.5, 19.5, 1.0, 2.0, 0.6466484586568244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 804569.535272872, 804569.5352728715, 168849.887282231]
[2019-03-23 23:33:33,065] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:33:33,070] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.26010075056877
[2019-03-23 23:33:42,387] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:33:42,388] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.79886173, 23.77630264, 1.0, 2.0, 0.3232300281537749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416964.6053096773, 416964.6053096773, 117019.2202382298]
[2019-03-23 23:33:42,389] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:33:42,392] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4905651255577991
[2019-03-23 23:34:00,218] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:34:00,219] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.96164365, 53.77864816, 1.0, 2.0, 0.6722357839581672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766142.8110823882, 766142.8110823882, 170957.7378356117]
[2019-03-23 23:34:00,219] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:34:00,221] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05646998234590983
[2019-03-23 23:34:47,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:34:47,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666666, 91.5, 1.0, 2.0, 0.5238753002827216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618961.6850618664, 618961.6850618664, 146470.1636111499]
[2019-03-23 23:34:47,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:34:47,479] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7643292363499605
[2019-03-23 23:34:48,091] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:34:48,092] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 92.33333333333334, 1.0, 2.0, 0.5132507791039707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606883.0684677681, 606883.0684677681, 144790.0420420775]
[2019-03-23 23:34:48,093] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:34:48,095] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6835758881802041
[2019-03-23 23:34:51,188] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:34:51,190] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666666, 94.0, 1.0, 2.0, 0.6013748964640909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685347.0099875702, 685347.0099875702, 158314.4823587722]
[2019-03-23 23:34:51,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:34:51,194] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7246005667559278
[2019-03-23 23:34:52,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:34:52,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.91666666666667, 66.0, 1.0, 2.0, 0.5653579400012011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 656481.7496376657, 656481.7496376652, 152801.8566412835]
[2019-03-23 23:34:52,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:34:52,605] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9077008196616198
[2019-03-23 23:35:05,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8364731]
[2019-03-23 23:35:05,550] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.8, 47.0, 1.0, 2.0, 0.768003741366017, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9721018207037491, 6.911200000000001, 6.9112, 121.9260423223876, 1618458.330153227, 1618458.330153226, 325014.1994264815]
[2019-03-23 23:35:05,551] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:35:05,553] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7991492e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.46258414826517524
[2019-03-23 23:35:05,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1618458.330153227 W.
[2019-03-23 23:35:05,620] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:35:05,870] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:35:05,976] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:35:06,111] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:35:06,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:35:07,189] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2050000, evaluation results [2050000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:35:09,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4922461e-24 1.0000000e+00 2.1864428e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:09,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1341
[2019-03-23 23:35:09,094] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1300113.328224875 W.
[2019-03-23 23:35:09,097] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 76.16666666666666, 1.0, 2.0, 0.3801199786363013, 1.0, 1.0, 0.3801199786363013, 1.0, 2.0, 0.605163385632428, 6.911200000000001, 6.9112, 121.94756008, 1300113.328224875, 1300113.328224875, 288483.1331797414], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5313000.0000, 
sim time next is 5313600.0000, 
raw observation next is [25.9, 75.0, 1.0, 2.0, 0.4181702498249865, 1.0, 2.0, 0.4181702498249865, 1.0, 2.0, 0.6657406565756336, 6.9112, 6.9112, 121.94756008, 1430377.067848529, 1430377.067848529, 305133.1662760465], 
processed observation next is [1.0, 0.5217391304347826, 0.5148148148148147, 0.75, 1.0, 1.0, 0.3073455355059363, 1.0, 1.0, 0.3073455355059363, 1.0, 1.0, 0.582175820719542, 0.0, 0.0, 0.8096049824067558, 0.5108489528030461, 0.5108489528030461, 0.5867945505308586], 
reward next is 0.4132, 
noisyNet noise sample is [array([0.31289065], dtype=float32), -0.19196743]. 
=============================================
[2019-03-23 23:35:09,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4960139e-24 1.0000000e+00 1.1868684e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:09,511] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5506
[2019-03-23 23:35:09,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1802118.409706023 W.
[2019-03-23 23:35:09,520] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 66.0, 1.0, 2.0, 0.7900975356953619, 1.0, 2.0, 0.7900975356953619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802118.409706023, 1802118.409706024, 339678.48491198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [28.41666666666667, 66.16666666666667, 1.0, 2.0, 0.7834815109255091, 1.0, 2.0, 0.7834815109255091, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1787012.949916264, 1787012.949916264, 336974.9565245507], 
processed observation next is [1.0, 0.6956521739130435, 0.6080246913580248, 0.6616666666666667, 1.0, 1.0, 0.7422398939589394, 1.0, 1.0, 0.7422398939589394, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.63821891068438, 0.63821891068438, 0.6480287625472129], 
reward next is 0.3520, 
noisyNet noise sample is [array([0.72484547], dtype=float32), -0.32003456]. 
=============================================
[2019-03-23 23:35:16,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.826926e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:35:16,230] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0977
[2019-03-23 23:35:16,234] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 94.33333333333334, 1.0, 2.0, 0.8352997017439378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952101.1458761266, 952101.1458761266, 203343.3778693043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5458800.0000, 
sim time next is 5459400.0000, 
raw observation next is [26.15, 94.5, 1.0, 2.0, 0.8283836227333559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944213.1227147543, 944213.1227147543, 201876.3314903781], 
processed observation next is [1.0, 0.17391304347826086, 0.524074074074074, 0.945, 1.0, 1.0, 0.7956947889682808, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33721897239812654, 0.33721897239812654, 0.38822371440457326], 
reward next is 0.6118, 
noisyNet noise sample is [array([1.3771306], dtype=float32), 1.0923601]. 
=============================================
[2019-03-23 23:35:16,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.493661e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:35:16,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3447
[2019-03-23 23:35:16,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2051206.069043531 W.
[2019-03-23 23:35:16,485] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 79.83333333333334, 1.0, 2.0, 0.5994528206457318, 1.0, 2.0, 0.5994528206457318, 1.0, 2.0, 0.9543484132834148, 6.911199999999999, 6.9112, 121.94756008, 2051206.069043531, 2051206.069043531, 395077.5436531527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5413800.0000, 
sim time next is 5414400.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.5472470714470741, 1.0, 2.0, 0.5472470714470741, 1.0, 2.0, 0.871235160336599, 6.911199999999999, 6.9112, 121.94756008, 1872381.344473545, 1872381.344473545, 367383.1889635389], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.79, 1.0, 1.0, 0.4610084183893739, 1.0, 1.0, 0.4610084183893739, 1.0, 1.0, 0.8390439504207486, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6687076230262661, 0.6687076230262661, 0.7065061326221902], 
reward next is 0.2935, 
noisyNet noise sample is [array([0.12360889], dtype=float32), 1.413269]. 
=============================================
[2019-03-23 23:35:20,199] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6961979e-22 1.0000000e+00 5.2558069e-35 0.0000000e+00 7.1842364e-38], sum to 1.0000
[2019-03-23 23:35:20,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4797
[2019-03-23 23:35:20,213] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 81.0, 1.0, 2.0, 0.641962059292895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731623.5754788135, 731623.5754788135, 165447.5215935002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5509800.0000, 
sim time next is 5510400.0000, 
raw observation next is [26.76666666666667, 81.0, 1.0, 2.0, 0.6410002601058736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730526.9214723133, 730526.9214723133, 165275.0647920434], 
processed observation next is [1.0, 0.782608695652174, 0.5469135802469137, 0.81, 1.0, 1.0, 0.5726193572688971, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26090247195439764, 0.26090247195439764, 0.31783666306162195], 
reward next is 0.6822, 
noisyNet noise sample is [array([1.5244939], dtype=float32), -1.1239468]. 
=============================================
[2019-03-23 23:35:25,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1972378e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:25,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4527
[2019-03-23 23:35:25,201] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 98.0, 1.0, 2.0, 0.6041701363160488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695669.3708905322, 695669.3708905322, 159144.972806075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5616000.0000, 
sim time next is 5616600.0000, 
raw observation next is [23.6, 97.83333333333334, 1.0, 2.0, 0.6026864260618222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 694260.97663111, 694260.9766311095, 158902.2552543243], 
processed observation next is [0.0, 0.0, 0.4296296296296297, 0.9783333333333334, 1.0, 1.0, 0.5270076500735978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24795034879682498, 0.24795034879682482, 0.3055812601044698], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.8690104], dtype=float32), -0.05514721]. 
=============================================
[2019-03-23 23:35:26,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.825251e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:35:26,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3268
[2019-03-23 23:35:26,358] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 72.0, 1.0, 2.0, 0.9133858200065555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.997791541476759, 6.9112, 121.9256770218909, 1157150.817416429, 1112808.341676953, 223786.5583937281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5819400.0000, 
sim time next is 5820000.0000, 
raw observation next is [24.16666666666666, 70.0, 1.0, 2.0, 0.9246001724041987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.083156771902974, 6.9112, 121.925192952788, 1216704.941231122, 1128648.318337125, 226464.4636006141], 
processed observation next is [1.0, 0.34782608695652173, 0.45061728395061706, 0.7, 1.0, 1.0, 0.9102383004811889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.01719567719029742, 0.0, 0.809456487942241, 0.434537479011115, 0.4030886851204018, 0.4355085838473348], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6975353], dtype=float32), 1.464946]. 
=============================================
[2019-03-23 23:35:26,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.951385]
 [71.951385]
 [71.951385]
 [71.951385]
 [71.951385]], R is [[71.23188019]
 [70.65624237]
 [70.55590057]
 [70.54883575]
 [70.5674057 ]].
[2019-03-23 23:35:28,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4556335e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:28,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8841
[2019-03-23 23:35:28,171] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 82.0, 1.0, 2.0, 0.6941929828995457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 791180.2049876829, 791180.2049876829, 175048.5603713311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5655600.0000, 
sim time next is 5656200.0000, 
raw observation next is [27.51666666666667, 81.50000000000001, 1.0, 2.0, 0.6960844736896401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793337.0757349993, 793337.0757349993, 175405.2001375567], 
processed observation next is [0.0, 0.4782608695652174, 0.5746913580246914, 0.8150000000000002, 1.0, 1.0, 0.6381958020114763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2833346699053569, 0.2833346699053569, 0.33731769257222444], 
reward next is 0.6627, 
noisyNet noise sample is [array([1.0419468], dtype=float32), -0.2057729]. 
=============================================
[2019-03-23 23:35:28,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7314605e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:28,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6362
[2019-03-23 23:35:28,473] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 86.0, 1.0, 2.0, 0.3921456714410512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485742.5287856225, 485742.5287856225, 127514.9459905666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5979600.0000, 
sim time next is 5980200.0000, 
raw observation next is [21.11666666666667, 85.16666666666667, 1.0, 2.0, 0.4675507086204132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579070.6168296319, 579070.6168296319, 138535.9725546141], 
processed observation next is [1.0, 0.21739130434782608, 0.33765432098765447, 0.8516666666666667, 1.0, 1.0, 0.36613179597668244, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20681093458201139, 0.20681093458201139, 0.26641533183579635], 
reward next is 0.7336, 
noisyNet noise sample is [array([1.2194369], dtype=float32), -1.613738]. 
=============================================
[2019-03-23 23:35:40,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.473785e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:35:40,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-23 23:35:40,687] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.53333333333333, 54.33333333333333, 1.0, 2.0, 0.5078915440276419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597255.3749164442, 597255.3749164442, 143807.8940549585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198000.0000, 
sim time next is 6198600.0000, 
raw observation next is [29.41666666666667, 55.16666666666667, 1.0, 2.0, 0.52094957543727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611975.0662026751, 611975.0662026746, 145856.8316069666], 
processed observation next is [1.0, 0.7391304347826086, 0.6450617283950619, 0.5516666666666667, 1.0, 1.0, 0.42970187552055955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21856252364381254, 0.21856252364381237, 0.2804939069364742], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.2762154], dtype=float32), -1.08851]. 
=============================================
[2019-03-23 23:35:45,226] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6344594e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:45,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-23 23:35:45,236] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 85.0, 1.0, 2.0, 0.3968884688925918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491341.4294852311, 491341.4294852311, 128172.1928026815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5978400.0000, 
sim time next is 5979000.0000, 
raw observation next is [21.08333333333333, 85.5, 1.0, 2.0, 0.3938252417576234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 487686.4909610581, 487686.4909610576, 127746.3673702821], 
processed observation next is [1.0, 0.17391304347826086, 0.3364197530864196, 0.855, 1.0, 1.0, 0.27836338304478975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17417374677180647, 0.17417374677180628, 0.24566609109669635], 
reward next is 0.7543, 
noisyNet noise sample is [array([-1.0166266], dtype=float32), 0.46357578]. 
=============================================
[2019-03-23 23:35:45,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.65953]
 [70.65953]
 [70.65953]
 [70.65953]
 [70.65953]], R is [[70.70726776]
 [70.75371552]
 [70.79785156]
 [70.84109497]
 [70.87711334]].
[2019-03-23 23:35:50,294] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8363885e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:50,302] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1291
[2019-03-23 23:35:50,311] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1848043.950399637 W.
[2019-03-23 23:35:50,314] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.15, 53.83333333333333, 1.0, 2.0, 0.8102117287610278, 1.0, 2.0, 0.8102117287610278, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1848043.950399637, 1848043.950399637, 347990.6411657101], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6105000.0000, 
sim time next is 6105600.0000, 
raw observation next is [30.1, 54.0, 1.0, 2.0, 0.9183221940697021, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999997, 6.9112, 121.9260426156618, 1761999.749482666, 1761999.749482667, 360948.3857688344], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.54, 1.0, 1.0, 0.9027645167496453, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.6292856248152379, 0.6292856248152382, 0.6941315110939122], 
reward next is 0.3059, 
noisyNet noise sample is [array([-1.3303301], dtype=float32), -0.13893425]. 
=============================================
[2019-03-23 23:35:50,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.434378e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:35:50,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3634
[2019-03-23 23:35:50,624] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.76666666666667, 55.66666666666667, 1.0, 2.0, 0.2587730797464554, 1.0, 1.0, 0.2587730797464554, 1.0, 2.0, 0.4119751706071994, 6.911199999999999, 6.9112, 121.94756008, 884834.4398049577, 884834.4398049582, 240757.7920050532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6109800.0000, 
sim time next is 6110400.0000, 
raw observation next is [29.63333333333333, 56.33333333333334, 1.0, 2.0, 0.5404375020690002, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426089086, 624674.8621590579, 624674.8621590579, 148559.8880531587], 
processed observation next is [1.0, 0.7391304347826086, 0.6530864197530862, 0.5633333333333335, 1.0, 1.0, 0.4529017881773812, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621287753018, 0.22309816505680638, 0.22309816505680638, 0.2856920924099206], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.574252], dtype=float32), 0.48246598]. 
=============================================
[2019-03-23 23:35:56,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0460016e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:56,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-23 23:35:56,090] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 81.0, 1.0, 2.0, 0.6681746117919681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761512.0200732715, 761512.0200732715, 170205.4966929669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487200.0000, 
sim time next is 6487800.0000, 
raw observation next is [26.86666666666667, 81.33333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.699557060867017, 6.9112, 123.2783215422265, 2089377.014806439, 1163421.256322564, 245787.2865379783], 
processed observation next is [1.0, 0.08695652173913043, 0.5506172839506175, 0.8133333333333332, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.17883570608670168, 0.0, 0.818439854621556, 0.7462060767165853, 0.41550759154377287, 0.47266785872688133], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2323945], dtype=float32), 0.986385]. 
=============================================
[2019-03-23 23:35:56,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1802253e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:56,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4406
[2019-03-23 23:35:56,369] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 70.66666666666667, 1.0, 2.0, 0.5249036267935487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623049.5549639451, 623049.5549639451, 146748.3419761707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6214800.0000, 
sim time next is 6215400.0000, 
raw observation next is [25.75, 71.0, 1.0, 2.0, 0.5196669371210391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617860.3222015793, 617860.3222015793, 145945.6270350577], 
processed observation next is [1.0, 0.9565217391304348, 0.5092592592592593, 0.71, 1.0, 1.0, 0.4281749251440941, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22066440078627833, 0.22066440078627833, 0.280664667375111], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.07327266], dtype=float32), 0.3740751]. 
=============================================
[2019-03-23 23:35:56,876] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 23:35:56,878] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:35:56,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:56,880] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:35:56,882] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:56,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:35:56,882] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:35:56,884] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:56,886] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:56,884] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:35:56,888] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:56,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 23:35:56,932] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 23:35:56,967] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 23:35:56,988] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 23:35:57,012] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 23:36:02,663] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86005026]
[2019-03-23 23:36:02,665] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.119910005, 43.66744810666667, 1.0, 2.0, 0.2472919482625724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 318984.6105129915, 318984.610512992, 86516.95553069786]
[2019-03-23 23:36:02,666] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:36:02,670] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9044964e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.45689139445958504
[2019-03-23 23:36:32,957] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86005026]
[2019-03-23 23:36:32,958] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.7, 30.0, 1.0, 2.0, 0.5842056431985151, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9475482779284938, 6.9112, 6.9112, 121.9260426156618, 1412846.367108712, 1412846.367108712, 285435.6779703327]
[2019-03-23 23:36:32,959] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:36:32,962] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9044964e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3157969648182849
[2019-03-23 23:36:32,965] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1412846.367108712 W.
[2019-03-23 23:37:16,989] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86005026]
[2019-03-23 23:37:16,990] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.13333333333334, 67.5, 1.0, 2.0, 0.6021897337327808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692556.7966661617, 692556.7966661617, 158762.2040413034]
[2019-03-23 23:37:16,992] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:37:16,996] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9044964e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5841732031749539
[2019-03-23 23:37:29,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86005026]
[2019-03-23 23:37:29,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.6, 92.0, 1.0, 2.0, 0.546156205784938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639287.7139621954, 639287.7139621954, 149848.7590077444]
[2019-03-23 23:37:29,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:37:29,339] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.9044964e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8337671982104904
[2019-03-23 23:37:41,635] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:37:41,725] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:37:41,763] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:37:41,896] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:37:41,898] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:37:42,914] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2075000, evaluation results [2075000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:37:51,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.030252e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:37:51,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7259
[2019-03-23 23:37:51,012] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 57.5, 1.0, 2.0, 0.67133209902431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765112.3731389625, 765112.3731389625, 170788.4889134279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6359400.0000, 
sim time next is 6360000.0000, 
raw observation next is [31.6, 57.33333333333334, 1.0, 2.0, 0.685844854980039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781660.8904581597, 781660.8904581597, 173481.705084467], 
processed observation next is [0.0, 0.6086956521739131, 0.725925925925926, 0.5733333333333335, 1.0, 1.0, 0.6260057797381416, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.279164603735057, 0.279164603735057, 0.33361866362397496], 
reward next is 0.6664, 
noisyNet noise sample is [array([-0.0934846], dtype=float32), -0.19274697]. 
=============================================
[2019-03-23 23:37:51,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.6562]
 [69.6562]
 [69.6562]
 [69.6562]
 [69.6562]], R is [[69.62601471]
 [69.60131836]
 [69.57720184]
 [69.55164337]
 [69.52303314]].
[2019-03-23 23:37:57,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.0679386e-23 1.0000000e+00 2.2940958e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:37:57,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2244
[2019-03-23 23:37:57,053] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 84.66666666666667, 1.0, 2.0, 0.9904861571974659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.086043825605604, 6.9112, 121.9252101760082, 1218718.969493683, 1129183.914716933, 238435.8808624956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6495600.0000, 
sim time next is 6496200.0000, 
raw observation next is [26.4, 85.0, 1.0, 2.0, 1.000425924602333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.147283557313712, 6.9112, 121.924855344784, 1261442.03432134, 1140547.329307364, 240826.1897259796], 
processed observation next is [1.0, 0.17391304347826086, 0.5333333333333333, 0.85, 1.0, 1.0, 1.0005070530980156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.023608355731371232, 0.0, 0.809454246576182, 0.4505150122576214, 0.4073383318954872, 0.4631272879345762], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38955095], dtype=float32), 0.10739086]. 
=============================================
[2019-03-23 23:38:02,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9696316e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:38:02,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6904
[2019-03-23 23:38:02,753] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 87.0, 1.0, 2.0, 0.7129743152034809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812596.865011365, 812596.865011365, 178616.7014523228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6550800.0000, 
sim time next is 6551400.0000, 
raw observation next is [26.86666666666667, 87.5, 1.0, 2.0, 0.7153424939674907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815297.3804265403, 815297.3804265403, 179070.7939855519], 
processed observation next is [1.0, 0.8260869565217391, 0.5506172839506175, 0.875, 1.0, 1.0, 0.6611220166279651, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29117763586662154, 0.29117763586662154, 0.3443669115106767], 
reward next is 0.6556, 
noisyNet noise sample is [array([-1.0341471], dtype=float32), -0.9811213]. 
=============================================
[2019-03-23 23:38:04,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.092978e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:38:04,076] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9551
[2019-03-23 23:38:04,079] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333333, 49.16666666666667, 1.0, 2.0, 0.9068795427957995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.16488950445054, 6.9112, 121.9246544953968, 1273724.784869151, 1143814.563116341, 223284.3733989524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6616200.0000, 
sim time next is 6616800.0000, 
raw observation next is [24.3, 52.0, 1.0, 2.0, 0.873256532260161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.949253699488906, 6.9112, 121.9254664739502, 1123290.301577648, 1103803.498320421, 215631.7879760214], 
processed observation next is [1.0, 0.6086956521739131, 0.4555555555555556, 0.52, 1.0, 1.0, 0.8491149193573345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.003805369948890558, 0.0, 0.8094583038383161, 0.4011751077063028, 0.3942155351144361, 0.4146765153385027], 
reward next is 0.3951, 
noisyNet noise sample is [array([1.2143962], dtype=float32), -0.7950535]. 
=============================================
[2019-03-23 23:38:08,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4668144e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:38:08,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5769
[2019-03-23 23:38:08,208] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.35, 95.0, 1.0, 2.0, 0.6452197994579677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 804938.6865809015, 804938.6865809006, 168630.9595551532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7378200.0000, 
sim time next is 7378800.0000, 
raw observation next is [19.4, 95.0, 1.0, 2.0, 0.6981069180562071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870322.4737780566, 870322.4737780566, 178635.6637911167], 
processed observation next is [1.0, 0.391304347826087, 0.274074074074074, 0.95, 1.0, 1.0, 0.640603473876437, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3108294549207345, 0.3108294549207345, 0.3435301226752244], 
reward next is 0.6565, 
noisyNet noise sample is [array([1.169715], dtype=float32), 1.4582978]. 
=============================================
[2019-03-23 23:38:19,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1075496e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:38:19,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4916
[2019-03-23 23:38:19,400] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 74.0, 1.0, 2.0, 0.4140996273262837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510471.8530456901, 510471.8530456901, 130561.5018996468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6916800.0000, 
sim time next is 6917400.0000, 
raw observation next is [22.95, 74.5, 1.0, 2.0, 0.4152814203104522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511761.0708367186, 511761.0708367186, 130726.7361765173], 
processed observation next is [0.0, 0.043478260869565216, 0.4055555555555555, 0.745, 1.0, 1.0, 0.30390645275053835, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1827718110131138, 0.1827718110131138, 0.2513975695702256], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.8807475], dtype=float32), -0.34443796]. 
=============================================
[2019-03-23 23:38:32,683] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 23:38:32,684] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:38:32,684] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:38:32,686] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:32,686] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:38:32,686] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:32,687] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:32,687] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:38:32,688] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:38:32,692] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:32,692] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:32,714] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 23:38:32,741] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 23:38:32,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 23:38:32,770] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 23:38:32,800] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 23:38:55,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.88719815]
[2019-03-23 23:38:55,518] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.892780145, 65.00698769499999, 1.0, 2.0, 0.3911496487667685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486486.9497276582, 486486.9497276582, 127419.4214400894]
[2019-03-23 23:38:55,519] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:38:55,522] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5570976e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.320021166722413
[2019-03-23 23:38:56,635] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.88719815]
[2019-03-23 23:38:56,638] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.438520065, 86.917385165, 1.0, 2.0, 0.2531011531277211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326086.2065920451, 326086.2065920451, 109967.8905676474]
[2019-03-23 23:38:56,639] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:38:56,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5570976e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7745381034191529
[2019-03-23 23:39:04,154] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.88719815]
[2019-03-23 23:39:04,154] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.7, 74.0, 1.0, 2.0, 0.8262742240745239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156583, 1007196.263308412, 1007196.263308411, 204333.2374204374]
[2019-03-23 23:39:04,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:39:04,160] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5570976e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.17700606730522828
[2019-03-23 23:39:48,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.88719815]
[2019-03-23 23:39:48,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.85331136, 88.23549269833335, 1.0, 2.0, 0.77678404706831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885364.6154407407, 885364.6154407403, 191197.0979308401]
[2019-03-23 23:39:48,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:39:48,289] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5570976e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.04698046281527912
[2019-03-23 23:39:50,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.88719815]
[2019-03-23 23:39:50,717] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.73333333333333, 76.66666666666667, 1.0, 2.0, 0.6095280963450842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698922.9598184916, 698922.9598184916, 159935.3533061932]
[2019-03-23 23:39:50,719] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:39:50,724] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5570976e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9895751518609882
[2019-03-23 23:40:17,077] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:40:17,218] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:40:17,273] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:40:17,315] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:40:17,534] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:40:18,550] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2100000, evaluation results [2100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:40:25,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:40:25,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:25,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 23:40:27,468] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2104650: loss 0.0254
[2019-03-23 23:40:27,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2104650: learning rate 0.0010
[2019-03-23 23:40:28,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.392072e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:29,007] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-23 23:40:29,013] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 96.0, 1.0, 2.0, 0.4538887796130949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550094.4537530483, 550094.4537530483, 136135.4869646743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [21.15, 96.0, 1.0, 2.0, 0.4521709072016236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548422.7231916204, 548422.7231916204, 135891.4139870474], 
processed observation next is [0.0, 0.043478260869565216, 0.33888888888888885, 0.96, 1.0, 1.0, 0.3478225085733615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19586525828272158, 0.19586525828272158, 0.26132964228278344], 
reward next is 0.7387, 
noisyNet noise sample is [array([1.0910368], dtype=float32), -1.0629416]. 
=============================================
[2019-03-23 23:40:29,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.58959]
 [74.58959]
 [74.58959]
 [74.58959]
 [74.58959]], R is [[74.58235931]
 [74.57473755]
 [74.56653595]
 [74.55786133]
 [74.54898071]].
[2019-03-23 23:40:29,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4598116e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:29,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8571
[2019-03-23 23:40:29,324] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4389197413244543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534678.0940801495, 534678.0940801495, 133997.6651840563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7526400.0000, 
sim time next is 7527000.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4387027754841036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534413.9669915632, 534413.9669915632, 133965.7295388391], 
processed observation next is [0.0, 0.08695652173913043, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3317890184334567, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19086213106841543, 0.19086213106841543, 0.257626402959306], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.6648971], dtype=float32), 2.1213982]. 
=============================================
[2019-03-23 23:40:29,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.11874]
 [74.11874]
 [74.11874]
 [74.11874]
 [74.11874]], R is [[74.11992645]
 [74.12104034]
 [74.12213898]
 [74.12319946]
 [74.12412262]].
[2019-03-23 23:40:36,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2441565e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:36,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-23 23:40:36,439] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 91.5, 1.0, 2.0, 0.3889128587222085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481037.2848531926, 481037.2848531926, 127049.0073877372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [20.63333333333333, 91.0, 1.0, 2.0, 0.3927702914876827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485072.1658291765, 485072.1658291765, 127568.5894328573], 
processed observation next is [0.0, 0.34782608695652173, 0.3197530864197529, 0.91, 1.0, 1.0, 0.27710748986628897, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1732400592247059, 0.1732400592247059, 0.2453242104478025], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.08400956], dtype=float32), 0.30178958]. 
=============================================
[2019-03-23 23:40:37,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.816836e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:37,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1563
[2019-03-23 23:40:37,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 79.33333333333334, 1.0, 2.0, 0.5165849728438026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612336.4326784036, 612336.4326784036, 145380.6292170055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7492800.0000, 
sim time next is 7493400.0000, 
raw observation next is [24.55, 80.0, 1.0, 2.0, 0.5147260736372311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 610344.1915545713, 610344.1915545708, 145092.2307306388], 
processed observation next is [0.0, 0.7391304347826086, 0.46481481481481485, 0.8, 1.0, 1.0, 0.4222929448062275, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21798006841234688, 0.2179800684123467, 0.27902352063584385], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.80123645], dtype=float32), 0.14414741]. 
=============================================
[2019-03-23 23:40:39,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.201997e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:39,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8934
[2019-03-23 23:40:39,318] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.46666666666667, 20.66666666666667, 1.0, 2.0, 0.3678579062778196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470530.52516416, 470530.52516416, 124372.9079445012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 240000.0000, 
sim time next is 240600.0000, 
raw observation next is [31.23333333333333, 21.33333333333334, 1.0, 2.0, 0.3670157485272285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469375.2921667987, 469375.2921667991, 124258.6576345839], 
processed observation next is [0.0, 0.782608695652174, 0.7123456790123456, 0.2133333333333334, 1.0, 1.0, 0.24644731967527206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16763403291671383, 0.16763403291671394, 0.23895895698958441], 
reward next is 0.7610, 
noisyNet noise sample is [array([0.45183864], dtype=float32), -0.549587]. 
=============================================
[2019-03-23 23:40:40,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5076413e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:40,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4290
[2019-03-23 23:40:40,726] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 62.0, 1.0, 2.0, 0.5300227987728848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625425.2358546399, 625425.2358546399, 147429.9848112595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7575600.0000, 
sim time next is 7576200.0000, 
raw observation next is [27.65, 62.0, 1.0, 2.0, 0.524970980968351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620714.3711427139, 620714.3711427139, 146664.6336514295], 
processed observation next is [0.0, 0.6956521739130435, 0.5796296296296296, 0.62, 1.0, 1.0, 0.43448926305756075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22168370397954068, 0.22168370397954068, 0.28204737240659516], 
reward next is 0.7180, 
noisyNet noise sample is [array([2.2031882], dtype=float32), -1.0498024]. 
=============================================
[2019-03-23 23:40:42,897] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2112633: loss 0.0492
[2019-03-23 23:40:42,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2112635: learning rate 0.0010
[2019-03-23 23:40:45,467] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:40:45,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:45,508] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 23:40:46,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2252195e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:46,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3914
[2019-03-23 23:40:46,180] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 66.0, 1.0, 2.0, 0.9411196654016792, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.088115904758467, 6.9112, 121.9252649862253, 1220164.355257005, 1129568.177271599, 229616.4945470785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7659000.0000, 
sim time next is 7659600.0000, 
raw observation next is [25.6, 66.0, 1.0, 2.0, 0.9667244989162226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.289616700062909, 6.9112, 121.9243434533689, 1360737.612866474, 1166957.14049724, 235962.7139576897], 
processed observation next is [1.0, 0.6521739130434783, 0.5037037037037038, 0.66, 1.0, 1.0, 0.9603863082335983, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.037841670006290865, 0.0, 0.8094508481495154, 0.4859777188808836, 0.41677040732044285, 0.453774449918634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1271081], dtype=float32), -0.3349249]. 
=============================================
[2019-03-23 23:40:47,290] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2114972: loss 0.0008
[2019-03-23 23:40:47,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2114972: learning rate 0.0010
[2019-03-23 23:40:48,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.018456e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:48,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2401
[2019-03-23 23:40:48,598] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 41.16666666666667, 1.0, 2.0, 0.3022922856753969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 387300.2554321137, 387300.2554321132, 115860.2984827703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 429000.0000, 
sim time next is 429600.0000, 
raw observation next is [24.96666666666667, 42.33333333333334, 1.0, 2.0, 0.2983812185605489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382314.767856197, 382314.767856197, 115376.7315955076], 
processed observation next is [1.0, 1.0, 0.48024691358024696, 0.42333333333333345, 1.0, 1.0, 0.16473954590541534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13654098852007038, 0.13654098852007038, 0.22187832999136078], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.76546234], dtype=float32), 0.56293076]. 
=============================================
[2019-03-23 23:40:52,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.772077e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:52,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1902
[2019-03-23 23:40:52,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1462208.481272832 W.
[2019-03-23 23:40:52,172] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 36.33333333333333, 1.0, 2.0, 0.6059966749364708, 1.0, 1.0, 0.6059966749364708, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260424312685, 1462208.481272832, 1462208.481272832, 273562.3464607833], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7825200.0000, 
sim time next is 7825800.0000, 
raw observation next is [30.5, 36.66666666666667, 1.0, 2.0, 0.6151061279789779, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9583286843961698, 6.911200000000001, 6.9112, 121.9260426156056, 1458801.415238886, 1458801.415238885, 291980.6348280796], 
processed observation next is [1.0, 0.5652173913043478, 0.6851851851851852, 0.3666666666666667, 1.0, 1.0, 0.5417930094987832, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9479108554952123, 8.881784197001253e-17, 0.0, 0.8094621288197628, 0.5210005054424592, 0.5210005054424589, 0.5615012208232301], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23683377], dtype=float32), 1.3064506]. 
=============================================
[2019-03-23 23:40:52,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:40:52,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:52,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 23:40:54,107] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2118348: loss 0.0733
[2019-03-23 23:40:54,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2118348: learning rate 0.0010
[2019-03-23 23:40:54,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0638955e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:54,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9627
[2019-03-23 23:40:54,317] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 54.66666666666667, 1.0, 2.0, 0.4366161652831812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532503.8509154575, 532503.8509154578, 133677.4889440345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7845000.0000, 
sim time next is 7845600.0000, 
raw observation next is [26.76666666666667, 56.33333333333334, 1.0, 2.0, 0.4370622439956717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532945.2151819244, 532945.2151819244, 133740.0268203064], 
processed observation next is [1.0, 0.8260869565217391, 0.5469135802469137, 0.5633333333333335, 1.0, 1.0, 0.329836004756752, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19033757685068728, 0.19033757685068728, 0.25719235926982], 
reward next is 0.7428, 
noisyNet noise sample is [array([-0.5937581], dtype=float32), -0.2563541]. 
=============================================
[2019-03-23 23:40:55,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1064723e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:55,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-23 23:40:55,088] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 85.0, 1.0, 2.0, 0.4143807996370593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514702.406284455, 514702.406284455, 130691.2325212486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7875600.0000, 
sim time next is 7876200.0000, 
raw observation next is [20.75, 85.5, 1.0, 2.0, 0.4114172587218946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511613.6507919726, 511613.6507919726, 130279.1432415095], 
processed observation next is [1.0, 0.13043478260869565, 0.32407407407407407, 0.855, 1.0, 1.0, 0.29930626038320784, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18271916099713306, 0.18271916099713306, 0.2505368139259798], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.22587107], dtype=float32), -1.3984588]. 
=============================================
[2019-03-23 23:40:55,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.190715e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:40:55,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3036
[2019-03-23 23:40:55,935] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 73.83333333333333, 1.0, 2.0, 0.3887099986312569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484560.4938643465, 484560.493864346, 127101.4624891581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890600.0000, 
sim time next is 7891200.0000, 
raw observation next is [22.3, 73.0, 1.0, 2.0, 0.3909878153811938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487350.0498356816, 487350.0498356816, 127417.6485808743], 
processed observation next is [1.0, 0.34782608695652173, 0.38148148148148153, 0.73, 1.0, 1.0, 0.27498549450142123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17405358922702915, 0.17405358922702915, 0.24503393957860442], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.7061579], dtype=float32), -0.7940004]. 
=============================================
[2019-03-23 23:40:58,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7866977e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:40:58,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9096
[2019-03-23 23:40:58,105] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 61.0, 1.0, 2.0, 0.9273593688128314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.114261723127182, 6.9112, 121.9251126013805, 1238404.655099842, 1134419.696579131, 227189.3218024149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7898400.0000, 
sim time next is 7899000.0000, 
raw observation next is [25.88333333333334, 60.0, 1.0, 2.0, 0.8761118273496423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257874513734, 1070160.014001258, 1070160.014001257, 215384.2348855563], 
processed observation next is [1.0, 0.43478260869565216, 0.5141975308641977, 0.6, 1.0, 1.0, 0.8525140801781457, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.809460434794613, 0.38220000500044926, 0.38220000500044893, 0.4142004517029929], 
reward next is 0.5858, 
noisyNet noise sample is [array([0.9057478], dtype=float32), 0.3968129]. 
=============================================
[2019-03-23 23:40:58,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.14721]
 [72.14721]
 [72.14721]
 [72.14721]
 [72.14721]], R is [[72.01153564]
 [71.29141998]
 [70.7552948 ]
 [70.04774475]
 [69.34726715]].
[2019-03-23 23:40:58,291] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2120372: loss 0.0346
[2019-03-23 23:40:58,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2120372: learning rate 0.0010
[2019-03-23 23:40:59,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:40:59,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:59,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 23:41:00,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,192] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 23:41:00,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 23:41:00,689] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,689] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,710] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 23:41:00,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 23:41:00,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 23:41:00,822] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,823] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,835] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 23:41:00,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:00,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:00,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 23:41:01,257] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2121677: loss 0.0007
[2019-03-23 23:41:01,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2121677: learning rate 0.0010
[2019-03-23 23:41:01,303] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121696: loss 0.0014
[2019-03-23 23:41:01,305] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121696: learning rate 0.0010
[2019-03-23 23:41:01,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:01,348] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:01,354] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 23:41:01,465] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:01,465] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:01,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 23:41:01,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:01,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:01,595] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 23:41:01,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:01,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:01,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 23:41:01,888] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2121841: loss 0.0007
[2019-03-23 23:41:01,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2121841: learning rate 0.0010
[2019-03-23 23:41:01,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1497955e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:41:01,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-23 23:41:01,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.6, 75.0, 1.0, 2.0, 0.2668291683464943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 344191.5410248222, 344191.5410248226, 110349.2012651284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7200.0000, 
sim time next is 7800.0000, 
raw observation next is [18.55, 75.16666666666667, 1.0, 2.0, 0.3705771552285159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478061.1256676101, 478061.1256676101, 123983.8816567004], 
processed observation next is [1.0, 0.08695652173913043, 0.2425925925925926, 0.7516666666666667, 1.0, 1.0, 0.25068708955775704, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17073611630986074, 0.17073611630986074, 0.23843054164750077], 
reward next is 0.7616, 
noisyNet noise sample is [array([1.6594555], dtype=float32), 0.27958086]. 
=============================================
[2019-03-23 23:41:02,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:41:02,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:02,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 23:41:02,207] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121930: loss 0.0023
[2019-03-23 23:41:02,208] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121930: learning rate 0.0010
[2019-03-23 23:41:02,416] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2122022: loss 0.0008
[2019-03-23 23:41:02,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2122022: learning rate 0.0010
[2019-03-23 23:41:02,498] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2122066: loss 0.0009
[2019-03-23 23:41:02,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2122066: learning rate 0.0010
[2019-03-23 23:41:02,597] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2122120: loss 0.0000
[2019-03-23 23:41:02,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2122120: learning rate 0.0010
[2019-03-23 23:41:02,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2122155: loss 0.0001
[2019-03-23 23:41:02,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2122155: learning rate 0.0010
[2019-03-23 23:41:02,706] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2122180: loss 0.0002
[2019-03-23 23:41:02,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2122181: learning rate 0.0010
[2019-03-23 23:41:02,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.506227e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:41:02,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4839
[2019-03-23 23:41:02,971] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.43333333333333, 14.16666666666667, 1.0, 2.0, 0.399597814056286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513743.9417870803, 513743.9417870798, 128763.3441137675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 227400.0000, 
sim time next is 228000.0000, 
raw observation next is [33.46666666666667, 14.33333333333333, 1.0, 2.0, 0.382249692349605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491139.5721728264, 491139.5721728264, 126339.8031222128], 
processed observation next is [0.0, 0.6521739130434783, 0.7950617283950618, 0.1433333333333333, 1.0, 1.0, 0.2645829670828631, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17540699006172372, 0.17540699006172372, 0.24296115985040925], 
reward next is 0.7570, 
noisyNet noise sample is [array([0.45567867], dtype=float32), 0.21557795]. 
=============================================
[2019-03-23 23:41:02,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.61372]
 [76.61372]
 [76.61372]
 [76.61372]
 [76.61372]], R is [[76.60462952]
 [76.59096527]
 [76.5825119 ]
 [76.57444763]
 [76.56680298]].
[2019-03-23 23:41:03,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8010364e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:41:03,075] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2215
[2019-03-23 23:41:03,078] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 48.0, 1.0, 2.0, 0.2910101450716173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375390.9958524862, 375390.9958524862, 113128.9627865281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 28800.0000, 
sim time next is 29400.0000, 
raw observation next is [23.03333333333333, 47.66666666666666, 1.0, 2.0, 0.3312920647367309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427174.6883726146, 427174.6883726146, 119516.0755628945], 
processed observation next is [1.0, 0.34782608695652173, 0.4086419753086419, 0.47666666666666657, 1.0, 1.0, 0.2039191246865844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15256238870450523, 0.15256238870450523, 0.2298386068517202], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.9901816], dtype=float32), 0.88906753]. 
=============================================
[2019-03-23 23:41:03,095] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122414: loss 0.0030
[2019-03-23 23:41:03,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122414: learning rate 0.0010
[2019-03-23 23:41:03,265] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2122511: loss 0.0073
[2019-03-23 23:41:03,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2122511: learning rate 0.0010
[2019-03-23 23:41:03,503] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2122644: loss 0.0193
[2019-03-23 23:41:03,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2122645: learning rate 0.0010
[2019-03-23 23:41:03,682] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2122730: loss 0.0125
[2019-03-23 23:41:03,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2122731: learning rate 0.0010
[2019-03-23 23:41:03,916] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2122837: loss 0.0333
[2019-03-23 23:41:03,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2122837: learning rate 0.0010
[2019-03-23 23:41:04,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.817641e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:41:04,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-23 23:41:04,941] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 75.16666666666667, 1.0, 2.0, 0.7130197368628025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9742978331686, 880005.1245360395, 880005.1245360391, 181345.1002761859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 94200.0000, 
sim time next is 94800.0000, 
raw observation next is [22.6, 75.33333333333334, 1.0, 2.0, 0.6054859004461701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747814.8281175683, 747814.8281175683, 161262.872185515], 
processed observation next is [1.0, 0.08695652173913043, 0.39259259259259266, 0.7533333333333334, 1.0, 1.0, 0.530340357674012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26707672432770296, 0.26707672432770296, 0.31012090804906733], 
reward next is 0.6899, 
noisyNet noise sample is [array([-0.18678579], dtype=float32), -1.6787179]. 
=============================================
[2019-03-23 23:41:05,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.608396e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:41:05,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3426
[2019-03-23 23:41:05,577] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333333, 52.83333333333334, 1.0, 2.0, 0.2449041700295523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 315903.9547290361, 315903.9547290361, 89447.6392724783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 276600.0000, 
sim time next is 277200.0000, 
raw observation next is [19.5, 53.0, 1.0, 2.0, 0.2437389128779365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 314400.5716231283, 314400.5716231283, 89049.32535301676], 
processed observation next is [0.0, 0.21739130434782608, 0.2777777777777778, 0.53, 1.0, 1.0, 0.09968918199754345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11228591843683154, 0.11228591843683154, 0.1712487026019553], 
reward next is 0.8288, 
noisyNet noise sample is [array([-0.12819263], dtype=float32), 1.6253872]. 
=============================================
[2019-03-23 23:41:07,406] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2124544: loss 0.0366
[2019-03-23 23:41:07,407] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2124544: learning rate 0.0010
[2019-03-23 23:41:08,319] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 23:41:08,320] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:41:08,321] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:41:08,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:08,323] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:08,327] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:41:08,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:41:08,328] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:08,328] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:08,328] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:41:08,329] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:41:08,348] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 23:41:08,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 23:41:08,401] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 23:41:08,431] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 23:41:08,454] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 23:42:04,123] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:04,124] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.6, 76.0, 1.0, 2.0, 0.60681409922574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691548.5039086458, 691548.5039086458, 159255.2248366926]
[2019-03-23 23:42:04,125] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:42:04,128] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5908893757592785
[2019-03-23 23:42:04,737] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:04,740] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.01546516, 104.8240118433333, 1.0, 2.0, 0.5951987228223342, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9475757510022722, 6.9112, 6.9112, 121.9260425427703, 1357211.354056814, 1357211.354056814, 292006.4092507903]
[2019-03-23 23:42:04,742] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:42:04,745] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2855043006130771
[2019-03-23 23:42:04,748] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1357211.354056814 W.
[2019-03-23 23:42:06,488] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:06,490] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.06666666666667, 88.0, 1.0, 2.0, 0.7423105203326241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846050.6163743304, 846050.6163743304, 184311.5662797164]
[2019-03-23 23:42:06,491] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:42:06,493] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7350495529091803
[2019-03-23 23:42:36,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:36,309] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.48543394333333, 97.52136922333332, 1.0, 2.0, 0.63133402738416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719505.4637754607, 719505.4637754607, 163557.5067764901]
[2019-03-23 23:42:36,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:42:36,314] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8240154912073202
[2019-03-23 23:42:43,164] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:43,164] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.0469791, 78.6013186, 1.0, 2.0, 0.3453618518898915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441091.3045939865, 441091.3045939865, 121364.2024002681]
[2019-03-23 23:42:43,165] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:42:43,167] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.20181170389638248
[2019-03-23 23:42:45,262] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.96495414]
[2019-03-23 23:42:45,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.08333333333334, 79.0, 1.0, 2.0, 0.9562466929099325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.006996892139298, 6.9112, 125.2238062111353, 1154364.865954462, 1103981.449835563, 231640.3054324938]
[2019-03-23 23:42:45,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:42:45,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3955276e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2759374658069299
[2019-03-23 23:42:52,933] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:42:53,130] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:42:53,304] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:42:53,397] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:42:53,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:42:54,433] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2125000, evaluation results [2125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:42:54,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4378693e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:42:54,954] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7750
[2019-03-23 23:42:54,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1621238.415591292 W.
[2019-03-23 23:42:54,966] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.34999999999999, 10.5, 1.0, 2.0, 0.6527012513139231, 1.0, 1.0, 0.6527012513139231, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1621238.415591292, 1621238.415591293, 291785.0919806312], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [37.33333333333333, 10.0, 1.0, 2.0, 0.4317563081703116, 1.0, 2.0, 0.4317563081703116, 1.0, 1.0, 0.7116494946066872, 6.911199999999999, 6.9112, 121.94756008, 1596472.759382336, 1596472.759382336, 309635.3618599308], 
processed observation next is [1.0, 0.6521739130434783, 0.9382716049382714, 0.1, 1.0, 1.0, 0.3235194144884662, 1.0, 1.0, 0.3235194144884662, 1.0, 0.5, 0.6395618682583589, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5701688426365485, 0.5701688426365485, 0.5954526189614053], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03238412], dtype=float32), 0.4855484]. 
=============================================
[2019-03-23 23:42:57,809] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2126739: loss 0.0125
[2019-03-23 23:42:57,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2126740: learning rate 0.0010
[2019-03-23 23:43:02,051] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2128929: loss 0.0024
[2019-03-23 23:43:02,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2128929: learning rate 0.0010
[2019-03-23 23:43:02,477] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2129146: loss 0.0037
[2019-03-23 23:43:02,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2129147: learning rate 0.0010
[2019-03-23 23:43:03,482] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2129660: loss 0.0003
[2019-03-23 23:43:03,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2129660: learning rate 0.0010
[2019-03-23 23:43:03,593] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2129719: loss 0.0005
[2019-03-23 23:43:03,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2129720: learning rate 0.0010
[2019-03-23 23:43:03,968] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2129914: loss 0.0035
[2019-03-23 23:43:03,972] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2129914: learning rate 0.0010
[2019-03-23 23:43:04,125] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2129996: loss 0.0016
[2019-03-23 23:43:04,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2129996: learning rate 0.0010
[2019-03-23 23:43:04,153] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2130006: loss 0.0059
[2019-03-23 23:43:04,156] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2130006: learning rate 0.0010
[2019-03-23 23:43:04,249] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2130062: loss 0.0009
[2019-03-23 23:43:04,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2130063: learning rate 0.0010
[2019-03-23 23:43:04,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2130158: loss 0.0379
[2019-03-23 23:43:04,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2130158: learning rate 0.0010
[2019-03-23 23:43:04,521] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8232642e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:04,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5743
[2019-03-23 23:43:04,530] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 30.33333333333334, 1.0, 2.0, 0.3340941402873989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427698.6664708984, 427698.666470898, 119893.5936040193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 319200.0000, 
sim time next is 319800.0000, 
raw observation next is [28.08333333333334, 30.16666666666666, 1.0, 2.0, 0.3342085996481317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427941.1182840086, 427941.1182840086, 119908.3782335972], 
processed observation next is [0.0, 0.6956521739130435, 0.5956790123456792, 0.3016666666666666, 1.0, 1.0, 0.20739119005729967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1528361136728602, 0.1528361136728602, 0.23059303506461], 
reward next is 0.7694, 
noisyNet noise sample is [array([0.13920268], dtype=float32), -0.60700667]. 
=============================================
[2019-03-23 23:43:05,016] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2130453: loss 0.0381
[2019-03-23 23:43:05,016] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2130453: loss 0.0231
[2019-03-23 23:43:05,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2130453: learning rate 0.0010
[2019-03-23 23:43:05,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2130454: learning rate 0.0010
[2019-03-23 23:43:05,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2130468: loss 0.0263
[2019-03-23 23:43:05,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2130468: learning rate 0.0010
[2019-03-23 23:43:05,635] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2130771: loss 0.0207
[2019-03-23 23:43:05,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2130772: learning rate 0.0010
[2019-03-23 23:43:05,675] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2130791: loss 0.0133
[2019-03-23 23:43:05,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2130794: learning rate 0.0010
[2019-03-23 23:43:05,957] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5512746e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:05,966] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9824
[2019-03-23 23:43:05,971] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 34.0, 1.0, 2.0, 0.3225186648836858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413657.0765227927, 413657.0765227927, 118403.5352944555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 327600.0000, 
sim time next is 328200.0000, 
raw observation next is [26.68333333333334, 34.33333333333334, 1.0, 2.0, 0.3216445827253943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 412609.0895792877, 412609.0895792873, 118291.8654268433], 
processed observation next is [0.0, 0.8260869565217391, 0.5438271604938274, 0.34333333333333343, 1.0, 1.0, 0.19243402705404086, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14736038913545987, 0.14736038913545974, 0.2274843565900833], 
reward next is 0.7725, 
noisyNet noise sample is [array([0.11875539], dtype=float32), 1.891325]. 
=============================================
[2019-03-23 23:43:09,035] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2132525: loss 0.1237
[2019-03-23 23:43:09,039] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2132526: learning rate 0.0010
[2019-03-23 23:43:13,189] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2134658: loss 0.0492
[2019-03-23 23:43:13,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2134659: learning rate 0.0010
[2019-03-23 23:43:16,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.066e-28 1.000e+00 0.000e+00 0.000e+00 0.000e+00], sum to 1.0000
[2019-03-23 23:43:16,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6772
[2019-03-23 23:43:16,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 39.66666666666667, 1.0, 2.0, 0.4881308579067671, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7957074094259194, 6.911199999999999, 6.9112, 121.9260426156618, 1188462.089124228, 1188462.089124228, 250296.3115301749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553200.0000, 
sim time next is 553800.0000, 
raw observation next is [29.1, 40.83333333333333, 1.0, 2.0, 0.9181455581014336, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.08823297792647, 6.9112, 121.9252568454711, 1220246.04942841, 1129589.925952435, 225243.9826178218], 
processed observation next is [1.0, 0.391304347826087, 0.6333333333333334, 0.40833333333333327, 1.0, 1.0, 0.90255423583504, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.01770329779264701, 0.0, 0.809456912123213, 0.4358021605101464, 0.40342497355444107, 0.4331615050342727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00335037], dtype=float32), 0.2895925]. 
=============================================
[2019-03-23 23:43:17,500] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2136888: loss 0.0177
[2019-03-23 23:43:17,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2136889: learning rate 0.0010
[2019-03-23 23:43:18,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2137210: loss 0.1216
[2019-03-23 23:43:18,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2137210: learning rate 0.0010
[2019-03-23 23:43:18,748] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.347922e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:43:18,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8910
[2019-03-23 23:43:18,763] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 45.0, 1.0, 2.0, 0.3531963990795027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444291.8388528557, 444291.8388528557, 122343.7950725963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 600000.0000, 
sim time next is 600600.0000, 
raw observation next is [26.28333333333333, 45.5, 1.0, 2.0, 0.3503931148352916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441085.5432829835, 441085.5432829835, 121976.4219694003], 
processed observation next is [1.0, 0.9565217391304348, 0.5290123456790122, 0.455, 1.0, 1.0, 0.22665847004201384, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1575305511724941, 0.1575305511724941, 0.23457004224884673], 
reward next is 0.7654, 
noisyNet noise sample is [array([-0.2983687], dtype=float32), 0.50699306]. 
=============================================
[2019-03-23 23:43:19,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.6837694e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:19,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8787
[2019-03-23 23:43:19,286] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2137807: loss 0.0002
[2019-03-23 23:43:19,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2137807: learning rate 0.0010
[2019-03-23 23:43:19,291] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 48.0, 1.0, 2.0, 0.3432226091050559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432905.5302585276, 432905.5302585276, 121042.6910095075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 603600.0000, 
sim time next is 604200.0000, 
raw observation next is [25.43333333333334, 48.5, 1.0, 2.0, 0.3426954274542354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432366.3658397129, 432366.3658397129, 120975.1182428139], 
processed observation next is [1.0, 1.0, 0.4975308641975311, 0.485, 1.0, 1.0, 0.21749455649313743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1544165592284689, 0.1544165592284689, 0.2326444581592575], 
reward next is 0.7674, 
noisyNet noise sample is [array([2.2673094], dtype=float32), 0.5642664]. 
=============================================
[2019-03-23 23:43:19,314] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2137820: loss 0.0003
[2019-03-23 23:43:19,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2137822: learning rate 0.0010
[2019-03-23 23:43:19,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137921: loss 0.0090
[2019-03-23 23:43:19,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137921: learning rate 0.0010
[2019-03-23 23:43:19,538] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137950: loss 0.0182
[2019-03-23 23:43:19,540] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137950: learning rate 0.0010
[2019-03-23 23:43:19,638] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2138009: loss 0.0296
[2019-03-23 23:43:19,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2138012: learning rate 0.0010
[2019-03-23 23:43:19,877] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2138158: loss 0.0089
[2019-03-23 23:43:19,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2138158: learning rate 0.0010
[2019-03-23 23:43:19,923] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2138183: loss 0.0001
[2019-03-23 23:43:19,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2138184: learning rate 0.0010
[2019-03-23 23:43:20,204] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2138329: loss 0.0070
[2019-03-23 23:43:20,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2138330: learning rate 0.0010
[2019-03-23 23:43:20,397] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2138425: loss 0.0068
[2019-03-23 23:43:20,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2138425: learning rate 0.0010
[2019-03-23 23:43:20,423] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2138436: loss 0.0100
[2019-03-23 23:43:20,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2138436: learning rate 0.0010
[2019-03-23 23:43:20,869] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2138660: loss 0.0482
[2019-03-23 23:43:20,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2138661: learning rate 0.0010
[2019-03-23 23:43:21,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.591826e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:43:21,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7857
[2019-03-23 23:43:21,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1413426.944023206 W.
[2019-03-23 23:43:21,068] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.13333333333334, 34.0, 1.0, 2.0, 0.5941852265387665, 1.0, 2.0, 0.5941852265387665, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1413426.944023206, 1413426.944023206, 268673.5736222427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [32.35, 33.0, 1.0, 2.0, 0.5682271767549225, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9169788889276895, 6.911199999999999, 6.9112, 121.9260426156618, 1362794.976606972, 1362794.976606973, 279929.798210096], 
processed observation next is [1.0, 0.4782608695652174, 0.7537037037037038, 0.33, 1.0, 1.0, 0.4859847342320506, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8962236111596119, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48671249164534713, 0.48671249164534747, 0.5383265350194154], 
reward next is 0.4617, 
noisyNet noise sample is [array([0.46864125], dtype=float32), 0.2016507]. 
=============================================
[2019-03-23 23:43:21,208] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2138819: loss 0.0095
[2019-03-23 23:43:21,210] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2138820: learning rate 0.0010
[2019-03-23 23:43:24,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2140574: loss 0.0107
[2019-03-23 23:43:24,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2140574: learning rate 0.0010
[2019-03-23 23:43:27,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.110176e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:43:27,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9189
[2019-03-23 23:43:27,964] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.06666666666667, 25.33333333333334, 1.0, 2.0, 0.3584612015369393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 454302.4301014823, 454302.4301014818, 123085.2476732173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756600.0000, 
sim time next is 757200.0000, 
raw observation next is [30.93333333333333, 25.66666666666667, 1.0, 2.0, 0.3595605037809761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 455751.360873438, 455751.3608734375, 123233.0844835735], 
processed observation next is [1.0, 0.782608695652174, 0.7012345679012344, 0.2566666666666667, 1.0, 1.0, 0.23757202831068583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.162768343169085, 0.1627683431690848, 0.23698670092994906], 
reward next is 0.7630, 
noisyNet noise sample is [array([-0.9608323], dtype=float32), 1.1652495]. 
=============================================
[2019-03-23 23:43:28,819] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2142523: loss 0.0440
[2019-03-23 23:43:28,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2142523: learning rate 0.0010
[2019-03-23 23:43:29,752] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6809261e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:29,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8372
[2019-03-23 23:43:29,766] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 44.66666666666666, 1.0, 2.0, 0.298045680332183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380038.7653004113, 380038.7653004113, 115333.4340579451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 780000.0000, 
sim time next is 780600.0000, 
raw observation next is [24.95, 45.33333333333334, 1.0, 2.0, 0.2988439798645069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 381081.9299182885, 381081.9299182885, 115431.9370505229], 
processed observation next is [0.0, 0.0, 0.47962962962962963, 0.4533333333333334, 1.0, 1.0, 0.16529045221965105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1361006892565316, 0.1361006892565316, 0.22198449432792866], 
reward next is 0.7780, 
noisyNet noise sample is [array([-0.7742726], dtype=float32), -0.04659397]. 
=============================================
[2019-03-23 23:43:30,576] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5229514e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:30,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1759
[2019-03-23 23:43:30,587] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 58.33333333333334, 1.0, 2.0, 0.3210496661510182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407055.6977871213, 407055.6977871213, 118200.810843074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 800400.0000, 
sim time next is 801000.0000, 
raw observation next is [23.2, 58.5, 1.0, 2.0, 0.3246328439728607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411211.0444537684, 411211.0444537684, 118654.5233008022], 
processed observation next is [0.0, 0.2608695652173913, 0.4148148148148148, 0.585, 1.0, 1.0, 0.19599148092007224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1468610873049173, 0.1468610873049173, 0.22818177557846578], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.384391], dtype=float32), -0.8647459]. 
=============================================
[2019-03-23 23:43:30,616] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.29283]
 [77.29283]
 [77.29283]
 [77.29283]
 [77.29283]], R is [[77.29172516]
 [77.29149628]
 [77.29219055]
 [77.29364777]
 [77.29558563]].
[2019-03-23 23:43:33,205] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2144668: loss 0.0055
[2019-03-23 23:43:33,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2144670: learning rate 0.0010
[2019-03-23 23:43:34,414] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2145264: loss 0.0363
[2019-03-23 23:43:34,416] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2145264: learning rate 0.0010
[2019-03-23 23:43:35,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2144406e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:35,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 23:43:35,338] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 64.66666666666667, 1.0, 2.0, 0.3630245296713652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454963.8137669302, 454963.8137669302, 123632.7191341527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 897000.0000, 
sim time next is 897600.0000, 
raw observation next is [23.3, 64.33333333333334, 1.0, 2.0, 0.3659421541361879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 458111.4296373353, 458111.4296373348, 124017.5790771113], 
processed observation next is [0.0, 0.391304347826087, 0.41851851851851857, 0.6433333333333334, 1.0, 1.0, 0.24516923111450942, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16361122487047688, 0.16361122487047672, 0.23849534437906017], 
reward next is 0.7615, 
noisyNet noise sample is [array([-2.0745087], dtype=float32), -0.16586389]. 
=============================================
[2019-03-23 23:43:35,485] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2145769: loss 0.0002
[2019-03-23 23:43:35,488] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2145770: learning rate 0.0010
[2019-03-23 23:43:35,582] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2145814: loss 0.0123
[2019-03-23 23:43:35,584] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2145814: learning rate 0.0010
[2019-03-23 23:43:35,894] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145968: loss 0.0003
[2019-03-23 23:43:35,897] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145969: learning rate 0.0010
[2019-03-23 23:43:35,909] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145976: loss 0.0001
[2019-03-23 23:43:35,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145976: learning rate 0.0010
[2019-03-23 23:43:36,114] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2146075: loss 0.0000
[2019-03-23 23:43:36,119] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2146077: learning rate 0.0010
[2019-03-23 23:43:36,152] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2146095: loss 0.0003
[2019-03-23 23:43:36,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2146095: learning rate 0.0010
[2019-03-23 23:43:36,359] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2146197: loss 0.0618
[2019-03-23 23:43:36,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2146198: learning rate 0.0010
[2019-03-23 23:43:36,571] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2146304: loss 0.0088
[2019-03-23 23:43:36,576] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2146305: learning rate 0.0010
[2019-03-23 23:43:36,945] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2146483: loss 0.0395
[2019-03-23 23:43:36,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2146484: learning rate 0.0010
[2019-03-23 23:43:37,014] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2146520: loss 0.0205
[2019-03-23 23:43:37,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2146521: learning rate 0.0010
[2019-03-23 23:43:37,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2146586: loss 0.0040
[2019-03-23 23:43:37,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2146587: learning rate 0.0010
[2019-03-23 23:43:37,740] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2146877: loss 0.0011
[2019-03-23 23:43:37,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2146877: learning rate 0.0010
[2019-03-23 23:43:38,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8728756e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:38,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8954
[2019-03-23 23:43:38,221] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333333, 80.33333333333334, 1.0, 2.0, 0.6155114232430022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779621.7673896962, 779621.7673896962, 163401.5418044946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680600.0000, 
sim time next is 1681200.0000, 
raw observation next is [19.9, 80.0, 1.0, 2.0, 0.6340060320216163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802864.5977711327, 802864.5977711322, 166754.9955444291], 
processed observation next is [1.0, 0.4782608695652174, 0.2925925925925925, 0.8, 1.0, 1.0, 0.564292895263829, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2867373563468331, 0.28673735634683295, 0.32068268373928677], 
reward next is 0.6793, 
noisyNet noise sample is [array([0.8113222], dtype=float32), 1.0888519]. 
=============================================
[2019-03-23 23:43:38,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.52945e-29 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 23:43:38,839] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1087
[2019-03-23 23:43:38,845] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 59.83333333333333, 1.0, 2.0, 0.3709213540838068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477056.3607776678, 477056.3607776678, 124782.7736748369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.36666666666667, 59.66666666666667, 1.0, 2.0, 0.3296747860436336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 423602.8250593706, 423602.8250593701, 119318.3496032123], 
processed observation next is [1.0, 0.2608695652173913, 0.3469135802469137, 0.5966666666666667, 1.0, 1.0, 0.20199379290908762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1512867232354895, 0.1512867232354893, 0.2294583646215621], 
reward next is 0.7705, 
noisyNet noise sample is [array([-1.785547], dtype=float32), -1.9193248]. 
=============================================
[2019-03-23 23:43:39,657] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1689769e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:39,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8638
[2019-03-23 23:43:39,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 49.33333333333334, 1.0, 2.0, 0.2971834060967605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380413.0980543584, 380413.0980543584, 115229.4504733886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 946200.0000, 
sim time next is 946800.0000, 
raw observation next is [23.5, 49.0, 1.0, 2.0, 0.2916937433939992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 373879.5588676313, 373879.5588676308, 114555.9105798371], 
processed observation next is [0.0, 1.0, 0.42592592592592593, 0.49, 1.0, 1.0, 0.15677826594523717, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13352841388129688, 0.13352841388129671, 0.22029982803814827], 
reward next is 0.7797, 
noisyNet noise sample is [array([0.80359507], dtype=float32), -0.87156653]. 
=============================================
[2019-03-23 23:43:41,212] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2148569: loss 0.1332
[2019-03-23 23:43:41,215] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2148570: learning rate 0.0010
[2019-03-23 23:43:43,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7290217e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:43:43,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-23 23:43:43,031] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 58.0, 1.0, 2.0, 0.285991218541871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366142.5894785766, 366142.5894785766, 113863.3991833415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039200.0000, 
sim time next is 1039800.0000, 
raw observation next is [22.0, 59.0, 1.0, 2.0, 0.2877707785766819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368210.2537563682, 368210.2537563682, 114079.2133687257], 
processed observation next is [1.0, 0.0, 0.37037037037037035, 0.59, 1.0, 1.0, 0.1521080697341451, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1315036620558458, 0.1315036620558458, 0.21938310263216482], 
reward next is 0.7806, 
noisyNet noise sample is [array([-1.3159785], dtype=float32), -0.888152]. 
=============================================
[2019-03-23 23:43:44,128] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:43:44,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:43:44,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:44,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:43:44,131] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:43:44,132] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:44,132] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:44,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:43:44,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:43:44,136] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:44,137] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:44,157] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 23:43:44,183] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 23:43:44,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 23:43:44,232] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 23:43:44,255] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 23:44:51,057] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.97508967]
[2019-03-23 23:44:51,058] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.26666666666667, 92.33333333333334, 1.0, 2.0, 0.7457997438222589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850029.6745064661, 850029.6745064661, 185003.2800598756]
[2019-03-23 23:44:51,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:44:51,062] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2804142e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9220006489891306
[2019-03-23 23:45:05,565] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.97508967]
[2019-03-23 23:45:05,566] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.35384364, 43.73069832, 1.0, 2.0, 0.6103034504538505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753265.9801258929, 753265.9801258929, 162106.2811511464]
[2019-03-23 23:45:05,567] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:45:05,571] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2804142e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9621216675039748
[2019-03-23 23:45:28,179] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:45:28,222] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:45:28,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:45:28,428] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:45:28,513] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:45:29,528] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2150000, evaluation results [2150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:45:30,861] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2150677: loss 0.0173
[2019-03-23 23:45:30,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2150677: learning rate 0.0010
[2019-03-23 23:45:31,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.331952e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:45:31,121] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5205
[2019-03-23 23:45:31,128] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 50.0, 1.0, 2.0, 0.3338246456458235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 420400.9854665766, 420400.9854665762, 119809.507890851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1100400.0000, 
sim time next is 1101000.0000, 
raw observation next is [25.05, 51.0, 1.0, 2.0, 0.3351694553965308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422306.2484225116, 422306.2484225116, 119986.5797259848], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.51, 1.0, 1.0, 0.20853506594825097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15082366015089702, 0.15082366015089702, 0.23074342254997077], 
reward next is 0.7693, 
noisyNet noise sample is [array([1.487476], dtype=float32), -0.04985165]. 
=============================================
[2019-03-23 23:45:31,141] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.15555]
 [71.15555]
 [71.15555]
 [71.15555]
 [71.15555]], R is [[71.21324158]
 [71.27070618]
 [71.32811737]
 [71.38346863]
 [71.40878296]].
[2019-03-23 23:45:34,773] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2152701: loss 0.0026
[2019-03-23 23:45:34,778] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2152701: learning rate 0.0010
[2019-03-23 23:45:35,858] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2153258: loss 0.0568
[2019-03-23 23:45:35,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2153258: learning rate 0.0010
[2019-03-23 23:45:36,814] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2153750: loss 0.0292
[2019-03-23 23:45:36,816] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2153751: learning rate 0.0010
[2019-03-23 23:45:37,055] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2153883: loss 0.0008
[2019-03-23 23:45:37,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2153884: learning rate 0.0010
[2019-03-23 23:45:37,169] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153933: loss 0.0081
[2019-03-23 23:45:37,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153934: learning rate 0.0010
[2019-03-23 23:45:37,252] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2153977: loss 0.0016
[2019-03-23 23:45:37,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2153978: learning rate 0.0010
[2019-03-23 23:45:37,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2153989: loss 0.0054
[2019-03-23 23:45:37,288] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2153990: learning rate 0.0010
[2019-03-23 23:45:37,312] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153999: loss 0.0190
[2019-03-23 23:45:37,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2154000: learning rate 0.0010
[2019-03-23 23:45:37,371] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2154036: loss 0.0311
[2019-03-23 23:45:37,378] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2154036: learning rate 0.0010
[2019-03-23 23:45:37,863] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2154289: loss 0.0058
[2019-03-23 23:45:37,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2154289: learning rate 0.0010
[2019-03-23 23:45:38,287] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2154508: loss 0.0078
[2019-03-23 23:45:38,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2154508: learning rate 0.0010
[2019-03-23 23:45:38,314] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2154523: loss 0.0048
[2019-03-23 23:45:38,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2154524: learning rate 0.0010
[2019-03-23 23:45:38,413] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2154571: loss 0.0051
[2019-03-23 23:45:38,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2154571: learning rate 0.0010
[2019-03-23 23:45:39,161] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2154955: loss 0.0498
[2019-03-23 23:45:39,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2154955: learning rate 0.0010
[2019-03-23 23:45:42,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2156545: loss 0.0052
[2019-03-23 23:45:42,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2156545: learning rate 0.0010
[2019-03-23 23:45:43,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3910688e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:45:43,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7330
[2019-03-23 23:45:43,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 69.0, 1.0, 2.0, 0.5081287035775254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 608206.1064550175, 608206.106455017, 144256.5027971114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1538400.0000, 
sim time next is 1539000.0000, 
raw observation next is [25.2, 71.5, 1.0, 2.0, 0.5048353941747977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 605144.8280509411, 605144.8280509406, 143766.1228044478], 
processed observation next is [0.0, 0.8260869565217391, 0.4888888888888889, 0.715, 1.0, 1.0, 0.4105183263985687, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21612315287533612, 0.21612315287533596, 0.27647331308547657], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.95721316], dtype=float32), -1.3870697]. 
=============================================
[2019-03-23 23:45:43,680] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.79991]
 [70.79991]
 [70.79991]
 [70.79991]
 [70.79991]], R is [[70.81543732]
 [70.8298645 ]
 [70.84346008]
 [70.85629272]
 [70.86794281]].
[2019-03-23 23:45:45,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4310746e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:45:45,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8264
[2019-03-23 23:45:45,938] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 57.0, 1.0, 2.0, 0.3657189214740841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458055.7255364552, 458055.7255364552, 123991.0969700316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1373400.0000, 
sim time next is 1374000.0000, 
raw observation next is [24.26666666666667, 58.0, 1.0, 2.0, 0.3640285552446775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456202.4737676824, 456202.4737676824, 123767.4706737285], 
processed observation next is [1.0, 0.9130434782608695, 0.4543209876543211, 0.58, 1.0, 1.0, 0.24289113719604463, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16292945491702943, 0.16292945491702943, 0.2380143666802471], 
reward next is 0.7620, 
noisyNet noise sample is [array([-1.3930234], dtype=float32), -0.23296803]. 
=============================================
[2019-03-23 23:45:45,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.30619]
 [70.30619]
 [70.30619]
 [70.30619]
 [70.30619]], R is [[70.36511993]
 [70.42302704]
 [70.47982788]
 [70.5355072 ]
 [70.590271  ]].
[2019-03-23 23:45:46,384] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2158653: loss 0.0628
[2019-03-23 23:45:46,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2158655: learning rate 0.0010
[2019-03-23 23:45:47,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7736313e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:45:47,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0411
[2019-03-23 23:45:47,536] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 46.0, 1.0, 2.0, 0.5493345185780555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 641942.7650608333, 641942.7650608328, 150325.7017229918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2133600.0000, 
sim time next is 2134200.0000, 
raw observation next is [31.91666666666667, 45.5, 1.0, 2.0, 0.5471608350031429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639865.7078387914, 639865.7078387914, 149988.087055216], 
processed observation next is [0.0, 0.6956521739130435, 0.7376543209876545, 0.455, 1.0, 1.0, 0.46090575595612254, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22852346708528265, 0.22852346708528265, 0.28843862895233846], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.649129], dtype=float32), -0.2929141]. 
=============================================
[2019-03-23 23:45:49,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1190213e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:45:49,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2570
[2019-03-23 23:45:49,736] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.95, 26.66666666666666, 1.0, 2.0, 0.3763876562115646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471808.0741199724, 471808.0741199724, 125448.4366130766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450200.0000, 
sim time next is 1450800.0000, 
raw observation next is [31.8, 27.0, 1.0, 2.0, 0.3750508425941144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 470268.3812071942, 470268.3812071938, 125267.7134060263], 
processed observation next is [0.0, 0.8260869565217391, 0.7333333333333334, 0.27, 1.0, 1.0, 0.2560129078501362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16795299328828364, 0.1679529932882835, 0.2408994488577429], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.26177928], dtype=float32), -0.9178131]. 
=============================================
[2019-03-23 23:45:50,437] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2160746: loss 0.0019
[2019-03-23 23:45:50,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2160749: learning rate 0.0010
[2019-03-23 23:45:51,549] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2161322: loss 0.0000
[2019-03-23 23:45:51,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2161323: learning rate 0.0010
[2019-03-23 23:45:52,571] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2161856: loss 0.0119
[2019-03-23 23:45:52,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2161856: learning rate 0.0010
[2019-03-23 23:45:52,662] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2161899: loss 0.0224
[2019-03-23 23:45:52,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2161899: learning rate 0.0010
[2019-03-23 23:45:52,807] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2161974: loss 0.0004
[2019-03-23 23:45:52,810] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2161975: learning rate 0.0010
[2019-03-23 23:45:52,829] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161985: loss 0.0003
[2019-03-23 23:45:52,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161985: learning rate 0.0010
[2019-03-23 23:45:52,912] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2162021: loss 0.0105
[2019-03-23 23:45:52,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2162021: learning rate 0.0010
[2019-03-23 23:45:52,954] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2162045: loss 0.0117
[2019-03-23 23:45:52,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2162045: learning rate 0.0010
[2019-03-23 23:45:53,147] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2162145: loss 0.0201
[2019-03-23 23:45:53,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2162145: learning rate 0.0010
[2019-03-23 23:45:53,435] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2162295: loss 0.0165
[2019-03-23 23:45:53,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2162297: learning rate 0.0010
[2019-03-23 23:45:53,470] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2162311: loss 0.0128
[2019-03-23 23:45:53,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2162313: learning rate 0.0010
[2019-03-23 23:45:53,826] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2162497: loss 0.0273
[2019-03-23 23:45:53,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2162498: learning rate 0.0010
[2019-03-23 23:45:53,860] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2162514: loss 0.0223
[2019-03-23 23:45:53,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2162514: learning rate 0.0010
[2019-03-23 23:45:54,295] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9843496e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:45:54,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3510
[2019-03-23 23:45:54,305] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 54.0, 1.0, 2.0, 0.5493174414445497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650148.1797353628, 650148.1797353628, 150663.7779339637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1534200.0000, 
sim time next is 1534800.0000, 
raw observation next is [28.7, 56.0, 1.0, 2.0, 0.5298129168716542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627863.196986527, 627863.196986527, 147502.7290671], 
processed observation next is [0.0, 0.782608695652174, 0.6185185185185185, 0.56, 1.0, 1.0, 0.440253472466255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22423685606661678, 0.22423685606661678, 0.2836590943598077], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.2622482], dtype=float32), 0.46824744]. 
=============================================
[2019-03-23 23:45:54,671] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2162956: loss 0.0094
[2019-03-23 23:45:54,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2162957: learning rate 0.0010
[2019-03-23 23:45:57,831] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2164599: loss 0.2952
[2019-03-23 23:45:57,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2164600: learning rate 0.0010
[2019-03-23 23:46:02,258] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2166759: loss 0.0156
[2019-03-23 23:46:02,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2166759: learning rate 0.0010
[2019-03-23 23:46:05,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2417948e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:46:05,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9287
[2019-03-23 23:46:05,307] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 81.16666666666667, 1.0, 2.0, 0.3784326872961695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471090.2565992745, 471090.256599274, 125668.9490937618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1732200.0000, 
sim time next is 1732800.0000, 
raw observation next is [21.23333333333333, 81.33333333333334, 1.0, 2.0, 0.3780729086734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470710.6046117082, 470710.6046117082, 125620.9818334616], 
processed observation next is [1.0, 0.043478260869565216, 0.34197530864197523, 0.8133333333333335, 1.0, 1.0, 0.25961060556367, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1681109302184672, 0.1681109302184672, 0.24157881121819538], 
reward next is 0.7584, 
noisyNet noise sample is [array([-0.7973099], dtype=float32), 0.07331658]. 
=============================================
[2019-03-23 23:46:06,187] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2168683: loss 0.0000
[2019-03-23 23:46:06,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2168683: learning rate 0.0010
[2019-03-23 23:46:07,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.985129e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:46:07,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1649
[2019-03-23 23:46:07,228] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.3674854998539895, 1.0, 1.0, 0.3674854998539895, 1.0, 2.0, 0.586371310052625, 6.9112, 6.9112, 121.94756008, 1281235.190609347, 1281235.190609347, 283182.1069808619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788600.0000, 
sim time next is 1789200.0000, 
raw observation next is [26.4, 63.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.613303802274352, 6.9112, 121.9231814070817, 1575684.129312109, 1216152.666456659, 248351.0145137601], 
processed observation next is [1.0, 0.7391304347826086, 0.5333333333333333, 0.63, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0702103802274352, 0.0, 0.8094431333706112, 0.5627443318971818, 0.4343402380202354, 0.47759810483415405], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52393615], dtype=float32), 0.08357907]. 
=============================================
[2019-03-23 23:46:07,716] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2169430: loss 0.2854
[2019-03-23 23:46:07,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2169430: learning rate 0.0010
[2019-03-23 23:46:08,410] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2169764: loss 0.1524
[2019-03-23 23:46:08,412] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2169764: learning rate 0.0010
[2019-03-23 23:46:08,460] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2169785: loss 0.1498
[2019-03-23 23:46:08,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2169786: learning rate 0.0010
[2019-03-23 23:46:08,696] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2169905: loss 0.0879
[2019-03-23 23:46:08,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2169906: learning rate 0.0010
[2019-03-23 23:46:08,854] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169982: loss 0.0139
[2019-03-23 23:46:08,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169983: learning rate 0.0010
[2019-03-23 23:46:08,923] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2170014: loss 0.0187
[2019-03-23 23:46:08,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2170014: learning rate 0.0010
[2019-03-23 23:46:08,977] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2170037: loss 0.0017
[2019-03-23 23:46:08,980] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2170038: learning rate 0.0010
[2019-03-23 23:46:09,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2170149: loss 0.0003
[2019-03-23 23:46:09,208] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2170149: learning rate 0.0010
[2019-03-23 23:46:09,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2170323: loss 0.0095
[2019-03-23 23:46:09,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2170323: learning rate 0.0010
[2019-03-23 23:46:09,690] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2170382: loss 0.0072
[2019-03-23 23:46:09,692] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2170384: learning rate 0.0010
[2019-03-23 23:46:09,918] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2170493: loss 0.0000
[2019-03-23 23:46:09,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2170493: learning rate 0.0010
[2019-03-23 23:46:09,945] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2170505: loss 0.0000
[2019-03-23 23:46:09,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2170505: learning rate 0.0010
[2019-03-23 23:46:10,895] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2170972: loss 0.0300
[2019-03-23 23:46:10,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2170972: learning rate 0.0010
[2019-03-23 23:46:11,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.81873e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 23:46:11,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-23 23:46:11,216] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.41666666666666, 90.83333333333334, 1.0, 2.0, 0.3187043508244601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404716.9352805301, 404716.9352805301, 117907.7624768591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1817400.0000, 
sim time next is 1818000.0000, 
raw observation next is [18.4, 91.0, 1.0, 2.0, 0.3194444460895023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 405644.8076287216, 405644.8076287216, 118001.6172849828], 
processed observation next is [1.0, 0.043478260869565216, 0.237037037037037, 0.91, 1.0, 1.0, 0.18981481677321702, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1448731455816863, 0.1448731455816863, 0.2269261870865054], 
reward next is 0.7731, 
noisyNet noise sample is [array([-2.1407592], dtype=float32), 0.72328824]. 
=============================================
[2019-03-23 23:46:11,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.93121]
 [70.93121]
 [70.93121]
 [70.93121]
 [70.93121]], R is [[70.99497986]
 [71.05828857]
 [71.1211319 ]
 [71.18347931]
 [71.24528503]].
[2019-03-23 23:46:14,077] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2172518: loss 0.0032
[2019-03-23 23:46:14,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2172519: learning rate 0.0010
[2019-03-23 23:46:14,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5452284e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:46:14,297] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7038
[2019-03-23 23:46:14,300] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 91.0, 1.0, 2.0, 0.4166828704638791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512174.6824490363, 512174.6824490363, 130894.4136458111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1893000.0000, 
sim time next is 1893600.0000, 
raw observation next is [20.9, 91.0, 1.0, 2.0, 0.4165155896284002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512096.7450176506, 512096.7450176506, 130873.7115666706], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.91, 1.0, 1.0, 0.3053757019385716, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18289169464916094, 0.18289169464916094, 0.2516802145512896], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.15091917], dtype=float32), 1.4520656]. 
=============================================
[2019-03-23 23:46:14,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5452284e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:46:14,392] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8933
[2019-03-23 23:46:14,399] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 91.5, 1.0, 2.0, 0.4231512144113953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519857.8386050754, 519857.838605075, 131820.1061738575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1895400.0000, 
sim time next is 1896000.0000, 
raw observation next is [20.9, 91.66666666666666, 1.0, 2.0, 0.42340049099718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520004.9313856516, 520004.9313856516, 131852.0258825016], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9166666666666665, 1.0, 1.0, 0.31357201309188093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18571604692344698, 0.18571604692344698, 0.25356158823558], 
reward next is 0.7464, 
noisyNet noise sample is [array([-0.15091917], dtype=float32), 1.4520656]. 
=============================================
[2019-03-23 23:46:14,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.287636]
 [76.287636]
 [76.287636]
 [76.287636]
 [76.287636]], R is [[76.27119446]
 [76.25498199]
 [76.23931122]
 [76.22454834]
 [76.21062469]].
[2019-03-23 23:46:16,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0767699e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:46:16,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-23 23:46:16,608] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 76.5, 1.0, 2.0, 0.5568337532585507, 1.0, 1.0, 0.5568337532585507, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.925753983793, 1285676.97128325, 1285676.97128325, 254290.9641636185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2298600.0000, 
sim time next is 2299200.0000, 
raw observation next is [25.5, 75.66666666666666, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.69011668293668, 6.9112, 121.9229510103626, 1594446.836625544, 1195581.990211204, 247364.1060443232], 
processed observation next is [1.0, 0.6086956521739131, 0.5, 0.7566666666666666, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.07789166829366803, 0.0, 0.8094416037759922, 0.5694452987948371, 0.4269935679325728, 0.4757002039313908], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20176066], dtype=float32), -0.18663491]. 
=============================================
[2019-03-23 23:46:19,078] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2174943: loss 0.0180
[2019-03-23 23:46:19,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2174944: learning rate 0.0010
[2019-03-23 23:46:19,191] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 23:46:19,194] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:46:19,195] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:46:19,196] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:46:19,196] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:46:19,199] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:46:19,196] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:46:19,200] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:46:19,200] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:46:19,201] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:46:19,204] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:46:19,228] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 23:46:19,228] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 23:46:19,277] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 23:46:19,298] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 23:46:19,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 23:46:41,189] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:46:41,193] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.37184944333333, 42.07979558, 1.0, 2.0, 0.5002340151283476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 588636.263242236, 588636.2632422355, 142620.2621563611]
[2019-03-23 23:46:41,194] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:46:41,196] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.606130755157083
[2019-03-23 23:46:50,918] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:46:50,918] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.611579885, 97.82502504166668, 1.0, 2.0, 0.6206118873903245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707280.2438876312, 707280.2438876312, 161661.1478130859]
[2019-03-23 23:46:50,922] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:46:50,925] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6359209915792727
[2019-03-23 23:47:28,658] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:47:28,660] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.475581593774061, 6.9112, 121.9197387004976, 1985923.431312837, 1184861.65172147, 246790.7081528299]
[2019-03-23 23:47:28,661] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:47:28,662] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.34584459010547475
[2019-03-23 23:47:28,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1985923.431312837 W.
[2019-03-23 23:47:35,041] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:47:35,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 94.5, 1.0, 2.0, 0.7432785984842568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847154.5961074317, 847154.5961074317, 184503.9044638739]
[2019-03-23 23:47:35,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:47:35,045] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.18047304201502246
[2019-03-23 23:47:35,742] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:47:35,745] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 53.0, 1.0, 2.0, 0.8678578798452218, 1.0, 1.0, 0.8678578798452218, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9256901349736, 1979677.068492957, 1979677.068492957, 372593.300135721]
[2019-03-23 23:47:35,746] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:47:35,749] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4278744187752338
[2019-03-23 23:47:35,750] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1979677.068492957 W.
[2019-03-23 23:47:51,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:47:51,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.7, 85.66666666666667, 1.0, 2.0, 0.8908425036765978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1056919.672774838, 1056919.672774838, 217499.8168477198]
[2019-03-23 23:47:51,510] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:47:51,516] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9008697751221465
[2019-03-23 23:47:54,701] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:47:54,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 81.83333333333334, 1.0, 2.0, 0.4849588231539975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583120.1167974209, 583120.1167974209, 140719.1871152882]
[2019-03-23 23:47:54,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:47:54,707] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7391336774695231
[2019-03-23 23:48:03,565] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0231392]
[2019-03-23 23:48:03,565] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.38660997, 49.94522782, 1.0, 2.0, 0.4625386122630787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570037.6733891667, 570037.6733891667, 137704.8709035219]
[2019-03-23 23:48:03,566] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:48:03,569] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4182735e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8881874754459642
[2019-03-23 23:48:04,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:48:04,369] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:48:04,403] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:48:04,415] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:48:04,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:48:05,455] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2175000, evaluation results [2175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:48:08,878] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2176782: loss 0.0023
[2019-03-23 23:48:08,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2176782: learning rate 0.0010
[2019-03-23 23:48:09,972] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2177343: loss 0.0201
[2019-03-23 23:48:09,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2177344: learning rate 0.0010
[2019-03-23 23:48:10,643] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2177686: loss 0.0417
[2019-03-23 23:48:10,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2177686: learning rate 0.0010
[2019-03-23 23:48:10,757] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2177748: loss 0.0028
[2019-03-23 23:48:10,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2177748: learning rate 0.0010
[2019-03-23 23:48:11,160] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2177954: loss 0.0059
[2019-03-23 23:48:11,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2177954: learning rate 0.0010
[2019-03-23 23:48:11,168] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2177955: loss 0.0053
[2019-03-23 23:48:11,170] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2177955: learning rate 0.0010
[2019-03-23 23:48:11,196] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2177971: loss 0.0188
[2019-03-23 23:48:11,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2177971: learning rate 0.0010
[2019-03-23 23:48:11,239] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2177989: loss 0.0092
[2019-03-23 23:48:11,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2177990: learning rate 0.0010
[2019-03-23 23:48:11,549] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2178152: loss 0.0041
[2019-03-23 23:48:11,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2178152: learning rate 0.0010
[2019-03-23 23:48:11,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2178308: loss 0.0083
[2019-03-23 23:48:11,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2178308: learning rate 0.0010
[2019-03-23 23:48:11,984] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2178342: loss 0.0007
[2019-03-23 23:48:11,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2178345: learning rate 0.0010
[2019-03-23 23:48:12,098] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2178403: loss 0.0076
[2019-03-23 23:48:12,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2178404: learning rate 0.0010
[2019-03-23 23:48:12,184] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2178450: loss 0.0094
[2019-03-23 23:48:12,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2178450: learning rate 0.0010
[2019-03-23 23:48:13,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2179027: loss 0.0159
[2019-03-23 23:48:13,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2179027: learning rate 0.0010
[2019-03-23 23:48:15,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2437375e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:48:15,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6192
[2019-03-23 23:48:15,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1385920.746770923 W.
[2019-03-23 23:48:15,544] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.7, 38.0, 1.0, 2.0, 0.5789263433106799, 1.0, 2.0, 0.5789263433106799, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1385920.746770923, 1385920.746770924, 263753.9718059984], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2394000.0000, 
sim time next is 2394600.0000, 
raw observation next is [30.53333333333333, 38.33333333333334, 1.0, 2.0, 0.189082702562004, 1.0, 2.0, 0.189082702562004, 1.0, 1.0, 0.3047261146683878, 6.9112, 6.9112, 121.94756008, 678214.7456153374, 678214.7456153374, 216526.62221082], 
processed observation next is [1.0, 0.7391304347826086, 0.6864197530864197, 0.3833333333333334, 1.0, 1.0, 0.034622264954766654, 1.0, 1.0, 0.034622264954766654, 1.0, 0.5, 0.1309076433354847, 0.0, 0.0, 0.8096049824067558, 0.24221955200547765, 0.24221955200547765, 0.4163973504054231], 
reward next is 0.5836, 
noisyNet noise sample is [array([-0.2804745], dtype=float32), -2.0837915]. 
=============================================
[2019-03-23 23:48:16,398] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2180616: loss 0.3971
[2019-03-23 23:48:16,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2180617: learning rate 0.0010
[2019-03-23 23:48:18,539] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.092161e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:48:18,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0837
[2019-03-23 23:48:18,547] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 95.5, 1.0, 2.0, 0.5350337975993131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631915.1346269567, 631915.1346269567, 148266.5648727074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2237400.0000, 
sim time next is 2238000.0000, 
raw observation next is [22.7, 95.66666666666667, 1.0, 2.0, 0.5355844393508734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632312.6618941576, 632312.6618941572, 148346.0603482004], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9566666666666667, 1.0, 1.0, 0.44712433256056355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22582595067648487, 0.2258259506764847, 0.2852808852850008], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.34202325], dtype=float32), -0.85597277]. 
=============================================
[2019-03-23 23:48:18,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.64631]
 [70.64631]
 [70.64631]
 [70.64631]
 [70.64631]], R is [[70.6545639 ]
 [70.6628952 ]
 [70.67144012]
 [70.68057251]
 [70.69032288]].
[2019-03-23 23:48:21,131] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2183048: loss 0.0360
[2019-03-23 23:48:21,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2183048: learning rate 0.0010
[2019-03-23 23:48:24,331] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2184702: loss 0.0003
[2019-03-23 23:48:24,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2184703: learning rate 0.0010
[2019-03-23 23:48:25,681] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2185403: loss 0.2941
[2019-03-23 23:48:25,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2185404: learning rate 0.0010
[2019-03-23 23:48:26,135] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2185639: loss 0.3171
[2019-03-23 23:48:26,137] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2185639: learning rate 0.0010
[2019-03-23 23:48:26,351] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2185747: loss 0.2106
[2019-03-23 23:48:26,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2185747: learning rate 0.0010
[2019-03-23 23:48:26,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2185871: loss 0.1689
[2019-03-23 23:48:26,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2185872: learning rate 0.0010
[2019-03-23 23:48:26,805] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2185983: loss 0.0798
[2019-03-23 23:48:26,810] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2185986: learning rate 0.0010
[2019-03-23 23:48:26,848] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2186006: loss 0.0518
[2019-03-23 23:48:26,850] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2186006: learning rate 0.0010
[2019-03-23 23:48:26,898] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2186033: loss 0.0680
[2019-03-23 23:48:26,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2186035: learning rate 0.0010
[2019-03-23 23:48:27,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0768252e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:48:27,166] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2312
[2019-03-23 23:48:27,172] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 63.33333333333334, 1.0, 2.0, 0.3573889652369676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 448982.3204113223, 448982.3204113219, 122893.9134373079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2418000.0000, 
sim time next is 2418600.0000, 
raw observation next is [22.95, 63.16666666666666, 1.0, 2.0, 0.3513750922220865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442290.8304224999, 442290.8304224999, 122106.0050100347], 
processed observation next is [1.0, 1.0, 0.4055555555555555, 0.6316666666666666, 1.0, 1.0, 0.2278274907405792, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15796101086517855, 0.15796101086517855, 0.2348192404039129], 
reward next is 0.7652, 
noisyNet noise sample is [array([0.35975644], dtype=float32), -0.9992112]. 
=============================================
[2019-03-23 23:48:27,301] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2186238: loss 0.0009
[2019-03-23 23:48:27,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2186238: learning rate 0.0010
[2019-03-23 23:48:27,434] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2186306: loss 0.0008
[2019-03-23 23:48:27,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2186306: learning rate 0.0010
[2019-03-23 23:48:27,541] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2186361: loss 0.0013
[2019-03-23 23:48:27,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2186361: learning rate 0.0010
[2019-03-23 23:48:27,619] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2186402: loss 0.0035
[2019-03-23 23:48:27,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2186402: learning rate 0.0010
[2019-03-23 23:48:27,644] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2186413: loss 0.0060
[2019-03-23 23:48:27,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2186413: learning rate 0.0010
[2019-03-23 23:48:28,714] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2186970: loss 0.0024
[2019-03-23 23:48:28,720] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2186970: learning rate 0.0010
[2019-03-23 23:48:31,646] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2188537: loss 0.0223
[2019-03-23 23:48:31,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2188537: learning rate 0.0010
[2019-03-23 23:48:32,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1993049e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:48:32,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5374
[2019-03-23 23:48:32,543] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.5004242934435484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597322.828683481, 597322.828683481, 142978.815413227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3231000.0000, 
sim time next is 3231600.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.5021410459322817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 598987.7343990458, 598987.7343990454, 143234.8444367167], 
processed observation next is [0.0, 0.391304347826087, 0.5802469135802467, 0.5933333333333333, 1.0, 1.0, 0.407310768967002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2139241908568021, 0.21392419085680192, 0.27545162391676287], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.69848126], dtype=float32), -0.9217443]. 
=============================================
[2019-03-23 23:48:36,645] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2191000: loss 0.0057
[2019-03-23 23:48:36,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2191000: learning rate 0.0010
[2019-03-23 23:48:40,383] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2192836: loss 0.0016
[2019-03-23 23:48:40,384] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2192837: learning rate 0.0010
[2019-03-23 23:48:41,542] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2193407: loss 0.0197
[2019-03-23 23:48:41,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2193407: learning rate 0.0010
[2019-03-23 23:48:42,104] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2193683: loss 0.0092
[2019-03-23 23:48:42,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2193684: learning rate 0.0010
[2019-03-23 23:48:42,138] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2193699: loss 0.0082
[2019-03-23 23:48:42,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2193699: learning rate 0.0010
[2019-03-23 23:48:42,595] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2193924: loss 0.0019
[2019-03-23 23:48:42,596] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2193924: learning rate 0.0010
[2019-03-23 23:48:42,646] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2193944: loss 0.0069
[2019-03-23 23:48:42,649] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2193944: learning rate 0.0010
[2019-03-23 23:48:42,729] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2193988: loss 0.0097
[2019-03-23 23:48:42,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2193989: learning rate 0.0010
[2019-03-23 23:48:42,801] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2194020: loss 0.0010
[2019-03-23 23:48:42,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2194021: learning rate 0.0010
[2019-03-23 23:48:43,252] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2194244: loss 0.0035
[2019-03-23 23:48:43,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2194244: learning rate 0.0010
[2019-03-23 23:48:43,323] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2194278: loss 0.0134
[2019-03-23 23:48:43,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2194279: learning rate 0.0010
[2019-03-23 23:48:43,441] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2194339: loss 0.0090
[2019-03-23 23:48:43,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2194340: learning rate 0.0010
[2019-03-23 23:48:43,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2194351: loss 0.0037
[2019-03-23 23:48:43,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2194351: learning rate 0.0010
[2019-03-23 23:48:43,536] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2194379: loss 0.0013
[2019-03-23 23:48:43,541] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2194385: learning rate 0.0010
[2019-03-23 23:48:44,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2194985: loss 0.0019
[2019-03-23 23:48:44,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2194986: learning rate 0.0010
[2019-03-23 23:48:46,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8983737e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:48:46,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-23 23:48:46,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1893376.622865933 W.
[2019-03-23 23:48:46,544] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5533769345127983, 1.0, 2.0, 0.5533769345127983, 1.0, 1.0, 0.8809941019729348, 6.911200000000001, 6.9112, 121.94756008, 1893376.622865933, 1893376.622865932, 370558.7684241098], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3490200.0000, 
sim time next is 3490800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5254208247200205, 1.0, 2.0, 0.5254208247200205, 1.0, 2.0, 0.8364870647158996, 6.9112, 6.9112, 121.94756008, 1797628.684552818, 1797628.684552818, 356241.0498971913], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.89, 1.0, 1.0, 0.4350247913333577, 1.0, 1.0, 0.4350247913333577, 1.0, 1.0, 0.7956088308948744, 0.0, 0.0, 0.8096049824067558, 0.6420102444831494, 0.6420102444831494, 0.6850789421099832], 
reward next is 0.3149, 
noisyNet noise sample is [array([-0.9833663], dtype=float32), 1.4326203]. 
=============================================
[2019-03-23 23:48:48,431] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2196774: loss 0.3772
[2019-03-23 23:48:48,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2196774: learning rate 0.0010
[2019-03-23 23:48:48,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8514580e-19 1.0000000e+00 1.3900750e-29 3.3352058e-34 1.5218694e-33], sum to 1.0000
[2019-03-23 23:48:48,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5442
[2019-03-23 23:48:48,905] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 75.66666666666667, 1.0, 2.0, 0.593182275104243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685025.0217701205, 685025.0217701205, 157345.6869280104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3531000.0000, 
sim time next is 3531600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.599064073900767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690151.516148759, 690151.516148759, 158279.5169470511], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5226953260723416, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24648268433884252, 0.24648268433884252, 0.3043836864366367], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.40355325], dtype=float32), -1.2638297]. 
=============================================
[2019-03-23 23:48:53,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2199156: loss 0.2673
[2019-03-23 23:48:53,344] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2199156: learning rate 0.0010
[2019-03-23 23:48:55,077] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 23:48:55,077] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:48:55,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:55,081] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:48:55,082] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:55,083] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:48:55,083] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:55,084] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:48:55,086] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:55,087] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:48:55,088] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:55,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 23:48:55,109] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 23:48:55,160] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 23:48:55,183] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 23:48:55,184] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 23:50:20,198] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0598757]
[2019-03-23 23:50:20,200] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 62.0, 1.0, 2.0, 0.6030275469234385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695137.4800165521, 695137.4800165521, 158983.9989776919]
[2019-03-23 23:50:20,201] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:50:20,204] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6838613e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6119048439098206
[2019-03-23 23:50:39,768] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:50:39,969] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:50:40,309] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:50:40,340] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:50:40,354] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:50:41,372] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2200000, evaluation results [2200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:50:42,926] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2200807: loss 0.1741
[2019-03-23 23:50:42,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2200808: learning rate 0.0010
[2019-03-23 23:50:43,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2775660e-23 1.0000000e+00 5.5373585e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:50:43,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-23 23:50:43,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1738346.701205276 W.
[2019-03-23 23:50:43,052] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 72.33333333333334, 1.0, 2.0, 0.5081104004165483, 1.0, 2.0, 0.5081104004165483, 1.0, 1.0, 0.8089283054636104, 6.9112, 6.9112, 121.94756008, 1738346.701205276, 1738346.701205276, 347587.5627774154], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2988600.0000, 
sim time next is 2989200.0000, 
raw observation next is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.7326457813675179, 1.0, 2.0, 0.7326457813675179, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1670955.238500559, 1670955.238500559, 316709.0857509275], 
processed observation next is [1.0, 0.6086956521739131, 0.6098765432098766, 0.7666666666666667, 1.0, 1.0, 0.6817211682946641, 1.0, 1.0, 0.6817211682946641, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5967697280359139, 0.5967697280359139, 0.609055934136399], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6273807], dtype=float32), 0.37978038]. 
=============================================
[2019-03-23 23:50:44,229] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2201466: loss 0.3124
[2019-03-23 23:50:44,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2201466: learning rate 0.0010
[2019-03-23 23:50:44,457] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2201585: loss 0.3766
[2019-03-23 23:50:44,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2201589: learning rate 0.0010
[2019-03-23 23:50:44,641] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2201681: loss 0.3383
[2019-03-23 23:50:44,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2201681: learning rate 0.0010
[2019-03-23 23:50:44,904] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2201811: loss 0.2890
[2019-03-23 23:50:44,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2201812: learning rate 0.0010
[2019-03-23 23:50:45,045] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2201883: loss 0.2583
[2019-03-23 23:50:45,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2201884: learning rate 0.0010
[2019-03-23 23:50:45,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2201989: loss 0.2323
[2019-03-23 23:50:45,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2201989: learning rate 0.0010
[2019-03-23 23:50:45,444] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2202088: loss 0.1388
[2019-03-23 23:50:45,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2202088: learning rate 0.0010
[2019-03-23 23:50:45,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2202208: loss 0.1138
[2019-03-23 23:50:45,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2202210: learning rate 0.0010
[2019-03-23 23:50:45,842] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2202294: loss 0.0332
[2019-03-23 23:50:45,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2202294: learning rate 0.0010
[2019-03-23 23:50:45,890] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2202320: loss 0.0260
[2019-03-23 23:50:45,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2202320: learning rate 0.0010
[2019-03-23 23:50:46,052] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2202405: loss 0.0003
[2019-03-23 23:50:46,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2202405: learning rate 0.0010
[2019-03-23 23:50:46,293] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2202530: loss 0.0001
[2019-03-23 23:50:46,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2202530: learning rate 0.0010
[2019-03-23 23:50:47,188] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2202993: loss 0.0089
[2019-03-23 23:50:47,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2202993: learning rate 0.0010
[2019-03-23 23:50:50,529] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2204708: loss 0.0448
[2019-03-23 23:50:50,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2204708: learning rate 0.0010
[2019-03-23 23:50:51,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.708938e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:50:51,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8922
[2019-03-23 23:50:51,041] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1564485.034418044 W.
[2019-03-23 23:50:51,045] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.36666666666667, 84.33333333333333, 1.0, 2.0, 0.6860048770225137, 1.0, 1.0, 0.6860048770225137, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1564485.034418044, 1564485.034418044, 298901.013191735], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3082200.0000, 
sim time next is 3082800.0000, 
raw observation next is [26.73333333333333, 84.66666666666667, 1.0, 2.0, 0.7462228358507086, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1565560.74611934, 1565560.74611934, 325798.6712078496], 
processed observation next is [1.0, 0.6956521739130435, 0.545679012345679, 0.8466666666666667, 1.0, 1.0, 0.6978843283937007, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5591288378997643, 0.5591288378997643, 0.6265359061689415], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.85351753], dtype=float32), 1.1400913]. 
=============================================
[2019-03-23 23:50:54,987] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2206941: loss 0.0055
[2019-03-23 23:50:54,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2206942: learning rate 0.0010
[2019-03-23 23:50:56,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4363663e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:50:56,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-23 23:50:56,862] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 71.66666666666667, 1.0, 2.0, 0.4762879776924986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 574678.7252459248, 574678.7252459243, 139449.8416613665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3223200.0000, 
sim time next is 3223800.0000, 
raw observation next is [25.15, 68.5, 1.0, 2.0, 0.4721661160352361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570792.5515275891, 570792.5515275891, 138854.3467980342], 
processed observation next is [0.0, 0.30434782608695654, 0.487037037037037, 0.685, 1.0, 1.0, 0.37162632861337636, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20385448268842468, 0.20385448268842468, 0.2670275899962196], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.22654577], dtype=float32), 1.3474668]. 
=============================================
[2019-03-23 23:50:58,669] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2208854: loss 0.0085
[2019-03-23 23:50:58,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2208856: learning rate 0.0010
[2019-03-23 23:50:59,745] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2209402: loss 0.0003
[2019-03-23 23:50:59,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2209403: learning rate 0.0010
[2019-03-23 23:50:59,754] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2209407: loss 0.0003
[2019-03-23 23:50:59,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2209408: learning rate 0.0010
[2019-03-23 23:51:00,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.975888e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:51:00,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9388
[2019-03-23 23:51:00,041] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 90.0, 1.0, 2.0, 0.5241909119862367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 624982.5690339754, 624982.5690339754, 146738.546047553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3279600.0000, 
sim time next is 3280200.0000, 
raw observation next is [22.83333333333333, 90.66666666666667, 1.0, 2.0, 0.5228757998829049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623319.2201853754, 623319.2201853754, 146523.4565865575], 
processed observation next is [0.0, 1.0, 0.4012345679012344, 0.9066666666666667, 1.0, 1.0, 0.431994999860601, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22261400720906266, 0.22261400720906266, 0.2817758780510721], 
reward next is 0.7182, 
noisyNet noise sample is [array([-0.20755164], dtype=float32), -0.99320936]. 
=============================================
[2019-03-23 23:51:00,380] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2209728: loss 0.0080
[2019-03-23 23:51:00,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2209728: learning rate 0.0010
[2019-03-23 23:51:00,408] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2209740: loss 0.0098
[2019-03-23 23:51:00,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2209740: learning rate 0.0010
[2019-03-23 23:51:00,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2209894: loss 0.0013
[2019-03-23 23:51:00,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2209896: learning rate 0.0010
[2019-03-23 23:51:00,876] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2209986: loss 0.0002
[2019-03-23 23:51:00,880] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2209986: learning rate 0.0010
[2019-03-23 23:51:01,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2210115: loss 0.0220
[2019-03-23 23:51:01,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2210116: learning rate 0.0010
[2019-03-23 23:51:01,318] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2210215: loss 0.0001
[2019-03-23 23:51:01,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2210218: learning rate 0.0010
[2019-03-23 23:51:01,550] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2210329: loss 0.0041
[2019-03-23 23:51:01,552] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2210329: learning rate 0.0010
[2019-03-23 23:51:01,763] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2210443: loss 0.0071
[2019-03-23 23:51:01,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2210444: learning rate 0.0010
[2019-03-23 23:51:01,844] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2210478: loss 0.0172
[2019-03-23 23:51:01,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2210478: learning rate 0.0010
[2019-03-23 23:51:02,095] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2210615: loss 0.0051
[2019-03-23 23:51:02,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2210618: learning rate 0.0010
[2019-03-23 23:51:02,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2210974: loss 0.0121
[2019-03-23 23:51:02,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2210975: learning rate 0.0010
[2019-03-23 23:51:06,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2212737: loss 0.2401
[2019-03-23 23:51:06,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2212738: learning rate 0.0010
[2019-03-23 23:51:07,256] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1774223e-20 1.0000000e+00 2.1069412e-34 1.8436672e-35 7.2786963e-36], sum to 1.0000
[2019-03-23 23:51:07,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4075
[2019-03-23 23:51:07,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2153391.816776877 W.
[2019-03-23 23:51:07,277] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.75, 60.33333333333334, 1.0, 2.0, 0.6318307569306695, 1.0, 2.0, 0.6292800404417693, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2153391.816776877, 2153391.816776878, 411424.1674105898], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3412200.0000, 
sim time next is 3412800.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6481025573640121, 1.0, 2.0, 0.6374159406584409, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2181266.81130098, 2181266.811300981, 415585.489437338], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.59, 1.0, 1.0, 0.5810744730523953, 1.0, 1.0, 0.5683523103076676, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7790238611789214, 0.7790238611789218, 0.7992028643025731], 
reward next is 0.2008, 
noisyNet noise sample is [array([-0.6838627], dtype=float32), -2.040493]. 
=============================================
[2019-03-23 23:51:08,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.13307405e-24 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 23:51:08,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0757
[2019-03-23 23:51:08,843] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.687556671858564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783612.8541800531, 783612.8541800531, 173801.0932862964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445800.0000, 
sim time next is 3446400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6880079618401421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 784127.4554207048, 784127.4554207039, 173885.559573154], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6285809069525501, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2800455197931089, 0.28004551979310854, 0.33439530687144997], 
reward next is 0.6656, 
noisyNet noise sample is [array([-3.1253943], dtype=float32), 0.5535495]. 
=============================================
[2019-03-23 23:51:10,462] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2214902: loss 0.2889
[2019-03-23 23:51:10,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2214902: learning rate 0.0010
[2019-03-23 23:51:13,099] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4170322e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:51:13,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9580
[2019-03-23 23:51:13,113] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 72.0, 1.0, 2.0, 0.5648043531354545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652371.6432497714, 652371.6432497714, 152551.3765280495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3519000.0000, 
sim time next is 3519600.0000, 
raw observation next is [27.16666666666667, 74.33333333333333, 1.0, 2.0, 0.5833710336792582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669763.5517666655, 669763.5517666655, 155484.3278101412], 
processed observation next is [1.0, 0.7391304347826086, 0.5617283950617286, 0.7433333333333333, 1.0, 1.0, 0.5040131353324503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23920126848809484, 0.23920126848809484, 0.29900832271181], 
reward next is 0.7010, 
noisyNet noise sample is [array([0.26803052], dtype=float32), -0.9217753]. 
=============================================
[2019-03-23 23:51:14,224] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2216731: loss 0.0229
[2019-03-23 23:51:14,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2216731: learning rate 0.0010
[2019-03-23 23:51:15,722] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2217450: loss 0.1077
[2019-03-23 23:51:15,725] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2217452: learning rate 0.0010
[2019-03-23 23:51:15,900] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2217542: loss 0.0857
[2019-03-23 23:51:15,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2217542: learning rate 0.0010
[2019-03-23 23:51:16,334] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2217747: loss 0.1203
[2019-03-23 23:51:16,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2217748: learning rate 0.0010
[2019-03-23 23:51:16,560] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2217857: loss 0.1029
[2019-03-23 23:51:16,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2217857: learning rate 0.0010
[2019-03-23 23:51:16,620] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2217886: loss 0.0685
[2019-03-23 23:51:16,626] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2217889: learning rate 0.0010
[2019-03-23 23:51:16,632] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2217891: loss 0.0556
[2019-03-23 23:51:16,636] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2217891: learning rate 0.0010
[2019-03-23 23:51:17,132] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2218134: loss 0.0298
[2019-03-23 23:51:17,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2218135: learning rate 0.0010
[2019-03-23 23:51:17,216] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2218179: loss 0.0123
[2019-03-23 23:51:17,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2218180: learning rate 0.0010
[2019-03-23 23:51:17,611] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2218372: loss 0.0016
[2019-03-23 23:51:17,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2218373: learning rate 0.0010
[2019-03-23 23:51:17,690] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2218411: loss 0.0017
[2019-03-23 23:51:17,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2218411: learning rate 0.0010
[2019-03-23 23:51:17,931] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2218527: loss 0.0002
[2019-03-23 23:51:17,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2218528: learning rate 0.0010
[2019-03-23 23:51:18,161] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2218642: loss 0.0072
[2019-03-23 23:51:18,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2218643: learning rate 0.0010
[2019-03-23 23:51:18,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0281942e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:51:18,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9503
[2019-03-23 23:51:18,920] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 98.83333333333333, 1.0, 2.0, 0.5738138367440835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 681210.0875008467, 681210.0875008462, 154849.6382051829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3654600.0000, 
sim time next is 3655200.0000, 
raw observation next is [22.03333333333333, 98.66666666666669, 1.0, 2.0, 0.5371180716750985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637706.7951182981, 637706.7951182981, 148737.3128619144], 
processed observation next is [1.0, 0.30434782608695654, 0.37160493827160485, 0.9866666666666668, 1.0, 1.0, 0.4489500853274982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22775242682796362, 0.22775242682796362, 0.28603329396522], 
reward next is 0.7140, 
noisyNet noise sample is [array([1.3534709], dtype=float32), 1.0525968]. 
=============================================
[2019-03-23 23:51:19,042] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2219065: loss 0.0004
[2019-03-23 23:51:19,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2219065: learning rate 0.0010
[2019-03-23 23:51:21,173] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6980754e-22 1.0000000e+00 3.2984344e-36 0.0000000e+00 1.1966649e-38], sum to 1.0000
[2019-03-23 23:51:21,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-23 23:51:21,196] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.7178856394877438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818197.4270262625, 818197.4270262625, 179560.9438940782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694800.0000, 
sim time next is 3695400.0000, 
raw observation next is [26.8, 89.5, 1.0, 2.0, 0.71586348645465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815891.4872938138, 815891.4872938138, 179172.0316786222], 
processed observation next is [1.0, 0.782608695652174, 0.5481481481481482, 0.895, 1.0, 1.0, 0.6617422457793453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2913898168906478, 0.2913898168906478, 0.3445615993819658], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.57954603], dtype=float32), -1.0134141]. 
=============================================
[2019-03-23 23:51:21,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7666016e-23 1.0000000e+00 1.8233602e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:51:21,827] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2540
[2019-03-23 23:51:21,833] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 94.0, 1.0, 2.0, 0.6704477485125631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 764103.9828510168, 764103.9828510165, 170623.8372515537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3711600.0000, 
sim time next is 3712200.0000, 
raw observation next is [25.08333333333334, 94.00000000000001, 1.0, 2.0, 0.6696799924360773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763228.5417115594, 763228.5417115594, 170482.4166058683], 
processed observation next is [1.0, 1.0, 0.4845679012345681, 0.9400000000000002, 1.0, 1.0, 0.6067618957572349, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27258162203984265, 0.27258162203984265, 0.3278508011651313], 
reward next is 0.6721, 
noisyNet noise sample is [array([-1.049404], dtype=float32), 0.3164848]. 
=============================================
[2019-03-23 23:51:22,383] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2220697: loss 0.0001
[2019-03-23 23:51:22,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2220698: learning rate 0.0010
[2019-03-23 23:51:26,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0147240e-21 1.0000000e+00 1.5576371e-35 0.0000000e+00 1.3272579e-38], sum to 1.0000
[2019-03-23 23:51:26,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9679
[2019-03-23 23:51:26,380] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333333, 74.0, 1.0, 2.0, 0.5917612412142687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686358.2195252635, 686358.2195252635, 157239.0434101971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3808200.0000, 
sim time next is 3808800.0000, 
raw observation next is [26.7, 72.0, 1.0, 2.0, 0.579787430937748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675223.980189638, 675223.980189638, 155320.1993962217], 
processed observation next is [0.0, 0.08695652173913043, 0.5444444444444444, 0.72, 1.0, 1.0, 0.4997469415925571, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24115142149629928, 0.24115142149629928, 0.2986926911465802], 
reward next is 0.7013, 
noisyNet noise sample is [array([-1.6433105], dtype=float32), -0.15172845]. 
=============================================
[2019-03-23 23:51:26,493] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2222699: loss 0.2302
[2019-03-23 23:51:26,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2222699: learning rate 0.0010
[2019-03-23 23:51:27,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9064257e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:51:27,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5487
[2019-03-23 23:51:27,924] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 78.16666666666667, 1.0, 2.0, 0.5794574409792116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672386.6430277174, 672386.6430277178, 155154.4090021297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3815400.0000, 
sim time next is 3816000.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.5861458972339221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678391.5182169673, 678391.5182169673, 156211.7133284055], 
processed observation next is [0.0, 0.17391304347826086, 0.5185185185185185, 0.79, 1.0, 1.0, 0.5073165443260977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24228268507748835, 0.24228268507748835, 0.3004071410161644], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.47049], dtype=float32), -0.018859874]. 
=============================================
[2019-03-23 23:51:27,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.6063]
 [69.6063]
 [69.6063]
 [69.6063]
 [69.6063]], R is [[69.60983276]
 [69.61536407]
 [69.62277222]
 [69.63186646]
 [69.64237976]].
[2019-03-23 23:51:30,814] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2224819: loss 0.1116
[2019-03-23 23:51:30,816] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2224819: learning rate 0.0010
[2019-03-23 23:51:31,185] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 23:51:31,187] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:51:31,187] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:51:31,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:31,189] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:31,191] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:51:31,190] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:51:31,189] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:51:31,196] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:31,198] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:31,198] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:31,215] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 23:51:31,243] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 23:51:31,243] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 23:51:31,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 23:51:31,313] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 23:51:33,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:51:33,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.16792059, 37.30917106, 1.0, 2.0, 0.7856361944771307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426119294, 987848.5220786053, 987848.5220786053, 196466.067931376]
[2019-03-23 23:51:33,029] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:51:33,032] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0905765897373404
[2019-03-23 23:51:39,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:51:39,243] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.6, 53.0, 1.0, 2.0, 0.3136569475441648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399175.0892156783, 399175.0892156783, 117275.0900786458]
[2019-03-23 23:51:39,244] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:51:39,246] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.4044154612089663
[2019-03-23 23:51:48,295] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:51:48,296] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.39473434, 64.36349945, 1.0, 2.0, 0.4368944867656184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558541.5206247014, 558541.5206247014, 134165.1996093817]
[2019-03-23 23:51:48,296] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:51:48,298] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.9827763876436764
[2019-03-23 23:52:02,193] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:02,197] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.2, 86.0, 1.0, 2.0, 0.3567677369185726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446669.6089137686, 446669.6089137686, 122786.5115474533]
[2019-03-23 23:52:02,197] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:02,201] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.986030700915964
[2019-03-23 23:52:11,204] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:11,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5388487052077442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637779.7970485712, 637779.7970485712, 148942.9707972665]
[2019-03-23 23:52:11,206] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:11,211] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.3461234365721989
[2019-03-23 23:52:15,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:15,933] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.2, 52.33333333333333, 1.0, 2.0, 0.5290657864130052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.842289962439246, 6.9112, 6.9112, 121.926042455362, 1206291.933585768, 1206291.933585768, 267279.8577324417]
[2019-03-23 23:52:15,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:15,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6930488064727923
[2019-03-23 23:52:27,457] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:27,459] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.23333333333333, 85.33333333333333, 1.0, 2.0, 0.622534125535621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709471.936052064, 709471.936052064, 161998.5682540876]
[2019-03-23 23:52:27,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:27,464] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.2500379803445688
[2019-03-23 23:52:36,751] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:36,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.53333333333333, 78.33333333333334, 1.0, 2.0, 0.918934869370229, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1762699.142899352, 1762699.142899352, 361090.0174812795]
[2019-03-23 23:52:36,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:36,759] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.09693831275631282
[2019-03-23 23:52:36,761] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1762699.142899352 W.
[2019-03-23 23:52:49,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:52:49,245] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.83333333333334, 36.33333333333334, 1.0, 2.0, 0.527977098837547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623715.8265876722, 623715.8265876722, 147127.6178504849]
[2019-03-23 23:52:49,246] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:52:49,250] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5386875696143807
[2019-03-23 23:53:13,332] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:53:13,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 73.0, 1.0, 2.0, 0.3762712927085862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 465264.5275663626, 465264.5275663622, 125304.7132542116]
[2019-03-23 23:53:13,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:53:13,335] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.5047752943738065
[2019-03-23 23:53:15,293] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0630046]
[2019-03-23 23:53:15,294] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.99535852, 32.92297511666666, 1.0, 2.0, 0.365567727481111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451202.7897333159, 451202.7897333159, 123834.162503036]
[2019-03-23 23:53:15,295] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:53:15,297] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.168056e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.77195056190786
[2019-03-23 23:53:16,305] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:53:16,362] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:53:16,435] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:53:16,575] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:53:16,814] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:53:17,830] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2225000, evaluation results [2225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:53:18,463] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2225327: loss 0.0232
[2019-03-23 23:53:18,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2225328: learning rate 0.0010
[2019-03-23 23:53:18,710] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2225457: loss 0.0015
[2019-03-23 23:53:18,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2225458: learning rate 0.0010
[2019-03-23 23:53:19,245] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2225740: loss 0.0139
[2019-03-23 23:53:19,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2225740: learning rate 0.0010
[2019-03-23 23:53:19,541] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2225893: loss 0.0002
[2019-03-23 23:53:19,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2225893: learning rate 0.0010
[2019-03-23 23:53:19,565] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2225905: loss 0.0043
[2019-03-23 23:53:19,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2225905: learning rate 0.0010
[2019-03-23 23:53:19,693] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2225969: loss 0.0024
[2019-03-23 23:53:19,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2225970: learning rate 0.0010
[2019-03-23 23:53:19,799] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.492753e-23 1.000000e+00 1.350945e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:53:19,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9575
[2019-03-23 23:53:19,815] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.21666666666667, 92.83333333333334, 1.0, 2.0, 0.7387305347464453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 841968.0759794725, 841968.075979473, 183607.8108979238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3913800.0000, 
sim time next is 3914400.0000, 
raw observation next is [26.43333333333334, 91.66666666666667, 1.0, 2.0, 0.724202435565198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825400.7598986909, 825400.7598986909, 180779.0301246073], 
processed observation next is [0.0, 0.30434782608695654, 0.5345679012345682, 0.9166666666666667, 1.0, 1.0, 0.6716695661490453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2947859856781039, 0.2947859856781039, 0.3476519810088602], 
reward next is 0.6523, 
noisyNet noise sample is [array([-3.1248736], dtype=float32), 1.7672176]. 
=============================================
[2019-03-23 23:53:19,919] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2226080: loss 0.0135
[2019-03-23 23:53:19,920] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2226080: learning rate 0.0010
[2019-03-23 23:53:20,048] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2226148: loss 0.0000
[2019-03-23 23:53:20,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2226148: learning rate 0.0010
[2019-03-23 23:53:20,485] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2226368: loss 0.0034
[2019-03-23 23:53:20,487] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2226369: learning rate 0.0010
[2019-03-23 23:53:20,568] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2226421: loss 0.0008
[2019-03-23 23:53:20,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2226422: learning rate 0.0010
[2019-03-23 23:53:20,637] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2226449: loss 0.0025
[2019-03-23 23:53:20,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2226449: learning rate 0.0010
[2019-03-23 23:53:20,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.893983e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:53:20,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3504
[2019-03-23 23:53:20,715] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 88.16666666666666, 1.0, 2.0, 0.7527109472435208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857911.1682090145, 857911.1682090145, 186366.0132743325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3916200.0000, 
sim time next is 3916800.0000, 
raw observation next is [27.3, 87.0, 1.0, 2.0, 0.7534482578789281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858751.9974890278, 858751.9974890278, 186512.6232461117], 
processed observation next is [0.0, 0.34782608695652173, 0.5666666666666667, 0.87, 1.0, 1.0, 0.7064860212844382, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30669714196036707, 0.30669714196036707, 0.3586781216271379], 
reward next is 0.6413, 
noisyNet noise sample is [array([0.11013649], dtype=float32), 1.6591274]. 
=============================================
[2019-03-23 23:53:21,046] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2226663: loss 0.0094
[2019-03-23 23:53:21,047] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2226663: learning rate 0.0010
[2019-03-23 23:53:21,866] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2227089: loss 0.0037
[2019-03-23 23:53:21,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2227091: learning rate 0.0010
[2019-03-23 23:53:22,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2230153e-25 1.0000000e+00 1.4034476e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:22,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7145
[2019-03-23 23:53:22,739] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 76.33333333333333, 1.0, 2.0, 0.7723117779333354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880264.2753882443, 880264.2753882443, 190290.488525072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3955200.0000, 
sim time next is 3955800.0000, 
raw observation next is [29.15, 77.66666666666667, 1.0, 2.0, 0.7791968963456898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888116.3315116852, 888116.3315116852, 191684.4756632553], 
processed observation next is [0.0, 0.782608695652174, 0.6351851851851852, 0.7766666666666667, 1.0, 1.0, 0.7371391623162974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31718440411131615, 0.31718440411131615, 0.36862399166010634], 
reward next is 0.6314, 
noisyNet noise sample is [array([-1.4052154], dtype=float32), 0.34275356]. 
=============================================
[2019-03-23 23:53:22,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0755717e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:22,856] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1838
[2019-03-23 23:53:22,860] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.771609890515014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879463.8202674534, 879463.8202674534, 190152.0553008922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7640533583523271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870846.159454618, 870846.159454618, 188632.9325222276], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7191111408956276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31101648551950645, 0.31101648551950645, 0.36275563946582234], 
reward next is 0.6372, 
noisyNet noise sample is [array([-0.4670993], dtype=float32), -0.09079977]. 
=============================================
[2019-03-23 23:53:24,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6177013e-23 1.0000000e+00 1.0435198e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:24,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9119
[2019-03-23 23:53:24,069] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.788674767442671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 901778.0216165015, 901778.0216165015, 193756.5838056124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3999000.0000, 
sim time next is 3999600.0000, 
raw observation next is [24.4, 94.0, 1.0, 2.0, 0.7524015776847948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860534.9805504632, 860534.9805504632, 186451.6835783528], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.94, 1.0, 1.0, 0.7052399734342795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30733392162516543, 0.30733392162516543, 0.35856092995837074], 
reward next is 0.6414, 
noisyNet noise sample is [array([-0.8459532], dtype=float32), 1.9081421]. 
=============================================
[2019-03-23 23:53:25,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0557218e-20 1.0000000e+00 1.6173680e-31 1.6403742e-34 6.1577339e-34], sum to 1.0000
[2019-03-23 23:53:25,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5840
[2019-03-23 23:53:25,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1804492.806748121 W.
[2019-03-23 23:53:25,081] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.2, 92.33333333333334, 1.0, 2.0, 0.5274250840645772, 1.0, 1.0, 0.5274250840645772, 1.0, 2.0, 0.8396779108666036, 6.9112, 6.9112, 121.94756008, 1804492.806748121, 1804492.806748121, 357253.4621929639], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4011000.0000, 
sim time next is 4011600.0000, 
raw observation next is [25.4, 90.66666666666667, 1.0, 2.0, 0.9160136501100418, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1759364.458925985, 1759364.458925984, 360446.3890829447], 
processed observation next is [1.0, 0.43478260869565216, 0.49629629629629624, 0.9066666666666667, 1.0, 1.0, 0.9000162501310021, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6283444496164232, 0.6283444496164229, 0.6931661328518167], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07608613], dtype=float32), -0.79414755]. 
=============================================
[2019-03-23 23:53:25,336] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2228849: loss 1.0537
[2019-03-23 23:53:25,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2228850: learning rate 0.0010
[2019-03-23 23:53:26,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4660436e-17 1.0000000e+00 3.2500257e-27 5.7824610e-30 7.0831979e-30], sum to 1.0000
[2019-03-23 23:53:26,449] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2777
[2019-03-23 23:53:26,452] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 98.0, 1.0, 2.0, 0.4725258959950108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573388.9975350302, 573388.9975350302, 138977.381521455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4060200.0000, 
sim time next is 4060800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4487397923208389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549149.8090784793, 549149.8090784793, 135523.2503132933], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 1.0, 1.0, 0.3437378480009987, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1961249318137426, 0.1961249318137426, 0.26062163521787174], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.42229044], dtype=float32), 0.6231152]. 
=============================================
[2019-03-23 23:53:29,000] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2230739: loss -174.4009
[2019-03-23 23:53:29,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2230739: learning rate 0.0010
[2019-03-23 23:53:31,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7863266e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:31,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3092
[2019-03-23 23:53:31,754] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 90.0, 1.0, 2.0, 0.5063888092171285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614282.8036685243, 614282.8036685243, 144255.0110237523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4338000.0000, 
sim time next is 4338600.0000, 
raw observation next is [22.0, 89.83333333333333, 1.0, 2.0, 0.5172293204959605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 626900.6258914957, 626900.6258914953, 145972.8810610166], 
processed observation next is [1.0, 0.21739130434782608, 0.37037037037037035, 0.8983333333333333, 1.0, 1.0, 0.4252730005904291, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22389308067553418, 0.223893080675534, 0.28071707896349346], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.26976493], dtype=float32), 0.04976105]. 
=============================================
[2019-03-23 23:53:32,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0909305e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:32,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3756
[2019-03-23 23:53:32,621] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 94.5, 1.0, 2.0, 0.4528912634971549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552101.4614570029, 552101.4614570029, 136084.0669607614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4140600.0000, 
sim time next is 4141200.0000, 
raw observation next is [21.13333333333333, 95.0, 1.0, 2.0, 0.4574483489257763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556538.5049302347, 556538.5049302347, 136735.1035747267], 
processed observation next is [1.0, 0.9565217391304348, 0.33827160493827146, 0.95, 1.0, 1.0, 0.3541051772925909, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19876375176079814, 0.19876375176079814, 0.2629521222590898], 
reward next is 0.7370, 
noisyNet noise sample is [array([2.3827777], dtype=float32), 0.6191939]. 
=============================================
[2019-03-23 23:53:33,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2232833: loss 0.0154
[2019-03-23 23:53:33,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2232833: learning rate 0.0010
[2019-03-23 23:53:34,176] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2233390: loss 0.0748
[2019-03-23 23:53:34,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2233392: learning rate 0.0010
[2019-03-23 23:53:34,460] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2233539: loss 0.1506
[2019-03-23 23:53:34,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2233539: learning rate 0.0010
[2019-03-23 23:53:35,011] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2233815: loss 0.2579
[2019-03-23 23:53:35,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2233816: learning rate 0.0010
[2019-03-23 23:53:35,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2233875: loss 0.1740
[2019-03-23 23:53:35,114] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2233876: learning rate 0.0010
[2019-03-23 23:53:35,258] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2233950: loss 0.1365
[2019-03-23 23:53:35,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2233952: learning rate 0.0010
[2019-03-23 23:53:35,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2233955: loss 0.1112
[2019-03-23 23:53:35,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2233956: learning rate 0.0010
[2019-03-23 23:53:35,439] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2234044: loss 0.2483
[2019-03-23 23:53:35,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2234044: learning rate 0.0010
[2019-03-23 23:53:35,623] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2234132: loss 0.0944
[2019-03-23 23:53:35,626] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2234132: learning rate 0.0010
[2019-03-23 23:53:36,164] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2234414: loss 0.0269
[2019-03-23 23:53:36,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2234415: learning rate 0.0010
[2019-03-23 23:53:36,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2234448: loss 0.1137
[2019-03-23 23:53:36,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2234448: learning rate 0.0010
[2019-03-23 23:53:36,262] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2234463: loss 0.0201
[2019-03-23 23:53:36,264] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2234464: learning rate 0.0010
[2019-03-23 23:53:36,785] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2234740: loss 0.0277
[2019-03-23 23:53:36,786] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2234740: learning rate 0.0010
[2019-03-23 23:53:37,236] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2234975: loss 0.1085
[2019-03-23 23:53:37,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2234976: learning rate 0.0010
[2019-03-23 23:53:38,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3855513e-23 1.0000000e+00 2.9241337e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:38,668] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-23 23:53:38,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1641921.785650371 W.
[2019-03-23 23:53:38,679] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.8, 36.0, 1.0, 2.0, 0.7892988248195123, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9732729208002426, 6.9112, 6.9112, 121.9260426156618, 1641921.785650371, 1641921.785650371, 329505.7331698909], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4282200.0000, 
sim time next is 4282800.0000, 
raw observation next is [33.06666666666666, 35.33333333333333, 1.0, 2.0, 0.7436544455198695, 1.0, 1.0, 0.7436544455198695, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1736972.09208534, 1736972.09208534, 323055.4501724668], 
processed observation next is [1.0, 0.5652173913043478, 0.7802469135802468, 0.3533333333333333, 1.0, 1.0, 0.6948267208569875, 1.0, 0.5, 0.6948267208569875, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6203471757447643, 0.6203471757447643, 0.6212604811008977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6594154], dtype=float32), -0.39997178]. 
=============================================
[2019-03-23 23:53:40,540] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2236647: loss 0.1001
[2019-03-23 23:53:40,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2236648: learning rate 0.0010
[2019-03-23 23:53:44,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2238663: loss 0.2413
[2019-03-23 23:53:44,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2238663: learning rate 0.0010
[2019-03-23 23:53:48,808] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2240876: loss -100.6568
[2019-03-23 23:53:48,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2240876: learning rate 0.0010
[2019-03-23 23:53:49,754] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2241335: loss 0.0174
[2019-03-23 23:53:49,757] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2241335: learning rate 0.0010
[2019-03-23 23:53:49,797] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2241358: loss 0.0064
[2019-03-23 23:53:49,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2241361: learning rate 0.0010
[2019-03-23 23:53:50,811] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2241848: loss 0.0350
[2019-03-23 23:53:50,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2241848: learning rate 0.0010
[2019-03-23 23:53:50,830] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2241857: loss 0.0352
[2019-03-23 23:53:50,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2241857: learning rate 0.0010
[2019-03-23 23:53:50,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2241894: loss 0.0158
[2019-03-23 23:53:50,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2241895: learning rate 0.0010
[2019-03-23 23:53:51,193] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2242031: loss 0.0007
[2019-03-23 23:53:51,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2242032: learning rate 0.0010
[2019-03-23 23:53:51,315] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2242099: loss 0.0068
[2019-03-23 23:53:51,318] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2242099: learning rate 0.0010
[2019-03-23 23:53:51,518] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2242196: loss 0.0051
[2019-03-23 23:53:51,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2242198: learning rate 0.0010
[2019-03-23 23:53:51,842] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2242350: loss 0.0069
[2019-03-23 23:53:51,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2242351: learning rate 0.0010
[2019-03-23 23:53:51,852] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2242358: loss 0.0136
[2019-03-23 23:53:51,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2242358: learning rate 0.0010
[2019-03-23 23:53:52,210] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2242528: loss 0.0055
[2019-03-23 23:53:52,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2242529: learning rate 0.0010
[2019-03-23 23:53:52,627] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2242736: loss 0.0303
[2019-03-23 23:53:52,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2242736: learning rate 0.0010
[2019-03-23 23:53:52,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7154564e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:53:52,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-23 23:53:52,651] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 87.5, 1.0, 2.0, 0.6064850753628971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699672.1593667789, 699672.1593667789, 159610.0435157321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4530600.0000, 
sim time next is 4531200.0000, 
raw observation next is [24.8, 87.0, 1.0, 2.0, 0.5995676539194082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 693435.0974533957, 693435.0974533953, 158493.1203539531], 
processed observation next is [0.0, 0.43478260869565216, 0.4740740740740741, 0.87, 1.0, 1.0, 0.5232948260945336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24765539194764133, 0.24765539194764116, 0.3047944622191406], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.0124674], dtype=float32), 0.0010096725]. 
=============================================
[2019-03-23 23:53:52,852] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2242845: loss 0.0010
[2019-03-23 23:53:52,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2242846: learning rate 0.0010
[2019-03-23 23:53:56,910] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2244841: loss -173.4648
[2019-03-23 23:53:56,916] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2244843: learning rate 0.0010
[2019-03-23 23:54:01,077] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2246873: loss -171.3346
[2019-03-23 23:54:01,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2246873: learning rate 0.0010
[2019-03-23 23:54:05,304] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2248948: loss 0.0084
[2019-03-23 23:54:05,312] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2248949: learning rate 0.0010
[2019-03-23 23:54:06,188] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2249383: loss -126.4995
[2019-03-23 23:54:06,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2249383: learning rate 0.0010
[2019-03-23 23:54:06,237] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2249404: loss -134.1237
[2019-03-23 23:54:06,241] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2249404: learning rate 0.0010
[2019-03-23 23:54:07,054] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2249807: loss -113.0637
[2019-03-23 23:54:07,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2249807: learning rate 0.0010
[2019-03-23 23:54:07,330] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2249942: loss -121.2399
[2019-03-23 23:54:07,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2249943: learning rate 0.0010
[2019-03-23 23:54:07,376] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2249961: loss -95.7869
[2019-03-23 23:54:07,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2249962: learning rate 0.0010
[2019-03-23 23:54:07,457] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 23:54:07,460] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:54:07,462] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:54:07,462] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:54:07,463] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:54:07,464] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:54:07,465] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:54:07,465] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:54:07,466] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:54:07,467] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:54:07,467] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:54:07,486] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 23:54:07,512] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 23:54:07,540] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 23:54:07,568] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 23:54:07,591] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 23:54:16,924] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:54:16,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.7, 61.0, 1.0, 2.0, 0.2572604015252331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 331605.6557455248, 331605.6557455252, 110446.55912903]
[2019-03-23 23:54:16,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:54:16,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.006447211134269937
[2019-03-23 23:54:17,087] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:54:17,090] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.53333333333333, 75.16666666666667, 1.0, 2.0, 0.2010618835008811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 259341.8584979927, 259341.8584979927, 83091.13539871527]
[2019-03-23 23:54:17,092] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:54:17,094] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.3783676676859382
[2019-03-23 23:54:36,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:54:36,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.8, 63.0, 1.0, 2.0, 0.5814415200133388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671481.6581717798, 671481.6581717798, 155343.4311367376]
[2019-03-23 23:54:36,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:54:36,678] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.13215522255446166
[2019-03-23 23:54:43,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:54:43,903] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 49.0, 1.0, 2.0, 0.6372582879226152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726260.2985779662, 726260.2985779662, 164606.5318782501]
[2019-03-23 23:54:43,904] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:54:43,907] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.7486575129486154
[2019-03-23 23:55:01,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:01,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.35803409, 60.23570907, 1.0, 2.0, 0.7894756156956267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899838.7314888258, 899838.7314888258, 193785.1187546111]
[2019-03-23 23:55:01,316] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:55:01,318] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.2046421024448517
[2019-03-23 23:55:19,863] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:19,864] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.08604504166667, 81.52951178166668, 1.0, 2.0, 0.7203105050634306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156594, 856826.0642463362, 856826.0642463358, 181687.4914756922]
[2019-03-23 23:55:19,866] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:55:19,869] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.07925270731692269
[2019-03-23 23:55:28,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:28,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.12678520333333, 57.58135926, 1.0, 2.0, 0.3861387271980674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478902.1322705271, 478902.1322705271, 126693.4653330269]
[2019-03-23 23:55:28,372] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:55:28,375] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.33369534105049214
[2019-03-23 23:55:33,101] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:33,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.55, 58.0, 1.0, 2.0, 0.7694747142966801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156554, 877028.8013662639, 877028.8013662639, 189708.1392281533]
[2019-03-23 23:55:33,103] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:55:33,106] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.6275425387639303
[2019-03-23 23:55:33,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:33,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.35, 92.0, 1.0, 2.0, 0.4886856461074025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 585696.0174989552, 585696.0174989556, 141231.1476363891]
[2019-03-23 23:55:33,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:55:33,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.8877323824706196
[2019-03-23 23:55:37,171] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:37,172] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.47802986, 71.26300874833333, 1.0, 2.0, 0.5550265040097427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 650512.9827955976, 650512.9827955972, 151347.9253190674]
[2019-03-23 23:55:37,172] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:55:37,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.4480428476002517
[2019-03-23 23:55:51,017] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0968293]
[2019-03-23 23:55:51,018] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.1, 90.66666666666667, 1.0, 2.0, 0.2776235319146452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 356937.0893817184, 356937.0893817184, 112851.2244688812]
[2019-03-23 23:55:51,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:55:51,021] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4936030e-22 1.0000000e+00 8.6066551e-35 4.9477169e-38 1.5503203e-37], sampled 0.8153070642078902
[2019-03-23 23:55:52,670] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:55:52,672] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:55:52,799] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:55:52,808] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:55:53,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:55:54,020] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2250000, evaluation results [2250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:55:54,144] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2250065: loss -121.5099
[2019-03-23 23:55:54,145] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2250066: learning rate 0.0010
[2019-03-23 23:55:54,165] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2250071: loss -107.0675
[2019-03-23 23:55:54,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2250072: learning rate 0.0010
[2019-03-23 23:55:54,584] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2250289: loss -106.5210
[2019-03-23 23:55:54,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2250290: learning rate 0.0010
[2019-03-23 23:55:54,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2250328: loss -122.9504
[2019-03-23 23:55:54,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2250328: learning rate 0.0010
[2019-03-23 23:55:54,848] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2250428: loss -106.0676
[2019-03-23 23:55:54,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2250428: learning rate 0.0010
[2019-03-23 23:55:55,079] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2250547: loss -82.1855
[2019-03-23 23:55:55,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2250547: learning rate 0.0010
[2019-03-23 23:55:55,348] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2250685: loss -92.0921
[2019-03-23 23:55:55,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2250685: learning rate 0.0010
[2019-03-23 23:55:55,610] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2250822: loss -129.2469
[2019-03-23 23:55:55,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2250822: learning rate 0.0010
[2019-03-23 23:55:56,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3442512e-24 1.0000000e+00 1.3629541e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:55:56,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6693
[2019-03-23 23:55:56,938] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 98.33333333333334, 1.0, 2.0, 0.7031167994577994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801356.104164444, 801356.104164444, 176735.6157864665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4843200.0000, 
sim time next is 4843800.0000, 
raw observation next is [25.2, 97.5, 1.0, 2.0, 0.70136496241678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 799358.4597607526, 799358.4597607522, 176403.1477723934], 
processed observation next is [1.0, 0.043478260869565216, 0.4888888888888889, 0.975, 1.0, 1.0, 0.6444820981152143, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2854851642002688, 0.28548516420026865, 0.33923682263921806], 
reward next is 0.6608, 
noisyNet noise sample is [array([2.3674555], dtype=float32), 0.40602115]. 
=============================================
[2019-03-23 23:55:59,251] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2252696: loss 0.1611
[2019-03-23 23:55:59,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2252696: learning rate 0.0010
[2019-03-23 23:56:03,379] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2254820: loss 0.3505
[2019-03-23 23:56:03,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2254820: learning rate 0.0010
[2019-03-23 23:56:04,773] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.958726e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:56:04,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8736
[2019-03-23 23:56:04,790] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 77.0, 1.0, 2.0, 0.7044939120287528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802926.4486423738, 802926.4486423738, 176998.1210362162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5048400.0000, 
sim time next is 5049000.0000, 
raw observation next is [28.55, 76.0, 1.0, 2.0, 0.7082427428137017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807201.3193343551, 807201.3193343551, 177711.9473004138], 
processed observation next is [0.0, 0.43478260869565216, 0.612962962962963, 0.76, 1.0, 1.0, 0.6526699319210735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2882861854765554, 0.2882861854765554, 0.3417537448084881], 
reward next is 0.6582, 
noisyNet noise sample is [array([-0.27883786], dtype=float32), 0.7584798]. 
=============================================
[2019-03-23 23:56:04,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.63805]
 [64.63805]
 [64.63805]
 [64.63805]
 [64.63805]], R is [[64.64990997]
 [64.66303253]
 [64.67985535]
 [64.69299316]
 [64.7073288 ]].
[2019-03-23 23:56:07,377] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2256934: loss -155.0054
[2019-03-23 23:56:07,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2256935: learning rate 0.0010
[2019-03-23 23:56:08,100] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2257301: loss 0.0256
[2019-03-23 23:56:08,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2257302: learning rate 0.0010
[2019-03-23 23:56:08,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2637131e-23 1.0000000e+00 6.8057916e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:08,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4019
[2019-03-23 23:56:08,219] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 94.0, 1.0, 2.0, 0.4513362186301482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548323.8491054247, 548323.8491054247, 135795.0126054409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5805600.0000, 
sim time next is 5806200.0000, 
raw observation next is [21.25, 94.5, 1.0, 2.0, 0.4485743959702321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544887.8932311657, 544887.8932311657, 135380.8013971864], 
processed observation next is [1.0, 0.17391304347826086, 0.3425925925925926, 0.945, 1.0, 1.0, 0.3435409475836096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1946028190111306, 0.1946028190111306, 0.26034769499458926], 
reward next is 0.7397, 
noisyNet noise sample is [array([-0.7369655], dtype=float32), 1.529069]. 
=============================================
[2019-03-23 23:56:08,259] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2257385: loss 0.0170
[2019-03-23 23:56:08,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2257385: learning rate 0.0010
[2019-03-23 23:56:08,882] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2257703: loss 0.0324
[2019-03-23 23:56:08,883] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2257703: learning rate 0.0010
[2019-03-23 23:56:09,230] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2257887: loss 0.0050
[2019-03-23 23:56:09,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2257887: learning rate 0.0010
[2019-03-23 23:56:09,290] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2257921: loss 0.0111
[2019-03-23 23:56:09,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2257921: learning rate 0.0010
[2019-03-23 23:56:09,324] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2257936: loss 0.0318
[2019-03-23 23:56:09,331] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2257938: learning rate 0.0010
[2019-03-23 23:56:09,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2258082: loss 0.0019
[2019-03-23 23:56:09,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2258082: learning rate 0.0010
[2019-03-23 23:56:09,744] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2258162: loss 0.0024
[2019-03-23 23:56:09,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2258162: learning rate 0.0010
[2019-03-23 23:56:10,112] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2258352: loss 0.0030
[2019-03-23 23:56:10,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2258352: learning rate 0.0010
[2019-03-23 23:56:10,207] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2258402: loss 0.0010
[2019-03-23 23:56:10,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2258403: learning rate 0.0010
[2019-03-23 23:56:10,589] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2258600: loss 0.0220
[2019-03-23 23:56:10,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2258600: learning rate 0.0010
[2019-03-23 23:56:10,769] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2258691: loss 0.0094
[2019-03-23 23:56:10,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2258691: learning rate 0.0010
[2019-03-23 23:56:10,852] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2258736: loss 0.0035
[2019-03-23 23:56:10,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2258736: learning rate 0.0010
[2019-03-23 23:56:15,157] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2260806: loss -107.0377
[2019-03-23 23:56:15,164] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2260807: learning rate 0.0010
[2019-03-23 23:56:18,875] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2262772: loss -128.4096
[2019-03-23 23:56:18,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2262772: learning rate 0.0010
[2019-03-23 23:56:21,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5031188e-23 1.0000000e+00 2.1817958e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:21,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6979
[2019-03-23 23:56:21,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1636412.189347602 W.
[2019-03-23 23:56:21,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.95, 84.50000000000001, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.759086529807944, 6.9112, 121.9229929898117, 1636412.189347602, 1202229.362941897, 247695.0162284839], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5307000.0000, 
sim time next is 5307600.0000, 
raw observation next is [24.1, 84.0, 1.0, 2.0, 0.4137962841802446, 1.0, 1.0, 0.4137962841802446, 1.0, 1.0, 0.6589226902784763, 6.9112, 6.9112, 121.94756008, 1420939.561451695, 1420939.561451695, 303215.4320465071], 
processed observation next is [1.0, 0.43478260869565216, 0.4481481481481482, 0.84, 1.0, 1.0, 0.3021384335479102, 1.0, 0.5, 0.3021384335479102, 1.0, 0.5, 0.5736533628480953, 0.0, 0.0, 0.8096049824067558, 0.5074784148041768, 0.5074784148041768, 0.5831066000894367], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10222993], dtype=float32), -0.45806438]. 
=============================================
[2019-03-23 23:56:23,098] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2265007: loss 0.0394
[2019-03-23 23:56:23,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2265007: learning rate 0.0010
[2019-03-23 23:56:23,636] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2265278: loss -130.3843
[2019-03-23 23:56:23,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2265279: learning rate 0.0010
[2019-03-23 23:56:23,985] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2265444: loss -116.1557
[2019-03-23 23:56:23,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2265445: learning rate 0.0010
[2019-03-23 23:56:24,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3432747e-22 1.0000000e+00 3.7968674e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:24,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9470
[2019-03-23 23:56:24,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1879866.044389919 W.
[2019-03-23 23:56:24,455] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666667, 78.66666666666667, 1.0, 2.0, 0.8241483721910918, 1.0, 2.0, 0.8241483721910918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1879866.044389919, 1879866.04438992, 353834.009179797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5397600.0000, 
sim time next is 5398200.0000, 
raw observation next is [27.5, 80.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.015847370482563, 6.9112, 121.9254730613854, 1931721.44721624, 1878132.890583231, 383757.8442524462], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.8, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.01046473704825628, 0.0, 0.8094583475720354, 0.6899005168629428, 0.6707617466368683, 0.7379958543316273], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.72390985], dtype=float32), -1.14475]. 
=============================================
[2019-03-23 23:56:24,553] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2265716: loss -111.6092
[2019-03-23 23:56:24,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2265721: learning rate 0.0010
[2019-03-23 23:56:24,962] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2265912: loss -107.4786
[2019-03-23 23:56:24,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2265912: learning rate 0.0010
[2019-03-23 23:56:25,069] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2265971: loss -124.8324
[2019-03-23 23:56:25,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2265971: learning rate 0.0010
[2019-03-23 23:56:25,096] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2265981: loss -81.8195
[2019-03-23 23:56:25,101] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2265981: learning rate 0.0010
[2019-03-23 23:56:25,288] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2266069: loss -106.0131
[2019-03-23 23:56:25,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2266069: learning rate 0.0010
[2019-03-23 23:56:25,406] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2266129: loss -101.4887
[2019-03-23 23:56:25,407] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2266129: learning rate 0.0010
[2019-03-23 23:56:26,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2266446: loss -157.4357
[2019-03-23 23:56:26,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2266446: learning rate 0.0010
[2019-03-23 23:56:26,204] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2266524: loss -148.9356
[2019-03-23 23:56:26,206] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2266524: learning rate 0.0010
[2019-03-23 23:56:26,554] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2266691: loss -142.8719
[2019-03-23 23:56:26,555] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2266691: learning rate 0.0010
[2019-03-23 23:56:26,649] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2266735: loss -127.5975
[2019-03-23 23:56:26,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2266739: learning rate 0.0010
[2019-03-23 23:56:26,768] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2266793: loss -150.4013
[2019-03-23 23:56:26,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2266793: learning rate 0.0010
[2019-03-23 23:56:29,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.69637028e-22 1.00000000e+00 7.56185113e-32 1.16024306e-35
 2.25799507e-35], sum to 1.0000
[2019-03-23 23:56:29,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6394
[2019-03-23 23:56:29,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1772346.943342221 W.
[2019-03-23 23:56:29,363] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.09999999999999, 70.0, 1.0, 2.0, 0.9273863855836773, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1772346.943342221, 1772346.943342222, 362955.2685558464], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [32.3, 69.0, 1.0, 2.0, 0.6385942677253816, 1.0, 1.0, 0.6326617958391255, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2164978.187181104, 2164978.187181104, 413146.9043617463], 
processed observation next is [1.0, 0.5652173913043478, 0.7518518518518518, 0.69, 1.0, 1.0, 0.5697550806254543, 1.0, 0.5, 0.562692614094197, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7732064954218228, 0.7732064954218228, 0.7945132776187428], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17635408], dtype=float32), -1.2517774]. 
=============================================
[2019-03-23 23:56:29,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[52.54905]
 [52.54905]
 [52.54905]
 [52.54905]
 [52.54905]], R is [[52.02355576]
 [51.80533218]
 [51.56926346]
 [51.17067719]
 [50.78796005]].
[2019-03-23 23:56:29,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3898815e-20 1.0000000e+00 9.4818648e-32 2.9314858e-35 4.4390894e-35], sum to 1.0000
[2019-03-23 23:56:29,755] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3379
[2019-03-23 23:56:29,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3117184.292766992 W.
[2019-03-23 23:56:29,773] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 67.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 9.328556183971763, 6.9112, 121.9164654705672, 3117184.292766992, 1879379.101487319, 375459.5989804815], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491200.0000, 
sim time next is 5491800.0000, 
raw observation next is [32.84999999999999, 66.0, 1.0, 2.0, 0.9473567875270509, 1.0, 1.0, 0.7870430557399601, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2694070.300674553, 2694070.300674553, 502322.9019893047], 
processed observation next is [1.0, 0.5652173913043478, 0.7722222222222217, 0.66, 1.0, 1.0, 0.9373295089607748, 1.0, 0.5, 0.7464798282618573, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9621679645266261, 0.9621679645266261, 0.9660055807486628], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1348197], dtype=float32), -0.17740834]. 
=============================================
[2019-03-23 23:56:30,549] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2268632: loss 0.7186
[2019-03-23 23:56:30,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2268632: learning rate 0.0010
[2019-03-23 23:56:33,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.514631e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:56:33,177] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7578
[2019-03-23 23:56:33,180] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.7380903630853702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 841238.0399506387, 841238.0399506382, 183478.20820334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5542200.0000, 
sim time next is 5542800.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.7297828785119441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831764.4517768071, 831764.4517768071, 181856.9061141408], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.6783129506094573, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2970587327774311, 0.2970587327774311, 0.34972481945027073], 
reward next is 0.6503, 
noisyNet noise sample is [array([1.156316], dtype=float32), 1.1703165]. 
=============================================
[2019-03-23 23:56:34,650] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2270633: loss 0.1231
[2019-03-23 23:56:34,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2270633: learning rate 0.0010
[2019-03-23 23:56:38,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4641955e-24 1.0000000e+00 1.5131765e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:38,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 23:56:38,683] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 75.33333333333334, 1.0, 2.0, 0.6768381957296297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771390.7896262357, 771390.7896262357, 171805.3539883304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6387600.0000, 
sim time next is 6388200.0000, 
raw observation next is [27.95, 76.0, 1.0, 2.0, 0.6902084150502221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786636.6141249839, 786636.6141249839, 174297.8866368962], 
processed observation next is [0.0, 0.9565217391304348, 0.5907407407407407, 0.76, 1.0, 1.0, 0.6312004941074073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28094164790177995, 0.28094164790177995, 0.3351882435324927], 
reward next is 0.6648, 
noisyNet noise sample is [array([1.9846287], dtype=float32), -0.22263151]. 
=============================================
[2019-03-23 23:56:39,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9528297e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:39,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6756
[2019-03-23 23:56:39,091] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 81.33333333333334, 1.0, 2.0, 0.397705681947093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493247.1960383186, 493247.1960383186, 128306.9307477109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5874000.0000, 
sim time next is 5874600.0000, 
raw observation next is [21.4, 81.66666666666667, 1.0, 2.0, 0.3943092881691931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489404.2004775843, 489404.2004775843, 127838.8144660111], 
processed observation next is [1.0, 1.0, 0.3481481481481481, 0.8166666666666668, 1.0, 1.0, 0.2789396287728489, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17478721445628012, 0.17478721445628012, 0.24584387397309826], 
reward next is 0.7542, 
noisyNet noise sample is [array([0.63732505], dtype=float32), 0.083360225]. 
=============================================
[2019-03-23 23:56:39,242] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2272883: loss -115.3280
[2019-03-23 23:56:39,243] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2272883: learning rate 0.0010
[2019-03-23 23:56:40,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2357194e-24 1.0000000e+00 1.4643798e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:40,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7037
[2019-03-23 23:56:40,076] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 84.66666666666667, 1.0, 2.0, 0.7684692665214801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875882.1612927575, 875882.1612927575, 189516.8447921825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5687400.0000, 
sim time next is 5688000.0000, 
raw observation next is [27.9, 86.0, 1.0, 2.0, 0.770527012895192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 878228.8732341613, 878228.8732341608, 189931.3033332886], 
processed observation next is [0.0, 0.8695652173913043, 0.5888888888888888, 0.86, 1.0, 1.0, 0.7268178724942762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3136531690122005, 0.3136531690122003, 0.36525250641017043], 
reward next is 0.6347, 
noisyNet noise sample is [array([1.2787468], dtype=float32), 0.497352]. 
=============================================
[2019-03-23 23:56:40,080] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273295: loss 0.0418
[2019-03-23 23:56:40,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273295: learning rate 0.0010
[2019-03-23 23:56:40,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.9325]
 [66.9325]
 [66.9325]
 [66.9325]
 [66.9325]], R is [[66.89792633]
 [66.86449432]
 [66.83279419]
 [66.80330658]
 [66.77565002]].
[2019-03-23 23:56:40,166] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2273338: loss 0.0356
[2019-03-23 23:56:40,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2273338: learning rate 0.0010
[2019-03-23 23:56:40,692] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2273592: loss 0.0398
[2019-03-23 23:56:40,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2273593: learning rate 0.0010
[2019-03-23 23:56:40,920] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.929767e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:56:40,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7543
[2019-03-23 23:56:40,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1334694.44851108 W.
[2019-03-23 23:56:40,940] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.35, 65.0, 1.0, 2.0, 0.9413476595919941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.252285634251525, 6.9112, 121.9244880806547, 1334694.44851108, 1160030.344850394, 230745.1570126223], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5909400.0000, 
sim time next is 5910000.0000, 
raw observation next is [24.6, 64.0, 1.0, 2.0, 0.5034515199577038, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8202660790118911, 6.911199999999999, 6.9112, 121.9258371898836, 1225002.677944964, 1225002.677944965, 255618.4858291414], 
processed observation next is [1.0, 0.391304347826087, 0.46666666666666673, 0.64, 1.0, 1.0, 0.4088708570925045, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7753325987648637, -8.881784197001253e-17, 0.0, 0.8094607650065964, 0.43750095640891573, 0.43750095640891606, 0.4915740112098873], 
reward next is 0.5084, 
noisyNet noise sample is [array([0.10933779], dtype=float32), -0.6391152]. 
=============================================
[2019-03-23 23:56:40,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.21935]
 [69.21935]
 [69.21935]
 [69.21935]
 [69.21935]], R is [[69.0355835 ]
 [68.3452301 ]
 [67.66178131]
 [67.57984924]
 [67.5692215 ]].
[2019-03-23 23:56:41,393] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2273933: loss 0.0189
[2019-03-23 23:56:41,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2273933: learning rate 0.0010
[2019-03-23 23:56:41,407] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2273939: loss 0.0092
[2019-03-23 23:56:41,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2273941: learning rate 0.0010
[2019-03-23 23:56:41,548] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2274007: loss 0.0087
[2019-03-23 23:56:41,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2274007: learning rate 0.0010
[2019-03-23 23:56:41,593] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2274029: loss 0.0036
[2019-03-23 23:56:41,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2274029: learning rate 0.0010
[2019-03-23 23:56:41,987] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2274219: loss 0.0060
[2019-03-23 23:56:41,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2274219: learning rate 0.0010
[2019-03-23 23:56:42,422] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2274426: loss 0.0003
[2019-03-23 23:56:42,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2274426: learning rate 0.0010
[2019-03-23 23:56:42,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2274519: loss 0.0003
[2019-03-23 23:56:42,612] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2274520: learning rate 0.0010
[2019-03-23 23:56:42,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2535651e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:56:42,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9586
[2019-03-23 23:56:42,759] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 96.16666666666666, 1.0, 2.0, 0.5318552572104641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630281.672019112, 630281.672019112, 147833.9577955492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706600.0000, 
sim time next is 5707200.0000, 
raw observation next is [22.33333333333334, 96.33333333333333, 1.0, 2.0, 0.5284320880873269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626979.9318578771, 626979.9318578771, 147308.4711238231], 
processed observation next is [0.0, 0.043478260869565216, 0.38271604938271625, 0.9633333333333333, 1.0, 1.0, 0.4386096286753891, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2239214042349561, 0.2239214042349561, 0.2832855213919675], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.4780976], dtype=float32), -0.23573278]. 
=============================================
[2019-03-23 23:56:42,998] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2274710: loss 0.0003
[2019-03-23 23:56:43,001] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2274712: learning rate 0.0010
[2019-03-23 23:56:43,280] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2274850: loss 0.0004
[2019-03-23 23:56:43,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2274850: learning rate 0.0010
[2019-03-23 23:56:43,313] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2274865: loss 0.0000
[2019-03-23 23:56:43,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2274866: learning rate 0.0010
[2019-03-23 23:56:43,588] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 23:56:43,589] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:56:43,591] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:56:43,593] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:43,592] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:43,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:56:43,592] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:56:43,595] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:43,600] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:43,597] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:56:43,603] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:43,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 23:56:43,650] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 23:56:43,651] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 23:56:43,651] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 23:56:43,721] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 23:56:55,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:56:55,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.778629045, 22.28086261666667, 1.0, 2.0, 0.6247108222936818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803475.6947936441, 803475.6947936441, 165099.2971726494]
[2019-03-23 23:56:55,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:56:55,138] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4037112647068518
[2019-03-23 23:57:11,641] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:57:11,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.13333333333333, 95.33333333333334, 1.0, 2.0, 0.3565363708697593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446349.3504985003, 446349.3504985003, 122755.2285906101]
[2019-03-23 23:57:11,644] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:57:11,648] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6170882958449269
[2019-03-23 23:57:34,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:57:34,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 87.0, 1.0, 2.0, 0.8618415093846526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013835.535287393, 1013835.535287393, 210643.0126438079]
[2019-03-23 23:57:34,033] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:57:34,038] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4481494165355756
[2019-03-23 23:58:15,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:58:15,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.66666666666667, 67.33333333333334, 1.0, 2.0, 0.6286730591189003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716471.4503040918, 716471.4503040918, 163079.3129945763]
[2019-03-23 23:58:15,792] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:58:15,794] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1473235654261581
[2019-03-23 23:58:20,690] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:58:20,693] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.5, 53.33333333333334, 1.0, 2.0, 0.7309773987073318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848927.0838929097, 848927.0838929097, 182876.3665000925]
[2019-03-23 23:58:20,694] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:58:20,695] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.16209389231087534
[2019-03-23 23:58:26,899] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -1.0142303]
[2019-03-23 23:58:26,900] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 79.0, 1.0, 2.0, 0.2447131088923478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 315657.4526052884, 315657.4526052884, 106091.0051057015]
[2019-03-23 23:58:26,902] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:58:26,905] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0170099e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5635032077368359
[2019-03-23 23:58:28,959] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:58:28,961] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:58:29,345] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:58:29,367] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:58:29,440] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:58:30,457] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2275000, evaluation results [2275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:58:32,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0413712e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:32,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0196
[2019-03-23 23:58:32,584] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 85.0, 1.0, 2.0, 0.4904736249082062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588215.4246070307, 588215.4246070307, 141522.3106405057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5788200.0000, 
sim time next is 5788800.0000, 
raw observation next is [23.1, 85.0, 1.0, 2.0, 0.4866668928933349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584490.0187378175, 584490.0187378171, 140960.2111245544], 
processed observation next is [1.0, 0.0, 0.41111111111111115, 0.85, 1.0, 1.0, 0.3888891582063511, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20874643526350625, 0.20874643526350609, 0.27107732908568155], 
reward next is 0.7289, 
noisyNet noise sample is [array([1.1301388], dtype=float32), 0.1694044]. 
=============================================
[2019-03-23 23:58:33,337] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8570567e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:33,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6803
[2019-03-23 23:58:33,353] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 84.0, 1.0, 2.0, 0.5121093124352167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609122.8329825962, 609122.8329825958, 144747.7659877211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5784000.0000, 
sim time next is 5784600.0000, 
raw observation next is [23.7, 84.5, 1.0, 2.0, 0.5104663398493184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607509.8423786379, 607509.8423786379, 144499.4763170625], 
processed observation next is [0.0, 0.9565217391304348, 0.4333333333333333, 0.845, 1.0, 1.0, 0.4172218331539505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21696780084951353, 0.21696780084951353, 0.2778836083020433], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.04330757], dtype=float32), -0.28008854]. 
=============================================
[2019-03-23 23:58:33,475] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2276551: loss -105.5555
[2019-03-23 23:58:33,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2276552: learning rate 0.0010
[2019-03-23 23:58:37,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2278813: loss -82.3195
[2019-03-23 23:58:37,862] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2278814: learning rate 0.0010
[2019-03-23 23:58:42,318] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2281113: loss 0.0122
[2019-03-23 23:58:42,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2281114: learning rate 0.0010
[2019-03-23 23:58:42,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3821043e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:42,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9373
[2019-03-23 23:58:42,539] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 61.0, 1.0, 2.0, 0.4798338107353255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577159.6777315339, 577159.6777315339, 139934.8149052352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5945400.0000, 
sim time next is 5946000.0000, 
raw observation next is [26.66666666666666, 61.66666666666667, 1.0, 2.0, 0.481290186772629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579001.4724363487, 579001.4724363487, 140162.2800339863], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432096, 0.6166666666666667, 1.0, 1.0, 0.3824883175864631, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20678624015583882, 0.20678624015583882, 0.2695428462192044], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.36879835], dtype=float32), 0.7184748]. 
=============================================
[2019-03-23 23:58:42,548] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2281234: loss -129.2514
[2019-03-23 23:58:42,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2281234: learning rate 0.0010
[2019-03-23 23:58:42,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.508514]
 [71.508514]
 [71.508514]
 [71.508514]
 [71.508514]], R is [[71.52388   ]
 [71.53953552]
 [71.55536652]
 [71.57113647]
 [71.58712769]].
[2019-03-23 23:58:42,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2281304: loss -101.1747
[2019-03-23 23:58:42,697] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2281304: learning rate 0.0010
[2019-03-23 23:58:43,204] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2281566: loss -138.1001
[2019-03-23 23:58:43,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2281567: learning rate 0.0010
[2019-03-23 23:58:43,949] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2281909: loss -111.0154
[2019-03-23 23:58:43,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2281910: learning rate 0.0010
[2019-03-23 23:58:44,077] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2281975: loss -136.8659
[2019-03-23 23:58:44,080] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2281975: learning rate 0.0010
[2019-03-23 23:58:44,136] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2282009: loss -93.0663
[2019-03-23 23:58:44,139] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2282010: learning rate 0.0010
[2019-03-23 23:58:44,287] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2282085: loss -93.7074
[2019-03-23 23:58:44,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2282085: learning rate 0.0010
[2019-03-23 23:58:44,546] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2282215: loss -103.0381
[2019-03-23 23:58:44,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2282215: learning rate 0.0010
[2019-03-23 23:58:44,870] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2282385: loss -99.9802
[2019-03-23 23:58:44,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2282385: learning rate 0.0010
[2019-03-23 23:58:45,038] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2282470: loss -143.0567
[2019-03-23 23:58:45,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2282471: learning rate 0.0010
[2019-03-23 23:58:45,391] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2282655: loss -128.7876
[2019-03-23 23:58:45,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2282655: learning rate 0.0010
[2019-03-23 23:58:45,601] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2282761: loss -101.9104
[2019-03-23 23:58:45,604] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2282761: learning rate 0.0010
[2019-03-23 23:58:45,991] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2282960: loss -122.5243
[2019-03-23 23:58:45,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2282962: learning rate 0.0010
[2019-03-23 23:58:48,281] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.487328e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:58:48,288] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-23 23:58:48,296] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1645036.824199598 W.
[2019-03-23 23:58:48,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.63333333333333, 61.66666666666667, 1.0, 2.0, 0.7212920661453879, 1.0, 1.0, 0.7212920661453879, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1645036.824199598, 1645036.824199599, 312302.9569174092], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6090000.0000, 
sim time next is 6090600.0000, 
raw observation next is [28.76666666666667, 60.83333333333333, 1.0, 2.0, 0.8059126697040783, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977647101559249, 6.911199999999999, 6.9112, 121.9260426156618, 1633697.491147515, 1633697.491147515, 337404.6739035536], 
processed observation next is [1.0, 0.4782608695652174, 0.6209876543209878, 0.6083333333333333, 1.0, 1.0, 0.768943654409617, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.997205887694906, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.583463389695541, 0.583463389695541, 0.6488551421222184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43027848], dtype=float32), -0.49233824]. 
=============================================
[2019-03-23 23:58:49,075] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2284548: loss 0.0373
[2019-03-23 23:58:49,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2284549: learning rate 0.0010
[2019-03-23 23:58:51,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2408768e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:51,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7180
[2019-03-23 23:58:51,080] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 90.0, 1.0, 2.0, 0.564351323559941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671889.6252172573, 671889.6252172573, 153323.8051847325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6147600.0000, 
sim time next is 6148200.0000, 
raw observation next is [22.86666666666667, 90.0, 1.0, 2.0, 0.559624483373567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667076.1333464056, 667076.1333464056, 152560.8291999832], 
processed observation next is [1.0, 0.13043478260869565, 0.4024691358024693, 0.9, 1.0, 1.0, 0.4757434325875797, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23824147619514485, 0.23824147619514485, 0.29338620999996773], 
reward next is 0.7066, 
noisyNet noise sample is [array([-1.1374134], dtype=float32), 0.7866912]. 
=============================================
[2019-03-23 23:58:53,201] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2286670: loss 0.1224
[2019-03-23 23:58:53,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2286670: learning rate 0.0010
[2019-03-23 23:58:56,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5036575e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:56,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8393
[2019-03-23 23:58:56,596] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 80.33333333333334, 1.0, 2.0, 0.5460135727722613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641154.1783912359, 641154.1783912359, 149911.368321784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6252600.0000, 
sim time next is 6253200.0000, 
raw observation next is [25.2, 80.0, 1.0, 2.0, 0.5511294969759273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645903.481836601, 645903.481836601, 150701.547605335], 
processed observation next is [0.0, 0.391304347826087, 0.4888888888888889, 0.8, 1.0, 1.0, 0.46563035354277055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23067981494164322, 0.23067981494164322, 0.2898106684717981], 
reward next is 0.7102, 
noisyNet noise sample is [array([1.0164015], dtype=float32), -0.4458757]. 
=============================================
[2019-03-23 23:58:57,933] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2289117: loss -69.8641
[2019-03-23 23:58:57,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2289120: learning rate 0.0010
[2019-03-23 23:58:58,000] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2289155: loss 0.0049
[2019-03-23 23:58:58,003] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2289156: learning rate 0.0010
[2019-03-23 23:58:58,330] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2289332: loss 0.0235
[2019-03-23 23:58:58,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2289333: learning rate 0.0010
[2019-03-23 23:58:58,792] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2289573: loss 0.0053
[2019-03-23 23:58:58,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2289573: learning rate 0.0010
[2019-03-23 23:58:59,342] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2289888: loss 0.0001
[2019-03-23 23:58:59,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2289889: learning rate 0.0010
[2019-03-23 23:58:59,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.577003e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:58:59,540] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2085
[2019-03-23 23:58:59,544] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 86.33333333333334, 1.0, 2.0, 0.5734593131208833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669545.532335665, 669545.532335665, 154323.921626353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6311400.0000, 
sim time next is 6312000.0000, 
raw observation next is [24.43333333333334, 86.66666666666667, 1.0, 2.0, 0.5742936660962548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670351.0677679334, 670351.0677679334, 154457.4849294374], 
processed observation next is [0.0, 0.043478260869565216, 0.4604938271604941, 0.8666666666666667, 1.0, 1.0, 0.4932067453526842, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23941109563140478, 0.23941109563140478, 0.2970336248643027], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.3460469], dtype=float32), -0.764362]. 
=============================================
[2019-03-23 23:58:59,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.9724]
 [65.9724]
 [65.9724]
 [65.9724]
 [65.9724]], R is [[66.01564026]
 [66.05870819]
 [66.10163116]
 [66.14442444]
 [66.18718719]].
[2019-03-23 23:58:59,560] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2289994: loss 0.0254
[2019-03-23 23:58:59,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2289994: learning rate 0.0010
[2019-03-23 23:58:59,629] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2290024: loss 0.0232
[2019-03-23 23:58:59,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2290024: learning rate 0.0010
[2019-03-23 23:58:59,757] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2290089: loss 0.0006
[2019-03-23 23:58:59,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2290089: learning rate 0.0010
[2019-03-23 23:58:59,930] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2290172: loss 0.0025
[2019-03-23 23:58:59,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2290173: learning rate 0.0010
[2019-03-23 23:59:00,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.128665e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:59:00,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0111
[2019-03-23 23:59:00,046] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666666, 61.33333333333333, 1.0, 2.0, 0.6908142164125136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787327.405879724, 787327.405879724, 174411.8493553651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352800.0000, 
sim time next is 6353400.0000, 
raw observation next is [30.83333333333334, 60.16666666666667, 1.0, 2.0, 0.6875110275544865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783560.8064772821, 783560.8064772821, 173792.5097834777], 
processed observation next is [0.0, 0.5217391304347826, 0.6975308641975311, 0.6016666666666667, 1.0, 1.0, 0.6279893185172457, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2798431451704579, 0.2798431451704579, 0.3342163649682263], 
reward next is 0.6658, 
noisyNet noise sample is [array([1.1612641], dtype=float32), -0.44404498]. 
=============================================
[2019-03-23 23:59:00,069] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2290242: loss 0.0075
[2019-03-23 23:59:00,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2290242: learning rate 0.0010
[2019-03-23 23:59:00,537] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2290464: loss 0.0013
[2019-03-23 23:59:00,540] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2290466: learning rate 0.0010
[2019-03-23 23:59:00,996] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2290685: loss 0.0013
[2019-03-23 23:59:00,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2290686: learning rate 0.0010
[2019-03-23 23:59:01,256] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2290813: loss 0.0003
[2019-03-23 23:59:01,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2290813: learning rate 0.0010
[2019-03-23 23:59:01,744] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2291051: loss 0.0004
[2019-03-23 23:59:01,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2291052: learning rate 0.0010
[2019-03-23 23:59:04,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6403026e-24 1.0000000e+00 6.5862911e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:59:04,383] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-23 23:59:04,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1435336.977900677 W.
[2019-03-23 23:59:04,394] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.55, 88.0, 1.0, 2.0, 0.6294282768377752, 1.0, 2.0, 0.6294282768377752, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260421237655, 1435336.977900677, 1435336.977900676, 278311.8968916998], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6402600.0000, 
sim time next is 6403200.0000, 
raw observation next is [25.5, 88.33333333333333, 1.0, 2.0, 0.5807575938808562, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9245850034127039, 6.9112, 6.9112, 121.9260426155118, 1324253.273615335, 1324253.273615335, 286448.7761544801], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.8833333333333333, 1.0, 1.0, 0.5009018974772098, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9057312542658799, 0.0, 0.0, 0.8094621288191401, 0.4729475977197625, 0.4729475977197625, 0.550863031066308], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8667903], dtype=float32), 0.36974376]. 
=============================================
[2019-03-23 23:59:04,962] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2292630: loss -67.5662
[2019-03-23 23:59:04,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2292630: learning rate 0.0010
[2019-03-23 23:59:07,985] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6903490e-21 1.0000000e+00 1.1103017e-33 3.3035575e-37 3.8521436e-36], sum to 1.0000
[2019-03-23 23:59:07,993] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3142
[2019-03-23 23:59:07,999] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.6890457452515938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785310.8302891499, 785310.8302891499, 174080.4375662615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465600.0000, 
sim time next is 6466200.0000, 
raw observation next is [30.08333333333334, 64.5, 1.0, 2.0, 0.6781439054198352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772879.653919917, 772879.653919917, 172047.8202711437], 
processed observation next is [1.0, 0.8695652173913043, 0.6697530864197533, 0.645, 1.0, 1.0, 0.6168379826426609, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27602844782854175, 0.27602844782854175, 0.33086119282912246], 
reward next is 0.6691, 
noisyNet noise sample is [array([0.69006586], dtype=float32), 0.3274483]. 
=============================================
[2019-03-23 23:59:08,821] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2294501: loss 0.0224
[2019-03-23 23:59:08,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2294501: learning rate 0.0010
[2019-03-23 23:59:08,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5087957e-23 1.0000000e+00 1.4878896e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 23:59:08,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3621
[2019-03-23 23:59:08,870] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.78333333333333, 69.5, 1.0, 2.0, 0.6655425433140666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 758510.7933670442, 758510.7933670437, 169722.4028654556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6473400.0000, 
sim time next is 6474000.0000, 
raw observation next is [28.66666666666667, 70.0, 1.0, 2.0, 0.6636484631082251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756351.0680375977, 756351.0680375977, 169375.3779437477], 
processed observation next is [1.0, 0.9565217391304348, 0.6172839506172841, 0.7, 1.0, 1.0, 0.599581503700268, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27012538144199916, 0.27012538144199916, 0.3257218806610533], 
reward next is 0.6743, 
noisyNet noise sample is [array([-0.44513372], dtype=float32), 0.45023802]. 
=============================================
[2019-03-23 23:59:08,892] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.44303]
 [59.44303]
 [59.44303]
 [59.44303]
 [59.44303]], R is [[59.52287292]
 [59.60125732]
 [59.67818069]
 [59.753582  ]
 [59.82753754]].
[2019-03-23 23:59:12,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3129243e-22 1.0000000e+00 2.0282739e-35 1.3693224e-37 1.4068521e-37], sum to 1.0000
[2019-03-23 23:59:12,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1993
[2019-03-23 23:59:12,703] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 85.50000000000001, 1.0, 2.0, 0.7116904817464083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811132.8696934327, 811132.8696934327, 178370.8463065555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6549000.0000, 
sim time next is 6549600.0000, 
raw observation next is [27.06666666666667, 86.0, 1.0, 2.0, 0.7126435609050775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812219.6953053667, 812219.6953053667, 178553.2935821962], 
processed observation next is [1.0, 0.8260869565217391, 0.5580246913580248, 0.86, 1.0, 1.0, 0.6579090010774732, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2900784626090595, 0.2900784626090595, 0.3433717184273004], 
reward next is 0.6566, 
noisyNet noise sample is [array([-0.787883], dtype=float32), 0.20910016]. 
=============================================
[2019-03-23 23:59:13,985] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2297011: loss 0.0408
[2019-03-23 23:59:13,989] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2297012: learning rate 0.0010
[2019-03-23 23:59:14,309] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2297158: loss -71.6588
[2019-03-23 23:59:14,310] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2297159: learning rate 0.0010
[2019-03-23 23:59:14,894] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2297437: loss -65.0745
[2019-03-23 23:59:14,896] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2297437: learning rate 0.0010
[2019-03-23 23:59:15,167] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2297579: loss -57.2775
[2019-03-23 23:59:15,169] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2297579: learning rate 0.0010
[2019-03-23 23:59:15,762] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2297863: loss -75.5983
[2019-03-23 23:59:15,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2297863: learning rate 0.0010
[2019-03-23 23:59:16,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2298041: loss -13.1413
[2019-03-23 23:59:16,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2298041: learning rate 0.0010
[2019-03-23 23:59:16,167] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2298061: loss -65.6806
[2019-03-23 23:59:16,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2298063: learning rate 0.0010
[2019-03-23 23:59:16,180] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2298067: loss -74.1687
[2019-03-23 23:59:16,183] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2298068: learning rate 0.0010
[2019-03-23 23:59:16,484] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2298219: loss -77.2934
[2019-03-23 23:59:16,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2298219: learning rate 0.0010
[2019-03-23 23:59:16,575] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2298261: loss -77.2294
[2019-03-23 23:59:16,576] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2298261: learning rate 0.0010
[2019-03-23 23:59:16,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2298472: loss -74.0139
[2019-03-23 23:59:16,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2298472: learning rate 0.0010
[2019-03-23 23:59:17,485] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2298713: loss -49.1994
[2019-03-23 23:59:17,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2298714: learning rate 0.0010
[2019-03-23 23:59:17,833] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2298878: loss -59.4499
[2019-03-23 23:59:17,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2298880: learning rate 0.0010
[2019-03-23 23:59:18,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2299042: loss -82.4558
[2019-03-23 23:59:18,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2299042: learning rate 0.0010
[2019-03-23 23:59:18,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.831395e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 23:59:18,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6977
[2019-03-23 23:59:18,920] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 49.33333333333333, 1.0, 2.0, 0.4944197353750281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590381.864098681, 590381.864098681, 142046.2796247138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 1.0, 2.0, 0.4990312110690504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594869.120835499, 594869.120835499, 142730.8563653702], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 1.0, 1.0, 0.40360858460601245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21245325744124965, 0.21245325744124965, 0.2744824160872504], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.76079625], dtype=float32), -0.9388974]. 
=============================================
[2019-03-23 23:59:20,127] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 23:59:20,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:59:20,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:59:20,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:59:20,129] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:59:20,130] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:59:20,130] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:59:20,131] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:59:20,130] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:59:20,131] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:59:20,131] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:59:20,146] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 23:59:20,171] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 23:59:20,196] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 23:59:20,198] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 23:59:20,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 23:59:27,401] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-23 23:59:27,403] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.59140324, 75.98334709166667, 1.0, 2.0, 0.3970812876289991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511326.9071063448, 511326.9071063448, 128402.6261107251]
[2019-03-23 23:59:27,405] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:59:27,407] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.019498178629738794
[2019-03-24 00:00:04,762] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:04,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.93333333333334, 48.0, 1.0, 2.0, 0.5514753579137299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640309.6037684492, 640309.6037684492, 150497.3606610014]
[2019-03-24 00:00:04,765] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:00:04,768] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.15884774282522673
[2019-03-24 00:00:26,398] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:26,401] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.4, 83.33333333333334, 1.0, 2.0, 0.5428593259067913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639160.7517999525, 639160.751799952, 149464.2723960075]
[2019-03-24 00:00:26,401] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:00:26,404] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6579896853485735
[2019-03-24 00:00:39,829] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:39,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.857720705, 82.71166343499999, 1.0, 2.0, 0.4811099160740586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575183.679801142, 575183.679801142, 140008.8127072889]
[2019-03-24 00:00:39,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:00:39,833] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9912988043528738
[2019-03-24 00:00:43,229] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:43,232] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.5, 83.0, 1.0, 2.0, 0.4130802993883881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510844.9991523761, 510844.9991523761, 130454.7855782272]
[2019-03-24 00:00:43,233] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:00:43,236] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.21860935928787528
[2019-03-24 00:00:48,078] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:48,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.70306299, 68.49531985833333, 1.0, 2.0, 0.7259620840395831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827407.3799794379, 827407.3799794379, 181117.6267959701]
[2019-03-24 00:00:48,080] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:00:48,083] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9530615443867152
[2019-03-24 00:00:54,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:00:54,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 49.0, 1.0, 2.0, 0.5580195494863893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652648.6042078888, 652648.6042078884, 151786.5286853809]
[2019-03-24 00:00:54,906] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:00:54,907] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1830739470862457
[2019-03-24 00:01:01,496] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9987504]
[2019-03-24 00:01:01,497] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.70074128333334, 82.67465431000001, 1.0, 2.0, 0.4320567669273886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526334.6648713775, 526334.6648713775, 132992.3785114755]
[2019-03-24 00:01:01,499] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:01:01,501] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3656732e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6878312098587822
[2019-03-24 00:01:05,373] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:01:05,581] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:01:05,598] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:01:05,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:01:05,746] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:01:06,763] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2300000, evaluation results [2300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:01:07,742] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2300505: loss 0.0061
[2019-03-24 00:01:07,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2300506: learning rate 0.0010
[2019-03-24 00:01:11,285] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2302333: loss 0.0094
[2019-03-24 00:01:11,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2302333: learning rate 0.0010
[2019-03-24 00:01:13,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.984505e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:01:13,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3326
[2019-03-24 00:01:13,414] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 50.33333333333333, 1.0, 2.0, 0.8030602954092736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926030586348, 997827.864427295, 997827.864427295, 199909.4023971784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6781200.0000, 
sim time next is 6781800.0000, 
raw observation next is [26.48333333333333, 50.16666666666667, 1.0, 2.0, 0.7875203336330939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426119938, 977809.4647989569, 977809.4647989573, 196609.6936188099], 
processed observation next is [1.0, 0.4782608695652174, 0.5364197530864196, 0.5016666666666667, 1.0, 1.0, 0.7470480162298737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621287957842, 0.34921766599962745, 0.3492176659996276, 0.37809556465155747], 
reward next is 0.6219, 
noisyNet noise sample is [array([-0.8898174], dtype=float32), 2.0920868]. 
=============================================
[2019-03-24 00:01:14,170] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1331304e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:14,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5466
[2019-03-24 00:01:14,179] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.3615282020127248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452814.4812998607, 452814.4812998607, 123426.9065572758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7167000.0000, 
sim time next is 7167600.0000, 
raw observation next is [19.8, 89.0, 1.0, 2.0, 0.361080466465221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452254.5932892781, 452254.5932892781, 123366.8104837094], 
processed observation next is [1.0, 1.0, 0.2888888888888889, 0.89, 1.0, 1.0, 0.2393815076966917, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1615194976033136, 0.1615194976033136, 0.23724386631482577], 
reward next is 0.7628, 
noisyNet noise sample is [array([0.09466037], dtype=float32), 0.7141391]. 
=============================================
[2019-03-24 00:01:15,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3964776e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:15,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4944
[2019-03-24 00:01:15,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 60.66666666666667, 1.0, 2.0, 0.4371701489201837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532963.4626864598, 532963.4626864598, 133752.5974998883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6860400.0000, 
sim time next is 6861000.0000, 
raw observation next is [26.23333333333333, 59.33333333333334, 1.0, 2.0, 0.437894842963704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533665.704929695, 533665.704929695, 133853.8295465575], 
processed observation next is [0.0, 0.391304347826087, 0.5271604938271603, 0.5933333333333334, 1.0, 1.0, 0.3308271940044096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1905948946177482, 0.1905948946177482, 0.2574112106664567], 
reward next is 0.7426, 
noisyNet noise sample is [array([-1.1493933], dtype=float32), -0.61640227]. 
=============================================
[2019-03-24 00:01:15,892] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.00088]
 [69.00088]
 [69.00088]
 [69.00088]
 [69.00088]], R is [[69.05345917]
 [69.10570526]
 [69.15764618]
 [69.20924377]
 [69.26045227]].
[2019-03-24 00:01:16,426] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2304989: loss 0.0677
[2019-03-24 00:01:16,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2304990: learning rate 0.0010
[2019-03-24 00:01:16,750] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2305157: loss 0.0013
[2019-03-24 00:01:16,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2305158: learning rate 0.0010
[2019-03-24 00:01:17,252] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2305412: loss 0.0004
[2019-03-24 00:01:17,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2305412: learning rate 0.0010
[2019-03-24 00:01:17,565] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2305570: loss 0.0163
[2019-03-24 00:01:17,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2305570: learning rate 0.0010
[2019-03-24 00:01:18,203] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2305906: loss 0.0448
[2019-03-24 00:01:18,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2305907: learning rate 0.0010
[2019-03-24 00:01:18,461] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2306039: loss 0.0026
[2019-03-24 00:01:18,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2306039: learning rate 0.0010
[2019-03-24 00:01:18,566] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2306095: loss 0.0011
[2019-03-24 00:01:18,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2306096: learning rate 0.0010
[2019-03-24 00:01:18,819] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2306228: loss 0.0160
[2019-03-24 00:01:18,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2306228: learning rate 0.0010
[2019-03-24 00:01:18,879] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2306257: loss 0.0103
[2019-03-24 00:01:18,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2306257: learning rate 0.0010
[2019-03-24 00:01:19,009] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2306326: loss 0.0000
[2019-03-24 00:01:19,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2306326: learning rate 0.0010
[2019-03-24 00:01:19,133] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2306392: loss 0.0010
[2019-03-24 00:01:19,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2306393: learning rate 0.0010
[2019-03-24 00:01:19,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3596478e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:19,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5271
[2019-03-24 00:01:19,555] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 85.66666666666667, 1.0, 2.0, 0.4204065669532469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517070.003503301, 517070.003503301, 131438.7215207398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6932400.0000, 
sim time next is 6933000.0000, 
raw observation next is [21.68333333333333, 85.33333333333334, 1.0, 2.0, 0.4230378501635422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519743.6915571488, 519743.6915571484, 131804.4223390517], 
processed observation next is [0.0, 0.21739130434782608, 0.35864197530864184, 0.8533333333333334, 1.0, 1.0, 0.3131402978137407, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.185622746984696, 0.18562274698469586, 0.2534700429597148], 
reward next is 0.7465, 
noisyNet noise sample is [array([2.284812], dtype=float32), 0.27345276]. 
=============================================
[2019-03-24 00:01:19,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.097084]
 [74.097084]
 [74.097084]
 [74.097084]
 [74.097084]], R is [[74.10264587]
 [74.10884857]
 [74.11548615]
 [74.12264252]
 [74.13050079]].
[2019-03-24 00:01:19,848] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2306754: loss 0.0166
[2019-03-24 00:01:19,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2306754: learning rate 0.0010
[2019-03-24 00:01:20,117] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2306898: loss 0.0018
[2019-03-24 00:01:20,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2306898: learning rate 0.0010
[2019-03-24 00:01:20,431] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2307059: loss 0.0039
[2019-03-24 00:01:20,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2307060: learning rate 0.0010
[2019-03-24 00:01:23,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2308521: loss 0.1731
[2019-03-24 00:01:23,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2308523: learning rate 0.0010
[2019-03-24 00:01:24,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.707051e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:01:24,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3259
[2019-03-24 00:01:24,021] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 88.0, 1.0, 2.0, 0.4331538285825101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 532591.7098035072, 532591.7098035068, 133288.2918898822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7021200.0000, 
sim time next is 7021800.0000, 
raw observation next is [21.35, 87.5, 1.0, 2.0, 0.4307008946851896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529442.604689321, 529442.604689321, 132925.9251009003], 
processed observation next is [1.0, 0.2608695652173913, 0.3462962962962963, 0.875, 1.0, 1.0, 0.32226296986332087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18908664453190036, 0.18908664453190036, 0.2556267790401929], 
reward next is 0.7444, 
noisyNet noise sample is [array([1.6100959], dtype=float32), 0.24390413]. 
=============================================
[2019-03-24 00:01:26,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2310270: loss 0.3502
[2019-03-24 00:01:26,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2310270: learning rate 0.0010
[2019-03-24 00:01:27,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1540121e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:27,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-24 00:01:27,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 73.66666666666667, 1.0, 2.0, 0.8591769826395732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1043815.083411236, 1043815.083411236, 211411.5303169634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [24.2, 72.83333333333333, 1.0, 2.0, 0.868022465709464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053397.361253308, 1053397.361253308, 213336.4285134923], 
processed observation next is [1.0, 0.4782608695652174, 0.45185185185185184, 0.7283333333333333, 1.0, 1.0, 0.8428838877493618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3762133433047528, 0.3762133433047528, 0.4102623625259468], 
reward next is 0.5897, 
noisyNet noise sample is [array([0.96290684], dtype=float32), -1.1740774]. 
=============================================
[2019-03-24 00:01:28,974] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1337777e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:28,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0792
[2019-03-24 00:01:28,984] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.6555154906893286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813799.1866184906, 813799.1866184906, 170456.1721635787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119600.0000, 
sim time next is 7120200.0000, 
raw observation next is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.667170776235628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827468.4622224324, 827468.4622224324, 172621.85722846], 
processed observation next is [1.0, 0.391304347826087, 0.36604938271604964, 0.7833333333333333, 1.0, 1.0, 0.6037747336138429, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29552445079372586, 0.29552445079372586, 0.3319651100547308], 
reward next is 0.6680, 
noisyNet noise sample is [array([1.7424315], dtype=float32), 0.26215246]. 
=============================================
[2019-03-24 00:01:29,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.191273e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:01:29,545] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2875
[2019-03-24 00:01:29,555] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 68.33333333333334, 1.0, 2.0, 0.5780586111437397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717596.2518220862, 717596.2518220862, 156552.9868748421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7129200.0000, 
sim time next is 7129800.0000, 
raw observation next is [23.3, 67.5, 1.0, 2.0, 0.5206755551749338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 647099.2945523005, 647099.2945523009, 146957.7169189849], 
processed observation next is [1.0, 0.5217391304347826, 0.41851851851851857, 0.675, 1.0, 1.0, 0.4293756609225402, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23110689091153588, 0.23110689091153605, 0.2826109940749709], 
reward next is 0.7174, 
noisyNet noise sample is [array([-1.0313064], dtype=float32), 1.3417695]. 
=============================================
[2019-03-24 00:01:31,852] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2312963: loss 0.0085
[2019-03-24 00:01:31,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2312963: learning rate 0.0010
[2019-03-24 00:01:32,322] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2313204: loss 0.1512
[2019-03-24 00:01:32,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2313205: learning rate 0.0010
[2019-03-24 00:01:32,595] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2313327: loss 0.1822
[2019-03-24 00:01:32,599] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2313327: learning rate 0.0010
[2019-03-24 00:01:33,120] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2313597: loss 0.1608
[2019-03-24 00:01:33,123] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2313597: learning rate 0.0010
[2019-03-24 00:01:33,919] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2314010: loss 0.1977
[2019-03-24 00:01:33,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2314010: learning rate 0.0010
[2019-03-24 00:01:33,927] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2314010: loss 0.1801
[2019-03-24 00:01:33,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2314013: learning rate 0.0010
[2019-03-24 00:01:33,953] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2314025: loss 0.1651
[2019-03-24 00:01:33,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2314025: learning rate 0.0010
[2019-03-24 00:01:34,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2314208: loss 0.0760
[2019-03-24 00:01:34,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2314208: learning rate 0.0010
[2019-03-24 00:01:34,366] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2314237: loss 0.1009
[2019-03-24 00:01:34,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2314237: learning rate 0.0010
[2019-03-24 00:01:34,406] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2314264: loss 0.1063
[2019-03-24 00:01:34,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2314264: learning rate 0.0010
[2019-03-24 00:01:34,596] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2314361: loss 0.1128
[2019-03-24 00:01:34,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2314361: learning rate 0.0010
[2019-03-24 00:01:35,091] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2314626: loss 0.1273
[2019-03-24 00:01:35,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2314626: learning rate 0.0010
[2019-03-24 00:01:35,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:01:35,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:35,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 00:01:35,510] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2314832: loss 0.1164
[2019-03-24 00:01:35,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2314833: learning rate 0.0010
[2019-03-24 00:01:35,692] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2314945: loss 0.1604
[2019-03-24 00:01:35,695] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2314946: learning rate 0.0010
[2019-03-24 00:01:38,555] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2316438: loss 0.0134
[2019-03-24 00:01:38,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2316438: learning rate 0.0010
[2019-03-24 00:01:47,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2321041: loss 0.9487
[2019-03-24 00:01:47,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2321041: learning rate 0.0010
[2019-03-24 00:01:48,116] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321118: loss 0.0000
[2019-03-24 00:01:48,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321118: learning rate 0.0010
[2019-03-24 00:01:48,231] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2321172: loss 0.0103
[2019-03-24 00:01:48,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2321172: learning rate 0.0010
[2019-03-24 00:01:48,831] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2321467: loss 0.0218
[2019-03-24 00:01:48,835] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2321467: learning rate 0.0010
[2019-03-24 00:01:49,459] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2321779: loss 0.0355
[2019-03-24 00:01:49,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2321781: learning rate 0.0010
[2019-03-24 00:01:49,843] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2321966: loss 0.0060
[2019-03-24 00:01:49,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2321967: learning rate 0.0010
[2019-03-24 00:01:49,876] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2321980: loss 0.0029
[2019-03-24 00:01:49,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2321980: learning rate 0.0010
[2019-03-24 00:01:50,055] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2322067: loss 0.0160
[2019-03-24 00:01:50,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2322067: learning rate 0.0010
[2019-03-24 00:01:50,077] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2322076: loss 0.0102
[2019-03-24 00:01:50,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2322079: learning rate 0.0010
[2019-03-24 00:01:50,253] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2322164: loss 0.0028
[2019-03-24 00:01:50,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2322166: learning rate 0.0010
[2019-03-24 00:01:50,524] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2322301: loss 0.0009
[2019-03-24 00:01:50,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2322302: learning rate 0.0010
[2019-03-24 00:01:51,095] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2322581: loss 0.0069
[2019-03-24 00:01:51,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2322582: learning rate 0.0010
[2019-03-24 00:01:51,575] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2322819: loss 0.0255
[2019-03-24 00:01:51,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2322819: learning rate 0.0010
[2019-03-24 00:01:51,835] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2322945: loss 0.0007
[2019-03-24 00:01:51,837] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2322946: learning rate 0.0010
[2019-03-24 00:01:52,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8461272e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:01:52,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0942
[2019-03-24 00:01:52,644] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4376790944393379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533168.5250358587, 533168.5250358587, 133815.1866299729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7530600.0000, 
sim time next is 7531200.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4377585527517444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533265.4717438206, 533265.471743821, 133826.8733552294], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3306649437520767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19045195419422165, 0.1904519541942218, 0.25735937183697966], 
reward next is 0.7426, 
noisyNet noise sample is [array([1.7017707], dtype=float32), -0.92880493]. 
=============================================
[2019-03-24 00:01:54,956] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2324486: loss 0.4858
[2019-03-24 00:01:54,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2324486: learning rate 0.0010
[2019-03-24 00:01:56,012] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 00:01:56,014] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:01:56,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,015] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:01:56,016] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,016] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:01:56,016] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:01:56,017] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,017] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,017] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:01:56,018] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,042] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 00:01:56,069] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 00:01:56,094] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 00:01:56,095] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 00:01:56,141] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 00:01:56,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:01:56,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:56,621] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 00:02:09,535] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:02:09,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.63333333333333, 44.0, 1.0, 2.0, 0.3830755119561723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 477166.7149448316, 477166.714944832, 126313.6196872307]
[2019-03-24 00:02:09,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:02:09,541] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6638830176547563
[2019-03-24 00:02:47,311] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:02:47,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.504572165, 89.55637326, 1.0, 2.0, 0.3917459196787348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485908.0664564453, 485908.0664564453, 127474.0603474783]
[2019-03-24 00:02:47,313] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:02:47,315] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7447746182915645
[2019-03-24 00:02:56,396] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:02:56,396] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.33333333333334, 74.0, 1.0, 2.0, 0.9825227250406035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.036978633105727, 6.9112, 121.9252601963802, 1184489.847730584, 1120080.358942629, 236555.6155140292]
[2019-03-24 00:02:56,397] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:02:56,401] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3882253460215064
[2019-03-24 00:03:03,644] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:03:03,645] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.7063807153730699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805078.0072505722, 805078.0072505722, 177356.5382913137]
[2019-03-24 00:03:03,646] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:03:03,650] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.36853189797188857
[2019-03-24 00:03:08,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:03:08,604] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666667, 83.16666666666667, 1.0, 2.0, 0.784173480520864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 124.031099956062, 941036.8088489417, 941036.8088489422, 195201.3160817024]
[2019-03-24 00:03:08,605] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:03:08,607] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.29861879590971274
[2019-03-24 00:03:21,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9541041]
[2019-03-24 00:03:21,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.879354969114292, 1.0, 2.0, 0.879354969114292, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2005932.612479076, 2005932.612479077, 377634.750687048]
[2019-03-24 00:03:21,061] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:03:21,065] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.1218388e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7341068503787743
[2019-03-24 00:03:21,066] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2005932.612479076 W.
[2019-03-24 00:03:41,664] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:03:41,832] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:03:41,839] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:03:41,898] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:03:41,913] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:03:42,931] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2325000, evaluation results [2325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:03:44,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.23553036e-26 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-24 00:03:44,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3776
[2019-03-24 00:03:44,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 80.0, 1.0, 2.0, 0.3669010674134592, 1.0, 1.0, 0.3669010674134592, 1.0, 1.0, 0.5860875518825712, 6.911200000000001, 6.9112, 121.94756008, 1285609.593713279, 1285609.593713279, 282907.4074476185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7641000.0000, 
sim time next is 7641600.0000, 
raw observation next is [25.06666666666667, 79.33333333333334, 1.0, 2.0, 1.004362207639153, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.313398205500172, 6.9112, 121.9246136709388, 1377327.566523573, 1171368.551059609, 243225.631023007], 
processed observation next is [1.0, 0.43478260869565216, 0.4839506172839507, 0.7933333333333334, 1.0, 1.0, 1.005193104332325, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.04021982055001718, 0.0, 0.809452642113173, 0.49190270232984745, 0.4183459110927175, 0.46774159812116733], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4241934], dtype=float32), 0.33162704]. 
=============================================
[2019-03-24 00:03:49,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4712149e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:03:49,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8534
[2019-03-24 00:03:49,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1327192.881979748 W.
[2019-03-24 00:03:49,219] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.41666666666667, 51.83333333333334, 1.0, 2.0, 0.5633982180405744, 1.0, 2.0, 0.5633982180405744, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1327192.881979748, 1327192.881979748, 257634.6689970098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 123000.0000, 
sim time next is 123600.0000, 
raw observation next is [28.83333333333334, 50.66666666666667, 1.0, 2.0, 0.5968836585115561, 1.0, 2.0, 0.5968836585115561, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1404847.05450822, 1404847.05450822, 269000.3259530879], 
processed observation next is [1.0, 0.43478260869565216, 0.623456790123457, 0.5066666666666667, 1.0, 1.0, 0.5200995934661382, 1.0, 1.0, 0.5200995934661382, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5017310908957928, 0.5017310908957928, 0.5173083191405536], 
reward next is 0.4827, 
noisyNet noise sample is [array([-0.0175797], dtype=float32), -0.36193153]. 
=============================================
[2019-03-24 00:03:50,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:50,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:50,213] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 00:03:50,744] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2328997: loss 0.7808
[2019-03-24 00:03:50,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2328997: learning rate 0.0010
[2019-03-24 00:03:51,104] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2329185: loss 0.6871
[2019-03-24 00:03:51,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2329185: learning rate 0.0010
[2019-03-24 00:03:51,514] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2329418: loss 0.8530
[2019-03-24 00:03:51,518] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2329419: learning rate 0.0010
[2019-03-24 00:03:51,829] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2329601: loss 0.8847
[2019-03-24 00:03:51,831] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2329601: learning rate 0.0010
[2019-03-24 00:03:52,092] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2329741: loss 0.9330
[2019-03-24 00:03:52,097] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2329741: learning rate 0.0010
[2019-03-24 00:03:52,412] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2329900: loss 0.7153
[2019-03-24 00:03:52,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2329900: loss 0.6271
[2019-03-24 00:03:52,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2329900: learning rate 0.0010
[2019-03-24 00:03:52,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2329901: learning rate 0.0010
[2019-03-24 00:03:52,597] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2329992: loss 0.6058
[2019-03-24 00:03:52,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2329995: learning rate 0.0010
[2019-03-24 00:03:52,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2330000: loss 0.6216
[2019-03-24 00:03:52,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2330000: learning rate 0.0010
[2019-03-24 00:03:53,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2330272: loss 0.5377
[2019-03-24 00:03:53,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2330272: learning rate 0.0010
[2019-03-24 00:03:53,738] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2330578: loss 0.4733
[2019-03-24 00:03:53,741] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2330578: learning rate 0.0010
[2019-03-24 00:03:53,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2330708: loss 0.5383
[2019-03-24 00:03:53,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2330709: learning rate 0.0010
[2019-03-24 00:03:54,198] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2330808: loss 0.4392
[2019-03-24 00:03:54,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2330809: learning rate 0.0010
[2019-03-24 00:03:58,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:58,737] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:58,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 00:03:59,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:59,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:59,207] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 00:03:59,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:59,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:59,751] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 00:03:59,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:59,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:59,858] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 00:03:59,980] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:03:59,980] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:03:59,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 00:04:00,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:00,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:00,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 00:04:00,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:00,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:00,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 00:04:00,449] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:00,449] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:00,467] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 00:04:00,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:00,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:00,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 00:04:00,713] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:00,713] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:00,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 00:04:01,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:01,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:01,032] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 00:04:01,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:01,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:01,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 00:04:01,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:04:01,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:01,201] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 00:04:03,119] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.202889e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:04:03,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1529
[2019-03-24 00:04:03,130] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 58.0, 1.0, 2.0, 0.3120308511521739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396570.7243281645, 396570.7243281645, 117067.42074699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.58, 1.0, 1.0, 0.18342182099366253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14246955213933976, 0.14246955213933957, 0.22562094760006463], 
reward next is 0.7744, 
noisyNet noise sample is [array([0.34254858], dtype=float32), 1.532962]. 
=============================================
[2019-03-24 00:04:06,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1354837e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:04:06,098] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4730
[2019-03-24 00:04:06,101] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 68.66666666666667, 1.0, 2.0, 0.4178592707776346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513859.7290058789, 513859.7290058789, 131069.6960763919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 87000.0000, 
sim time next is 87600.0000, 
raw observation next is [23.9, 69.33333333333334, 1.0, 2.0, 0.4187074376357676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514863.4061783089, 514863.4061783089, 131190.7346649135], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.6933333333333335, 1.0, 1.0, 0.3079850448044853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1838797879208246, 0.1838797879208246, 0.2522898743556029], 
reward next is 0.7477, 
noisyNet noise sample is [array([1.8373379], dtype=float32), 1.9981385]. 
=============================================
[2019-03-24 00:04:10,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.29918e-24 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-24 00:04:10,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7518
[2019-03-24 00:04:10,131] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.9, 14.66666666666667, 1.0, 2.0, 0.3719787301762465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478748.2410212555, 478748.2410212555, 124924.5376566399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [33.1, 13.83333333333333, 1.0, 2.0, 0.3733559869705815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979039, 125108.8648741274], 
processed observation next is [0.0, 0.5652173913043478, 0.7814814814814816, 0.1383333333333333, 1.0, 1.0, 0.25399522258402557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17178849667782298, 0.1717884966778228, 0.24059397091178344], 
reward next is 0.7594, 
noisyNet noise sample is [array([0.697539], dtype=float32), -0.8984452]. 
=============================================
[2019-03-24 00:04:11,638] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4016211e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:04:11,647] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7776
[2019-03-24 00:04:11,653] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.279734927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195000.0000, 
sim time next is 195600.0000, 
raw observation next is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.2582619160811347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729705, 110570.5709980323], 
processed observation next is [0.0, 0.2608695652173913, 0.33950617283950635, 0.6133333333333334, 1.0, 1.0, 0.11697847152516035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11856162702606089, 0.11856162702606089, 0.21263571345775442], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.352768], dtype=float32), -0.21578406]. 
=============================================
[2019-03-24 00:04:11,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.68485e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-24 00:04:11,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-24 00:04:11,925] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 39.0, 1.0, 2.0, 0.2668611173348681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 344232.7623089361, 344232.7623089361, 92012.21116339364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187200.0000, 
sim time next is 187800.0000, 
raw observation next is [21.53333333333333, 41.5, 1.0, 2.0, 0.2631969107847023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339505.1379254797, 339505.1379254797, 91923.77616648245], 
processed observation next is [0.0, 0.17391304347826086, 0.35308641975308636, 0.415, 1.0, 1.0, 0.1228534652198837, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1212518349733856, 0.1212518349733856, 0.17677649262785086], 
reward next is 0.8232, 
noisyNet noise sample is [array([1.7952274], dtype=float32), -1.3753777]. 
=============================================
[2019-03-24 00:04:18,094] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2778516e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:04:18,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9225
[2019-03-24 00:04:18,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.51666666666667, 29.83333333333333, 1.0, 2.0, 0.3134467816145898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404340.9546614452, 404340.9546614452, 112247.5445223868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 301800.0000, 
sim time next is 302400.0000, 
raw observation next is [26.6, 30.0, 1.0, 2.0, 0.314258748872469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405388.6552993165, 405388.655299316, 113466.7596223942], 
processed observation next is [0.0, 0.5217391304347826, 0.5407407407407407, 0.3, 1.0, 1.0, 0.18364136770532027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14478166260689876, 0.14478166260689856, 0.21820530696614268], 
reward next is 0.7818, 
noisyNet noise sample is [array([-2.2474766], dtype=float32), 0.78473955]. 
=============================================
[2019-03-24 00:04:24,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2401484e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:04:24,594] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3659
[2019-03-24 00:04:24,598] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 45.83333333333334, 1.0, 2.0, 0.2894801883946098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371073.8589290125, 371073.8589290125, 114286.1486384805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 431400.0000, 
sim time next is 432000.0000, 
raw observation next is [23.9, 47.0, 1.0, 2.0, 0.2866383481308504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367516.2610158189, 367516.2610158189, 113940.8367881442], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.47, 1.0, 1.0, 0.15075993825101236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1312558075056496, 0.1312558075056496, 0.21911699382335423], 
reward next is 0.7809, 
noisyNet noise sample is [array([0.26004538], dtype=float32), 2.5015278]. 
=============================================
[2019-03-24 00:04:24,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.54143]
 [77.54143]
 [77.54143]
 [77.54143]
 [77.54143]], R is [[77.54689026]
 [77.55164337]
 [77.55570984]
 [77.5590744 ]
 [77.56160736]].
[2019-03-24 00:04:32,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8805583e-23 1.0000000e+00 4.1893176e-36 1.2528413e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 00:04:32,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5304
[2019-03-24 00:04:32,960] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 44.5, 1.0, 2.0, 0.3556900625969951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 447108.1961736394, 447108.1961736389, 122671.1236002641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 599400.0000, 
sim time next is 600000.0000, 
raw observation next is [26.46666666666667, 45.0, 1.0, 2.0, 0.3531963990795027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444291.8388528557, 444291.8388528557, 122343.7950725963], 
processed observation next is [1.0, 0.9565217391304348, 0.5358024691358025, 0.45, 1.0, 1.0, 0.22999571318988415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15867565673316275, 0.15867565673316275, 0.23527652898576212], 
reward next is 0.7647, 
noisyNet noise sample is [array([0.06252153], dtype=float32), -1.0819955]. 
=============================================
[2019-03-24 00:04:32,975] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.089558]
 [61.089558]
 [61.089558]
 [61.089558]
 [61.089558]], R is [[61.24339294]
 [61.39505386]
 [61.54444885]
 [61.69158936]
 [61.83679199]].
[2019-03-24 00:04:33,438] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 00:04:33,439] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:04:33,440] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:33,440] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:04:33,442] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:04:33,442] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:33,443] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:04:33,441] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:04:33,444] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:33,445] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:33,444] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:33,469] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 00:04:33,494] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 00:04:33,495] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 00:04:33,554] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 00:04:33,555] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 00:04:34,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9551963]
[2019-03-24 00:04:34,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.5, 75.33333333333334, 1.0, 2.0, 0.315291087046744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406720.7078314415, 406720.7078314415, 116225.4599584329]
[2019-03-24 00:04:34,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:04:34,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.5728664e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4369406850489427
[2019-03-24 00:04:57,430] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9551963]
[2019-03-24 00:04:57,430] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.91666666666667, 69.66666666666666, 1.0, 2.0, 0.7526139090332702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 936001.46221054, 936001.46221054, 189428.8086850785]
[2019-03-24 00:04:57,431] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:04:57,437] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.5728664e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.0002609491555818355
[2019-03-24 00:04:59,406] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9551963]
[2019-03-24 00:04:59,407] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.314137005, 88.07776442833332, 1.0, 2.0, 0.4110343198658969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505351.6277831505, 505351.6277831505, 130089.394174452]
[2019-03-24 00:04:59,407] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:04:59,414] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.5728664e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6181525937489505
[2019-03-24 00:06:06,826] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9551963]
[2019-03-24 00:06:06,828] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.73333333333333, 77.66666666666667, 1.0, 2.0, 0.4251653955326882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521845.609228336, 521845.6092283356, 132099.0224457206]
[2019-03-24 00:06:06,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:06:06,831] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.5728664e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.46696606079002356
[2019-03-24 00:06:17,083] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9551963]
[2019-03-24 00:06:17,084] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.47052291, 59.42674838, 1.0, 2.0, 0.3524653036362388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442981.172606047, 442981.172606047, 122240.2673444189]
[2019-03-24 00:06:17,085] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:06:17,089] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.5728664e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2816964430836084
[2019-03-24 00:06:18,865] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:06:19,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:06:19,281] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:06:19,332] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:06:19,512] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:06:20,528] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2350000, evaluation results [2350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:06:23,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0326918e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:23,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6363
[2019-03-24 00:06:23,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1551681.342256386 W.
[2019-03-24 00:06:23,350] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 36.0, 1.0, 2.0, 0.4398485077280085, 1.0, 1.0, 0.4398485077280085, 1.0, 2.0, 0.7039016724979373, 6.911200000000001, 6.9112, 121.94756008, 1551681.342256386, 1551681.342256385, 315005.927084362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 644400.0000, 
sim time next is 645000.0000, 
raw observation next is [31.91666666666667, 35.0, 1.0, 2.0, 0.6656779304867091, 1.0, 2.0, 0.6656779304867091, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1576957.953732921, 1576957.95373292, 294112.3933474913], 
processed observation next is [1.0, 0.4782608695652174, 0.7376543209876545, 0.35, 1.0, 1.0, 0.6019975362937012, 1.0, 1.0, 0.6019975362937012, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5631992691903289, 0.5631992691903286, 0.5656007564374832], 
reward next is 0.4344, 
noisyNet noise sample is [array([1.1141391], dtype=float32), -1.1982071]. 
=============================================
[2019-03-24 00:06:23,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.04201]
 [73.04201]
 [73.04201]
 [73.04201]
 [73.04201]], R is [[72.74599457]
 [72.0185318 ]
 [71.29834747]
 [70.5853653 ]
 [69.87950897]].
[2019-03-24 00:06:26,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1227902e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:26,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-24 00:06:26,833] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.4568728632101202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578452.5066020227, 578452.5066020227, 137124.6042342954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 717000.0000, 
sim time next is 717600.0000, 
raw observation next is [24.1, 54.00000000000001, 1.0, 2.0, 0.4100490740951208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518679.3911358484, 518679.3911358484, 130222.5151801996], 
processed observation next is [1.0, 0.30434782608695654, 0.4481481481481482, 0.54, 1.0, 1.0, 0.2976774691608581, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18524263969137444, 0.18524263969137444, 0.25042791380807616], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.8565289], dtype=float32), -2.082351]. 
=============================================
[2019-03-24 00:06:27,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.755635e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:06:27,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3320
[2019-03-24 00:06:27,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1449706.69263417 W.
[2019-03-24 00:06:27,356] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 24.33333333333333, 1.0, 2.0, 0.9511073461170427, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.417148275549042, 6.9112, 121.9239273649637, 1449706.69263417, 1190620.449280596, 233535.8088327183], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 741000.0000, 
sim time next is 741600.0000, 
raw observation next is [32.2, 23.0, 1.0, 2.0, 0.3596080916254373, 1.0, 1.0, 0.3596080916254373, 1.0, 1.0, 0.592050051556036, 6.9112, 6.9112, 121.94756008, 1327987.835790007, 1327987.835790007, 278191.8820220265], 
processed observation next is [1.0, 0.6086956521739131, 0.7481481481481482, 0.23, 1.0, 1.0, 0.23762868050647296, 1.0, 0.5, 0.23762868050647296, 1.0, 0.5, 0.4900625644450449, 0.0, 0.0, 0.8096049824067558, 0.47428136992500247, 0.47428136992500247, 0.5349843885038972], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19258133], dtype=float32), -0.28896692]. 
=============================================
[2019-03-24 00:06:27,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.561165e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:06:27,837] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7152
[2019-03-24 00:06:27,846] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 54.0, 1.0, 2.0, 0.382028401643829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485572.5121102174, 485572.5121102174, 126302.2075922488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714600.0000, 
sim time next is 715200.0000, 
raw observation next is [23.7, 54.0, 1.0, 2.0, 0.43192076825734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 548479.1884169166, 548479.1884169162, 133414.3542207107], 
processed observation next is [1.0, 0.2608695652173913, 0.4333333333333333, 0.54, 1.0, 1.0, 0.3237152003063572, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1958854244346131, 0.19588542443461293, 0.25656606580905905], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.381227], dtype=float32), -0.47587597]. 
=============================================
[2019-03-24 00:06:30,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8767955e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:30,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-24 00:06:30,397] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 50.5, 1.0, 2.0, 0.2967150461636717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 378966.7859959558, 378966.7859959562, 115171.3815422247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [23.66666666666667, 51.0, 1.0, 2.0, 0.2975972077020465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380004.8513250869, 380004.8513250869, 115279.7610683204], 
processed observation next is [0.0, 0.08695652173913043, 0.43209876543209896, 0.51, 1.0, 1.0, 0.16380619964529347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13571601833038818, 0.13571601833038818, 0.22169184820830845], 
reward next is 0.7783, 
noisyNet noise sample is [array([0.08031402], dtype=float32), 2.3418376]. 
=============================================
[2019-03-24 00:06:30,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[78.41027]
 [78.41027]
 [78.41027]
 [78.41027]
 [78.41027]], R is [[78.40447235]
 [78.39894867]
 [78.39353943]
 [78.38787079]
 [78.38195038]].
[2019-03-24 00:06:34,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.91878e-28 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-24 00:06:34,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-24 00:06:34,391] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 66.5, 1.0, 2.0, 0.3429790681987868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434309.4052427977, 434309.4052427977, 121029.4824522859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [21.76666666666667, 66.33333333333334, 1.0, 2.0, 0.3379137662042673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428373.8733191731, 428373.8733191731, 120371.727495494], 
processed observation next is [0.0, 0.13043478260869565, 0.3617283950617285, 0.6633333333333334, 1.0, 1.0, 0.2118021026241277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15299066904256184, 0.15299066904256184, 0.23148409133748846], 
reward next is 0.7685, 
noisyNet noise sample is [array([0.77276206], dtype=float32), 1.7022679]. 
=============================================
[2019-03-24 00:06:41,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4662e-26 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00], sum to 1.0000
[2019-03-24 00:06:41,356] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1003
[2019-03-24 00:06:41,359] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.76666666666667, 88.83333333333334, 1.0, 2.0, 0.3212298525647462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407456.800549154, 407456.800549154, 118225.1559950018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1235400.0000, 
sim time next is 1236000.0000, 
raw observation next is [18.83333333333334, 88.66666666666667, 1.0, 2.0, 0.333517934196144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422818.9020351854, 422818.9020351854, 119801.0807006167], 
processed observation next is [1.0, 0.30434782608695654, 0.25308641975308666, 0.8866666666666667, 1.0, 1.0, 0.2065689692811238, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15100675072685193, 0.15100675072685193, 0.23038669365503212], 
reward next is 0.7696, 
noisyNet noise sample is [array([-0.5169558], dtype=float32), 0.5959582]. 
=============================================
[2019-03-24 00:06:41,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.18886]
 [73.18886]
 [73.18886]
 [73.18886]
 [73.18886]], R is [[73.22659302]
 [73.2669754 ]
 [73.30713654]
 [73.3458786 ]
 [73.38230896]].
[2019-03-24 00:06:43,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5164758e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:43,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9696
[2019-03-24 00:06:43,935] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 59.0, 1.0, 2.0, 0.2877707785766819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368210.2537563682, 368210.2537563682, 114079.2133687257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [21.9, 60.0, 1.0, 2.0, 0.2897142613062078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 370488.8197661703, 370488.8197661703, 114315.4104267125], 
processed observation next is [1.0, 0.043478260869565216, 0.36666666666666664, 0.6, 1.0, 1.0, 0.15442173965024739, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1323174356307751, 0.1323174356307751, 0.21983732774367787], 
reward next is 0.7802, 
noisyNet noise sample is [array([1.2280102], dtype=float32), -1.3215016]. 
=============================================
[2019-03-24 00:06:51,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.933856e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:06:51,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2069
[2019-03-24 00:06:51,138] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 69.5, 1.0, 2.0, 0.6467384935040523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815809.688081679, 815809.688081679, 169062.7219499009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1179000.0000, 
sim time next is 1179600.0000, 
raw observation next is [21.63333333333333, 70.0, 1.0, 2.0, 0.6443739557138977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812800.0308235734, 812800.0308235734, 168624.8062895136], 
processed observation next is [1.0, 0.6521739130434783, 0.35679012345678995, 0.7, 1.0, 1.0, 0.5766356615641639, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2902857252941333, 0.2902857252941333, 0.32427847363368], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.8902647], dtype=float32), -1.3576022]. 
=============================================
[2019-03-24 00:06:52,012] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2604185e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:52,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2913
[2019-03-24 00:06:52,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 59.5, 1.0, 2.0, 0.772467980965938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950788.594820052, 950788.5948200516, 193253.9840431349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1258200.0000, 
sim time next is 1258800.0000, 
raw observation next is [25.63333333333333, 59.0, 1.0, 2.0, 0.8955258088455921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932903453313346, 6.9112, 121.9259655174369, 1111882.399962135, 1100768.299060907, 220000.3828075718], 
processed observation next is [1.0, 0.5652173913043478, 0.5049382716049381, 0.59, 1.0, 1.0, 0.8756259629114191, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0021703453313345555, 0.0, 0.809461616968099, 0.3971008571293339, 0.39313153537889534, 0.42307765924533036], 
reward next is 0.4684, 
noisyNet noise sample is [array([0.45347223], dtype=float32), 1.2124691]. 
=============================================
[2019-03-24 00:06:52,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9229036e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:52,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6087
[2019-03-24 00:06:52,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.73333333333333, 94.0, 1.0, 2.0, 0.3472185430346996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437452.3426364116, 437452.3426364116, 121561.8972315227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1207200.0000, 
sim time next is 1207800.0000, 
raw observation next is [18.7, 94.0, 1.0, 2.0, 0.3458505810346735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435903.042919568, 435903.042919568, 121383.9640059345], 
processed observation next is [1.0, 1.0, 0.24814814814814812, 0.94, 1.0, 1.0, 0.22125069170794462, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15567965818556, 0.15567965818556, 0.2334307000114125], 
reward next is 0.7666, 
noisyNet noise sample is [array([0.8555812], dtype=float32), 0.49224094]. 
=============================================
[2019-03-24 00:06:55,371] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4816491e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:55,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7720
[2019-03-24 00:06:55,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 61.0, 1.0, 2.0, 0.5823406854737997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719631.1383769782, 719631.1383769782, 157217.0726338079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1256400.0000, 
sim time next is 1257000.0000, 
raw observation next is [25.08333333333333, 60.5, 1.0, 2.0, 0.665976333548561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821947.3686272339, 821947.3686272339, 172297.5092361896], 
processed observation next is [1.0, 0.5652173913043478, 0.4845679012345677, 0.605, 1.0, 1.0, 0.6023527780340012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29355263165258355, 0.29355263165258355, 0.3313413639157492], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.71251315], dtype=float32), 2.2282445]. 
=============================================
[2019-03-24 00:06:55,412] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.533295]
 [68.533295]
 [68.533295]
 [68.533295]
 [68.533295]], R is [[68.51662445]
 [68.5291214 ]
 [68.55832672]
 [68.58361053]
 [68.58764648]].
[2019-03-24 00:06:57,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3108676e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:06:57,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3385
[2019-03-24 00:06:57,261] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 91.0, 1.0, 2.0, 0.3256685852868851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413088.5888125903, 413088.5888125898, 118792.0642841812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1314600.0000, 
sim time next is 1315200.0000, 
raw observation next is [18.76666666666667, 90.0, 1.0, 2.0, 0.3353102481195699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424774.7582443145, 424774.7582443145, 120030.7009141555], 
processed observation next is [1.0, 0.21739130434782608, 0.2506172839506174, 0.9, 1.0, 1.0, 0.2087026763328213, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1517052708015409, 0.1517052708015409, 0.23082827098876058], 
reward next is 0.7692, 
noisyNet noise sample is [array([1.1141483], dtype=float32), -0.59436274]. 
=============================================
[2019-03-24 00:07:07,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.096255e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:07:07,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-24 00:07:07,151] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 65.5, 1.0, 2.0, 0.3382838226446179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428217.2636750843, 428217.2636750843, 120414.2985573978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1481400.0000, 
sim time next is 1482000.0000, 
raw observation next is [22.0, 66.33333333333333, 1.0, 2.0, 0.3388910567155046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428853.0606733214, 428853.0606733214, 120492.1508044539], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.6633333333333333, 1.0, 1.0, 0.21296554370893409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15316180738332907, 0.15316180738332907, 0.2317156746239498], 
reward next is 0.7683, 
noisyNet noise sample is [array([-2.0634508], dtype=float32), -1.140807]. 
=============================================
[2019-03-24 00:07:07,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[79.73045]
 [79.73045]
 [79.73045]
 [79.73045]
 [79.73045]], R is [[79.7014389 ]
 [79.67285919]
 [79.64490509]
 [79.61780548]
 [79.59146118]].
[2019-03-24 00:07:08,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7819815e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:07:08,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0071
[2019-03-24 00:07:08,843] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.25, 26.5, 1.0, 2.0, 0.4158122490252531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509869.0754663933, 509869.0754663933, 130736.8354944936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1512600.0000, 
sim time next is 1513200.0000, 
raw observation next is [34.40000000000001, 26.0, 1.0, 2.0, 0.413941708730112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507791.8597542069, 507791.8597542069, 130474.7632458571], 
processed observation next is [0.0, 0.5217391304347826, 0.82962962962963, 0.26, 1.0, 1.0, 0.30231155801203813, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18135423562650246, 0.18135423562650246, 0.2509130062420329], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.8543757], dtype=float32), -0.07412883]. 
=============================================
[2019-03-24 00:07:10,107] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 00:07:10,108] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:07:10,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:07:10,111] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:07:10,113] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:07:10,114] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:07:10,114] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:07:10,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:07:10,117] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:07:10,117] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:07:10,117] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:07:10,138] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 00:07:10,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 00:07:10,164] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 00:07:10,189] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 00:07:10,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 00:07:11,919] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:11,920] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.47733207833333, 37.275962125, 1.0, 2.0, 0.7394169462348383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156607, 928597.8178521766, 928597.8178521771, 186935.0012221374]
[2019-03-24 00:07:11,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:07:11,924] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5159188059376243
[2019-03-24 00:07:24,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:24,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.9, 59.0, 1.0, 2.0, 0.3117349174359729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 399219.1464332732, 399219.1464332727, 117039.2521002799]
[2019-03-24 00:07:24,680] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:07:24,683] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3352540673785175
[2019-03-24 00:07:27,928] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:27,928] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.4, 94.0, 1.0, 2.0, 0.3350839064631392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423803.88257905, 423803.88257905, 119994.4335267545]
[2019-03-24 00:07:27,930] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:07:27,933] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1110943621081878
[2019-03-24 00:07:40,608] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:40,611] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.13333333333333, 38.0, 1.0, 2.0, 0.4313828716282345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525141.7725017787, 525141.7725017787, 132882.3796655965]
[2019-03-24 00:07:40,613] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:07:40,614] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.12092303392374038
[2019-03-24 00:07:43,850] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:43,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.94161904333333, 45.37780409, 1.0, 2.0, 0.8388455602749159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 982673.2568012185, 982673.2568012185, 205443.5205127384]
[2019-03-24 00:07:43,852] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:07:43,854] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05012991140098444
[2019-03-24 00:07:55,671] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:07:55,675] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.46062538, 27.01407041333334, 1.0, 2.0, 0.3585968587498768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451189.4613013, 451189.4613013, 123065.766097676]
[2019-03-24 00:07:55,676] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:07:55,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.36932736134272737
[2019-03-24 00:08:16,096] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:08:16,098] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.979801359369117, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.099360830686336, 6.9112, 121.9251544047384, 1228009.355194975, 1131654.894190683, 236704.4930728171]
[2019-03-24 00:08:16,102] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:08:16,106] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.13108470888216706
[2019-03-24 00:08:50,617] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9071642]
[2019-03-24 00:08:50,618] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.5, 67.0, 1.0, 2.0, 0.3539964564535445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444638.3350939993, 444638.3350939993, 122440.4016816597]
[2019-03-24 00:08:50,619] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:08:50,623] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0232055e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.15489085217716647
[2019-03-24 00:08:55,669] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:08:55,845] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:08:56,024] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:08:56,129] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:08:56,175] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:08:57,192] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2375000, evaluation results [2375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:09:00,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3438338e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:00,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7758
[2019-03-24 00:09:00,016] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 55.0, 1.0, 2.0, 0.5042855962961567, 1.0, 1.0, 0.5042855962961567, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258246822249, 1233639.409802257, 1233639.409802257, 240050.0726167583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1593000.0000, 
sim time next is 1593600.0000, 
raw observation next is [25.53333333333333, 54.66666666666667, 1.0, 2.0, 0.9431989061862014, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.286298059474582, 6.9112, 121.9244599664082, 1358422.244779607, 1166341.005768885, 231298.7383782021], 
processed observation next is [1.0, 0.43478260869565216, 0.5012345679012346, 0.5466666666666667, 1.0, 1.0, 0.9323796502216684, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03750980594745821, 0.0, 0.8094516216749312, 0.48515080170700253, 0.4165503592031732, 0.4448052661119271], 
reward next is 0.0000, 
noisyNet noise sample is [array([-3.7486718], dtype=float32), -0.27757263]. 
=============================================
[2019-03-24 00:09:04,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.941757e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:04,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-24 00:09:04,065] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.63333333333333, 77.33333333333334, 1.0, 2.0, 0.7367985026070634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929138.3123281476, 929138.3123281476, 186466.5646262558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1683600.0000, 
sim time next is 1684200.0000, 
raw observation next is [20.81666666666667, 76.66666666666667, 1.0, 2.0, 0.7499221031455706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944672.6232351062, 944672.6232351062, 189109.110897298], 
processed observation next is [1.0, 0.4782608695652174, 0.32654320987654334, 0.7666666666666667, 1.0, 1.0, 0.7022882180304412, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33738307972682363, 0.33738307972682363, 0.36367136711018844], 
reward next is 0.6363, 
noisyNet noise sample is [array([0.89045465], dtype=float32), -0.52478975]. 
=============================================
[2019-03-24 00:09:06,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.254937e-23 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:06,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7742
[2019-03-24 00:09:06,774] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 68.66666666666667, 1.0, 2.0, 0.8346785320903775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1029446.831923466, 1029446.831923466, 206521.4409325969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1700400.0000, 
sim time next is 1701000.0000, 
raw observation next is [23.75, 68.5, 1.0, 2.0, 0.8655824421819108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1067155.455176149, 1067155.455176149, 213329.5347419428], 
processed observation next is [1.0, 0.6956521739130435, 0.4351851851851852, 0.685, 1.0, 1.0, 0.8399790978356081, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.38112694827719606, 0.38112694827719606, 0.41024910527296693], 
reward next is 0.5898, 
noisyNet noise sample is [array([-0.47280785], dtype=float32), 0.2575324]. 
=============================================
[2019-03-24 00:09:06,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.224014]
 [66.224014]
 [66.224014]
 [66.224014]
 [66.224014]], R is [[66.1515274 ]
 [66.09285736]
 [66.04647064]
 [65.38600922]
 [64.73214722]].
[2019-03-24 00:09:08,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6000788e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:08,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9400
[2019-03-24 00:09:08,047] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.35, 85.5, 1.0, 2.0, 0.2991671463905152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382627.7960521247, 382627.7960521247, 115474.1115160139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [18.36666666666667, 85.66666666666666, 1.0, 2.0, 0.2989319299462199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 382194.828453599, 382194.8284535985, 115445.0034690849], 
processed observation next is [1.0, 0.8695652173913043, 0.2358024691358026, 0.8566666666666666, 1.0, 1.0, 0.16539515469788085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1364981530191425, 0.1364981530191423, 0.2220096220559325], 
reward next is 0.7780, 
noisyNet noise sample is [array([1.4048827], dtype=float32), -0.4691765]. 
=============================================
[2019-03-24 00:09:10,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3496816e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:10,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0061
[2019-03-24 00:09:10,081] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 85.33333333333334, 1.0, 2.0, 0.2996126104914926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 383326.1795471035, 383326.179547104, 115529.1393432375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801200.0000, 
sim time next is 1801800.0000, 
raw observation next is [18.35, 85.5, 1.0, 2.0, 0.2991671463905153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382627.7960521247, 382627.7960521247, 115474.1115160139], 
processed observation next is [1.0, 0.8695652173913043, 0.23518518518518525, 0.855, 1.0, 1.0, 0.16567517427442296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13665278430433025, 0.13665278430433025, 0.2220655990692575], 
reward next is 0.7779, 
noisyNet noise sample is [array([-0.5513536], dtype=float32), -1.3786353]. 
=============================================
[2019-03-24 00:09:10,602] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0839962e-22 1.0000000e+00 6.4845546e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:10,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4837
[2019-03-24 00:09:10,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1451948.514694995 W.
[2019-03-24 00:09:10,629] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333334, 59.33333333333334, 1.0, 2.0, 0.6258966640035195, 1.0, 2.0, 0.6258966640035195, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1451948.514694995, 1451948.514694995, 278262.3749724875], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1782600.0000, 
sim time next is 1783200.0000, 
raw observation next is [27.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6409663013439095, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9784446129145267, 6.911199999999999, 6.9112, 121.9260426156618, 1462097.610648349, 1462097.61064835, 303102.8140159963], 
processed observation next is [1.0, 0.6521739130434783, 0.580246913580247, 0.6066666666666667, 1.0, 1.0, 0.5725789301713209, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9730557661431583, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5221777180886961, 0.5221777180886965, 0.5828900269538391], 
reward next is 0.4171, 
noisyNet noise sample is [array([-1.0139172], dtype=float32), -0.7149461]. 
=============================================
[2019-03-24 00:09:10,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1244298e-21 1.0000000e+00 1.0450940e-35 0.0000000e+00 2.5150062e-38], sum to 1.0000
[2019-03-24 00:09:10,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2807
[2019-03-24 00:09:10,750] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 85.0, 1.0, 2.0, 0.3034962682577806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 388187.6273831071, 388187.6273831076, 116009.7810975926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1800000.0000, 
sim time next is 1800600.0000, 
raw observation next is [18.31666666666667, 85.16666666666667, 1.0, 2.0, 0.3003113430638545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384326.6800464137, 384326.6800464137, 115615.4523081649], 
processed observation next is [1.0, 0.8695652173913043, 0.23395061728395075, 0.8516666666666667, 1.0, 1.0, 0.16703731317125534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1372595285880049, 0.1372595285880049, 0.22233740828493248], 
reward next is 0.7777, 
noisyNet noise sample is [array([-0.5453907], dtype=float32), -0.7610929]. 
=============================================
[2019-03-24 00:09:12,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9953135e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:12,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-24 00:09:12,511] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 78.0, 1.0, 2.0, 0.5207823362725307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617626.6837530661, 617626.6837530661, 146064.6595756334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2067600.0000, 
sim time next is 2068200.0000, 
raw observation next is [24.65, 78.0, 1.0, 2.0, 0.5139342380303181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611142.825641699, 611142.8256416986, 145032.5606388845], 
processed observation next is [0.0, 0.9565217391304348, 0.46851851851851845, 0.78, 1.0, 1.0, 0.4213502833694263, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21826529487203536, 0.2182652948720352, 0.2789087704593933], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.6493361], dtype=float32), 1.0190843]. 
=============================================
[2019-03-24 00:09:15,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.580586e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:15,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6214
[2019-03-24 00:09:15,576] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 92.0, 1.0, 2.0, 0.4115289264787134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506789.9669858423, 506789.9669858423, 130180.9328187131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1899000.0000, 
sim time next is 1899600.0000, 
raw observation next is [20.56666666666666, 92.0, 1.0, 2.0, 0.4082624960314347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 503384.7211880759, 503384.7211880754, 129731.0058783027], 
processed observation next is [1.0, 1.0, 0.3172839506172837, 0.92, 1.0, 1.0, 0.29555059051361277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17978025756716998, 0.17978025756716978, 0.24948270361212058], 
reward next is 0.7505, 
noisyNet noise sample is [array([-1.4691625], dtype=float32), -3.3401055]. 
=============================================
[2019-03-24 00:09:17,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.428993e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:17,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-24 00:09:17,473] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333333, 92.0, 1.0, 2.0, 0.3663638010087946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457919.1518491962, 457919.1518491962, 124061.7455398165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1907400.0000, 
sim time next is 1908000.0000, 
raw observation next is [19.5, 92.0, 1.0, 2.0, 0.3629950705450773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 454199.224823771, 454199.2248237706, 123616.2746080964], 
processed observation next is [1.0, 0.08695652173913043, 0.2777777777777778, 0.92, 1.0, 1.0, 0.24166079826794917, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1622140088656325, 0.16221400886563234, 0.23772360501557], 
reward next is 0.7623, 
noisyNet noise sample is [array([0.7163074], dtype=float32), 0.47137654]. 
=============================================
[2019-03-24 00:09:17,491] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.987915]
 [71.987915]
 [71.987915]
 [71.987915]
 [71.987915]], R is [[72.03031158]
 [72.07143402]
 [72.11125946]
 [72.14975739]
 [72.18691254]].
[2019-03-24 00:09:18,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.20589e-25 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-24 00:09:18,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2059
[2019-03-24 00:09:18,595] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 86.83333333333333, 1.0, 2.0, 0.8464599239068588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1030797.334162651, 1030797.334162651, 208692.7078840011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1937400.0000, 
sim time next is 1938000.0000, 
raw observation next is [22.13333333333333, 86.66666666666667, 1.0, 2.0, 0.7729893771877698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 939902.2312866347, 939902.2312866347, 193006.4634842947], 
processed observation next is [1.0, 0.43478260869565216, 0.3753086419753085, 0.8666666666666667, 1.0, 1.0, 0.7297492585568688, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33567936831665524, 0.33567936831665524, 0.371166275931336], 
reward next is 0.6288, 
noisyNet noise sample is [array([-0.02388147], dtype=float32), 0.3785215]. 
=============================================
[2019-03-24 00:09:18,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.067535]
 [71.067535]
 [71.067535]
 [71.067535]
 [71.067535]], R is [[70.98567963]
 [70.87449646]
 [70.7844696 ]
 [70.69942474]
 [70.6255188 ]].
[2019-03-24 00:09:21,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4527078e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:21,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2000
[2019-03-24 00:09:21,617] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 94.0, 1.0, 2.0, 0.3637406085848497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455127.5759493977, 455127.5759493977, 123716.6486799251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2005200.0000, 
sim time next is 2005800.0000, 
raw observation next is [19.41666666666667, 93.16666666666667, 1.0, 2.0, 0.3641215539663184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 455484.9660628318, 455484.9660628313, 123765.8822411116], 
processed observation next is [0.0, 0.21739130434782608, 0.2746913580246915, 0.9316666666666668, 1.0, 1.0, 0.24300184995990287, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16267320216529707, 0.16267320216529688, 0.23801131200213768], 
reward next is 0.7620, 
noisyNet noise sample is [array([2.2006664], dtype=float32), -2.0563567]. 
=============================================
[2019-03-24 00:09:22,485] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1674061e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:22,497] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4681
[2019-03-24 00:09:22,501] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 65.5, 1.0, 2.0, 0.5015087583224104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595777.5304548923, 595777.5304548923, 143043.210786118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2032200.0000, 
sim time next is 2032800.0000, 
raw observation next is [26.93333333333333, 65.33333333333333, 1.0, 2.0, 0.507921730890875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 602321.1526738508, 602321.1526738512, 144013.5054007561], 
processed observation next is [0.0, 0.5217391304347826, 0.5530864197530863, 0.6533333333333333, 1.0, 1.0, 0.4141925367748512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21511469738351813, 0.2151146973835183, 0.2769490488476079], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.5173769], dtype=float32), 0.6498847]. 
=============================================
[2019-03-24 00:09:24,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.273046e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:24,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9300
[2019-03-24 00:09:24,288] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 77.5, 1.0, 2.0, 0.5539844438216828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648893.3454298056, 648893.3454298056, 151158.3628880849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2064600.0000, 
sim time next is 2065200.0000, 
raw observation next is [25.4, 77.66666666666667, 1.0, 2.0, 0.547609247534671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642952.992180584, 642952.992180584, 150170.4623377333], 
processed observation next is [0.0, 0.9130434782608695, 0.49629629629629624, 0.7766666666666667, 1.0, 1.0, 0.4614395803984178, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22962606863592286, 0.22962606863592286, 0.28878935064948713], 
reward next is 0.7112, 
noisyNet noise sample is [array([1.2387676], dtype=float32), -1.906147]. 
=============================================
[2019-03-24 00:09:25,688] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3018675e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:25,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0339
[2019-03-24 00:09:25,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 78.66666666666666, 1.0, 2.0, 0.475465116135028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573461.9685937813, 573461.9685937813, 139316.2934398247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320800.0000, 
sim time next is 2321400.0000, 
raw observation next is [23.63333333333333, 79.33333333333334, 1.0, 2.0, 0.4742517382631883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572341.9906740022, 572341.9906740022, 139141.7775859183], 
processed observation next is [1.0, 0.8695652173913043, 0.430864197530864, 0.7933333333333334, 1.0, 1.0, 0.37410921221808136, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20440785381214366, 0.20440785381214366, 0.2675803415113813], 
reward next is 0.7324, 
noisyNet noise sample is [array([-1.307257], dtype=float32), -0.95661306]. 
=============================================
[2019-03-24 00:09:28,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.162098e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:28,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1285
[2019-03-24 00:09:28,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 71.0, 1.0, 2.0, 0.654216586600276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745596.4595800295, 745596.45958003, 167656.5997248457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2146800.0000, 
sim time next is 2147400.0000, 
raw observation next is [28.2, 71.5, 1.0, 2.0, 0.6523295756034185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743444.8311567395, 743444.8311567395, 167314.3340598574], 
processed observation next is [0.0, 0.8695652173913043, 0.6, 0.715, 1.0, 1.0, 0.5861066376231173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26551601112740697, 0.26551601112740697, 0.32175833473049503], 
reward next is 0.6782, 
noisyNet noise sample is [array([0.5371832], dtype=float32), 0.9604248]. 
=============================================
[2019-03-24 00:09:30,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.534257e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:30,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4810
[2019-03-24 00:09:30,642] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.6903146440321163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807645.5035197203, 807645.5035197203, 175322.997795456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2181600.0000, 
sim time next is 2182200.0000, 
raw observation next is [24.03333333333333, 89.0, 1.0, 2.0, 0.6677488403913536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780747.9770508385, 780747.9770508385, 171071.3506785375], 
processed observation next is [1.0, 0.2608695652173913, 0.4456790123456789, 0.89, 1.0, 1.0, 0.6044629052278019, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2788385632324423, 0.2788385632324423, 0.3289833666894952], 
reward next is 0.6710, 
noisyNet noise sample is [array([0.2462797], dtype=float32), 1.4612107]. 
=============================================
[2019-03-24 00:09:30,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2769257e-23 1.0000000e+00 1.3004549e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:09:30,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7432
[2019-03-24 00:09:30,848] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 65.33333333333334, 1.0, 2.0, 0.500466627995941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598922.0960266674, 598922.0960266674, 143041.6198984788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [26.1, 66.66666666666667, 1.0, 2.0, 0.4986244417339429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596896.7386084081, 596896.7386084077, 142758.457562499], 
processed observation next is [1.0, 0.9565217391304348, 0.5222222222222223, 0.6666666666666667, 1.0, 1.0, 0.4031243353975511, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21317740664586005, 0.21317740664585988, 0.2745354953124981], 
reward next is 0.7255, 
noisyNet noise sample is [array([-0.55203474], dtype=float32), -0.45872757]. 
=============================================
[2019-03-24 00:09:30,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.08921]
 [68.08921]
 [68.08921]
 [68.08921]
 [68.08921]], R is [[68.13378143]
 [68.17736816]
 [68.22026825]
 [68.26292419]
 [68.30544281]].
[2019-03-24 00:09:38,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.601258e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:09:38,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1009
[2019-03-24 00:09:38,937] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 86.66666666666667, 1.0, 2.0, 0.4649569682059906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562931.0643709342, 562931.0643709342, 137784.8034770289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2326800.0000, 
sim time next is 2327400.0000, 
raw observation next is [22.3, 87.5, 1.0, 2.0, 0.4637369753140788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561675.1328872836, 561675.1328872836, 137607.0020323604], 
processed observation next is [1.0, 0.9565217391304348, 0.38148148148148153, 0.875, 1.0, 1.0, 0.3615916372786653, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20059826174545842, 0.20059826174545842, 0.2646288500622316], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.30336347], dtype=float32), -0.32629058]. 
=============================================
[2019-03-24 00:09:42,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1105974e-22 1.0000000e+00 1.2368640e-35 1.3250378e-37 7.5884135e-38], sum to 1.0000
[2019-03-24 00:09:42,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1662
[2019-03-24 00:09:42,724] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 83.33333333333334, 1.0, 2.0, 0.5510752118215364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 645869.8404517189, 645869.8404517184, 150693.9857861564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2634600.0000, 
sim time next is 2635200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5623548727326608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 656460.3237094629, 656460.3237094624, 152454.7274644275], 
processed observation next is [0.0, 0.5217391304347826, 0.48148148148148145, 0.83, 1.0, 1.0, 0.4789938961103105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23445011561052245, 0.23445011561052229, 0.2931821682008221], 
reward next is 0.7068, 
noisyNet noise sample is [array([0.777041], dtype=float32), 0.53367215]. 
=============================================
[2019-03-24 00:09:46,608] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 00:09:46,609] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:09:46,609] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:09:46,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:46,610] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:46,610] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:09:46,612] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:09:46,614] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:46,616] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:46,612] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:09:46,620] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:46,635] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 00:09:46,659] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 00:09:46,686] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 00:09:46,712] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 00:09:46,712] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 00:10:15,358] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:10:15,359] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.11969445, 56.18331966, 1.0, 2.0, 0.3955439450711615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490993.4940053449, 490993.4940053449, 128012.1141930592]
[2019-03-24 00:10:15,360] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:10:15,363] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.724291986621043
[2019-03-24 00:10:44,017] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:10:44,018] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.90983650333333, 75.64464140666666, 1.0, 2.0, 0.8017112600324695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944091.784091158, 944091.784091158, 197788.8729670761]
[2019-03-24 00:10:44,020] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:10:44,023] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.47661637161335746
[2019-03-24 00:10:48,798] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:10:48,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 59.0, 1.0, 2.0, 0.6346074588149162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723237.8190317126, 723237.8190317126, 164135.3365783638]
[2019-03-24 00:10:48,803] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:10:48,807] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8974797685960618
[2019-03-24 00:11:21,176] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:11:21,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.5319168484224753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626827.7763963448, 626827.7763963448, 147703.2685050164]
[2019-03-24 00:11:21,179] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:11:21,182] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.21883369469216407
[2019-03-24 00:11:23,909] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:11:23,911] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.73611599333334, 85.54878264666667, 1.0, 2.0, 0.3758283556315062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467283.5913648108, 467283.5913648108, 125300.5906384884]
[2019-03-24 00:11:23,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:11:23,914] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8329528775919384
[2019-03-24 00:11:27,038] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:11:27,040] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.56107907666667, 65.84640495333333, 1.0, 2.0, 0.4792964282409148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 572458.9195869223, 572458.9195869227, 139709.9015647069]
[2019-03-24 00:11:27,041] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:11:27,044] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6315708861723844
[2019-03-24 00:11:27,535] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:11:27,536] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.36174564666667, 84.07696444000001, 1.0, 2.0, 0.4421761184074527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538175.961180502, 538175.961180502, 134463.764186951]
[2019-03-24 00:11:27,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:11:27,540] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.09322365237826569
[2019-03-24 00:11:28,418] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.9197056]
[2019-03-24 00:11:28,418] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.93942477666667, 82.47669559333335, 1.0, 2.0, 0.4978878413733667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593476.5738253432, 593476.5738253436, 142550.4612378274]
[2019-03-24 00:11:28,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:11:28,421] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9482902e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9098103556294538
[2019-03-24 00:11:32,420] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:11:32,807] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:11:32,827] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:11:32,920] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:11:33,014] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:11:34,032] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2400000, evaluation results [2400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:11:37,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6494815e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:11:37,362] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7362
[2019-03-24 00:11:37,365] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.3, 42.5, 1.0, 2.0, 0.4827898846095929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 577112.3115799113, 577112.3115799117, 140264.1026073565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2572200.0000, 
sim time next is 2572800.0000, 
raw observation next is [31.03333333333333, 43.66666666666666, 1.0, 2.0, 0.4862055368655918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580876.0729309233, 580876.0729309233, 140780.2097790058], 
processed observation next is [1.0, 0.782608695652174, 0.7049382716049382, 0.4366666666666666, 1.0, 1.0, 0.3883399248399903, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2074557403324726, 0.2074557403324726, 0.2707311726519342], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.40636674], dtype=float32), -0.37288457]. 
=============================================
[2019-03-24 00:11:41,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.763918e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:11:41,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4795
[2019-03-24 00:11:41,119] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.5638895064803419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659743.8784264196, 659743.8784264196, 152775.4633030464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2668200.0000, 
sim time next is 2668800.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.5629976180584154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658703.5856605092, 658703.5856605092, 152626.4607625688], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.4797590691171612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23525128059303899, 0.23525128059303899, 0.29351242454340154], 
reward next is 0.7065, 
noisyNet noise sample is [array([-0.27581894], dtype=float32), -1.1530159]. 
=============================================
[2019-03-24 00:11:44,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7265967e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:11:44,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9567
[2019-03-24 00:11:44,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1911372.914957974 W.
[2019-03-24 00:11:44,589] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 75.0, 1.0, 2.0, 0.8379464727758922, 1.0, 2.0, 0.8379464727758922, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1911372.914957974, 1911372.914957974, 359684.7725322972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3078000.0000, 
sim time next is 3078600.0000, 
raw observation next is [28.58333333333334, 76.5, 1.0, 2.0, 0.8590141679673498, 1.0, 2.0, 0.8590141679673498, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1959481.473667459, 1959481.473667459, 368743.9687507592], 
processed observation next is [1.0, 0.6521739130434783, 0.6141975308641977, 0.765, 1.0, 1.0, 0.8321597237706545, 1.0, 1.0, 0.8321597237706545, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6998148120240926, 0.6998148120240926, 0.7091230168283831], 
reward next is 0.2909, 
noisyNet noise sample is [array([-0.06339902], dtype=float32), -0.88165545]. 
=============================================
[2019-03-24 00:11:44,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.709829e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:11:44,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4225
[2019-03-24 00:11:44,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2033579.43637115 W.
[2019-03-24 00:11:44,764] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.5943073994384402, 1.0, 2.0, 0.5943073994384402, 1.0, 1.0, 0.9461567351467368, 6.911200000000001, 6.9112, 121.94756008, 2033579.43637115, 2033579.436371149, 392282.6958039716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3429600.0000, 
sim time next is 3430200.0000, 
raw observation next is [29.51666666666667, 68.16666666666666, 1.0, 2.0, 0.8810775630287117, 1.0, 2.0, 0.8810775630287117, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2009866.513890397, 2009866.513890397, 378396.0360341409], 
processed observation next is [1.0, 0.6956521739130435, 0.6487654320987656, 0.6816666666666665, 1.0, 1.0, 0.8584256702722758, 1.0, 1.0, 0.8584256702722758, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7178094692465704, 0.7178094692465704, 0.7276846846810402], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1813216], dtype=float32), -0.48895645]. 
=============================================
[2019-03-24 00:11:48,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2100598e-23 1.0000000e+00 1.4726033e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:11:48,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4788
[2019-03-24 00:11:48,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2002656.709169941 W.
[2019-03-24 00:11:48,411] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 81.33333333333333, 1.0, 2.0, 0.5852804466595581, 1.0, 2.0, 0.5852804466595581, 1.0, 1.0, 0.9317855323354289, 6.911200000000001, 6.9112, 121.94756008, 2002656.709169941, 2002656.70916994, 387413.9669172406], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2976000.0000, 
sim time next is 2976600.0000, 
raw observation next is [28.33333333333334, 80.66666666666667, 1.0, 2.0, 0.8519901358119031, 1.0, 2.0, 0.8519901358119031, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155942, 1943441.649318585, 1943441.649318584, 365706.8127210111], 
processed observation next is [1.0, 0.43478260869565216, 0.6049382716049385, 0.8066666666666668, 1.0, 1.0, 0.823797780728456, 1.0, 1.0, 0.823797780728456, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288196872, 0.6940863033280661, 0.6940863033280658, 0.7032823321557906], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28784072], dtype=float32), -0.36298466]. 
=============================================
[2019-03-24 00:11:53,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1262270e-22 1.0000000e+00 1.9995876e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:11:53,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-24 00:11:53,334] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 45.66666666666666, 1.0, 2.0, 0.534827068309566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630648.936660699, 630648.936660699, 148191.5234827288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3248400.0000, 
sim time next is 3249000.0000, 
raw observation next is [31.5, 44.5, 1.0, 2.0, 0.530535646588999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626846.2067352091, 626846.2067352091, 147545.7643708859], 
processed observation next is [0.0, 0.6086956521739131, 0.7222222222222222, 0.445, 1.0, 1.0, 0.4411138649869035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22387364526257467, 0.22387364526257467, 0.283741854559396], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.12896702], dtype=float32), -0.12957266]. 
=============================================
[2019-03-24 00:11:53,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.30436]
 [60.30436]
 [60.30436]
 [60.30436]
 [60.30436]], R is [[60.41757965]
 [60.52841949]
 [60.63713455]
 [60.7443924 ]
 [60.85167694]].
[2019-03-24 00:11:54,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.00252672e-23 1.00000000e+00 1.19133705e-36 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-24 00:11:54,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2159
[2019-03-24 00:11:54,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 68.0, 1.0, 2.0, 0.6744560500301537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768674.5028649953, 768674.5028649953, 171364.4886218789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2838000.0000, 
sim time next is 2838600.0000, 
raw observation next is [29.25, 68.5, 1.0, 2.0, 0.6791291555061129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 774003.1089914998, 774003.1089914988, 172230.2674901998], 
processed observation next is [1.0, 0.8695652173913043, 0.6388888888888888, 0.685, 1.0, 1.0, 0.6180108994120391, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.27642968178267846, 0.2764296817826781, 0.3312120528657688], 
reward next is 0.6688, 
noisyNet noise sample is [array([0.253941], dtype=float32), -1.7963245]. 
=============================================
[2019-03-24 00:12:00,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4485455e-23 1.0000000e+00 4.2943753e-37 0.0000000e+00 1.8244456e-38], sum to 1.0000
[2019-03-24 00:12:00,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3755
[2019-03-24 00:12:00,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1504977.24804223 W.
[2019-03-24 00:12:00,028] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 88.16666666666667, 1.0, 2.0, 0.6599371587652803, 1.0, 2.0, 0.6599371587652803, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1504977.24804223, 1504977.24804223, 289277.3123419482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2970600.0000, 
sim time next is 2971200.0000, 
raw observation next is [26.66666666666667, 87.33333333333334, 1.0, 2.0, 0.7056516477574555, 1.0, 2.0, 0.7056516477574555, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1609333.897401709, 1609333.89740171, 306310.7939324852], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.8733333333333334, 1.0, 1.0, 0.6495852949493518, 1.0, 1.0, 0.6495852949493518, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5747621062148961, 0.5747621062148964, 0.5890592191009331], 
reward next is 0.4109, 
noisyNet noise sample is [array([-0.14252457], dtype=float32), -0.25636554]. 
=============================================
[2019-03-24 00:12:10,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.883515e-22 1.000000e+00 7.389058e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:12:10,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5149
[2019-03-24 00:12:10,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1734886.303649754 W.
[2019-03-24 00:12:10,884] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.58333333333334, 33.83333333333334, 1.0, 2.0, 0.4969982295392745, 1.0, 2.0, 0.4969982295392745, 1.0, 1.0, 0.7931759479153968, 6.911200000000001, 6.9112, 121.94756008, 1734886.303649754, 1734886.303649754, 342235.6159312849], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3149400.0000, 
sim time next is 3150000.0000, 
raw observation next is [32.9, 32.0, 1.0, 2.0, 0.7255907956114181, 1.0, 2.0, 0.7255907956114181, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1712976.657110296, 1712976.657110297, 316754.720123646], 
processed observation next is [1.0, 0.4782608695652174, 0.774074074074074, 0.32, 1.0, 1.0, 0.6733223757278788, 1.0, 1.0, 0.6733223757278788, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6117773775393914, 0.6117773775393918, 0.6091436925454731], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9649427], dtype=float32), 0.32049352]. 
=============================================
[2019-03-24 00:12:10,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[58.515568]
 [58.515568]
 [58.515568]
 [58.515568]
 [58.515568]], R is [[57.93041229]
 [57.35110855]
 [56.77759933]
 [56.56489944]
 [56.3795433 ]].
[2019-03-24 00:12:19,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9081578e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:12:19,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-24 00:12:19,489] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.18333333333334, 98.33333333333334, 1.0, 2.0, 0.5323870355280252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630756.4488575602, 630756.4488575602, 147914.3182910878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3309000.0000, 
sim time next is 3309600.0000, 
raw observation next is [22.36666666666667, 96.66666666666667, 1.0, 2.0, 0.5322825406332412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630825.1614604671, 630825.1614604671, 147904.8741214962], 
processed observation next is [0.0, 0.30434782608695654, 0.38395061728395075, 0.9666666666666667, 1.0, 1.0, 0.44319350075385855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22529470052159542, 0.22529470052159542, 0.28443245023364655], 
reward next is 0.7156, 
noisyNet noise sample is [array([0.5874984], dtype=float32), 0.11624779]. 
=============================================
[2019-03-24 00:12:22,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8459653e-24 1.0000000e+00 2.0339034e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:12:22,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3517
[2019-03-24 00:12:22,214] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 90.66666666666666, 1.0, 2.0, 0.4544920893766531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 553599.9061732817, 553599.9061732817, 136310.5741394971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4135200.0000, 
sim time next is 4135800.0000, 
raw observation next is [21.78333333333333, 89.33333333333334, 1.0, 2.0, 0.4572204285722748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556476.4995856278, 556476.4995856278, 136707.163534313], 
processed observation next is [1.0, 0.8695652173913043, 0.3623456790123456, 0.8933333333333334, 1.0, 1.0, 0.3538338435384224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19874160699486706, 0.19874160699486706, 0.2628983914121404], 
reward next is 0.7371, 
noisyNet noise sample is [array([-0.841044], dtype=float32), -0.6794775]. 
=============================================
[2019-03-24 00:12:23,713] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 00:12:23,714] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:12:23,715] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:12:23,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:23,715] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:12:23,717] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:12:23,716] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:12:23,718] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:23,717] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:23,720] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:23,723] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:23,744] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 00:12:23,772] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 00:12:23,795] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 00:12:23,796] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 00:12:23,852] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 00:12:33,556] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:12:33,556] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.13999911, 70.58125336, 1.0, 2.0, 0.721671918598815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 896507.6031437092, 896507.6031437088, 183188.8750625128]
[2019-03-24 00:12:33,557] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:12:33,560] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.715506232740902
[2019-03-24 00:12:46,671] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:12:46,673] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.45610017, 82.09205751333334, 1.0, 2.0, 0.6278912558450845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795566.304352642, 795566.3043526416, 165643.0261438473]
[2019-03-24 00:12:46,675] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:12:46,680] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.5325932591026799
[2019-03-24 00:13:03,879] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:13:03,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.218476725, 74.638842935, 1.0, 2.0, 0.6944104954535243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791428.234681051, 791428.2346810505, 175092.9465182134]
[2019-03-24 00:13:03,883] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:13:03,885] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.6483959080040332
[2019-03-24 00:13:41,238] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:13:41,238] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.35, 47.5, 1.0, 2.0, 0.604069152943026, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9616977646441541, 6.9112, 6.9112, 121.9260426155912, 1377456.482024562, 1377456.482024562, 295452.4518669749]
[2019-03-24 00:13:41,240] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:13:41,243] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.4269976478088118
[2019-03-24 00:13:41,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1377456.482024562 W.
[2019-03-24 00:13:52,613] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:13:52,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.32622952, 88.955013425, 1.0, 2.0, 0.7583783699908593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 864374.3225949979, 864374.3225949983, 187484.8862665031]
[2019-03-24 00:13:52,616] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:13:52,619] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.11621335912651021
[2019-03-24 00:13:58,940] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:13:58,941] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.19045026166667, 46.99575181166666, 1.0, 2.0, 0.4996975318240177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598763.5336375552, 598763.5336375552, 142948.6481390546]
[2019-03-24 00:13:58,941] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:13:58,945] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.3476041333527733
[2019-03-24 00:14:04,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8870263]
[2019-03-24 00:14:04,624] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.12113276, 71.76201977, 1.0, 2.0, 0.5465306624430669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635126.1605959582, 635126.1605959582, 149710.2613873459]
[2019-03-24 00:14:04,625] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:14:04,629] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.4471776e-23 1.0000000e+00 1.2015056e-36 0.0000000e+00 0.0000000e+00], sampled 0.21170938253224236
[2019-03-24 00:14:09,342] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:14:09,660] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:14:09,716] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:14:09,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:14:10,066] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:14:11,083] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2425000, evaluation results [2425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:14:14,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7163228e-23 1.0000000e+00 1.2622973e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:14,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8817
[2019-03-24 00:14:14,392] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7279124184573589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829631.4554496525, 829631.4554496525, 181491.0226340292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469200.0000, 
sim time next is 3469800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9595190924], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6624566883424349, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2916342286225599, 0.2916342286225599, 0.34476915292133153], 
reward next is 0.6552, 
noisyNet noise sample is [array([-2.4054382], dtype=float32), 0.8175477]. 
=============================================
[2019-03-24 00:14:18,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4916616e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:18,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1938
[2019-03-24 00:14:18,337] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 56.0, 1.0, 2.0, 0.7210729665136959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821832.0740545145, 821832.0740545145, 180176.0691259631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3783600.0000, 
sim time next is 3784200.0000, 
raw observation next is [32.58333333333334, 59.66666666666667, 1.0, 2.0, 0.7223528956618376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 823291.6375372452, 823291.6375372447, 180425.137465589], 
processed observation next is [1.0, 0.8260869565217391, 0.7623456790123461, 0.5966666666666667, 1.0, 1.0, 0.669467732930759, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2940327276918733, 0.2940327276918731, 0.34697141820305577], 
reward next is 0.6530, 
noisyNet noise sample is [array([1.1238344], dtype=float32), -0.198765]. 
=============================================
[2019-03-24 00:14:27,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0011555e-24 1.0000000e+00 1.1869590e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:27,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2660
[2019-03-24 00:14:27,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6642644370687326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757053.4318002438, 757053.4318002438, 169487.9323580488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718800.0000, 
sim time next is 3719400.0000, 
raw observation next is [24.95, 94.33333333333334, 1.0, 2.0, 0.6627204197130796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755292.8685938807, 755292.8685938807, 169205.4138434182], 
processed observation next is [1.0, 0.043478260869565216, 0.47962962962962963, 0.9433333333333335, 1.0, 1.0, 0.5984766901346186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2697474530692431, 0.2697474530692431, 0.3253950266219581], 
reward next is 0.6746, 
noisyNet noise sample is [array([-1.0067434], dtype=float32), -0.87354106]. 
=============================================
[2019-03-24 00:14:30,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9836994e-22 1.0000000e+00 2.4361509e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:30,689] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5620
[2019-03-24 00:14:30,692] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 75.66666666666667, 1.0, 2.0, 0.6232282681183617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716454.4423241487, 716454.4423241492, 162424.3303603744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3802200.0000, 
sim time next is 3802800.0000, 
raw observation next is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.6239922536581565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715922.6717271695, 715922.6717271695, 162490.7333145527], 
processed observation next is [0.0, 0.0, 0.5432098765432101, 0.7733333333333334, 1.0, 1.0, 0.5523717305454243, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25568666847398913, 0.25568666847398913, 0.3124821794510629], 
reward next is 0.6875, 
noisyNet noise sample is [array([-0.8950377], dtype=float32), 1.3004153]. 
=============================================
[2019-03-24 00:14:31,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1439813e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:31,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4189
[2019-03-24 00:14:31,319] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.6014335430909789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694156.5555027412, 694156.5555027412, 158748.8369508204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4560000.0000, 
sim time next is 4560600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6004602859199565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 693034.7523098465, 693034.7523098469, 158580.6028200891], 
processed observation next is [0.0, 0.782608695652174, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5243574832380434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24751241153923087, 0.24751241153923104, 0.30496269773094054], 
reward next is 0.6950, 
noisyNet noise sample is [array([-0.46556294], dtype=float32), 0.29099184]. 
=============================================
[2019-03-24 00:14:33,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6018376e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:33,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8905
[2019-03-24 00:14:33,375] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.9, 56.66666666666667, 1.0, 2.0, 0.7121213315838378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 811624.1808841641, 811624.1808841637, 178456.2235433882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.7447858466969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848873.4393030676, 848873.4393030676, 184803.1683238671], 
processed observation next is [0.0, 0.5217391304347826, 0.7777777777777778, 0.59, 1.0, 1.0, 0.696173627020119, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3031690854653813, 0.3031690854653813, 0.35539070831512903], 
reward next is 0.6446, 
noisyNet noise sample is [array([-1.0217025], dtype=float32), 0.88716674]. 
=============================================
[2019-03-24 00:14:34,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0673533e-22 1.0000000e+00 1.2208922e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:34,366] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0299
[2019-03-24 00:14:34,370] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 70.0, 1.0, 2.0, 0.7166831249538088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816826.1521088869, 816826.1521088869, 179328.6432743666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.7224511196562801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823403.6470985591, 823403.6470985591, 180441.2997306091], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666666, 0.7, 1.0, 1.0, 0.6695846662574763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29407273110662824, 0.29407273110662824, 0.3470024994819406], 
reward next is 0.6530, 
noisyNet noise sample is [array([-0.10466935], dtype=float32), -0.07111066]. 
=============================================
[2019-03-24 00:14:48,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8170495e-22 1.0000000e+00 2.6338860e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:48,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4575
[2019-03-24 00:14:48,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2009473.287692101 W.
[2019-03-24 00:14:48,292] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 85.66666666666667, 1.0, 2.0, 0.5872703669665561, 1.0, 2.0, 0.5872703669665561, 1.0, 2.0, 0.9349535502713496, 6.911199999999999, 6.9112, 121.94756008, 2009473.287692101, 2009473.287692102, 388483.4669403141], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4876800.0000, 
sim time next is 4877400.0000, 
raw observation next is [28.38333333333333, 84.83333333333333, 1.0, 2.0, 0.5960585624992414, 1.0, 2.0, 0.5960585624992414, 1.0, 2.0, 0.9489446437709317, 6.9112, 6.9112, 121.94756008, 2039578.344109158, 2039578.344109158, 393232.2777409695], 
processed observation next is [1.0, 0.43478260869565216, 0.60679012345679, 0.8483333333333333, 1.0, 1.0, 0.5191173363086207, 1.0, 1.0, 0.5191173363086207, 1.0, 1.0, 0.9361808047136646, 0.0, 0.0, 0.8096049824067558, 0.7284208371818421, 0.7284208371818421, 0.7562159187326336], 
reward next is 0.2438, 
noisyNet noise sample is [array([-0.30670017], dtype=float32), 0.17394653]. 
=============================================
[2019-03-24 00:14:55,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5127538e-24 1.0000000e+00 1.1835408e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:14:55,937] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-24 00:14:55,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1558839.865032824 W.
[2019-03-24 00:14:55,949] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 62.66666666666666, 1.0, 2.0, 0.4556881257669147, 1.0, 2.0, 0.4556881257669147, 1.0, 1.0, 0.7254703369470994, 6.911200000000001, 6.9112, 121.94756008, 1558839.865032824, 1558839.865032824, 322335.03125677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4266600.0000, 
sim time next is 4267200.0000, 
raw observation next is [28.0, 59.33333333333334, 1.0, 2.0, 0.6648953035478293, 1.0, 2.0, 0.6648953035478293, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1532976.767206043, 1532976.767206043, 291922.3249649295], 
processed observation next is [1.0, 0.391304347826087, 0.5925925925925926, 0.5933333333333334, 1.0, 1.0, 0.6010658375569397, 1.0, 1.0, 0.6010658375569397, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5474917025735868, 0.5474917025735868, 0.5613890864710183], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.213064], dtype=float32), -0.5161167]. 
=============================================
[2019-03-24 00:14:58,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.533046e-23 1.000000e+00 5.612918e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:14:58,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8269
[2019-03-24 00:14:58,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1492360.72608754 W.
[2019-03-24 00:14:58,504] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 1.002268982747028, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.478290261840876, 6.9112, 121.9236794926979, 1492360.72608754, 1201965.454509448, 244278.1280703085], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4279800.0000, 
sim time next is 4280400.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.3774495018185725, 1.0, 1.0, 0.3774495018185725, 1.0, 1.0, 0.6029415179733281, 6.9112, 6.9112, 121.94756008, 1322637.811044997, 1322637.811044997, 287373.6306180776], 
processed observation next is [1.0, 0.5652173913043478, 0.7407407407407407, 0.38, 1.0, 1.0, 0.25886845454591967, 1.0, 0.5, 0.25886845454591967, 1.0, 0.5, 0.50367689746666, 0.0, 0.0, 0.8096049824067558, 0.47237064680178464, 0.47237064680178464, 0.5526415973424569], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7077887], dtype=float32), 0.37464926]. 
=============================================
[2019-03-24 00:15:00,495] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 00:15:00,497] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:15:00,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:15:00,499] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:15:00,499] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:15:00,500] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:15:00,501] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:15:00,501] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:15:00,502] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:15:00,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:15:00,505] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:15:00,525] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 00:15:00,551] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 00:15:00,587] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 00:15:00,589] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 00:15:00,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 00:15:35,981] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86887455]
[2019-03-24 00:15:35,984] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.4997307042207739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596713.6776448616, 596713.6776448616, 142877.7498613589]
[2019-03-24 00:15:35,985] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:15:35,988] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5963443e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6457583139531664
[2019-03-24 00:15:40,259] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86887455]
[2019-03-24 00:15:40,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.08724250333333, 53.56521072333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.581266794475031, 6.9112, 121.923438867474, 1506175.397171267, 1163048.636187404, 245587.8069015681]
[2019-03-24 00:15:40,261] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:15:40,265] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5963443e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8768301830461402
[2019-03-24 00:15:40,266] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1506175.397171267 W.
[2019-03-24 00:16:01,371] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86887455]
[2019-03-24 00:16:01,374] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.87941568, 93.58486915, 1.0, 2.0, 0.5117861638243816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605071.8369364287, 605071.8369364287, 144554.3191484329]
[2019-03-24 00:16:01,375] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:16:01,377] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5963443e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8138277972243039
[2019-03-24 00:16:05,547] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86887455]
[2019-03-24 00:16:05,659] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6792775036266989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774172.2666411969, 774172.2666411969, 172259.139147299]
[2019-03-24 00:16:05,659] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:16:05,663] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5963443e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.10638221769135325
[2019-03-24 00:16:38,125] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.86887455]
[2019-03-24 00:16:38,125] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.4239431, 82.09567858, 1.0, 2.0, 0.3460711875754727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434434.8700619306, 434434.8700619306, 121388.041769668]
[2019-03-24 00:16:38,126] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:16:38,129] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5963443e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.40890554355484676
[2019-03-24 00:16:46,137] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:16:46,356] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:16:46,430] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:16:46,430] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:16:46,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:16:47,624] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2450000, evaluation results [2450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:16:52,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0302901e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:16:52,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5842
[2019-03-24 00:16:52,013] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4955116253734915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594850.0473400932, 594850.0473400932, 142329.7924478032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4410000.0000, 
sim time next is 4410600.0000, 
raw observation next is [22.08333333333334, 93.33333333333334, 1.0, 2.0, 0.4946705142072801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593831.1887744697, 593831.1887744697, 142197.7973363253], 
processed observation next is [0.0, 0.043478260869565216, 0.373456790123457, 0.9333333333333335, 1.0, 1.0, 0.3984172788181906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21208256741945344, 0.21208256741945344, 0.27345730256985634], 
reward next is 0.7265, 
noisyNet noise sample is [array([0.24255268], dtype=float32), -0.84071714]. 
=============================================
[2019-03-24 00:16:53,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.108724e-25 1.000000e+00 2.668177e-38 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:16:53,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6961
[2019-03-24 00:16:53,187] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.41666666666667, 92.5, 1.0, 2.0, 0.782772985759429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426108923, 898168.7581161336, 898168.7581161336, 192714.2879160272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5212200.0000, 
sim time next is 5212800.0000, 
raw observation next is [24.5, 91.0, 1.0, 2.0, 0.8648448177416019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156604, 994833.8870689421, 994833.8870689425, 210183.5930635652], 
processed observation next is [1.0, 0.34782608695652173, 0.46296296296296297, 0.91, 1.0, 1.0, 0.839100973501907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201267, 0.35529781681033645, 0.3552978168103366, 0.4041992174299331], 
reward next is 0.5958, 
noisyNet noise sample is [array([0.06640392], dtype=float32), 1.413655]. 
=============================================
[2019-03-24 00:16:53,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3973942e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:16:53,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2406
[2019-03-24 00:16:53,604] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.7333141580214746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835791.3950273665, 835791.3950273665, 182549.9663078595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4462800.0000, 
sim time next is 4463400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.7354304689294429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838204.7694741348, 838204.7694741348, 182963.1488113035], 
processed observation next is [0.0, 0.6521739130434783, 0.6666666666666666, 0.7, 1.0, 1.0, 0.6850362725350511, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2993588462407624, 0.2993588462407624, 0.3518522092525067], 
reward next is 0.6481, 
noisyNet noise sample is [array([2.1487355], dtype=float32), 1.2268434]. 
=============================================
[2019-03-24 00:16:54,105] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2787397e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:16:54,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4416
[2019-03-24 00:16:54,117] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.08333333333333, 72.66666666666667, 1.0, 2.0, 0.708835067239042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807876.7615317225, 807876.7615317225, 177824.7544246038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4470600.0000, 
sim time next is 4471200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.7164078067530073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 816512.1962128424, 816512.1962128419, 179275.4764292319], 
processed observation next is [0.0, 0.782608695652174, 0.6296296296296297, 0.74, 1.0, 1.0, 0.6623902461345325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2916114986474437, 0.2916114986474435, 0.34476053159467673], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.5411201], dtype=float32), 1.0518028]. 
=============================================
[2019-03-24 00:16:55,972] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1205877e-24 1.0000000e+00 6.2731379e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:16:55,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2988
[2019-03-24 00:16:55,982] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.5852850402488553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678714.2085457573, 678714.2085457573, 156125.4731403083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [24.33333333333334, 90.66666666666667, 1.0, 2.0, 0.5903433234599739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683202.1034655073, 683202.1034655073, 156926.7957883757], 
processed observation next is [0.0, 0.391304347826087, 0.4567901234567903, 0.9066666666666667, 1.0, 1.0, 0.5123134803094926, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24400075123768117, 0.24400075123768117, 0.30178229959303016], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.61239326], dtype=float32), 0.5909463]. 
=============================================
[2019-03-24 00:16:59,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3258396e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:16:59,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8445
[2019-03-24 00:16:59,035] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 97.0, 1.0, 2.0, 0.5656707968679139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660526.4577357398, 660526.4577357398, 153017.4885326418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4566600.0000, 
sim time next is 4567200.0000, 
raw observation next is [23.06666666666667, 98.0, 1.0, 2.0, 0.569772348042185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664080.0430902912, 664080.0430902912, 153651.7259342367], 
processed observation next is [0.0, 0.8695652173913043, 0.40987654320987665, 0.98, 1.0, 1.0, 0.48782422385974405, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2371714439608183, 0.2371714439608183, 0.29548408833507056], 
reward next is 0.7045, 
noisyNet noise sample is [array([-1.1026161], dtype=float32), -0.65464145]. 
=============================================
[2019-03-24 00:16:59,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.791761e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:16:59,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0665
[2019-03-24 00:16:59,336] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5875525105617495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 681892.1997830862, 681892.1997830857, 156537.3680467289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4550400.0000, 
sim time next is 4551000.0000, 
raw observation next is [23.15, 99.16666666666667, 1.0, 2.0, 0.5892542273332497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 683335.541315483, 683335.5413154826, 156804.3564006998], 
processed observation next is [0.0, 0.6956521739130435, 0.4129629629629629, 0.9916666666666667, 1.0, 1.0, 0.5110169373014878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24404840761267252, 0.24404840761267235, 0.301546839232115], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.32241887], dtype=float32), -0.16647364]. 
=============================================
[2019-03-24 00:16:59,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.02667]
 [70.02667]
 [70.02667]
 [70.02667]
 [70.02667]], R is [[70.02487183]
 [70.02359009]
 [70.02229309]
 [70.02088928]
 [70.0192337 ]].
[2019-03-24 00:17:00,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2736957e-24 1.0000000e+00 2.9528845e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:17:00,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5947
[2019-03-24 00:17:00,105] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 85.66666666666667, 1.0, 2.0, 0.614949042738052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726399.6839182051, 726399.6839182051, 161839.1798332473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608600.0000, 
sim time next is 4609200.0000, 
raw observation next is [24.46666666666667, 86.33333333333334, 1.0, 2.0, 0.9739310075978798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.143917879090234, 6.9112, 121.925215938918, 1259093.196824242, 1139921.650648362, 236091.7921877085], 
processed observation next is [1.0, 0.34782608695652173, 0.46172839506172847, 0.8633333333333334, 1.0, 1.0, 0.9689654852355711, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.023271787909023355, 0.0, 0.8094566405462403, 0.4496761417229435, 0.40711487523155787, 0.45402267728405477], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.061569], dtype=float32), -2.3172226]. 
=============================================
[2019-03-24 00:17:09,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.477548e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:17:09,201] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1556
[2019-03-24 00:17:09,208] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 92.33333333333333, 1.0, 2.0, 0.5938327677525224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686058.1673202098, 686058.1673202098, 157470.3687214837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758600.0000, 
sim time next is 4759200.0000, 
raw observation next is [24.2, 92.0, 1.0, 2.0, 0.5934103091156503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685721.1739788963, 685721.1739788959, 157404.8735761999], 
processed observation next is [1.0, 0.08695652173913043, 0.45185185185185184, 0.92, 1.0, 1.0, 0.5159646537091075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24490041927817727, 0.2449004192781771, 0.3027016799542306], 
reward next is 0.6973, 
noisyNet noise sample is [array([-1.0739238], dtype=float32), -0.8923424]. 
=============================================
[2019-03-24 00:17:28,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6040108e-23 1.0000000e+00 2.6177679e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:17:28,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0493
[2019-03-24 00:17:28,825] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 93.16666666666667, 1.0, 2.0, 0.7523827438174635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857536.8852156377, 857536.8852156377, 186303.0087456266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127000.0000, 
sim time next is 5127600.0000, 
raw observation next is [26.8, 93.33333333333334, 1.0, 2.0, 0.7696448016123544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 877222.7737510388, 877222.7737510388, 189753.298278651], 
processed observation next is [0.0, 0.34782608695652173, 0.5481481481481482, 0.9333333333333335, 1.0, 1.0, 0.7257676209670886, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31329384776822816, 0.31329384776822816, 0.36491018899740574], 
reward next is 0.6351, 
noisyNet noise sample is [array([-0.02936888], dtype=float32), 0.80764395]. 
=============================================
[2019-03-24 00:17:37,163] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 00:17:37,165] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:17:37,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:37,166] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:17:37,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:37,167] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:17:37,169] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:37,170] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:17:37,172] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:17:37,172] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:37,174] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:37,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 00:17:37,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 00:17:37,225] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 00:17:37,279] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 00:17:37,312] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 00:17:54,426] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8751431]
[2019-03-24 00:17:54,427] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.4, 31.0, 1.0, 2.0, 0.3187723533355629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409348.9233366532, 409348.9233366532, 117924.9848861522]
[2019-03-24 00:17:54,428] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:17:54,431] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3364486e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3457219918947875
[2019-03-24 00:18:42,690] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8751431]
[2019-03-24 00:18:42,692] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.82772296, 64.72723552, 1.0, 2.0, 0.8528586917037324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972128.135444983, 972128.135444983, 207104.7558975833]
[2019-03-24 00:18:42,695] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:18:42,696] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3364486e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4845868095941168
[2019-03-24 00:18:59,513] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8751431]
[2019-03-24 00:18:59,514] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.4, 85.0, 1.0, 2.0, 0.3614997430522861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457395.6620533384, 457395.6620533384, 123485.8022460818]
[2019-03-24 00:18:59,515] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:18:59,519] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3364486e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4916462343034832
[2019-03-24 00:19:08,258] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8751431]
[2019-03-24 00:19:08,259] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.6, 88.0, 1.0, 2.0, 0.434822665971102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531666.1974201335, 531666.1974201335, 133452.7044467096]
[2019-03-24 00:19:08,260] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:19:08,262] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3364486e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.38928746691094285
[2019-03-24 00:19:08,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8751431]
[2019-03-24 00:19:08,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.05, 46.5, 1.0, 2.0, 0.3319409276759566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428195.9636084027, 428195.9636084027, 118687.3253338917]
[2019-03-24 00:19:08,789] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:19:08,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3364486e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5885592927365875
[2019-03-24 00:19:22,157] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:19:22,779] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:19:22,846] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:19:22,930] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:19:23,140] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:19:24,157] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2475000, evaluation results [2475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:19:24,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5116876e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:24,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7103
[2019-03-24 00:19:24,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1455250.206710822 W.
[2019-03-24 00:19:24,284] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 82.0, 1.0, 2.0, 0.6352082016139038, 1.0, 2.0, 0.6352082016139038, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1455250.206710822, 1455250.206710823, 280701.314924486], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5310000.0000, 
sim time next is 5310600.0000, 
raw observation next is [24.9, 80.83333333333334, 1.0, 2.0, 0.3990150793794426, 1.0, 2.0, 0.3990150793794426, 1.0, 1.0, 0.6352450013859788, 6.911199999999999, 6.9112, 121.94756008, 1364797.259658505, 1364797.259658505, 296650.9528254907], 
processed observation next is [1.0, 0.4782608695652174, 0.47777777777777775, 0.8083333333333335, 1.0, 1.0, 0.2845417611660031, 1.0, 1.0, 0.2845417611660031, 1.0, 0.5, 0.5440562517324735, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4874275927351803, 0.4874275927351803, 0.5704826015874821], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17628263], dtype=float32), 0.09396504]. 
=============================================
[2019-03-24 00:19:26,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5067415e-22 1.0000000e+00 1.9010226e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:26,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6117
[2019-03-24 00:19:26,604] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 67.5, 1.0, 2.0, 0.5747424296815083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657763.7514122635, 657763.7514122635, 153926.3635162112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5333400.0000, 
sim time next is 5334000.0000, 
raw observation next is [28.36666666666667, 67.66666666666666, 1.0, 2.0, 0.5815955838766952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665724.5852588853, 665724.5852588853, 155086.3740216427], 
processed observation next is [1.0, 0.7391304347826086, 0.606172839506173, 0.6766666666666665, 1.0, 1.0, 0.5018995046151133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2377587804496019, 0.2377587804496019, 0.2982430269646975], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.8917474], dtype=float32), -0.6561342]. 
=============================================
[2019-03-24 00:19:26,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.116447]
 [61.116447]
 [61.116447]
 [61.116447]
 [61.116447]], R is [[61.20703888]
 [61.29895782]
 [61.38659668]
 [61.34102249]
 [60.72761154]].
[2019-03-24 00:19:32,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9070209e-23 1.0000000e+00 7.3093275e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:32,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6856
[2019-03-24 00:19:32,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 78.5, 1.0, 2.0, 0.7635595856332688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 870283.0519029445, 870283.0519029449, 188531.9101965194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5425800.0000, 
sim time next is 5426400.0000, 
raw observation next is [29.06666666666667, 79.0, 1.0, 2.0, 0.7651908413745665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872143.3677295578, 872143.3677295578, 188858.9530108575], 
processed observation next is [1.0, 0.8260869565217391, 0.6320987654320989, 0.79, 1.0, 1.0, 0.7204652873506744, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31147977418912776, 0.31147977418912776, 0.36319029425164906], 
reward next is 0.6368, 
noisyNet noise sample is [array([-0.88612324], dtype=float32), -0.8430479]. 
=============================================
[2019-03-24 00:19:38,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0641577e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:38,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1166
[2019-03-24 00:19:38,227] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 85.66666666666667, 1.0, 2.0, 0.7235659841935049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829718.9859861023, 829718.9859861023, 180907.6165964613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5557200.0000, 
sim time next is 5557800.0000, 
raw observation next is [25.4, 85.33333333333334, 1.0, 2.0, 0.7187164923332447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 824988.747273251, 824988.7472732505, 180011.8397986843], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.8533333333333334, 1.0, 1.0, 0.6651386813491009, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2946388383118753, 0.29463883831187515, 0.34617661499746977], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.58406776], dtype=float32), -1.6111709]. 
=============================================
[2019-03-24 00:19:42,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.668141e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:19:42,304] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-24 00:19:42,307] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 82.0, 1.0, 2.0, 0.391480599439211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486259.0534430764, 486259.0534430759, 127451.5856219057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5875200.0000, 
sim time next is 5875800.0000, 
raw observation next is [21.18333333333333, 82.16666666666667, 1.0, 2.0, 0.388029729214556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482511.3769824877, 482511.3769824877, 126982.7420333007], 
processed observation next is [1.0, 0.0, 0.34012345679012335, 0.8216666666666668, 1.0, 1.0, 0.27146396335066186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17232549177945988, 0.17232549177945988, 0.2441975808332706], 
reward next is 0.7558, 
noisyNet noise sample is [array([-1.9920264], dtype=float32), -0.2457694]. 
=============================================
[2019-03-24 00:19:51,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2866943e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:51,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1334
[2019-03-24 00:19:51,659] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 45.5, 1.0, 2.0, 0.9038185791195201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.104559769049052, 6.9112, 121.9250150377203, 1231636.606345274, 1132619.956799492, 222449.1399466163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5830200.0000, 
sim time next is 5830800.0000, 
raw observation next is [26.66666666666667, 45.66666666666666, 1.0, 2.0, 0.9168057569350389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.185900487850556, 6.9112, 121.9247005023095, 1288382.372966671, 1147712.719188798, 225438.2093515593], 
processed observation next is [1.0, 0.4782608695652174, 0.5432098765432101, 0.45666666666666655, 1.0, 1.0, 0.9009592344464749, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.027470048785055566, 0.0, 0.8094532185831762, 0.460136561773811, 0.409897399710285, 0.43353501798376787], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.058567], dtype=float32), 0.3951391]. 
=============================================
[2019-03-24 00:19:54,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4740945e-24 1.0000000e+00 5.0575574e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:54,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3994
[2019-03-24 00:19:54,549] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 70.0, 1.0, 2.0, 0.4188713661933642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515299.8323312071, 515299.8323312066, 131220.3634592499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [23.55, 71.0, 1.0, 2.0, 0.4180151406937834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514446.9521744305, 514446.9521744301, 131102.2429836291], 
processed observation next is [1.0, 0.9130434782608695, 0.4277777777777778, 0.71, 1.0, 1.0, 0.3071608817783136, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18373105434801087, 0.18373105434801074, 0.2521196980454406], 
reward next is 0.7479, 
noisyNet noise sample is [array([1.0073515], dtype=float32), 1.8011127]. 
=============================================
[2019-03-24 00:19:58,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8638951e-24 1.0000000e+00 4.2412834e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:19:58,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0751
[2019-03-24 00:19:58,105] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 77.0, 1.0, 2.0, 0.4508983077953888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557033.2995638859, 557033.2995638859, 135981.9205735227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5986800.0000, 
sim time next is 5987400.0000, 
raw observation next is [22.51666666666667, 76.33333333333334, 1.0, 2.0, 0.5587365226391323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689922.7998019736, 689922.7998019736, 153165.1159935599], 
processed observation next is [1.0, 0.30434782608695654, 0.3895061728395063, 0.7633333333333334, 1.0, 1.0, 0.4746863364751575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2464009999292763, 0.2464009999292763, 0.2945482999876152], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.28745916], dtype=float32), 0.6029124]. 
=============================================
[2019-03-24 00:20:00,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1341077e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:20:00,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8408
[2019-03-24 00:20:00,410] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 83.5, 1.0, 2.0, 0.4299384355561725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531816.2610071403, 531816.2610071403, 132896.202335909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976600.0000, 
sim time next is 5977200.0000, 
raw observation next is [21.33333333333334, 84.0, 1.0, 2.0, 0.4053919065895645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 501582.238371277, 501582.2383712765, 129365.1169745671], 
processed observation next is [1.0, 0.17391304347826086, 0.3456790123456792, 0.84, 1.0, 1.0, 0.2921332221304339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1791365137040275, 0.1791365137040273, 0.24877907110493674], 
reward next is 0.7512, 
noisyNet noise sample is [array([1.1409392], dtype=float32), -0.50453997]. 
=============================================
[2019-03-24 00:20:02,204] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.207534e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:20:02,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-24 00:20:02,219] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 72.0, 1.0, 2.0, 0.5220135290974621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618613.8887175892, 618613.8887175892, 146244.1373602733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6038400.0000, 
sim time next is 6039000.0000, 
raw observation next is [25.7, 72.5, 1.0, 2.0, 0.5234370492894204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620516.0628820707, 620516.0628820707, 146481.4123678921], 
processed observation next is [1.0, 0.9130434782608695, 0.5074074074074074, 0.725, 1.0, 1.0, 0.4326631539159766, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22161287960073953, 0.22161287960073953, 0.2816950237844079], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.07900295], dtype=float32), 1.9034921]. 
=============================================
[2019-03-24 00:20:02,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.13859]
 [68.13859]
 [68.13859]
 [68.13859]
 [68.13859]], R is [[68.17550659]
 [68.21250916]
 [68.2485733 ]
 [68.28367615]
 [68.31786346]].
[2019-03-24 00:20:05,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1179839e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:20:05,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2097
[2019-03-24 00:20:05,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1675377.303879516 W.
[2019-03-24 00:20:05,286] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 61.5, 1.0, 2.0, 0.4897219879238953, 1.0, 1.0, 0.4897219879238953, 1.0, 2.0, 0.7796533539065211, 6.911199999999999, 6.9112, 121.94756008, 1675377.303879516, 1675377.303879516, 338573.1046078034], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6085800.0000, 
sim time next is 6086400.0000, 
raw observation next is [28.5, 62.66666666666666, 1.0, 2.0, 0.9038149718678388, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1745439.333760404, 1745439.333760404, 357787.4375770144], 
processed observation next is [1.0, 0.43478260869565216, 0.6111111111111112, 0.6266666666666666, 1.0, 1.0, 0.8854940141283795, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6233711906287157, 0.6233711906287157, 0.6880527645711815], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12555707], dtype=float32), 0.49038392]. 
=============================================
[2019-03-24 00:20:05,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.977404e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 00:20:05,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8972
[2019-03-24 00:20:05,876] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 73.5, 1.0, 2.0, 0.5244068684629434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622110.8385706975, 622110.8385706975, 146654.8558120476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6040200.0000, 
sim time next is 6040800.0000, 
raw observation next is [25.4, 74.0, 1.0, 2.0, 0.5230681342840725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620756.497990397, 620756.497990397, 146448.3358443968], 
processed observation next is [1.0, 0.9565217391304348, 0.49629629629629624, 0.74, 1.0, 1.0, 0.4322239693858006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22169874928228467, 0.22169874928228467, 0.2816314150853784], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.5071], dtype=float32), 1.2794278]. 
=============================================
[2019-03-24 00:20:08,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0197648e-24 1.0000000e+00 1.5091757e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 00:20:08,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2101
[2019-03-24 00:20:08,309] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 53.66666666666667, 1.0, 2.0, 0.4885838245297905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 586483.3477726496, 586483.3477726501, 141247.1449567288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6888000.0000, 
sim time next is 6888600.0000, 
raw observation next is [28.25, 54.0, 1.0, 2.0, 0.4866959617926254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584634.5067661225, 584634.5067661221, 140968.5673665104], 
processed observation next is [0.0, 0.7391304347826086, 0.6018518518518519, 0.54, 1.0, 1.0, 0.38892376403883977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20879803813075803, 0.20879803813075787, 0.27109339878175076], 
reward next is 0.7289, 
noisyNet noise sample is [array([-0.1468853], dtype=float32), 1.1908816]. 
=============================================
[2019-03-24 00:20:13,581] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 00:20:13,582] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:20:13,583] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:20:13,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:20:13,583] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:20:13,583] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:20:13,583] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:20:13,584] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:20:13,585] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:20:13,586] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:20:13,587] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:20:13,614] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 00:20:13,640] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 00:20:13,677] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 00:20:13,702] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 00:20:13,728] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/37/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 00:20:18,235] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8837161]
[2019-03-24 00:20:18,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.11666666666667, 41.00000000000001, 1.0, 2.0, 0.2526293585174813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 325870.8574791412, 325870.8574791407, 97707.8346852294]
[2019-03-24 00:20:18,238] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:20:18,241] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5017595e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4216814087458982
[2019-03-24 00:20:33,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8837161]
[2019-03-24 00:20:33,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.66666666666666, 30.16666666666666, 1.0, 2.0, 0.4874285189528065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599837.9755699959, 599837.9755699959, 141516.4655174341]
[2019-03-24 00:20:33,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:20:33,730] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5017595e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.08474301745421842
[2019-03-24 00:21:34,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02470155], dtype=float32), -0.8837161]
[2019-03-24 00:21:34,578] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.25, 30.5, 1.0, 2.0, 0.5047962653438531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600239.9098770042, 600239.9098770042, 143581.6407455135]
[2019-03-24 00:21:34,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:21:34,580] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5017595e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.24653697529484997
[2019-03-24 00:22:00,084] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:22:00,185] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:22:00,276] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:22:00,382] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:22:00,648] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:22:01,665] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2500000, evaluation results [2500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
